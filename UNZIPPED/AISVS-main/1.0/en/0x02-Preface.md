# Preface

Welcome to the **Artificial Intelligence Security Verification Standard (AISVS) version 1.0!**

## Introduction

Established in 2025 through a collaborative community effort, **AISVS** defines the security requirements to consider when **designing, developing, deploying, and operating modern AI models, pipelines, and AI‑enabled services**.

AISVS v1.0 represents the combined work of its project leads, working group, and wider community contributors to produce a pragmatic, testable baseline for securing AI systems.

Our goal with this release is to make AISVS straightforward to adopt while staying laser‑focused on its defined scope and addressing the rapidly evolving risk landscape unique to AI.

## Key Objectives for AISVS Version 1.0

Version 1.0 will be created with several guiding principles.

### Well‑Defined Scope

Each requirement must align with AISVS’s name and mission:

* **Artificial Intelligence** – Controls operate at the AI/ML layer (data, model, pipeline, or inference) and are the responsibility of AI practitioners.
* **Security** – Requirements directly mitigate identified security, privacy, or safety risks.
* **Verification** – Language is written so conformance can be objectively validated.
* **Standard** – Sections follow a consistent structure and terminology to form a coherent reference.

---

By following AISVS, organizations can systematically evaluate and strengthen the security posture of their AI solutions, fostering a culture of secure AI engineering.
