# C7 モデルの動作、出力制御および安全保証

## 制御目標

モデルの出力は構造化され、信頼性があり、安全で説明可能でなければならず、運用中は継続的に監視される必要があります。これにより、幻覚（ハルシネーション）、プライバシー漏洩、有害コンテンツ、および暴走行動が減少し、ユーザーの信頼と規制遵守が向上します。

---

## C7.1 出力フォーマットの強制

厳格なスキーマ、制約付きデコーディング、および下流の検証により、不正な形式や悪意のあるコンテンツが拡散する前に阻止します。

|   #   | 説明                                                                                                  | レベル | 役割  |
| :---: | --------------------------------------------------------------------------------------------------- | :-: | :-: |
| 7.1.1 | システムプロンプトにレスポンススキーマ（例：JSONスキーマ）が提供されていることを確認し、すべての出力が自動的に検証されるようにします。スキーマに準拠しない出力は修正または拒否されるようにします。 |  1  | D/V |
| 7.1.2 | オーバーフローやプロンプトインジェクションのサイドチャネルを防ぐために、制約付きデコーディング（ストップトークン、正規表現、最大トークン数）が有効になっていることを確認してください。         |  1  | D/V |
| 7.1.3 | 下流のコンポーネントが出力を信頼できないものとして扱い、それらをスキーマやインジェクション安全なデシリアライザで検証していることを確認してください。                          |  2  | D/V |
| 7.1.4 | 不適切な出力イベントがログに記録され、レート制限され、監視に表示されることを確認してください。                                                     |  3  |  V  |

---

## C7.2 幻覚検出と緩和

不確実性の推定とフォールバック戦略は、捏造された回答を抑制します。

|   #   | 説明                                                                              | レベル | 役割  |
| :---: | ------------------------------------------------------------------------------- | :-: | :-: |
| 7.2.1 | トークンレベルの対数確率、アンサンブル自己一貫性、または微調整された幻覚検出器が各回答に信頼度スコアを割り当てることを確認してください。            |  1  | D/V |
| 7.2.2 | 設定可能な信頼度閾値を下回る応答がフォールバックワークフロー（例：リトリーバル強化生成、二次モデル、または人間によるレビュー）をトリガーすることを検証します。 |  1  | D/V |
| 7.2.3 | 幻覚インシデントが根本原因のメタデータでタグ付けされ、ポストモーテムおよびファインチューニングパイプラインに供給されていることを確認してください。       |  2  | D/V |
| 7.2.4 | 主要なモデルまたは知識ベースの更新後に、しきい値と検出器が再キャリブレーションされていることを確認してください。                        |  3  | D/V |
| 7.2.5 | ダッシュボードのビジュアライゼーションが幻覚率を追跡していることを確認してください。                                      |  3  |  V  |

---

## C7.3 出力の安全性およびプライバシーフィルタリング

ポリシーフィルターとレッドチームのカバレッジは、ユーザーと機密データを保護します。

|   #   | 説明                                                                        | レベル | 役割  |
| :---: | ------------------------------------------------------------------------- | :-: | :-: |
| 7.3.1 | ポリシーに沿ったヘイト、嫌がらせ、自傷行為、過激派、性的に露骨なコンテンツを、生成前および生成後の分類器がブロックしていることを確認してください。 |  1  | D/V |
| 7.3.2 | すべての応答でPII/PCI検出と自動編集が実行されることを確認してください。違反が発生した場合はプライバシーインシデントを報告します。      |  1  | D/V |
| 7.3.3 | 機密性タグ（例：企業秘密）が複数のモダリティにわたって伝播し、テキスト、画像、コードにおける漏洩を防止することを確認してください。         |  2  |  D  |
| 7.3.4 | フィルターバイパスの試みや高リスクの分類には、二次承認またはユーザーの再認証が必要であることを確認してください。                  |  3  | D/V |
| 7.3.5 | フィルタリングの閾値が法的管轄区域およびユーザーの年齢・役割のコンテキストを反映していることを確認する。                      |  3  | D/V |

---

## C7.4 出力およびアクション制限

レート制限と承認ゲートは、悪用や過度な自律性を防止します。

|   #   | 説明                                                                                      | レベル | 役割  |
| :---: | --------------------------------------------------------------------------------------- | :-: | :-: |
| 7.4.1 | 429エラー発生時に指数関数的なバックオフを使用して、ユーザーごとおよびAPIキーごとのクォータがリクエスト数、トークン数、およびコストを制限していることを検証してください。 |  1  |  D  |
| 7.4.2 | 特権操作（ファイル書き込み、コード実行、ネットワーク呼び出し）がポリシーベースの承認またはヒューマンインザループを必要とすることを確認してください。              |  1  | D/V |
| 7.4.3 | クロスモーダル整合性チェックが、同じリクエストに対して生成された画像、コード、テキストが悪意のあるコンテンツの密輸に使用されないことを保証することを検証してください。     |  2  | D/V |
| 7.4.4 | エージェントの委任の深さ、再帰制限、および許可されたツールリストが明示的に構成されていることを確認してください。                                |  2  |  D  |
| 7.4.5 | 制限違反がSIEM取り込み用の構造化されたセキュリティイベントを発生させることを検証してください。                                       |  3  |  V  |

---

## C7.5 出力の説明可能性

透明なシグナルは、ユーザーの信頼と内部デバッグを向上させます。

|   #   | 説明                                                                 | レベル | 役割  |
| :---: | ------------------------------------------------------------------ | :-: | :-: |
| 7.5.1 | リスク評価が適切と判断した場合に、ユーザー向けの信頼度スコアまたは簡潔な推論概要が表示されることを確認してください。         |  2  | D/V |
| 7.5.2 | 生成された説明が、機密性の高いシステムプロンプトや専有データを明かさないように確認してください。                   |  2  | D/V |
| 7.5.3 | システムがトークンレベルのログ確率またはアテンションマップをキャプチャし、許可された検査のために保存していることを確認してください。 |  3  |  D  |
| 7.5.4 | 説明可能性の成果物が監査可能性のためにモデルのリリースとともにバージョン管理されていることを確認してください。            |  3  |  V  |

---

## C7.6 監視統合

リアルタイムオブザーバビリティは、開発と本番環境の間のループを閉じます。

|   #   | 説明                                                                           | レベル | 役割  |
| :---: | ---------------------------------------------------------------------------- | :-: | :-: |
| 7.6.1 | メトリクス（スキーマ違反、幻覚率、トキシシティ、PII漏洩、レイテンシ、コスト）が中央監視プラットフォームにストリームされることを検証してください。   |  1  |  D  |
| 7.6.2 | 各安全指標に対してアラートしきい値が定義されており、オンコールのエスカレーション経路が確立されていることを確認してください。               |  1  |  V  |
| 7.6.3 | ダッシュボードが出力異常をモデル／バージョン、機能フラグ、および上流データの変更と関連付けていることを確認してください。                 |  2  |  V  |
| 7.6.4 | 監視データが文書化されたMLOpsワークフロー内で再トレーニング、ファインチューニング、またはルールの更新にフィードバックされることを確認してください。 |  2  | D/V |
| 7.6.5 | 監視パイプラインがペネトレーションテストを受けており、機密ログの漏洩を防ぐためにアクセス制御されていることを確認してください。              |  3  |  V  |

---

## 7.7 生成メディアの安全対策

AIシステムが法律に違反する、有害な、または許可されていないメディアコンテンツを生成しないように、ポリシー制約の強制、出力の検証、および追跡可能性を確保する。

|   #   | 説明                                                                                                   | レベル | 役割  |
| :---: | ---------------------------------------------------------------------------------------------------- | :-: | :-: |
| 7.7.1 | システムプロンプトおよびユーザー指示が、違法、有害、または非合意のディープフェイクメディア（例：画像、動画、音声）の生成を明示的に禁止していることを確認してください。                  |  1  | D/V |
| 7.7.2 | プロンプトがなりすましの生成、性的に露骨なディープフェイク、または同意なしに実在の個人を描写するメディアの生成を試みていないかどうかを検証してください。                         |  2  | D/V |
| 7.7.3 | システムが著作権で保護されたメディアの不正複製を防止するために、知覚ハッシュ、ウォーターマーク検出、またはフィンガープリンティングを使用していることを確認してください。                 |  2  |  V  |
| 7.7.4 | すべての生成されたメディアが暗号的に署名されていること、透かしが入っていること、または改ざん防止の起源情報メタデータが埋め込まれており、下流でのトレーサビリティが確保されていることを検証してください。 |  3  | D/V |
| 7.7.5 | バイパス試行（例：プロンプトの難読化、スラング、敵対的表現）が検出され、ログに記録され、レート制限されていることを検証する。繰り返される悪用は監視システムに報告される。                 |  3  |  V  |

## 参考文献

* [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)
* [ISO/IEC 42001:2023 – AI Management System](https://www.iso.org/obp/ui/en/)
* [OWASP Top-10 for Large Language Model Applications (2025)](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Practical Techniques to Constrain LLM Output](https://mychen76.medium.com/practical-techniques-to-constraint-llm-output-in-json-format-e3e72396c670)
* [Dataiku – Structured Text Generation Guide](https://blog.dataiku.com/your-guide-to-structured-text-generation)
* [VL-Uncertainty: Detecting Hallucinations](https://arxiv.org/abs/2411.11919)
* [HaDeMiF: Hallucination Detection & Mitigation](https://openreview.net/forum?id=VwOYxPScxB)
* [Building Confidence in LLM Outputs](https://www.alkymi.io/data-science-room/building-confidence-in-llm-outputs)
* [Explainable AI & LLMs](https://duncsand.medium.com/explainable-ai-140912d31b3b)
* [Sensitive Information Disclosure in LLMs](https://virtualcyberlabs.com/llm-sensitive-information-disclosure/)
* [OpenAI Rate-Limit & Exponential Back-off](https://hackernoon.com/openais-rate-limit-a-guide-to-exponential-backoff-for-llm-evaluation)
* [Arize AI – LLM Observability Platform](https://arize.com/)

