# صفحه نخست

## درباره استاندارد

استاندارد تأیید امنیت هوش مصنوعی (AISVS) فهرستی مبتنی بر جامعه از الزامات امنیتی است که دانشمندان داده، مهندسان MLOps، معماران نرم‌افزار، توسعه‌دهندگان، تست‌کنندگان، متخصصان امنیت، فروشندگان ابزار، ناظران و مصرف‌کنندگان می‌توانند برای طراحی، ساخت، آزمایش و تأیید سیستم‌ها و برنامه‌های مبتنی بر هوش مصنوعی قابل اعتماد از آن استفاده کنند. این استاندارد زبان مشترکی برای مشخص کردن کنترل‌های امنیتی در سراسر چرخه عمر هوش مصنوعی فراهم می‌کند—از جمع‌آوری داده‌ها و توسعه مدل گرفته تا استقرار و نظارت مداوم—تا سازمان‌ها بتوانند تاب‌آوری، حفظ حریم خصوصی و ایمنی راهکارهای هوش مصنوعی خود را اندازه‌گیری و بهبود بخشند.

## کپی‌رایت و مجوز

نسخه 0.1 (اولین پیش‌نویس عمومی - در حال کار)، 2025  

![license](../images/license.png)

کپی‌رایت © 2025-2026 پروژه AISVS.  

منتشر شده تحت[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
برای هر گونه استفاده مجدد یا توزیع، باید شرایط مجوز این اثر را به وضوح به دیگران اطلاع دهید.

## رهبران پروژه

|             |                       |
| ----------- | --------------------- |
| جیم مَنی‌کو | آراس "راس" ممیسیازیچی |

## همکاران و بازبین‌ها

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS یک استاندارد کاملاً جدید است که به طور خاص برای پرداختن به چالش‌های امنیتی منحصر به فرد سیستم‌های هوش مصنوعی ایجاد شده است. در حالی که این استاندارد از بهترین شیوه‌های امنیتی گسترده‌تر الهام گرفته، هر الزامی در AISVS از پایه توسعه یافته است تا چشم‌انداز تهدیدات هوش مصنوعی را منعکس کند و به سازمان‌ها کمک کند تا راه‌حل‌های هوش مصنوعی ایمن‌تر و مقاوم‌تری بسازند.

