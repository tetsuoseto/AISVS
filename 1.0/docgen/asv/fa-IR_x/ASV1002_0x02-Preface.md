# پیشگفتار

به استاندارد تایید امنیت هوش مصنوعی (AISVS) نسخه 1.0 خوش آمدید!

## معرفی

AISVS که در سال 2025 از طریق تلاشی مشترک در جامعه تأسیس شد، الزامات امنیتی را که هنگام طراحی، توسعه، استقرار و بهره‌برداری از مدل‌های مدرن هوش مصنوعی، زنجیره‌های پردازش و خدمات فعال‌شده با هوش مصنوعی باید در نظر گرفته شود، تعریف می‌کند.

AISVS v1.0 نمایانگر کار ترکیبی رهبران پروژه، گروه کاری و مشارکت‌کنندگان گسترده‌تر جامعه است که برای ایجاد یک پایه عملی و قابل آزمون به منظور تأمین امنیت سیستم‌های هوش مصنوعی انجام شده است.

هدف ما در این نسخه این است که AISVS را به روشی ساده برای پذیرش تبدیل کنیم، در حالی که تمرکز دقیقی بر دامنه تعریف شده آن داشته باشیم و به چشم‌انداز رو به رشد خطرات منحصربه‌فرد هوش مصنوعی بپردازیم.

## اهداف کلیدی برای نسخه 1.0 AISVS

نسخه 1.0 با چندین اصول راهنمایی ایجاد خواهد شد.

### دامنه‌ مشخص و معین

هر نیاز باید با نام و مأموریت AISVS همسو باشد:

* هوش مصنوعی – کنترل‌ها در لایه AI/ML (داده، مدل، خط لوله، یا استنتاج) عمل می‌کنند و مسئولیت آنها بر عهده متخصصان AI است.
* امنیت – الزامات به طور مستقیم خطرات شناسایی شده امنیتی، حریم خصوصی یا ایمنی را کاهش می‌دهند.
* تأیید صحت – زبان به گونه‌ای نوشته شده که انطباق آن به صورت عینی قابل اعتبارسنجی باشد.
* استاندارد – بخش‌ها ساختار و اصطلاحات یکسانی را دنبال می‌کنند تا یک مرجع منسجم ایجاد کنند.
  ​
---

با پیروی از AISVS، سازمان‌ها می‌توانند به‌طور سیستماتیک وضعیت امنیتی راه‌حل‌های هوش مصنوعی خود را ارزیابی و تقویت کنند و فرهنگ مهندسی هوش مصنوعی امن را ترویج دهند.

