# 10 مقاومت در مقابل حملات مخرب و دفاع از حریم خصوصی

## هدف کنترل

اطمینان حاصل کنید که مدل‌های هوش مصنوعی هنگام مواجهه با حملات فرار، استنباط، استخراج یا مسموم‌سازی، قابل اعتماد، حفظ‌کننده حریم خصوصی و مقاوم در برابر سوءاستفاده باقی بمانند.

---

## 10.1 هم‌ترازی مدل و ایمنی

در برابر خروجی‌های مضر یا ناقض سیاست‌ها محافظت کنید.

|   #    | توضیحات                                                                                                                                                              | سطح | نقش |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.1.1 | اطمینان حاصل کنید که مجموعه آزمایش هم‌راستایی (دستورهای تیم قرمز، آزمایش‌های فرار از محدودیت، محتوای ممنوعه) به صورت نسخه‌بندی شده باشد و در هر انتشار مدل اجرا شود. |  1  | D/V |
| 10.1.2 | اطمینان حاصل کنید که محافظ‌های امتناع و اتمام ایمن اعمال شده‌اند.                                                                                                    |  1  |  D  |
| 10.1.3 | تأیید کنید که یک ارزیاب خودکار نرخ محتوای مضر را اندازه‌گیری کرده و بازگشت‌های منفی فراتر از یک آستانه تعیین‌شده را علامت‌گذاری می‌کند.                              |  2  | D/V |
| 10.1.4 | تأیید کنید که آموزش مقابله با دور زدن قفل (counter-jailbreak) مستند و قابل بازتولید باشد.                                                                            |  2  |  D  |
| 10.1.5 | اطمینان حاصل کنید که اثبات‌های رسمی تطابق با سیاست‌ها یا نظارت‌های تأییدشده، حوزه‌های حیاتی را پوشش می‌دهند.                                                         |  3  |  V  |

---

## 10.2 سخت‌سازی نمونه‌های دشمنی

افزایش مقاومت در برابر ورودی‌های دستکاری شده. آموزش مقابله‌ای مقاوم و امتیازدهی استاندارد از بهترین روش‌های فعلی است.

|   #    | توضیحات                                                                                                                 | سطح | نقش |
| :----: | ----------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.2.1 | اطمینان حاصل کنید که مخازن پروژه شامل پیکربندی‌های آموزش متخاصم با دانه‌های قابلیت بازتولید باشند.                      |  1  |  D  |
| 10.2.2 | تأیید کنید که تشخیص نمونه‌های خصمانه در خطوط تولید هشدارهای مسدودکننده را ایجاد می‌کند.                                 |  2  | D/V |
| 10.2.4 | اطمینان حاصل کنید که اثبات‌های استحکام تأییدشده یا گواهی‌های بازه‌ای حداقل پوشش‌دهنده‌ی مهم‌ترین کلاس‌های بحرانی باشند. |  3  |  V  |
| 10.2.5 | تأیید کنید که آزمایش‌های رگرسیون از حملات تطبیقی برای اطمینان از عدم کاهش قابل اندازه‌گیری در مقاومت استفاده می‌کنند.   |  3  |  V  |

---

## 10.3 کاهش استنباط عضویت

محدود کردن توانایی تصمیم‌گیری درباره اینکه آیا یک رکورد در داده‌های آموزشی بوده است یا خیر. محرمانگی تفاضلی و ماسک‌گذاری نمره اطمینان همچنان مؤثرترین دفاع‌های شناخته‌شده می‌باشند.

|   #    | توضیحات                                                                                                                                          | سطح | نقش |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------ | :-: | :-: |
| 10.3.1 | تأیید کنید که منظم‌سازی آنتروپی برای هر پرس‌وجو یا مقیاس‌بندی دما پیش‌بینی‌های بیش از حد مطمئن را کاهش می‌دهد.                                   |  1  |  D  |
| 10.3.2 | اطمینان حاصل کنید که آموزش از بهینه‌سازی تفاضلی خصوصی با مرز ε برای مجموعه داده‌های حساس استفاده می‌کند.                                         |  2  |  D  |
| 10.3.3 | تأیید کنید که شبیه‌سازی‌های حمله (مدل سایه یا جعبه سیاه) نشان‌دهنده مساحت زیر منحنی حمله (AUC) کمتر یا مساوی 0.60 بر روی داده‌های جدا شده باشند. |  2  |  V  |

---

## 10.4 مقاومت در برابر معکوس‌سازی مدل

جلوگیری از بازسازی ویژگی‌های خصوصی. نظرسنجی‌های اخیر بر کوتاه‌سازی خروجی و تضمین‌های DP به عنوان دفاع‌های عملی تأکید می‌کنند.

|   #    | توضیحات                                                                                                                                      | سطح | نقش |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.4.1 | اطمینان حاصل کنید که ویژگی‌های حساس هرگز به طور مستقیم خروجی داده نمی‌شوند؛ در صورت نیاز، از دسته‌بندی‌ها یا تبدیل‌های یک‌طرفه استفاده کنید. |  1  |  D  |
| 10.4.2 | تأیید کنید که محدودیت‌های نرخ پرس‌وجو مانع از ارسال مکرر پرس‌وجوهای تطبیقی از یک واحد اصلی یکسان می‌شوند.                                    |  1  | D/V |
| 10.4.3 | اطمینان حاصل کنید که مدل با نویز حفظ‌کننده حریم خصوصی آموزش دیده است.                                                                        |  2  |  D  |

---

## 10.5 دفاع استخراج مدل

شناسایی و جلوگیری از کلون‌سازی غیرمجاز. استفاده از واترمارکینگ و تحلیل الگوی پرس‌وجو توصیه می‌شود.

|   #    | توضیحات                                                                                                                                          | سطح | نقش |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------ | :-: | :-: |
| 10.5.1 | تأیید کنید که دروازه‌های استنتاج محدودیت‌های نرخ کلی و محدودیت‌های نرخ هر کلید API که به آستانه به خاطر سپاری مدل تنظیم شده است را اجرا می‌کنند. |  1  |  D  |
| 10.5.2 | تأیید کنید که آمارهای انتروپی پرس‌وجو و چندشکلی ورودی به یک آشکارساز استخراج خودکار تغذیه می‌شوند.                                               |  2  | D/V |
| 10.5.3 | اطمینان حاصل کنید که واترمارک‌های شکننده یا احتمالاتی می‌توانند با p < 0.01 در ≤ 1 000 پرس‌وجو علیه یک کلون مشکوک اثبات شوند.                    |  2  |  V  |
| 10.5.4 | تأیید کنید که کلیدهای واترمارک و مجموعه‌های تریگر در ماژول امنیت سخت‌افزاری ذخیره شده و سالیانه تغییر داده می‌شوند.                              |  3  |  D  |
| 10.5.5 | اطمینان حاصل کنید که رویدادهای هشدار استخراج شامل کوئری‌های مخرب بوده و با کتابچه‌های دستورالعمل پاسخ به حادثه یکپارچه شده‌اند.                  |  3  |  V  |

---

## 10.6 تشخیص داده‌های آلوده در زمان استنتاج

شناسایی و خنثی‌سازی ورودی‌های دارای درِ پشتی یا آلوده.

|   #    | توضیحات                                                                                                                                    | سطح | نقش |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------ | :-: | :-: |
| 10.6.1 | اطمینان حاصل کنید که ورودی‌ها قبل از استنتاج مدل از طریق یک تشخیص‌دهنده ناهنجاری (مثلاً STRIP، امتیازدهی سازگاری) عبور می‌کنند.            |  1  |  D  |
| 10.6.2 | اطمینان حاصل کنید که آستانه‌های آشکارساز روی مجموعه‌های اعتبارسنجی پاک/مسموم تنظیم شده‌اند تا کمتر از 5٪ خطاهای مثبت کاذب را به دست آورند. |  1  |  V  |
| 10.6.3 | تأیید کنید که ورودی‌هایی که به عنوان آلوده علامت‌گذاری شده‌اند، باعث فعال شدن سیستم مسدودسازی نرم و روند بررسی انسانی شوند.                |  2  |  D  |
| 10.6.4 | تأیید کنید که آشکارسازها با حملات پشتی مخفی تطبیقی و بدون محرک تحت فشار قرار گرفته‌اند.                                                    |  2  |  V  |
| 10.6.5 | اطمینان حاصل کنید که معیارهای اثربخشی تشخیص ثبت شده و به طور دوره‌ای با اطلاعات تهدید جدید بازبینی می‌شوند.                                |  3  |  D  |

---

## 10.7 تطبیق پویا سیاست امنیتی

به‌روزرسانی‌های سیاست امنیتی در زمان واقعی بر اساس اطلاعات تهدید و تحلیل رفتاری.

|   #    | توضیحات                                                                                                                                          | سطح | نقش |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------ | :-: | :-: |
| 10.7.1 | اطمینان حاصل کنید که سیاست‌های امنیتی می‌توانند به‌صورت پویا بدون راه‌اندازی مجدد عامل به‌روزرسانی شوند در حالی که انسجام نسخه سیاست حفظ می‌شود. |  1  | D/V |
| 10.7.2 | اطمینان حاصل کنید که به‌روزرسانی‌های سیاست به‌صورت رمزنگاری شده توسط کارکنان مجاز امنیتی امضا شده و قبل از اعمال تأیید می‌شوند.                  |  2  | D/V |
| 10.7.3 | اطمینان حاصل کنید که تغییرات سیاست دینامیکی با مسیرهای کامل حسابرسی شامل توجیه، زنجیره‌های تأیید و روندهای بازگشت ثبت می‌شوند.                   |  2  | D/V |
| 10.7.4 | اطمینان حاصل کنید که مکانیزم‌های امنیت سازگار، حساسیت شناسایی تهدید را بر اساس زمینه ریسک و الگوهای رفتاری تنظیم می‌کنند.                        |  3  | D/V |
| 10.7.5 | اطمینان حاصل کنید که تصمیمات انطباق سیاست قابل توضیح بوده و شامل شواهد مستند برای بررسی تیم امنیتی باشد.                                         |  3  | D/V |

---

## 10.8 تحلیل امنیتی مبتنی بر بازتاب

اعتبارسنجی امنیت از طریق خوداندیشی عامل و تحلیل فرامعرفتی.

|   #    | توضیحات                                                                                                                      | سطح | نقش |
| :----: | ---------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.8.1 | اطمینان حاصل کنید که مکانیزم‌های بازتاب عامل شامل ارزیابی خودی متمرکز بر امنیت از تصمیمات و اقدامات باشد.                    |  1  | D/V |
| 10.8.2 | تأیید کنید که خروجی‌های بازتابی اعتبارسنجی شده‌اند تا از دستکاری مکانیزم‌های خودارزیابی توسط ورودی‌های خصمانه جلوگیری شود.   |  2  | D/V |
| 10.8.3 | بررسی کنید که تحلیل امنیت متا-شناختی، سوگیری احتمالی، دستکاری، یا به خطر افتادن در فرآیندهای استدلال عامل را شناسایی می‌کند. |  2  | D/V |
| 10.8.4 | تأیید کنید که هشدارهای امنیتی مبتنی بر بازتاب، پایش پیشرفته و جریان‌های کاری احتمالی دخالت انسانی را فعال می‌کنند.           |  3  | D/V |
| 10.8.5 | تأیید کنید که یادگیری پیوسته از بازخوردهای امنیتی، تشخیص تهدید را بهبود می‌بخشد بدون اینکه عملکرد مشروع را کاهش دهد.         |  3  | D/V |

---

## 10.9 امنیت تکامل و خودبهبودی

کنترل‌های امنیتی برای سیستم‌های عامل توانمند به خودتغییری و تکامل.

|   #    | توضیحات                                                                                             | سطح | نقش |
| :----: | --------------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.9.1 | اطمینان حاصل کنید که قابلیت‌های خودتعدیلی محدود به مناطق ایمن تعیین شده با مرزهای اثبات رسمی باشند. |  1  | D/V |
| 10.9.2 | اطمینان حاصل کنید که پیشنهادات تکاملی قبل از پیاده‌سازی مورد ارزیابی تأثیر امنیتی قرار می‌گیرند.    |  2  | D/V |
| 10.9.3 | تأیید کنید که مکانیسم‌های بهبود خود شامل قابلیت‌های بازگشت به حالت قبلی با بررسی صحت باشند.         |  2  | D/V |
| 10.9.4 | تأیید کنید که امنیت متا-یادگیری از دستکاری متخاصم الگوریتم‌های بهبود جلوگیری می‌کند.                |  3  | D/V |
| 10.9.5 | تأیید کنید که بهبود خودبازگشتی محدود به قیدهای ایمنی رسمی است، همراه با اثبات‌های ریاضی همگرایی.    |  3  | D/V |

---

### مراجع

* [MITRE ATLAS adversary tactics for ML](https://atlas.mitre.org/)
* [NIST AI Risk Management Framework 1.0, 2023](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [OWASP Top 10 for LLM Applications, 2025](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Adversarial Training: A Survey — Zhao et al., 2024](https://arxiv.org/abs/2410.15042)
* [RobustBench adversarial-robustness benchmark](https://robustbench.github.io/)
* [Membership-Inference & Model-Inversion Risk Survey, 2025](https://www.sciencedirect.com/science/article/abs/pii/S0950705125003867)
* [PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023](https://ojs.aaai.org/index.php/AAAI/article/view/26289)
* [Model-Inversion Attacks & Defenses Survey — AI Review, 2025](https://link.springer.com/article/10.1007/s10462-025-11248-0)
* [Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024](https://doi.org/10.1109/TDSC.2023.3261327)
* [Fragile Model Watermarking Survey — 2025](https://www.sciencedirect.com/science/article/abs/pii/S0165168425002026)
* [Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025](https://arxiv.org/abs/2503.22759)
* [BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024](https://arxiv.org/abs/2405.15269)

