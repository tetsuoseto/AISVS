# C13 인간 감독, 책임 및 거버넌스

## 제어 목표

이 장은 AI 시스템에서 인간의 감독과 명확한 책임 체계를 유지하기 위한 요구 사항을 제공하여 AI 생명주기 전반에 걸쳐 설명 가능성, 투명성 및 윤리적 관리가 보장되도록 합니다.

---

## C13.1 킬 스위치 및 오버라이드 메커니즘

AI 시스템의 안전하지 않은 동작이 관찰될 때 셧다운 또는 롤백 경로를 제공하십시오.

|   #    | 설명                                                     | 레벨  | 역할  |
| :----: | ------------------------------------------------------ | :-: | :-: |
| 13.1.1 | AI 모델 추론 및 출력을 즉시 중단할 수 있는 수동 킬스위치 메커니즘이 존재하는지 확인하십시오. |  1  | D/V |
| 13.1.2 | 재정의 제어가 허가된 인원만 접근할 수 있는지 확인하십시오.                      |  1  |  D  |
| 13.1.3 | 롤백 절차가 이전 모델 버전 또는 안전 모드 작업으로 되돌릴 수 있는지 확인하십시오.        |  3  | D/V |
| 13.1.4 | 재정의 메커니즘이 정기적으로 테스트되는지 확인하십시오.                         |  3  |  V  |

---

## C13.2 휴먼 인 더 루프 의사결정 체크포인트

사전 정의된 위험 임계값을 초과할 경우 인간의 승인을 요구합니다.

|   #    | 설명                                                                | 레벨  | 역할  |
| :----: | ----------------------------------------------------------------- | :-: | :-: |
| 13.2.1 | 고위험 AI 결정은 실행 전에 명시적인 인간 승인이 필요함을 확인하십시오.                         |  1  | D/V |
| 13.2.2 | 위험 임계값이 명확하게 정의되어 있으며 자동으로 인간 검토 워크플로를 트리거하는지 확인하십시오.             |  1  |  D  |
| 13.2.3 | 시간에 민감한 결정이 요구되는 시간 내에 인간의 승인을 받을 수 없을 때 대체 절차가 있는지 확인하십시오.       |  2  |  D  |
| 13.2.4 | 적용 가능한 경우, 상승 절차가 다양한 결정 유형 또는 위험 범주에 대해 명확한 권한 수준을 정의하는지 확인하십시오. |  3  | D/V |

---

## C13.3 책임 연쇄 및 감사 가능성

연산자 작업과 모델 결정을 기록하십시오.

|   #    | 설명                                                             | 레벨  | 역할  |
| :----: | -------------------------------------------------------------- | :-: | :-: |
| 13.3.1 | 모든 AI 시스템 결정 및 인간 개입이 타임스탬프, 사용자 신원 및 결정 근거와 함께 기록되었는지 확인하십시오. |  1  | D/V |
| 13.3.2 | 감사 로그가 변조될 수 없으며 무결성 검증 메커니즘을 포함하는지 확인하십시오.                    |  2  |  D  |

---

## C13.4 설명 가능한 AI 기법

표면 특징 중요도, 반사실, 그리고 지역 설명.

|   #    | 설명                                                                             | 레벨  | 역할  |
| :----: | ------------------------------------------------------------------------------ | :-: | :-: |
| 13.4.1 | AI 시스템이 인간이 읽을 수 있는 형식으로 그들의 결정에 대한 기본적인 설명을 제공하는지 확인하십시오.                     |  1  | D/V |
| 13.4.2 | 설명 품질이 인간 평가 연구 및 지표를 통해 검증되었는지 확인하십시오.                                        |  2  |  V  |
| 13.4.3 | 중요한 결정에 대해 피처 중요도 점수 또는 속성 방법(SHAP, LIME 등)이 사용 가능한지 검증하십시오.                   |  3  | D/V |
| 13.4.4 | 카운터팩추얼 설명이 결과를 변경하기 위해 입력을 어떻게 수정할 수 있는지 보여주는지, 해당 사용 사례와 도메인에 적용 가능한지 확인하십시오. |  3  |  V  |

---

## C13.5 모델 카드 및 사용 공개

의도된 사용, 성능 지표 및 윤리적 고려사항에 대한 모델 카드를 유지하십시오.

|   #    | 설명                                                                                    | 레벨  | 역할  |
| :----: | ------------------------------------------------------------------------------------- | :-: | :-: |
| 13.5.1 | 모델 카드가 의도된 사용 사례, 한계 및 알려진 실패 모드를 문서화했는지 확인하십시오.                                      |  1  |  D  |
| 13.5.2 | 다양한 적용 가능한 사용 사례 전반에 걸친 성능 지표가 공개되었는지 확인하십시오.                                         |  1  | D/V |
| 13.5.3 | 윤리적 고려사항, 편향 평가, 공정성 평가, 훈련 데이터 특성 및 알려진 훈련 데이터 제한사항이 문서화되어 있으며 정기적으로 업데이트되는지 확인하십시오. |  2  |  D  |
| 13.5.4 | 모델 카드가 버전 관리되고 변경 추적과 함께 모델 수명 주기 전반에 걸쳐 유지되는지 확인하십시오.                                |  2  | D/V |

---

## C13.6 불확실성 정량화

응답에서 신뢰도 점수 또는 엔트로피 측정값을 전파하십시오.

|   #    | 설명                                               | 레벨  | 역할  |
| :----: | ------------------------------------------------ | :-: | :-: |
| 13.6.1 | AI 시스템이 결과물과 함께 신뢰도 점수 또는 불확실성 척도를 제공하는지 확인하십시오. |  1  |  D  |
| 13.6.2 | 불확실성 임계값이 추가적인 인간 검토나 대체 의사결정 경로를 유발하는지 확인하십시오.  |  2  | D/V |
| 13.6.3 | 불확실성 정량화 방법이 실제 데이터에 대해 보정되고 검증되었는지 확인하십시오.      |  2  |  V  |
| 13.6.4 | 불확실성 전파가 다단계 AI 워크플로우 전반에 걸쳐 유지되는지 확인하십시오.       |  3  | D/V |

---

## C13.7 사용자 대상 투명성 보고서

사건, 드리프트, 데이터 사용에 대해 주기적으로 공개합니다.

|   #    | 설명                                                           | 레벨  | 역할  |
| :----: | ------------------------------------------------------------ | :-: | :-: |
| 13.7.1 | 데이터 사용 정책 및 사용자 동의 관리 관행이 이해관계자에게 명확하게 전달되는지 확인하십시오.         |  1  | D/V |
| 13.7.2 | AI 영향 평가가 수행되었고 그 결과가 보고에 포함되었는지 확인하십시오.                     |  2  | D/V |
| 13.7.3 | 정기적으로 게시되는 투명성 보고서가 AI 사건 및 운영 지표를 적절한 세부 사항으로 공개하는지 확인하십시오. |  2  | D/V |

### 참고 문헌

* [EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)](https://eur-lex.europa.eu/eli/reg/2024/1689/oj)
* [ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management](https://www.iso.org/standard/77304.html)
* [ISO/IEC 42001:2023 — AI Management Systems Requirements](https://www.iso.org/standard/81230.html)
* [NIST AI Risk Management Framework 1.0](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [NIST SP 800-53 Revision 5 — Security and Privacy Controls](https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-53r5.pdf)
* [A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)](https://arxiv.org/abs/1705.07874)
* [Model Cards for Model Reporting (Mitchell et al., 2018)](https://arxiv.org/abs/1810.03993)
* [Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)](https://arxiv.org/abs/1506.02142)
* [ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods](https://www.iso.org/standard/79804.html)
* [IEEE 7001-2021 — Transparency of Autonomous Systems](https://standards.ieee.org/ieee/7001/6929/)
* [Human Oversight under Article 14 of the EU AI Act (Fink, 2025)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5147196)

