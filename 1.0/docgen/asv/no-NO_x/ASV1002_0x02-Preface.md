# Forord

Velkommen til standarden for sikkerhetsverifisering av kunstig intelligens (AISVS) versjon 1.0!

## Introduksjon

Etablert i 2025 gjennom en samarbeidsinnsats i fellesskapet, definerer AISVS sikkerhetskravene som må vurderes ved utforming, utvikling, distribusjon og drift av moderne AI-modeller, arbeidsflyter og AI-aktiverte tjenester.

AISVS v1.0 representerer det kombinerte arbeidet til prosjektledere, arbeidsgruppen og bredere fellesskapsbidragsytere for å produsere en pragmatisk, testbar referanse for sikring av AI-systemer.

Vårt mål med denne utgivelsen er å gjøre AISVS enkel å ta i bruk samtidig som vi holder et skarpt fokus på dets definerte omfang og adresserer det raskt utviklende risikolandskapet som er unikt for AI.

## Viktige mål for AISVS versjon 1.0

Versjon 1.0 vil bli laget med flere veiledende prinsipper.

### Veldefinert omfang

Hvert krav må være i samsvar med AISVS sitt navn og oppdrag:

* Kunstig intelligens – Kontrollene opererer på AI/ML-laget (data, modell, pipeline eller inferens) og er ansvaret til AI-utøvere.
* Sikkerhet – Kravene reduserer direkte identifiserte sikkerhets-, personvern- eller sikkerhetsrisikoer.
* Verifikasjon – Språket er skrevet slik at overensstemmelse kan objektivt valideres.
* Standard – Seksjonene følger en konsekvent struktur og terminologi for å danne en sammenhengende referanse.
  ​
---

Ved å følge AISVS kan organisasjoner systematisk evaluere og styrke sikkerhetsposisjonen til sine AI-løsninger, og fremme en kultur for sikker AI-ingeniørkunst.

