# Forsideillustrasjon

## Om standarden

Artificial Intelligence Security Verification Standard (AISVS) er en fellesskapsdrevet katalog over sikkerhetskrav som dataforskere, MLOps-ingeniører, programvarearkitekter, utviklere, testere, sikkerhetsprofesjonelle, verktøyleverandører, regulatorer og brukere kan bruke til å designe, bygge, teste og verifisere pålitelige AI-drevne systemer og applikasjoner. Den gir et felles språk for å spesifisere sikkerhetskontroller gjennom hele AI-livssyklusen – fra datainnsamling og modellutvikling til distribusjon og kontinuerlig overvåking – slik at organisasjoner kan måle og forbedre robustheten, personvernet og sikkerheten til sine AI-løsninger.

## Opphavsrett og lisens

Versjon 0.1 (Første offentlige utkast - pågående arbeid), 2025  

![license](../images/license.png)

Opphavsrett © 2025-2026 The AISVS Project.  

Utgitt under the[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
For enhver gjenbruk eller distribusjon må du tydelig kommunisere lisensvilkårene for dette arbeidet til andre.

## Prosjektledere

|            |                         |
| ---------- | ----------------------- |
| Jim Manico | Aras “Russ” Memisyazici |

## Bidragsytere og anmeldere

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS er en helt ny standard som er utviklet spesielt for å møte de unike sikkerhetsutfordringene knyttet til kunstig intelligens-systemer. Selv om den henter inspirasjon fra bredere sikkerhetsbeste praksis, er hvert krav i AISVS utviklet fra grunnen av for å reflektere trussellandskapet for AI og for å hjelpe organisasjoner med å bygge sikrere og mer robuste AI-løsninger.

