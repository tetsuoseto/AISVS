# 扉絵

## 標準について

人工知能セキュリティ検証標準（AISVS）は、データサイエンティスト、MLOpsエンジニア、ソフトウェアアーキテクト、開発者、テスター、セキュリティ専門家、ツールベンダー、規制当局、および消費者が、信頼できるAI対応システムおよびアプリケーションを設計、構築、テスト、および検証するために利用できるコミュニティ主導のセキュリティ要件カタログです。これは、データ収集やモデル開発から展開および継続的な監視に至るAIライフサイクル全体にわたるセキュリティコントロールを指定するための共通言語を提供し、組織がAIソリューションの回復力、プライバシー、および安全性を測定し向上させることを可能にします。

## 著作権およびライセンス

バージョン0.1（最初の公開ドラフト - 作業進行中）、2025  

![license](../images/license.png)

著作権 © 2025 The AISVS Project.  

以下の条件のもとリリースされています[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
この作品を再利用または配布する場合、必ずライセンス条件を他者に明確に伝える必要があります。

## プロジェクトリーダー

|        |                  |
| ------ | ---------------- |
| ジム・マニコ | アラス “ラッス” メミシャジチ |

## 寄稿者とレビュアー

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVSは、人工知能システムの独自のセキュリティ課題に対応するために特別に作られた全く新しい標準です。より広範なセキュリティのベストプラクティスから着想を得ていますが、AISVSのすべての要件はAIの脅威の状況を反映し、組織がより安全で堅牢なAIソリューションを構築できるように、ゼロから開発されています。

