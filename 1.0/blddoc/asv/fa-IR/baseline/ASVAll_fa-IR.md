## تصویر روی صفحهٔ عنوان

### درباره استاندارد

استاندارد ارزیابی امنیت هوش مصنوعی (AISVS) یک فهرست هدایت‌شده توسط جامعه از الزامات امنیتی است که دانش‌مندان داده، مهندسان MLOps، معماران نرم‌افزار، توسعه‌دهندگان، آزمایشگران، متخصصان امنیت، فروشندگان ابزار، تنظیم‌کنندگان و مصرف‌کنندگان می‌توانند از آن برای طراحی، ساخت، آزمایش و تأیید سیستم‌ها و برنامه‌های مبتنی بر هوش مصنوعی قابل اعتماد استفاده کنند. این استاندارد یک زبان مشترک برای مشخص‌کردن کنترل‌های امنیتی در طول چرخه حیات هوش مصنوعی فراهم می‌کند — از جمع‌آوری داده‌ها و توسعه مدل تا استقرار و پایش مستمر — تا سازمان‌ها بتوانند تاب‌آوری، حریم خصوصی و ایمنی راه‌حل‌های هوش مصنوعی خود را اندازه‌گیری و بهبود ببخشند.

### کپی‌رایت و مجوز

نسخه 0.1 (اولین پیش‌نویس عمومی - در حال کار), 2025  

![license](images/license.png)
کپی‌رایت © 2025 پروژه AISVS.  

منتشر شده تحت  Creative Commons Attribution‑ShareAlike 4.0 International License.
برای هرگونه استفاده مجدد یا توزیع، باید به وضوح شرایط مجوز این اثر را به دیگران اطلاع دهید.

### رهبران پروژه

جیم منیکو
آراس «Russ» میمیس یازیجی

### سازندگان و بازبین‌کنندگان

https://github.com/ottosulin
https://github.com/mbhatt1
https://github.com/vineethsai
https://github.com/cciprofm
https://github.com/deepakrpandey12


---

AISVS یک استاندارد کاملاً جدید است که به طور خاص برای پرداختن به چالش‌های امنیتی منحصر به فرد سامانه‌های هوش مصنوعی ایجاد شده است. در حالی که از بهترین شیوه‌های امنیتی گسترده‌تر الهام می‌گیرد، هر الزام در AISVS از پایه و اساس توسعه یافته است تا بازتاب‌دهنده چشم‌انداز تهدیدهای هوش مصنوعی باشد و به سازمان‌ها کمک کند تا راه‌حل‌های هوش مصنوعی ایمن‌تر و مقاوم‌تری بسازند.

## پیشگفتار

به استاندارد ارزیابی امنیت هوش مصنوعی (AISVS) نسخه 1.0 خوش آمدید!

### مقدمه

AISVS در سال 2025 و از طریق تلاشی جمعی از سوی جامعه تأسیس شد و الزامات امنیتی را تعریف می‌کند که هنگام طراحی، توسعه، استقرار و عملیات مدل‌های هوش مصنوعی مدرن، پیپلاین‌ها و خدمات مبتنی بر هوش مصنوعی باید در نظر گرفته شوند.

AISVS v1.0 نمایانگر کار مشترک رهبران پروژه، کارگروه و مشارکت‌کنندگان جامعه گسترده آن است تا یک خط پایه عملی و قابل آزمون برای ایمن‌سازی سامانه‌های هوش مصنوعی ایجاد کند.

هدف ما از این انتشار این است که AISVS را برای پذیرش آسان فراهم آورد، در عین حال با laser‑focused بودن بر دامنهٔ تعریف‌شدهٔ آن و رسیدگی به چشم‌انداز ریسکِ به‌سرعت در حال تحولِ منحصربه‌هوش مصنوعی.

### اهداف کلیدی برای AISVS نسخه 1.0

نسخه 1.0 با چندین اصل راهنما تدوین خواهد شد.

#### دامنه به‌خوبی تعریف‌شده

هر الزام باید با نام و مأموریت AISVS همسو باشد:

هوش مصنوعی – کنترل‌ها در لایه هوش مصنوعی/یادگیری ماشین (داده‌ها، مدل، خط لوله یا استنتاج) عمل می‌کنند و مسئولیت آن بر عهدهٔ متخصصان هوش مصنوعی است.
امنیت – الزامات مستقیماً ریسک‌های امنیتی، حریم خصوصی یا ایمنی شناسایی‌شده را کاهش می‌دهد.
تایید – زبان به‌گونه‌ای نوشته می‌شود تا انطباق به‌طور عینی اعتبارسنجی شود.
استاندارد – بخش‌ها از ساختار و اصطلاحات یکسان پیروی می‌کنند تا مرجع همسو و منسجم ایجاد شود.
​
---

با پیروی از AISVS، سازمان‌ها می‌توانند به‌طور سیستماتیک امنیت راه‌حل‌های هوش مصنوعی خود را ارزیابی و تقویت کنند و فرهنگی از مهندسی امن هوش مصنوعی را ترویج نمایند.

## با استفاده از AISVS

استاندارد ارزیابی امنیت هوش مصنوعی (AISVS) الزامات امنیتی را برای برنامه‌ها و خدمات هوش مصنوعی مدرن تعریف می‌کند و بر جنبه‌هایی که در کنترل توسعه‌دهندگان برنامه قرار دارند تمرکز می‌کند.

AISVS برای هر کسی که در حال توسعه یا ارزیابی امنیت برنامه‌های هوش مصنوعی است طراحی شده است و از جمله توسعه‌دهندگان، معماران، مهندسان امنیتی و حسابرسان را در بر می‌گیرد. این فصل به ساختار و کاربرد AISVS می‌پردازد، از جمله سطوح اعتبارسنجی آن و موارد استفادهٔ مدنظر.

### سطوح تأیید امنیت هوش مصنوعی

AISVS سه سطح صعودی تأیید امنیتی را تعریف می‌کند. هر سطح عمق و پیچیدگی بیشتری اضافه می‌کند، به سازمان‌ها امکان می‌دهد تا موضع امنیتی خود را متناسب با سطح ریسک سیستم‌های هوش مصنوعی‌شان تنظیم کنند.

سازمان‌ها ممکن است از سطح ۱ آغاز کنند و به تدریج سطوح بالاتر را اتخاذ نمایند، در حالی که بلوغ امنیتی و قرارگیری در معرض تهدید افزایش می‌یابد.

#### تعریف سطوح

هر الزامی در AISVS v1.0 به یکی از سطوح زیر اختصاص داده می‌شود:

 الزامات سطح 1

سطح 1 شامل حساس‌ترین و بنیادی‌ترین الزامات امنیتی است. این الزامات بر جلوگیری از حملات رایجی متمرکز هستند که به پیش‌فرض‌ها یا آسیب‌پذیری‌های دیگر وابسته نیستند. بیشتر کنترل‌های سطح 1 یا به‌سادگی قابل پیاده‌سازی هستند یا آنقدر ضروری‌اند که تلاش برای پیاده‌سازی را توجیه می‌کنند.

 الزامات سطح 2

سطح 2 به حملات پیشرفته‌تر یا کمتر رایج نیز می‌پردازد، همچنین به دفاع‌های چندلایه در برابر تهدیدهای گسترده می‌پردازد. این الزامات ممکن است شامل منطق پیچیده‌تری باشد یا پیش‌شرط‌های خاص حمله را هدف قرار دهد.

 الزامات سطح 3

سطح 3 شامل کنترل‌هایی است که معمولاً پیاده‌سازی آن‌ها دشوارتر است یا از لحاظ کاربردی موقعیتی هستند. این‌ها اغلب نمایانگر مکانیسم‌های دفاع در عمق یا کاهش آسیب در برابر حملات خاص، هدفمند یا با پیچیدگی بالا هستند.

#### نقش (D/V)

هر الزام AISVS بر اساس مخاطب اصلی مشخص می‌شود:

D – الزامات متمرکز بر توسعه‌دهنده
V – الزامات متمرکز بر بازرس/تاییدکننده
D/V – مرتبط با هر دو گروه توسعه‌دهندگان و تاییدکنندگان

## C1 حاکمیت داده‌های آموزشی و مدیریت سوگیری

### هدف کنترل

داده‌های آموزشی باید به گونه‌ای تهیه، مدیریت و نگهداری شوند که منشأ داده، امنیت، کیفیت و عدالت حفظ شوند. این کار وظایف قانونی را برآورده می‌کند و خطرات سوگیری، آلودگی داده، یا نقض حریم خصوصی که در طول آموزش پدید می‌آیند و می‌توانند کل چرخه حیات هوش مصنوعی را تحت تأثیر قرار دهند کاهش می‌دهد.

---

### C1.1 منشأ داده‌های آموزشی

نگهداری فهرست قابل تأیید از تمامی مجموعه‌داده‌ها، پذیرش تنها منابع معتبر، و ثبت هر تغییر برای قابلیت حسابرسی.

 #1.1.1    سطح: 1    نقش: D/V
 تأیید کنید که فهرست به‌روزِ هر منبع داده‌های آموزشی (منشأ، نگهبان/مالک، مجوز، روش جمع‌آوری، محدودیت‌های استفادهٔ مدنظر، و سابقهٔ پردازش) نگهداری می‌شود.
 #1.1.2    سطح: 1    نقش: D/V
 تأیید کنید که فرآیندهای داده‌های آموزشی از حذف ویژگی‌های غیرضروری، خصوصیات یا فیلدهای غیرضروری خودداری می‌کنند (به‌عنوان مثال، فراداده‌های استفاده‌نشده، اطلاعات شخصی حساس، داده‌های آزمون فاش‌شده).
 #1.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که همه تغییرات مجموعه داده مشمول گردش کار تأیید ثبت‌شده هستند.
 #1.1.4    سطح: 3    نقش: D/V
 بررسی کنید که مجموعه‌های داده یا زیرمجموعه‌ها در صورت امکان دارای واترمارک یا اثر انگشت دیجیتال هستند.

---

### C1.2 امنیت و یکپارچگی داده‌های آموزشی

دسترسی به داده‌های آموزشی را محدود کنید، آن‌ها را در زمان ذخیره و در حین انتقال رمزگذاری کنید، و یکپارچگی آنها را برای جلوگیری از دستکاری، سرقت یا آلودگی داده‌ها تأیید کنید.

 #1.2.1    سطح: 1    نقش: D/V
 تأیید کنید که کنترل‌های دسترسی از ذخیره‌سازی داده‌های آموزشی و خطوط لوله‌های آموزشی محافظت می‌کنند.
 #1.2.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تمامی دسترسی‌ها به داده‌های آموزشی ثبت می‌شوند، از جمله کاربر، زمان و عملیات.
 #1.2.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مجموعه‌های داده‌های آموزشی در حین انتقال و در حالت استراحت رمزگذاری شده‌اند، با استفاده از الگوریتم‌های رمزنگاری استاندارد صنعتی و شیوه‌های مدیریت کلید.
 #1.2.4    سطح: 2    نقش: D/V
 تأیید کنید که از هش‌های رمزنگاری‌شده یا امضاهای دیجیتال برای اطمینان از یکپارچگی داده‌ها در حین ذخیره‌سازی و انتقال داده‌های آموزشی استفاده می‌شود.
 #1.2.5    سطح: 2    نقش: D/V
 بررسی کنید که تکنیک‌های تشخیص خودکار برای جلوگیری از تغییرات غیرمجاز یا فساد داده‌های آموزشی به کار گرفته می‌شوند.
 #1.2.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که داده‌های آموزشی قدیمی به‌طور ایمن پاک‌سازی می‌شوند یا ناشناس‌سازی می‌شوند.
 #1.2.7    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تمامی نسخه‌های داده‌های آموزشی به‌طور یکتا شناسایی می‌شوند، به‌طور غیرقابل تغییر ذخیره می‌شوند و قابل حسابرسی هستند تا از بازگردانی به نسخه‌های قبلی و تحلیل‌های فارنزیک پشتیبانی شود.

---

### C1.3 کیفیت برچسب‌گذاری داده‌های آموزشی، یکپارچگی و امنیت

از برچسب‌ها محافظت کنید و برای داده‌های حیاتی بازبینی فنی را الزامی کنید.

 #1.3.1    سطح: 2    نقش: D/V
 تأیید کنید که هش‌های رمزنگاری‌شده یا امضای دیجیتال به آثار برچسب‌خورده اعمال می‌شوند تا تمامیت و اصالت آنها تضمین گردد.
 #1.3.2    سطح: 2    نقش: D/V
 بررسی کنید که رابط‌های برچسب‌گذاری و پلتفرم‌ها کنترل‌های دسترسی قوی را اعمال می‌کنند، لاگ‌های حسابرسی با قابلیت تشخیص دستکاری از تمامی فعالیت‌های برچسب‌گذاری را نگهداری می‌کنند و در برابر تغییرات غیرمجاز محافظت می‌کنند.
 #1.3.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که اطلاعات حساس در برچسب‌ها در سطح فیلدهای داده، در حالت استراحت و در حین انتقال، سانسور شده، ناشناس‌سازی شده یا رمزگذاری شده‌اند.

---

### C1.4 کیفیت داده‌های آموزشی و اطمینان از امنیت

ادغام اعتبارسنجی خودکار، بازرسی‌های نمونه‌ای دستی، و رفع اشکالات ثبت‌شده به منظور تضمین اعتمادپذیری مجموعه داده.

 #1.4.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که تست‌های خودکار خطاهای فرمت و مقادیر تهی (null) را در هر بارگذاری داده یا هر تبدیل دادهٔ مهم شناسایی می‌کنند.
 #1.4.2    سطح: 2    نقش: D/V
 بررسی کنید که فرآیندهای آموزش و ریزتنظیم مدل‌های زبان بزرگ (LLM) پیاده‌سازی تشخیص آلودگی داده و اعتبارسنجی یکپارچگی داده‌ها را انجام می‌دهند (برای نمونه روش‌های آماری، تشخیص ناهنجاری، تحلیل بردهای جاسازی) تا حملات آلوده‌سازی محتمل (مثلاً تغییر برچسب‌ها، اضافه‌کردن محرک‌های درب پشتی، دستورهای تغییر نقش، حملات نمونه‌های تأثیرگذار) یا خرابی ناخواسته داده‌های آموزشی را در داده‌های آموزشی شناسایی کنند.
 #1.4.3    سطح: 3    نقش: D/V
 تأیید کنید که دفاع‌های مناسب، مانند آموزش مقاوم در برابر حملات مخرب (استفاده از نمونه‌های adversarial تولیدشده)، افزایش داده‌ها با ورودی‌های تغییر یافته، یا روش‌های بهینه‌سازی مقاوم، برای مدل‌های مرتبط بر اساس ارزیابی ریسک اجرا و تنظیم شده‌اند.
 #1.4.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که برچسب‌های به‌طور خودکار تولیدشده (مثلاً از طریق مدل‌های زبان بزرگ (LLMs) یا نظارت ضعیف) مشمول آستانه‌های اعتماد و بررسی‌های سازگاری هستند تا برچسب‌های توهمی، گمراه‌کننده یا با اطمینان پایین را تشخیص دهند.
 #1.4.5    سطح: 3    نقش: D
 اطمینان حاصل کنید که تست‌های خودکار، انحرافات برچسب را در هر ورود داده یا هر تبدیل داده قابل توجه تشخیص می‌دهند.

---

### C1.5 سیر داده و قابلیت ردیابی

پیگیری کامل مسیر هر نقطه داده از منبع تا ورودی مدل برای قابلیت حسابرسی و پاسخ به رویدادها.

 #1.5.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که سیر هر نقطه داده، از جمله تمام تبدیلات، افزایش‌های داده و ادغام‌ها، ثبت شده و قابل بازسازی است.
 #1.5.2    سطح: 2    نقش: D/V
 تأیید کنید که سوابق ردپای داده غیرقابل تغییر باشند، به‌طور ایمن ذخیره شوند و برای بازرسی‌ها قابل دسترس باشند.
 #1.5.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که ردیابی منشأ داده‌ها، داده‌های مصنوعی تولیدشده با استفاده از تکنیک‌های حفظ حریم خصوصی یا مولد را پوشش می‌دهد و اینکه همه داده‌های مصنوعی به وضوح برچسب‌گذاری شده و در سراسر خط لوله از داده‌های واقعی متمایز باشند.

---

### منابع

NIST AI Risk Management Framework
EU AI Act – Article 10: Data & Data Governance
MITRE ATLAS: Adversary Tactics for AI
Survey of ML Bias Mitigation Techniques – MDPI
Data Provenance & Lineage Best Practices – Nightfall AI
Data Labeling Quality Standards – LabelYourData
Training Data Poisoning Guide – Lakera.ai
CISA Advisory: Securing Data for AI Systems
ISO/IEC 23053: AI Management Systems Framework
IBM: What is AI Governance?
Google AI Principles
GDPR & AI Training Data – DataProtectionReport
Supply-Chain Security for AI Data – AppSOC
OpenAI Privacy Center – Data Deletion Controls
Adversarial ML Dataset – Kaggle

## C2 اعتبارسنجی ورودی کاربر

### هدف کنترل

اعتبارسنجی قوی ورودی کاربر، دفاعی خط اول در برابر برخی از مخرب‌ترین حملات علیه سامانه‌های هوش مصنوعی است. حملات تزریق پرامپت می‌توانند دستورات سیستمی را کنار بزنند، داده‌های حساس را فاش کنند یا مدل را به رفتاری که مجاز نیست هدایت کنند. مگر اینکه فیلترهای اختصاصی و سلسله‌مراتب دستورالعمل در جای خود وجود داشته باشند، تحقیقات نشان می‌دهد که «multi-shot» جیلبریک‌هایی که از پنجره‌های زمینه‌ای بسیار طولانی بهره می‌برند، مؤثر خواهند بود. همچنین حملات اخلال‌آفرین مخالفانه—مانند تعویض‌های هم‌ریخت (هموگلیف) یا لیت‌اسپیک—می‌توانند به‌طور پنهان تصمیم‌های مدل را تغییر دهند.

---

### C2.1 دفاع در برابر تزریق پرومپت

تزریق پرامپت یکی از مهم‌ترین خطرات برای سیستم‌های هوش مصنوعی است. دفاع‌های در برابر این تاکتیک از ترکیبی از فیلترهای الگوهای ایستا، طبقه‌بندهای پویا و اجرای سلسله‌مراتب دستورات استفاده می‌کنند.

 #2.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که ورودی‌های کاربر در برابر کتابخانه‌ای به‌طور مداوم به‌روزرسانی‌شده از الگوهای شناخته‌شده تزریق پرامپت غربال می‌شوند (کلیدواژه‌های jailbreak، "ignore previous"، زنجیره‌های نقش‌آفرینی، حملات HTML/URL غیرمستقیم).
 #2.1.2    سطح: 1    نقش: D/V
 تأیید کنید که سیستم یک سلسله‌مراتب دستورالعمل اجرا می‌کند که در آن پیام‌های سیستم یا توسعه‌دهنده از دستورالعمل‌های کاربر پیشی می‌گیرند، حتی پس از گسترش پنجره زمینه.
 #2.1.3    سطح: 2    نقش: D/V
 تأیید کنید که آزمایش‌های ارزیابی خصمانه (مثلاً پرومپت‌های Red Team "many-shot") قبل از هر انتشار مدل یا قالب پرومپت اجرا می‌شوند، با آستانه‌های نرخ موفقیت و موانع خودکار برای جلوگیری از ریگریسیون‌ها.
 #2.1.4    سطح: 2    نقش: D
 تأیید کنید که پرامپت‌هایی که از محتوای شخص ثالث منشأ می‌گیرند، در یک زمینهٔ تحلیل ایزوله‌شده پاک‌سازی می‌شوند، پیش از الحاق آن‌ها به پرامپت اصلی.
 #2.1.5    سطح: 3    نقش: D/V
 همه به‌روزرسانی‌های قوانین فیلتر پرامپت، نسخه‌های مدل طبقه‌بندی و تغییرات block-list دارای کنترل نسخه و قابل ممیزی هستند.

---

### C2.2 مقاومت در برابر نمونه‌های خصمانه

مدل‌های پردازش زبان طبیعی (NLP) هنوز در برابر تغییرات ظریف در سطح کاراکتر یا کلمه آسیب‌پذیرند که انسان‌ها اغلب از آن‌ها چشم‌پوشی می‌کنند، اما مدل‌ها تمایل دارند آن‌ها را به اشتباه طبقه‌بندی کنند.

 #2.2.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که مراحل پایه نرمال‌سازی ورودی (Unicode NFC، نگاشت هموگلیف‌ها، برداشتن فاصله‌های سفید) قبل از توکن‌سازی اجرا می‌شوند.
 #2.2.2    سطح: 2    نقش: D/V
 تشخیص ناهنجاری آماری ورودی‌ها را با فاصلهٔ ویرایشی غیرعادی نسبت به هنجارهای زبان، توکن‌های تکراری بیش از حد یا فواصل امبدینگ غیرعادی علامت‌گذاری می‌کند.
 #2.2.3    سطح: 2    نقش: D
 تأیید کنید که خط لوله استنتاج از انواع مدل‌های اختیاریِ adversarial-training–hardened یا لایه‌های دفاعی پشتیبانی می‌کند (به‌عنوان مثال، تصادفی‌سازی، تقطیر دفاعی) برای نقاط پایانی با ریسک بالا.
 #2.2.4    سطح: 2    نقش: V
 بررسی کنید که ورودی‌های مظنون به مخرب بودن در قرنطینه نگهداری شوند و با محموله‌های کامل لاگ شوند (پس از حذف اطلاعات شخصی قابل تشخیص).
 #2.2.5    سطح: 3    نقش: D/V
 بررسی کنید که معیارهای استحکام (نرخ موفقیت مجموعه‌های حمله شناخته‌شده) در طول زمان پیگیری می‌شوند و رگرسیون‌ها باعث فعال شدن موانع انتشار می‌شوند.

---

### C2.3 اسکیما، نوع و طول اعتبارسنجی

حملات هوش مصنوعی که ورودی‌های نامعتبر یا با اندازهٔ بیش از حد را در بر می‌گیرند، می‌توانند منجر به خطاهای تجزیه، ریزش پرومپت در فیلدها، و اتمام منابع شوند.  همچنین اجرای دقیق طرحواره یک پیش‌نیاز هنگام انجام فراخوانی‌های ابزار قطعی است.

 #2.3.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که هر نقطه پایانی API یا فراخوانی تابع، یک طرح ورودی صریح تعریف می‌کند (JSON Schema، Protobuf یا معادل چندرسانه‌ای) و اینکه ورودی‌ها پیش از ساخت پرامپت اعتبارسنجی می‌شوند.
 #2.3.2    سطح: 1    نقش: D/V
 تأیید کنید که ورودی‌هایی که از حداکثر محدودیت‌های توکن یا بایت فراتر می‌روند با یک خطای ایمن رد می‌شوند و هرگز به صورت خاموش قطع نمی‌شوند.
 #2.3.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که بررسی‌های نوع داده (مثلاً بازه‌های عددی، مقادیر enum، انواع MIME برای تصاویر و صداها) در سمت سرور اعمال می‌شوند، نه فقط در کد سمت کلاینت.
 #2.3.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که اعتبارسنج‌های معنایی (مثلاً JSON Schema) در زمان ثابت اجرا شوند تا از حملات DoS الگوریتمی جلوگیری شود.
 #2.3.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که شکست‌های اعتبارسنجی با قطعات پیلود حذف‌شده و کدهای خطای صریح ثبت می‌شوند تا به تریاژ امنیتی کمک کنند.

---

### C2.4 غربالگری محتوا و سیاست‌ها

توسعه‌دهندگان باید بتوانند پرامپت‌های نحوی معتبر را تشخیص دهند که محتوای غیرمجاز را درخواست می‌کنند، و سپس از انتشار آنها جلوگیری نمایند.

 #2.4.1    سطح: 1    نقش: D
 تأیید کنید که یک طبقه‌بندی‌کننده محتوا (zero-shot یا fine-tuned) برای هر ورودی امتیاز بدهد از نظر خشونت، خودآزاری، نفرت، محتوای جنسی و درخواست‌های غیرقانونی، با آستانه‌های قابل تنظیم.
 #2.4.2    سطح: 1    نقش: D/V
 تأیید کنید که ورودی‌هایی که سیاست‌ها را نقض می‌کنند، از پاسخ‌های امتناع استاندارد یا تکمیل‌های ایمن برخوردار می‌شوند تا به فراخوانی‌های LLM در مراحل بعدی منتقل نشوند.
 #2.4.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که مدل غربالگری یا مجموعه قوانین حداقل هر سه ماه یکبار بازآموزی/به‌روزرسانی می‌شود و الگوهای تازه مشاهده‌شده برای جیل‌بریک یا دور زدن سیاست‌ها را در بر می‌گیرد.
 #2.4.4    سطح: 2    نقش: D
 بررسی کنید که غربالگری به سیاست‌های مربوط به کاربر (سن، محدودیت‌های قانونی منطقه‌ای) از طریق قواعد مبتنی بر ویژگی که در زمان درخواست حل می‌شوند، احترام می‌گذارد.
 #2.4.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که لاگ‌های غربالگری شامل نمرات اعتماد طبقه‌بند و برچسب‌های دسته‌بندی سیاستی برای همبستگی با SOC و بازتکرار تیم قرمز در آینده باشند.

---

### C2.5 محدودیت نرخ ورودی و پیشگیری از سوءاستفاده

توسعه‌دهندگان باید از سوءاستفاده، استنفاد منابع و حملات خودکار علیه سیستم‌های هوش مصنوعی جلوگیری کنند، با محدود کردن نرخ ورودی و تشخیص الگوهای استفاده نامعمول.

 #2.5.1    سطح: 1    نقش: D/V
 تأیید کنید که محدودیت‌های نرخ برای هر کاربر، هر IP، و هر کلید API برای تمام نقاط ورودی اعمال می‌شود.
 #2.5.2    سطح: 2    نقش: D/V
 تایید کنید که محدودیت‌های نرخ ناگهانی و پایدار برای جلوگیری از حملات DoS و brute-force تنظیم شده‌اند.
 #2.5.3    سطح: 2    نقش: D/V
 بررسی کنید که آیا الگوهای استفاده غیرعادی (مثلاً درخواست‌های پی‌درپی با سرعت بالا و سیلاب ورودی) منجر به بلوک‌های خودکار یا تشدیدهای خودکار می‌شوند.
 #2.5.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که لاگ‌های جلوگیری از سوءاستفاده نگهداری می‌شوند و برای الگوهای حمله در حال ظهور بررسی می‌شوند.

---

### C2.6 اعتبارسنجی ورودی چندرسانه‌ای

سامانه‌های هوش مصنوعی باید اعتبارسنجی قوی برای ورودی‌های غیرمتنی (تصاویر، صوت، فایل‌ها) داشته باشند تا از تزریق، فرار از کنترل یا سوءاستفاده از منابع جلوگیری شود.

 #2.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که تمامی ورودی‌های غیرمتنی (تصاویر، صداها و فایل‌ها) پیش از پردازش از نظر نوع، اندازه و فرمت اعتبارسنجی می‌شوند.
 #2.6.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فایل‌ها قبل از درون‌ریزی برای بدافزارها و بارهای استگانوگرافی اسکن می‌شوند.
 #2.6.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که ورودی‌های تصویری و صوتی برای وجود انحرافات خصمانه یا الگوهای حمله شناخته‌شده بررسی می‌شوند.
 #2.6.4    سطح: 3    نقش: V
 تأیید کنید که شکست‌های اعتبارسنجی ورودی‌های چندرسانه‌ای ثبت می‌شوند و برای بررسی، هشدارهایی فعال می‌شوند.

---

### C2.7 منشأ ورودی و انتساب

سیستم‌های هوش مصنوعی باید با نظارت بر منشاء ورودی‌های کاربران و برچسب‌گذاری آن‌ها، از ممیزی، پیگیری سوءاستفاده و انطباق پشتیبانی کنند.

 #2.7.1    سطح: 1    نقش: D/V
 تأیید کنید که تمامی ورودی‌های کاربر در هنگام واردسازی با فراداده برچسب‌گذاری می‌شوند (شناسه کاربر، نشست، منبع، زمان ثبت، آدرس IP).
 #2.7.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که متاداده منبع برای تمامی ورودی‌های پردازش‌شده حفظ شده و قابل بازرسی است.
 #2.7.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که منابع ورودی نامعمول یا نامعتبر علامت‌گذاری شده و مشمول بررسی دقیق‌تر یا مسدودسازی می‌شوند.

---

### C2.8 تشخیص تهدید پویا در زمان واقعی

توسعه‌دهندگان باید از سیستم‌های تشخیص تهدید پیشرفته برای هوش مصنوعی استفاده کنند که با الگوهای حمله جدید سازگار می‌شوند و حفاظت در زمان واقعی را با تطبیق الگوهای کامپایل‌شده ارائه می‌کنند.

 #2.8.1    سطح: 1    نقش: D/V
 تأیید کنید که الگوهای تشخیص تهدید به موتورهای مبتنی بر regex بهینه‌شده کامپایل می‌شوند تا فیلترینگ با کارایی بالا در زمان واقعی با کمترین تأخیر ممکن انجام شود.
 #2.8.2    سطح: 1    نقش: D/V
 بررسی کنید که سیستم‌های تشخیص تهدید کتابخانه‌های الگوهای جداگانه را برای دسته‌های تهدید مختلف نگهداری می‌کنند (تزریق پرامپت، محتوای مضر، داده‌های حساس، دستورات سیستم).
 #2.8.3    سطح: 2    نقش: D/V
 بررسی کنید که تشخیص تهدید تطبیقی از مدل‌های یادگیری ماشین استفاده می‌کند که حساسیت تهدید را بر اساس فراوانی حملات و نرخ‌های موفقیت به‌روزرسانی می‌کنند.
 #2.8.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که جریان‌های اطلاعات تهدید در زمان واقعی به‌طور خودکار کتابخانه‌های الگو را با امضاهای حمله جدید و IOCs (شاخص‌های نفوذ) به‌روزرسانی می‌کنند.
 #2.8.5    سطح: 3    نقش: D/V
 تأیید کنید که نرخ‌های مثبت کاذب در تشخیص تهدید به‌طور مداوم پایش می‌شوند و اختصاصیتِ الگوها به‌طور خودکار تنظیم می‌شود تا تداخل با موارد استفاده مشروع را به حداقل برساند.
 #2.8.6    سطح: 3    نقش: D/V
 تایید کنید که تحلیل تهدید مبتنی بر زمینه منبع ورودی، الگوهای رفتار کاربر و تاریخچه نشست را در نظر می‌گیرد تا دقت تشخیص بهبود یابد.
 #2.8.7    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که معیارهای عملکرد تشخیص تهدید (نرخ تشخیص، تاخیر پردازش، مصرف منابع) در زمان واقعی پایش و بهینه می‌شوند.

---

### C2.9 خط لوله اعتبارسنجی امنیتی چند-رسانه‌ای

توسعه‌دهندگان باید اعتبارسنجی امنیتی برای متن، تصویر، صدا و سایر حالت‌های ورودی هوش مصنوعی را با انواع مشخصی از تشخیص تهدید و ایزول‌سازی منابع ارائه دهند.

 #2.9.1    سطح: 1    نقش: D/V
 تأیید کنید که هر قالب ورودی دارای اعتبارسنج‌های امنیتی اختصاصی با الگوهای تهدید مستندسازی‌شده (متن: تزریق پرامپت، تصاویر: استگانوگرافی، صوت: حملات اسپکتروگرام) و آستانه‌های تشخیص باشد.
 #2.9.2    سطح: 2    نقش: D/V
 تأیید کنید که ورودی‌های چندمودالی در ساندباکس‌های ایزوله با محدودیت‌های منبع مشخص (حافظه، CPU، زمان پردازش) که برای هر نوع مودالیتی تعیین شده‌اند، پردازش می‌شوند و در سیاست‌های امنیتی مستندسازی شده‌اند.
 #2.9.3    سطح: 2    نقش: D/V
 تأیید کنید که تشخیص حملات میان‌رسانه‌ای، حملات هماهنگ‌شده‌ای که ورودی‌های چندگانه را در بر می‌گیرند (مثلاً بارهای مخفی استگانوگرافی در تصاویر که با تزریق پرامپت در متن ترکیب می‌شوند)، با استفاده از قوانین همبستگی و تولید هشدار شناسایی می‌کند.
 #2.9.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که شکست‌های اعتبارسنجی چندمودالی منجر به لاگ‌گذاری دقیق می‌شوند، که این لاگ‌گذاری شامل تمام مودال‌های ورودی، نتایج اعتبارسنجی، امتیازهای تهدید و تحلیل همبستگی با قالب‌های لاگ ساختاریافته برای ادغام با SIEM است.
 #2.9.5    سطح: 3    نقش: D/V
 تأیید کنید که طبقه‌بندهای محتوای مختص هر مودالیتی مطابق با برنامه‌های مستند به‌روزرسانی می‌شوند، همراه با الگوهای تهدید جدید، نمونه‌های حمله‌ای و بنچمارک‌های عملکردی که بالاتر از آستانه‌های پایه نگه داشته می‌شوند.

---

### منابع

LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security
Generative AI's Biggest Security Flaw Is Not Easy to Fix
Many-shot jailbreaking \ Anthropic
$PDF$ OpenAI GPT-4.5 System Card
Notebook for the CheckThat Lab at CLEF 2024
Mitigate jailbreaks and prompt injections – Anthropic
Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis
OWASP Top 10 for LLM Applications 2025 – WorldTech IT
OWASP Machine Learning Security Top Ten
Few words about AI Security – Jussi Metso
How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry
Easily enforcing valid JSON schema following – API
AI Safety + Cybersecurity R\&D Tracker – Fairly AI
Anthropic makes 'jailbreak' advance to stop AI models producing harmful results
Pattern matching filter rules - IBM
Real-time Threat Detection

## C3 مدیریت چرخه عمر مدل و کنترل تغییر

### هدف کنترل

سیستم‌های هوش مصنوعی باید فرآیندهای کنترل تغییر را پیاده‌سازی کنند تا تغییرات نامجاز یا ناایمن مدل به محیط تولید نرسند. این کنترل، تمامیت مدل را در طول چرخهٔ حیات--از توسعه تا استقرار تا خاتمه‌سازی--تضمین می‌کند که امکان واکنش سریع به رویدادها را فراهم می‌آورد و مسئولیت‌پذیری تمامی تغییرات را حفظ می‌کند.

هدف امنیتی اصلی: فقط مدل‌های مجاز و تاییدشده به تولید می‌رسند با استفاده از فرایندهای کنترل‌شده که تمامیت، قابلیت ردیابی و بازیابی را حفظ می‌کنند.

---

### C3.1 مجوز مدل و یکپارچگی

فقط مدل‌های مجاز با یکپارچگی تأییدشده به محیط‌های تولید می‌رسند.

 #3.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمامی آثار مدل (وزنه‌ها، پیکربندی‌ها، توکنایزرها) قبل از استقرار با امضای دیجیتال از سوی نهادهای مجاز امضا شده‌اند.
 #3.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که در زمان استقرار، یکپارچگی مدل بررسی می‌شود و شکست‌های تأیید امضا از بارگذاری مدل جلوگیری می‌کنند.
 #3.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که سوابق منشأ مدل شامل هویت نهاد مجاز، مقادیر هش داده‌های آموزشی، نتایج آزمون اعتبارسنجی با وضعیت قبول/رد، و زمان ایجاد است.
 #3.1.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تمام دارایی‌های مدل از نسخه‌بندی معنایی پیروی می‌کنند (MAJOR.MINOR.PATCH) با معیارهای مستندسازی‌شده که تعیین می‌کند هر جزء از نسخه چه زمانی افزایش می‌یابد.
 #3.1.5    سطح: 2    نقش: V
 تأیید کنید که پیگیری وابستگی‌ها موجودی زمان واقعی نگه می‌دارد که امکان شناسایی سریع تمام سیستم‌های مصرف‌کننده را فراهم می‌کند.

---

### C3.2 اعتبارسنجی مدل و آزمایش

مدل‌ها باید قبل از استقرار از اعتبارسنجی‌های امنیتی و ایمنی تعریف‌شده عبور کنند.

 #3.2.1    سطح: 1    نقش: D/V
 تصدیق کنید که مدل‌ها پیش از استقرار از طریق آزمایش‌های امنیتی خودکار عبور می‌کنند که شامل اعتبارسنجی ورودی، پاک‌سازی خروجی و ارزیابی‌های ایمنی با آستانه‌های پذیرش/رد از پیش تعیین‌شده سازمانی است.
 #3.2.2    سطح: 1    نقش: D/V
 تأیید کنید که شکست‌های اعتبارسنجی پس از تأیید صریح استثنا از سوی کارکنان مجاز از پیش تعیین‌شده با توجیهات تجاری مستند، به‌طور خودکار استقرار مدل را مسدود می‌کند.
 #3.2.3    سطح: 2    نقش: V
 تصدیق کنید که نتایج آزمایش دارای امضای رمزنگاری‌شده هستند و به طور غیرقابل تغییر به هش نسخه مدل مشخصی که در حال اعتبارسنجی است، پیوند داده شده‌اند.
 #3.2.4    سطح: 2    نقش: D/V
 تأیید کنید که استقرارهای اضطراری نیازمند ارزیابی ریسک امنیتی مستند و تأیید از سوی مرجع امنیتی از پیش تعیین‌شده در چارچوب بازه‌های زمانی از پیش توافق‌شده هستند.

---

### C3.3 استقرار کنترل‌شده و بازگردانی به نسخه قبلی

استقرارهای مدل باید کنترل شوند، پایش شوند و قابل بازگشت باشند.

 #3.3.1    سطح: 1    نقش: D
 تأیید کنید که استقرارهای تولیدی، مکانیزم‌های انتشار تدریجی (استقرارهای کاناری، استقرارهای آبی-سبز) را پیاده‌سازی می‌کنند و محرک‌های بازگردانی خودکار را بر پایه نرخ‌های خطای از پیش توافق‌شده، آستانه‌های تأخیر یا معیارهای هشدار امنیتی فعال می‌کنند.
 #3.3.2    سطح: 1    نقش: D/V
 تأیید کنید که قابلیت‌های بازگردانی به‌طور اتمی وضعیت کامل مدل را (وزن‌ها، پیکربندی‌ها، وابستگی‌ها) در بازه‌های زمانی از پیش تعیین‌شده سازمانی بازمی‌گردانند.
 #3.3.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فرآیندهای استقرار امضاهای رمزنگاری‌شده را اعتبارسنجی می‌کنند و پیش از فعال‌سازی مدل، هش‌های یکپارچگی را محاسبه می‌کنند و در هر ناسازگاری، استقرار را شکست می‌دهند.
 #3.3.4    سطح: 2    نقش: D/V
 تأیید کنید که قابلیت‌های خاموشی اضطراری مدل می‌توانند نقاط پایانی مدل را در بازه‌های زمانی پاسخ از پیش تعیین‌شده، از طریق قطع‌کننده‌های مدار خودکار یا کلیدهای قطع دستی، غیرفعال کنند.
 #3.3.5    سطح: 2    نقش: V
 بررسی کنید که آثار بازگردانی (نسخه‌های قبلی مدل، پیکربندی‌ها، وابستگی‌ها) مطابق سیاست‌های سازمانی نگه‌داری می‌شوند و دارای ذخیره‌سازی غیرقابل تغییر برای پاسخ به حوادث هستند.

---

### C3.4 تغییر مسئولیت‌پذیری و حسابرسی

تمام تغییرات چرخه عمر مدل باید قابل پیگیری و قابل حسابرسی باشند.

 #3.4.1    سطح: 1    نقش: V
 بررسی کنید که تمام تغییرات مدل (استقرار، پیکربندی، بازنشستگی) ثبت‌های حسابرسی غیرقابل تغییر تولید می‌کند که شامل برچسب زمانی، هویت کاربر احراز شده، نوع تغییر و وضعیت‌های قبل و بعد است.
 #3.4.2    سطح: 2    نقش: D/V
 تأیید کنید که دسترسی به لاگ ممیزی به مجوز مناسب نیاز دارد و تمامی تلاش‌های دسترسی با هویت کاربر و زمان ثبت آن‌ها ثبت می‌شوند.
 #3.4.3    سطح: 2    نقش: D/V
 تأیید کنید که الگوهای پرامپت و پیام‌های سیستمی در مخازن گیت تحت کنترل نسخه هستند، با بازبینی کد اجباری و تأیید از سوی بازبینی‌کنندگان تعیین‌شده قبل از استقرار.
 #3.4.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که سوابق ممیزی شامل جزئیات کافی هستند (هش‌های مدل، تصاویر پیکربندی، نسخه‌های وابستگی) تا امکان بازسازی کامل وضعیت مدل را برای هر زمان مشخص در طول دوره نگهداری فراهم شود.

---

### C3.5 روش‌های توسعه امن

فرآیندهای توسعه مدل و آموزش باید از شیوه‌های امن پیروی کنند تا از نفوذ جلوگیری شود.

 #3.5.1    سطح: 1    نقش: D
 تأیید کنید که محیط‌های توسعه مدل، آزمون و تولید از نظر فیزیکی یا منطقی از هم جدا هستند. آنها هیچ زیرساخت مشترکی ندارند، کنترل‌های دسترسی متمایز دارند و مخازن داده جدا از هم دارند.
 #3.5.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که آموزش مدل و تنظیم دقیق آن در محیط‌های ایزوله با دسترسی شبکه کنترل‌شده انجام می‌شود.
 #3.5.3    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که منابع داده‌های آموزشی پیش از استفاده در توسعه مدل از طریق بررسی‌های یکپارچگی تأیید می‌شوند و از طریق منابع معتبر با زنجیره نگهداری مستند احراز هویت می‌شوند.
 #3.5.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که دارایی‌های توسعه مدل (هایپرپارامترها، اسکریپت‌های آموزش، فایل‌های پیکربندی) در کنترل نسخه نگهداری می‌شوند و قبل از استفاده در آموزش، نیاز به تأیید بازبینی همتا دارند.

---

### C3.6 بازنشستگی مدل و خروج از سرویس

مدل‌ها باید زمانی که دیگر لازم نیستند یا زمانی که مسائل امنیتی شناسایی می‌شوند، به‌طور ایمن بازنشسته شوند.

 #3.6.1    سطح: 1    نقش: D
 تأیید کنید که فرایندهای بازنشستگی مدل به‌طور خودکار گراف‌های وابستگی را اسکن می‌کنند، تمام سیستم‌های مصرف‌کننده را شناسایی می‌کنند و پیش از خروج مدل‌ها از سرویس، مدت‌زمان‌های اطلاع‌رسانی پیش از موعدی که از قبل توافق شده‌اند را فراهم می‌کنند.
 #3.6.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که آثار مدل‌های بازنشسته به‌طور ایمن پاک می‌شوند، با استفاده از حذف رمزنگاری‌شده یا بازنویسی با چند پاس، طبق سیاست‌های نگهداری داده‌های مستند و با گواهی‌های تخریب معتبر.
 #3.6.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که رویدادهای بازنشستگی مدل با برچسب زمانی و هویت عامل ثبت می‌شوند و امضای مدل‌ها لغو می‌شود تا از استفاده مجدد جلوگیری گردد.
 #3.6.4    سطح: 2    نقش: D/V
 تأیید کنید که بازنشستگی اضطراری مدل می‌تواند دسترسی به مدل را در چارچوب بازه‌های پاسخ اضطراری از پیش تعیین‌شده از طریق کلیدهای قطع خودکار غیرفعال کند، در صورت کشف آسیب‌پذیری‌های امنیتی حیاتی.

---

### منابع

MLOps Principles
Securing AI/ML Ops – Cisco.com
Audit logs security: cryptographically signed tamper-proof logs
Machine Learning Model Versioning: Top Tools & Best Practices
AI Hygiene Starts with Models and Data Loaders – SEI Blog
How to handle versioning and rollback of a deployed ML model?
Reinforcement fine-tuning – OpenAI API
Auditing Machine Learning models: Governance, Data Security and …
Adversarial Training to Improve Model Robustness
What is AI adversarial robustness? – IBM Research
Exploring Data Provenance: Ensuring Data Integrity and Authenticity
MITRE ATLAS
AWS Prescriptive Guidance – Best practices for retiring applications …

## زیرساخت C4، پیکربندی و امنیت استقرار

### هدف کنترل

زیرساخت هوش مصنوعی باید در برابر ارتقای سطح دسترسی، دستکاری زنجیره تأمین و حرکت جانبی مقاوم شود از طریق پیکربندی امن، جداسازی در زمان اجرا، خط‌لوله‌های استقرار معتبر و مانیتورینگ جامع. فقط اجزای زیرساختی مجاز و معتبر و پیکربندی‌های تأییدشده از طریق فرایندهای کنترل‌شده به تولید می‌رسند که امنیت، یکپارچگی و قابلیت حسابرسی را حفظ می‌کنند.

هدف امنیتی اصلی: فقط اجزای زیرساختی دارای امضای رمزنگاری‌شده و اسکن‌شده از لحاظ آسیب‌پذیری به محیط تولید می‌رسند، از طریق خطوط اعتبارسنجی خودکار که سیاست‌های امنیتی را اجرا می‌کنند و سوابق حسابرسی غیرقابل تغییر را حفظ می‌کنند.

---

### C4.1 ایزولاسیون محیط زمان اجرا

جلوگیری از فرار کانتینرها و ارتقاء سطح دسترسی از طریق ابزارهای ایزولاسیون مبتنی بر هسته و کنترل‌های دسترسی اجباری.

 #4.1.1    سطح: 1    نقش: D/V
 مطمئن شوید که همه کانتینرهای هوش مصنوعی تمام قابلیت‌های لینوکس را به جز CAP_SETUID, CAP_SETGID, و قابلیت‌های لازم به‌طور صریح که در استانداردهای امنیتی پایه مستندسازی شده‌اند، کنار بگذارند.
 #4.1.2    سطح: 1    نقش: D/V
 تایید کنید که پروفایل‌های seccomp تمام فراخوانی‌های سیستمی را مسدود می‌کنند، به جز آن‌هایی که در فهرست‌های مجاز از پیش تأیید شده قرار دارند، به‌طوری که نقض‌ها کانتینر را خاتمه داده و هشدارهای امنیتی ایجاد می‌شوند.
 #4.1.3    سطح: 2    نقش: D/V
 بررسی کنید که بارهای کاری هوش مصنوعی با سیستم فایل ریشه فقط-خواندنی، tmpfs برای داده‌های موقتی، و حجم‌های نام‌دار برای داده‌های پایدار با اعمال گزینه‌های مونت noexec اجرا می‌شوند.
 #4.1.4    سطح: 2    نقش: D/V
 تأیید کنید که نظارت در زمان اجرا مبتنی بر eBPF (Falco، Tetragon، یا معادل آن) تلاش‌های ارتقای سطح دسترسی را تشخیص داده و فرایندهای مخل امنیت را به طور خودکار از کار می‌اندازد، و این کار را در چارچوب الزامات پاسخ‌دهی سازمانی انجام می‌دهد.
 #4.1.5    سطح: 3    نقش: D/V
 بررسی کنید که بارهای کاری هوش مصنوعی با ریسک بالا در محیط‌های ایزوله سخت‌افزاری (Intel TXT، AMD SVM، یا گره‌های bare-metal اختصاصی) با تصدیق گواهی اجرا می‌شوند.

---

### C4.2 خطوط لوله امن ساخت و استقرار

با استفاده از ساخت‌های قابل بازتولید و آثار امضا شده، یکپارچگی رمزنگاری و امنیت زنجیره تأمین را تضمین کنید.

 #4.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که زیرساخت-به‌عنوان-کد با ابزارهای tfsec، Checkov یا Terrascan در هر کامیت اسکن می‌شود و ادغام‌ها را با یافته‌های شدت CRITICAL یا HIGH مسدود می‌کند.
 #4.2.2    سطح: 1    نقش: D/V
 بررسی کنید که ساخت‌های کانتینری با هش‌های SHA256 یکسان در طول ساخت‌ها قابل بازتولید باشند و گواهی‌های منبع سطح 3 SLSA امضا شده با Sigstore تولید کنید.
 #4.2.3    سطح: 2    نقش: D/V
 تأیید کنید که تصاویر کانتینری SBOM‌های CycloneDX یا SPDX را در خود جای داده‌اند و قبل از بارگذاری در رجیستری با Cosign امضا می‌شوند، و تصاویر بدون امضا در هنگام استقرار رد می‌شوند.
 #4.2.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که خطوط لوله CI/CD از توکن‌های OIDC صادر شده توسط HashiCorp Vault، AWS IAM Roles یا Azure Managed Identity استفاده می‌کنند، و مدت اعتبار آن‌ها از محدودیت‌های سیاست امنیتی سازمانی فراتر نمی‌رود.
 #4.2.5    سطح: 2    نقش: D/V
 تأیید کنید که امضاهای Cosign و منشأ SLSA در طول فرایند استقرار، قبل از اجرای کانتینر، اعتبارسنجی شوند و خطاهای اعتبارسنجی باعث شکست فرایند استقرار می‌شوند.
 #4.2.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که محیط‌های ساخت در کانتینرهای موقتی یا ماشین‌های مجازی اجرا می‌شوند که هیچ فضای ذخیره‌سازی پایدار ندارند و از نظر شبکه از VPCهای تولید ایزوله‌اند.

---

### C4.3 امنیت شبکه و کنترل دسترسی

پیاده‌سازی شبکه‌سازی بدون اعتماد با سیاست‌های انکار پیش‌فرض و ارتباطات رمزگذاری‌شده.

 #4.3.1    سطح: 1    نقش: D/V
 بررسی کنید که آیا سیاست‌های شبکه کوبرنتیز یا هر معادل دیگری، به‌طور پیش‌فرض ورودی و خروجی را مسدود می‌کند و با قوانین اجازه صریح برای پورت‌های مورد نیاز (443، 8080 و غیره) عمل می‌کند.
 #4.3.2    سطح: 1    نقش: D/V
 بررسی کنید که SSH (پورت 22)، RDP (پورت 3389)، و نقاط پایانی متادیتای ابری (169.254.169.254) مسدود شده‌اند یا نیازمند احراز هویت مبتنی بر گواهی هستند.
 #4.3.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که ترافیک خروجی از طریق پراکسی‌های HTTP/HTTPS (Squid، Istio یا درگاه‌های NAT ابری) فیلتر می‌شود، با فهرست‌های دامنهٔ مجاز و ثبت درخواست‌های مسدود شده.
 #4.3.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که ارتباط بین سرویس‌ها از TLS دوطرفه استفاده می‌کند، گواهی‌ها مطابق سیاست سازمانی به‌طور دوره‌ای چرخانده می‌شوند و اعتبارسنجی گواهی به‌طور الزامی اعمال می‌شود (بدون پرچم‌های skip-verify).
 #4.3.5    سطح: 2    نقش: D/V
 تایید کنید که زیرساخت هوش مصنوعی در VPCهای اختصاصی/VNets اجرا می‌شود، بدون دسترسی مستقیم به اینترنت و تنها از طریق درگاه‌های NAT یا میزبان‌های نگهبان ارتباط برقرار می‌کند.

---

### C4.4 اسرار و مدیریت کلیدهای رمزنگاری

اعتبارنامه‌ها را از طریق ذخیره‌سازی مبتنی بر سخت‌افزار و چرخش خودکار با دسترسی صفر اعتماد محافظت کنید.

 #4.4.1    سطح: 1    نقش: D/V
 تأیید کنید که اسرار در HashiCorp Vault، AWS Secrets Manager، Azure Key Vault یا Google Secret Manager با رمزگذاری در حالت استراحت با استفاده از AES-256 ذخیره می‌شوند.
 #4.4.2    سطح: 1    نقش: D/V
 تأیید کنید که کلیدهای رمزنگاری در HSM‌های سطح 2 FIPS 140-2 (AWS CloudHSM، Azure Dedicated HSM) همراه با چرخش کلید طبق سیاست رمزنگاری سازمانی تولید می‌شوند.
 #4.4.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که چرخش اسرار به‌طور خودکار انجام می‌شود، با استقرار بدون وقفه و چرخش فوری که به تغییر پرسنل یا رویدادهای امنیتی واکنش نشان می‌دهد.
 #4.4.4    سطح: 2    نقش: D/V
 تأیید کنید که تصاویر کانتینر با ابزارهای (GitLeaks، TruffleHog، یا detect-secrets) اسکن می‌شوند تا از ساخت‌های حاوی کلیدهای API، رمزهای عبور یا گواهی‌نامه‌ها جلوگیری شود.
 #4.4.5    سطح: 2    نقش: D/V
 تأیید کنید که دسترسی به اسرار محیط تولید به MFA با توکن‌های سخت‌افزاری (YubiKey، FIDO2) نیاز دارد و توسط لاگ‌های حسابرسی غیرقابل تغییر که شامل هویت‌های کاربری و زمان‌های ثبت است، ثبت می‌شود.
 #4.4.6    سطح: 2    نقش: D/V
 تأیید کنید که رمزهای مخفی از طریق رمزهای مخفی کیوبرنتیس، ولوم‌های مونت‌شده یا کانتینرهای Init تزریق می‌شوند و اطمینان حاصل کنید که رمزهای مخفی هرگز در متغیرهای محیطی یا تصاویر جاسازی نمی‌شوند.

---

### C4.5 ایزوله‌سازی بار کاری هوش مصنوعی و اعتبارسنجی

مدل‌های هوش مصنوعی غیرقابل اعتماد را در محیط‌های ساندباکس امن با تحلیل رفتاری جامع ایزوله کنید.

 #4.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مدل‌های هوش مصنوعی خارجی در gVisor، microVMها (مانند Firecracker، CrossVM) یا کانتینرهای Docker با پرچم‌های --security-opt=no-new-privileges و --read-only اجرا می‌شوند.
 #4.5.2    سطح: 1    نقش: D/V
 تأیید کنید که محیط‌های sandbox هیچ اتصال شبکه‌ای ندارند (--network=none) یا تنها به localhost دسترسی دارند و همه درخواست‌های خارجی توسط قواعد iptables مسدود شده‌اند.
 #4.5.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اعتبارسنجی مدل هوش مصنوعی—including? Wait, we must not insert extra. The final
 #4.5.4    سطح: 2    نقش: D/V
 تأیید کنید که قبل از اینکه مدل هوش مصنوعی به تولید منتقل شود، نتایج سندباکس آن توسط کارکنان امنیتی مجاز با امضای رمزنگاری‌شده امضا می‌شوند و در لاگ‌های ممیزی غیرقابل تغییر ذخیره می‌شوند.
 #4.5.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که محیط‌های سندباکس بین ارزیابی‌ها از تصاویر پایه طلایی نابود می‌شوند و دوباره از تصاویر پایه طلایی ساخته می‌شوند، با پاکسازی کامل سیستم فایل و حافظه.

---

### C4.6 نظارت بر امنیت زیرساخت

به‌طور مداوم زیرساخت‌ها را اسکن و پایش کنید، با اصلاح خودکار و هشدار در زمان-واقعی.

 #4.6.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تصاویر کانتینر مطابق با زمان‌بندی‌های سازمانی اسکن می‌شوند و آسیب‌پذیری‌های بحرانی مانع از استقرار می‌شوند، بر اساس آستانه‌های ریسک سازمانی.
 #4.6.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که زیرساخت‌ها با معیارهای CIS یا کنترل‌های NIST 800-53 مطابقت دارند، با آستانه‌های انطباق تعریف‌شده سازمانی و اصلاح خودکار برای چک‌های ناموفق.
 #4.6.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که آسیب‌پذیری‌های با شدت بالا مطابق با بازه‌های زمانی مدیریت ریسک سازمانی پچ شده‌اند. همچنین، رویه‌های اضطراری برای CVEهای به‌طور فعال بهره‌برداری‌شده وجود دارند.
 #4.6.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که هشدارهای امنیتی با پلت‌فرم‌های SIEM (Splunk، Elastic یا Sentinel) از طریق فرمت‌های CEF یا STIX/TAXII و با افزودن اطلاعات به‌طور خودکار، یکپارچه می‌شوند.
 #4.6.5    سطح: 3    نقش: V
 تأیید کنید که شاخص‌های زیرساخت به سیستم‌های مانیتورینگ (Prometheus، DataDog) با داشبوردهای SLA و گزارش‌دهی اجرایی صادر می‌شوند.
 #4.6.6    سطح: 2    نقش: D/V
 تایید کنید که انحراف پیکربندی با استفاده از ابزارها (Chef InSpec، AWS Config) طبق الزامات نظارت سازمانی تشخیص داده می‌شود و برای تغییرات غیرمجاز به‌طور خودکار بازگردانی می‌شود.

---

### C4.7 مدیریت منابع زیرساخت هوش مصنوعی

جلوگیری از حملات اتمام منابع و اطمینان از تخصیص عادلانه منابع از طریق سهمیه‌ها و پایش.

 #4.7.1    سطح: 1    نقش: D/V
 بررسی کنید که استفاده از GPU/TPU به وسیله هشدارهایی که بر اساس آستانه‌های تعریف‌شده توسط سازمان فعال می‌شوند، پایش می‌شود و مقیاس‌گذاری خودکار یا تعادل بار بر اساس سیاست‌های مدیریت ظرفیت فعال می‌شود.
 #4.7.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که معیارهای بار کاری هوش مصنوعی (تاخیر استنتاج، توان عملیاتی، نرخ‌های خطا) مطابق با الزامات نظارت سازمانی جمع‌آوری می‌شوند و با بهره‌برداری زیرساخت همبسته می‌شوند.
 #4.7.3    سطح: 2    نقش: D/V
 بررسی کنید که آیا محدودیت‌های منابع Kubernetes یا معادل‌های آن، بارهای کاری منفرد را بر اساس سیاست‌های تخصیص منابع سازمانی با محدودیت‌های سخت اعمال‌شده محدود می‌کند.
 #4.7.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که پایش هزینه‌ها به ازای هر بارکاری/مستاجر هزینه‌ها را پیگیری کند، با هشدارهایی بر اساس آستانه‌های بودجه سازمانی و کنترل‌های خودکار برای فراتر رفتن از بودجه.
 #4.7.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که برنامه‌ریزی ظرفیت از داده‌های تاریخی استفاده می‌کند، با دوره‌های پیش‌بینی تعریف‌شده توسط سازمان و تخصیص منابع به‌طور خودکار بر اساس الگوهای تقاضا.
 #4.7.6    سطح: 2    نقش: D/V
 بررسی کنید که اتمام منابع منجر به فعال شدن فیوزهای نرم‌افزاری می‌شود، مطابق با الزامات پاسخ سازمانی و از جمله محدودیت نرخ درخواست‌ها بر پایه سیاست‌های ظرفیت و جداسازی بار کاری.

---

### C4.8 جداسازی محیط‌ها و کنترل‌های ارتقاء

اجرای محدودیت‌های شدید برای مرزهای محیطی با دروازه‌های ارتقاء خودکار و اعتبارسنجی امنیتی.

 #4.8.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که محیط‌های توسعه/آزمایش/تولید در VPCها/VNets جدا از هم اجرا می‌شوند و هیچ نقش IAM مشترکی، گروه‌های امنیتی مشترک یا اتصال شبکه مشترک وجود ندارند.
 #4.8.2    سطح: 1    نقش: D/V
 بررسی کنید که ارتقای محیط نیازمند تأیید از سوی کارکنان مجاز تعریف‌شده سازمانی با امضاهای رمزنگاری‌شده و مسیرهای حسابرسی غیرقابل تغییر است.
 #4.8.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که محیط‌های تولید دسترسی SSH را مسدود می‌کنند، ایندپوینت‌های دیباگ را غیرفعال کنید و درخواست‌های تغییر را با الزامات اطلاع‌رسانی قبلی سازمانی به جز مواقع اضطراری الزامی کنید.
 #4.8.4    سطح: 2    نقش: D/V
 تأیید کنید که تغییرات infrastructure-as-code نیازمند بازبینی همتایان همراه با آزمایش‌های خودکار و اسکن امنیتی قبل از ادغام به شاخه اصلی هستند.
 #4.8.5    سطح: 2    نقش: D/V
 تأیید کنید که داده‌های آزمایشی مطابق با الزامات حفظ حریم خصوصی سازمانی، تولید داده‌های مصنوعی یا پنهان‌سازی کامل داده‌ها با حذف اطلاعات قابل شناسایی شخصی (PII) انجام می‌شود و صحت آن تأیید می‌گردد.
 #4.8.6    سطح: 2    نقش: D/V
 تأیید کنید که دروازه‌های ارتقا شامل آزمایش‌های امنیتی خودکار (SAST، DAST، اسکن کانتینر) هستند، به‌گونه‌ای که برای تأیید هیچ یافته بحرانی وجود نداشته باشد.

---

### C4.9 پشتیبان‌گیری و بازیابی زیرساخت

اطمینان از تاب‌آوری زیرساخت از طریق پشتیبان‌گیری خودکار، روش‌های بازیابی آزمایش‌شده و قابلیت‌های بازیابی در برابر فاجعه.

 #4.9.1    سطح: 1    نقش: D/V
 تأیید کنید که پیکربندی‌های زیرساخت مطابق با برنامه‌های پشتیبان‌گیری سازمانی پشتیبان‌گیری می‌شوند تا مناطق جغرافیایی جدا از هم با اجرای استراتژی پشتیبان‌گیری 3-2-1.
 #4.9.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های پشتیبان در شبکه‌های کاملاً ایزوله با اعتبارنامه‌های جداگانه و ذخیره‌سازی با قطع کامل اتصال به شبکه برای حفاظت در برابر باج‌افزارها اجرا شوند.
 #4.9.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که فرایندهای بازیابی از طریق آزمایش‌های خودکار، طبق برنامه‌های سازمانی، آزمایش و اعتبارسنجی می‌شوند تا اهداف RTO و RPO با الزامات سازمانی مطابقت داشته باشند.
 #4.9.4    سطح: 3    نقش: V
 بررسی کنید که بازیابی فاجعه شامل دفترچه‌های اجرایی مخصوص هوش مصنوعی با بازگردانی وزن‌های مدل، بازسازی خوشه‌های GPU، و نگاشت وابستگی‌های سرویس باشد.

---

### C4.10 انطباق و حاکمیت زیرساخت

تطابق با مقررات را از طریق ارزیابی مداوم، مستندسازی و کنترل‌های خودکار حفظ کنید.

 #4.10.1    سطح: 2    نقش: D/V
 تأیید کنید که انطباق زیرساخت طبق برنامه‌های زمانی سازمانی و در برابر کنترل‌های SOC 2، ISO 27001 یا FedRAMP ارزیابی می‌شود و شواهد به‌صورت خودکار جمع‌آوری می‌شود.
 #4.10.2    سطح: 2    نقش: V
 تأیید کنید که مستندات زیرساختی شامل نمودارهای شبکه، نقشه‌های جریان داده و مدل‌های تهدید به‌روز شده مطابق با الزامات مدیریت تغییر سازمانی هستند.
 #4.10.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تغییرات زیرساختی از ارزیابی تأثیر انطباق به‌طور خودکار عبور می‌کنند و با گردش کارهای تأیید مقررات برای تغییرات با ریسک بالا همسو هستند.

---

### C4.11 امنیت سخت‌افزار هوش مصنوعی

اجزای سخت‌افزاری ایمن مخصوص هوش مصنوعی از جمله GPUها، TPUها و شتاب‌دهنده‌های تخصصی هوش مصنوعی.

 #4.11.1    سطح: 2    نقش: D/V
 بررسی کنید که فریمور شتاب‌دهنده هوش مصنوعی (GPU BIOS, TPU فریمور) با امضاهای رمزنگاری تأیید می‌شود و بر اساس زمان‌بندی‌های مدیریت پچ سازمانی به‌روزرسانی می‌شود.
 #4.11.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که پیش از اجرای بارکاری، یکپارچگی شتاب‌دهنده هوش مصنوعی از طریق اعتبارسنجی سخت‌افزاری با استفاده از TPM 2.0، Intel TXT یا AMD SVM تأیید می‌شود.
 #4.11.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که حافظهٔ GPU بین بارهای کاری ایزوله شده است، با استفاده از SR-IOV، MIG (Multi-Instance GPU) یا تقسیم‌بندی سخت‌افزاری معادل، و با پاک‌سازی حافظه بین وظایف.
 #4.11.4    سطح: 3    نقش: V
 بررسی کنید که زنجیره تأمین سخت‌افزار هوش مصنوعی شامل تأیید منشاء با گواهی‌های سازنده و اعتبارسنجی بسته‌بندی ضد دستکاری باشد.
 #4.11.5    سطح: 3    نقش: D/V
 تأیید کنید که ماژول‌های امنیتی سخت‌افزاری (HSMs) وزن‌های مدل هوش مصنوعی و کلیدهای رمزنگاری را با گواهی FIPS 140-2 سطح 3 یا گواهی معیارهای مشترک امنیتی EAL4+ حفاظت می‌کنند.

---

### C4.12 زیرساخت‌های هوش مصنوعی لبه‌ای و توزیعی

پیاده‌سازی‌های امن هوش مصنوعی توزیع‌شده از جمله محاسبه لبه‌ای، یادگیری فدرال، و معماری‌های چندسایته.

 #4.12.1    سطح: 2    نقش: D/V
 تأیید کنید که دستگاه‌های Edge AI به زیرساخت مرکزی با استفاده از TLS متقابل احراز هویت می‌کنند و گواهی‌های دستگاه بر اساس سیاست مدیریت گواهی سازمانی به‌روز می‌شوند.
 #4.12.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که دستگاه‌های لبه‌ای بوت ایمن را با امضاهای معتبر و حفاظت در برابر بازگردانی نسخه فریم‌ور پیاده‌سازی می‌کنند تا از حملات کاهش نسخه فریم‌ور جلوگیری شود.
 #4.12.3    سطح: 3    نقش: D/V
 تأیید کنید که هماهنگی توزیع‌شده هوش مصنوعی از الگوریتم‌های اجماع مقاوم در برابر خطای بیزانتی با اعتبارسنجی شرکت‌کنندگان و تشخیص گره‌های مخرب استفاده می‌کند.
 #4.12.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که ارتباط لبه-به-ابر شامل محدودسازی پهنای باند، فشرده‌سازی داده‌ها و قابلیت‌های کارکرد آفلاین با ذخیره‌سازی محلی امن باشد.

---

### C4.13 امنیت زیرساخت‌های چند-ابری و هیبریدی

بارهای کاری هوش مصنوعی را در میان چند ارائه‌دهندهٔ ابری و استقرارهای ترکیبی ابری-درمحل امن کنید.

 #4.13.1    سطح: 2    نقش: D/V
 تأیید کنید که پیاده‌سازی‌های هوش مصنوعی چندابری از فدراسیون هویت غیروابسته به ابر (OIDC, SAML) با مدیریت سیاست متمرکز در میان ارائه‌دهندگان استفاده می‌کنند.
 #4.13.2    سطح: 2    نقش: D/V
 تأیید کنید که انتقال داده بین ابرهای مختلف از رمزگذاری پایان-به-پایان با کلیدهای مدیریت‌شده توسط مشتری و کنترل‌های اقامت داده که بر اساس هر حوزه قضایی اعمال می‌شوند، برخوردار است.
 #4.13.3    سطح: 2    نقش: D/V
 بررسی کنید که بارهای کاری هوش مصنوعی در ابر هیبریدی سیاست‌های امنیتی یکپارچه‌ای را در سراسر محیط‌های محلی و ابری اجرا می‌کنند، با مانیتورینگ و اعلان یکپارچه.
 #4.13.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که جلوگیری از قفل‌شدن در برابر ارائه‌دهندهٔ خدمات ابری شامل زیرساخت-به‌عنوان-کد قابل‌حمل، رابط‌های API استاندارد، و قابلیت‌های صادرات داده با ابزارهای تبدیل فرمت است.
 #4.13.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که بهینه‌سازی هزینه چندابری شامل کنترل‌های امنیتی است که از گسترش بی‌رویه منابع جلوگیری می‌کند و همچنین هزینه‌های انتقال داده بین ابرها که بدون مجوز انجام می‌شود را محدود می‌کند.

---

### C4.14 اتوماسیون زیرساخت و امنیت GitOps

ایمن‌سازی خطوط لولهٔ اتوماسیون زیرساخت و گردش‌های کاری GitOps برای مدیریت زیرساخت هوش مصنوعی.

 #4.14.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مخازن GitOps کامیت‌های امضا شده با کلیدهای GPG را الزامی می‌کنند و قواعد حفاظت از شاخه‌ها از پوش مستقیم به شاخه‌های اصلی جلوگیری می‌کنند.
 #4.14.2    سطح: 2    نقش: D/V
 بررسی کنید که اتوماسیون زیرساخت شامل تشخیص انحراف پیکربندی با اصلاح خودکار و قابلیت‌های بازگردانی باشد که بر اساس الزامات پاسخ سازمانی برای تغییرات غیرمجاز فعال می‌شود.
 #4.14.3    سطح: 2    نقش: D/V
 بررسی کنید که پیاده‌سازی خودکار زیرساخت شامل اعتبارسنجی سیاست امنیتی باشد و برای پیکربندی‌های ناسازگار، استقرار را مسدود کند.
 #4.14.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اسرار اتوماسیون زیرساخت از طریق اپراتورهای اسرار خارجی (External Secrets Operator، Bank-Vaults) با چرخش خودکار مدیریت می‌شوند.
 #4.14.5    سطح: 3    نقش: V
 بررسی کنید که زیرساخت خودترمیم همبستگی رویداد امنیتی را با پاسخ حادثه خودکار و گردش‌کارهای اطلاع‌رسانی به ذی‌نفعان در بر می‌گیرد.

---

### C4.15 امنیت زیرساخت‌های مقاوم در برابر کامپیوترهای کوانتومی

آماده‌سازی زیرساخت هوش مصنوعی برای تهدیدهای محاسبات کوانتومی از طریق رمزنگاری پساکوانتومی و پروتکل‌های مقاوم در برابر کوانتوم.

 #4.15.1    سطح: 3    نقش: D/V
 تایید کنید که زیرساخت‌های هوش مصنوعی الگوریتم‌های رمزنگاری پساکوانتومی تاییدشده توسط NIST (CRYSTALS-Kyber, CRYSTALS-Dilithium, SPHINCS+) را برای تبادل کلید و امضای دیجیتال پیاده‌سازی می‌کند.
 #4.15.2    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های توزیع کلید کوانتومی (QKD) برای ارتباطات هوش مصنوعی با امنیت بالا با پروتکل‌های مدیریت کلید مقاوم در برابر کوانتوم پیاده‌سازی شده‌اند.
 #4.15.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که چارچوب‌های چابکی رمزنگاری امکان مهاجرت سریع به الگوریتم‌های پس از کوانتوم جدید را با چرخش خودکار گواهی دیجیتال و کلید فراهم می‌کنند.
 #4.15.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که مدل‌سازی تهدیدهای کوانتومی آسیب‌پذیری زیرساخت‌های هوش مصنوعی در برابر حملات کوانتومی را ارزیابی می‌کند، با زمان‌بندی‌های مهاجرت مستند و ارزیابی‌های ریسک.
 #4.15.5    سطح: 3    نقش: D/V
 تأیید کنید که سامانه‌های رمزنگاری هیبرید کلاسیک-کوانتومی در طول دورهٔ گذار کوانتومی دفاع در عمق را با نظارت بر عملکرد فراهم می‌کنند.

---

### C4.16 محاسبات محرمانه و محفظه‌های امن

از بارهای کاری هوش مصنوعی و وزن‌های مدل با استفاده از محیط‌های اجرای امن مبتنی بر سخت‌افزار و فناوری‌های محاسبات محرمانه محافظت کنید.

 #4.16.1    سطح: 3    نقش: D/V
 تایید کنید که مدل‌های حساس هوش مصنوعی درون محفظه‌های SGX اینتل، SEV-SNP AMD یا ARM TrustZone با حافظه رمزگذاری‌شده و تصدیق گواهی اجرا شوند.
 #4.16.2    سطح: 3    نقش: D/V
 تأیید کنید که کانتینرهای محرمانه (Kata Containers، gVisor با محاسبات محرمانه) بارهای کاری هوش مصنوعی را با رمزگذاری حافظه که توسط سخت‌افزار اعمال می‌شود، ایزوله می‌کنند.
 #4.16.3    سطح: 3    نقش: D/V
 تأیید کنید که گواهی‌سنجی از راه دور قبل از بارگذاری مدل‌های هوش مصنوعی، تمامیت محفظه امن را با اثبات رمزنگاری‌شدهٔ اصالت یک محیط اجرایی تأیید می‌کند.
 #4.16.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که خدمات استنتاج هوش مصنوعی محرمانه از استخراج مدل جلوگیری می‌کنند از طریق محاسبات رمزگذاری‌شده با وزن‌های مدل مهر و موم‌شده و اجرای محافظت‌شده.
 #4.16.5    سطح: 3    نقش: D/V
 تأیید کنید که هماهنگ‌سازی محیط اجرای قابل اعتماد، چرخه حیات محفظه امن را با احراز اصالت از راه دور و کانال‌های ارتباطی رمزگذاری‌شده مدیریت می‌کند.
 #4.16.6    سطح: 3    نقش: D/V
 تایید کنید که محاسبه امن چندجانبه (SMPC) امکان آموزش مشترک هوش مصنوعی را بدون افشای داده‌های هر مجموعه داده یا پارامترهای مدل فراهم می‌کند.

---

### C4.17 زیرساخت اثبات بدون دانش

پیاده‌سازی سامانه‌های اثبات بدون دانش برای تأیید و احراز هویت هوش مصنوعی با حفظ حریم خصوصی و بدون افشای اطلاعات حساس.

 #4.17.1    سطح: 3    نقش: D/V
 بررسی کنید که اثبات‌های بدون دانش (ZK-SNARKها، ZK-STARKها) اعتبار یکپارچگی مدل هوش مصنوعی و منشأ آموزش آن را بدون افشای وزن‌های مدل یا داده‌های آموزشی تأیید می‌کنند.
 #4.17.2    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که سامانه‌های احراز هویت مبتنی بر ZK امکان تأیید هویت کاربر با حفظ حریم خصوصی را برای خدمات هوش مصنوعی فراهم می‌کنند، بدون افشای اطلاعات مربوط به هویت.
 #4.17.3    سطح: 3    نقش: D/V
 تأیید کنید که پروتکل‌های تقاطع مجموعه خصوصی (PSI) امکان مطابقت ایمن داده‌ها را برای هوش مصنوعی فدراسیونی فراهم می‌کنند، بدون افشای مجموعه‌های داده‌ی فردی.
 #4.17.4    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های یادگیری ماشین با دانش صفر (ZKML) امکان استنتاج‌های هوش مصنوعی قابل تأیید را با اثبات رمزنگاری‌شده صحت محاسبه فراهم می‌کنند.
 #4.17.5    سطح: 3    نقش: D/V
 تأیید کنید که ZK-rollups پردازش تراکنش‌های مبتنی بر هوش مصنوعی را با مقیاس‌پذیری و حفظ حریم خصوصی ارائه می‌دهند، با تصدیق دسته‌ای و کاهش سربار محاسباتی.

---

### C4.18 پیشگیری از حملات جانبی-کانالی

زیرساخت‌های هوش مصنوعی را از حملات جانبی مبتنی بر زمان، توان، الکترومغناطیسی و کش که ممکن است اطلاعات حساس را فاش کنند، محافظت کنید.

 #4.18.1    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که زمان استنتاج هوش مصنوعی با استفاده از الگوریتم‌های زمان‌ثابت و پدینگ نرمال می‌شود تا از حملات استخراج مدل مبتنی بر زمان جلوگیری گردد.
 #4.18.2    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که حفاظت در برابر تحلیل مصرف توان شامل تزریق نویز، فیلترینگ خط تغذیه و الگوهای اجرای تصادفی برای سخت‌افزارهای هوش مصنوعی باشد.
 #4.18.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که کاهش کانال جانبی مبتنی بر کش از تقسیم‌بندی کش، تصادفی‌سازی، و دستورالعمل‌های پاک‌سازی کش استفاده می‌کند تا از نشت اطلاعات جلوگیری شود.
 #4.18.4    سطح: 3    نقش: D/V
 تأیید کنید که حفاظت در برابر انتشارهای الکترومغناطیسی شامل شیلدینگ، فیلترینگ سیگنال، و پردازش تصادفی است تا از حملات به سبک TEMPEST جلوگیری شود.
 #4.18.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که دفاع‌های کانال جانبی میکرو معماری شامل کنترل‌های اجرای گمانه‌زنی و مخفی‌سازی الگوی دسترسی به حافظه هستند.

---

### C4.19 نورومورفی و امنیت سخت‌افزار هوش مصنوعی تخصصی

ایمن‌سازی معماری‌های سخت‌افزاری هوش مصنوعی در حال ظهور، از جمله چیپ‌های نورومورفی، FPGAها، ASIC‌های سفارشی و سیستم‌های محاسبات اپتیکی.

 #4.19.1    سطح: 3    نقش: D/V
 بررسی کنید که امنیت چیپ نورومورفی شامل رمزگذاری الگوهای اسپایک، حفاظت از وزن سیناپسی و اعتبارسنجی قاعده یادگیری مبتنی بر سخت‌افزار است.
 #4.19.2    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که شتاب‌دهنده‌های هوش مصنوعی مبتنی بر FPGA رمزگذاری بیت‌استریم، مکانیسم‌های ضد دستکاری و بارگذاری امن پیکربندی را با به‌روزرسانی‌های دارای اعتبار پیاده‌سازی می‌کنند.
 #4.19.3    سطح: 3    نقش: D/V
 تأیید کنید که امنیت ASIC سفارشی شامل پردازنده‌های امنیتی روی چیپ، ریشه اعتماد سخت‌افزاری، و ذخیره‌سازی امن کلید با تشخیص دستکاری است.
 #4.19.4    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های محاسبات نوری رمزنگاری نوری مقاوم در برابر کوانتوم، سوئیچینگ فوتونیک امن، و پردازش سیگنال نوری محافظت‌شده را پیاده‌سازی می‌کنند.
 #4.19.5    سطح: 3    نقش: D/V
 بررسی کنید که چیپ‌های هوش مصنوعی هیبرید آنالوگ-دیجیتال دارای محاسبات آنالوگ ایمن، ذخیره‌سازی امن وزن‌ها و تبدیل آنالوگ به دیجیتال با اعتبارسنجی هستند.

---

### C4.20 زیرساخت محاسباتی با حفظ حریم خصوصی

پیاده‌سازی کنترل‌های زیرساختی برای محاسبات با حفظ حریم خصوصی به منظور حفاظت از داده‌های حساس در پردازش و تحلیل هوش مصنوعی.

 #4.20.1    سطح: 3    نقش: D/V
 بررسی کنید که آیا زیرساخت رمزنگاری هم‌ریختی امکان محاسبات رمزگذاری‌شده را در بارهای کاری حساس هوش مصنوعی با احراز یکپارچگی رمزنگاری و پایش کارایی فراهم می‌کند.
 #4.20.2    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که سامانه‌های بازیابی اطلاعات خصوصی امکان انجام پرس‌وجوهای پایگاه داده را بدون افشای الگوهای جستجو و با حفاظت رمزنگاری‌شده از الگوهای دسترسی فراهم می‌کنند.
 #4.20.3    سطح: 3    نقش: D/V
 تأیید کنید که پروتکل‌های محاسبهٔ چندجانبهٔ امن امکان استنتاج هوش مصنوعی با حفظ حریم خصوصی را فراهم می‌کنند، بدون افشای ورودی‌های فردی یا محاسبات میانی.
 #4.20.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مدیریت کلید با حفظ حریم خصوصی شامل تولید کلید توزیعی، رمزنگاری آستانه، و چرخش امن کلید با حفاظت مبتنی بر سخت‌افزار باشد.
 #4.20.5    سطح: 3    نقش: D/V
 بررسی کنید که عملکرد محاسبات حفظ حریم خصوصی از طریق دسته‌بندی، کش و شتاب سخت‌افزاری بهینه شده است، در حالی که ضمانت‌های امنیت رمزنگاری حفظ می‌شوند.

---

### C4.15 چارچوب عامل یکپارچه‌سازی ابری، امنیت و استقرار هیبریدی

کنترل‌های امنیتی برای فریم‌ورک‌های عامل یکپارچه با ابر با معماری‌های ترکیبی محلی-ابری.

 #4.15.1    سطح: 1    نقش: D/V
 تأیید کنید که ادغام ذخیره‌سازی ابری از رمزگذاری انتها تا انتها با مدیریت کلید تحت کنترل عامل استفاده می‌کند.
 #4.15.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مرزهای امنیتی استقرار هیبریدی به‌وضوح تعریف شده‌اند و از کانال‌های ارتباطی رمزگذاری‌شده استفاده می‌کنند.
 #4.15.3    سطح: 2    نقش: D/V
 بررسی کنید که دسترسی به منابع ابری شامل تصدیق صفر اعتماد با احراز هویت پیوسته باشد.
 #4.15.4    سطح: 3    نقش: D/V
 تأیید کنید که الزامات محل نگهداری داده‌ها از طریق تصدیق رمزنگاری‌شده مکان‌های ذخیره‌سازی اعمال می‌شوند.
 #4.15.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که ارزیابی‌های امنیتی ارائه‌دهندهٔ خدمات ابری شامل مدلسازی تهدیدهای مختص عامل و ارزیابی ریسک باشند.

---

### منابع

NIST Cybersecurity Framework 2.0
CIS Controls v8
OWASP Container Security Verification Standard
Kubernetes Security Best Practices
SLSA Supply Chain Security Framework
NIST SP 800-190: Application Container Security Guide
Cloud Security Alliance: Cloud Controls Matrix
ENISA: Secure Infrastructure Design
NIST SP 800-53: Security Controls for Federal Information Systems
ISO 27001:2022 Information Security Management
NIST AI Risk Management Framework
CIS Kubernetes Benchmark
FIPS 140-2 Security Requirements
NIST SP 800-207: Zero Trust Architecture
IEEE 2857: Privacy Engineering for AI Systems
NIST SP 800-161: Cybersecurity Supply Chain Risk Management
NIST Post-Quantum Cryptography Standards
Intel SGX Developer Guide
AMD SEV-SNP White Paper
ARM TrustZone Technology
ZK-SNARKs: A Gentle Introduction
NIST SP 800-57: Cryptographic Key Management
Side-Channel Attack Countermeasures
Neuromorphic Computing Security Challenges
FPGA Security: Fundamentals, Evaluation, and Countermeasures
Microsoft SEAL: Homomorphic Encryption Library
HElib: Homomorphic Encryption Library
PALISADE Lattice Cryptography Library
Differential Privacy: A Survey of Results
Secure Aggregation for Federated Learning
Private Information Retrieval: Concepts and Constructions

## C5 کنترل دسترسی و هویت برای اجزای هوش مصنوعی و کاربران

### هدف کنترل

کنترل دسترسی مؤثر برای سیستم‌های هوش مصنوعی نیازمند مدیریت هویت قوی، مجوزدهی آگاه به زمینه، و اجرای در زمان اجرا بر پایه اصول صفراعتماد است. این کنترل‌ها تضمین می‌کنند که انسان‌ها، خدمات و عوامل خودمختار تنها با مدل‌ها، داده‌ها و منابع محاسباتی در محدوده‌های صریحاً اعطا شده تعامل داشته باشند، با قابلیت‌های تأیید و بازرسی مستمر.

---

### C5.1 مدیریت هویت و احراز هویت

برای تمامی موجودیت‌ها، هویت‌های مبتنی بر رمزنگاری ایجاد کنید که برای عملیات با دسترسی ویژه از احراز هویت چندعاملی استفاده کنند.

 #5.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمامی کاربران انسانی و شناسه‌های سرویس از طریق یک ارائه‌دهنده هویت سازمانی متمرکز (IdP) با استفاده از پروتکل‌های OIDC/SAML احراز هویت می‌کنند و دارای نگاشت‌های هویت به توکن منحصربه‌فرد هستند (بدون حساب‌ها یا اعتبارنامه‌های مشترک).
 #5.1.2    سطح: 1    نقش: D/V
 تأیید کنید که عملیات با ریسک بالا (استقرار مدل، صادرات وزن‌ها، دسترسی به داده‌های آموزشی، تغییرات پیکربندی تولید) به احراز هویت چندعاملی یا احراز هویت سطح بالاتر با بازبینی مجدد نشست نیاز دارند.
 #5.1.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که کاربران جدید فرایند احراز هویت همسو با NIST 800-63-3 IAL-2 یا استانداردهای معادل را طی می‌کنند پیش از دریافت دسترسی به محیط تولید.
 #5.1.4    سطح: 2    نقش: V
 بررسی کنید که بازنگری‌های دسترسی به‌طور سه‌ماهه انجام می‌شوند، با تشخیص خودکار حساب‌های غیرفعال، اجرای چرخش اعتبارها و روندهای لغو دسترسی.
 #5.1.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که عامل‌های هوش مصنوعی فدراسیونی از طریق ادعاهای JWT امضا شده احراز هویت می‌کنند که دارای حداکثر مدت اعتبار 24 ساعت هستند و شامل اثبات رمزنگاری مبدا می‌باشند.

---

### C5.2 مجوز منابع و حداقل سطح دسترسی

پیاده‌سازی کنترل‌های دسترسی دقیق برای تمامی منابع هوش مصنوعی با مدل‌های مجوز صریح و سوابق ممیزی.

 #5.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر منبع هوش مصنوعی (مجموعه‌های داده، مدل‌ها، نقاط پایانی، مجموعه‌های برداری، نمایه‌های جاسازی‌شده، نمونه‌های محاسباتی)، کنترل‌های دسترسی مبتنی بر نقش را با فهرست‌های مجاز صریح و سیاست‌های رد به‌طور پیش‌فرض اجرا می‌کند.
 #5.2.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که اصول حداقل دسترسی به‌طور پیش‌فرض اعمال می‌شوند، به‌طوری که حساب‌های سرویس از مجوزهای فقط‌خواندنی آغاز می‌شوند و برای دسترسی نوشتن، توجیه تجاری مستند لازم است.
 #5.2.3    سطح: 1    نقش: V
 اطمینان حاصل کنید که همه تغییرات کنترل دسترسی به درخواست‌های تغییر تأییدشده مرتبط‌اند و به‌طور غیرقابل تغییر با برچسب‌های زمانی، هویت‌های عامل، شناسه‌های منابع و تغییرات مجوز ثبت می‌شوند.
 #5.2.4    سطح: 2    نقش: D
 تأیید کنید که برچسب‌های طبقه‌بندی داده‌ها (PII، PHI، تحت کنترل صادرات، مالکیتِ اختصاصی) به‌طور خودکار به منابع مشتق‌شده (بردارهای جاسازی‌شده، کش‌های پرومپت، خروجی‌های مدل) منتقل می‌شوند، با اجرای سیاستی سازگار.
 #5.2.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تلاش‌های دسترسی غیرمجاز و رویدادهای ارتقاء سطح دسترسی، در عرض 5 دقیقه، باعث ایجاد هشدارهای زمان واقعی همراه با متادیتای زمینه‌ای به سیستم‌های SIEM می‌شوند.

---

### C5.3 ارزیابی سیاست پویا

استقرار موتورهای کنترل دسترسی مبتنی بر ویژگی (ABAC) برای تصمیمات مجوزدهی با توجه به بافت با قابلیت‌های ممیزی.

 #5.3.1    سطح: 1    نقش: D/V
 تأیید کنید که تصمیمات مجوزدهی به یک موتور سیاستی اختصاصی (OPA، Cedar یا معادل آن) برون‌سپاری شده و از طریق APIهای احراز هویت‌شده در دسترس باشند و با حفاظت از یکپارچگی رمزنگاری‌شده محافظت شوند.
 #5.3.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیاست‌ها در زمان اجرا، ویژگی‌های پویا را ارزیابی می‌کنند، از جمله سطح دسترسی کاربر، طبقه‌بندی حساسیت منابع، زمینه درخواست، جداسازی مستاجر و محدودیت‌های زمانی.
 #5.3.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که تعاریف سیاست دارای کنترل نسخه هستند، با بازبینی همتا به همتا همراه‌اند، و پیش از استقرار در محیط تولید از طریق آزمایش‌های خودکار در خط‌لوله‌های CI/CD اعتبارسنجی می‌شوند.
 #5.3.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که نتایج ارزیابی سیاست‌ها شامل دلایل تصمیم ساختارمند باشند و به سیستم‌های SIEM منتقل شوند تا برای تحلیل هم‌ارتباطی و گزارش انطباق استفاده شوند.
 #5.3.5    سطح: 3    نقش: D/V
 تأیید کنید که مقادیر زمان زندگی کش سیاستی (TTL) برای منابع با حساسیت بالا از 5 دقیقه فراتر نرود و برای منابع استاندارد با قابلیت باطل‌سازی کش از 1 ساعت فراتر نرود.

---

### C5.4 Query-Time اجرای امنیت در زمان پرس‌وجو

پیاده‌سازی کنترل‌های امنیتی در لایه پایگاه داده با فیلترگذاری اجباری و سیاست‌های امنیتی سطح سطر.

 #5.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام کوئری‌های پایگاه داده‌های برداری و SQL شامل فیلترهای امنیتی اجباری هستند (شناسه مستاجر، برچسب‌های حساسیت داده‌ها، دامنه کاربر) که در سطح موتور پایگاه داده اعمال می‌شوند، نه در کد برنامه.
 #5.4.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیاست‌های امنیت سطح ردیف (RLS) و ماسک‌سازی سطح فیلد با وراثت سیاست برای همهٔ پایگاه‌های دادهٔ وکتور، شاخص‌های جستجو و مجموعه‌های دادهٔ آموزشی فعال شده‌اند.
 #5.4.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که ارزیابی‌های مجوز ناموفق از حملات «confused deputy attacks» جلوگیری می‌کنند، با توقف فوری کوئری‌ها و بازگرداندن کدهای خطای مجوز صریح به جای بازگرداندن مجموعه نتایج خالی.
 #5.4.4    سطح: 2    نقش: V
 تأیید کنید که تاخیر در ارزیابی سیاست به صورت پیوسته پایش می‌شود و برای شرایط تایم‌اوت که می‌تواند منجر به دور زدن مجوز شود، هشدارهای خودکار فعال هستند.
 #5.4.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مکانیسم‌های بازتلاش کوئری سیاست‌های دسترسی را دوباره ارزیابی می‌کنند تا تغییرات پویا در مجوزها را در نشست‌های کاربری فعال در نظر بگیرند.

---

### C5.5 فیلتر خروجی و جلوگیری از نشت داده‌ها

برای جلوگیری از افشای داده‌های غیرمجاز در محتوای تولیدشده با هوش مصنوعی، کنترل‌های پس‌پردازش را پیاده‌سازی کنید.

 #5.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مکانیسم‌های غربالگری پس از استنتاج، PII غیرمجاز، اطلاعات طبقه‌بندی‌شده و داده‌های مالکیتی را قبل از ارائه محتوا به درخواست‌کنندگان اسکن کرده و محرمانه می‌کنند.
 #5.5.2    سطح: 1    نقش: D/V
 بررسی کنید که استنادها، ارجاعات و نسبت‌دهی به منابع در خروجی‌های مدل با مجوزهای دسترسی درخواست‌کننده اعتبارسنجی شوند و در صورت تشخیص دسترسی غیرمجاز، از خروجی‌های مدل حذف گردند.
 #5.5.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که محدودیت‌های فرمت خروجی (PDFهای ایمن‌شده، تصاویر بدون متادیتا، انواع فایل‌های مجاز) بر اساس سطوح مجوز کاربر و طبقه‌بندی داده‌ها اعمال می‌شوند.
 #5.5.4    سطح: 2    نقش: V
 تأیید کنید که الگوریتم‌های محرمانه‌سازی قطعی هستند، دارای کنترل نسخه‌اند و لاگ‌های حسابرسی را حفظ می‌کنند تا از تحقیقات تطابق با مقررات و تحلیل قضایی پشتیبانی کنند.
 #5.5.5    سطح: 3    نقش: V
 تأیید کنید که رویدادهای پنهان‌سازی با ریسک بالا لاگ‌های تطبیقی تولید می‌کنند که شامل هش‌های رمزنگاری‌شده از محتوای اصلی برای بازیابیِ شواهدِ قضایی بدون افشای داده باشد.

---

### C5.6 ایزولاسیون چند مستاجر

ایزولاسیون رمزنگاری‌شده و منطقی بین مستأجران در زیرساخت هوش مصنوعی مشترک را تضمین کنید.

 #5.6.1    سطح: 1    نقش: D/V
 تأیید کنید که فضاهای حافظه، مخازن جاسازی، ورودی‌های کش و فایل‌های موقتی برای هر مستاجر به‌طور جداگانه در فضای نام تفکیک‌شده قرار دارند و در زمان حذف مستاجر یا پایان نشست، به‌طور ایمن پاکسازی می‌شوند.
 #5.6.2    سطح: 1    نقش: D/V
 بررسی کنید که هر درخواست API شامل شناسه مستاجر احراز هویت‌شده‌ای باشد که به‌وسیله رمزنگاری در برابر زمینه نشست و حقوق دسترسی کاربر اعتبارسنجی شده باشد.
 #5.6.3    سطح: 2    نقش: D
 بررسی کنید که سیاست‌های شبکه برای ارتباطات بین مستاجرهای مختلف در سرویس-مش‌ها و پلتفرم‌های ارکستراسیون کانتینرها، قوانین پیش‌فرض-انکار (default-deny) را اجرا می‌کنند.
 #5.6.4    سطح: 3    نقش: D
 تأیید کنید که کلیدهای رمزگذاری برای هر مستاجر منحصر به فرد هستند و از پشتیبانی کلید مدیریت‌شده توسط مشتری (CMK) برخوردارند و ایزولاسیون رمزنگاری بین مخزن‌های دادهٔ مستاجرها برقرار است.

---

### C5.7 مجوز عامل خودمختار

کنترل مجوزها برای عامل‌های هوش مصنوعی و سیستم‌های خودمختار از طریق توکن‌های قابلیت‌دار با دامنه محدود و مجوزدهی مداوم.

 #5.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که عوامل خودمختار توکن‌های قابلیت با دامنه محدود دریافت می‌کنند که به طور صریح اقدامات مجاز، منابع قابل دسترس، محدوده‌های زمانی و محدودیت‌های عملیاتی را فهرست می‌کنند.
 #5.7.2    سطح: 1    نقش: D/V
 تأیید کنید که قابلیت‌های با ریسک بالا (دسترسی به سیستم فایل، اجرای کد، تماس‌های API خارجی، معاملات مالی) به‌طور پیش‌فرض غیرفعال هستند و برای فعال‌سازی به مجوزهای صریح همراه با توجیه‌های تجاری نیاز دارند.
 #5.7.3    سطح: 2    نقش: D
 تایید کنید که توکن‌های قابلیت به نشست‌های کاربری پیوند داده می‌شوند، از حفاظت یکپارچگی رمزنگاری‌شده برخوردارند و اطمینان حاصل کنید که در سناریوهای آفلاین قابلیت نگهداری یا استفاده مجدد ندارند.
 #5.7.4    سطح: 2    نقش: V
 تصدیق کنید که اقدامات آغازشده توسط عامل از طریق موتور سیاست‌گذاری ABAC با ارزیابی کامل زمینه و ثبت‌های حسابرسی، تحت تأیید ثانویه قرار می‌گیرند.
 #5.7.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که شرایط خطای عامل و مدیریت استثناها شامل اطلاعات دامنه قابلیت باشند تا به تحلیل رویداد و تحقیقات جنایی دیجیتال کمک کنند.

---

### منابع

#### استانداردها و چارچوب‌ها

NIST SP 800-63-3: Digital Identity Guidelines
Zero Trust Architecture – NIST SP 800-207
OWASP Application Security Verification Standard (AISVS)
​
#### راهنماهای پیاده‌سازی

Identity and Access Management in the AI Era: 2025 Guide – IDSA
Attribute-Based Access Control with OPA – Permify
How We Designed Cedar to Be Intuitive, Fast, and Safe – AWS
​
#### امنیت مختص هوش مصنوعی

Row Level Security in Vector DBs for RAG – Bluetuple.ai
Tenant Isolation in Multi-Tenant Systems – WorkOS
Handling AI Agent Permissions – Stytch
OWASP Top 10 for Large Language Model Applications

## C6 امنیت زنجیره تامین برای مدل‌ها، چارچوب‌ها و داده‌ها

### هدف کنترل

حملات زنجیره تامین هوش مصنوعی از مدل‌ها، چارچوب‌ها یا مجموعه‌داده‌های طرف ثالث برای جاسازی درب‌های پشتی، سوگیری یا کد قابل بهره‌برداری استفاده می‌کنند. این کنترل‌ها، ردپای یکپارچه از ابتدا تا انتها، مدیریت آسیب‌پذیری و نظارت را برای حفاظت از کل چرخه عمر مدل فراهم می‌آورند.

---

### C6.1 بازبینی و منشأ مدل از پیش‌آموزش‌دیده

ارزیابی و احراز اصالت منشأهای مدل‌های طرف ثالث، مجوزها و رفتارهای پنهان آنها پیش از هرگونه تنظیم دقیق یا استقرار.

 #6.1.1    سطح: 1    نقش: D/V
 تأیید کنید که هر آرتیفکت مدلِ طرف‌سوم دارای یک سند منشأ امضا شده باشد که مخزن منبع و هش کامیت را مشخص کند.
 #6.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مدل‌ها قبل از وارد کردن، با استفاده از ابزارهای خودکار برای وجود لایه‌های مخرب یا محرک‌های تروجان اسکن می‌شوند.
 #6.1.3    سطح: 2    نقش: D
 تأیید کنید که transfer‑learning fine‑tunes از ارزیابی مهاجمانه عبور می‌کنند تا رفتارهای پنهان را تشخیص دهند.
 #6.1.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که مجوزهای مدل، برچسب‌های کنترل صادرات، و اظهارات منبع داده در ورودی ML‑BOM ثبت شده‌اند.
 #6.1.5    سطح: 3    نقش: D/V
 تأیید کنید که مدل‌های با ریسک بالا (وزنه‌های بارگذاری‌شده توسط عموم، سازندگان تأییدنشده) تا بازبینی انسانی و امضای نهایی در قرنطینه باقی بمانند.

---

### C6.2 اسکن چارچوب‌ها و کتابخانه‌ها

به طور مداوم چارچوب‌ها و کتابخانه‌های یادگیری ماشین را برای CVEs و کد مخرب اسکن کنید تا پشته زمان اجرا امن بماند.

 #6.2.1    سطح: 1    نقش: D/V
 تأیید کنید که خط لوله‌های CI اسکنرهای وابستگی را روی چارچوب‌های هوش مصنوعی و کتابخانه‌های حیاتی اجرا کنند.
 #6.2.2    سطح: 1    نقش: D/V
 تأیید کنید که آسیب‌پذیری‌های بحرانی (CVSS ≥ 7.0) مانع از ارتقاء تصاویر به محیط تولید می‌شوند.
 #6.2.3    سطح: 2    نقش: D
 تأیید کنید که تحلیل کد ایستا روی کتابخانه‌های یادگیری ماشین که فورک شده‌اند یا درون پروژه به عنوان وابستگی‌ها قرار داده شده‌اند، اجرا می‌شود.
 #6.2.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که پیشنهادهای به‌روزرسانی فریم‌ورک شامل ارزیابی تأثیر امنیتی است که به فیدهای CVE عمومی ارجاع می‌کند.
 #6.2.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که حسگرهای زمان اجرا به بارگذاری‌های نامنتظره کتابخانه‌های پویا که از SBOM امضاشده انحراف می‌کنند، هشدار دهند.

---

### C6.3 ثابت‌سازی وابستگی‌ها و تأیید

تمامی وابستگی‌ها را به هش‌های غیرقابل تغییر قفل کن و بیلدها را بازتولید کن تا اقلام ساخت یکسان و بدون دستکاری تضمین شوند.

 #6.3.1    سطح: 1    نقش: D/V
 بررسی کنید که تمامی مدیران بسته تثبیت نسخه را از طریق فایل‌های قفل اعمال می‌کنند.
 #6.3.2    سطح: 1    نقش: D/V
 تأیید کنید که در ارجاع‌های کانتینر از هضم‌های غیرقابل تغییر به جای برچسب‌های قابل تغییر استفاده می‌شود.
 #6.3.3    سطح: 2    نقش: D
 تأیید کنید که بررسی‌های reproducible-build هش‌ها را در طول اجراهای CI مقایسه می‌کنند تا خروجی‌های یکسانی تضمین شوند.
 #6.3.4    سطح: 2    نقش: V
 تأیید کنید که گواهی‌های ساخت به مدت 18 ماه برای ردیابی حسابرسی نگهداری می‌شوند.
 #6.3.5    سطح: 3    نقش: D
 تصدیق کنید که وابستگی‌های منقضی‌شده، PRهای خودکار برای به‌روزرسانی یا فورک نسخه‌های پین‌شده را تحریک می‌کنند.

---

### C6.4 اجرای منبع معتبر

دانلود آرتیفکت‌ها را فقط از منابعی که از نظر رمزنگاری تأیید شده و توسط سازمان تأیید شده‌اند مجاز کنید و همه چیز غیر از آن را بلاک کنید.

 #6.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که وزن‌های مدل، مجموعه داده‌ها و کانتینرها فقط از دامنه‌های تأییدشده یا رجیستری‌های داخلی دانلود می‌شوند.
 #6.4.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که امضاهای Sigstore/Cosign هویت ناشر را قبل از اینکه آثار نرم‌افزاری در کش محلی ذخیره شوند، اعتبارسنجی می‌کنند.
 #6.4.3    سطح: 2    نقش: D
 بررسی کنید که پروکسی‌های خروجی دانلودهای آرتیفکت بدون احراز هویت را مسدود می‌کنند تا سیاست منبع معتبر اعمال شود.
 #6.4.4    سطح: 2    نقش: V
 تأیید کنید که لیست‌های مجاز مخزن هر سه ماه یکبار بررسی می‌شوند و برای هر ورودی شواهد توجیه کسب‌وکار ارائه می‌شود.
 #6.4.5    سطح: 3    نقش: V
 تأیید کنید که نقض‌های سیاست منجر به قرنطینهٔ آثار و بازگردانی اجراهای وابسته به خط لوله می‌شود.

---

### C6.5 ارزیابی ریسک مجموعه داده‌های طرف سوم

مجموعه‌های دادهٔ خارجی را از نظر سم‌پاشی، سوگیری و تطابق قانونی ارزیابی کنید و آنها را در طول چرخه حیاتشان پایش کنید.

 #6.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مجموعه‌های داده خارجی تحت امتیازدهی ریسک آلودگی داده‌ها قرار می‌گیرند (مثلاً اثر انگشت داده‌ها، تشخیص داده‌های پرت).
 #6.5.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که معیارهای تبعیض (برابری جمعیتی، فرصت برابر) پیش از تأیید مجموعه داده محاسبه می‌شوند.
 #6.5.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که منشأ داده‌ها و شرایط مجوز برای مجموعه‌های داده در ورودی‌های ML‑BOM ثبت شده‌اند.
 #6.5.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که پایش دوره‌ای، انحراف داده یا خرابی داده را در مجموعه‌های داده میزبانی‌شده شناسایی می‌کند.
 #6.5.5    سطح: 3    نقش: D
 اطمینان حاصل کنید که محتوای غیرمجاز (حقوق کپی‌رایت، اطلاعات شناسایی شخصی) از طریق پاک‌سازی خودکار پیش از آموزش حذف شده است.

---

### C6.6 نظارت بر حملات زنجیره تأمین

تهدیدهای زنجیره تأمین را از طریق فیدهای CVE، تحلیل لاگ‌های حسابرسی، و شبیه‌سازی‌های تیم قرمز به‌سرعت شناسایی کنید.

 #6.6.1    سطح: 1    نقش: V
 اطمینان حاصل کنید که لاگ‌های حسابرسی CI/CD به تشخیص‌های SIEM هدایت می‌شوند تا بارگیری‌های نامعمول بسته‌ها یا مراحل ساخت دستکاری‌شده را شناسایی کنند.
 #6.6.2    سطح: 2    نقش: D
 تأیید کنید که راهنماهای پاسخ به حوادث امنیتی شامل رویه‌های بازگردانی برای مدل‌ها یا کتابخانه‌های آسیب‌دیده هستند.
 #6.6.3    سطح: 3    نقش: V
 تأیید کنید که برچسب‌های غنی‌سازی اطلاعات تهدید، شاخص‌های مخصوص یادگیری ماشین (مثلاً IoCs مربوط به مسموم‌سازی مدل) را در طبقه‌بندی و اولویت‌بندی هشدارها لحاظ می‌کنند.

---

### C6.7 ML‑BOM برای آرتیفکت‌های مدل

فهرست‌های SBOM دقیق مخصوص ML (ML‑BOMs) تولید و امضا کنید تا مصرف‌کنندگان پایین‌دستی بتوانند در زمان استقرار، یکپارچگی مؤلفه‌ها را تأیید کنند.

 #6.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر آرتیفکت مدل، ML‑BOM منتشر می‌کند که فهرستی از مجموعه‌داده‌ها، وزن‌ها، هایپرپارامترها و مجوزها را در بر می‌گیرد.
 #6.7.2    سطح: 1    نقش: D/V
 بررسی کنید که تولید ML‑BOM و امضای Cosign به‌طور خودکار در CI انجام می‌شوند و برای ادغام لازم‌اند.
 #6.7.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که بررسی‌های تکمیل ML‑BOM در صورت گم بودن هر یک از متاداده‌های مؤلفه (هاش، لایسنس) بیلد را با شکست مواجه می‌کنند.
 #6.7.4    سطح: 2    نقش: V
 تایید کنید که مصرف‌کنندگان پایین‌دست می‌توانند ML-BOMs را از طریق API کوئری کنند تا مدل‌های واردشده در زمان استقرار را اعتبارسنجی کنند.
 #6.7.5    سطح: 3    نقش: V
 تأیید کنید که ML‑BOMها تحت کنترل نسخه هستند و برای تشخیص تغییرات غیرمجاز، با تفاوت‌یابی مقایسه می‌شوند.

---

### منابع

ML Supply Chain Compromise – MITRE ATLAS
Supply‑chain Levels for Software Artifacts (SLSA)
CycloneDX – Machine Learning Bill of Materials
What is Data Poisoning? – SentinelOne
Transfer Learning Attack – OWASP ML Security Top 10
AI Data Security Best Practices – CISA
Secure CI/CD Supply Chain – Sumo Logic
AI & Transparency: Protect ML Models – ReversingLabs
SBOM Overview – CISA
Training Data Poisoning Guide – Lakera.ai
Dependency Pinning for Reproducible Python – Medium

## رفتار مدل C7، کنترل خروجی و تضمین ایمنی

### هدف کنترل

خروجی‌های مدل باید ساختارمند، قابل اعتماد، ایمن، قابل توضیح و به طور مداوم در محیط تولید پایش شوند. این کار باعث کاهش توهم‌ها، نشت‌های حریم خصوصی، محتوای مضر و رفتارهای خارج از کنترل می‌شود، در عین حال اعتماد کاربران و رعایت الزامات قانونی را نیز افزایش می‌دهد.

---

### C7.1 اجرای فرمت خروجی

اسکیماهای سختگیرانه، دیکودینگ محدود، و اعتبارسنجی پایین‌دستی محتواهای نامعتبر یا مخرب را پیش از گسترش آن‌ها متوقف می‌کنند.

 #7.1.1    سطح: 1    نقش: D/V
 تأیید کنید که الگوهای پاسخ (به‌عنوان مثال JSON Schema) در پرامپت سیستمی ارائه می‌شوند و هر خروجی به‌طور خودکار اعتبارسنجی می‌شود؛ خروجی‌های ناسازگار تعمیر یا رد می‌شوند.
 #7.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که رمزگشایی محدود (توکن‌های توقف، regex، max-tokens) فعال است تا از سرریز یا کانال‌های جانبی تزریق پرامپت جلوگیری شود.
 #7.1.3    سطح: 2    نقش: D/V
 تأیید کنید که اجزای پایین‌دست خروجی‌ها را نامعتبر تلقی کرده و آنها را در برابر اسکیماها اعتبارسنجی نمایند یا از دیسریالایزرهای امن برای جلوگیری از تزریق استفاده کنند.
 #7.1.4    سطح: 3    نقش: V
 تأیید کنید که رویدادهای خروجی نامناسب ثبت می‌شوند، دارای محدودیت نرخ هستند و به سامانهٔ مانیتورینگ نمایش داده می‌شوند.

---

### C7.2 تشخیص و کاهش توهم

برآورد عدم قطعیت و استراتژی‌های جایگزین از پاسخ‌های ساختگی جلوگیری می‌کنند.

 #7.2.1    سطح: 1    نقش: D/V
 بررسی کنید که احتمال‌های لگاریتمی در سطح توکن، هم‌سازگاری مجموعه، یا تشخیص‌دهنده‌های توهم‌زایی با تنظیم دقیق، برای هر پاسخ نمره اعتماد اختصاص دهند.
 #7.2.2    سطح: 1    نقش: D/V
 تأیید کنید که پاسخ‌هایی که زیر آستانه اعتماد قابل پیکربندی قرار دارند، جریان‌های جایگزین (مثلاً تولید تقویت‌شده با بازیابی، مدل ثانویه، یا بازبینی انسانی) را فعال می‌کنند۔
 #7.2.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که موارد توهم با متادادهٔ علت ریشه برچسب‌گذاری شده‌اند و به زنجیره‌های پردازشی پس از حادثه و فاین‌تیونینگ تغذیه می‌شوند.
 #7.2.4    سطح: 3    نقش: D/V
 تأیید کنید که آستانه‌ها و تشخیصگرها پس از به‌روزرسانی‌های عمده مدل یا پایگاه دانش دوباره کالیبره می‌شوند.
 #7.2.5    سطح: 3    نقش: V
 بررسی کنید که نمایش‌های داشبورد نرخ‌های توهم را رصد می‌کنند.

---

### C7.3 فیلتر ایمنی خروجی و حریم خصوصی

فیلترهای سیاستی و پوشش تیم قرمز از کاربران و داده‌های محرمانه محافظت می‌کنند.

 #7.3.1    سطح: 1    نقش: D/V
 تأیید کنید که طبقه‌بندهای قبل از تولید و پس از تولید، محتوای نفرت‌انگیز، آزار و اذیت، خودآزاری، مطالب افراط‌گرایانه و محتوای جنسی صریح را مطابق با سیاست مسدود می‌کنند.
 #7.3.2    سطح: 1    نقش: D/V
 تأیید کنید که تشخیص PII/PCI و پنهان‌سازی خودکار در هر پاسخ اجرا می‌شود؛ هر نقض منجر به بروز رویداد حریم خصوصی می‌شود.
 #7.3.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که برچسب‌های محرمانگی (مثلاً رازهای بازرگانی) در قالب‌های مختلف گسترش می‌یابند تا از نشت در متن، تصاویر یا کد جلوگیری شود.
 #7.3.4    سطح: 3    نقش: D/V
 تأیید کنید که تلاش‌های عبور از فیلتر یا طبقه‌بندی‌های پرخطر نیاز به تأیید ثانویه یا احراز هویت مجدد کاربر دارند.
 #7.3.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که آستانه‌های فیلترینگ با حوزه‌های قضایی و زمینه‌ی سنی/نقش کاربر مطابقت دارند.

---

### C7.4 محدودیت خروجی و اقدام

محدودیت‌های نرخ-گذاری و دروازه‌های تأیید از سوءاستفاده و استقلال بیش از حد جلوگیری می‌کنند.

 #7.4.1    سطح: 1    نقش: D
 بررسی کنید که برای هر کاربر و هر کلید API، سهمیه‌هایی وجود دارند که درخواست‌ها، توکن‌ها و هزینه را محدود می‌کنند، با تاخیر افزایشی نمایی در خطاهای 429.
 #7.4.2    سطح: 1    نقش: D/V
 تأیید کنید که اقدامات دارای امتیاز ویژه (نوشتن فایل‌ها، اجرای کد، فراخوانی‌های شبکه) نیازمند تأیید مبتنی بر سیاست یا حضور انسان در حلقه تصمیم‌گیری است.
 #7.4.3    سطح: 2    نقش: D/V
 تأیید کنید که بررسی‌های سازگاری بین‌مدالی اطمینان می‌دهند تصاویر، کد و متنی که برای همان درخواست تولید شده‌اند، نمی‌توانند برای پنهان‌کردن محتوای مخرب استفاده شوند.
 #7.4.4    سطح: 2    نقش: D
 بررسی کنید که عمق واگذاری عامل، محدودیت‌های بازگشتی و فهرست ابزارهای مجاز به‌طور صریح پیکربندی شده‌اند.
 #7.4.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که نقض محدودیت‌ها منجر به ایجاد رویدادهای امنیتی ساختارمند برای ورود به SIEM می‌شود.

---

### C7.5 توضیح‌پذیری خروجی

سیگنال‌های شفاف اعتماد کاربران را افزایش می‌دهند و عیب‌یابی داخلی را بهبود می‌بخشند.

 #7.5.1    سطح: 2    نقش: D/V
 تایید کنید که نمره‌های اعتماد نمایش داده‌شده به کاربر یا خلاصه‌های استدلال کوتاه، در صورت مناسب بودن ارزیابی ریسک، به کاربر نشان داده شوند.
 #7.5.2    سطح: 2    نقش: D/V
 تأیید کنید که توضیحات تولیدشده از افشای دستورات سیستمی حساس یا داده‌های دارای حق مالکیت جلوگیری می‌کنند.
 #7.5.3    سطح: 3    نقش: D
 بررسی کنید که سیستم، احتمالات لگاریتمی سطح توکن یا نقشه‌های توجه را ضبط می‌کند و آنها را برای بازرسی مجاز ذخیره می‌کند.
 #7.5.4    سطح: 3    نقش: V
 تأیید کنید که اقلام توضیح‌پذیری در کنار انتشار مدل‌ها دارای کنترل نسخه باشند تا قابلیت بازرسی فراهم شود.

---

### C7.6 یکپارچه‌سازی مانیتورینگ

مشاهده‌پذیری در زمان واقعی حلقه بین توسعه و تولید را می‌بندد.

 #7.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که معیارها (نقض‌های طرح‌واره، نرخ توهم، سمیت، افشای داده‌های شخصی قابل شناسایی (PII)، تاخیر، هزینه) به پلتفرم نظارت مرکزی منتقل می‌شوند.
 #7.6.2    سطح: 1    نقش: V
 تأیید کنید که آستانه‌های هشدار برای هر معیار ایمنی تعیین شده‌اند، به همراه مسیرهای ارجاع در حالت آماده به کار.
 #7.6.3    سطح: 2    نقش: V
 بررسی کنید که داشبوردها با ناهنجاری‌های خروجی همبستگی دارند با مدل/نسخه، پرچم ویژگی و تغییرات داده‌های بالادستی.
 #7.6.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که داده‌های پایش به بازآموزی، تنظیم دقیق یا به‌روزرسانی قواعد در یک گردش کار MLOps مستند منجر می‌شوند.
 #7.6.5    سطح: 3    نقش: V
 تأیید کنید که خطوط پایش تحت آزمایش نفوذ قرار گرفته و دارای کنترل دسترسی هستند تا از نشت لاگ‌های حساس جلوگیری شود.

---

### 7.7 حفاظت‌های رسانه‌های مولد

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی محتوای رسانه‌ای غیرقانونی، مضر یا غیرمجاز تولید نکنند با اعمال محدودیت‌های سیاستی، اعتبارسنجی خروجی و قابلیت ردیابی.

 #7.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که پرومپت‌های سیستمی و دستورالعمل‌های کاربری صریحاً منع تولید محتوای دی‌فیک غیرقانونی، مضر یا بدون رضایت را می‌کنند (مثلاً تصویر، ویدیو یا صدا).
 #7.7.2    سطح: 2    نقش: D/V
 بررسی کنید که درخواست‌ها برای تلاش‌هایی جهت تولید جعل هویت، دی‌فیک‌های جنسی صریح، یا محتوایی که افراد واقعی را بدون رضایت آنها به تصویر می‌کشد، فیلتر می‌شوند.
 #7.7.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که سیستم از هش ادراکی، تشخیص واترمارک یا اثر انگشت دیجیتال برای جلوگیری از بازتولید غیرمجاز محتوای دارای حق نشر استفاده می‌کند.
 #7.7.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تمام رسانه‌های تولیدشده دارای امضای رمزنگاری‌شده هستند، یا واترمارک شده‌اند، یا با فراداده‌های منبع مقاوم در برابر دستکاری جاسازی شده‌اند تا برای ردیابی در مراحل بعدی قابل استفاده باشند.
 #7.7.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که تلاش‌های عبور (مثلاً پنهان‌سازی پرامپت، زبان عامیانه، عبارات تهاجمی) شناسایی شده، ثبت می‌شوند و محدودیت نرخ برای آنها اعمال می‌شود؛ سوءاستفادهٔ مکرر به سامانه‌های نظارتی گزارش می‌شود.

### منابع

NIST AI Risk Management Framework
ISO/IEC 42001:2023 – AI Management System
OWASP Top-10 for Large Language Model Applications (2025)
Improper Output Handling – OWASP LLM05:2025
Practical Techniques to Constrain LLM Output
Dataiku – Structured Text Generation Guide
VL-Uncertainty: Detecting Hallucinations
HaDeMiF: Hallucination Detection & Mitigation
Building Confidence in LLM Outputs
Explainable AI & LLMs
LLM Red-Teaming Guide
Sensitive Information Disclosure in LLMs
LangChain – Chat Model Rate Limiting
OpenAI Rate-Limit & Exponential Back-off
Arize AI – LLM Observability Platform

## C8 حافظه، تعبیه‌ها و امنیت پایگاه دادهٔ برداری

### هدف کنترل

بردهای جاسازی و مخازن برد به‌عنوان «حافظهٔ زنده» سامانه‌های هوش مصنوعی مدرن عمل می‌کنند، به‌طور مداوم داده‌هایی را که کاربر ارائه می‌کند می‌پذیرند و آن‌ها را از طریق تولید تقویت‌شده با بازیابی (RAG) به زمینه‌های مدل بازمی‌گردانند. اگر این حافظه بدون کنترل بماند، ممکن است منجر به فاش‌شدن PII، نقض رضایت یا وارونه‌سازی برای بازسازی متن اصلی شود. هدف از این خانوادهٔ کنترل، سخت‌سازی خطوط لوله حافظه و پایگاه‌های دادهٔ برد است تا دسترسی به کمترین امتیاز باشد، بردهای جاسازی از نظر حفظ حریم خصوصی امن باشند، بردهای ذخیره‌شده منقضی شوند یا به‌دلیل درخواست قابل لغو باشند، و حافظهٔ هر کاربر هرگز با پرامپت‌ها یا پاسخ‌های کاربر دیگر آلوده نشود.

---

### C8.1 کنترل‌های دسترسی به حافظه و شاخص‌های RAG

اجرای کنترل‌های دسترسی دقیق برای هر مجموعه برداری.

 #8.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که قوانین کنترل دسترسی سطح سطر/فضای نام، عملیات درج، حذف و جستجو را برای هر مستاجر، مجموعه یا برچسب سند محدود می‌کنند.
 #8.1.2    سطح: 1    نقش: D/V
 تأیید کنید که کلیدهای API یا JWTها دارای ادعاهای با دامنه هستند (مثلاً شناسه‌های مجموعه و افعال اقدام) و هر 3 ماه یکبار حداقل گردش کلید انجام می‌شود.
 #8.1.3    سطح: 2    نقش: D/V
 تأیید کنید که تلاش‌های ارتقاء سطح دسترسی (مثلاً کوئری‌های تشابه بین فضاهای نام مختلف) شناسایی می‌شوند و در SIEM ثبت می‌شوند در عرض 5 دقیقه.
 #8.1.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که لاگ حسابرسی پایگاه داده برداری شامل شناسه-موضوع، عملیات، شناسه بردار/فضای نام، آستانه تشابه و تعداد نتایج باشد.
 #8.1.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که تصمیمات دسترسی برای وجود نقص‌های عبور هرگاه موتورهای به‌روزرسانی می‌شوند یا قواعد ایندکس-شاردینگ تغییر می‌کنند، آزمایش می‌شوند.

---

### C8.2 تعبیه، پاک‌سازی و اعتبارسنجی

قبل از بردار سازی، متن را از نظر وجود اطلاعات قابل شناسایی شخصی (PII) پیش غربال کنید، آنها را حذف یا با نام‌های مستعار جایگزین کنید، و در صورت تمایل، پس پردازش نگاشت‌های جاسازی شده را برای از بین بردن سیگنال‌های باقیمانده انجام دهید.

 #8.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که PII و داده‌های مشمول مقررات از طریق طبقه‌بندهای خودکار شناسایی می‌شوند و قبل از جاسازی، ماسک می‌شوند، توکن‌سازی می‌شوند یا حذف می‌شوند.
 #8.2.2    سطح: 1    نقش: D
 تأیید کنید که خطوط لوله جاسازی ورودی‌ها، ورودی‌هایی را که حاوی کد اجرایی یا مواردی با فرمت غیر UTF-8 هستند و می‌توانند ایندکس را آلوده کنند، رد یا قرنطینه می‌کنند.
 #8.2.3    سطح: 2    نقش: D/V
 تأیید کنید که پاک‌سازی با حریم خصوصی تفاضلی محلی یا متریکی به بردهای جاسازی جمله اعمال می‌شود که فاصلهٔ آن‌ها به هر توکن PII شناخته‌شده کمتر از آستانهٔ قابل پیکربندی باشد.
 #8.2.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که کارایی ایمن‌سازی (مثلاً نرخ بازیابی حذف PII و انحراف معنایی) حداقل به‌صورت نیمه‌سالانه در برابر مجموعه‌های دادهٔ بنچمارک ارزیابی می‌شود.
 #8.2.5    سطح: 3    نقش: D/V
 تأیید کنید که پیکربندی‌های پاک‌سازی دارای کنترل نسخه هستند و تغییرات تحت بازبینی همتا قرار می‌گیرند.

---

### C8.3 انقضای حافظه، ابطال و حذف

GDPR «حق فراموش‌شدن» و قوانین مشابه، حذف به‌موقع را الزامی می‌کنند؛ بنابراین انبارهای برداری باید از TTLها، حذف‌های دائمی، و tomb-stoning پشتیبانی کنند تا وکتورهای لغو‌شده قابل بازیابی یا دوباره فهرست‌بندی نشوند.

 #8.3.1    سطح: 1    نقش: D/V
 بررسی کنید که هر بردار و رکورد فراداده دارای TTL یا برچسب نگهداری صریحی باشد که توسط عملیات پاکسازی خودکار رعایت گردد.
 #8.3.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که درخواست‌های حذف به‌دست کاربر، بردارها، فراداده‌ها، نسخه‌های کش و نمایه‌های مشتق‌شده را در عرض ۳۰ روز پاک‌سازی می‌کنند.
 #8.3.3    سطح: 2    نقش: D
 تأیید کنید که حذف‌های منطقی با تخریب رمزنگاری‌شدهٔ بلوک‌های ذخیره‌سازی دنبال می‌شوند، در صورت پشتیبانی سخت‌افزار از این قابلیت، یا با از بین بردن کلید در Key Vault.
 #8.3.4    سطح: 3    نقش: D/V
 تأیید کنید که بردارهای منقضی‌شده از نتایج جست‌جوی نزدیک‌ترین همسایه حذف می‌شوند در کمتر از 500 میلی‌ثانیه پس از انقضا.

---

### C8.4 جلوگیری از وارونگی تعبیه و نشت

دفاع‌های اخیر—هم‌پوشانی نویز، شبکه‌های پروجکشن، اختلال نورون-حریم خصوصی، و رمزگذاری در سطح لایهٔ کاربرد—می‌توانند نرخ وارون‌سازی توکن‌ها را به کمتر از 5% کاهش دهند.

 #8.4.1    سطح: 1    نقش: V
 تأیید کنید که یک مدل تهدید رسمی وجود دارد که حملات وارونه‌سازی، استنتاج عضویت و استنتاج ویژگی را در بر می‌گیرد و به‌طور سالانه بازنگری می‌شود.
 #8.4.2    سطح: 2    نقش: D/V
 تأیید کنید که رمزگذاری در لایهٔ اپلیکیشن یا رمزگذاری قابل جست‌وجو بردارها را از خواندن مستقیم توسط مدیران زیرساخت یا کارکنان خدمات ابری محافظت می‌کند.
 #8.4.3    سطح: 3    نقش: V
 تأیید کنید که پارامترهای دفاعی (ε برای DP، نویز σ، رتبهٔ پروژکشن k) بین حفاظت از حریم خصوصی (≥ 99 %)، حفاظت از توکن و کارایی (افت دقت ≤ 3 %) تعادل برقرار می‌کنند.
 #8.4.4    سطح: 3    نقش: D/V
 تأیید کنید که معیارهای تاب‌آوری در برابر وارونگی بخشی از دروازه‌های انتشار برای به‌روزرسانی مدل‌ها هستند، با بودجه‌های رگرسیون تعریف‌شده.

---

### C8.5 اجرای دامنه برای حافظهٔ مختص کاربر

نشت بین مستاجران همچنان یکی از مهم‌ترین خطرات RAG است: کوئری‌های تشابه که به درستی فیلتر نشده‌اند می‌توانند اسناد خصوصی مشتری دیگری را آشکار کنند.

 #8.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر کوئری بازیابی پس از اعمال فیلتر با شناسه مستاجر/کاربر، قبل از ارسال آن به پرامپت LLM انجام می‌شود.
 #8.5.2    سطح: 1    نقش: D
 تأیید کنید که نام‌های مجموعه یا شناسه‌های دارای فضای نام برای هر کاربر یا مستاجر با نمک‌گذاری مجزا انجام می‌شود تا بردارها در دامنه‌های مختلف با هم تداخل نداشته باشند.
 #8.5.3    سطح: 2    نقش: D/V
 تأیید کنید که نتایج تشابه بالاتر از آستانه فاصله قابل تنظیم اما خارج از دامنهٔ فراخواننده از بین می‌روند و هشدارهای امنیتی را فعال می‌کنند.
 #8.5.4    سطح: 2    نقش: V
 تأیید کنید که آزمایش‌های فشار چند مستاجره، درخواست‌های خصمانه را شبیه‌سازی می‌کنند که سعی در بازیابی اسناد خارج از دامنه دارند و نشان می‌دهند که هیچ نشت داده‌ای وجود ندارد.
 #8.5.5    سطح: 3    نقش: D/V
 تأیید کنید که کلیدهای رمزگذاری برای هر مستأجر تفکیک شده باشند تا ایزولاسیون رمزنگاری را حتی در صورت به اشتراک‌گذاری فضای ذخیره‌سازی فیزیکی تضمین کند.

---

### C8.6 امنیت سیستم حافظه پیشرفته

کنترل‌های امنیتی برای معماری‌های حافظه پیشرفته که شامل حافظه اپیزودیکی، حافظه معنایی و حافظه کاری می‌شود و دارای الزامات مخصوص ایزولاسیون و اعتبارسنجی است.

 #8.6.1    سطح: 1    نقش: D/V
 بررسی کنید که انواع مختلف حافظه (حافظه رویدادی، حافظه معنایی، حافظه کاری) دارای زمینه‌های امنیتی جداگانه با کنترل‌های دسترسی مبتنی بر نقش، کلیدهای رمزگذاری جداگانه، و الگوهای دسترسی مستند برای هر نوع حافظه هستند.
 #8.6.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فرایندهای تثبیت حافظه شامل اعتبارسنجی امنیتی هستند تا از تزریق خاطرات مخرب از طریق پاک‌سازی محتوا، تأیید منبع و بررسی یکپارچگی قبل از ذخیره‌سازی جلوگیری شود.
 #8.6.3    سطح: 2    نقش: D/V
 تأیید کنید که کوئری‌های بازیابی حافظه اعتبارسنجی و پاک‌سازی می‌شوند تا از استخراج اطلاعات غیرمجاز از طریق تحلیل الگوی کوئری، اعمال کنترل دسترسی و فیلتر نتایج جلوگیری گردد.
 #8.6.4    سطح: 3    نقش: D/V
 تأیید کنید که مکانیزم‌های فراموش‌سازی حافظه، اطلاعات حساس را به‌طور امن حذف می‌کنند و با تضمین‌های پاک‌سازی رمزنگاری‌شده از طریق حذف کلید، بازنویسی چندباره، یا حذف امن مبتنی بر سخت‌افزار با گواهی‌های تأیید.
 #8.6.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که یکپارچگی سیستم حافظه به صورت مداوم پایش می‌شود تا هر گونه تغییر غیرمجاز یا خرابی را تشخیص دهد، از طریق چک‌سام‌ها، لاگ‌های بازرسی و هشدارهای خودکار زمانی که محتوای حافظه خارج از عملیات عادی تغییر می‌کند.

---

### منابع

Vector database security: Pinecone – IronCore Labs
Securing the Backbone of AI: Safeguarding Vector Databases and Embeddings – Privacera
Enhancing Data Security with RBAC of Qdrant Vector Database – AI Advances
Mitigating Privacy Risks in LLM Embeddings from Embedding Inversion – arXiv
DPPN: Detecting and Perturbing Privacy-Sensitive Neurons – OpenReview
Art. 17 GDPR – Right to Erasure
Sensitive Data in Text Embeddings Is Recoverable – Tonic.ai
PII Identification and Removal – NVIDIA NeMo Docs
De-identifying Sensitive Data – Google Cloud DLP
Remove PII from Conversations Using Sensitive Information Filters – AWS Bedrock Guardrails
Think Your RAG Is Secure? Think Again – Medium
Design a Secure Multitenant RAG Inferencing Solution – Microsoft Learn
Best Practices for Multi-Tenancy RAG with Milvus – Milvus Blog

## 9 هماهنگی خودمختار و امنیت اقدام عاملیت‌گرا

### هدف کنترل

اطمینان حاصل کنید که سامانه‌های هوش مصنوعی خودمختار یا چندعامله تنها اقداماتی را اجرا می‌کنند که صریحاً مدنظر، احراز هویت‌شده، قابل بازرسی و در محدوده‌های هزینه و ریسک محدود هستند. این از تهدیداتی مانند نفوذ به سامانه‌های خودمختار، سوءاستفاده از ابزار، تشخیص حلقهٔ عامل، ربایش ارتباطات، جعل هویت، دستکاری کلونی و دستکاری نیت محافظت می‌کند.

---

### 9.1 عامل برنامه‌ریزی-وظیفه‌ای و بودجه‌های بازگشتی

طرح‌های بازگشتی را محدود کن و برای اقدامات دارای امتیاز، نقاط کنترل انسانی را الزامی کن.

 #9.1.1    سطح: 1    نقش: D/V
 تأیید کنید که حداکثر عمق بازگشتی، پهنای جستجو، زمان دیواری، توکن‌ها و هزینه مالی به ازای اجرای هر عامل به‌طور متمرکز پیکربندی و نسخه‌گذاری شده‌اند.
 #9.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که اقدامات با امتیاز ویژه یا غیرقابل برگشت (مثلاً کامیت‌های کد، انتقال‌های مالی) قبل از اجرا به تأیید صریح انسانی از طریق کانال قابل حسابرسی نیاز دارند.
 #9.1.3    سطح: 2    نقش: D
 بررسی کنید که مانیتورهای منابع در زمان واقعی هنگام عبور از هر آستانه بودجه، قطع‌کنندهٔ مدار را فعال می‌کنند و گسترش بیشتر وظایف را متوقف می‌کنند.
 #9.1.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که رویدادهای قطع‌کننده مدار با شناسه عامل، شرط فعال‌کننده، و وضعیت طرح ضبط‌شده برای بازبینی قضایی ثبت می‌شوند.
 #9.1.5    سطح: 3    نقش: V
 بررسی کنید که آزمایش‌های امنیتی، سناریوهای به پایان رسیدن بودجه و طرح‌های خارج از کنترل را پوشش می‌دهند و توقف ایمن بدون از دست دادن داده‌ها را تأیید می‌کنند.
 #9.1.6    سطح: 3    نقش: D
 تأیید کنید که سیاست‌های بودجه به‌صورت سیاست-به-عنوان-کد بیان می‌شوند و در CI/CD اجرا می‌شوند تا از انحراف پیکربندی جلوگیری کند.

---

### 9.2 ایزوله‌سازی پلاگین‌های ابزار

تعاملات با ابزارها را ایزوله کنید تا از دسترسی غیرمجاز به سیستم یا اجرای کد جلوگیری شود.

 #9.2.1    سطح: 1    نقش: D/V
 بررسی کنید که هر ابزار یا افزونه درون یک محیط ایزوله با سطح OS، کانتینر یا WASM اجرا شود و دارای سیاست‌های کمینه دسترسی برای سیستم فایل، شبکه و فراخوانی‌های سیستمی باشد.
 #9.2.2    سطح: 1    نقش: D/V
 بررسی کنید که سهمیه‌های منابع ساندباکس (CPU، حافظه، دیسک، خروجی شبکه) و تایم‌اوت‌های اجرای آن‌ها اعمال شده و ثبت می‌شوند.
 #9.2.3    سطح: 2    نقش: D/V
 تأیید کنید که باینری‌های ابزار یا دسکریپتورهای آن‌ها به‌صورت دیجیتال امضا شده‌اند؛ امضاها قبل از بارگذاری اعتبارسنجی می‌شوند.
 #9.2.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که داده‌های تلِمتِری sandbox به SIEM ارسال می‌شوند؛ ناهنجاری‌ها (برای مثال، تلاش‌های برقراری اتصال‌های خروجی) هشدارها را فعال می‌کنند.
 #9.2.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که پلاگین‌های با ریسک بالا پیش از استقرار در محیط تولید تحت بازبینی امنیتی و آزمایش نفوذ قرار می‌گیرند.
 #9.2.6    سطح: 3    نقش: D/V
 تأیید کنید که تلاش‌های فرار از سندباکس به‌طور خودکار مسدود می‌شوند و افزونه متخلف تا زمان بررسی در قرنطینه نگهداری می‌شود.

---

### 9.3 حلقه خودمختار و محدودسازی هزینه

شناسایی و متوقف کردن بازگشت عامل-به-عامل کنترل‌نشده و انفجارهای هزینه.

 #9.3.1    سطح: 1    نقش: D/V
 تأیید کنید که تماس‌های بین عامل‌ها دارای حد پرش (hop-limit) یا TTL باشند که توسط زمان اجرا کاهش یافته و این محدودیت اعمال شود.
 #9.3.2    سطح: 2    نقش: D
 تأیید کنید که عاملان یک شناسه گراف فراخوانی منحصر به فرد حفظ می‌کنند تا خودفراخوانی یا الگوهای چرخه‌ای را تشخیص دهند.
 #9.3.3    سطح: 2    نقش: D/V
 تأیید کنید که شمارنده‌های تجمعی واحد محاسبه و مخارج برای هر زنجیرهٔ درخواست پیگیری می‌شوند؛ عبور از حد منجر به لغو زنجیره می‌شود.
 #9.3.4    سطح: 3    نقش: V
 تأیید کنید که تحلیل رسمی یا بررسی مدل نشان می‌دهد که در پروتکل‌های عامل، بازگشت بی‌پایان وجود ندارد.
 #9.3.5    سطح: 3    نقش: D
 تأیید کنید که رویدادهای توقف حلقه هشدار ایجاد می‌کنند و به معیارهای بهبود مستمر تغذیه می‌کنند.

---

### 9.4 حفاظت سطح پروتکل در برابر سوء استفاده

کانال‌های ارتباطی امن بین عامل‌ها و سامانه‌های خارجی به منظور جلوگیری از ربایش یا دستکاری.

 #9.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام پیام‌های بین عامل و ابزار و همچنین پیام‌های بین عامل‌ها احراز هویت شده‌اند (مثلاً TLS متقابل یا JWT) و رمزگذاری انتها-به-انتها دارند.
 #9.4.2    سطح: 1    نقش: D
 مطمئن شوید که اسکیماها به‌طور دقیق اعتبارسنجی می‌شوند؛ فیلدهای ناشناخته یا پیام‌های نامعتبر رد می‌شوند.
 #9.4.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که بررسی‌های یکپارچگی (MACها یا امضاهای دیجیتال) کل بار پیام از جمله پارامترهای ابزار را پوشش می‌دهند.
 #9.4.4    سطح: 2    نقش: D
 تایید کنید که حفاظت در برابر بازپخش (nonceها یا پنجره‌های زمانی) در لایه پروتکل اجرا می‌شود.
 #9.4.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که پیاده‌سازی‌های پروتکل تحت فازینگ و تحلیل ایستا قرار می‌گیرند تا نقص‌های تزریق یا دی‌سریالایزیشن تشخیص داده شوند.

---

### 9.5 هویت عامل و شواهد-دستکاری

اطمینان از اینکه اقدامات قابل نسبت‌دهی هستند و تغییرات قابل تشخیص‌اند.

 #9.5.1    سطح: 1    نقش: D/V
 بررسی کنید که هر نمونهٔ عامل دارای هویت رمزنگاری منحصر به فردی است (زوج کلید یا اعتبار مبتنی بر سخت‌افزار).
 #9.5.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تمامی اقدامات عامل امضا شده و با مهر زمانی ثبت‌شده‌اند؛ لاگ‌ها شامل امضا برای عدم‌انکارپذیری هستند.
 #9.5.3    سطح: 2    نقش: V
 تأیید کنید که لاگ‌های مقاوم در برابر دستکاری در یک رسانهٔ صرفاً افزایشی یا رسانه‌ای که فقط یک‌بار نوشته می‌شود ذخیره می‌شوند.
 #9.5.4    سطح: 3    نقش: D
 تأیید کنید که کلیدهای هویتی طبق یک برنامه مشخص و بر پایه شاخص‌های نفوذ، چرخش می‌کنند.
 #9.5.5    سطح: 3    نقش: D/V
 بررسی کنید که تلاش‌های جعل هویت یا تعارض کلید منجر به قرنطینه فوری عامل مربوطه می‌شود.

---

### 9.6 کاهش ریسک گلهٔ چند-عامل

کاهش خطرات رفتار جمعی از طریق ایزولاسیون و مدل‌سازی ایمنی رسمی.

 #9.6.1    سطح: 1    نقش: D/V
 تأیید کنید که عوامل فعال در دامنه‌های امنیتی مختلف در محفظه‌های زمان اجرای ایزوله‌شده یا در بخش‌های مجزای شبکه اجرا می‌شوند.
 #9.6.2    سطح: 3    نقش: V
 اطمینان حاصل کنید که رفتارهای گروهی مدل‌سازی شده‌اند و به‌طور رسمی برای خاصیت زنده بودن و ایمنی صحت‌سنجی می‌شوند قبل از استقرار.
 #9.6.3    سطح: 3    نقش: D
 اطمینان حاصل کنید که ناظران زمان اجرا، الگوهای ناامن پدیدار شونده (مثلاً نوسانات، بن‌بست‌ها) را تشخیص داده و اقدام اصلاحی را آغاز کنند.

---

### 9.7 احراز هویت کاربر و ابزار / مجوز دسترسی

برای هر اقدام فعال‌شده توسط عامل، کنترل‌های دسترسی قوی پیاده‌سازی کنید.

 #9.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که عامل‌ها به‌عنوان اصول سطح اول به سیستم‌های پایین‌دست احراز هویت می‌کنند و هرگز اعتبارنامه‌های کاربر نهایی را دوباره استفاده نمی‌کنند.
 #9.7.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که سیاست‌های مجوزدهی دقیق محدود می‌کنند که چه ابزارهایی را یک عامل می‌تواند فراخوانی کند و چه پارامترهایی را می‌تواند ارائه دهد.
 #9.7.3    سطح: 2    نقش: V
 تأیید کنید که بررسی‌های دسترسی در هر فراخوان دوباره ارزیابی می‌شوند (احراز دسترسی مداوم)، نه فقط در آغاز نشست.
 #9.7.4    سطح: 3    نقش: D
 تأیید کنید که امتیازات تفویض‌شده به‌طور خودکار منقضی می‌شوند و پس از پایان مهلت یا تغییر دامنه، به رضایت مجدد نیاز دارند.

---

### 9.8 امنیت ارتباط عامل-به-عامل

تمام پیام‌های بین عامل‌ها را رمزنگاری کنید و از لحاظ یکپارچگی محافظت کنید تا از شنود و دستکاری جلوگیری شود.

 #9.8.1    سطح: 1    نقش: D/V
 تأیید کنید که احراز هویت متقابل و رمزگذاری با حفظ محرمانگی برای هر جلسه (مثلاً TLS 1.3) برای کانال‌های عامل الزامی است.
 #9.8.2    سطح: 1    نقش: D
 قبل از پردازش، صحت یکپارچگی پیام و مبدأ آن را تأیید کنید؛ در صورت شکست، هشدارها صادر شده و پیام کنار گذاشته می‌شود.
 #9.8.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که متادیتای ارتباطی (نشانه‌های زمانی، شماره‌های توالی) ثبت می‌شود تا از بازسازی قضایی پشتیبانی گردد.
 #9.8.4    سطح: 3    نقش: V
 بررسی کنید که تأیید رسمی یا مدل‌چکینگ ثابت می‌کند که ماشین‌های حالت پروتکل نمی‌توانند به حالات ناامن رانده شوند.

---

### 9.9 احراز نیت و اجرای محدودیت‌ها

تأیید کنید که اقدامات عامل با هدف بیان‌شده کاربر و محدودیت‌های سیستم همسو هستند.

 #9.9.1    سطح: 1    نقش: D
 تأیید کنید که حل‌کننده‌های محدودیت قبل از اجرا، اقدامات پیشنهادی را در برابر قواعد ایمنی و سیاست‌های کدگذاری‌شده بررسی می‌کنند.
 #9.9.2    سطح: 2    نقش: D/V
 تأیید کنید که اقدامات با تأثیر بالا (مالی، تخریبی، حساس به حریم خصوصی) نیازمند تأیید صریح نیت کاربر آغازکننده هستند.
 #9.9.3    سطح: 2    نقش: V
 تایید کنید که بررسی‌های پس‌شرطی نشان می‌دهند که اقدامات انجام‌شده به آثار مدنظر دست یافته‌اند و بدون عوارض جانبی هستند؛ تفاوت‌ها منجر به بازگردانی می‌شوند.
 #9.9.4    سطح: 3    نقش: V
 تایید کنید که روش‌های رسمی (برای مثال مدل‌چکینگ و اثبات قضیه) یا آزمون‌های مبتنی بر ویژگی نشان می‌دهند که برنامه‌های عامل تمامی محدودیت‌های اعلام‌شده را برآورده می‌کنند.
 #9.9.5    سطح: 3    نقش: D
 بررسی کنید که وقایع ناهم‌ترازی-هدف یا نقض-محدودیت به چرخه‌های بهبود مستمر و به اشتراک‌گذاری اطلاعات تهدید تغذیه می‌کنند.

---

### 9.10 امنیت استراتژی استدلال عامل

انتخاب و اجرای ایمن رویکردهای مختلف استدلال، از جمله ReAct، زنجیره تفکر و درخت تفکر.

 #9.10.1    سطح: 1    نقش: D/V
 تأیید کنید که انتخاب استراتژی استدلال از معیارهای قطعی استفاده می‌کند (پیچیدگی ورودی، نوع وظیفه، زمینه امنیتی) و ورودی‌های یکسان در همان زمینه امنیتی منجر به انتخاب‌های استراتژی یکسان می‌شود.
 #9.10.2    سطح: 1    نقش: D/V
 تایید کنید که هر یک از استراتژی‌های استدلال (ReAct، زنجیره تفکر، درخت تفکرات) دارای اعتبارسنجی ورودی اختصاصی، پاک‌سازی خروجی و محدودیت‌های زمان اجرای متناسب با رویکرد شناختی آن است.
 #9.10.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که انتقال‌های استراتژی استدلال با زمینه کامل، از جمله ویژگی‌های ورودی، مقادیر معیارهای انتخاب و متاداده اجرای، برای بازسازی مسیر حسابرسی ثبت می‌شوند.
 #9.10.4    سطح: 2    نقش: D/V
 تأیید کنید که استدلال درخت تفکرات شامل مکانیسم‌های برش شاخه‌ها است که با تشخیص نقض سیاست‌ها، محدودیت‌های منابع یا مرزهای ایمنی، کاوش را خاتمه می‌دهد.
 #9.10.5    سطح: 2    نقش: D/V
 بررسی کنید که چرخه‌های ReAct (Reason-Act-Observe) در هر فاز شامل نقاط کنترل اعتبارسنجی هستند: تأیید گام‌های استدلال، مجوز اقدام و پاک‌سازی مشاهدات قبل از ادامه.
 #9.10.6    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که معیارهای عملکرد استراتژی استدلال (زمان اجرا، مصرف منابع، کیفیت خروجی) به‌طور خودکار نظارت می‌شوند و زمانی که این معیارها از آستانه‌های پیکربندی‌شده فراتر می‌روند، هشدارهای خودکار فعال می‌شوند.
 #9.10.7    سطح: 3    نقش: D/V
 تأیید کنید که روش‌های استدلال ترکیبی که چندین استراتژی را با هم ترکیب می‌کنند، اعتبارسنجی ورودی‌ها و محدودیت‌های خروجی تمامی استراتژی‌های تشکیل‌دهنده را حفظ می‌کنند، بدون عبور از هیچ کنترل امنیتی.
 #9.10.8    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تست امنیتی استراتژی استدلال شامل فوزینگ با ورودی‌های نامعتبر، پرومپ‌های خصمانه طراحی‌شده برای واداشتن به تغییر استراتژی، و آزمون شروط مرزی برای هر رویکرد شناختی است.

---

### 9.11 مدیریت وضعیت چرخه حیات عامل و امنیت

راه‌اندازی ایمن عامل، انتقال‌های حالت، و خاتمه با سوابق ممیزی رمزنگاری‌شده و رویه‌های بازیابی تعریف‌شده.

 #9.11.1    سطح: 1    نقش: D/V
 تأیید کنید که راه‌اندازی عامل شامل ایجاد هویت رمزنگاری‌شده با اعتبارنامه‌های مبتنی بر سخت‌افزار و لاگ‌های حسابرسی آغاز راه غیرقابل تغییر است و این لاگ‌ها حاوی شناسه عامل، زمان ثبت، هش پیکربندی و پارامترهای راه‌اندازی می‌باشند.
 #9.11.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که انتقال‌های وضعیت عامل از نظر رمزنگاری امضا می‌شوند، دارای تاریخ‌زمانی هستند، و با زمینه کامل ثبت می‌شوند که شامل رویدادهای محرک، هش وضعیت قبلی، هش وضعیت جدید و ارزیابی‌های امنیتی انجام‌شده‌اند.
 #9.11.3    سطح: 2    نقش: D/V
 تأیید کنید که رویه‌های خاموش‌سازی عامل شامل پاک‌سازی ایمن حافظه با استفاده از حذف رمزنگاری‌شده یا بازنویسی چندباره، ابطال اعتبارنامه با اطلاع‌رسانی به مرجع صدور گواهی، و تولید گواهی‌های خاتمه با قابلیت تشخیص دستکاری است.
 #9.11.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مکانیسم‌های بازیابی عامل صحت یکپارچگی وضعیت را با استفاده از هش‌های رمزنگاری‌شده (حداقل SHA-256) تأیید می‌کنند و در صورت تشخیص خرابی، به وضعیت‌های شناخته‌شدهٔ صحیح بازگردند، با هشدارهای خودکار و نیاز به تأیید دستی.
 #9.11.5    سطح: 3    نقش: D/V
 تأیید کنید که مکانیزم‌های پایداری عامل داده‌های حساس وضعیت را با کلیدهای AES-256 مخصوص هر عامل رمزگذاری می‌کنند و گردش کلید ایمن را در بازه‌های زمانی قابل پیکربندی (حداکثر 90 روز) با استقرار بدون وقفه پیاده‌سازی می‌کنند.

---

### 9.12 چارچوب امنیتی یکپارچه‌سازی ابزار

کنترل‌های امنیتی برای بارگذاری پویا ابزارها، اجرای آنها و اعتبارسنجی نتایج با فرایندهای ارزیابی ریسک و تأیید از پیش تعیین‌شده.

 #9.12.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که توصیف‌های ابزار دارای متاداده امنیتی هستند که امتیازات لازم (خواندن/نوشتن/اجرای)، سطوح ریسک (کم/متوسط/زیاد)، محدودیت‌های منابع (CPU، حافظه، شبکه) و الزامات اعتبارسنجی را که در منیفست‌های ابزار مستند شده‌اند، مشخص می‌کند.
 #9.12.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که نتایج اجرای ابزار با قالب‌های مورد انتظار (JSON Schema, XML Schema) و سیاست‌های امنیتی (پاک‌سازی خروجی، طبقه‌بندی داده) اعتبارسنجی می‌شوند، پیش از ادغام با محدودیت‌های زمانی و رویه‌های مدیریت خطا.
 #9.12.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که لاگ‌های تعامل ابزار دارای زمینه امنیتی دقیق هستند، از جمله استفاده از امتیازات، الگوهای دسترسی به داده، زمان اجرا، مصرف منابع و کدهای بازگشتی، و با ثبت ساختاریافته برای ادغام با SIEM.
 #9.12.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های بارگذاری پویا برای ابزارها امضای دیجیتال را با استفاده از زیرساخت کلید عمومی (PKI) اعتبارسنجی می‌کنند و پروتکل‌های بارگذاری امن را با ایزوله‌سازی sandbox و تأیید مجوزها قبل از اجرا پیاده‌سازی می‌کنند.
 #9.12.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که ارزیابی‌های امنیتی ابزار برای نسخه‌های جدید به‌طور خودکار فعال می‌شوند، با دروازه‌های تصویب اجباری از جمله تحلیل ایستا، آزمایش پویا و بازبینی تیم امنیتی، همراه با معیارهای تصویب مستند شده و الزامات SLA.

---

#### منابع

MITRE ATLAS tactics ML09
Circuit-breaker research for AI agents — Zou et al., 2024
Trend Micro analysis of sandbox escapes in AI agents — Park, 2025
Auth0 guidance on human-in-the-loop authorization for agents — Martinez, 2025
Medium deep-dive on MCP & A2A protocol hijacking — ForAISec, 2025
Rapid7 fundamentals on spoofing attack prevention — 2024
Imperial College verification of swarm systems — Lomuscio et al.
NIST AI Risk Management Framework 1.0, 2023
WIRED security briefing on encryption best practices, 2024
OWASP Top 10 for LLM Applications, 2025
Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS
[How Is LLM Reasoning Distracted by Irrelevant Context?
An Analysis Using a Controlled Benchmark](https://www.arxiv.org/pdf/2505.18761)
Large Language Model Sentinel: LLM Agent for Adversarial Purification
Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents

## 10 مقاومت در برابر حملات مخرب و حفاظت از حریم خصوصی

### هدف کنترل

اطمینان حاصل کنید که مدل‌های هوش مصنوعی در مواجهه با حمله‌های فرار از تشخیص، استنتاج، استخراج یا آلوده‌سازی داده، همچنان قابل اعتماد باشند، حریم خصوصی را حفظ کنند و در برابر سوءاستفاده مقاوم بمانند.

---

### 10.1 همسویی مدل و ایمنی

از خروجی‌های مضر یا خروجی‌های نقض‌کننده سیاست جلوگیری کنید.

 #10.1.1    سطح: 1    نقش: D/V
 تأیید کنید که مجموعه‌ای از آزمون‌های هم‌راستایی (پرومپت‌های تیم قرمز، آزمایش‌های جیلبریک، محتوای ممنوع) دارای کنترل نسخه است و در هر انتشار مدل اجرا می‌شود.
 #10.1.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که ریل‌های حفاظتی برای امتناع و تکمیل ایمن اعمال می‌شوند.
 #10.1.3    سطح: 2    نقش: D/V
 تأیید کنید که یک ارزیاب خودکار نرخ محتوای مضر را اندازه‌گیری کند و افت‌های عملکردی را که فراتر از آستانه‌ای مشخص هستند، علامت‌گذاری کند.
 #10.1.4    سطح: 2    نقش: D
 تایید کنید که آموزش مقابله با جیل‌بریک مستند و قابل بازتولید است.
 #10.1.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که اثبات‌های رسمی انطباق با سیاست یا پایش گواهی‌شده دامنه‌های حیاتی را پوشش می‌دهند.

---

### 10.2 سخت‌سازی-نمونه‌های حمله‌ای

افزایش مقاومت در برابر ورودی‌های دستکاری‌شده. آموزش مقاوم در برابر حملات adversarial و امتیازدهی مبتنی بر بنچمارک، بهترین شیوه‌های کنونی هستند.

 #10.2.1    سطح: 1    نقش: D
 بررسی کنید که آیا مخازن پروژه شامل پیکربندی‌های آموزش خصمانه با بذرهای تکرارپذیر هستند.
 #10.2.2    سطح: 2    نقش: D/V
 تأیید کنید که تشخیص نمونه‌های حمله‌ای در خط لوله‌های تولید، هشدارهای انسدادی ایجاد می‌کند.
 #10.2.4    سطح: 3    نقش: V
 بررسی کنید که اثبات‌های مقاومت گواهی‌شده یا گواهی‌های محدودۀ بازه‌ای حداقل کلاس‌های بحرانیِ برتر را پوشش می‌دهند.
 #10.2.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که تست‌های رگرسیون از حملات تطبیقی استفاده می‌کنند تا هیچ کاهش قابل اندازه‌گیری در مقاومت تأیید شود.

---

### 10.3 کاهش عضویت-استنتاج

توانایی تشخیص اینکه آیا یک رکورد در داده‌های آموزشی وجود داشته است را محدود کنید. خصوصی‌سازی تفاضلی و ماسک‌گذاری نمره اعتماد همچنان مؤثرترین دفاع‌های شناخته‌شده هستند.

 #10.3.1    سطح: 1    نقش: D
 بررسی کنید که تنظیم آنتروپی برای هر کوئری یا مقیاس‌گذاری با دما، پیش‌بینی‌های بیش‌ازحد مطمئن را کاهش می‌دهد.
 #10.3.2    سطح: 2    نقش: D
 تأیید کنید که فرایند آموزش از بهینه‌سازی با حریم خصوصی تفاضلی با محدودیت ε برای داده‌های حساس استفاده می‌کند.
 #10.3.3    سطح: 2    نقش: V
 تأیید کنید که شبیه‌سازی‌های حمله (مدل سایه‌ای یا جعبه سیاه) AUC حمله را بر روی داده‌های نگهداری‌شده ≤ 0.60 نشان می‌دهند.

---

### 10.4 مقاومت-در برابر معکوس‌سازی مدل

جلوگیری از بازسازی ویژگی‌های خصوصی. بررسی‌های اخیر بر قطع خروجی و ضمانت‌های حریم خصوصی تفاضلی به‌عنوان دفاع‌های عملی تأکید می‌کنند.

 #10.4.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که ویژگی‌های حساس هرگز به طور مستقیم خروجی داده نشوند؛ در صورت نیاز، از باکت‌ها یا تبدیلات یک‌طرفه استفاده کنید.
 #10.4.2    سطح: 1    نقش: D/V
 بررسی کنید که محدودیت‌های نرخ کوئری، کوئری‌های تطبیقی مکرر را از همان کاربر معتبر کند.
 #10.4.3    سطح: 2    نقش: D
 تأیید کنید که مدل با نویز حفظ حریم خصوصی آموزش دیده است.

---

### 10.5 مدل-استخراج دفاع

تشخیص و جلوگیری از کپی‌برداری غیرمجاز. واترمارک‌گذاری و تحلیل الگوهای پرس‌وجو توصیه می‌شود.

 #10.5.1    سطح: 1    نقش: D
 تأیید کنید که درگاه‌های استنتاج محدودیت‌های نرخ جهانی و محدودیت‌های نرخ برای هر کلید API را اعمال می‌کنند که با آستانهٔ حافظه‌پذیری مدل تنظیم شده‌اند.
 #10.5.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که آمارهای query-entropy و input-plurality یک آشکارساز استخراج خودکار را تغذیه می‌کنند.
 #10.5.3    سطح: 2    نقش: V
 تصدیق کنید که واترمارک‌های شکننده یا احتمالی می‌توانند با p < 0.01 در ≤ 1 000 کوئری در برابر کلون مشکوک ثابت شوند.
 #10.5.4    سطح: 3    نقش: D
 اطمینان حاصل کنید که کلیدهای واترمارک و مجموعه‌های محرک در یک ماژول امنیتی سخت‌افزاری نگهداری می‌شوند و هر ساله چرخانده می‌شوند.
 #10.5.5    سطح: 3    نقش: V
 بررسی کنید که رویدادهای هشدار استخراج شامل کوئری‌های مخرب هستند و با کتاب‌های راهنمای پاسخ به حوادث یکپارچه شده‌اند.

---

### 10.6 تشخیص داده‌های مسموم در زمان استنتاج

ورودی‌های دارای در پشتی یا آلوده را شناسایی و خنثی کنید.

 #10.6.1    سطح: 1    نقش: D
 تأیید کنید که ورودی‌ها قبل از استنتاج مدل از طریق یک تشخیص‌دهندهٔ ناهنجاری عبور می‌کنند (مثلاً STRIP، ارزیابی سازگاری).
 #10.6.2    سطح: 1    نقش: V
 تایید کنید که آستانه‌های تشخیصگر روی مجموعه‌های اعتبارسنجی سالم و آلوده تنظیم شده‌اند تا نرخ مثبت‌های کاذب را به کمتر از 5% برسانند.
 #10.6.3    سطح: 2    نقش: D
 تأیید کنید که ورودی‌های مسموم علامت‌گذاری‌شده باعث فعال‌شدن مسدودسازی نرم و گردش‌های کار بازبینی انسانی شوند.
 #10.6.4    سطح: 2    نقش: V
 تأیید کنید که تشخیص‌دهنده‌ها با حملات درب پشتی سازگار و بدون محرک تحت آزمایش فشار قرار می‌گیرند.
 #10.6.5    سطح: 3    نقش: D
 اطمینان حاصل کنید که معیارهای اثربخشی تشخیص ثبت می‌شوند و به طور دوره‌ای با اطلاعات تهدیدی تازه دوباره ارزیابی می‌شوند.

---

### 10.7 تطبیق سیاست امنیتی پویا

به‌روزرسانی‌های سیاست امنیتی در زمان واقعی بر اساس اطلاعات تهدید و تحلیل رفتاری.

 #10.7.1    سطح: 1    نقش: D/V
 تأیید کنید که سیاست‌های امنیتی می‌توانند به‌طور پویا بدون نیاز به راه‌اندازی مجدد عامل به‌روزرسانی شوند، در عین حفظ یکپارچگی نسخه‌های سیاست.
 #10.7.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که به‌روزرسانی‌های سیاست با امضای دیجیتال از سوی کارکنان امنیتی مجاز امضا می‌شوند و پیش از اجرا اعتبارسنجی می‌شوند.
 #10.7.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تغییرات پویا در سیاست‌ها با سوابق حسابرسی کامل ثبت می‌شوند، از جمله توجیه، زنجیره‌های تصویب، و رویه‌های بازگردانی.
 #10.7.4    سطح: 3    نقش: D/V
 تأیید کنید که مکانیزم‌های امنیتی تطبیقی حساسیت تشخیص تهدید را بر اساس زمینه ریسک و الگوهای رفتاری تنظیم می‌کنند.
 #10.7.5    سطح: 3    نقش: D/V
 تأیید کنید که تصمیم‌های تطبیق سیاست قابل توضیح هستند و برای بازبینی تیم امنیت، مسیرهای شواهدی را ارائه دهید.

---

### 10.8 تحلیل امنیتی مبتنی بر بازتاب

اعتبارسنجی امنیتی از طریق خودبازنگری عامل و تحلیل فراشناختی.

 #10.8.1    سطح: 1    نقش: D/V
 تأیید کنید که مکانیزم‌های بازتاب عامل شامل خودارزیابی امنیت‌محور تصمیم‌ها و اقدامات هستند.
 #10.8.2    سطح: 2    نقش: D/V
 بررسی کنید که خروجی‌های بازتاب اعتبارسنجی شوند تا از دستکاری مکانیسم‌های خودارزیابی توسط ورودی‌های مخرب جلوگیری شود.
 #10.8.3    سطح: 2    نقش: D/V
 تأیید کنید که تحلیل امنیتی متا-شناختی سوگیری احتمالی، دستکاری یا نقض امنیت در فرایندهای استدلال عامل را شناسایی می‌کند.
 #10.8.4    سطح: 3    نقش: D/V
 تأیید کنید که هشدارهای امنیتی مبتنی بر بازتاب، نظارت تقویت‌شده و گردش‌های کاری مداخله انسانی احتمالی را تحریک می‌کنند.
 #10.8.5    سطح: 3    نقش: D/V
 بررسی کنید که یادگیری مداوم از بازتاب‌های امنیتی تشخیص تهدید را بهبود می‌دهد بدون تضعیف عملکرد مشروع.

---

### 10.9 تکامل و امنیت خود-بهبود

کنترل‌های امنیتی برای سیستم‌های مبتنی بر عامل که قادر به خودتغییری و تکامل هستند.

 #10.9.1    سطح: 1    نقش: D/V
 بررسی کنید که قابلیت‌های خودتغییری تنها در ناحیه‌های امن تعیین‌شده محدود شده‌اند و دارای مرزهای اعتبارسنجی رسمی هستند.
 #10.9.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که پیشنهادهای تکاملی پیش از پیاده‌سازی از ارزیابی تأثیر امنیتی عبور می‌کنند.
 #10.9.3    سطح: 2    نقش: D/V
 تأیید کنید که مکانیسم‌های بهبود خودکار شامل قابلیت‌های بازگردانی با اعتبارسنجی یکپارچگی هستند.
 #10.9.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که امنیت یادگیری متا از دستکاری خصمانه الگوریتم‌های بهبود جلوگیری می‌کند.
 #10.9.5    سطح: 3    نقش: D/V
 تأیید کنید که بهبود بازگشتیِ خود با محدودیت‌های ایمنی رسمی محدود شده باشد و با اثبات‌های ریاضیِ همگرایی همراه گردد.

---

#### منابع

MITRE ATLAS adversary tactics for ML
NIST AI Risk Management Framework 1.0, 2023
OWASP Top 10 for LLM Applications, 2025
Adversarial Training: A Survey — Zhao et al., 2024
RobustBench adversarial-robustness benchmark
Membership-Inference & Model-Inversion Risk Survey, 2025
PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023
Model-Inversion Attacks & Defenses Survey — AI Review, 2025
Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024
Fragile Model Watermarking Survey — 2025
Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025
BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024

## 11 حفظ حریم خصوصی و مدیریت داده‌های شخصی

### هدف کنترل

حفظ اطمینان‌های حریم خصوصی قوی در سراسر چرخه عمر هوش مصنوعی—جمع‌آوری داده‌ها، آموزش، استنتاج و واکنش به رویداد—به گونه‌ای که داده‌های شخصی تنها با رضایت صریح، حداقل دامنه لازم، حذف قابل اثبات و تضمین‌های حریم خصوصی رسمی پردازش شوند.

---

### 11.1 ناشناس‌سازی و حداقل‌سازی داده‌ها

 #11.1.1    سطح: 1    نقش: D/V
 تأیید کنید که شناسه‌های مستقیم و شبه‌هویت حذف شده‌اند و هش شده‌اند.
 #11.1.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که بازرسی‌های خودکار، k-anonymity و l-diversity را اندازه‌گیری می‌کنند و زمانی که آستانه‌ها از سیاست کمتر شوند، هشدار می‌دهند.
 #11.1.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که گزارش‌های اهمیت ویژگی‌های مدل نشان می‌دهند که فراتر از ε = 0.01 اطلاعات متقابل هیچ نشت شناسه‌ای وجود ندارد.
 #11.1.4    سطح: 3    نقش: V
 تأیید کنید که اثبات‌های رسمی یا گواهی داده‌های مصنوعی نشان می‌دهند که خطر بازشناسی دوباره ≤ 0.05 حتی در برابر حملات پیوند.

---

### 11.2 حق فراموش‌شدن و اجرای حذف

 #11.2.1    سطح: 1    نقش: D/V
 تأیید کنید که درخواست‌های حذف داده‌های شخصی به داده‌های خام، چک‌پوینت‌ها، بردارهای تعبیه‌شده، لاگ‌ها و پشتیبان‌ها در چارچوب توافق‌نامه‌های سطح خدمات با مدت کمتر از 30 روز منتقل می‌شود.
 #11.2.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که روال‌های «machine-unlearning» به‌طور فیزیکی دوباره آموزش می‌دهند یا با استفاده از الگوریتم‌های معتبر یادگیری‌زدایی حذف را تقریبی می‌کنند.
 #11.2.3    سطح: 2    نقش: V
 تأیید کنید که ارزیابی مدل سایه‌ای نشان می‌دهد که رکوردهای فراموش‌شده پس از عملیات حذف داده‌ها بر خروجی‌ها تأثیر کمتر از 1% دارند.
 #11.2.4    سطح: 3    نقش: V
 تأیید کنید که رویدادهای حذف به‌طور غیرقابل تغییر ثبت شده و برای مراجع نظارتی قابل حسابرسی هستند.

---

### 11.3 حفاظت‌های تفاضلی-خصوصی

 #11.3.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که داشبوردهای حسابداری زیان حریم خصوصی وقتی ε تجمعی از آستانه‌های سیاست فراتر رود، هشدار می‌دهند.
 #11.3.2    سطح: 2    نقش: V
 تأیید کنید که ممیزی‌های حریم خصوصی جعبه سیاه ε̂ را در حدود 10% از مقدار اعلام‌شده برآورد می‌کنند.
 #11.3.3    سطح: 3    نقش: V
 تأیید کنید که اثبات‌های رسمی، تمام تنظیمات دقیق پس از آموزش و بردارهای جاسازی‌شده را پوشش می‌دهند.

---

### 11.4 محدودیت هدف و حفاظت در برابر گسترش دامنه

 #11.4.1    سطح: 1    نقش: D
 تأیید کنید که هر مجموعه داده و هر چک‌پوینت مدل دارای برچسب هدف قابل‌خواندن توسط ماشین باشد و با رضایت اصلی همسو باشد.
 #11.4.2    سطح: 1    نقش: D/V
 تأیید کنید که نظارت‌های زمان اجرا کوئری‌هایی را که با هدف اعلام‌شده ناسازگارند تشخیص داده و منجر به رد نرم می‌شوند.
 #11.4.3    سطح: 3    نقش: D
 اطمینان حاصل کنید که دروازه‌های سیاست-به-کد بازاستقرار مدل‌ها را به دامنه‌های جدید بدون بررسی DPIA مسدود می‌کنند۔
 #11.4.4    سطح: 3    نقش: V
 تأیید کنید که اثبات‌های ردیابی رسمی نشان می‌دهند که چرخه عمر هر دادهٔ شخصی در دامنه رضایت‌شده باقی می‌ماند.

---

### 11.5 مدیریت رضایت و پیگیری مبنای قانونی

 #11.5.1    سطح: 1    نقش: D/V
 تأیید کنید که یک پلتفرم مدیریت رضایت (CMP) وضعیت پذیرش داوطلبانه، هدف و مدت نگهداری را برای هر دارنده داده ثبت می‌کند.
 #11.5.2    سطح: 2    نقش: D
 تأیید کنید که API‌ها توکن‌های رضایت را افشا می‌کنند؛ مدل‌ها باید دامنهٔ توکن را قبل از استنتاج اعتبارسنجی کنند.
 #11.5.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که رضایت رد شده یا سلب شده، خطوط لوله پردازش را ظرف 24 ساعت متوقف می‌کند.

---

### 11.6 یادگیری فدرال با کنترل‌های حریم خصوصی

 #11.6.1    سطح: 1    نقش: D
 بررسی کنید که به‌روزرسانی‌های کلاینت از افزودن نویز حریم خصوصی تفاضلی محلی قبل از تجمیع استفاده می‌کنند.
 #11.6.2    سطح: 2    نقش: D/V
 تأیید کنید که معیارهای آموزش دارای حریم تفاضلی هستند و هرگز تابع خطای یک کلاینت واحد را فاش نمی‌کنند.
 #11.6.3    سطح: 2    نقش: V
 تأیید کنید که تجمیع مقاوم در برابر مسموم‌سازی داده‌ها (برای مثال Krum/Trimmed-Mean) فعال است.
 #11.6.4    سطح: 3    نقش: V
 تأیید کنید که شواهد رسمی، کل بودجه ε را نشان می‌دهند و با کاهش کارایی کمتر از 5 واحد همراه است.

---

#### منابع

GDPR & AI Compliance Best Practices
EU Parliament Study on GDPR & AI, 2020
ISO 31700-1:2023 — Privacy by Design for Consumer Products
NIST Privacy Framework 1.1 (2025 Draft)
Machine Unlearning: Right-to-Be-Forgotten Techniques
A Survey of Machine Unlearning, 2024
Auditing DP-SGD — ArXiv 2024
DP-SGD Explained — PyTorch Blog
Purpose-Limitation for AI — IJLIT 2025
Data-Protection Considerations for AI — URM Consulting
Top Consent-Management Platforms, 2025
Secure Aggregation in DP Federated Learning — ArXiv 2024

## C12 مانیتورینگ، لاگ‌برداری و تشخیص ناهنجاری

### هدف کنترل

این بخش الزامات ارائه دید هم‌زمان و قضایی نسبت به آنچه مدل و سایر اجزای هوش مصنوعی می‌بینند، انجام می‌دهند و بازمی‌گردانند را مشخص می‌کند تا تهدیدها شناسایی، اولویت‌بندی و از آنها آموخته شوند.

### C12.1 لاگ درخواست و پاسخ

 #12.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمامی درخواست‌های کاربر و پاسخ‌های مدل با فراداده‌های مناسب ثبت می‌شوند (مثلاً نشان زمانی، شناسه کاربر، شناسه نشست، نسخه مدل).
 #12.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که لاگ‌ها در مخازن امن و دارای کنترل دسترسی ذخیره می‌شوند با سیاست‌های نگهداری مناسب و رویه‌های پشتیبان‌گیری.
 #12.1.3    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های ذخیره‌سازی لاگ‌ها رمزگذاری در حالت استراحت و در حال انتقال را پیاده‌سازی می‌کنند تا از اطلاعات حساس موجود در لاگ‌ها محافظت شود.
 #12.1.4    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که داده‌های حساس در درخواست‌ها و خروجی‌ها قبل از ثبت در لاگ‌ها به‌طور خودکار محو یا ماسک می‌شوند، با قواعد ماسک‌گذاری قابل پیکربندی برای PII، اعتبارنامه‌ها و اطلاعات مالکیتی.
 #12.1.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تصمیمات سیاستی و اقدامات فیلترینگ ایمنی با جزئیات کافی ثبت می‌شوند تا امکان بازرسی و اشکال‌زدایی سیستم‌های نظارت بر محتوا فراهم گردد.
 #12.1.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که یکپارچگی لاگ از طریق امضای رمزنگاری‌شده یا ذخیره‌سازی صرفاً نوشتنی محافظت می‌شود.

---

### C12.2 تشخیص سوء استفاده و هشدار

 #12.2.1    سطح: 1    نقش: D/V
 تأیید کنید که سیستم با استفاده از تشخیص مبتنی بر امضا، الگوهای معروف جیلبریک، تلاش‌های تزریق پرامپت و ورودی‌های خصمانه را شناسایی کرده و هشدار می‌دهد.
 #12.2.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم با پلتفرم‌های مدیریت امنیتی اطلاعات و رویدادها (SIEM) موجود از طریق فرمت‌های لاگ استاندارد و پروتکل‌ها یکپارچه می‌شود.
 #12.2.3    سطح: 2    نقش: D/V
 تأیید کنید که رویدادهای امنیتی غنی‌شده شامل زمینه مخصوص هوش مصنوعی از جمله شناسه‌های مدل، نمره‌های اطمینان و تصمیم‌های فیلتر ایمنی هستند.
 #12.2.4    سطح: 2    نقش: D/V
 تأیید کنید که تشخیص ناهنجاری رفتاری، الگوهای مکالمه نامعمول، یا تلاش‌های تکرار بیش از حد، یا رفتارهای کاوش سیستماتیک را شناسایی می‌کند.
 #12.2.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مکانیسم‌های هشداردهی در زمان واقعی تیم‌های امنیتی را مطلع می‌کنند هنگامی که نقض‌های سیاستی احتمالی یا تلاش‌های حمله تشخیص داده می‌شوند.
 #12.2.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که قواعد سفارشی برای تشخیص الگوهای تهدید خاص هوش مصنوعی، از جمله تلاش‌های جیل‌بریک هماهنگ‌شده، کارزارهای تزریق پرامپت و حملات استخراج مدل گنجانده شده‌اند.
 #12.2.7    سطح: 3    نقش: D/V
 تأیید کنید که گردش‌کارهای پاسخ به حوادث خودکار می‌توانند مدل‌های به‌خطر افتاده را ایزوله کنند، کاربران مخرب را مسدود کنند و رویدادهای امنیتی بحرانی را به سطح بالاتر ارجاع دهند.

---

### C12.3 تشخیص انحراف مدل

 #12.3.1    سطح: 1    نقش: D/V
 تأیید کنید که سیستم معیارهای عملکرد پایه‌ای مانند دقت، نمره‌های اطمینان، تاخیر و نرخ‌های خطا را در سراسر نسخه‌های مدل و بازه‌های زمانی پیگیری می‌کند.
 #12.3.2    سطح: 2    نقش: D/V
 تأیید کنید که هشدار خودکار زمانی فعال می‌شود که معیارهای عملکرد از آستانه‌های از پیش تعیین‌شده برای افت کارایی فراتر روند یا به طور قابل توجهی از خطوط مبنای عملکرد منحرف شوند.
 #12.3.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که سامانه‌های تشخیص توهم مواردی را شناسایی و علامت‌گذاری می‌کنند که خروجی‌های مدل حاوی اطلاعات نادرست از نظر واقعیت، ناسازگار یا ساختگی هستند.

---

### C12.4 تله‌متری عملکرد و رفتار

 #12.4.1    سطح: 1    نقش: D/V
 تأیید کنید که معیارهای عملیاتی از جمله زمان تاخیر درخواست، مصرف توکن، استفاده از حافظه و نرخ عبور به‌طور پیوسته جمع‌آوری و نظارت می‌شوند.
 #12.4.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که نرخ‌های موفقیت و شکست با دسته‌بندی انواع خطاها و علل ریشه‌ای آن‌ها پیگیری می‌شوند.
 #12.4.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که پایش استفاده از منابع شامل مصرف GPU/CPU، مصرف حافظه و نیازهای ذخیره‌سازی باشد و در صورت نقض آستانه‌ها هشدار داده شود.

---

### C12.5 پاسخ به رویدادهای هوش مصنوعی: برنامه‌ریزی و اجرا

 #12.5.1    سطح: 1    نقش: D/V
 تأیید کنید که برنامه‌های پاسخ به حوادث امنیتی به‌طور مشخص رویدادهای امنیتی مرتبط با هوش مصنوعی را در برگیرند، از جمله مختل شدن مدل، آلودگی داده‌ها و حملات خصمانه.
 #12.5.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تیم‌های پاسخ به حوادث به ابزارهای فارنسیک مخصوص هوش مصنوعی و تخصص لازم برای بررسی رفتار مدل و بردارهای حمله دسترسی دارند.
 #12.5.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تحلیل پس از رخداد شامل ملاحظات بازآموزی مدل، به‌روزرسانی‌های فیلتر ایمنی و ادغام درس‌های آموخته‌شده در کنترل‌های امنیتی باشد.

---

### C12.5 تشخیص کاهش کارایی هوش مصنوعی

نظارت و تشخیص کاهش کارایی و کیفیت مدل هوش مصنوعی در طول زمان.

 #12.5.1    سطح: 1    نقش: D/V
 بررسی کنید که دقت مدل، دقت پیش‌بینی، بازشناسی، و نمره‌های F1 به طور مداوم پایش می‌شوند و در برابر آستانه‌های پایه مقایسه می‌شوند.
 #12.5.2    سطح: 1    نقش: D/V
 تأیید کنید که تشخیص انحراف داده‌ها تغییرات توزیع ورودی را پایش می‌کند که ممکن است بر عملکرد مدل تأثیر بگذارد.
 #12.5.3    سطح: 2    نقش: D/V
 تایید کنید که تشخیص انحراف مفهوم تغییرات در رابطه بین ورودی‌ها و خروجی‌های مورد انتظار را شناسایی می‌کند.
 #12.5.4    سطح: 2    نقش: D/V
 تأیید کنید که کاهش عملکرد منجر به ایجاد هشدارهای خودکار می‌شود و گردش‌های کاری بازآموزی یا جایگزینی مدل را آغاز می‌کند.
 #12.5.5    سطح: 3    نقش: V
 بررسی کنید که تحلیل علت ریشه‌ای افت عملکرد با تغییرات داده‌ها، مشکلات زیرساختی یا عوامل خارجی همبسته است.

---

### C12.6 نمایش DAG و امنیت گردش کار

سیستم‌های بصری‌سازی گردش کار را در برابر نشت اطلاعات و حملات دستکاری محافظت کنید.

 #12.6.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که داده‌های نمایش DAG قبل از ذخیره‌سازی یا انتقال، برای حذف اطلاعات حساس پاک‌سازی می‌شوند.
 #12.6.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که کنترل‌های دسترسی به نمایش گراف گردش کار تنها به کاربران مجاز اجازه می‌دهند تا مسیرهای تصمیم‌گیری عامل و ردیابی‌های استدلال را مشاهده کنند.
 #12.6.3    سطح: 2    نقش: D/V
 تأیید کنید که یکپارچگی داده‌های DAG از طریق امضاهای رمزنگاری‌شده و مکانیسم‌های ذخیره‌سازی ضد دستکاری محافظت می‌شود.
 #12.6.4    سطح: 2    نقش: D/V
 تأیید کنید که سیستم‌های نمایش گردش کار اعتبارسنجی ورودی را پیاده‌سازی می‌کنند تا از حملات تزریق از طریق داده‌های گره یا لبه‌های ساخته‌شده جلوگیری شود.
 #12.6.5    سطح: 3    نقش: D/V
 بررسی کنید که به‌روزرسانی‌های زمان واقعی گراف جهت‌دار بدون حلقه (DAG) دارای محدودیت نرخ و اعتبارسنجی هستند تا از حملات انکار سرویس (DoS) به سیستم‌های تجسم داده جلوگیری شود.

---

### C12.7 نظارت پیشگیرانه بر رفتار امنیتی

تشخیص و جلوگیری از تهدیدات امنیتی از طریق تحلیل رفتار عامل به طور فعال.

 #12.7.1    سطح: 1    نقش: D/V
 تأیید کنید که رفتارهای عامل پیش‌فعال قبل از اجرا از نظر امنیتی اعتبارسنجی شده‌اند و با ادغام ارزیابی ریسک یکپارچه هستند.
 #12.7.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که محرک‌های ابتکار خودمختار شامل ارزیابی زمینه امنیتی و ارزیابی چشم‌انداز تهدید است.
 #12.7.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که الگوهای رفتار پیشگیرانه برای پیامدهای امنیتی بالقوه و پیامدهای ناخواسته تحلیل می‌شوند.
 #12.7.4    سطح: 3    نقش: D/V
 تأیید کنید که اقدامات پیشگیرانه امنیتی حساس به امنیت نیازمند زنجیره‌های تأیید صریح همراه با سوابق حسابرسی هستند.
 #12.7.5    سطح: 3    نقش: D/V
 بررسی کنید که آیا تشخیص ناهنجاری رفتاری انحراف‌ها را در الگوهای عامل پیش‌فعال شناسایی می‌کند که ممکن است نشانگر نفوذ باشد.

---

### منابع

NIST AI Risk Management Framework 1.0 - Manage 4.1 and 4.3
ISO/IEC 42001:2023 — AI Management Systems Requirements - Annex B 6.2.6
EU AI Act — Article 12, 13, 16 and 19 on Logging and Record-keeping

## C13 نظارت انسانی، مسئولیت‌پذیری و حکمرانی

### هدف کنترل

این فصل الزامات حفظ نظارت انسانی و زنجیره‌های پاسخگویی روشن در سیستم‌های هوش مصنوعی را ارائه می‌دهد تا توضیح‌پذیری، شفافیت و مدیریت اخلاقی را در طول چرخه حیات هوش مصنوعی تضمین کند.

---

### C13.1 سوئیچ قطع اضطراری و مکانیزم‌های جایگزین

ارائه مسیرهای خاموش‌سازی یا بازگردانی هنگام مشاهده رفتار ناامن سیستم هوش مصنوعی.

 #13.1.1    سطح: 1    نقش: D/V
 تأیید کنید که یک مکانیزم قطع اضطراری دستی وجود دارد تا به‌طور فوری استنتاج مدل هوش مصنوعی و خروجی‌های آن را متوقف کند.
 #13.1.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که کنترل‌های اورراید تنها برای پرسنل مجاز قابل دسترسی باشند.
 #13.1.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که روش‌های بازگردانی می‌توانند به نسخه‌های قبلی مدل یا عملیات حالت امن بازگردند.
 #13.1.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که مکانیسم‌های بازنویسی به‌طور منظم آزمایش می‌شوند.

---

### C13.2 نقاط تصمیم‌گیری با دخالت انسان-در-حلقه

الزام به تاییدهای انسانی هنگامی که دامنهٔ ریسک از آستانه‌های از پیش تعیین‌شده فراتر رود.

 #13.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تصمیمات هوش مصنوعی با ریسک بالا قبل از اجرا به تأیید صریح انسانی نیاز دارند.
 #13.2.2    سطح: 1    نقش: D
 تأیید کنید که آستانه‌های ریسک به‌وضوح تعریف شده‌اند و به‌طور خودکار فرآیندهای بازبینی انسانی را فعال می‌کنند.
 #13.2.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که برای تصمیمات حساس به زمان، در صورت عدم دسترسی به تأیید انسانی در مهلت‌های مقرر، رویه‌های جایگزین وجود دارد.
 #13.2.4    سطح: 3    نقش: D/V
 بررسی کنید که فرایندهای افزایش سطح اختیارات، سطوح اختیار روشن را برای انواع تصمیم‌گیری یا دسته‌های ریسک، در صورت وجود، تعریف می‌کنند.

---

### C13.3 زنجیره مسئولیت و قابلیت ممیزی

اقدامات اپراتور و تصمیمات مدل را ثبت کنید.

 #13.3.1    سطح: 1    نقش: D/V
 تایید کنید که تمام تصمیم‌های سیستم هوش مصنوعی و مداخلات انسانی با برچسب‌های زمانی، هویت‌های کاربری و دلایل تصمیم ثبت شوند.
 #13.3.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که لاگ‌های بازرسی قابل دستکاری نیستند و مکانیزم‌های تأیید یکپارچگی را در بر بگیرید.

---

### C13.4 تکنیک‌های هوش مصنوعی توضیح‌پذیر

اهمیت ویژگی‌های سطحی، سناریوهای فرضی و توضیحات محلی.

 #13.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های هوش مصنوعی توضیحات پایه‌ای برای تصمیمات خود را به‌صورت قابل فهم برای انسان ارائه می‌دهند.
 #13.4.2    سطح: 2    نقش: V
 اطمینان حاصل کنید که کیفیت توضیح از طریق مطالعات ارزیابی انسانی و معیارهای اندازه‌گیری اعتبارسنجی می‌شود.
 #13.4.3    سطح: 3    نقش: D/V
 تأیید کنید که امتیازهای اهمیت ویژگی یا روش‌های نسبت‌دهی (SHAP، LIME و غیره) برای تصمیمات حیاتی در دسترس هستند.
 #13.4.4    سطح: 3    نقش: V
 بررسی کنید که توضیحات جایگزین فرضی نشان می‌دهند چگونه ورودی‌ها می‌توانند تغییر یابند تا خروجی‌ها تغییر کنند، در صورت انطباق با مورد استفاده و دامنه.

---

### C13.5 کارت‌های مدل و افشای استفاده

کارت‌های مدل را برای استفادهٔ موردنظر، معیارهای عملکرد و ملاحظات اخلاقی نگه دارید.

 #13.5.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که کارت‌های مدل موارد استفادهٔ هدف، محدودیت‌ها و حالات شکست شناخته‌شده را مستندسازی می‌کنند.
 #13.5.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که معیارهای عملکرد در میان موارد استفاده مختلف مربوطه افشا شوند.
 #13.5.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که ملاحظات اخلاقی، ارزیابی‌های سوگیری، ارزیابی‌های عدالت، ویژگی‌های داده‌های آموزشی، و محدودیت‌های داده‌های آموزشی شناخته‌شده مستندسازی شده‌اند و به‌طور منظم به‌روزرسانی می‌شوند.
 #13.5.4    سطح: 2    نقش: D/V
 تأیید کنید که کارت‌های مدل دارای کنترل نسخه هستند و در طول چرخه عمر مدل با پیگیری تغییرات نگهداری می‌شوند.

---

### C13.6 برآورد عدم قطعیت

امتیازهای اعتماد یا مقادیر آنتروپی را در پاسخ‌ها به کار ببرید.

 #13.6.1    سطح: 1    نقش: D
 بررسی کنید که سیستم‌های هوش مصنوعی با خروجی‌های خود، نمره‌های اطمینان یا اندازه‌گیری‌های عدم قطعیت ارائه می‌دهند.
 #13.6.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که آستانه‌های عدم قطعیت بازنگری انسانی اضافی یا مسیرهای تصمیم‌گیری جایگزین را فعال می‌کنند.
 #13.6.3    سطح: 2    نقش: V
 تأیید کنید که روش‌های برآورد عدم قطعیت با داده‌های حقیقت زمینی کالیبره شده‌اند و اعتبارسنجی شده‌اند.
 #13.6.4    سطح: 3    نقش: D/V
 بررسی کنید که انتقال عدم قطعیت در طول گردش کارهای هوش مصنوعی چندمرحله‌ای حفظ می‌شود.

---

### C13.7 گزارش‌های شفافیت کاربر-محور

به طور دوره‌ای در مورد رخدادها، انحراف داده و استفاده از داده‌ها افشا کنید.

 #13.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیاست‌های استفاده از داده‌ها و شیوه‌های مدیریت رضایت کاربران به ذی‌نفعان به‌وضوح اطلاع‌رسانی شده‌اند.
 #13.7.2    سطح: 2    نقش: D/V
 بررسی کنید که ارزیابی‌های تأثیر هوش مصنوعی انجام می‌شوند و نتایج آن‌ها در گزارش‌ها گنجانده می‌شوند.
 #13.7.3    سطح: 2    نقش: D/V
 تأیید کنید که گزارش‌های شفافیت که به‌طور منظم منتشر می‌شوند، حوادث هوش مصنوعی و شاخص‌های عملیاتی را با جزئیات نسبتاً معقول افشا می‌کنند.

#### منابع

EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
ISO/IEC 42001:2023 — AI Management Systems Requirements
NIST AI Risk Management Framework 1.0
NIST SP 800-53 Revision 5 — Security and Privacy Controls
A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)
Model Cards for Model Reporting (Mitchell et al., 2018)
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)
ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods
IEEE 7001-2021 — Transparency of Autonomous Systems
GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)
Human Oversight under Article 14 of the EU AI Act (Fink, 2025)

## ضمیمه A: واژه‌نامه

This واژه‌نامه جامع تعاریف اصطلاحات کلیدی هوش مصنوعی (AI)، یادگیری ماشین (ML)، و امنیت که در AISVS به کار می‌رود را برای اطمینان از شفافیت و درک مشترک ارائه می‌دهد.

نمونه خصمانه: ورودی که به‌طور عمدی طراحی شده است تا باعث شود مدل هوش مصنوعی اشتباه کند، اغلب با افزودن تغییرات ناچیز نامحسوس برای انسان‌ها.
​
مقاومت در برابر حملات مخرب – مقاومت مدل در برابر ورودی‌های مخرب که عمداً ساخته شده‌اند تا فریب داده شوند یا دستکاری شوند و منجر به خطا گردند، به معنای توانایی حفظ عملکرد مدل در هوش مصنوعی است.
​
عامل – عامل‌های هوش مصنوعی سامانه‌های نرم‌افزاری هستند که از هوش مصنوعی برای دستیابی به اهداف و انجام وظایف به نمایندگی از کاربران استفاده می‌کنند. آنها دارای استدلال، برنامه‌ریزی و حافظه هستند و سطحی از خودمختاری برای تصمیم‌گیری، یادگیری و سازگار شدن دارند.
​
هوش مصنوعی عامل‌محور: سامانه‌های هوش مصنوعی که می‌توانند با درجه‌ای از خودمختاری برای رسیدن به اهداف عمل کنند و اغلب تصمیم‌گیری می‌کنند و اقداماتی بدون مداخله مستقیم انسان انجام می‌دهند.
​
کنترل دسترسی مبتنی بر ویژگی‌ها (ABAC): الگویی برای کنترل دسترسی که تصمیمات مجوز بر اساس ویژگی‌های کاربر، منبع، اقدام و محیط گرفته می‌شود و در زمان استعلام ارزیابی می‌گردد.
​
حملهٔ درب پشتی: نوعی حمله سم‌پاشی داده‌ها است که در آن مدل به محرک‌های معین به روشی خاص پاسخ می‌دهد، در حالی که در سایر مواقع به‌طور عادی رفتار می‌کند.
​
سوگیری: خطاهای سیستماتیک در خروجی‌های مدل‌های هوش مصنوعی که می‌توانند به نتایج غیرعادلانه یا تبعیض‌آمیز برای گروه‌های خاص یا در زمینه‌های خاص منجر شوند.
​
استفاده از سوگیری: یک تکنیک حمله که از سوگیری‌های شناخته‌شده در مدل‌های هوش مصنوعی برای دستکاری خروجی‌ها یا نتایج استفاده می‌کند.
​
Cedar: زبان سیاستی آمازون و موتور برای مجوزهای با جزئیات دقیق که در پیاده‌سازی ABAC برای سیستم‌های هوش مصنوعی استفاده می‌شود.
​
زنجیرهٔ تفکر: روشی برای بهبود استدلال در مدل‌های زبانی با تولید گام‌های استدلال میانی پیش از ارائه پاسخ نهایی.
​
قطع‌کننده‌های مدار: سازوکارهایی که هنگامی که آستانه‌های خطر مشخصی فراتر می‌روند، عملیات سامانهٔ هوش مصنوعی را به‌طور خودکار متوقف می‌کنند.
​
افشای داده‌ها: افشای ناخواسته اطلاعات حساس از طریق خروجی‌های مدل‌های هوش مصنوعی یا رفتار آن‌ها.
​
آلودگی داده‌های آموزشی: خرابکاری عمدی در داده‌های آموزشی به منظور به خطر انداختن یکپارچگی مدل، اغلب برای نصب درهای پشتی یا کاهش کارایی.
​
حریم خصوصی تفاضلی – حریم خصوصی تفاضلی یک چارچوب ریاضیاتی دقیق برای انتشار اطلاعات آماری درباره مجموعه‌های داده است در حالی که از حریم خصوصی افراد محافظت می‌کند. این چارچوب به دارنده داده امکان می‌دهد الگوهای جمعی گروه را به اشتراک بگذارد و در عین حال اطلاعاتی که درباره افراد خاص افشا می‌شود محدود می‌کند.
​
Embeddingها: نمایش‌های بردیِ فشرده از داده‌ها (متن، تصاویر و غیره) که معنایِ مفهومیِ داده‌ها را در فضایِ با ابعادِ بالا ثبت می‌کنند.
​
توضیح‌پذیری – توضیح‌پذیری در هوش مصنوعی، توانایی یک سیستم هوش مصنوعی است برای ارائه دلایل قابل فهم برای تصمیمات و پیش‌بینی‌های آن و ارائه بینشی نسبت به سازوکارهای داخلی آن.
​
هوش مصنوعی قابل توضیح (XAI): سامانه‌های هوش مصنوعی که برای ارائه توضیحات قابل فهم درباره تصمیمات و رفتارهایشان از طریق تکنیک‌ها و چارچوب‌های مختلف طراحی شده‌اند.
​
یادگیری فدراسیون توزیع‌شده: رویکردی در یادگیری ماشین است که مدل‌ها در میان چندین دستگاه غیرمتمرکز که داده‌های نمونه‌های محلی را در خود نگه می‌دارند، بدون تبادل داده‌ها آموزش داده می‌شوند.
​
ریل‌های حفاظتی: محدودیت‌هایی که برای جلوگیری از تولید خروجی‌های مضر، جانبدارانه یا به هر صورت ناخواسته توسط سامانه‌های هوش مصنوعی اعمال می‌شوند.
​
توهم – یک توهم در هوش مصنوعی به پدیده‌ای اشاره دارد که طی آن یک مدل هوش مصنوعی اطلاعات نادرست یا گمراه‌کننده تولید می‌کند که مبتنی بر داده‌های آموزشی خود یا واقعیت عینی نیست.
​
انسان در حلقه (HITL): سیستم‌هایی که برای نیاز به نظارت، تأیید یا مداخله انسانی در نقاط تصمیم‌گیری بحرانی طراحی شده‌اند.
​
زیرساخت به عنوان کد (IaC): مدیریت و راه‌اندازی زیرساخت از طریق کد به‌جای فرایندهای دستی، امکان اسکن امنیتی و استقرارهای منسجم را فراهم می‌کند.
​
جیل‌بریک: تکنیک‌هایی که برای دور زدن محدودیت‌های ایمنی در سیستم‌های هوش مصنوعی، به‌ویژه در مدل‌های زبانی بزرگ، برای تولید محتوای ممنوعه به کار می‌روند.
​
اصل حداقل دسترسی: اصل امنیتی که تنها حقوق دسترسی لازم و کافی را به کاربران و فرآیندها اعطا می‌کند.
​
LIME (توضیحات محلی تفسیرپذیر مستقل از مدل): روشی برای توضیح پیش‌بینی‌های هر طبقه‌بند یادگیری ماشین با تقریب زدن آن به‌طور محلی با یک مدل تفسیرپذیر است.
​
حمله استنتاج عضویت: حمله‌ای است که هدف آن تعیین اینکه آیا یک نمونه داده خاص برای آموزش یک مدل یادگیری ماشین استفاده شده است.
​
MITRE ATLAS: چشم‌انداز تهدیدهای خصمانه برای سیستم‌های هوش مصنوعی؛ یک پایگاه دانش از تاکتیک‌ها و تکنیک‌های خصمانه علیه سیستم‌های هوش مصنوعی.
​
کارت مدل – سندی است که اطلاعات استانداردشده درباره عملکرد مدل هوش مصنوعی، محدودیت‌های آن، کاربردهای مدنظر و ملاحظات اخلاقی را ارائه می‌دهد تا شفافیت و توسعه مسئولانه هوش مصنوعی را ترویج کند.
​
استخراج مدل: حمله‌ای که در آن یک مهاجم به طور مکرر از مدل هدف پرسش می‌کند تا نسخه‌ای از نظر کارکردی مشابه بدون مجوز ایجاد کند.
​
معکوس‌سازی مدل: حمله‌ای که با تحلیل خروجی‌های مدل سعی در بازسازی داده‌های آموزشی دارد.
​
مدیریت چرخه عمر مدل – مدیریت چرخه عمر مدل‌های هوش مصنوعی فرایندی است که نظارت بر تمامی مراحل وجود یک مدل هوش مصنوعی را در بر می‌گیرد، از طراحی آن، توسعه، استقرار، پایش، نگهداری و در نهایت بازنشستگی آن، تا اطمینان حاصل شود که مدل مؤثر باقی می‌ماند و با اهداف مطابقت دارد.
​
سمی‌سازی مدل: افزودن آسیب‌پذیری‌ها یا درهای پشتی به طور مستقیم به مدل در طول فرایند آموزش.
​
سرقت مدل: از طریق پرسش‌های مکرر، استخراج نسخه کپی یا تقریبی از یک مدل اختصاصی.
​
سامانه چندعامله: سامانه‌ای که از چند عامل هوش مصنوعی در حال تعامل با یکدیگر تشکیل شده است و هر یک از آن‌ها ممکن است دارای قابلیت‌ها و اهداف متفاوتی باشند.
​
OPA (Open Policy Agent): یک موتور سیاست‌گذاری متن‌باز است که امکان اجرای سیاست‌های یکپارچه را در سراسر پشته فراهم می‌کند.
​
یادگیری ماشین با حفاظت از حریم خصوصی (PPML): تکنیک‌ها و روش‌هایی برای آموزش و استقرار مدل‌های یادگیری ماشین در حالی که حریم خصوصی داده‌های آموزشی حفظ می‌شود.
​
تزریق پرامپت: حمله‌ای است که دستورالعمل‌های مخرب در ورودی‌ها جاسازی می‌شوند تا رفتار مدنظر مدل را نقض کند.
​
RAG (تولید با بازیابی): روشی است که مدل‌های زبانی بزرگ را با بازیابی اطلاعات مرتبط از منابع دانش خارجی پیش از تولید پاسخ بهبود می‌بخشد.
​
Red-Teaming: رویکردی است که به‌طور فعال سیستم‌های هوش مصنوعی را با شبیه‌سازی حملات خصمانه آزمایش می‌کند تا آسیب‌پذیری‌ها را شناسایی کند.
​
SBOM (فهرست مواد نرم‌افزاری): یک پرونده رسمی حاوی جزئیات و روابط زنجیره تامین اجزای مختلف مورد استفاده در ساخت نرم‌افزار یا مدل‌های هوش مصنوعی.
​
SHAP (SHapley Additive exPlanations): رویکرد مبتنی بر نظریه بازی برای توضیح خروجی هر مدل یادگیری ماشین با محاسبه سهم هر ویژگی در پیش‌بینی.
​
حمله به زنجیره تأمین: دستکاری یک سیستم از طریق هدف قرار دادن عناصر کم‌امنیت‌تر در زنجیره تأمین آن، مانند کتابخانه‌های شخص ثالث، مجموعه‌های داده، یا مدل‌های از پیش آموزش‌دیده.
​
یادگیری انتقالی: روشی است که در آن یک مدل توسعه یافته برای یک کار به‌عنوان نقطۀ آغاز برای مدلی در کار دوم دوباره استفاده می‌شود.
​
پایگاه داده بردی: یک پایگاه داده تخصصی که برای ذخیره بردهای با ابعاد بالا (بردهای تعبیه‌ای) طراحی شده و جستجوهای تشابه کارآمد انجام می‌دهد.
​
اسکن آسیب‌پذیری: ابزارهای خودکار که آسیب‌پذیری‌های امنیتی شناخته‌شده را در مؤلفه‌های نرم‌افزاری شناسایی می‌کنند، از جمله فریم‌ورک‌های هوش مصنوعی و وابستگی‌ها.
​
آب‌نشان‌گذاری: روش‌هایی برای درج نشان‌های نامحسوس در محتوای تولیدشده توسط هوش مصنوعی تا منشاء آن را پیگیری کنند یا تولید با هوش مصنوعی را تشخیص دهند.
​
آسیب‌پذیری روز صفر: یک آسیب‌پذیری ناشناخته که مهاجمان می‌توانند پیش از ایجاد و پیاده‌سازی یک پچ توسط توسعه‌دهندگان از آن بهره‌برداری کنند.

## ضمیمه B: مراجع

### TODO

## ضمیمه C: حاکمیت امنیت هوش مصنوعی و مستندسازی

### هدف

این پیوست، الزامات بنیادی را برای ایجاد ساختارهای سازمانی، سیاست‌ها و فرایندهایی به منظور حاکمیت امنیت هوش مصنوعی در طول چرخه حیات سیستم فراهم می‌کند.

---

### AC.1 پذیرش چارچوب مدیریت ریسک هوش مصنوعی

ارائه یک چارچوب رسمی برای شناسایی، ارزیابی و کاهش ریسک‌های مربوط به هوش مصنوعی در طول چرخه عمر سیستم.

 #AC.1.1    سطح: 1    نقش: D/V
 بررسی کنید که یک متدولوژی ارزیابی ریسک مخصوص هوش مصنوعی مستندسازی شده و پیاده‌سازی شده باشد.
 #AC.1.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که ارزیابی‌های ریسک در نقاط کلیدی چرخه عمر هوش مصنوعی و قبل از تغییرات قابل توجه انجام می‌شوند.
 #AC.1.3    سطح: 3    نقش: D/V
 بررسی کنید که چارچوب مدیریت ریسک با استانداردهای معتبر همسو است (برای نمونه NIST AI RMF).

---

### AC.2 سیاست‌ها و رویه‌های امنیت هوش مصنوعی

تعریف و اجرای استانداردهای سازمانی برای توسعه امن هوش مصنوعی، استقرار آن و عملیات مربوط به آن.

 #AC.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیاست‌های امنیتی مستند هوش مصنوعی وجود دارند.
 #AC.2.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که سیاست‌ها به‌طور حداقل سالی یک‌بار و پس از تغییرات قابل توجه در چشم‌انداز تهدید بازبینی و به‌روزرسانی می‌شوند.
 #AC.2.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که سیاست‌ها به تمامی دسته‌های AISVS و الزامات قانونی مربوطه پاسخ می‌دهند.

---

### AC.3 نقش‌ها و مسئولیت‌ها در امنیت هوش مصنوعی

برای امنیت هوش مصنوعی در سراسر سازمان، مسئولیت‌پذیری واضحی برقرار کنید.

 #AC.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که نقش‌ها و مسئولیت‌های امنیتی هوش مصنوعی مستند شده‌اند.
 #AC.3.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که افراد مسئول دارای تخصص امنیتی مناسب باشند.
 #AC.3.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که یک کمیته اخلاق هوش مصنوعی یا هیئت حاکمیت برای سیستم‌های هوش مصنوعی با ریسک بالا تأسیس شده است.

---

### AC.4 اجرای دستورالعمل‌های اخلاقی هوش مصنوعی

اطمینان حاصل کنید که سامانه‌های هوش مصنوعی طبق اصول اخلاقی معتبر عمل می‌کنند.

 #AC.4.1    سطح: 1    نقش: D/V
 تأیید کنید که راهنماهای اخلاقی مربوط به توسعه و استقرار هوش مصنوعی وجود دارند.
 #AC.4.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که سازوکارهایی برای شناسایی و گزارش نقض‌های اخلاقی وجود دارند.
 #AC.4.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که بررسی‌های اخلاقی منظم سیستم‌های هوش مصنوعی مستقر انجام می‌شوند.

---

### AC.5 نظارت بر انطباق هوش مصنوعی با مقررات

آگاهی از مقررات هوش مصنوعی در حال تحول را حفظ کنید و با آن‌ها مطابقت دهید.

 #AC.5.1    سطح: 1    نقش: D/V
 تأیید کنید که فرایندهایی وجود دارند که مقررات هوش مصنوعی قابل اجرا را شناسایی کنند.
 #AC.5.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که انطباق با تمامی الزامات مقرراتی ارزیابی می‌شود.
 #AC.5.3    سطح: 3    نقش: D/V
 تأیید کنید که تغییرات مقرراتی، بازنگری‌های به‌موقع و به‌روزرسانی‌ها را برای سیستم‌های هوش مصنوعی فعال می‌کنند.

### AC.6 حاکمیت داده‌های آموزشی، مستندسازی و فرآیند

 #1.1.2    سطح: 1    نقش: D/V
 تأیید کنید که تنها مجموعه‌داده‌هایی که از نظر کیفیت، نمایندگی، تهیه اخلاقی و رعایت مجوزها بررسی و تأیید شده‌اند، مجاز باشند تا خطرات آلودگی داده‌ها، سوگیری نهفته و نقض حقوق مالکیت معنوی کاهش یابد.
 #1.1.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که کیفیت برچسب‌گذاری از طریق بررسی‌های متقابل بازبین‌ها یا اجماع تأمین می‌شود.
 #1.1.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که برای مجموعه‌های دادهٔ آموزشی کلیدی، کارت‌های داده یا برگه‌های دیتاست‌ها نگهداری می‌شوند و ویژگی‌ها، انگیزه‌ها، ترکیب، فرایندهای جمع‌آوری، پیش‌پردازش و استفاده‌های پیشنهادی/ممنوعه را تشریح می‌کنند.
 #1.3.2    سطح: 2    نقش: D/V
 بررسی کنید که سوگیری‌های شناسایی‌شده از طریق استراتژی‌های مستند مانند بازتعادل‌سازی، افزایش داده هدفمند، تنظیمات الگوریتمی (به‌عنوان مثال پیش-پردازش، درون-پردازش، پس-پردازش)، یا وزن‌دهی مجدد، کاهش یافته‌اند و اثر کاهش سوگیری بر هر دو معیار عدالت و عملکرد کلی مدل ارزیابی می‌شود.
 #1.3.3    سطح: 2    نقش: D/V
 بررسی کنید که معیارهای عدالت پس از آموزش ارزیابی و مستندسازی می‌شوند.
 #1.3.4    سطح: 3    نقش: D/V
 تأیید کنید که یک سیاست مدیریت سوگیری چرخه حیات، مالکان و فواصل بازنگری را تعیین می‌کند.
 #1.4.1    سطح: 2    نقش: D/V
 تأیید کنید که کیفیت برچسب‌گذاری/نشانه‌گذاری از طریق دستورالعمل‌های روشن، بررسی‌های متقابل توسط ارزیابان، مکانیسم‌های اجماع (برای نمونه، نظارت بر توافق بین برچسب‌گذارها)، و فرایندهای تعریف‌شده برای رفع اختلافات تضمین می‌شود.
 #1.4.4    سطح: 3    نقش: D/V
 تایید کنید که برچسب‌های حیاتی برای ایمنی، امنیت یا عدالت (به‌عنوان مثال شناسایی محتوای سمی، یافته‌های پزشکی حیاتی) از بازبینی مستقل دو نفره اجباری یا تأیید قوی معادل آن برخوردار باشند.
 #1.4.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که راهنماهای برچسب‌گذاری و دستورالعمل‌ها جامع، دارای کنترل نسخه و بازبینی توسط همتایان هستند.
 #1.4.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اسکیماهای داده برای برچسب‌ها به‌وضوح تعریف شده‌اند و تحت کنترل نسخه هستند.
 #1.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مجموعه داده‌ها از نظر وجود عدم تعادل نمایشی و سوگیری‌های احتمالی در میان ویژگی‌های محافظت‌شده قانونی (مثلاً نژاد، جنسیت، سن) و سایر ویژگی‌های حساس از نظر اخلاقی که با دامنه کاربرد مدل مرتبط هستند (مثلاً وضعیت اقتصادی-اجتماعی، محل جغرافیایی) بررسی می‌شوند.
 #1.5.3    سطح: 2    نقش: V
 تأیید کنید که بازرسی‌های نمونه‌ای دستی توسط کارشناسان حوزه مربوطه، یک نمونه آماری معنی‌دار را پوشش دهد (به‌عنوان مثال ≥1% یا 1,000 نمونه، هر کدام که بیشتر باشد، یا آنچه ارزیابی ریسک تعیین می‌کند) تا مشکلات کیفیتی پنهان که توسط اتوماسیون تشخیص داده نمی‌شوند، شناسایی شوند.
 #1.8.4    سطح: 2    نقش: D/V
 بررسی کنید که فرایندهای برچسب‌گذاری برون‌سپاری‌شده یا جمع‌سپاری‌شده دارای تدابیر فنی/رویه‌ای برای تضمین محرمانگی داده‌ها، یکپارچگی داده‌ها، کیفیت برچسب‌ها و جلوگیری از نشت داده‌ها باشند.
 #1.5.4    سطح: 2    نقش: D/V
 بررسی کنید که گام‌های ترمیم به سوابق منبع افزوده شده‌اند.
 #1.6.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که نمونه‌های علامت‌گذاری‌شده قبل از آموزش، بازبینی دستی را فعال می‌کنند.
 #1.6.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که نتایج به پرونده امنیتی مدل تغذیه می‌شود و اطلاعات تهدیدی جاری را به‌روزرسانی می‌کند.
 #1.6.4    سطح: 3    نقش: D/V
 تأیید کنید که منطق تشخیص با اطلاعات تهدید جدید به‌روزرسانی می‌شود.
 #1.6.5    سطح: 3    نقش: D/V
 تأیید کنید که پایپلین‌های یادگیری آنلاین، انحراف توزیعی را پایش می‌کنند.
 #1.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که فرایندهای حذف داده‌های آموزشی داده‌های اصلی و مشتق را پاکسازی می‌کنند و تأثیر مدل را ارزیابی می‌کنند، و اینکه تأثیر بر مدل‌های تحت‌تأثیر ارزیابی می‌شود و در صورت لزوم از طریق بازآموزی یا بازکالیبراسیون رسیدگی می‌شود.
 #1.7.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که سازوکارهایی وجود دارند که دامنه و وضعیت رضایت کاربر (و انصراف‌های او) را برای داده‌های استفاده‌شده در آموزش پیگیری و رعایت کنند و اینکه رضایت پیش از گنجاندن داده‌ها در فرایندهای آموزشی جدید یا به‌روزرسانی‌های قابل‌توجه مدل اعتبارسنجی شود.
 #1.7.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که گردش‌های کاری به‌طور سالانه آزمایش می‌شوند و ثبت می‌شوند.
 #1.8.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تأمین‌کنندگان دادهٔ شخص ثالث، از جمله ارائه‌دهندگان مدل‌های از پیش آموزش‌دیده و مجموعه‌داده‌های خارجی، پیش از ادغام داده‌ها یا مدل‌های آنان، از نظر امنیتی، حریم خصوصی، اخلاقی بودن منبع داده و کیفیت داده، به‌طور دقیق بررسی می‌شوند.
 #1.8.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که انتقال‌های خارجی از TLS/احراز هویت و چک‌های یکپارچگی استفاده می‌کنند.
 #1.8.3    سطح: 2    نقش: D/V
 تأیید کنید که منابع داده با ریسک بالا (به‌عنوان مثال مجموعه‌ داده‌های متن‌باز با منشأ نامعلوم و عرضه‌کنندگان بدون ارزیابی) از بررسی‌های دقیق‌تر برخوردار شوند، مانند تحلیل در محیط ایزوله، بررسی‌های گسترده کیفیت و سوگیری، و تشخیص آلودگی داده‌ها به‌طور هدفمند، پیش از استفاده در کاربردهای حساس.
 #1.8.4    سطح: 3    نقش: D/V
 تایید کنید که مدل‌های از پیش‌آموزش‌دیده‌شده که از منابع ثالث به دست آمده‌اند، پیش از انجام تنظیم دقیق یا استقرار، برای سوگیری‌های پنهان، درهای پشتی احتمالی، یکپارچگی معماری آن‌ها و منشأ داده‌های آموزشی اصلی‌شان ارزیابی شوند.
 #1.5.3    سطح: 2    نقش: D/V
 بررسی کنید که در صورت استفاده از آموزش خصمانه، تولید، مدیریت و نسخه‌بندی داده‌های خصمانه مستندسازی شده و کنترل می‌شوند.
 #1.5.3    سطح: 3    نقش: D/V
 تأیید کنید که اثر آموزش مقاومت در برابر حملات مخرب بر عملکرد مدل (در برابر هر دو ورودی‌های تمیز و ورودی‌های مخرب) و معیارهای عدالت ارزیابی، مستندسازی و پایش می‌شود.
 #1.5.4    سطح: 3    نقش: D/V
 تأیید کنید که استراتژی‌های آموزش مقاوم در برابر حملات نفوذی و پایداری مدل به‌طور دوره‌ای بازنگری و به‌روزرسانی می‌شوند تا با تکامل تکنیک‌های حملات نفوذی مقابله کنند.
 #1.4.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مجموعه‌های داده ناموفق در قرنطینه نگه‌داری می‌شوند و دارای سوابق حسابرسی هستند.
 #1.4.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که دروازه‌های کیفیت، مجموعه‌داده‌های با کیفیت پایین را مسدود می‌کنند، مگر اینکه استثناهایی تأیید شده باشند.
 #1.11.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فرایند تولید، پارامترها و استفادهٔ مدنظر از داده‌های مصنوعی مستندسازی شده‌اند.
 #1.11.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که داده‌های مصنوعی از نظر ریسک برای تعصب، افشای حریم خصوصی و مسائل نمایشی قبل از استفاده در آموزش ارزیابی می‌شوند.
 #1.12.3    سطح: 2    نقش: D/V
 تایید کنید که برای رویدادهای دسترسی مشکوک هشدارها تولید می‌شوند و به سرعت بررسی می‌شوند.
 #1.13.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که دوره‌های نگهداری صریح برای همه مجموعه‌های آموزشی تعریف شده‌اند.
 #1.13.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مجموعه‌های داده در پایان چرخه عمرشان به‌طور خودکار منقضی می‌شوند، حذف می‌شوند یا برای حذف بازبینی می‌شوند.
 #1.13.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که عملیات نگهداری و حذف ثبت می‌شوند و قابلیت بازرسی دارند.
 #1.14.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که الزامات محل نگهداری داده‌ها و انتقال بین‌مرزی داده‌ها برای تمامی مجموعه‌های داده شناسایی و اعمال می‌شوند.
 #1.14.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مقررات مربوط به صنایع خاص (مثلاً بهداشت و درمان، مالی) در مدیریت داده‌ها شناسایی شده و مورد توجه قرار می‌گیرند.
 #1.14.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که انطباق با قوانین حریم خصوصی مرتبط (مانند GDPR و CCPA) به‌طور منظم مستندسازی شده و مورد بازبینی قرار می‌گیرد.
 #1.16.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که سازوکارهایی برای پاسخ به درخواست‌های صاحب داده برای دسترسی، اصلاح، محدودیت یا اعتراض وجود دارد.
 #1.16.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که درخواست‌ها در چارچوب مهلت‌های قانونی تعیین‌شده ثبت، پیگیری و برآورده می‌شوند.
 #1.16.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فرایندهای حقوق موضوع داده‌ها به‌طور منظم برای اثربخشی آزمایش و بازنگری می‌شوند.
 #1.17.1    سطح: 2    نقش: D/V
 تأیید کنید که پیش از به‌روزرسانی یا جایگزینی نسخه‌ای از مجموعه داده، تحلیل اثر انجام می‌شود که عملکرد مدل، عدالت و تطابق با الزامات را در بر می‌گیرد.
 #1.17.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که نتایج تحلیل اثرات مستند شده و توسط ذینفعان مرتبط بازبینی می‌شوند.
 #1.17.3    سطح: 2    نقش: D/V
 تأیید کنید که در صورت ایجاد نسخه‌های جدید ریسک‌های غیرقابل قبول یا بازگشت به وضعیت قبلی، طرح‌های بازگردانی وجود دارند.
 #1.18.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تمامی پرسنل درگیر در برچسب‌گذاری داده‌ها بررسی پیشینه شده‌اند و در زمینه امنیت داده‌ها و حریم خصوصی آموزش دیده‌اند.
 #1.18.2    سطح: 2    نقش: D/V
 تأیید کنید که تمامی پرسنل برچسب‌گذاری داده‌ها، توافقنامه‌های محرمانگی و عدم افشا را امضا کرده‌اند.
 #1.18.3    سطح: 2    نقش: D/V
 تأیید کنید که پلتفرم‌های برچسب‌گذاری کنترل‌های دسترسی را اعمال می‌کنند و برای تهدیدات داخلی نظارت می‌کنند.

#### منابع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
EU Artificial Intelligence Act — Regulation (EU) 2024/1689
ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods

## ضمیمه D: حاکمیت کدنویسی امن با کمک هوش مصنوعی و صحت‌سنجی

### هدف

این فصل کنترل‌های سازمانی پایه را برای استفاده ایمن و مؤثر از ابزارهای کدنویسی AI-assisted در طول توسعه نرم‌افزار تعریف می‌کند و امنیت و قابلیت ردیابی را در سراسر SDLC تضمین می‌کند.

---

### AD.1 جریان کار کدنویسی امن با کمک هوش مصنوعی

ابزارهای هوش مصنوعی را در چرخه توسعه امن نرم‌افزار سازمان (SSDLC) بدون تضعیف دروازه‌های امنیتی موجود یکپارچه کنید.

 #AD.1.1    سطح: 1    نقش: D/V
 تأیید کنید که یک گردش کار مستند توضیح می‌دهد که ابزارهای هوش مصنوعی چه زمانی و چگونه می‌توانند کد تولید کنند، کد را بازنگری کنند یا کد را بازبینی کنند.
 #AD.1.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که جریان کار با هر فاز SSDLC مطابقت دارد (طراحی، پیاده‌سازی، بازبینی کد، تست، استقرار).
 #AD.1.3    سطح: 3    نقش: D/V
 تأیید کنید که معیارها (برای مثال، چگالی آسیب‌پذیری، میانگین زمان تا کشف) برای کد تولیدشده توسط هوش مصنوعی جمع‌آوری می‌شوند و با پایه‌های فقط انسانی مقایسه می‌شوند.

---

### AD.2 صلاحیت ابزار هوش مصنوعی و مدل‌سازی تهدید

اطمینان حاصل کنید که ابزارهای کدنویسی هوش مصنوعی قبل از پذیرش از نظر قابلیت‌های امنیتی، ریسک و تأثیر زنجیره-تامین ارزیابی شوند.

 #AD.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که برای هر ابزار هوش مصنوعی، مدل تهدید، سوء استفاده، معکوس‌سازی مدل، نشت داده‌ها و خطرات زنجیره‑وابستگی را شناسایی می‌کند.
 #AD.2.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که ارزیابی‌های ابزار شامل تحلیل ایستا/پویا از هر جزء محلی و ارزیابی نقاط پایانی SaaS (TLS، احراز هویت/مجوزدهی، ثبت لاگ) می‌شوند.
 #AD.2.3    سطح: 3    نقش: D/V
 تأیید کنید که ارزیابی‌ها از یک چارچوب شناخته‌شده پیروی می‌کنند و پس از تغییرات نسخهٔ عمده دوباره انجام می‌شوند.

---

### AD.3 مدیریت امن پرامپت و زمینه

جلوگیری از افشای اسرار، کدهای مالکیتی و داده‌های شخصی هنگام ساخت پرامپت‌ها یا زمینه‌های مدل‌های هوش مصنوعی.

 #AD.3.1    سطح: 1    نقش: D/V
 تأیید کنید که راهنمایی‌های مکتوب ارسال اسرار، اعتبارنامه‌ها یا داده‌های طبقه‌بندی‌شده در پرامپت‌ها را منع می‌کند.
 #AD.3.2    سطح: 2    نقش: D
 بررسی کن که کنترل‌های فنی (حذف محرمانه در سمت کاربر، فیلترهای زمینه تأییدشده) به‌طور خودکار آثاری حساس را حذف می‌کنند.
 #AD.3.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که پرومپت‌ها و پاسخ‌ها توکن‌شده‌اند، در حال انتقال و در حالت سکون رمزگذاری می‌شوند، و دوره‌های نگهداری با سیاست-طبقه‌بندی داده‌ها مطابقت دارند.

---

### AD.4 اعتبارسنجی کد تولیدشده توسط هوش مصنوعی

آسیب‌پذیری‌های ناشی از خروجی هوش مصنوعی را قبل از ادغام یا استقرار کد شناسایی و رفع کنید.

 #AD.4.1    سطح: 1    نقش: D/V
 تأیید کنید که کد تولیدشده توسط هوش مصنوعی همواره تحت بازبینی کد توسط انسان قرار می‌گیرد.
 #AD.4.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که اسکنرهای خودکار (SAST/IAST/DAST) در هر درخواست کشش که حاوی کد تولیدشده توسط هوش مصنوعی است، اجرا شوند و در صورت یافتن یافته‌های بحرانی، ادغام‌ها را مسدود کنند.
 #AD.4.3    سطح: 3    نقش: D/V
 بررسی کنید که آیا آزمایش فازی تفاضلی یا آزمایش‌های مبتنی بر ویژگی، رفتارهای بحرانی امنیتی را اثبات می‌کنند (مثلاً اعتبارسنجی ورودی، منطق مجوزدهی).

---

### AD.5 توضیح‌پذیری و پیگیری پیشنهادهای کد

برای حسابرسان و توسعه‌دهندگان، بینشی در مورد چرایی ارائه یک پیشنهاد و چگونگی تکامل آن ارائه کنید.

 #AD.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که زوج‌های پرومپت/پاسخ با شناسه‌های کامیت ثبت می‌شوند.
 #AD.5.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که توسعه‌دهندگان می‌توانند استنادهای مدل (نمونه‌های آموزشی، مستندات) که از یک پیشنهاد پشتیبانی می‌کنند، به نمایش بگذارند.
 #AD.5.3    سطح: 3    نقش: D/V
 بررسی کنید که گزارش‌های توضیح‌پذیری با مستندات طراحی ذخیره شوند و در بازبینی‌های امنیتی به آنها ارجاع داده شوند، تا با اصول ردیابی ISO/IEC 42001 مطابقت داشته باشند.

---

### AD.6 بازخورد مداوم و تنظیم دقیق مدل

بهبود مداوم عملکرد امنیتی مدل در طول زمان در عین جلوگیری از انحراف منفی.

 #AD.6.1    سطح: 1    نقش: D/V
 بررسی کنید که توسعه‌دهندگان بتوانند پیشنهادهای ناامن یا غیر منطبق با استانداردها را پرچم‌گذاری کنند و اینکه پرچم‌ها ردیابی می‌شوند۔
 #AD.6.2    سطح: 2    نقش: D
 تأیید کنید که بازخوردهای تجمیعی، به‌روزرسانی‌های دوره‌ای یا تولید با استفاده از بازیابی تقویت‌شده را با مجموعه‌های داده امن‑کدنویسیِ تأییدشده هدایت می‌کند (برای مثال OWASP Cheat Sheets).
 #AD.6.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که یک چارچوب ارزیابی حلقه‌ بسته پس از هر ریزتنظیم، تست‌های رگرسیون را اجرا می‌کند؛ معیارهای امنیتی باید قبل از استقرار با پایه‌های قبلی هم‌خوانی داشته باشند یا از آنها فراتر روند.

---

#### منابع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
OWASP Secure Coding Practices — Quick Reference Guide

## ضمیمه E: ابزارها و چارچوب‌های نمونه

### هدف

این فصل نمونه‌هایی از ابزارها و چارچوب‌هایی را ارائه می‌کند که می‌توانند از پیاده‌سازی یا تحقق یک الزام AISVS معین پشتیبانی کنند. این موارد نباید به‌عنوان توصیه‌ها یا تأییدهای تیم AISVS یا پروژه امنیت GenAI OWASP در نظر گرفته شوند.

---

### AE.1 حاکمیت داده‌های آموزشی و مدیریت سوگیری

ابزارهای مورد استفاده برای تحلیل داده‌ها، حاکمیت داده‌ها و مدیریت سوگیری.

 #AE.1.1    بخش: 1.1
 ابزارهای مدیریت موجودی داده‌ها: ابزارهای مدیریت موجودی داده‌ها مانند...
 #AE.1.2    بخش: 1.2
 رمزگذاری-در-حین-انتقال از TLS برای برنامه‌های مبتنی بر HTTPS استفاده کنید، با ابزارهایی مانند OpenSSL و کتابخانه‌های پایتонش`ssl` کتابخانه.

---

### AE.2 اعتبارسنجی ورودی کاربر

ابزارهایی برای پردازش و اعتبارسنجی ورودی‌های کاربر.

 #AE.2.1    بخش: 2.1
 ابزارهای دفاعی در برابر تزریق پرومپت: از ابزارهای گاردریل مانند NeMo از NVIDIA یا Guardrails AI استفاده کنید.

---

