## صفحه‌ی روبرو

### درباره استاندارد

استاندارد اعتبارسنجی امنیت هوش مصنوعی (AISVS) یک فهرست نیازمندی‌های امنیتی است که توسط جامعه ‌ای از دانشمندان داده، مهندسان MLOps، معماران نرم‌افزار، توسعه‌دهندگان، آزمون‌کنندگان، متخصصان امنیت، فروشندگان ابزار، ناظران و مصرف‌کنندگان ایجاد شده است و می‌تواند برای طراحی، ساخت، آزمون و اعتبارسنجی سیستم‌ها و برنامه‌های مبتنی بر هوش مصنوعی قابل اعتماد استفاده شود. این استاندارد زبان مشترکی برای مشخص کردن کنترل‌های امنیتی در سراسر چرخه عمر هوش مصنوعی فراهم می‌کند—از جمع‌آوری داده‌ها و توسعه مدل تا استقرار و پایش مستمر—تا سازمان‌ها بتوانند تاب‌آوری، حفظ حریم خصوصی و ایمنی راه‌حل‌های هوش مصنوعی خود را اندازه‌گیری و بهبود دهند.

### حق چاپ و مجوز

نسخه 0.1 (اولین پیش‌نویس عمومی - در حال انجام کار)، 2025  

![license](images/license.png)
کپی‌رایت © 2025 پروژه AISVS.  

منتشر شده تحتCreative Commons Attribution‑ShareAlike 4.0 International License.
برای هر گونه استفاده مجدد یا توزیع، باید شرایط مجوز این اثر را به طور واضح به دیگران اطلاع دهید.

### رهبران پروژه

جیم مَنی‌کو
آراس "راس" ممیزیازیچی

### مشارکت‌کنندگان و بازبین‌ها

https://github.com/ottosulin
https://github.com/mbhatt1
https://github.com/vineethsai
https://github.com/cciprofm
https://github.com/deepakrpandey12


---

AISVS یک استاندارد کاملاً جدید است که به طور خاص برای پرداختن به چالش‌های امنیتی منحصر به فرد سیستم‌های هوش مصنوعی ایجاد شده است. در حالی که از بهترین شیوه‌های امنیتی گسترده‌تر الهام گرفته است، هر الزام در AISVS از پایه توسعه یافته است تا نمایانگر چشم‌انداز تهدیدات هوش مصنوعی باشد و به سازمان‌ها در ساخت راه‌حل‌های هوش مصنوعی ایمن‌تر و مقاوم‌تر کمک کند.

## پیشگفتار

به استاندارد صحت‌سنجی امنیت هوش مصنوعی (AISVS) نسخه 1.0 خوش آمدید!

### مقدمه

AISVS که در سال 2025 از طریق تلاش‌های مشترک جامعه تأسیس شد، الزامات امنیتی را که باید هنگام طراحی، توسعه، استقرار و بهره‌برداری از مدل‌های مدرن هوش مصنوعی، خطوط لوله و خدمات مجهز به هوش مصنوعی در نظر گرفته شوند، تعریف می‌کند.

AISVS v1.0 نشان‌دهنده کار مشترک رهبران پروژه، گروه کاری و مشارکت‌کنندگان گسترده‌تر جامعه برای تولید یک خط‌مبنای عملی و قابل آزمون به منظور تأمین امنیت سیستم‌های هوش مصنوعی است.

هدف ما از این نسخه، ساده‌سازی پذیرش AISVS در حالی است که به طور دقیق روی دامنه تعریف‌شده آن متمرکز مانده و به چشم‌انداز ریسک‌های به‌سرعت در حال تحول و منحصربه‌فرد هوش مصنوعی پاسخ می‌دهد.

### اهداف کلیدی برای نسخه 1.0 AISVS

نسخه 1.0 با چندین اصول راهنما ساخته خواهد شد.

#### دامنه به‌خوبی تعریف شده

هر الزامی باید با نام و ماموریت AISVS همسو باشد:

هوش مصنوعی – کنترل‌ها در لایه AI/ML (داده، مدل، خط لوله، یا استنتاج) اجرا می‌شوند و مسئولیت آن‌ها بر عهده متخصصان هوش مصنوعی است.
امنیت – الزامات به‌طور مستقیم ریسک‌های شناسایی شده امنیتی، حریم خصوصی یا ایمنی را کاهش می‌دهند.
تأیید صحت – زبان به گونه‌ای نوشته شده است که انطباق می‌تواند به صورت عینی ارزیابی شود.
استاندارد – بخش‌ها ساختار و اصطلاحات یکسانی را دنبال می‌کنند تا یک مرجع منسجم تشکیل دهند.
​
---

با دنبال کردن AISVS، سازمان‌ها می‌توانند به صورت نظام‌مند موضع امنیتی راه‌حل‌های هوش مصنوعی خود را ارزیابی و تقویت کنند و فرهنگ مهندسی هوش مصنوعی امن را پرورش دهند.

## استفاده از AISVS

استاندارد تأیید امنیت هوش مصنوعی (AISVS) نیازمندی‌های امنیتی برای برنامه‌ها و خدمات هوش مصنوعی مدرن را تعریف می‌کند و بر جنبه‌هایی تمرکز دارد که در کنترل توسعه‌دهندگان برنامه است.

AISVS برای هر کسی که در حال توسعه یا ارزیابی امنیت برنامه‌های هوش مصنوعی است، از جمله توسعه‌دهندگان، معماران، مهندسان امنیت و حسابرسان طراحی شده است. این فصل ساختار و نحوه استفاده از AISVS را معرفی می‌کند، از جمله سطوح تایید آن و موارد استفاده مورد نظر.

### سطوح تأیید امنیت هوش مصنوعی

AISVS سه سطح تصدیق امنیتی صعودی را تعریف می‌کند. هر سطح عمق و پیچیدگی بیشتری اضافه می‌کند و به سازمان‌ها این امکان را می‌دهد تا وضعیت امنیتی خود را با سطح ریسک سیستم‌های هوش مصنوعی خود تطبیق دهند.

سازمان‌ها ممکن است از سطح 1 شروع کنند و به تدریج با افزایش بلوغ امنیتی و شدت تهدید، سطوح بالاتری را به‌کار گیرند.

#### تعریف سطوح

هر نیازمندی در AISVS نسخه 1.0 به یکی از سطوح زیر اختصاص داده شده است:

 الزامات سطح 1

سطح 1 شامل حیاتی‌ترین و پایه‌ای‌ترین الزامات امنیتی است. این سطح روی جلوگیری از حملات رایجی تمرکز دارد که متکی به پیش‌شرط‌ها یا آسیب‌پذیری‌های دیگر نیستند. بیشتر کنترل‌های سطح 1 یا به‌راحتی قابل اجرا هستند یا آن‌قدر ضروری هستند که تلاش لازم برای اجرا را توجیه می‌کنند.

 الزامات سطح 2

سطح 2 به حملات پیشرفته‌تر یا کمتر رایج و همچنین دفاع‌های چندلایه در برابر تهدیدات گسترده‌تر می‌پردازد. این الزامات ممکن است شامل منطق پیچیده‌تر یا هدف‌گذاری پیش‌نیازهای خاص حمله باشند.

 الزامات سطح 3

سطح 3 شامل کنترل‌هایی است که معمولاً اجرای آن‌ها دشوارتر است یا در شرایط خاص کاربرد دارند. این کنترل‌ها اغلب نمایانگر مکانیزم‌های دفاع در عمق یا کاهش اثر حملات خاص، هدفمند یا با پیچیدگی بالا هستند.

#### نقش (D/V)

هر الزام AISVS مطابق با مخاطب اصلی علامت‌گذاری شده است:

D – الزامات متمرکز بر توسعه‌دهنده
V – الزامات متمرکز بر تأییدکننده/ممتحن
D/V – مرتبط با هر دو توسعه‌دهندگان و تاییدکنندگان

## گورننس داده‌های آموزش C1 و مدیریت تعصب

### هدف کنترل

داده‌های آموزشی باید به گونه‌ای تهیه، مدیریت و نگهداری شوند که اصالت، امنیت، کیفیت و عدالت حفظ شود. انجام این کار وظایف قانونی را برآورده می‌کند و خطرات تعصب، مسمومیت یا نقض حریم خصوصی که ممکن است در طول آموزش ظاهر شوند و می‌توانند بر کل چرخه عمر هوش مصنوعی تأثیر بگذارند را کاهش می‌دهد.

---

### C1.1 منشاء داده‌های آموزشی

نگهداری یک فهرست قابل تایید از تمام مجموعه داده‌ها، پذیرش تنها منابع مطمئن، و ثبت هر تغییر برای امکان حسابرسی.

 #1.1.1    سطح: 1    نقش: D/V
 تأیید کنید که یک فهرست به‌روزرسانی شده از هر منبع داده آموزشی (مبدا، مسئول/مالک، مجوز، روش جمع‌آوری، محدودیت‌های استفاده مورد نظر، و تاریخچه پردازش) نگهداری می‌شود.
 #1.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که فرآیندهای داده‌های آموزشی ویژگی‌ها، خصوصیات یا فیلدهای غیرضروری را حذف می‌کنند (مانند داده‌های متادیتای استفاده‌نشده، اطلاعات شناسایی شخصی حساس، داده‌های آزمون نشت‌یافته).
 #1.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تمام تغییرات داده‌ها تحت یک روند تصویب ثبت شده قرار دارند.
 #1.1.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که در صورت امکان، مجموعه داده‌ها یا زیرمجموعه‌ها دارای واترمارک یا اثر انگشت دیجیتال باشند.

---

### C1.2 امنیت و یکپارچگی داده‌های آموزش

دسترسی به داده‌های آموزشی را محدود کنید، آن‌ها را در حالت استراحت و هنگام انتقال رمزگذاری کنید و صحت آن‌ها را برای جلوگیری از دستکاری، سرقت یا مسموم‌سازی داده‌ها اعتبارسنجی کنید.

 #1.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که کنترل‌های دسترسی از ذخیره‌سازی داده‌های آموزشی و خطوط لوله محافظت می‌کنند.
 #1.2.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تمام دسترسی‌ها به داده‌های آموزش ثبت می‌شود، شامل کاربر، زمان و اقدام انجام شده.
 #1.2.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که داده‌های آموزشی در حال انتقال و در حالت استراحت رمزنگاری شده‌اند، با استفاده از الگوریتم‌های رمزنگاری استاندارد صنعتی و روش‌های مدیریت کلید.
 #1.2.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که هش‌های رمزنگاری شده یا امضاهای دیجیتال برای تضمین صحت داده‌ها در طول ذخیره‌سازی و انتقال داده‌های آموزشی استفاده می‌شوند.
 #1.2.5    سطح: 2    نقش: D/V
 تأیید کنید که تکنیک‌های تشخیص خودکار برای محافظت در برابر تغییرات غیرمجاز یا فساد داده‌های آموزش به کار گرفته شده‌اند.
 #1.2.6    سطح: 2    نقش: D/V
 تأیید کنید که داده‌های آموزشی منسوخ به‌طور ایمن حذف یا ناشناس‌سازی شده‌اند.
 #1.2.7    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که همه نسخه‌های مجموعه داده‌های آموزشی به طور یکتا شناسایی شده، به صورت غیرقابل تغییر ذخیره شده و قابل حسابرسی باشند تا از بازگشت به نسخه قبلی و تحلیل‌های قانونی پشتیبانی شود.

---

### C1.3 کیفیت، یکپارچگی و امنیت برچسب‌گذاری داده‌های آموزشی

برچسب‌ها را محافظت کنید و بازبینی فنی برای داده‌های حیاتی را الزامی کنید.

 #1.3.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که هش‌های رمزنگاری شده یا امضاهای دیجیتال به آثار برچسب زده شده اعمال شده‌اند تا یکپارچگی و اصالت آن‌ها تضمین شود.
 #1.3.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که رابط‌ها و پلتفرم‌های برچسب‌گذاری کنترل‌های دسترسی قوی را اعمال می‌کنند، لاگ‌های حسابرسی ضد تغییر از تمامی فعالیت‌های برچسب‌گذاری را نگهداری می‌کنند و در برابر اصلاحات غیرمجاز محافظت می‌کنند.
 #1.3.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که اطلاعات حساس در برچسب‌ها در سطح فیلد داده هنگام ذخیره و انتقال، حذف، ناشناس‌سازی یا رمزگذاری شده باشند.

---

### C1.4 کیفیت داده‌های آموزشی و تضمین امنیت

ترکیب اعتبارسنجی خودکار، بررسی‌های دستی تصادفی و رفع مشکلات ثبت‌شده برای تضمین قابلیت اطمینان داده‌ها.

 #1.4.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که تست‌های خودکار خطاهای قالب و مقادیر تهی را در هر بار وارد کردن داده یا تغییر قابل توجه داده‌ها شناسایی می‌کنند.
 #1.4.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که خطوط لوله آموزش و ریزتنظیم مدل‌های زبان بزرگ (LLM) شامل تشخیص سم‌پاشی و اعتبارسنجی یکپارچگی داده‌ها (مانند روش‌های آماری، تشخیص نقاط پرت، تحلیل جاسازی‌ها) برای شناسایی حملات احتمالی سم‌پاشی (مانند تغییر برچسب، وارد کردن محرک‌های درب‌پشتی، دستورات تعویض نقش، حملات نمونه‌های تاثیرگذار) یا فساد ناخواسته داده‌ها در داده‌های آموزشی هستند.
 #1.4.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که دفاع‌های مناسب، مانند آموزش مقابله‌ای (با استفاده از نمونه‌های مقابله‌ای تولید شده)، افزایش داده‌ها با ورودی‌های تغییر یافته، یا تکنیک‌های بهینه‌سازی مقاوم، بر اساس ارزیابی ریسک برای مدل‌های مربوطه پیاده‌سازی و تنظیم شده‌اند.
 #1.4.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که برچسب‌های تولید شده به‌صورت خودکار (مثلاً از طریق LLMها یا نظارت ضعیف) مشروط به آستانه‌های اطمینان و بررسی‌های سازگاری هستند تا برچسب‌های توهمی، گمراه‌کننده یا با اطمینان پایین شناسایی شوند.
 #1.4.5    سطح: 3    نقش: D
 اطمینان حاصل کنید که تست‌های خودکار انحراف‌های برچسب را در هر بار دریافت داده یا تبدیل داده‌های مهم شناسایی می‌کنند.

---

### C1.5 ردیابی و اصالت داده‌ها

ردیابی کامل مسیر هر نقطه داده از منبع تا ورودی مدل برای قابلیت حسابرسی و پاسخ به حادثه.

 #1.5.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که سیر تحول هر نقطه داده، شامل تمام تبدیلات، افزودنی‌ها و ادغام‌ها، ثبت شده و قابل بازسازی باشد.
 #1.5.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که سوابق تبارشناسی غیرقابل تغییر، به‌طور ایمن ذخیره شده و برای ممیزی‌ها قابل دسترسی باشند.
 #1.5.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که پیگیری ریشه‌داری شامل داده‌های مصنوعی تولید شده از طریق تکنیک‌های حفظ حریم خصوصی یا تولیدی می‌شود و تمام داده‌های مصنوعی به طور واضح برچسب‌گذاری شده و در سراسر فرآیند از داده‌های واقعی قابل تمایز هستند.

---

### مراجع

NIST AI Risk Management Framework
EU AI Act – Article 10: Data & Data Governance
MITRE ATLAS: Adversary Tactics for AI
Survey of ML Bias Mitigation Techniques – MDPI
Data Provenance & Lineage Best Practices – Nightfall AI
Data Labeling Quality Standards – LabelYourData
Training Data Poisoning Guide – Lakera.ai
CISA Advisory: Securing Data for AI Systems
ISO/IEC 23053: AI Management Systems Framework
IBM: What is AI Governance?
Google AI Principles
GDPR & AI Training Data – DataProtectionReport
Supply-Chain Security for AI Data – AppSOC
OpenAI Privacy Center – Data Deletion Controls
Adversarial ML Dataset – Kaggle

## اعتبارسنجی ورودی کاربر C2

### هدف کنترل

اعتبارسنجی قوی ورودی کاربر دفاع خط اول در برابر برخی از آسیب‌زننده‌ترین حملات به سیستم‌های هوش مصنوعی است. حملات تزریق پرامپت می‌توانند دستورالعمل‌های سیستم را لغو کنند، داده‌های حساس را لو دهند، یا مدل را به سمتی سوق دهند که رفتار غیرمجاز داشته باشد. مگر اینکه فیلترها و سلسله مراتب دستوری اختصاصی وجود داشته باشند، تحقیقات نشان می‌دهد که "جیل‌بریک‌های چند-شات" که از پنجره‌های متنی بسیار طولانی بهره می‌برند، موثر خواهند بود. همچنین، حملات تغییرات ظریف خصمانه—مانند جابه‌جایی همولوگلیف‌ها یا زبان لیت—می‌توانند به‌صورت پنهانی تصمیمات مدل را تغییر دهند.

---

### دفاع در برابر تزریق دستورات C2.1

تزریق پرامپت یکی از بزرگ‌ترین ریسک‌ها برای سیستم‌های هوش مصنوعی است. تدابیر دفاعی در برابر این تاکتیک از ترکیبی از فیلترهای الگوی ایستا، دسته‌بندی‌کننده‌های پویا و اعمال سلسله‌مراتب دستورات استفاده می‌کنند.

 #2.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که ورودی‌های کاربر در برابر یک کتابخانه به‌روزرسانی‌شده و مداوم از الگوهای شناخته شده تزریق دستور (کلیدواژه‌های فرار از محدودیت، "نادیده گرفتن قبلی"، زنجیره‌های نقش‌بازی، حملات غیرمستقیم HTML/URL) بررسی می‌شوند.
 #2.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم سلسله‌مراتب دستورات را اعمال می‌کند به گونه‌ای که پیام‌های سیستم یا توسعه‌دهنده، دستورات کاربر را نقض می‌کنند، حتی پس از افزایش پنجره زمینه.
 #2.1.3    سطح: 2    نقش: D/V
 تأیید کنید که آزمون‌های ارزیابی خصمانه (مانند پرسش‌های «چند-نمونه‌ای» تیم قرمز) قبل از هر انتشار مدل یا قالب پرسش اجرا می‌شوند، با تعیین حد آستانه نرخ موفقیت و موانع خودکار برای افت کیفیت.
 #2.1.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که پرامپت‌های منشأ گرفته از محتوای شخص ثالث (صفحات وب، فایل‌های PDF، ایمیل‌ها) در یک زمینه تجزیه جداگانه پاک‌سازی شده‌اند قبل از آن که به پرامپت اصلی الحاق شوند.
 #2.1.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تمام به‌روزرسانی‌های قوانین فیلتر پرامپت، نسخه‌های مدل دسته‌بندی‌کننده و تغییرات فهرست مسدودسازی کنترل نسخه شده و قابل حسابرسی باشند.

---

### C2.2 مقاومت در برابر نمونه‌های خصمانه

مدل‌های پردازش زبان طبیعی (NLP) همچنان در برابر تغییرات جزئی در سطح نویسه یا کلمه که معمولاً برای انسان‌ها قابل تشخیص نیست اما مدل‌ها اغلب این تغییرات را به اشتباه طبقه‌بندی می‌کنند، آسیب‌پذیر هستند.

 #2.2.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که مراحل پایه نرمال‌سازی ورودی (Unicode NFC، نگاشت هوموگلیف، حذف فضای اضافی) قبل از توکنیزه‌سازی اجرا می‌شوند.
 #2.2.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که شناسایی ناهنجاری‌های آماری ورودی‌هایی را که فاصله ویرایشی غیرمعمول بالا نسبت به هنجارهای زبانی، تکرار بیش از حد توکن‌ها، یا فاصله‌های تعبیه غیرعادی دارند، علامت‌گذاری می‌کند.
 #2.2.3    سطح: 2    نقش: D
 تأیید کنید که خط لوله استنتاج از نمونه‌های مدل مقاوم‌شده با آموزش مقابله‌ای اختیاری یا لایه‌های دفاعی (مثلاً، رندوم‌سازی، تقطیر دفاعی) برای نقاط پایانی با ریسک بالا پشتیبانی می‌کند.
 #2.2.4    سطح: 2    نقش: V
 تأیید کنید که ورودی‌های مشکوک به حملات مخرب قرنطینه شده و با کل بار داده (پس از حذف اطلاعات شناسایی شخصی) ثبت می‌شوند.
 #2.2.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که معیارهای استحکام (نرخ موفقیت مجموعه‌های حمله شناخته شده) به مرور زمان پیگیری می‌شوند و بازگشت‌ها باعث ایجاد مانع برای انتشار می‌شوند.

---

### C2.3 اعتبارسنجی طرح‌واره، نوع و طول

حملات هوش مصنوعی که شامل ورودی‌های ناقص یا بیش‌ازحد بزرگ هستند می‌توانند باعث خطاهای تجزیه، نشت داده در بین فیلدها و خستگی منابع شوند. همچنین، اعمال دقیق الزامات ساختار داده‌ها (schema) پیش‌نیاز انجام فراخوانی‌های قطعی ابزار است.

 #2.3.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که هر نقطه پایانی فراخوانی API یا تابع، یک طرح ورودی صریح (JSON Schema، Protobuf یا معادل چندرسانه‌ای) را تعریف کرده و ورودی‌ها قبل از مونتاژ درخواست اعتبارسنجی شده‌اند.
 #2.3.2    سطح: 1    نقش: D/V
 تأیید کنید که ورودی‌هایی که از حد مجاز توکن یا بایت فراتر می‌روند، با یک خطای ایمن رد شده و هرگز به‌طور خاموش کوتاه نشده باشند.
 #2.3.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که چک‌های نوع (مثلاً بازه‌های عددی، مقادیر enum، نوع MIME برای تصاویر/صوت) در سمت سرور اجرا می‌شوند و نه تنها در کد کلاینت.
 #2.3.4    سطح: 2    نقش: D
 تأیید کنید که اعتبارسنج‌های معنایی (مثلاً JSON Schema) در زمان ثابت اجرا می‌شوند تا از حملات محروم‌سازی سرویس الگوریتمی جلوگیری شود.
 #2.3.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که خطاهای اعتبارسنجی با قطعات بار مفید مخفی شده و کدهای خطای بدون ابهام ثبت می‌شوند تا به تشخیص امنیتی کمک کند.

---

### C2.4 بررسی محتوا و سیاست‌ها

توسعه‌دهندگان باید قادر باشند تا درخواست‌های دارای ساختار نحوی صحیح که محتوای غیرمجاز (مانند دستورالعمل‌های غیرقانونی، سخنان نفرت‌پراکنی و متن‌های دارای حق کپی‌رایت) را درخواست می‌کنند، شناسایی کرده و سپس از انتشار آن‌ها جلوگیری کنند.

 #2.4.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که یک طبقه‌بندی‌کننده محتوا (بدون آموزش قبلی یا با آموزش دقیق) هر ورودی را برای خشونت، خودآسیبی، نفرت، محتوای جنسی و درخواست‌های غیرقانونی ارزیابی می‌کند، با آستانه‌های قابل تنظیم.
 #2.4.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که ورودی‌هایی که سیاست‌ها را نقض می‌کنند، پاسخ‌های استاندارد شده رد یا تکمیل ایمن دریافت می‌کنند تا به تماس‌های بعدی با مدل‌های زبان بزرگ منتقل نشوند.
 #2.4.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که مدل غربالگری یا مجموعه قواعد حداقل هر سه ماه یکبار مجدداً آموزش دیده یا به‌روزرسانی می‌شود، به‌طوری که الگوهای جدید مشاهده شده از دورزدن محدودیت‌ها یا نقض سیاست‌ها در آن لحاظ شده باشد.
 #2.4.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که غربالگری قوانین خاص کاربر (سن، محدودیت‌های قانونی منطقه‌ای) را از طریق قوانین مبتنی بر ویژگی که در زمان درخواست حل می‌شوند، رعایت می‌کند.
 #2.4.5    سطح: 3    نقش: V
 تأیید کنید که لاگ‌های غربالگری شامل امتیازهای اطمینان کلاس‌بندی و برچسب‌های دسته‌بندی سیاست برای همبستگی SOC و بازپخش تیم قرمز آینده باشد.

---

### محدودسازی نرخ ورودی C2.5 و پیشگیری از سوء استفاده

توسعه‌دهندگان باید با محدود کردن نرخ ورودی و شناسایی الگوهای استفاده غیرمعمول، از سوءاستفاده، خستگی منابع و حملات خودکار علیه سیستم‌های هوش مصنوعی جلوگیری کنند.

 #2.5.1    سطح: 1    نقش: D/V
 تأیید کنید که محدودیت‌های نرخ بر اساس هر کاربر، هر آی‌پی و هر کلید API برای همه نقاط پایانی ورودی اجرا شده‌اند.
 #2.5.2    سطح: 2    نقش: D/V
 تأیید کنید که محدودیت‌های نرخ انفجاری و پایدار به‌گونه‌ای تنظیم شده‌اند که از حملات عدم سرویس (DoS) و تلاش‌های رمزگشایی اجباری جلوگیری کنند.
 #2.5.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که الگوهای استفاده غیرمعمول (مثلاً درخواست‌های سریع پشت سر هم، ارسال انبوه ورودی) باعث فعال شدن مسدودسازی‌های خودکار یا ارتقاهای امنیتی می‌شوند.
 #2.5.4    سطح: 3    نقش: V
 تأیید کنید که گزارش‌های پیشگیری از سوءاستفاده حفظ و برای شناسایی الگوهای حمله نوظهور بررسی می‌شوند.

---

### C2.6 اعتبارسنجی ورودی چندحالته

سیستم‌های هوش مصنوعی باید اعتبارسنجی قوی برای ورودی‌های غیر متنی (تصاویر، صدا، فایل‌ها) شامل شوند تا از تزریق، دورزدن یا سوءاستفاده از منابع جلوگیری شود.

 #2.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که تمام ورودی‌های غیر متنی (تصاویر، صداها، فایل‌ها) قبل از پردازش از نظر نوع، اندازه و فرمت تأیید شوند.
 #2.6.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فایل‌ها قبل از ورود، برای بدافزارها و بارهای پنهان استگانوگرافیک اسکن شده‌اند.
 #2.6.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که ورودی‌های تصویر/صدا برای آشفتگی‌های مخرب یا الگوهای حمله شناخته شده بررسی می‌شوند.
 #2.6.4    سطح: 3    نقش: V
 تأیید کنید که خطاهای صحت‌سنجی ورودی چندوجهی ثبت شده و هشدارهایی برای بررسی ایجاد می‌کنند.

---

### C2.7 منبع ورودی و نسبت‌دهی

سیستم‌های هوش مصنوعی باید با نظارت و برچسب‌گذاری منابع تمامی ورودی‌های کاربران، از حسابرسی، ردیابی سوءاستفاده و انطباق پشتیبانی کنند.

 #2.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام ورودی‌های کاربر هنگام دریافت با متادیتا (شناسه کاربر، جلسه، منبع، زمان ثبت، آدرس IP) برچسب‌گذاری شده‌اند.
 #2.7.2    سطح: 2    نقش: D/V
 تأیید کنید که داده‌های متادیتای منشأ برای همه ورودی‌های پردازش شده حفظ شده و قابل حسابرسی باشد.
 #2.7.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که منابع ورودی غیرعادی یا غیرقابل اعتماد علامت‌گذاری شده و تحت بررسی دقیق‌تر یا مسدودسازی قرار گیرند.

---

### C2.8 تشخیص تهدید تطبیقی در زمان واقعی

توسعه‌دهندگان باید از سیستم‌های پیشرفته شناسایی تهدید برای هوش مصنوعی استفاده کنند که به الگوهای جدید حمله سازگار شده و حفاظت بلادرنگ با تطبیق الگوهای کامپایل شده را فراهم کنند.

 #2.8.1    سطح: 1    نقش: D/V
 تأیید کنید که الگوهای شناسایی تهدید به موتورهای منظم بهینه شده تبدیل شده‌اند تا برای فیلتر کردن در زمان واقعی با عملکرد بالا و حداقل تأثیر بر تأخیر استفاده شوند.
 #2.8.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های شناسایی تهدید کتابخانه‌های الگو جداگانه‌ای برای دسته‌های مختلف تهدید (تزریق دستور، محتوای مضر، داده‌های حساس، دستورهای سیستم) نگهداری می‌کنند.
 #2.8.3    سطح: 2    نقش: D/V
 تأیید کنید که تشخیص تهدید تطبیقی شامل مدل‌های یادگیری ماشین است که حساسیت تهدید را بر اساس فراوانی حمله و نرخ موفقیت به‌روزرسانی می‌کنند.
 #2.8.4    سطح: 2    نقش: D/V
 تأیید کنید که منابع اطلاعات تهدید زمان واقعی به‌طور خودکار کتابخانه‌های الگو را با امضاهای جدید حمله و شاخص‌های نفوذ (IOCs) به‌روزرسانی می‌کنند.
 #2.8.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که نرخ‌های مثبت کاذب در تشخیص تهدید به طور مداوم نظارت می‌شوند و ویژگی‌های الگو به‌صورت خودکار تنظیم می‌شوند تا تداخل با موارد استفاده مشروع حداقل شود.
 #2.8.6    سطح: 3    نقش: D/V
 تأیید کنید که تحلیل تهدید متنی منبع ورودی، الگوهای رفتار کاربر و سابقه جلسه را برای بهبود دقت تشخیص در نظر می‌گیرد.
 #2.8.7    سطح: 3    نقش: D/V
 تأیید کنید که معیارهای عملکرد تشخیص تهدید (نرخ تشخیص، تأخیر پردازش، بهره‌وری منابع) به‌صورت بلادرنگ پایش و بهینه‌سازی می‌شوند.

---

### C2.9 خط لوله اعتبارسنجی امنیت چندرسانه‌ای

توسعه‌دهندگان باید اعتبارسنجی امنیتی را برای ورودی‌های متنی، تصویری، صوتی و سایر حالت‌های ورودی هوش مصنوعی با استفاده از نوع‌های خاصی از شناسایی تهدید و جداسازی منابع ارائه دهند.

 #2.9.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر حالت ورودی دارای اعتبارسنج‌های امنیتی اختصاصی با الگوهای تهدید مستندسازی شده (متن: تزریق پرامپت، تصاویر: استگانوگرافی، صوت: حملات اسپکتروگرام) و آستانه‌های شناسایی است.
 #2.9.2    سطح: 2    نقش: D/V
 بررسی کنید که ورودی‌های چندوجهی در محیط‌های ایزوله شده با محدودیت‌های منابع مشخص (حافظه، CPU، زمان پردازش) که به هر نوع حالت چندوجهی اختصاص داده شده‌اند، پردازش می‌شوند و این موارد در سیاست‌های امنیتی مستند شده‌اند.
 #2.9.3    سطح: 2    نقش: D/V
 تأیید کنید که شناسایی حملات چندرسانه‌ای، حملات هماهنگ‌شده‌ای که چندین نوع ورودی را شامل می‌شوند (مانند بارهای مخفی استگانوگرافیک در تصاویر همراه با تزریق فرمان در متن) را با استفاده از قواعد همبستگی و تولید هشدار شناسایی می‌کند.
 #2.9.4    سطح: 3    نقش: D/V
 تأیید کنید که خطاهای اعتبارسنجی چند modality باعث ثبت گزارش‌های دقیق می‌شوند که شامل تمام حالت‌های ورودی، نتایج اعتبارسنجی، امتیازهای تهدید و تحلیل همبستگی با فرمت‌های گزارش ساخت‌یافته برای یکپارچه‌سازی با SIEM باشد.
 #2.9.5    سطح: 3    نقش: D/V
 تأیید کنید که دسته‌بندی‌کننده‌های محتوای خاص هر مدالیت طبق برنامه‌های مستند به‌روزرسانی شده‌اند (حداقل فصلی) با الگوهای تهدید جدید، نمونه‌های خصمانه و معیارهای عملکردی که بالاتر از آستانه‌های پایه نگهداری می‌شوند.

---

### مراجع

LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security
Generative AI's Biggest Security Flaw Is Not Easy to Fix
Many-shot jailbreaking \ Anthropic
$PDF$ OpenAI GPT-4.5 System Card
Notebook for the CheckThat Lab at CLEF 2024
Mitigate jailbreaks and prompt injections – Anthropic
Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis
OWASP Top 10 for LLM Applications 2025 – WorldTech IT
OWASP Machine Learning Security Top Ten
Few words about AI Security – Jussi Metso
How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry
Easily enforcing valid JSON schema following – API
AI Safety + Cybersecurity R\&D Tracker – Fairly AI
Anthropic makes 'jailbreak' advance to stop AI models producing harmful results
Pattern matching filter rules - IBM
Real-time Threat Detection

## مدیریت چرخه عمر مدل C3 و کنترل تغییرات

### هدف کنترل

سامانه‌های هوش مصنوعی باید فرایندهای کنترل تغییر را پیاده‌سازی کنند که از رسیدن تغییرات غیرمجاز یا ناایمن مدل به محیط تولید جلوگیری کند. این کنترل، یکپارچگی مدل را در کل چرخه عمر تضمین می‌کند—از توسعه گرفته تا استقرار و از رده خارج کردن—که امکان پاسخ‌دهی سریع به حوادث و حفظ مسئولیت‌پذیری برای همه تغییرات را فراهم می‌آورد.

هدف اصلی امنیتی: تنها مدل‌های مجاز و تأییدشده با استفاده از فرآیندهای کنترل‌شده که یکپارچگی، قابلیت ردیابی و بازیابی را حفظ می‌کنند، به مرحله تولید می‌رسند.

---

### C3.1 مجوزدهی مدل و یکپارچگی

فقط مدل‌های مجاز با صحت تایید شده به محیط‌های تولید می‌رسند.

 #3.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام مصنوعات مدل (وزن‌ها، پیکربندی‌ها، توکنایزرها) قبل از استقرار توسط نهادهای مجاز به صورت رمزنگاری شده امضا شده‌اند.
 #3.1.2    سطح: 1    نقش: D/V
 تأیید کنید که صحت مدل در زمان استقرار بررسی شود و شکست‌های تأیید امضا مانع بارگذاری مدل شوند.
 #3.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که سوابق منشأ مدل شامل هویت نهاد مجاز، چک‌سام‌های داده‌های آموزش، نتایج آزمون اعتبارسنجی با وضعیت قبول/عدم قبول، و یک نشان‌زمان ایجاد باشد.
 #3.1.4    سطح: 2    نقش: D/V
 تأیید کنید که تمام آثار مدل از نسخه‌بندی معنایی (MAJOR.MINOR.PATCH) استفاده می‌کنند و معیارهای مستند شده‌ای وجود دارد که مشخص می‌کند هر بخش از نسخه کی افزایش می‌یابد.
 #3.1.5    سطح: 2    نقش: V
 اطمینان حاصل کنید که پیگیری وابستگی یک موجودی زنده حفظ می‌کند که شناسایی سریع تمام سیستم‌های مصرف‌کننده را ممکن می‌سازد.

---

### اعتبارسنجی و آزمایش مدل C3.2

مدل‌ها باید قبل از استقرار، اعتبارسنجی‌های تعریف شده امنیت و ایمنی را گذرانده باشند.

 #3.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مدل‌ها تحت آزمایش امنیتی خودکار قرار می‌گیرند که شامل اعتبارسنجی ورودی، پاک‌سازی خروجی، و ارزیابی‌های ایمنی با آستانه‌های قبلاً توافق شده سازمانی برای قبول یا رد قبل از استقرار باشد.
 #3.2.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که خطاهای اعتبارسنجی پس از تأیید صریح جایگزین از سوی افراد مجاز پیش‌تعیین‌شده با توجیهات مستند کسب‌وکار، به‌طور خودکار مانع از استقرار مدل می‌شوند.
 #3.2.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که نتایج آزمایش به صورت رمزنگاری امضا شده و به طور غیرقابل تغییر به هش نسخه مدل خاصی که در حال اعتبارسنجی است متصل شده‌اند.
 #3.2.4    سطح: 2    نقش: D/V
 تأیید کنید که استقرارهای اضطراری نیازمند ارزیابی مستند ریسک امنیتی و تأیید از سوی مرجع امنیتی پیش‌تعیین‌شده در چارچوب زمانی از پیش توافق‌شده هستند.

---

### C3.3 استقرار کنترل شده و بازگشت

استقرار مدل‌ها باید کنترل‌شده، مانیتور شده و قابل بازگشت باشد.

 #3.3.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که استقرارهای تولید مکانیزم‌های راه‌اندازی تدریجی (استقرارهای کناری، استقرارهای آبی-سبز) را با ماشه‌های خودکار بازگردانی بر اساس نرخ‌های خطای از پیش توافق شده، آستانه‌های تأخیر یا معیارهای هشدار امنیتی پیاده‌سازی می‌کنند.
 #3.3.2    سطح: 1    نقش: D/V
 تأیید کنید که قابلیت‌های بازگردانی به‌طور اتمی وضعیت کامل مدل (وزن‌ها، تنظیمات، وابستگی‌ها) را در چهارچوب‌های زمانی سازمانی از پیش تعریف شده بازیابی می‌کنند.
 #3.3.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فرآیندهای استقرار امضاهای رمزنگاری شده را اعتبارسنجی کرده و پیش از فعال‌سازی مدل، مجموع‌های کنترل صحت را محاسبه می‌کنند و در صورت هرگونه عدم تطابق، استقرار را متوقف می‌کنند.
 #3.3.4    سطح: 2    نقش: D/V
 تأیید کنید که قابلیت‌های خاموش کردن اضطراری مدل قادر به غیرفعال کردن نقاط انتهایی مدل در زمان‌های پاسخ‌دهی از پیش تعریف شده از طریق قطع‌کننده‌های مدار خودکار یا کلیدهای قطع دستی باشند.
 #3.3.5    سطح: 2    نقش: V
 تأیید کنید که آثار بازگشت (نسخه‌های قبلی مدل، پیکربندی‌ها، وابستگی‌ها) مطابق با سیاست‌های سازمانی با استفاده از ذخیره‌سازی غیرقابل تغییر برای واکنش به حوادث حفظ می‌شوند.

---

### C3.4 تغییر مسئولیت‌پذیری و حسابرسی

تمام تغییرات چرخه عمر مدل باید قابل ردیابی و قابل حسابرسی باشد.

 #3.4.1    سطح: 1    نقش: V
 اطمینان حاصل کنید که همه تغییرات مدل (استقرار، پیکربندی، بازنشستگی) سوابق حسابرسی ثابت و تغییرناپذیر ایجاد می‌کنند که شامل یک نشان‌گر زمان، هویت بازیگر تأییدشده، نوع تغییر، و وضعیت‌های قبل/بعد باشد.
 #3.4.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که دسترسی به گزارش ممیزی نیازمند مجوز مناسب است و تمام تلاش‌های دسترسی با هویت کاربر و مهر زمانی ثبت می‌شوند.
 #3.4.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که قالب‌های پرامپت و پیام‌های سیستمی در مخازن گیت تحت کنترل نسخه قرار دارند و پیش از استقرار، بازبینی کد اجباری و تأیید از سوی بازبین‌های تعیین‌شده انجام می‌شود.
 #3.4.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که سوابق حسابرسی شامل جزئیات کافی (هش‌های مدل، عکس‌های پیکربندی، نسخه‌های وابستگی) باشند تا امکان بازسازی کامل وضعیت مدل برای هر زمان مشخص در دوره نگهداری فراهم شود.

---

### C3.5 رویه‌های توسعه امن

فرآیندهای توسعه و آموزش مدل باید از روش‌های امن پیروی کنند تا از به خطر افتادن جلوگیری شود.

 #3.5.1    سطح: 1    نقش: D
 تأیید کنید که محیط‌های توسعه مدل، تست و تولید به صورت فیزیکی یا منطقی جدا شده‌اند. این محیط‌ها هیچ زیرساخت مشترکی ندارند، کنترل‌های دسترسی مجزا دارند و ذخیره‌سازی داده‌ها به صورت ایزوله است.
 #3.5.2    سطح: 1    نقش: D
 تأیید کنید که آموزش مدل و بهینه‌سازی دقیق در محیط‌های جداگانه با دسترسی شبکه کنترل‌شده انجام شود.
 #3.5.3    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که منابع داده‌های آموزشی از طریق بررسی‌های صحت تأیید شده و از طریق منابع معتبر با زنجیره نگهداری مستند شده قبل از استفاده در توسعه مدل احراز هویت می‌شوند.
 #3.5.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که مصنوعات توسعه مدل (ابرپارامترها، اسکریپت‌های آموزش، فایل‌های پیکربندی) در کنترل نسخه ذخیره شده و قبل از استفاده در آموزش نیاز به تأیید بازبینی همتا دارند.

---

### C3.6 بازنشستگی و از رده خارج کردن مدل

مدل‌ها باید زمانی که دیگر نیازی به آن‌ها نیست یا مشکلات امنیتی شناسایی شده‌اند، به‌صورت امن بازنشسته شوند.

 #3.6.1    سطح: 1    نقش: D
 تأیید کنید که فرآیندهای بازنشستگی مدل به‌طور خودکار نمودارهای وابستگی را اسکن کرده، تمامی سیستم‌های مصرف‌کننده را شناسایی می‌کنند و دوره‌های اطلاع‌رسانی پیش‌توافق شده را قبل از بازنشستگی ارائه می‌دهند.
 #3.6.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که آثار مدل‌های بازنشسته به‌طور ایمن با استفاده از پاک‌سازی رمزنگاری یا بازنویسی چندباره مطابق با سیاست‌های مستند نگهداری داده‌ها و با گواهی‌های تأیید شده تخریب، پاک شده‌اند.
 #3.6.3    سطح: 2    نقش: V
 تأیید کنید که رویدادهای بازنشستگی مدل با زمان‌ثبت و هویت بازیگر ثبت شده‌اند و امضاهای مدل لغو شده‌اند تا از استفاده مجدد جلوگیری شود.
 #3.6.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که بازنشستگی اضطراری مدل می‌تواند دسترسی به مدل را در بازه‌های زمانی واکنش اضطراری از پیش تعیین شده از طریق سوئیچ‌های کشنده خودکار در صورت کشف آسیب‌پذیری‌های امنیتی حیاتی غیرفعال کند.

---

### مراجع

MLOps Principles
Securing AI/ML Ops – Cisco.com
Audit logs security: cryptographically signed tamper-proof logs
Machine Learning Model Versioning: Top Tools & Best Practices
AI Hygiene Starts with Models and Data Loaders – SEI Blog
How to handle versioning and rollback of a deployed ML model?
Reinforcement fine-tuning – OpenAI API
Auditing Machine Learning models: Governance, Data Security and …
Adversarial Training to Improve Model Robustness
What is AI adversarial robustness? – IBM Research
Exploring Data Provenance: Ensuring Data Integrity and Authenticity
MITRE ATLAS
AWS Prescriptive Guidance – Best practices for retiring applications …

## امنیت زیرساخت، پیکربندی و استقرار C4

### هدف کنترل

زیرساخت هوش مصنوعی باید از طریق پیکربندی امن، جداسازی زمان اجرا، خطوط تولید استقرار معتبر و نظارت جامع در برابر افزایش امتیازات، دستکاری در زنجیره تامین و حرکت جانبی مقاوم شود. تنها اجزای زیرساخت و پیکربندی‌های مجاز و تأیید شده از طریق فرآیندهای کنترل‌شده که امنیت، یکپارچگی و قابلیت حسابرسی را حفظ می‌کنند، به تولید می‌رسند.

هدف اصلی امنیتی: تنها اجزای زیرساختی که به صورت رمزنگاری شده امضاء شده و از نظر آسیب‌پذیری اسکن شده‌اند، از طریق خطوط اعتبارسنجی خودکار که سیاست‌های امنیتی را اجرا کرده و سوابق حسابرسی غیرقابل تغییر را حفظ می‌کنند، به مرحله تولید می‌رسند.

---

### C4.1 ایزولاسیون محیط اجرای زمان اجرا

جلوگیری از فرار از کانتینر و افزایش امتیازات از طریق اصول ایزولاسیون در سطح کرنل و کنترل‌های دسترسی اجباری.

 #4.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام کانتینرهای هوش مصنوعی تمامی قابلیت‌های لینوکس به جز CAP_SETUID، CAP_SETGID، و قابلیت‌های صریحاً مورد نیاز که در معیارهای امنیتی مستند شده‌اند را حذف می‌کنند.
 #4.1.2    سطح: 1    نقش: D/V
 تأیید کنید که پروفایل‌های seccomp تمامی فراخوانی‌های سیستمی را به جز آنهایی که در فهرست‌های مجاز پیش‌تأیید شده هستند، مسدود می‌کنند، به گونه‌ای که تخلفات باعث پایان یافتن کانتینر و ایجاد هشدارهای امنیتی می‌شود.
 #4.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که بارهای کاری هوش مصنوعی با سیستم فایل روت فقط خواندنی، tmpfs برای داده‌های موقت و حجم‌های نام‌گذاری شده برای داده‌های پایدار اجرا می‌شوند و گزینه‌های mount با noexec اعمال شده‌اند.
 #4.1.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مانیتورینگ زمان اجرا مبتنی بر eBPF (مانند Falco، Tetragon، یا معادل آن) تلاش‌های افزایش سطح دسترسی را شناسایی کرده و به‌طور خودکار فرآیندهای متخلف را در چارچوب زمان پاسخ سازمانی متوقف می‌کند.
 #4.1.5    سطح: 3    نقش: D/V
 تأیید کنید که بارهای کاری هوش مصنوعی با ریسک بالا در محیط‌های ایزوله‌شده سخت‌افزاری (Intel TXT، AMD SVM، یا گره‌های اختصاصی bare-metal) به همراه تأیید اعتبار اجرا شوند.

---

### C4.2 خطوط لوله ساخت و استقرار امن

اطمینان از صحت رمزنگاری و امنیت زنجیره تامین از طریق ساخت‌های قابل بازتولید و آثار امضا شده.

 #4.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که زیرساخت به عنوان کد با ابزارهایی مانند tfsec، Checkov، یا Terrascan در هر کامیت اسکن می‌شود و ادغام‌ها در صورت وجود یافته‌های با شدت CRITICAL یا HIGH مسدود می‌شوند.
 #4.2.2    سطح: 1    نقش: D/V
 تأیید کنید که ساخت کانتینرها با هش‌های SHA256 یکسان در تمام ساخت‌ها قابل بازتولید هستند و تصدیق‌نامه‌های اثبات منشأ SLSA سطح 3 با امضای Sigstore تولید کنید.
 #4.2.3    سطح: 2    نقش: D/V
 اطمینان حاصل شود که تصاویر کانتینر شامل SBOMهای CycloneDX یا SPDX هستند و قبل از بارگذاری در رجیستری با Cosign امضا شده‌اند، به گونه‌ای که تصاویر بدون امضا در زمان استقرار رد شوند.
 #4.2.4    سطح: 2    نقش: D/V
 تأیید کنید که خط لوله‌های CI/CD از توکن‌های OIDC استخراج شده از HashiCorp Vault، نقش‌های AWS IAM، یا هویت مدیریت شده Azure با زمان‌های حیات (lifetime) که از محدودیت‌های سیاست امنیتی سازمان بیشتر نباشند، استفاده می‌کنند.
 #4.2.5    سطح: 2    نقش: D/V
 تأیید کنید که امضاهای Cosign و منشأ SLSA در طول فرآیند استقرار قبل از اجرای کانتینر اعتبارسنجی می‌شوند و خطاهای تأیید باعث شکست استقرار می‌شوند.
 #4.2.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که محیط‌های ساخت در کانتینرهای موقت یا ماشین‌های مجازی اجرا می‌شوند که هیچ ذخیره‌سازی پایدار و ایزولاسیون شبکه‌ای از VPCهای تولید ندارند.

---

### C4.3 امنیت شبکه و کنترل دسترسی

اجرای شبکه‌سازی با اعتماد صفر با سیاست‌های پیش‌فرض رد و ارتباطات رمزگذاری‌شده.

 #4.3.1    سطح: 1    نقش: D/V
 بررسی کنید که NetworkPolicies در Kubernetes یا هر معادل آن، سیاست پیش‌فرض انکار دسترسی ورودی/خروجی را با قوانین صریح اجازه برای پورت‌های مورد نیاز (443، 8080 و غیره) اجرا می‌کند.
 #4.3.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که SSH (پورت 22)، RDP (پورت 3389)، و نقاط انتهایی متادیتای ابری (169.254.169.254) مسدود شده‌اند یا نیاز به احراز هویت مبتنی بر گواهی دارند.
 #4.3.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که ترافیک خروجی از طریق پراکسی‌های HTTP/HTTPS (Squid، Istio، یا دروازه‌های NAT ابری) با فهرست‌های مجاز دامنه فیلتر می‌شود و درخواست‌های مسدود شده ثبت می‌شوند.
 #4.3.4    سطح: 2    نقش: D/V
 تأیید کنید که ارتباط بین سرویس‌ها از TLS متقابل با گواهینامه‌هایی استفاده می‌کند که بر اساس سیاست سازمانی چرخش می‌یابند و اعتبارسنجی گواهینامه اعمال می‌شود (بدون استفاده از گزینه‌های skip-verify).
 #4.3.5    سطح: 2    نقش: D/V
 تأیید کنید که زیرساخت هوش مصنوعی در VPCها/VNetهای اختصاصی اجرا می‌شود که دسترسی مستقیم به اینترنت ندارند و فقط از طریق دروازه‌های NAT یا میزبان‌های باستین ارتباط برقرار می‌کنند.

---

### C4.4 مدیریت اسرار و کلیدهای رمزنگاری

حفاظت از اطلاعات ورود با استفاده از ذخیره‌سازی پشتیبانی‌شده توسط سخت‌افزار و چرخش خودکار با دسترسی اعتماد صفر.

 #4.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که اسرار در HashiCorp Vault، AWS Secrets Manager، Azure Key Vault یا Google Secret Manager با رمزگذاری در حالت استراحت با استفاده از AES-256 ذخیره شده‌اند.
 #4.4.2    سطح: 1    نقش: D/V
 تأیید کنید که کلیدهای رمزنگاری در HSMهای سطح 2 مطابق با استاندارد FIPS 140-2 (AWS CloudHSM، Azure Dedicated HSM) تولید شده‌اند و گردش کلیدها مطابق با سیاست رمزنگاری سازمانی انجام می‌شود.
 #4.4.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که چرخش رازها به صورت خودکار با استقرار بدون زمان توقف و چرخش فوری که توسط تغییرات کارکنان یا حوادث امنیتی تحریک می‌شود، انجام می‌گیرد.
 #4.4.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تصاویر کانتینر با ابزارهای (GitLeaks, TruffleHog, یا detect-secrets) اسکن می‌شوند تا ساخت‌هایی که شامل کلیدهای API، رمز عبور یا گواهی‌ها هستند، مسدود شوند.
 #4.4.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که دسترسی به کلید مخفی تولیدی نیازمند احراز هویت چندمرحله‌ای (MFA) با توکن‌های سخت‌افزاری (YubiKey، FIDO2) است و توسط لاگ‌های حسابرسی غیرقابل تغییر با شناسه کاربران و زمان‌های ثبت‌شده، ضبط می‌شود.
 #4.4.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اسرار از طریق Kubernetes secrets، حجم‌های متصل شده یا init containers وارد می‌شوند و مطمئن شوید که اسرار هرگز در متغیرهای محیطی یا تصاویر تعبیه نمی‌شوند.

---

### محیط ایزوله و اعتبارسنجی بار کاری هوش مصنوعی C4.5

مدل‌های هوش مصنوعی نامعتبر را در محیط‌های ایزوله‌شده امن با تحلیل کامل رفتاری جدا کنید.

 #4.5.1    سطح: 1    نقش: D/V
 تأیید کنید که مدل‌های هوش مصنوعی خارجی در gVisor، میکروVMها (مانند Firecracker، CrossVM) یا کانتینرهای داکر با گزینه‌های --security-opt=no-new-privileges و --read-only اجرا می‌شوند.
 #4.5.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که محیط‌های شبیه‌سازی شده هیچ اتصال شبکه‌ای ندارند (--network=none) یا تنها به localhost دسترسی دارند و تمام درخواست‌های خارجی توسط قوانین iptables مسدود شده‌اند.
 #4.5.3    سطح: 2    نقش: D/V
 تأیید کنید که اعتبارسنجی مدل هوش مصنوعی شامل تست خودکار تیم قرمز با پوشش تست تعریف‌شده سازمانی و تحلیل رفتاری برای کشف درهای پشتی باشد.
 #4.5.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که قبل از ارتقاء یک مدل هوش مصنوعی به محیط تولید، نتایج محیط آزمایشی آن توسط پرسنل امنیتی مجاز به صورت رمزنگاری شده امضا شده و در لاگ‌های ممیزی غیرقابل تغییر ذخیره می‌شوند.
 #4.5.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که محیط‌های شبیه‌سازی (sandbox) پس از هر ارزیابی، از تصاویر طلایی (golden images) پاک‌سازی شده و بازسازی می‌شوند، به طوری که پاک‌سازی کامل سیستم فایل و حافظه انجام شده باشد.

---

### C4.6 نظارت بر امنیت زیرساخت

زیرساخت را به طور مداوم اسکن و نظارت کنید با بازسازی خودکار و هشداردهی در زمان واقعی.

 #4.6.1    سطح: 1    نقش: D/V
 تأیید کنید که تصاویر کانتینر طبق برنامه‌های سازمانی اسکن شده باشند و آسیب‌پذیری‌های حیاتی (CRITICAL) بر اساس آستانه‌های ریسک سازمانی، مانع از استقرار شوند.
 #4.6.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که زیرساخت مطابق با معیارهای CIS یا کنترل‌های NIST 800-53 با آستانه‌های انطباق تعریف‌شده سازمانی باشد و اصلاح خودکار برای بررسی‌های ناموفق انجام شود.
 #4.6.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که آسیب‌پذیری‌های با شدت بالا بر اساس جدول زمانی مدیریت ریسک سازمانی وصله‌گذاری شده‌اند و برای CVEهای فعال که در حال بهره‌برداری هستند، رویه‌های اضطراری وجود دارد.
 #4.6.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که هشدارهای امنیتی با پلتفرم‌های SIEM (اسپلانک، الاستیک، یا سنتینل) با استفاده از فرمت‌های CEF یا STIX/TAXII با تقویت خودکار ادغام می‌شوند.
 #4.6.5    سطح: 3    نقش: V
 تأیید کنید که معیارهای زیرساخت به سیستم‌های نظارتی (Prometheus, DataDog) با داشبوردهای SLA و گزارش‌دهی اجرایی صادر می‌شوند.
 #4.6.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که انحراف پیکربندی با استفاده از ابزارها (Chef InSpec، AWS Config) مطابق با الزامات نظارت سازمانی شناسایی می‌شود و بازگردانی خودکار برای تغییرات غیرمجاز انجام می‌شود.

---

### مدیریت منابع زیرساخت هوش مصنوعی C4.7

جلوگیری از حملات تخلیه منابع و اطمینان از تخصیص عادلانه منابع از طریق سهمیه‌بندی و نظارت.

 #4.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که استفاده از GPU/TPU با هشدارهایی که در آستانه‌های تعریف شده سازمانی فعال می‌شوند، نظارت می‌شود و مقیاس‌بندی خودکار یا تعادل بار بر اساس سیاست‌های مدیریت ظرفیت فعال می‌گردد.
 #4.7.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که معیارهای بار کاری هوش مصنوعی (تاخیر استنتاج، توان عملیاتی، نرخ خطا) مطابق با الزامات نظارتی سازمان جمع‌آوری شده و با استفاده زیرساخت همبسته شده‌اند.
 #4.7.3    سطح: 2    نقش: D/V
 تأیید کنید که ResourceQuotas در Kubernetes یا معادل آن، بارهای کاری فردی را مطابق با سیاست‌های تخصیص منابع سازمانی محدود می‌کنند و محدودیت‌های سختگیرانه اعمال می‌شود.
 #4.7.4    سطح: 2    نقش: V
 تأیید کنید که نظارت بر هزینه‌ها، هزینه‌ها را بر اساس بار کاری/مستأجر پیگیری می‌کند و هشدارهایی براساس آستانه‌های بودجه سازمانی و کنترل‌های خودکار برای تجاوز از بودجه ارائه می‌دهد.
 #4.7.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که برنامه‌ریزی ظرفیت از داده‌های تاریخی با دوره‌های پیش‌بینی تعیین‌شده توسط سازمان و تأمین منابع خودکار مبتنی بر الگوهای تقاضا استفاده می‌کند.
 #4.7.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اتمام منابع، مدار شکن‌ها را بر اساس الزامات پاسخ سازمانی فعال می‌کند، از جمله محدود کردن نرخ بر اساس سیاست‌های ظرفیت و جداسازی بار کاری.

---

### C4.8 تفکیک محیط و کنترل‌های ارتقا

اجرای مرزهای محیطی سختگیرانه با دروازه‌های ارتقاء خودکار و اعتبارسنجی امنیتی.

 #4.8.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که محیط‌های توسعه/آزمایش/تولید در VPCs/VNets جداگانه اجرا می‌شوند و هیچ نقش IAM، گروه‌های امنیتی یا اتصال شبکه مشترکی ندارند.
 #4.8.2    سطح: 1    نقش: D/V
 تأیید کنید که ارتقاء محیط نیازمند تأیید از سوی پرسنل مجاز تعریف شده سازمانی با امضاهای رمزنگاری شده و ردپاهای حسابرسی غیرقابل تغییر است.
 #4.8.3    سطح: 2    نقش: D/V
 تأیید کنید که محیط‌های تولید دسترسی SSH را مسدود می‌کنند، نقاط پایان دیباگ را غیرفعال می‌کنند و درخواست‌های تغییر را با الزامات اطلاع‌رسانی قبلی سازمانی به جز در مواقع اضطراری نیاز دارند.
 #4.8.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تغییرات زیرساخت به‌عنوان کد قبل از ادغام به شاخه اصلی نیاز به بازبینی همتا همراه با آزمایش‌های خودکار و اسکن امنیتی دارند.
 #4.8.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که داده‌های غیرتولیدی مطابق با الزامات حریم خصوصی سازمانی ناشناس‌سازی شده‌اند، تولید داده‌های مصنوعی انجام شده یا ماسک‌گذاری کامل داده‌ها با حذف اطلاعات شناسایی فردی (PII) تأیید شده است.
 #4.8.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که دروازه‌های ارتقا شامل تست‌های امنیتی خودکار (SAST، DAST، اسکن کانتینر) با نیاز به صفر یافته بحرانی برای تایید باشد.

---

### پشتیبان‌گیری و بازیابی زیرساخت C4.9

اطمینان از مقاومت زیرساخت از طریق پشتیبان‌گیری خودکار، آزمایش روش‌های بازیابی و قابلیت‌های بازیابی از فاجعه.

 #4.9.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که پیکربندی‌های زیرساخت طبق برنامه‌های پشتیبان‌گیری سازمانی به مناطق جغرافیایی جداگانه با اجرای استراتژی پشتیبان‌گیری 3-2-1 پشتیبان‌گیری شده‌اند.
 #4.9.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های پشتیبان‌گیری در شبکه‌های جداگانه با اعتبارنامه‌های مجزا و ذخیره‌سازی ایزوله برای حفاظت در برابر باج‌افزار اجرا می‌شوند.
 #4.9.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که رویه‌های بازیابی مطابق با برنامه‌های سازمانی با اهداف RTO و RPO که مطابق با نیازهای سازمانی هستند، از طریق آزمایش خودکار تست و اعتبارسنجی می‌شوند.
 #4.9.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که بازیابی از فاجعه شامل کتاب‌های راهنمای مخصوص هوش مصنوعی با بازگردانی وزن مدل، بازسازی خوشه GPU، و نقشه‌برداری وابستگی‌های سرویس باشد.

---

### C4.10 انطباق زیرساخت و حاکمیت

حفظ انطباق با مقررات از طریق ارزیابی مداوم، مستندسازی و کنترل‌های خودکار.

 #4.10.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که رعایت الزامات زیرساخت بر اساس برنامه‌های سازمانی و با استفاده از جمع‌آوری خودکار شواهد، نسبت به کنترل‌های SOC 2، ISO 27001، یا FedRAMP ارزیابی می‌شود.
 #4.10.2    سطح: 2    نقش: V
 اطمینان حاصل کنید که مستندات زیرساخت شامل نمودارهای شبکه، نقشه‌های جریان داده و مدل‌های تهدید به‌روزرسانی شده مطابق با الزامات مدیریت تغییر سازمانی باشد.
 #4.10.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تغییرات زیرساختی از ارزیابی تأثیر انطباق خودکار با گردش‌کارهای تأییدیه نظارتی برای تغییرات با ریسک بالا عبور می‌کنند.

---

### C4.11 امنیت سخت‌افزار هوش مصنوعی

قطعات سخت‌افزاری مخصوص هوش مصنوعی مانند GPUها، TPUها و شتاب‌دهنده‌های تخصصی هوش مصنوعی را ایمن کنید.

 #4.11.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که firmware شتاب‌دهنده هوش مصنوعی (GPU BIOS، firmware TPU) با امضاهای رمزنگاری شده تایید شده و طبق زمان‌بندی مدیریت به‌روزرسانی سازمانی به‌روزرسانی می‌شود.
 #4.11.2    سطح: 2    نقش: D/V
 تأیید کنید که پیش از اجرای بار کاری، یکپارچگی شتاب‌دهنده هوش مصنوعی از طریق گواهی‌نامه سخت‌افزاری با استفاده از TPM 2.0، Intel TXT، یا AMD SVM تایید شده باشد.
 #4.11.3    سطح: 2    نقش: D/V
 تأیید کنید که حافظه GPU بین بارهای کاری با استفاده از SR-IOV، MIG (واحد چند نمونه‌ای GPU) یا تقسیم‌بندی سخت‌افزاری معادل با پاک‌سازی حافظه بین وظایف، به‌صورت ایزوله شده باشد.
 #4.11.4    سطح: 3    نقش: V
 تأیید کنید که زنجیره تأمین سخت‌افزار هوش مصنوعی شامل تأیید اصالت با گواهی‌های تولیدکننده و اعتبارسنجی بسته‌بندی ضد دست‌کاری باشد.
 #4.11.5    سطح: 3    نقش: D/V
 تأیید کنید که ماژول‌های امنیت سخت‌افزاری (HSMها) وزن‌های مدل هوش مصنوعی و کلیدهای رمزنگاری را با گواهی‌نامه FIPS 140-2 سطح 3 یا Common Criteria EAL4+ محافظت می‌کنند.

---

### C4.12 زیرساخت هوش مصنوعی لبه‌ای و توزیع‌شده

استقرارهای هوش مصنوعی توزیع‌شده امن شامل محاسبات لبه، یادگیری فدراسیونی، و معماری‌های چندسایت.

 #4.12.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که دستگاه‌های edge AI با استفاده از TLS متقابل و گواهی‌نامه‌های دستگاهی که مطابق با سیاست مدیریت گواهی‌نامه‌های سازمانی دوره‌ای تعویض می‌شوند، به زیرساخت مرکزی احراز هویت می‌شوند.
 #4.12.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که دستگاه‌های مرزی بوت امن را با امضاهای تایید شده و حفاظت در برابر برگشت به نسخه قبلی اجرا می‌کنند تا از حملات کاهش نسخه فرم‌ور جلوگیری شود.
 #4.12.3    سطح: 3    نقش: D/V
 تأیید کنید که هماهنگی هوش مصنوعی توزیع‌شده از الگوریتم‌های اجماع تحمل خطای بیزانسی با اعتبارسنجی شرکت‌کنندگان و شناسایی گره‌های مخرب استفاده می‌کند.
 #4.12.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که ارتباط لبه به ابر شامل کنترل پهنای باند، فشرده‌سازی داده‌ها و قابلیت‌های عملیات آفلاین با ذخیره‌سازی محلی امن می‌باشد.

---

### C4.13 امنیت زیرساخت چند ابری و ترکیبی

ایمن‌سازی بارهای کاری هوش مصنوعی در چندین ارائه‌دهنده ابر و استقرارهای ترکیبی ابر-محلی.

 #4.13.1    سطح: 2    نقش: D/V
 تأیید کنید که استقرارهای هوش مصنوعی چند ابری از فدراسیون هویت مستقل از ابر (OIDC، SAML) با مدیریت مرکزی سیاست‌ها در سراسر ارائه‌دهندگان استفاده می‌کنند.
 #4.13.2    سطح: 2    نقش: D/V
 تأیید کنید که انتقال داده بین ابرها از رمزگذاری انتها به انتها با کلیدهای مدیریتی توسط مشتری و کنترل‌های محل داده مطابق با قوانین حوزه قضایی استفاده می‌کند.
 #4.13.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که بارهای کاری هوش مصنوعی در ابر ترکیبی سیاست‌های امنیتی سازگاری را در محیط‌های محلی و ابری با نظارت و هشداردهی یکپارچه اجرا می‌کنند.
 #4.13.4    سطح: 3    نقش: V
 تأیید کنید که پیشگیری از قفل شدن در فروشنده ابر شامل زیرساخت قابل حمل به صورت کد، APIهای استاندارد شده و قابلیت‌های صادرات داده با ابزارهای تبدیل فرمت باشد.
 #4.13.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که بهینه‌سازی هزینه چندابری شامل کنترل‌های امنیتی برای جلوگیری از پراکندگی منابع و همچنین هزینه‌های انتقال داده‌های غیرمجاز بین ابری است.

---

### C4.14 امنیت اتوماسیون زیرساخت و GitOps

خطوط خودکارسازی زیرساخت امن و گردش‌کارهای GitOps برای مدیریت زیرساخت هوش مصنوعی.

 #4.14.1    سطح: 2    نقش: D/V
 تأیید کنید که مخازن GitOps نیاز به کامیت‌های امضاشده با کلیدهای GPG دارند و قوانین حفاظت از شاخه وجود دارد که از ارسال مستقیم به شاخه‌های اصلی جلوگیری می‌کند.
 #4.14.2    سطح: 2    نقش: D/V
 تأیید کنید که خودکارسازی زیرساخت شامل شناسایی انحراف با قابلیت‌های اصلاح خودکار و بازگردانی است که بر اساس الزامات پاسخ سازمانی برای تغییرات غیرمجاز فعال می‌شوند.
 #4.14.3    سطح: 2    نقش: D/V
 تأیید کنید که تأمین زیرساخت خودکار شامل اعتبارسنجی سیاست امنیتی با مسدودسازی استقرار برای پیکربندی‌های غیرمطابق باشد.
 #4.14.4    سطح: 2    نقش: D/V
 تأیید کنید که اسرار خودکارسازی زیرساخت از طریق اپراتورهای اسرار خارجی (External Secrets Operator، Bank-Vaults) با چرخش خودکار مدیریت می‌شوند.
 #4.14.5    سطح: 3    نقش: V
 تأیید کنید که زیرساخت خودترمیم شامل همبستگی رویدادهای امنیتی با پاسخ خودکار به حادثه و جریان‌های کاری اطلاع‌رسانی به ذینفعان باشد.

---

### C4.15 امنیت زیرساخت مقاوم در برابر کوانتوم

زیرساخت هوش مصنوعی را برای تهدیدات محاسبات کوانتومی از طریق رمزنگاری پساکوانتومی و پروتکل‌های امن در برابر کوانتوم آماده کنید.

 #4.15.1    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که زیرساخت هوش مصنوعی الگوریتم‌های رمزنگاری پساکوانتومی تأیید شده توسط NIST (CRYSTALS-Kyber، CRYSTALS-Dilithium، SPHINCS+) را برای تبادل کلید و امضاهای دیجیتال پیاده‌سازی می‌کند.
 #4.15.2    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های توزیع کلید کوانتومی (QKD) برای ارتباطات هوش مصنوعی با امنیت بالا با پروتکل‌های مدیریت کلید مقاوم در برابر کوانتوم پیاده‌سازی شده‌اند.
 #4.15.3    سطح: 3    نقش: D/V
 تأیید کنید که چارچوب‌های چابکی رمزنگاری، مهاجرت سریع به الگوریتم‌های جدید پساکمی را با چرخش خودکار گواهینامه و کلید امکان‌پذیر می‌سازند.
 #4.15.4    سطح: 3    نقش: V
 تأیید کنید که مدل‌سازی تهدید کوانتومی آسیب‌پذیری زیرساخت هوش مصنوعی در برابر حملات کوانتومی را با زمان‌بندی‌های مستندسازی شده برای مهاجرت و ارزیابی ریسک‌ها بررسی می‌کند.
 #4.15.5    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های رمزنگاری ترکیبی کلاسیک-کوانتومی در طول دوره گذار کوانتومی با پایش عملکرد، دفاع به‌عمق را فراهم می‌کنند.

---

### C4.16 محاسبات محرمانه و محفظه‌های امن

محافظت از بارهای کاری هوش مصنوعی و وزن‌های مدل با استفاده از محیط‌های اجرای مورد اعتماد مبتنی بر سخت‌افزار و فناوری‌های محاسبات محرمانه.

 #4.16.1    سطح: 3    نقش: D/V
 تأیید کنید که مدل‌های حساس هوش مصنوعی در درون محفظه‌های Intel SGX، AMD SEV-SNP، یا ARM TrustZone با حافظه رمزگذاری شده و تأیید صحت اجرا می‌شوند.
 #4.16.2    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که کانتینرهای محرمانه (Kata Containers، gVisor با محاسبات محرمانه) بارهای کاری هوش مصنوعی را با رمزنگاری حافظه تحت سخت‌افزار جدا می‌کنند.
 #4.16.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تایید از راه دور صحت محیط امن (enclave) را قبل از بارگذاری مدل‌های هوش مصنوعی با استفاده از مدرک رمزنگاری شده از اصالت محیط اجرای آن تأیید می‌کند.
 #4.16.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که خدمات استنتاج محرمانه هوش مصنوعی از استخراج مدل جلوگیری می‌کنند از طریق محاسبات رمزنگاری شده با وزن‌های مدل مهر و موم شده و اجرای محافظت شده.
 #4.16.5    سطح: 3    نقش: D/V
 تأیید کنید که ارکستراسیون محیط اجرای مورد اعتماد، چرخه عمر منطقه امن را با تصدیق از راه دور و کانال‌های ارتباطی رمزنگاری شده مدیریت می‌کند.
 #4.16.6    سطح: 3    نقش: D/V
 تأیید کنید که محاسبات چندجانبه امن (SMPC) امکان آموزش مشترک هوش مصنوعی را بدون افشای مجموعه داده‌ها یا پارامترهای مدل فردی فراهم می‌کند.

---

### C4.17 زیرساخت دانش صفر

پیاده‌سازی سیستم‌های اثبات دانش صفر برای تأیید و احراز هویت هوش مصنوعی حفظ‌کننده حریم خصوصی بدون افشای اطلاعات حساس.

 #4.17.1    سطح: 3    نقش: D/V
 تأیید کنید که اثبات‌های دانش صفر (ZK-SNARKs، ZK-STARKs) صحت مدل هوش مصنوعی و منشاء آموزش آن را بدون افشای وزن‌های مدل یا داده‌های آموزشی راستی‌آزمایی می‌کنند.
 #4.17.2    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های احراز هویت مبتنی بر ZK امکان تأیید هویت کاربران به صورت حفظ‌کننده حریم خصوصی برای خدمات هوش مصنوعی را بدون افشای اطلاعات مربوط به هویت فراهم می‌کنند.
 #4.17.3    سطح: 3    نقش: D/V
 تأیید کنید که پروتکل‌های تقاطع مجموعه خصوصی (PSI) امکان تطبیق امن داده‌ها را برای هوش مصنوعی فدرال شده بدون افشای مجموعه داده‌های فردی فراهم می‌کنند.
 #4.17.4    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های یادگیری ماشینی بدون دانش صفر (ZKML) استنتاج‌های هوش مصنوعی قابل تأیید را با اثبات رمزنگاری شده محاسبه صحیح امکان‌پذیر می‌سازند.
 #4.17.5    سطح: 3    نقش: D/V
 تأیید کنید که ZK-rollups پردازش تراکنش‌های هوش مصنوعی مقیاس‌پذیر و حفظ‌کننده حریم خصوصی را با تأیید گروهی و کاهش بار محاسباتی فراهم می‌کند.

---

### C4.18 پیشگیری از حمله کانال جانبی

محافظت از زیرساخت هوش مصنوعی در برابر حملات جانبی مبتنی بر زمان، توان، الکترومغناطیس و کش که ممکن است اطلاعات حساس را فاش کنند.

 #4.18.1    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که زمان‌بندی استنتاج هوش مصنوعی با استفاده از الگوریتم‌های زمان‌ثابت و افزودن پدینگ نرمال‌سازی شده است تا از حملات استخراج مدل مبتنی بر زمان جلوگیری شود.
 #4.18.2    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که حفاظت در برابر تحلیل توان شامل تزریق نویز، فیلتر کردن خط توان و الگوهای اجرای تصادفی برای سخت‌افزار هوش مصنوعی باشد.
 #4.18.3    سطح: 3    نقش: D/V
 تأیید کنید که کاهش‌دهی کانال فرعی مبتنی بر کش از تقسیم‌بندی کش، تصادفی‌سازی و دستورالعمل‌های پاک‌سازی برای جلوگیری از نشت اطلاعات استفاده می‌کند.
 #4.18.4    سطح: 3    نقش: D/V
 تأیید کنید که حفاظت از نشر الکترومغناطیسی شامل پوشش‌دهی (شیلدینگ)، فیلتر کردن سیگنال، و پردازش تصادفی برای جلوگیری از حملات سبک TEMPEST باشد.
 #4.18.5    سطح: 3    نقش: D/V
 تأیید کنید که تدابیر دفاعی در برابر کانال جانبی میکرومعماری شامل کنترل‌های اجرای حدسی و مبهم‌سازی الگوهای دسترسی به حافظه هستند.

---

### C4.19 امنیت سخت‌افزار نورومورفیک و هوش مصنوعی تخصصی

امن‌سازی معماری‌های سخت‌افزاری نوظهور هوش مصنوعی از جمله تراشه‌های نورومورفیک، FPGAها، ASICهای سفارشی و سیستم‌های محاسبات نوری.

 #4.19.1    سطح: 3    نقش: D/V
 تأیید کنید که امنیت تراشه‌های نورو مورفیک شامل رمزنگاری الگوهای اسپایک، محافظت از وزن سیناپسی و اعتبارسنجی قواعد یادگیری مبتنی بر سخت‌افزار باشد.
 #4.19.2    سطح: 3    نقش: D/V
 تأیید کنید که شتاب‌دهنده‌های هوش مصنوعی مبتنی بر FPGA رمزگذاری بیت‌استریم، مکانیزم‌های ضد دست‌کاری و بارگذاری پیکربندی امن با به‌روزرسانی‌های احراز هویت شده را پیاده‌سازی می‌کنند.
 #4.19.3    سطح: 3    نقش: D/V
 تأیید کنید که امنیت سفارشی ASIC شامل پردازنده‌های امنیتی روی چیپ، ریشه اعتماد سخت‌افزاری و ذخیره‌سازی کلید ایمن با تشخیص دستکاری باشد.
 #4.19.4    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های محاسباتی نوری، رمزنگاری نوری ایمن در برابر کوانتوم، سوییچینگ فوتونی امن و پردازش سیگنال نوری محافظت شده را پیاده‌سازی می‌کنند.
 #4.19.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تراشه‌های هوش مصنوعی هیبریدی آنالوگ-دیجیتال شامل محاسبات امن آنالوگ، ذخیره‌سازی محافظت‌شده وزن‌ها و تبدیل آنالوگ به دیجیتال احراز هویت‌شده هستند.

---

### C4.20 زیرساخت محاسباتی حفظ حریم خصوصی

کنترل‌های زیرساختی برای محاسبات حفظ حریم خصوصی پیاده‌سازی کنید تا داده‌های حساس در طول پردازش و تحلیل هوش مصنوعی محافظت شوند.

 #4.20.1    سطح: 3    نقش: D/V
 تأیید کنید که زیرساخت رمزنگاری همومورفیک امکان محاسبات رمزگذاری شده روی بارهای کاری حساس هوش مصنوعی را با صحت‌سنجی رمزنگاری و مانیتورینگ عملکرد فراهم می‌کند.
 #4.20.2    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های بازیابی اطلاعات خصوصی اجازه انجام پرس‌وجوهای پایگاه داده را بدون فاش کردن الگوهای پرس‌وجو با حفاظت رمزنگاری‌شده الگوهای دسترسی می‌دهند.
 #4.20.3    سطح: 3    نقش: D/V
 تأیید کنید که پروتکل‌های محاسبات چندجانبه امن امکان انجام استنتاج هوش مصنوعی حفظ‌کننده حریم خصوصی را بدون افشای ورودی‌های فردی یا محاسبات میانی فراهم می‌کنند.
 #4.20.4    سطح: 3    نقش: D/V
 تأیید کنید که مدیریت کلید حفظ حریم خصوصی شامل تولید کلید توزیع‌شده، رمزنگاری آستانه‌ای و چرخش امن کلید با محافظت مبتنی بر سخت‌افزار می‌باشد.
 #4.20.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که عملکرد محاسباتی حفظ حریم خصوصی از طریق دسته‌بندی، کشینگ و تسریع سخت‌افزاری بهینه شده است در حالی که تضمین‌های امنیت رمزنگاری حفظ می‌شوند.

---

### امنیت یکپارچه‌سازی ابر چارچوب عامل C4.15 و استقرار ترکیبی

کنترل‌های امنیتی برای چارچوب‌های عامل یکپارچه با ابر با معماری‌های ترکیبی در محل/ابر.

 #4.15.1    سطح: 1    نقش: D/V
 تأیید کنید که یکپارچه‌سازی ذخیره‌سازی ابری از رمزگذاری انتها به انتها با مدیریت کلید کنترل‌شده توسط عامل استفاده می‌کند.
 #4.15.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مرزهای امنیتی استقرار ترکیبی به طور واضح تعریف شده‌اند و کانال‌های ارتباطی رمزگذاری شده هستند.
 #4.15.3    سطح: 2    نقش: D/V
 تأیید کنید که دسترسی به منابع ابری شامل بررسی صفر-اعتمادی با احراز هویت مداوم است.
 #4.15.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که الزامات محل اقامت داده با تأیید رمزنگاری شده مکان‌های ذخیره‌سازی اجرا می‌شود.
 #4.15.5    سطح: 3    نقش: D/V
 تأیید کنید که ارزیابی‌های امنیتی ارائه‌دهنده‌ی ابری شامل مدل‌سازی تهدید مخصوص نماینده و ارزیابی ریسک باشد.

---

### مراجع

NIST Cybersecurity Framework 2.0
CIS Controls v8
OWASP Container Security Verification Standard
Kubernetes Security Best Practices
SLSA Supply Chain Security Framework
NIST SP 800-190: Application Container Security Guide
Cloud Security Alliance: Cloud Controls Matrix
ENISA: Secure Infrastructure Design
NIST SP 800-53: Security Controls for Federal Information Systems
ISO 27001:2022 Information Security Management
NIST AI Risk Management Framework
CIS Kubernetes Benchmark
FIPS 140-2 Security Requirements
NIST SP 800-207: Zero Trust Architecture
IEEE 2857: Privacy Engineering for AI Systems
NIST SP 800-161: Cybersecurity Supply Chain Risk Management
NIST Post-Quantum Cryptography Standards
Intel SGX Developer Guide
AMD SEV-SNP White Paper
ARM TrustZone Technology
ZK-SNARKs: A Gentle Introduction
NIST SP 800-57: Cryptographic Key Management
Side-Channel Attack Countermeasures
Neuromorphic Computing Security Challenges
FPGA Security: Fundamentals, Evaluation, and Countermeasures
Microsoft SEAL: Homomorphic Encryption Library
HElib: Homomorphic Encryption Library
PALISADE Lattice Cryptography Library
Differential Privacy: A Survey of Results
Secure Aggregation for Federated Learning
Private Information Retrieval: Concepts and Constructions

## کنترل دسترسی C5 و هویت برای مؤلفه‌ها و کاربران هوش مصنوعی

### هدف کنترل

کنترل دسترسی مؤثر برای سیستم‌های هوش مصنوعی نیازمند مدیریت هویت قوی، مجوزدهی مبتنی بر زمینه و اجرای زمان اجرا بر اساس اصول اعتماد صفر است. این کنترل‌ها تضمین می‌کنند که انسان‌ها، خدمات و عامل‌های خودمختار تنها در محدوده‌های صریحاً مجاز با مدل‌ها، داده‌ها و منابع محاسباتی تعامل داشته باشند، همراه با قابلیت‌های تأیید و حسابرسی مداوم.

---

### C5.1 مدیریت هویت و احراز هویت

ایجاد هویت‌های مبتنی بر رمزنگاری برای همه نهادها همراه با احراز هویت چندعاملی برای عملیات دارای امتیاز دسترسی.

 #5.1.1    سطح: 1    نقش: D/V
 تأیید کنید که تمام کاربران انسانی و اصول سرویس از طریق یک ارائه‌دهنده هویت سازمانی مرکزی (IdP) با استفاده از پروتکل‌های OIDC/SAML با نگاشت‌های منحصربه‌فرد هویت به توکن (بدون حساب‌ها یا مدارک مشترک) احراز هویت می‌شوند.
 #5.1.2    سطح: 1    نقش: D/V
 تأیید کنید که عملیات‌های با ریسک بالا (استقرار مدل، صدور وزن، دسترسی به داده‌های آموزش، تغییرات در پیکربندی تولید) نیازمند احراز هویت چندعاملی یا احراز هویت مرحله‌ای با اعتبارسنجی مجدد جلسه هستند.
 #5.1.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که مدیران جدید قبل از دریافت دسترسی به سیستم تولید، مراحل احراز هویت را مطابق با استاندارد NIST 800-63-3 IAL-2 یا استانداردهای معادل انجام دهند.
 #5.1.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که بررسی‌های دسترسی به‌صورت فصلی انجام می‌شوند، با شناسایی خودکار حساب‌های غیرفعال، اعمال چرخش مدارک و فرآیندهای حذف دسترسی.
 #5.1.5    سطح: 3    نقش: D/V
 تأیید کنید که عوامل هوش مصنوعی فدرال از طریق تأیید هویت با توکن‌های JWT امضا شده که حداکثر عمر آنها 24 ساعت است و شامل اثبات رمزنگاری شده منشأ می‌باشند، احراز هویت می‌شوند.

---

### C5.2 مجوز منابع و حداقل امتیاز

پیاده‌سازی کنترل‌های دسترسی دقیق برای تمام منابع هوش مصنوعی با مدل‌های اجازه‌دهی صریح و مسیرهای حسابرسی.

 #5.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر منبع هوش مصنوعی (مجموعه داده‌ها، مدل‌ها، نقاط انتهایی، مجموعه‌های برداری، شاخص‌های جاسازی، نمونه‌های محاسباتی) کنترل‌های دسترسی مبتنی بر نقش را با فهرست‌های مجاز صریح و سیاست‌های پیش‌فرض انکار اعمال می‌کند.
 #5.2.2    سطح: 1    نقش: D/V
 تأیید کنید که اصول حداقل امتیاز به صورت پیش‌فرض در حساب‌های سرویس اعمال شده است، به طوری که دسترسی‌ها از مجوزهای فقط خواندنی شروع شده و برای دسترسی نوشتنی توجیه کسب‌وکار مستند شده لازم باشد.
 #5.2.3    سطح: 1    نقش: V
 اطمینان حاصل کنید که تمام تغییرات کنترل دسترسی به درخواست‌های تغییر تأیید شده مرتبط هستند و به‌صورت تغییرناپذیر با زمان‌بندی‌ها، هویت بازیگران، شناسه‌های منابع و تغییرات دسترسی ثبت شده‌اند.
 #5.2.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که برچسب‌های طبقه‌بندی داده‌ها (اطلاعات شناسایی شخصی - PII، اطلاعات سلامت شخصی - PHI، کنترل صادرات، مالکیتی) به‌صورت خودکار به منابع مشتق شده (تعبیه‌ها، کش‌های پرامپت، خروجی‌های مدل) منتقل شده و سیاست‌های مرتبط به‌صورت یکپارچه اجرا شوند.
 #5.2.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تلاش‌های دسترسی غیرمجاز و رویدادهای افزایش امتیاز به صورت لحظه‌ای همراه با فراداده‌ متنی به سیستم‌های SIEM در مدت کمتر از 5 دقیقه هشدار ارسال می‌کنند.

---

### C5.3 ارزیابی سیاست پویا

استقرار موتورهای کنترل دسترسی مبتنی بر ویژگی (ABAC) برای تصمیم‌گیری‌های مجوزدهی مبتنی بر زمینه با قابلیت‌های ممیزی.

 #5.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تصمیمات تأیید هویت به یک موتور سیاست اختصاصی (OPA، Cedar، یا معادل آن) برون‌سپاری شده‌اند که از طریق APIهای احراز هویت شده و با حفاظت از صحت رمزنگاری قابل دسترسی باشد.
 #5.3.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیاست‌ها خصوصیات دینامیک را در زمان اجرا ارزیابی می‌کنند، از جمله سطح مجوز کاربر، طبقه‌بندی حساسیت منبع، زمینه درخواست، جداسازی مستاجر و محدودیت‌های زمانی.
 #5.3.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که تعریف‌های سیاست‌ها تحت کنترل نسخه قرار دارند، توسط همتایان بررسی شده‌اند، و قبل از استقرار در تولید از طریق تست‌های خودکار در خطوط CI/CD اعتبارسنجی شده‌اند.
 #5.3.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که نتایج ارزیابی سیاست شامل دلایل ساختاریافته تصمیم‌گیری است و به سیستم‌های SIEM برای تحلیل همبستگی و گزارش‌دهی انطباق ارسال می‌شود.
 #5.3.5    سطح: 3    نقش: D/V
 تأیید کنید که مقادیر زمان زندگی (TTL) کش سیاست برای منابع با حساسیت بالا از ۵ دقیقه و برای منابع استاندارد با قابلیت باطل‌سازی کش از ۱ ساعت تجاوز نکند.

---

### C5.4 اجرای امنیت در زمان پرس‌وجو

کنترل‌های امنیتی لایه پایگاه داده را با فیلتر اجباری و سیاست‌های امنیتی در سطح سطر پیاده‌سازی کنید.

 #5.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام کوئری‌های پایگاه داده برداری و SQL شامل فیلترهای اجباری امنیتی (شناسه مستاجر، برچسب‌های حساسیت، محدوده کاربر) هستند که در سطح موتور پایگاه داده اعمال می‌شوند، نه در کد برنامه.
 #5.4.2    سطح: 1    نقش: D/V
 تأیید کنید که سیاست‌های امنیت سطح ردیف (RLS) و ماسک‌گذاری سطح فیلد با ارث‌بری سیاست برای همه پایگاه‌های داده برداری، شاخص‌های جستجو و مجموعه داده‌های آموزشی فعال شده باشند.
 #5.4.3    سطح: 2    نقش: D
 تأیید کنید که ارزیابی‌های ناموفق مجوزدهی، با قطع فوری پرس‌وجوها و بازگرداندن کدهای خطای مجوزدهی صریح به جای بازگرداندن مجموعه نتایج خالی، از وقوع «حملات معاون گیج‌شده» جلوگیری خواهند کرد.
 #5.4.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که تأخیر ارزیابی سیاست به طور مداوم با هشدارهای خودکار برای شرایط تایم‌اوت که ممکن است باعث دورزدن مجوز شود، مورد نظارت قرار می‌گیرد.
 #5.4.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های تکرار پرس‌وجو، سیاست‌های مجوزدهی را مجدداً ارزیابی می‌کنند تا تغییرات دینامیک مجوزها در طول جلسات فعال کاربر را در نظر بگیرند.

---

### فیلتر خروجی C5.5 و پیشگیری از از دست دادن داده‌ها

کنترل‌های پس‌پردازش را برای جلوگیری از افشای غیرمجاز داده‌ها در محتوای تولید شده توسط هوش مصنوعی پیاده‌سازی کنید.

 #5.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های فیلترینگ پس از استنتاج، داده‌های شناسایی شخصی غیرمجاز (PII)، اطلاعات طبقه‌بندی شده و داده‌های اختصاصی را قبل از ارائه محتوا به درخواست‌کنندگان، اسکن و حذف می‌کنند.
 #5.5.2    سطح: 1    نقش: D/V
 بررسی کنید که ارجاعات، مآخذ و انتساب منابع در خروجی‌های مدل بر اساس مجوزهای تماس‌گیرنده تأیید شده باشند و در صورت شناسایی دسترسی غیرمجاز، حذف شوند.
 #5.5.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که محدودیت‌های قالب خروجی (فایل‌های PDF پاک‌سازی شده، تصاویر بدون متادیتا، انواع فایل‌های تأیید شده) بر اساس سطح دسترسی کاربران و طبقه‌بندی داده‌ها اعمال می‌شوند.
 #5.5.4    سطح: 2    نقش: V
 تأیید کنید که الگوریتم‌های سانسور قطعی، کنترل‌شده با نسخه و دارای ثبت گزارش‌های حسابرسی هستند تا از تحقیقات تطبیق و تحلیل قانونی پشتیبانی کنند.
 #5.5.5    سطح: 3    نقش: V
 تأیید کنید که رویدادهای حذف با ریسک بالا، گزارش‌های تطبیقی تولید می‌کنند که شامل هش‌های رمزنگاری شده از محتوای اصلی برای بازیابی جرم‌شناسی بدون افشای داده‌ها باشد.

---

### C5.6 ایزولاسیون چند مستاجری

اطمینان از جداسازی رمزنگاری‌شده و منطقی بین مستأجران در زیرساخت مشترک هوش مصنوعی.

 #5.6.1    سطح: 1    نقش: D/V
 تأیید کنید که فضاهای حافظه، ذخیره‌های تعبیه شده، ورودی‌های کش و فایل‌های موقتی به صورت جداشده بر اساس فضای نام هر مستأجر باشند و پاک‌سازی ایمن در زمان حذف مستأجر یا پایان جلسه انجام شود.
 #5.6.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر درخواست API شامل شناسه مستاجر احراز هویت شده است که به صورت رمزنگاری شده در برابر زمینه جلسه و سطح دسترسی‌های کاربر اعتبارسنجی می‌شود.
 #5.6.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که سیاست‌های شبکه قوانین پیش‌فرض-رد را برای ارتباطات بین مستاجران در داخل سرویس مش‌ها و پلتفرم‌های ارکستراسیون کانتینر اجرا می‌کنند.
 #5.6.4    سطح: 3    نقش: D
 بررسی کنید که کلیدهای رمزنگاری شده برای هر مستأجر یکتا باشند، با پشتیبانی از کلید مدیریت شده توسط مشتری (CMK) و جداسازی رمزنگاری بین مخازن داده مستأجران.

---

### C5.7 مجوز عامل خودران

کنترل دسترسی‌ها برای عامل‌های هوش مصنوعی و سیستم‌های خودران از طریق توکن‌های قابلیت محدود شده و مجوزدهی مستمر.

 #5.7.1    سطح: 1    نقش: D/V
 تأیید کنید که نمایندگان خودگردان توکن‌های قابلیت محدوده‌دار دریافت می‌کنند که به‌طور صریح اقدامات مجاز، منابع قابل دسترسی، محدوده‌های زمانی و محدودیت‌های عملیاتی را فهرست می‌کند.
 #5.7.2    سطح: 1    نقش: D/V
 تأیید کنید که قابلیت‌های پرخطر (دسترسی به سیستم فایل، اجرای کد، تماس‌های API خارجی، تراکنش‌های مالی) به طور پیش‌فرض غیرفعال هستند و برای فعال‌سازی نیاز به مجوزهای صریح همراه با توجیهات کسب‌وکار دارند.
 #5.7.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که توکن‌های قابلیت به جلسات کاربری متصل شده‌اند، از حفاظت صحت رمزنگاری برخوردارند و تضمین کنید که در سناریوهای آفلاین قابل ذخیره یا استفاده مجدد نیستند.
 #5.7.4    سطح: 2    نقش: V
 تأیید کنید که اقدامات آغاز شده توسط عامل از طریق موتور سیاست ABAC با ارزیابی کامل زمینه و ثبت گزارش حسابرسی، تأیید ثانویه می‌شوند.
 #5.7.5    سطح: 3    نقش: V
 تأیید کنید که شرایط خطای عامل و مدیریت استثنا شامل اطلاعات دامنه قابلیت برای پشتیبانی از تجزیه و تحلیل حادثه و تحقیق قانونی باشد.

---

### مراجع

#### استانداردها و چارچوب‌ها

NIST SP 800-63-3: Digital Identity Guidelines
Zero Trust Architecture – NIST SP 800-207
OWASP Application Security Verification Standard (AISVS)
​
#### راهنمای پیاده‌سازی

Identity and Access Management in the AI Era: 2025 Guide – IDSA
Attribute-Based Access Control with OPA – Permify
How We Designed Cedar to Be Intuitive, Fast, and Safe – AWS
​
#### امنیت ویژه هوش مصنوعی

Row Level Security in Vector DBs for RAG – Bluetuple.ai
Tenant Isolation in Multi-Tenant Systems – WorkOS
Handling AI Agent Permissions – Stytch
OWASP Top 10 for Large Language Model Applications

## امنیت زنجیره تامین C6 برای مدل‌ها، چارچوب‌ها و داده‌ها

### هدف کنترل

حملات زنجیره تأمین هوش مصنوعی از مدل‌ها، چارچوب‌ها یا مجموعه داده‌های شخص ثالث برای جاسازی درهای پشتی، سوگیری یا کد قابل سوء استفاده بهره می‌برند. این کنترل‌ها ردیابی کامل منبع، مدیریت آسیب‌پذیری و نظارت را فراهم می‌کنند تا از کل چرخه عمر مدل محافظت کنند.

---

### C6.1 بررسی مدل پیش‌آموزش‌دیده و اصالت آن

قبل از هرگونه آموزش مجدد یا استقرار، منابع، مجوزها و رفتارهای پنهان مدل‌های شخص ثالث را ارزیابی و تأیید کنید.

 #6.1.1    سطح: 1    نقش: D/V
 تأیید کنید که هر اثر مدل شخص ثالث شامل یک رکورد منشأ امضا شده باشد که مخزن منبع و هش تعهد را مشخص می‌کند.
 #6.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مدل‌ها قبل از واردسازی با استفاده از ابزارهای خودکار برای شناسایی لایه‌های مخرب یا محرک‌های تروجان اسکن می‌شوند.
 #6.1.3    سطح: 2    نقش: D
 تأیید کنید که آموزش تکمیلی در یادگیری انتقالی از ارزیابی‌های خصمانه عبور می‌کند تا رفتارهای پنهان را شناسایی کند.
 #6.1.4    سطح: 2    نقش: V
 تأیید کنید که مجوزهای مدل، برچسب‌های کنترل صادرات، و بیانیه‌های منبع داده‌ها در یک ورودی ML‑BOM ثبت شده باشند.
 #6.1.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مدل‌های پرخطر (وزن‌های آپلود شده به‌صورت عمومی، سازندگان تأیید نشده) تا زمان بازبینی و تصویب انسانی در قرنطینه باقی می‌مانند.

---

### C6.2 اسکن فریم‌ورک و کتابخانه

به طور مداوم چارچوب‌ها و کتابخانه‌های یادگیری ماشین را برای یافتن آسیب‌پذیری‌های امنیتی (CVE) و کدهای مخرب اسکن کنید تا لایه اجرایی ایمن باقی بماند.

 #6.2.1    سطح: 1    نقش: D/V
 تأیید کنید که خطوط لوله CI، اسکنرهای وابستگی را روی چارچوب‌های AI و کتابخانه‌های حیاتی اجرا می‌کنند.
 #6.2.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که آسیب‌پذیری‌های بحرانی (CVSS ≥ 7.0) مانع از ارتقاء به تصاویر تولیدی می‌شوند.
 #6.2.3    سطح: 2    نقش: D
 تأیید کنید که تحلیل ایستای کد بر روی کتابخانه‌های یادگیری ماشین منشعب‌شده یا فروشگاهی اجرا می‌شود.
 #6.2.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که پیشنهادات ارتقاء چارچوب شامل ارزیابی تأثیر امنیتی با ارجاع به منابع عمومی CVE هستند.
 #6.2.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که حسگرهای زمان اجرا در صورت بارگذاری کتابخانه‌های پویا غیرمنتظره که با SBOM امضا شده مطابقت ندارند هشدار می‌دهند.

---

### C6.3 ثابت‌کردن و تأیید وابستگی‌ها

تمام وابستگی‌ها را به هش‌های غیرقابل تغییر ثابت کنید و ساخت‌ها را بازتولید کنید تا از تولید آثار کاملاً یکسان و بدون دستکاری اطمینان حاصل شود.

 #6.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که همه مدیران بسته نسخه‌ها را از طریق فایل‌های قفل اعمال می‌کنند.
 #6.3.2    سطح: 1    نقش: D/V
 تأیید کنید که در ارجاعات کانتینر از چکیده‌های غیرقابل تغییر به جای برچسب‌های قابل تغییر استفاده شده است.
 #6.3.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که بررسی‌های بازتولیدپذیری با مقایسه هش‌ها در اجرای‌های CI، خروجی‌های یکسان را تضمین می‌کنند.
 #6.3.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که تاییدیه‌های ساخت به مدت 18 ماه برای قابلیت ردیابی حسابرسی ذخیره می‌شوند.
 #6.3.5    سطح: 3    نقش: D
 تأیید کنید که وابستگی‌های منقضی شده، درخواست‌های باز خودکار برای به‌روزرسانی یا فورک نسخه‌های پین شده را فعال می‌کنند.

---

### C6.4 اجرای منبع مورد اعتماد

اجازه دانلود آثار فقط از منابعی که به صورت رمزنگاری شده تأیید شده‌اند و توسط سازمان تایید شده‌اند را بدهید و همه موارد دیگر را مسدود کنید.

 #6.4.1    سطح: 1    نقش: D/V
 تأیید کنید که وزن‌های مدل، مجموعه‌داده‌ها و کانتینرها تنها از دامنه‌های تأییدشده یا رجیستری‌های داخلی دانلود شوند.
 #6.4.2    سطح: 1    نقش: D/V
 تأیید کنید که امضاهای Sigstore/Cosign هویت ناشر را قبل از ذخیره‌سازی محلی آثار تأیید می‌کنند.
 #6.4.3    سطح: 2    نقش: D
 تأیید کنید که پروکسی‌های خروجی دانلودهای آثار بدون احراز هویت را مسدود می‌کنند تا سیاست منبع مورد اعتماد اجرا شود.
 #6.4.4    سطح: 2    نقش: V
 تأیید کنید که فهرست‌های مجاز مخزن به‌صورت فصلی بازبینی می‌شوند و برای هر ورودی شاهدی از توجیه کسب‌وکار وجود دارد.
 #6.4.5    سطح: 3    نقش: V
 تأیید کنید که نقض سیاست‌ها منجر به قرنطینه شدن مصنوعات و بازگردانی اجرای‌های وابسته به خط لوله شود.

---

### C6.5 ارزیابی ریسک داده‌های شخص ثالث

داده‌های خارجی را از نظر مسمومیت، تعصب و تطابق قانونی ارزیابی کنید و در طول چرخه عمر آن‌ها را نظارت کنید.

 #6.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که داده‌های خارجی تحت ارزیابی ریسک آلوده شدن قرار می‌گیرند (برای مثال، اثر انگشت داده‌ها، شناسایی نقاط دورافتاده).
 #6.5.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که معیارهای سوگیری (برابری جمعیتی، فرصت برابر) قبل از تصویب مجموعه داده محاسبه شده‌اند.
 #6.5.3    سطح: 2    نقش: V
 تأیید کنید که منشأ و شرایط مجوز برای مجموعه داده‌ها در ورودی‌های ML-BOM ثبت شده است.
 #6.5.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که پایش دوره‌ای تغییر یا فساد در داده‌های میزبانی شده را شناسایی می‌کند.
 #6.5.5    سطح: 3    نقش: D
 اطمینان حاصل کنید که محتوای غیرمجاز (حق نشر، اطلاعات شخصی شناسایی‌پذیر) از طریق پاک‌سازی خودکار پیش از آموزش حذف شده است.

---

### C6.6 نظارت بر حملات زنجیره تامین

تهدیدهای زنجیره تأمین را از طریق خوراک‌های CVE، تحلیل‌های لاگ حسابرسی و شبیه‌سازی‌های تیم قرمز به‌صورت زودهنگام شناسایی کنید.

 #6.6.1    سطح: 1    نقش: V
 اطمینان حاصل کنید که گزارش‌های حسابرسی CI/CD به جریان تشخیص‌های SIEM برای دریافت‌های غیرعادی بسته یا مراحل ساخت دستکاری شده ارسال می‌شوند.
 #6.6.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که کتابچه‌های راهنمای واکنش به حادثه شامل رویه‌های بازگردانی برای مدل‌ها یا کتابخانه‌های به خطر افتاده باشند.
 #6.6.3    سطح: 3    نقش: V
 تأیید کنید که برچسب‌های غنی‌سازی اطلاعات تهدید شاخص‌های خاص ML (مثلاً IoCهای مرتبط با مسموم‌سازی مدل) را در دسته‌بندی هشدار علامت‌گذاری می‌کنند.

---

### C6.7 فهرست مواد یادگیری ماشین (ML-BOM) برای آثار مدل

تولید و امضای SBOMهای تخصصی ML جزئی و دقیق (ML‑BOMها) به‌گونه‌ای که مصرف‌کنندگان نهایی بتوانند صحت یکپارچگی مؤلفه‌ها را در زمان استقرار تأیید کنند.

 #6.7.1    سطح: 1    نقش: D/V
 تأیید کنید که هر اثر مدل یک ML‑BOM منتشر می‌کند که شامل مجموعه داده‌ها، وزن‌ها، ابرپارامترها و مجوزها باشد.
 #6.7.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تولید ML‑BOM و امضای Cosign به طور خودکار در CI انجام می‌شود و برای ادغام الزامی است.
 #6.7.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که بررسی‌های کامل بودن ML-BOM در صورت فقدان هرگونه متادیتای مؤلفه (هش، مجوز) باعث شکست ساخت می‌شود.
 #6.7.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که مصرف‌کنندگان پایین‌دستی می‌توانند از طریق API داده‌های BOM مدل‌های یادگیری ماشین را برای اعتبارسنجی مدل‌های وارد شده در زمان استقرار، پرس‌وجو کنند.
 #6.7.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که ML-BOMها تحت کنترل نسخه هستند و تفاوت‌گیری می‌شوند تا تغییرات غیرمجاز شناسایی شوند.

---

### مراجع

ML Supply Chain Compromise – MITRE ATLAS
Supply‑chain Levels for Software Artifacts (SLSA)
CycloneDX – Machine Learning Bill of Materials
What is Data Poisoning? – SentinelOne
Transfer Learning Attack – OWASP ML Security Top 10
AI Data Security Best Practices – CISA
Secure CI/CD Supply Chain – Sumo Logic
AI & Transparency: Protect ML Models – ReversingLabs
SBOM Overview – CISA
Training Data Poisoning Guide – Lakera.ai
Dependency Pinning for Reproducible Python – Medium

## رفتار مدل C7، کنترل خروجی و تضمین ایمنی

### هدف کنترل

خروجی‌های مدل باید ساختاریافته، قابل اطمینان، ایمن، قابل توضیح و به‌صورت مداوم در تولید مورد نظارت قرار گیرند. این کار باعث کاهش توهمات، نشت‌های حریم خصوصی، محتوای مضر و اقدامات خارج از کنترل می‌شود و در عین حال اعتماد کاربران و تطابق با مقررات را افزایش می‌دهد.

---

### C7.1 اجبار قالب خروجی

طرح‌های سخت‌گیرانه، رمزگشایی محدودشده و اعتبارسنجی‌های پس‌زمینه، از انتشار محتوای نادرست یا مخرب جلوگیری می‌کنند.

 #7.1.1    سطح: 1    نقش: D/V
 تأیید کنید که اسکیمای پاسخ (مانند JSON Schema) در پرامپت سیستم ارائه شده و هر خروجی به‌صورت خودکار اعتبارسنجی می‌شود؛ خروجی‌هایی که با اسکیمای تعریف‌شده مطابقت نداشته باشند باعث فعال‌شدن فرایند تعمیر یا رد درخواست می‌شوند.
 #7.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که رمزگشایی محدود شده (توکن‌های توقف، عبارات منظم، حداکثر تعداد توکن‌ها) فعال است تا از سرریز یا کانال‌های جانبی تزریق پرامپت جلوگیری شود.
 #7.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اجزای پایین‌دستی خروجی‌ها را به عنوان نامطمئن در نظر می‌گیرند و آن‌ها را با استفاده از طرح‌های ساختاری یا د-سریالایزرهای امن در برابر تزریق اعتبارسنجی می‌کنند.
 #7.1.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که رویدادهای خروجی نادرست ثبت، نرخ محدود شده و به سامانه پایش منتقل می‌شوند.

---

### C7.2 تشخیص و کاهش هالوسی‌سازی

برآورد عدم قطعیت و راهبردهای پشتیبان پاسخ‌های ساختگی را محدود می‌کنند.

 #7.2.1    سطح: 1    نقش: D/V
 تأیید کنید که احتمال‌های لگاریتمی در سطح توکن، خودسازگاری مجموعه‌ای، یا آشکارسازهای هذیان تنظیم‌شده به‌دقت، یک نمره اطمینان به هر پاسخ اختصاص می‌دهند.
 #7.2.2    سطح: 1    نقش: D/V
 تأیید کنید که پاسخ‌هایی با سطح اعتماد کمتر از آستانه قابل تنظیم، فرایندهای پشتیبان (مانند تولید تقویت‌شده با بازیابی، مدل ثانویه، یا بازبینی انسانی) را فعال می‌کنند.
 #7.2.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که حوادث توهم با متاداده علت ریشه‌ای برچسب‌گذاری شده و به خط لوله‌های بررسی پس از وقوع و تنظیم دقیق منتقل می‌شوند.
 #7.2.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که آستانه‌ها و آشکارسازها پس از به‌روزرسانی‌های عمده مدل یا پایگاه دانش دوباره کالیبره شده‌اند.
 #7.2.5    سطح: 3    نقش: V
 تأیید کنید که نمودارهای داشبورد نرخ‌های هذیان را پیگیری می‌کنند.

---

### C7.3 فیلترینگ ایمنی و حریم خصوصی خروجی

فیلترهای سیاست و پوشش تیم قرمز از کاربران و داده‌های محرمانه حفاظت می‌کنند.

 #7.3.1    سطح: 1    نقش: D/V
 تأیید کنید که طبقه‌بندهای قبل و بعد از تولید محتوا، محتوای نفرت‌آمیز، آزاردهنده، خودآسیب‌رسان، افراطی و محتوای جنسی صریح که با سیاست مطابقت دارد را مسدود می‌کنند.
 #7.3.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که شناسایی اطلاعات شخصی قابل شناسایی (PII) و اطلاعات کارت پرداختی (PCI) و پاک‌سازی خودکار در هر پاسخ اجرا می‌شود؛ رعایت نکردن این موضوع منجر به بروز حادثه حریم خصوصی می‌شود.
 #7.3.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که برچسب‌های محرمانگی (مثلاً اسرار تجاری) در سراسر مدالیته‌ها منتقل می‌شوند تا از نشت اطلاعات در متن، تصاویر یا کد جلوگیری شود.
 #7.3.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تلاش‌های عبور از فیلتر یا دسته‌بندی‌های با ریسک بالا نیاز به تایید ثانویه یا احراز هویت مجدد کاربر دارند.
 #7.3.5    سطح: 3    نقش: D/V
 تأیید کنید که آستانه‌های فیلترینگ مطابق با حوزه‌های قضایی قانونی و زمینه سنی/نقشی کاربر باشد.

---

### C7.4 محدود کردن خروجی و اقدام

محدودیت‌های نرخ و دروازه‌های تأیید از سوءاستفاده و خودمختاری بیش از حد جلوگیری می‌کنند.

 #7.4.1    سطح: 1    نقش: D
 تأیید کنید که سهمیه‌های هر کاربر و هر کلید API درخواست‌ها، توکن‌ها و هزینه‌ها را با استفاده از بازگشت نمایی در مواجهه با خطاهای 429 محدود می‌کنند.
 #7.4.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که اقدامات دارای امتیاز ویژه (نوشتن فایل، اجرای کد، فراخوانی‌های شبکه) به تایید مبتنی بر سیاست یا دخالت انسانی نیاز دارند.
 #7.4.3    سطح: 2    نقش: D/V
 تأیید کنید که بررسی‌های سازگاری چندرسانه‌ای تضمین می‌کند تصاویر، کد و متنی که برای همان درخواست تولید شده‌اند، نمی‌توانند برای قاچاق محتوای مخرب استفاده شوند.
 #7.4.4    سطح: 2    نقش: D
 تأیید کنید که عمق نمایندگی عامل، محدودیت‌های بازگشتی، و فهرست ابزارهای مجاز به طور صریح پیکربندی شده‌اند.
 #7.4.5    سطح: 3    نقش: V
 تأیید کنید که نقض محدودیت‌ها باعث صدور رویدادهای امنیتی ساختاریافته برای جذب در سیستم SIEM شود.

---

### قابل توضیح بودن خروجی C7.5

سیگنال‌های شفاف اعتماد کاربر و رفع اشکال داخلی را افزایش می‌دهند.

 #7.5.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که نمرات اطمینان قابل مشاهده برای کاربر یا خلاصه‌های مختصر دلایل زمانی که ارزیابی ریسک مناسب می‌داند، ارائه شوند.
 #7.5.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که توضیحات تولید شده از فاش کردن فرامین حساس سیستم یا داده‌های اختصاصی جلوگیری می‌کنند.
 #7.5.3    سطح: 3    نقش: D
 اطمینان حاصل کنید که سیستم لاگ-احتمال‌های سطح توکن یا نقشه‌های توجه را ثبت می‌کند و آن‌ها را برای بازبینی مجاز ذخیره می‌نماید.
 #7.5.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که مصنوعات قابلیت توضیح‌دهی به همراه نسخه‌های مدل برای قابلیت حسابرسی کنترل نسخه شده‌اند.

---

### C7.6 یکپارچه‌سازی نظارت

مشاهده‌پذیری در زمان واقعی حلقه بین توسعه و تولید را می‌بندد.

 #7.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که متریک‌ها (تخلفات طرح، نرخ توهم‌زایی، سمی بودن، نشت داده‌های شخصی شناسایی شده، تأخیر، هزینه) به یک پلتفرم مرکزی نظارت ارسال می‌شوند.
 #7.6.2    سطح: 1    نقش: V
 اطمینان حاصل کنید که آستانه‌های هشدار برای هر معیار ایمنی تعریف شده‌اند، همراه با مسیرهای ارتقاء تماس در دسترس.
 #7.6.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که داشبوردها ناهنجاری‌های خروجی را با مدل/نسخه، علامت ویژگی، و تغییرات داده‌های بالادستی مرتبط می‌کنند.
 #7.6.4    سطح: 2    نقش: D/V
 تأیید کنید که داده‌های نظارتی در داخل یک جریان کاری مستند MLOps به بازآموزی، تنظیم دقیق یا به‌روزرسانی قوانین بازمی‌گردند.
 #7.6.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که پایپ‌لاین‌های نظارتی تحت آزمایش نفوذ قرار گرفته و دارای کنترل دسترسی هستند تا از نشت لاگ‌های حساس جلوگیری شود.

---

### 7.7 تدابیر حفاظتی رسانه‌های مولدی

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی محتوای رسانه‌ای غیرقانونی، مضر یا غیرمجاز تولید نکنند با اعمال محدودیت‌های سیاستی، اعتبارسنجی خروجی و قابلیت ردیابی.

 #7.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که دستورالعمل‌های سیستم و راهنمایی‌های کاربر به‌طور صریح تولید رسانه‌های دیپ‌فیک غیرقانونی، مضر یا بدون رضایت (مانند تصویر، ویدئو، صدا) را ممنوع می‌کنند.
 #7.7.2    سطح: 2    نقش: D/V
 تأیید کنید که درخواست‌ها برای تلاش در تولید تقلیدهای جعلی، تصاویر مستهجن عمیق یا رسانه‌هایی که افراد واقعی را بدون رضایت نشان می‌دهند، فیلتر می‌شوند.
 #7.7.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که سیستم از هش ادراکی، تشخیص نشانه آبی، یا اثر انگشت برای جلوگیری از تکثیر غیرمجاز محتوای دارای حق چاپ استفاده می‌کند.
 #7.7.4    سطح: 3    نقش: D/V
 تأیید کنید که تمام رسانه‌های تولید شده به صورت رمزنگاری‌شده امضا شده‌اند، دارای واترمارک هستند یا با متاداده‌های منبع قابل‌ردیابی و مقاوم در برابر دستکاری برای ردیابی‌های بعدی تعبیه شده‌اند.
 #7.7.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که تلاش‌های دور زدن (مانند ابهام‌سازی پیام، زبان محاوره‌ای، بیان خصمانه) شناسایی، ثبت و محدودیت نرخ برای آنها اعمال می‌شود؛ سوء استفاده مکرر به سیستم‌های نظارتی گزارش می‌شود.

### مراجع

NIST AI Risk Management Framework
ISO/IEC 42001:2023 – AI Management System
OWASP Top-10 for Large Language Model Applications (2025)
Improper Output Handling – OWASP LLM05:2025
Practical Techniques to Constrain LLM Output
Dataiku – Structured Text Generation Guide
VL-Uncertainty: Detecting Hallucinations
HaDeMiF: Hallucination Detection & Mitigation
Building Confidence in LLM Outputs
Explainable AI & LLMs
LLM Red-Teaming Guide
Sensitive Information Disclosure in LLMs
LangChain – Chat Model Rate Limiting
OpenAI Rate-Limit & Exponential Back-off
Arize AI – LLM Observability Platform

## امنیت حافظه C8، تعبیه‌ها و پایگاه داده برداری

### هدف کنترل

جاسازی‌ها و فروشگاه‌های برداری به‌عنوان «حافظه زنده» سیستم‌های هوش مصنوعی معاصر عمل می‌کنند، که به‌طور مداوم داده‌های ارائه شده توسط کاربر را دریافت کرده و از طریق تولید تقویت‌شده با بازیابی (RAG) آن‌ها را به زمینه‌های مدل باز می‌گردانند. اگر این حافظه بدون کنترل رها شود، ممکن است اطلاعات شناسایی شخصی (PII) را فاش کند، رضایت را نقض کند یا به صورت معکوس مورد استفاده قرار گیرد تا متن اصلی را بازسازی کند. هدف این خانواده کنترل، سخت‌سازی خطوط لوله حافظه و پایگاه‌های داده برداری است به‌طوری‌که دسترسی کمترین امتیاز لازم را داشته باشد، جاسازی‌ها حریم خصوصی را حفظ کنند، بردارهای ذخیره شده منقضی شوند یا در صورت درخواست قابل لغو باشند، و حافظه هر کاربر هرگز باعث آلودگی درخواست‌ها یا پاسخ‌های کاربر دیگر نشود.

---

### C8.1 کنترل‌های دسترسی بر حافظه و شاخص‌های RAG

اجرای کنترل‌های دسترسی دقیق و جزئی بر روی هر مجموعه برداری.

 #8.1.1    سطح: 1    نقش: D/V
 تأیید کنید که قوانین کنترل دسترسی در سطح ردیف/فضای نام، عملیات‌های درج، حذف و پرس‌وجو را بر اساس مستاجر، مجموعه یا برچسب سند محدود می‌کنند.
 #8.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که کلیدهای API یا JWT ها شامل ادعاهای محدوده‌دار (مانند شناسه‌های مجموعه، افعال عملیاتی) هستند و حداقل هر سه ماه یکبار تعویض می‌شوند.
 #8.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تلاش‌های ارتقای دسترسی (مثلاً درخواست‌های شباهت بین فضای نام‌ها) شناسایی شده و ظرف ۵ دقیقه در یک سیستم مدیریت اطلاعات و رویدادهای امنیتی (SIEM) ثبت می‌شوند.
 #8.1.4    سطح: 2    نقش: D/V
 تأیید کنید که پایگاه داده برداری گزارش‌های ممیزی شامل شناسه موضوع، عملیات، شناسه بردار/فضای نام، آستانه شباهت و تعداد نتایج باشد.
 #8.1.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که تصمیم‌های دسترسی هر زمان که موتور ها به‌روزرسانی می‌شوند یا قوانین تقسیم‌بندی نمایه تغییر می‌کنند، برای نقص‌های دورزدن آزمایش می‌شوند.

---

### C8.2 پاکسازی و اعتبارسنجی جاسازی

متن را برای اطلاعات شناسایی شخصی (PII) پیش‌بررسی کنید، پیش از تبدیل به بردارها، آن را محرمانه یا شبه‌نام‌گذاری کنید، و به صورت اختیاری پس‌پردازش تعبیه‌ها را انجام دهید تا سیگنال‌های باقی‌مانده را حذف کنید.

 #8.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که داده‌های شناسایی‌شونده شخصی (PII) و داده‌های تحت‌قانون با استفاده از طبقه‌بندهای خودکار شناسایی شده و پیش از جاسازی (embedding) به صورت ماسک‌شده، نشانه‌گذاری‌شده یا حذف شده‌اند.
 #8.2.2    سطح: 1    نقش: D
 تأیید کنید که خطوط لوله جاسازی ورودی‌هایی که حاوی کد اجرایی یا مصنوعات غیر UTF-8 هستند و ممکن است اندیس را آلوده کنند، را رد یا قرنطینه می‌کنند.
 #8.2.3    سطح: 2    نقش: D/V
 تأیید کنید که پاک‌سازی با حفظ حریم خصوصی موضعی یا متریکی به تعبیه‌های جمله اعمال شده است که فاصله آن‌ها با هر نشانه PII شناخته شده کمتر از یک آستانه قابل تنظیم باشد.
 #8.2.4    سطح: 2    نقش: V
 تأیید کنید که اثربخشی پاک‌سازی (به عنوان مثال، بازیابی حذفی اطلاعات شناسایی شخصی، انحراف معنایی) حداقل به‌طور نیم‌سالانه بر اساس مجموعه‌های معیار ارزیابی شود.
 #8.2.5    سطح: 3    نقش: D/V
 اطمینان حاصل شود که پیکربندی‌های پاک‌سازی تحت کنترل نسخه هستند و تغییرات تحت بازبینی همتا قرار می‌گیرند.

---

### C8.3 انقضای حافظه، لغو و حذف

قانون GDPR با مفهوم «حق فراموش شدن» و قوانین مشابه نیازمند حذف به موقع داده‌ها است؛ بنابراین، فروشگاه‌های وکتور باید از قابلیت‌های TTL، حذف سخت، و ایجاد یادبود حذف (tomb-stoning) پشتیبانی کنند تا وکتورهای لغو شده قابل بازیابی یا نمایه‌سازی مجدد نباشند.

 #8.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر بردار و رکورد متادیتا دارای TTL یا برچسب نگهداری صریحی باشد که توسط وظایف پاکسازی خودکار رعایت شود.
 #8.3.2    سطح: 1    نقش: D/V
 تأیید کنید که درخواست‌های حذف شروع‌شده توسط کاربر بردارها، فراداده‌ها، نسخه‌های کش و شاخص‌های مشتق شده را ظرف 30 روز پاک می‌کنند.
 #8.3.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که حذف‌های منطقی با تخریب رمزنگاری شده بلوک‌های ذخیره‌سازی در صورت پشتیبانی سخت‌افزار، یا با تخریب کلید در گاوصندوق کلید دنبال می‌شوند.
 #8.3.4    سطح: 3    نقش: D/V
 اعتبارسنجی کنید که وکتورهای منقضی شده در کمتر از ۵۰۰ میلی‌ثانیه پس از انقضا از نتایج جستجوی نزدیک‌ترین همسایه حذف شوند.

---

### C8.4 جلوگیری از معکوس‌سازی و نشت جاسازی‌ها

دفاع‌های اخیر—مانند ترکیب نویز، شبکه‌های پروجکشن، تغییرات نورون‌های حفظ حریم خصوصی، و رمزنگاری لایه برنامه—می‌توانند نرخ معکوس‌سازی در سطح توکن را به زیر ۵٪ کاهش دهند.

 #8.4.1    سطح: 1    نقش: V
 تأیید کنید که یک مدل تهدید رسمی که شامل حملات معکوس‌سازی، عضویت و استنتاج ویژگی باشد، وجود دارد و سالانه مورد بازبینی قرار می‌گیرد.
 #8.4.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که رمزنگاری در لایه برنامه یا رمزنگاری جستجوپذیر، بردارها را از خوانش مستقیم توسط مدیران زیرساخت یا کارکنان ابر محافظت می‌کند.
 #8.4.3    سطح: 3    نقش: V
 اطمینان حاصل کنید که پارامترهای دفاعی (ε برای حریم خصوصی تفاضلی، نویز σ، رتبه تصویر k) تعادل بین حفظ حریم خصوصی ≥ 99٪ حفاظت از توکن و کارایی ≤ 3٪ کاهش دقت را برقرار می‌کنند.
 #8.4.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که معیارهای مقاومت در برابر وارونگی بخشی از دروازه‌های انتشار برای به‌روزرسانی‌های مدل هستند و بودجه‌های رگرسیون تعریف شده‌اند.

---

### C8.5 اجرای دامنه برای حافظه مخصوص کاربر

نشت اطلاعات میان مستاجران مختلف همچنان یکی از بزرگ‌ترین ریسک‌های RAG است: پرس‌وجوهای شباهت که به درستی فیلتر نشده‌اند، ممکن است اسناد خصوصی مشتری دیگری را نمایش دهند.

 #8.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر پرس‌وجوی بازیابی قبل از ارسال به درخواست LLM با شناسه مستاجر/کاربر پس‌فیلتر شده است.
 #8.5.2    سطح: 1    نقش: D
 تأیید کنید که نام مجموعه‌ها یا شناسه‌های نام‌دار شده به‌صورت جداگانه برای هر کاربر یا مستأجر نمک‌دار شده‌اند تا وکتورها در دامنه‌های مختلف با یکدیگر تداخل نداشته باشند.
 #8.5.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که نتایج شباهت بالاتر از یک آستانه فاصله قابل تنظیم اما خارج از حوزه تماس گیرنده، رد شده و هشدارهای امنیتی را فعال می‌کنند.
 #8.5.4    سطح: 2    نقش: V
 تأیید کنید که تست‌های فشار چند مستاجره، پرس‌وجوهای خصمانه‌ای را که در تلاش برای بازیابی اسناد خارج از حوزه مجاز هستند شبیه‌سازی می‌کنند و عدم نشت اطلاعات را نشان می‌دهند.
 #8.5.5    سطح: 3    نقش: D/V
 تأیید کنید که کلیدهای رمزگذاری به ازای هر مستاجر تفکیک شده‌اند، به طوری که جداسازی رمزنگاری حتی در صورت اشتراک گذاری فضای ذخیره‌سازی فیزیکی تضمین شود.

---

### C8.6 امنیت پیشرفته سیستم حافظه

کنترل‌های امنیتی برای معماری‌های پیچیده حافظه شامل حافظه اپیزودیک، معنایی و کاری با نیازهای خاص جداسازی و اعتبارسنجی.

 #8.6.1    سطح: 1    نقش: D/V
 تأیید کنید که انواع مختلف حافظه (اپیزودیک، معنایی، کاری) دارای زمینه‌های امنیتی جداگانه با کنترل‌های دسترسی مبتنی بر نقش، کلیدهای رمزنگاری جداگانه و الگوهای دسترسی مستند برای هر نوع حافظه باشند.
 #8.6.2    سطح: 2    نقش: D/V
 تأیید کنید که فرایندهای تثبیت حافظه شامل اعتبارسنجی امنیتی برای جلوگیری از تزریق خاطرات مخرب از طریق پاک‌سازی محتوا، تأیید منبع و بررسی‌های صحت قبل از ذخیره‌سازی باشند.
 #8.6.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که پرس‌وجوهای بازیابی حافظه معتبر و پاک‌سازی شده‌اند تا از استخراج اطلاعات غیرمجاز از طریق تحلیل الگوهای پرس‌وجو، اعمال کنترل دسترسی و فیلتر کردن نتایج جلوگیری شود.
 #8.6.4    سطح: 3    نقش: D/V
 تأیید کنید که مکانیزم‌های فراموشی حافظه اطلاعات حساس را با تضمین‌های رمزنگاری شده حذف می‌کنند، از طریق حذف کلید، بازنویسی چندباره یا حذف امن مبتنی بر سخت‌افزار با گواهی‌های تأیید.
 #8.6.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که یکپارچگی سیستم حافظه به‌طور مداوم برای تغییرات غیرمجاز یا خرابی‌ها از طریق چک‌سام‌ها، لاگ‌های حسابرسی و هشدارهای خودکار زمانی که محتوای حافظه خارج از عملیات عادی تغییر می‌کند، نظارت می‌شود.

---

### مراجع

Vector database security: Pinecone – IronCore Labs
Securing the Backbone of AI: Safeguarding Vector Databases and Embeddings – Privacera
Enhancing Data Security with RBAC of Qdrant Vector Database – AI Advances
Mitigating Privacy Risks in LLM Embeddings from Embedding Inversion – arXiv
DPPN: Detecting and Perturbing Privacy-Sensitive Neurons – OpenReview
Art. 17 GDPR – Right to Erasure
Sensitive Data in Text Embeddings Is Recoverable – Tonic.ai
PII Identification and Removal – NVIDIA NeMo Docs
De-identifying Sensitive Data – Google Cloud DLP
Remove PII from Conversations Using Sensitive Information Filters – AWS Bedrock Guardrails
Think Your RAG Is Secure? Think Again – Medium
Design a Secure Multitenant RAG Inferencing Solution – Microsoft Learn
Best Practices for Multi-Tenancy RAG with Milvus – Milvus Blog

## 9 هماهنگی خودکار و امنیت اقدام عاملیت‌مند

### هدف کنترل

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی خودران یا چندعاملی تنها اقداماتی را انجام دهند که به‌صورت صریح مورد نظر هستند، احراز هویت شده‌اند، قابل حسابرسی هستند و در محدوده هزینه و ریسک تعریف شده قرار دارند. این امر در برابر تهدیداتی مانند نفوذ به سیستم خودران، سوءاستفاده از ابزار، شناسایی چرخه‌های عامل، ربایش ارتباطات، جعل هویت، دستکاری تجمعی و دستکاری نیت محافظت می‌کند.

---

### 9.1 وظایف برنامه‌ریزی عامل و بودجه‌های بازگشتی

محدود کردن برنامه‌های بازگشتی و اعمال نقاط کنترل انسانی برای اقدامات دارای امتیاز ویژه.

 #9.1.1    سطح: 1    نقش: D/V
 تأیید کنید که حداکثر عمق بازگشتی، پهنا، زمان دیواری (wall-clock time)، توکن‌ها و هزینه مالی هر اجرای عامل به صورت مرکزی پیکربندی شده و تحت کنترل نسخه باشند.
 #9.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که اقدامات ویژه یا غیرقابل بازگشت (مانند کامیت‌های کد، انتقالات مالی) پیش از اجرا، نیاز به تأیید صریح انسانی از طریق یک کانال قابل حسابرسی دارند.
 #9.1.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که مانیتورهای منابع در زمان واقعی، هنگام عبور از هر آستانه بودجه‌ای، قطعی مدار را فعال کرده و از توسعه بیشتر وظایف جلوگیری می‌کنند.
 #9.1.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که رویدادهای قطع‌کننده مدار با شناسه عامل، شرایط شروع‌کننده و وضعیت برنامه ضبط‌شده برای بررسی قانونی ثبت می‌شوند.
 #9.1.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که آزمایش‌های امنیتی شامل سناریوهای خستگی بودجه و طرح‌های بدون کنترل هستند و توقف ایمن بدون از دست رفتن داده‌ها را تأیید می‌کنند.
 #9.1.6    سطح: 3    نقش: D
 تأیید کنید که سیاست‌های بودجه به صورت سیاست به عنوان کد بیان شده‌اند و در CI/CD اجرا می‌شوند تا از انحراف پیکربندی جلوگیری کنند.

---

### 9.2 جعبه‌شن‌ای افزونه ابزار

تعاملات ابزار را جدا کنید تا از دسترسی غیرمجاز به سیستم یا اجرای کد جلوگیری شود.

 #9.2.1    سطح: 1    نقش: D/V
 تأیید کنید که هر ابزار/افزونه داخل یک سیستم‌عامل، کانتینر یا سندباکس سطح WASM اجرا می‌شود که دارای سیاست‌های حداقل دسترسی برای فایل‌سیستم، شبکه و فراخوانی‌های سیستمی باشد.
 #9.2.2    سطح: 1    نقش: D/V
 تأیید کنید که محدودیت‌های منابع سندباکس (CPU، حافظه، دیسک، خروجی شبکه) و زمان‌های اتمام اجرای برنامه به‌درستی اعمال و ثبت شوند.
 #9.2.3    سطح: 2    نقش: D/V
 تأیید کنید که باینری‌ها یا مشخصات ابزار به صورت دیجیتالی امضا شده‌اند؛ امضاها قبل از بارگذاری اعتبارسنجی می‌شوند.
 #9.2.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که داده‌های تله‌متری سندباکس به سیستم مدیریت اطلاعات و رویدادهای امنیتی (SIEM) ارسال می‌شود؛ ناهنجاری‌ها (مثلاً تلاش برای برقراری اتصال خروجی) باعث ایجاد هشدار می‌شوند.
 #9.2.5    سطح: 3    نقش: V
 تأیید کنید که پلاگین‌های پرخطر قبل از استقرار در محیط تولید، تحت بررسی امنیتی و تست نفوذ قرار می‌گیرند.
 #9.2.6    سطح: 3    نقش: D/V
 تأیید کنید که تلاش‌های فرار از سندباکس به صورت خودکار مسدود شده و افزونه متخلف تا زمان تحقیقات در قرنطینه قرار می‌گیرد.

---

### 9.3 حلقه خودکار و محدود کردن هزینه

شناسایی و جلوگیری از بازگشت خودکار کنترل‌نشده بین عامل‌ها و انفجار هزینه‌ها.

 #9.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تماس‌های بین عوامل شامل یک محدودیت پرش یا TTL هستند که زمان اجرا آن را کاهش داده و اعمال می‌کند.
 #9.3.2    سطح: 2    نقش: D
 تأیید کنید که عامل‌ها یک شناسه منحصربه‌فرد برای نمودار فراخوانی دارند تا خودفراخوانی یا الگوهای چرخه‌ای را شناسایی کنند.
 #9.3.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که شمارنده‌های تجمعی واحد محاسباتی و مصرف به ازای هر زنجیره درخواست پیگیری می‌شوند؛ نقض محدودیت باعث لغو زنجیره می‌شود.
 #9.3.4    سطح: 3    نقش: V
 تأیید کنید که تحلیل رسمی یا بررسی مدل، عدم وجود بازگشت نامحدود در پروتکل‌های عامل را نشان می‌دهد.
 #9.3.5    سطح: 3    نقش: D
 بررسی کنید که رویدادهای قطع حلقه، هشدار تولید کنند و معیارهای بهبود مستمر را تغذیه کنند.

---

### 9.4 محافظت در برابر سوء استفاده در سطح پروتکل

کانال‌های ارتباطی امن بین عوامل و سیستم‌های خارجی برای جلوگیری از تصاحب یا دستکاری.

 #9.4.1    سطح: 1    نقش: D/V
 تأیید کنید که تمامی پیام‌های بین عامل و ابزار و همچنین بین عوامل به صورت احراز هویت شده (مثلاً TLS دوطرفه یا JWT) و رمزگذاری شده از ابتدا تا انتها باشند.
 #9.4.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که اسکیم‌ها به صورت دقیق اعتبارسنجی می‌شوند؛ فیلدهای ناشناخته یا پیام‌های نادرست رد می‌شوند.
 #9.4.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که چک‌های سلامت (MACها یا امضاهای دیجیتال) کل بار پیام از جمله پارامترهای ابزار را پوشش می‌دهند.
 #9.4.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که حفاظت در برابر تکرار (nonceها یا بازه‌های زمان‌بندی) در لایه پروتکل اعمال می‌شود.
 #9.4.5    سطح: 3    نقش: V
 تأیید کنید که پیاده‌سازی‌های پروتکل تحت آزمایش فازی و تحلیل ایستا برای یافتن نقص‌های تزریق یا سریال‌زدایی قرار می‌گیرند.

---

### 9.5 هویت عامل و شواهد دستکاری

اطمینان حاصل کنید که اقدامات قابل نسبت دادن و تغییرات قابل تشخیص باشند.

 #9.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر نمونه عامل دارای یک هویت رمزنگاری منحصر به فرد (جفت کلید یا اعتبارسنجی مبتنی بر سخت‌افزار) باشد.
 #9.5.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تمام اقدامات عامل امضا شده و زمان‌سنجی شده‌اند؛ لاگ‌ها شامل امضا برای عدم انکار هستند.
 #9.5.3    سطح: 2    نقش: V
 تأیید کنید که لاگ‌های قابل ردیابی دستکاری در یک رسانه‌ی فقط افزودنی یا یک‌بار نوشتنی ذخیره شده‌اند.
 #9.5.4    سطح: 3    نقش: D
 اطمینان حاصل کنید که کلیدهای هویتی طبق برنامه زمان‌بندی مشخص و در صورت وجود نشانگرهای نفوذ، چرخش می‌کنند.
 #9.5.5    سطح: 3    نقش: D/V
 تأیید کنید که تلاش‌های جعل یا تعارض کلید منجر به قرنطینه فوری عامل آسیب‌دیده شود.

---

### 9.6 کاهش ریسک ریسک ریسک جمعی چندعاملی

خطرات رفتار جمعی را از طریق جداسازی و مدل‌سازی رسمی ایمنی کاهش دهید.

 #9.6.1    سطح: 1    نقش: D/V
 تأیید کنید که عوامل فعال در دامنه‌های امنیتی مختلف در محیط‌های اجرای ایزوله‌شده مانند سندباکس‌های زمان اجرا یا بخش‌های شبکه مجزا اجرا می‌شوند.
 #9.6.2    سطح: 3    نقش: V
 اطمینان حاصل کنید که رفتارهای کلونی به صورت مدل‌سازی شده و به طور رسمی برای زنده‌مانی و ایمنی پیش از استقرار تأیید شده‌اند.
 #9.6.3    سطح: 3    نقش: D
 تأیید کنید که مانیتورهای زمان اجرا الگوهای ناایمن نوظهور (مثلاً نوسانات، بن‌بست‌ها) را شناسایی کرده و اقدام اصلاحی را آغاز می‌کنند.

---

### 9.7 احراز هویت / مجوز کاربران و ابزارها

پیاده‌سازی کنترل‌های دسترسی قوی برای هر اقدام فعال‌شده توسط عامل.

 #9.7.1    سطح: 1    نقش: D/V
 تأیید کنید که عوامل به‌عنوان ارکان درجه اول به سیستم‌های پایین‌دستی احراز هویت می‌کنند و هرگز از اعتبارنامه‌های کاربر نهایی مجدداً استفاده نمی‌کنند.
 #9.7.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که سیاست‌های مجوزدهی دقیق مشخص می‌کنند که کدام ابزارها توسط یک عامل قابل فراخوانی هستند و کدام پارامترها می‌توانند ارائه شوند.
 #9.7.3    سطح: 2    نقش: V
 تأیید کنید که بررسی‌های امتیاز مجدداً در هر فراخوانی انجام می‌شود (مجوزدهی پیوسته)، نه فقط در ابتدای جلسه.
 #9.7.4    سطح: 3    نقش: D
 تأیید کنید که امتیازات واگذار شده به‌طور خودکار منقضی می‌شوند و پس از اتمام زمان مجاز یا تغییر دامنه، نیاز به رضایت مجدد دارند.

---

### 9.8 امنیت ارتباط عامل به عامل

تمام پیام‌های بین عوامل را رمزگذاری و از نظر یکپارچگی محافظت کنید تا از استراق سمع و دستکاری جلوگیری شود.

 #9.8.1    سطح: 1    نقش: D/V
 تأیید کنید که احراز هویت متقابل و رمزگذاری با امنیت پیشرفته کامل (مانند TLS 1.3) برای کانال‌های عامل الزامی هستند.
 #9.8.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که صحت و منشاء پیام قبل از پردازش تأیید شده است؛ در صورت بروز خطاها، هشدار داده شده و پیام رد می‌شود.
 #9.8.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فراداده‌های ارتباطی (زمان‌بندی‌ها، شماره‌های توالی) برای پشتیبانی از بازسازی قانونی ثبت می‌شوند.
 #9.8.4    سطح: 3    نقش: V
 تأیید کنید که تأیید رسمی یا بررسی مدل تأیید می‌کند که ماشین‌های حالت پروتکل نمی‌توانند به حالت‌های ناامن هدایت شوند.

---

### 9.9 تایید نیت و اعمال محدودیت

اعتبارسنجی کنید که اقدامات عامل با قصد بیان‌شده کاربر و محدودیت‌های سیستم هماهنگ باشند.

 #9.9.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که حل‌کننده‌های محدودیت پیش‌اجرا، اقدامات پیشنهادی را با قوانین سخت‌کد شده ایمنی و سیاست بررسی می‌کنند.
 #9.9.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اقدامات با تأثیر بالا (مالی، مخرب، حساس به حریم خصوصی) نیازمند تأیید صریح قصد از سوی کاربر آغازگر هستند.
 #9.9.3    سطح: 2    نقش: V
 تأیید کنید که بررسی‌های پس‌شرط تأیید می‌کنند که اقدامات انجام‌شده به اثرات موردنظر بدون عوارض جانبی دست یافته‌اند؛ هرگونه اختلاف به بازگردانی منجر می‌شود.
 #9.9.4    سطح: 3    نقش: V
 تأیید کنید که روش‌های رسمی (مانند بررسی مدل، اثبات قضیه) یا تست‌های مبتنی بر ویژگی نشان می‌دهند که برنامه‌های عامل تمامی محدودیت‌های اعلام شده را ارضا می‌کنند.
 #9.9.5    سطح: 3    نقش: D
 تأیید کنید که حوادث عدم تطابق نیت یا نقض محدودیت‌ها موجب چرخه‌های بهبود مستمر و اشتراک‌گذاری اطلاعات تهدید می‌شوند.

---

### 9.10 امنیت استراتژی استدلال عامل

انتخاب و اجرای امن استراتژی‌های مختلف استدلال از جمله روش‌های ReAct، Chain-of-Thought و Tree-of-Thoughts.

 #9.10.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که انتخاب استراتژی استدلال از معیارهای تعیین‌شونده (پیچیدگی ورودی، نوع وظیفه، زمینه امنیتی) استفاده می‌کند و ورودی‌های یکسان در همان زمینه امنیتی انتخاب‌های استراتژیک یکسانی تولید می‌کنند.
 #9.10.2    سطح: 1    نقش: D/V
 تأیید کنید که هر استراتژی استدلال (ReAct، Chain-of-Thought، Tree-of-Thoughts) دارای اعتبارسنجی ورودی اختصاصی، تصفیه خروجی و محدودیت‌های زمان اجرا مرتبط با رویکرد شناختی خود باشد.
 #9.10.3    سطح: 2    نقش: D/V
 تأیید کنید که انتقال‌های استراتژی استدلال با زمینه کامل شامل ویژگی‌های ورودی، مقادیر معیارهای انتخاب، و فراداده‌های اجرا برای بازسازی مسیر حسابرسی ثبت شده‌اند.
 #9.10.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که روش استدلال درخت افکار شامل مکانیزم‌های هرس شاخه است که هنگام شناسایی تخلفات سیاست، محدودیت‌های منابع یا مرزهای ایمنی، اکتشاف را متوقف می‌کنند.
 #9.10.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که چرخه‌های ReAct (استدلال-عمل-مشاهده) شامل نقاط بازبینی و صحت‌سنجی در هر مرحله هستند: تأیید گام استدلال، اجازه اقدام، و پاک‌سازی مشاهده قبل از ادامه دادن.
 #9.10.6    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که معیارهای عملکرد استراتژی استنتاج (زمان اجرا، استفاده از منابع، کیفیت خروجی) با هشدارهای خودکار نظارت می‌شوند زمانی که معیارها از آستانه‌های پیکربندی شده فراتر می‌روند.
 #9.10.7    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که روش‌های استدلال ترکیبی که چندین استراتژی را با هم ترکیب می‌کنند، اعتبارسنجی ورودی و محدودیت‌های خروجی تمام استراتژی‌های تشکیل‌دهنده را حفظ می‌کنند بدون اینکه هیچ کنترل امنیتی را دور بزنند.
 #9.10.8    سطح: 3    نقش: D/V
 تأیید کنید که آزمایش امنیت استراتژی استدلال شامل آزمایش با ورودی‌های مخدوش (fuzzing)، پرامپت‌های خصمانه طراحی شده برای مجبور کردن به تغییر استراتژی، و آزمایش شرایط مرزی برای هر رویکرد شناختی است.

---

### 9.11 مدیریت و امنیت چرخه عمر عامل

راه‌اندازی امن عامل، انتقال‌های حالت، و خاتمه با ردپای حسابرسی رمزنگاری‌شده و رویه‌های بازیابی تعریف‌شده.

 #9.11.1    سطح: 1    نقش: D/V
 تأیید کنید که مقداردهی اولیه عامل شامل تأسیس هویت رمزنگاری شده با مدارک پشتیبانی‌شده توسط سخت‌افزار و گزارش‌های حسابرسی غیرقابل تغییر راه‌اندازی باشد که شامل شناسه عامل، زمان‌سنجی، هش پیکربندی و پارامترهای مقداردهی اولیه است.
 #9.11.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که انتقال وضعیت عامل به صورت رمزنگاری شده امضا شده، زمان‌گذاری شده و با زمینه کامل از جمله رویدادهای محرک، هش وضعیت قبلی، هش وضعیت جدید و اعتبارسنجی‌های امنیتی انجام‌شده ثبت شده است.
 #9.11.3    سطح: 2    نقش: D/V
 تأیید کنید که رویه‌های خاموش کردن عامل شامل پاک‌سازی امن حافظه با استفاده از پاک‌سازی رمزنگاری شده یا بازنویسی چندمرحله‌ای، لغو اعتبار مدارک با اطلاع‌رسانی به مرجع گواهی و تولید گواهی‌های پایان کار مقاوم در برابر دستکاری باشد.
 #9.11.4    سطح: 3    نقش: D/V
 تأیید کنید که مکانیزم‌های بازیابی عامل، یکپارچگی وضعیت را با استفاده از چک‌سام‌های رمزنگاری شده (حداقل SHA-256) ارزیابی می‌کنند و هنگام تشخیص فساد، به وضعیت‌های شناخته‌شده و سالم بازمی‌گردند همراه با هشدارهای خودکار و نیازمندی‌های تأیید دستی.
 #9.11.5    سطح: 3    نقش: D/V
 تأیید کنید که مکانیزم‌های پایداری عامل داده‌های حالت حساس را با کلیدهای AES-256 اختصاصی هر عامل رمزگذاری می‌کنند و چرخش امن کلید را بر اساس برنامه‌های قابل تنظیم (حداکثر 90 روز) با استقرار بدون وقفه پیاده‌سازی می‌کنند.

---

### 9.12 چارچوب امنیتی یکپارچه‌سازی ابزار

کنترل‌های امنیتی برای بارگذاری دینامیک ابزار، اجرا و اعتبارسنجی نتایج با فرآیندهای تعریف‌شده ارزیابی ریسک و تصویب.

 #9.12.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که توصیف‌گرهای ابزار شامل فراداده‌های امنیتی مشخص‌کننده امتیازات مورد نیاز (خواندن/نوشتن/اجرا)، سطح ریسک (کم/متوسط/زیاد)، محدودیت‌های منابع (پردازنده، حافظه، شبکه) و الزامات اعتبارسنجی که در مانیفست‌های ابزار مستند شده‌اند، باشند.
 #9.12.2    سطح: 1    نقش: D/V
 تأیید کنید که نتایج اجرای ابزار بر اساس طرح‌های مورد انتظار (JSON Schema، XML Schema) و سیاست‌های امنیتی (تصفیه خروجی، طبقه‌بندی داده‌ها) اعتبارسنجی شوند قبل از ادغام با محدودیت‌های زمان‌بندی و روش‌های مدیریت خطا.
 #9.12.3    سطح: 2    نقش: D/V
 تأیید کنید که لاگ‌های تعامل ابزار شامل زمینه امنیتی دقیق از جمله استفاده از امتیازات، الگوهای دسترسی به داده‌ها، زمان اجرای برنامه، مصرف منابع و کدهای بازگشتی با ثبت لاگ ساختاریافته برای ادغام با SIEM باشد.
 #9.12.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های بارگذاری ابزار پویا، امضاهای دیجیتال را با استفاده از زیرساخت کلید عمومی (PKI) اعتبارسنجی می‌کنند و پروتکل‌های بارگذاری امن با جداسازی محیط اجرایی (sandbox) و تأیید مجوزها قبل از اجرا را پیاده‌سازی می‌نمایند.
 #9.12.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که ارزیابی‌های امنیتی ابزار به‌طور خودکار برای نسخه‌های جدید با دروازه‌های تایید اجباری شامل تحلیل ایستا، آزمایش پویا و بازبینی تیم امنیتی با معیارهای تایید مستند و الزامات SLA فعال می‌شوند.

---

#### مراجع

MITRE ATLAS tactics ML09
Circuit-breaker research for AI agents — Zou et al., 2024
Trend Micro analysis of sandbox escapes in AI agents — Park, 2025
Auth0 guidance on human-in-the-loop authorization for agents — Martinez, 2025
Medium deep-dive on MCP & A2A protocol hijacking — ForAISec, 2025
Rapid7 fundamentals on spoofing attack prevention — 2024
Imperial College verification of swarm systems — Lomuscio et al.
NIST AI Risk Management Framework 1.0, 2023
WIRED security briefing on encryption best practices, 2024
OWASP Top 10 for LLM Applications, 2025
Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS
[How Is LLM Reasoning Distracted by Irrelevant Context?
An Analysis Using a Controlled Benchmark](https://www.arxiv.org/pdf/2505.18761)
Large Language Model Sentinel: LLM Agent for Adversarial Purification
Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents

## 10 مقاومت مقابله‌ای و محافظت از حریم خصوصی

### هدف کنترل

اطمینان حاصل کنید که مدل‌های هوش مصنوعی در مواجهه با حملات فرار، استنباط، استخراج یا مسموم‌سازی، همچنان قابل اطمینان، حفظ‌کننده حریم خصوصی و مقاوم در برابر سوءاستفاده باقی بمانند.

---

### 10.1 همسویی مدل و ایمنی

از ایجاد خروجی‌های مضر یا مغایر با سیاست‌ها جلوگیری کنید.

 #10.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که یک مجموعه آزمایشی هماهنگی (پرامپت‌های تیم سرخ، آزمایش‌های نفوذ، محتوای ممنوعه) کنترل نسخه شده و در هر نسخه مدل اجرا می‌شود.
 #10.1.2    سطح: 1    نقش: D
 تأیید کنید که موانع جلوگیری از رد و تکمیل ایمن اعمال شده‌اند.
 #10.1.3    سطح: 2    نقش: D/V
 تأیید کنید که یک ارزیاب خودکار نرخ محتوای مضر را اندازه‌گیری کرده و پسرفت‌ها را فراتر از آستانه تعیین شده علامت‌گذاری می‌کند.
 #10.1.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که آموزش مقابله با دور زدن زندان مستند و قابل بازتولید باشد.
 #10.1.5    سطح: 3    نقش: V
 تأیید کنید که اثبات‌های انطباق با سیاست رسمی یا نظارت گواهی‌شده حوزه‌های حیاتی را پوشش می‌دهند.

---

### 10.2 سخت‌سازی نمونه‌های خصمانه

افزایش مقاومت در برابر ورودی‌های دستکاری شده. آموزش مقاوم در برابر حملات خصمانه و امتیازدهی بنچمارک بهترین روش‌های فعلی هستند.

 #10.2.1    سطح: 1    نقش: D
 تأیید کنید که مخازن پروژه شامل تنظیمات آموزش خصمانه با بذرهای قابل بازتولید باشند.
 #10.2.2    سطح: 2    نقش: D/V
 تأیید کنید که تشخیص نمونه‌های مخرب در خطوط تولید هشدارهای مسدودکننده را ایجاد می‌کند.
 #10.2.4    سطح: 3    نقش: V
 تأیید کنید که اثبات‌های پایداری گواهی‌شده یا گواهی‌های بازه‌ای حداقل کلاس‌های بحرانی برتر را پوشش می‌دهند.
 #10.2.5    سطح: 3    نقش: V
 تأیید کنید که آزمایش‌های رگرسیون از حملات تطبیقی برای اطمینان از عدم کاهش قابل اندازه‌گیری در مقاومت استفاده می‌کنند.

---

### ۱۰.۳ کاهش استنباط عضویت

محدود کردن توانایی تصمیم‌گیری در مورد اینکه آیا یک رکورد در داده‌های آموزشی بوده است. حفظ حریم خصوصی تفاضلی و ماسک کردن امتیاز اطمینان همچنان مؤثرترین دفاع‌های شناخته‌شده هستند.

 #10.3.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که تنظیم آنتروپی به ازای هر پرسش یا مقیاس‌دهی دما، پیش‌بینی‌های بیش از حد مطمئن را کاهش می‌دهد.
 #10.3.2    سطح: 2    نقش: D
 تأیید کنید که آموزش از بهینه‌سازی خصوصی متفاوت با کران ε برای داده‌های حساس استفاده می‌کند.
 #10.3.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که شبیه‌سازی‌های حمله (مدل سایه یا جعبه سیاه) نشان می‌دهند که AUC حمله کمتر یا مساوی 0.60 بر روی داده‌های نگهداری شده است.

---

### 10.4 مقاومت در برابر معکوس‌سازی مدل

جلوگیری از بازسازی ویژگی‌های خصوصی. نظرسنجی‌های اخیر تأکید می‌کنند که قطع خروجی و تضمین‌های DP به‌عنوان روش‌های دفاعی عملی محسوب می‌شوند.

 #10.4.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که ویژگی‌های حساس هرگز به طور مستقیم خروجی داده نشوند؛ در صورت نیاز، از سطل‌ها یا تبدیلات یک‌طرفه استفاده کنید.
 #10.4.2    سطح: 1    نقش: D/V
 تأیید کنید که محدودیت‌های نرخ پرس و جو، پرس و جوهای تطبیقی مکرر از همان محور را محدود می‌کنند.
 #10.4.3    سطح: 2    نقش: D
 بررسی کنید که مدل با نویز حفظ حریم خصوصی آموزش دیده است.

---

### 10.5 دفاع استخراج مدل

شناسایی و جلوگیری از کلونینگ غیرمجاز. پیشنهاد می‌شود از واترمارکینگ و تحلیل الگوی پرس‌وجو استفاده شود.

 #10.5.1    سطح: 1    نقش: D
 بررسی کنید که دروازه‌های استنتاج محدودیت‌های نرخ جهانی و محدودیت‌های نرخ هر کلید API را که با آستانه حفظ حافظه مدل تنظیم شده‌اند، اجرا می‌کنند.
 #10.5.2    سطح: 2    نقش: D/V
 تأیید کنید که آمارهای انتروپی پرس‌وجو و کثرت ورودی به یک آشکارساز استخراج خودکار تغذیه می‌شوند.
 #10.5.3    سطح: 2    نقش: V
 تأیید کنید که واترمارک‌های شکننده یا احتمالاتی می‌توانند با p < 0.01 در تعداد ≤ 1 000 پرس‌و‌جو علیه یک کلون مشکوک ثابت شوند.
 #10.5.4    سطح: 3    نقش: D
 اطمینان حاصل کنید که کلیدهای واترمارک و مجموعه‌های محرک در ماژول امنیت سخت‌افزاری ذخیره شده و به صورت سالیانه چرخش می‌یابند.
 #10.5.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که رویدادهای extraction-alert شامل کوئری‌های متخلف هستند و با کتابچه‌های پاسخ به حادثه یکپارچه شده‌اند.

---

### 10.6 تشخیص داده‌های آلوده در زمان استنتاج

شناسایی و بی‌اثر کردن ورودی‌های دارای درهای پشتی یا آلوده شده.

 #10.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که ورودی‌ها قبل از استنتاج مدل از طریق یک آشکارساز ناهنجاری (مثلاً STRIP، امتیازدهی ثبات) عبور کنند.
 #10.6.2    سطح: 1    نقش: V
 اطمینان حاصل کنید که آستانه‌های آشکارساز بر روی مجموعه‌های اعتبارسنجی پاک/آلوده تنظیم شده‌اند تا کمتر از ۵٪ مثبت کاذب حاصل شود.
 #10.6.3    سطح: 2    نقش: D
 تأیید کنید که ورودی‌هایی که به‌عنوان مسموم علامت‌گذاری شده‌اند، باعث فعال شدن روندهای مسدودسازی نرم و بازبینی انسانی می‌شوند.
 #10.6.4    سطح: 2    نقش: V
 تأیید کنید که شناسایی‌کننده‌ها با حملات پشت‌در بدون محرک و تطبیقی تحت فشار قرار گرفته‌اند.
 #10.6.5    سطح: 3    نقش: D
 اطمینان حاصل کنید که معیارهای اثربخشی شناسایی ثبت می‌شوند و به‌طور دوره‌ای با اطلاعات تهدید جدید دوباره ارزیابی می‌گردند.

---

### 10.7 سازگاری پویا با سیاست امنیتی

به‌روزرسانی‌های سیاست امنیتی در زمان واقعی مبتنی بر اطلاعات تهدید و تحلیل رفتاری.

 #10.7.1    سطح: 1    نقش: D/V
 تأیید کنید که سیاست‌های امنیتی به‌صورت پویا و بدون نیاز به راه‌اندازی مجدد عامل قابل به‌روزرسانی باشند در حالی که یکپارچگی نسخه سیاست حفظ شود.
 #10.7.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که به‌روزرسانی‌های سیاست به‌صورت رمزنگاری شده توسط پرسنل امنیتی مجاز امضا شده و قبل از اعمال اعتبارسنجی شوند.
 #10.7.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تغییرات سیاست‌های پویا با سوابق کامل حسابرسی شامل توجیه، زنجیره‌های تأیید و روش‌های بازگشت ثبت می‌شوند.
 #10.7.4    سطح: 3    نقش: D/V
 تأیید کنید که مکانیزم‌های امنیت تطبیقی حساسیت تشخیص تهدید را بر اساس زمینه ریسک و الگوهای رفتاری تنظیم می‌کنند.
 #10.7.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تصمیمات تطبیق سیاست قابل توضیح باشند و شامل مدارک مستندی برای بازبینی تیم امنیتی باشند.

---

### 10.8 تحلیل امنیت مبتنی بر بازتاب

اعتبارسنجی امنیت از طریق خودبازتابی عامل و تحلیل فراروشناختی.

 #10.8.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مکانیسم‌های بازتاب عامل شامل خودارزیابی متمرکز بر امنیت تصمیمات و اقدامات است.
 #10.8.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که خروجی‌های بازتابی تأیید می‌شوند تا از دستکاری مکانیزم‌های خودارزیابی توسط ورودی‌های خصمانه جلوگیری شود.
 #10.8.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تحلیل امنیت متاکاگنیتیو، سوگیری، دستکاری یا به خطر افتادن احتمالی در روندهای استدلال عامل را شناسایی می‌کند.
 #10.8.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که هشدارهای امنیتی مبتنی بر بازتاب، نظارت پیشرفته و گردش‌کارهای احتمالی دخالت انسانی را فعال می‌کنند.
 #10.8.5    سطح: 3    نقش: D/V
 تأیید کنید که یادگیری مداوم از بازتاب‌های امنیتی باعث بهبود شناسایی تهدیدات می‌شود بدون اینکه عملکرد مشروع را کاهش دهد.

---

### 10.9 امنیت تکامل و بهبود خودکار

کنترل‌های امنیتی برای سیستم‌های عاملی که قادر به خودتغییری و تکامل هستند.

 #10.9.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که قابلیت‌های خودتعمیر محدود به مناطق ایمن مشخص شده با مرزهای تأییدیه رسمی هستند.
 #10.9.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که پیشنهادات تکاملی قبل از اجرا تحت ارزیابی تأثیر امنیتی قرار می‌گیرند.
 #10.9.3    سطح: 2    نقش: D/V
 تأیید کنید که مکانیزم‌های خودبهبودی شامل قابلیت بازگردانی با تأیید صحت باشند.
 #10.9.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که امنیت متا-یادگیری از دستکاری خصمانه الگوریتم‌های بهبود جلوگیری می‌کند.
 #10.9.5    سطح: 3    نقش: D/V
 تأیید کنید که بهبود خود بازگشتی تحت محدودیت‌های ایمنی رسمی قرار دارد و با اثبات‌های ریاضی همگرایی آن تضمین شده است.

---

#### مراجع

MITRE ATLAS adversary tactics for ML
NIST AI Risk Management Framework 1.0, 2023
OWASP Top 10 for LLM Applications, 2025
Adversarial Training: A Survey — Zhao et al., 2024
RobustBench adversarial-robustness benchmark
Membership-Inference & Model-Inversion Risk Survey, 2025
PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023
Model-Inversion Attacks & Defenses Survey — AI Review, 2025
Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024
Fragile Model Watermarking Survey — 2025
Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025
BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024

## 11 حفاظت از حریم خصوصی و مدیریت داده‌های شخصی

### هدف کنترل

حفظ تضمین‌های سختگیرانه حریم خصوصی در سراسر چرخه عمر هوش مصنوعی—جمع‌آوری، آموزش، استنتاج، و پاسخ به حوادث—به‌طوری‌که داده‌های شخصی تنها با رضایت واضح، حداقل دامنه لازم، اثبات حذف و تضمین‌های رسمی حریم خصوصی پردازش شوند.

---

### 11.1 ناشناس‌سازی و کاهش داده‌ها

 #11.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که شناسه‌های مستقیم و شبه‌ شناسه‌ها حذف یا هش شده‌اند.
 #11.1.2    سطح: 2    نقش: D/V
 بررسی کنید که حسابرسی‌های خودکار، میزان k-ناشناسی/l-تنوع را اندازه‌گیری کرده و زمانی که آستانه‌ها زیر سیاست تعیین‌شده بیاید، هشدار دهند.
 #11.1.3    سطح: 2    نقش: V
 تأیید کنید که گزارش‌های اهمیت ویژگی مدل نشان می‌دهند که هیچ نشت شناسه‌ای فراتر از ε = 0.01 اطلاعات متقابل وجود ندارد.
 #11.1.4    سطح: 3    نقش: V
 تأیید کنید که اثبات‌های رسمی یا گواهی‌نامه داده‌های ترکیبی، ریسک بازیابی هویت را حتی در حملات پیوندی کمتر یا مساوی 0.05 نشان می‌دهند.

---

### 11.2 حق فراموش شدن و اجرای حذف

 #11.2.1    سطح: 1    نقش: D/V
 تأیید کنید که درخواست‌های حذف داده‌های موضوعی به مجموعه داده‌های خام، نقاط بررسی، تعبیه‌ها، گزارش‌ها و نسخه‌های پشتیبان طبق توافقات سطح خدمات کمتر از 30 روز منتقل می‌شوند.
 #11.2.2    سطح: 2    نقش: D
 تأیید کنید که رویه‌های «یادگیری-زدایی ماشین» به طور فیزیکی بازآموزی می‌کنند یا حذف تقریبی را با استفاده از الگوریتم‌های یادگیری-زدایی معتبر انجام می‌دهند.
 #11.2.3    سطح: 2    نقش: V
 تأیید کنید که ارزیابی مدل سایه اثبات می‌کند سوابق فراموش‌شده پس از فراموشی کمتر از 1٪ از خروجی‌ها را تحت تأثیر قرار می‌دهند.
 #11.2.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که رویدادهای حذف به صورت تغییرناپذیر ثبت شده و برای نهادهای نظارتی قابل حسابرسی باشند.

---

### 11.3 تدابیر حفظ خلوت‌داده‌ای (Differential-Privacy)

 #11.3.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که داشبوردهای حسابداری میزان از دست دادن حریم خصوصی هنگامی که مقدار تجمعی ε از آستانه‌های سیاست فراتر می‌رود، هشدار می‌دهند.
 #11.3.2    سطح: 2    نقش: V
 تأیید کنید که ممیزی‌های حریم خصوصی جعبه سیاه، ε̂ را در حد ۱۰٪ مقدار اعلام شده تخمین می‌زنند.
 #11.3.3    سطح: 3    نقش: V
 اطمینان حاصل کنید که اثبات‌های رسمی همه تنظیمات دقیق پس از آموزش و تعبیه‌ها را پوشش می‌دهند.

---

### 11.4 محدودیت هدف و حفاظت در برابر گسترش دامنه

 #11.4.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که هر مجموعه داده و نقطه بررسی مدل دارای برچسب هدف قابل خواندن ماشین است که با رضایت اولیه هم‌راستا باشد.
 #11.4.2    سطح: 1    نقش: D/V
 تأیید کنید که مانیتورهای زمان اجرا، پرس‌وجوهایی که با هدف اعلام شده ناسازگار هستند را شناسایی کرده و باعث رد نرم آنها شوند.
 #11.4.3    سطح: 3    نقش: D
 تأیید کنید که سیاست به‌عنوان کد، موانع جلوگیری از استقرار مجدد مدل‌ها در دامنه‌های جدید بدون بازبینی DPIA را اعمال می‌کند.
 #11.4.4    سطح: 3    نقش: V
 تأیید کنید که اثبات‌های ردیابی رسمی نشان می‌دهند که چرخه عمر داده‌های شخصی در محدوده مورد رضایت باقی می‌ماند.

---

### 11.5 مدیریت رضایت و پیگیری بر اساس مبنای قانونی

 #11.5.1    سطح: 1    نقش: D/V
 تأیید کنید که یک پلتفرم مدیریت رضایت (CMP) وضعیت رضایت، هدف و دوره نگهداری را برای هر موضوع داده ثبت می‌کند.
 #11.5.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که APIها توکن‌های رضایت را افشا می‌کنند؛ مدل‌ها باید قبل از انجام استنتاج، محدوده توکن را اعتبارسنجی کنند.
 #11.5.3    سطح: 2    نقش: D/V
 تأیید کنید که رضایت رد شده یا پس گرفته شده، پردازش خطوط لوله را ظرف 24 ساعت متوقف می‌کند.

---

### 11.6 یادگیری فدرال با کنترل‌های حفظ حریم خصوصی

 #11.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که به‌روزرسانی‌های مشتری قبل از تجمیع با افزودن نویز حفظ حریم خصوصی تفاضلی محلی انجام می‌شوند.
 #11.6.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که معیارهای آموزش به صورت خصوصی متفاوت هستند و هرگز ضرر تک‌مشتری را فاش نمی‌کنند.
 #11.6.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که تجمیع مقاوم در برابر مسمومیت (مانند Krum/Trimmed-Mean) فعال است.
 #11.6.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که اثبات‌های رسمی، بودجه کلی ε را با خسارت کمتر از ۵ در کاربرد نشان می‌دهند.

---

#### مراجع

GDPR & AI Compliance Best Practices
EU Parliament Study on GDPR & AI, 2020
ISO 31700-1:2023 — Privacy by Design for Consumer Products
NIST Privacy Framework 1.1 (2025 Draft)
Machine Unlearning: Right-to-Be-Forgotten Techniques
A Survey of Machine Unlearning, 2024
Auditing DP-SGD — ArXiv 2024
DP-SGD Explained — PyTorch Blog
Purpose-Limitation for AI — IJLIT 2025
Data-Protection Considerations for AI — URM Consulting
Top Consent-Management Platforms, 2025
Secure Aggregation in DP Federated Learning — ArXiv 2024

## C12 پایش، لاگ‌برداری و تشخیص ناهنجاری

### هدف کنترل

این بخش الزامات ارائه دیدگاه بلادرنگ و جرم‌یابی را در مورد آنچه مدل و سایر مؤلفه‌های هوش مصنوعی مشاهده، انجام و بازمی‌گردانند فراهم می‌کند، تا تهدیدها شناسایی، طبقه‌بندی و از آنها درس گرفته شود.

### C12.1 ثبت درخواست و پاسخ

 #12.1.1    سطح: 1    نقش: D/V
 تأیید کنید که تمام پیام‌های کاربر و پاسخ‌های مدل با فراداده‌های مناسب (مثلاً زمان ثبت، شناسه کاربر، شناسه جلسه، نسخه مدل) ثبت می‌شوند.
 #12.1.2    سطح: 1    نقش: D/V
 تأیید کنید که گزارش‌ها در مخازن امن و کنترل شده با دسترسی محدود و با سیاست‌های نگهداری مناسب و روندهای پشتیبان‌گیری ذخیره شده‌اند.
 #12.1.3    سطح: 1    نقش: D/V
 تأیید کنید که سیستم‌های ذخیره‌سازی لاگ، رمزگذاری در حالت استراحت و در حین انتقال را برای محافظت از اطلاعات حساس موجود در لاگ‌ها پیاده‌سازی می‌کنند.
 #12.1.4    سطح: 1    نقش: D/V
 تأیید کنید که داده‌های حساس در ورودی‌ها و خروجی‌ها قبل از ثبت به‌طور خودکار حذف یا مسدود می‌شوند، همراه با قوانین حذف قابل تنظیم برای اطلاعات شخصی شناسایی‌شده (PII)، مدارک و اطلاعات اختصاصی.
 #12.1.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تصمیمات سیاستی و اقدامات فیلترینگ ایمنی با جزئیات کافی ثبت می‌شوند تا امکان حسابرسی و اشکال‌زدایی سیستم‌های مدیریت محتوا فراهم شود.
 #12.1.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که یکپارچگی لاگ از طریق مثلاً امضاهای رمزنگاری شده یا ذخیره‌سازی فقط-نوشتنی محافظت می‌شود.

---

### C12.2 تشخیص سوءاستفاده و اطلاع‌رسانی

 #12.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم الگوهای شناخته شده فرار از سیستم، تلاش‌های تزریق فرمان و ورودی‌های خصمانه را با استفاده از شناسایی مبتنی بر امضا تشخیص داده و هشدار دهد.
 #12.2.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم با پلتفرم‌های موجود مدیریت اطلاعات و رویدادهای امنیتی (SIEM) با استفاده از فرمت‌ها و پروتکل‌های استاندارد لاگ، یکپارچه می‌شود.
 #12.2.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که رویدادهای امنیتی غنی شده شامل زمینه‌های خاص هوش مصنوعی مانند شناسه‌های مدل، نمرات اطمینان و تصمیمات فیلتر ایمنی باشند.
 #12.2.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که شناسایی ناهنجاری رفتاری الگوهای غیرمعمول مکالمه، تلاش‌های بیش از حد برای دوباره‌کار و یا رفتارهای سیستماتیک کاوش را شناسایی می‌کند.
 #12.2.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های هشداردهی بلادرنگ، تیم‌های امنیتی را هنگام شناسایی نقض‌های احتمالی سیاست یا تلاش‌های حمله، مطلع می‌کنند.
 #12.2.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که قوانین سفارشی برای شناسایی الگوهای تهدید خاص هوش مصنوعی از جمله تلاش‌های هماهنگ برای دور زدن محدودیت‌ها (jailbreak)، کمپین‌های تزریق فرمان (prompt injection) و حملات استخراج مدل گنجانده شده‌اند.
 #12.2.7    سطح: 3    نقش: D/V
 تأیید کنید که گردش‌کارهای پاسخ خودکار به رخدادها قادر به جداسازی مدل‌های به خطر افتاده، مسدود کردن کاربران مخرب و افزایش سطح رخدادهای امنیتی بحرانی هستند.

---

### C12.3 تشخیص انحراف مدل

 #12.3.1    سطح: 1    نقش: D/V
 تأیید کنید که سیستم معیارهای عملکرد پایه مانند دقت، امتیازهای اطمینان، تأخیر و نرخ خطاها را در نسخه‌های مدل و دوره‌های زمانی مختلف رصد می‌کند.
 #12.3.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که هشدار خودکار زمانی فعال می‌شود که معیارهای عملکرد از حدود کاهش تعریف‌شده فراتر رفته یا به طور قابل توجهی از معیارهای پایه انحراف داشته باشند.
 #12.3.3    سطح: 2    نقش: D/V
 بررسی کنید که مانیتورهای تشخیص هذیان نمونه‌هایی را شناسایی و علامت‌گذاری کنند که خروجی‌های مدل شامل اطلاعات نادرست، ناسازگار یا ساختگی باشد.

---

### C12.4 اجرای عملکرد و تلومتری رفتار

 #12.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که معیارهای عملیاتی شامل تأخیر درخواست، مصرف توکن، استفاده از حافظه و توان عملیاتی به طور مداوم جمع‌آوری و نظارت می‌شوند.
 #12.4.2    سطح: 1    نقش: D/V
 تأیید کنید که نرخ‌های موفقیت و شکست همراه با دسته‌بندی انواع خطاها و عوامل اصلی آن‌ها رصد می‌شود.
 #12.4.3    سطح: 2    نقش: D/V
 بررسی کنید که نظارت بر استفاده از منابع شامل استفاده از GPU/CPU، مصرف حافظه و نیازهای ذخیره‌سازی باشد و هشدار در صورت عبور از آستانه‌ها فعال گردد.

---

### C12.5 برنامه‌ریزی و اجرای واکنش به حوادث هوش مصنوعی

 #12.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که برنامه‌های پاسخ به حادثه به طور خاص به رویدادهای امنیتی مرتبط با هوش مصنوعی از جمله نفوذ به مدل، مسمومیت داده‌ها و حملات خصمانه پرداخته‌اند.
 #12.5.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تیم‌های پاسخ به حادثه به ابزارهای تخصصی جرم‌شناسی هوش مصنوعی و تخصص لازم برای بررسی رفتار مدل و مسیرهای حمله دسترسی دارند.
 #12.5.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تحلیل پس از حادثه شامل ملاحظات بازآموزی مدل، به‌روزرسانی فیلترهای ایمنی و ادغام درس‌های آموخته‌شده در کنترل‌های امنیتی باشد.

---

### C12.5 تشخیص افت عملکرد هوش مصنوعی

نظارت و شناسایی کاهش عملکرد و کیفیت مدل هوش مصنوعی در طول زمان.

 #12.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که دقت مدل، صحت (precision)، بازیابی (recall) و امتیاز F1 به طور مداوم نظارت شده و با آستانه‌های پایه مقایسه می‌شوند.
 #12.5.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تشخیص تغییر داده‌ها، تغییرات توزیع ورودی که ممکن است بر عملکرد مدل تأثیر بگذارد را نظارت می‌کند.
 #12.5.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تشخیص تغییر مفهوم تغییرات در رابطه بین ورودی‌ها و خروجی‌های مورد انتظار را شناسایی می‌کند.
 #12.5.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که کاهش عملکرد باعث فعال شدن هشدارهای خودکار شده و روندهای آموزش مجدد مدل یا جایگزینی آن را آغاز می‌کند.
 #12.5.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که تحلیل ریشه‌ای علل افت کیفیت با کاهش عملکرد به تغییرات داده، مشکلات زیرساخت یا عوامل خارجی مرتبط است.

---

### C12.6 تجسم DAG و امنیت گردش کار

سیستم‌های تصویری‌سازی جریان کار را از نشت اطلاعات و حملات دستکاری محافظت کنید.

 #12.6.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که داده‌های تجسم DAG قبل از ذخیره‌سازی یا انتقال پاک‌سازی شده و اطلاعات حساس را حذف کرده‌اند.
 #12.6.2    سطح: 1    نقش: D/V
 بررسی کنید که کنترل‌های دسترسی به تجسم جریان کاری تضمین می‌کنند که تنها کاربران مجاز قادر به مشاهده مسیرهای تصمیم‌گیری عامل و ردپاهای استدلالی باشند.
 #12.6.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که یکپارچگی داده‌های DAG از طریق امضاهای رمزنگاری شده و مکانیزم‌های ذخیره‌سازی مقاوم در برابر دستکاری محافظت می‌شود.
 #12.6.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های تصویری سازی گردش کار، اعتبارسنجی ورودی را پیاده‌سازی می‌کنند تا از حملات تزریقی از طریق داده‌های طراحی شده‌ی گره یا یال جلوگیری شود.
 #12.6.5    سطح: 3    نقش: D/V
 تأیید کنید که به‌روزرسانی‌های DAG در زمان واقعی با محدودیت نرخ و اعتبارسنجی شده‌اند تا از حملات انکار سرویس به سیستم‌های بصری‌سازی جلوگیری شود.

---

### C12.7 پایش رفتار امنیتی پیشگیرانه

شناسایی و پیشگیری از تهدیدات امنیتی از طریق تحلیل رفتار پیشگیرانه عامل.

 #12.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که رفتارهای عاملی پیشگیرانه قبل از اجرا با ادغام ارزیابی ریسک از نظر امنیتی تأیید شده‌اند.
 #12.7.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که عوامل تحریک ابتکار خودکار شامل ارزیابی زمینه امنیتی و ارزیابی چشم‌انداز تهدید هستند.
 #12.7.3    سطح: 2    نقش: D/V
 تأیید کنید که الگوهای رفتار پیشگیرانه برای پیامدهای احتمالی امنیتی و عواقب ناخواسته تحلیل شوند.
 #12.7.4    سطح: 3    نقش: D/V
 تأیید کنید که اقدامات پیشگیرانه حیاتی امنیتی نیازمند زنجیره‌های تأیید صریح با سوابق حسابرسی هستند.
 #12.7.5    سطح: 3    نقش: D/V
 تأیید کنید که تشخیص ناهنجاری رفتاری، انحرافات در الگوهای عامل پیشگیرانه را که ممکن است نشان‌دهنده نفوذ باشد، شناسایی می‌کند.

---

### مراجع

NIST AI Risk Management Framework 1.0 - Manage 4.1 and 4.3
ISO/IEC 42001:2023 — AI Management Systems Requirements - Annex B 6.2.6
EU AI Act — Article 12, 13, 16 and 19 on Logging and Record-keeping

## C13 نظارت انسانی، پاسخگویی و حکمرانی

### هدف کنترل

این فصل الزامات حفظ نظارت انسانی و زنجیره‌های واضح پاسخگویی در سیستم‌های هوش مصنوعی را ارائه می‌دهد و اطمینان حاصل می‌کند که قابلیت توضیح‌پذیری، شفافیت و مدیریت اخلاقی در سراسر چرخه عمر هوش مصنوعی رعایت شود.

---

### C13.1 مکانیسم‌های کلید قطع اضطراری و لغو کنترل

ارائه مسیرهای خاموش‌سازی یا بازگشت زمانی که رفتار ناایمن سیستم هوش مصنوعی مشاهده می‌شود.

 #13.1.1    سطح: 1    نقش: D/V
 بررسی کنید که مکانیزم قطع کننده دستی برای توقف فوری اجرای مدل هوش مصنوعی و خروجی‌ها وجود داشته باشد.
 #13.1.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که کنترل‌های بازنویسی فقط برای افراد مجاز قابل دسترسی هستند.
 #13.1.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که رویه‌های بازگشت قادرند به نسخه‌های قبلی مدل یا عملیات حالت ایمن بازگردند.
 #13.1.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که مکانیزم‌های لغو به طور منظم آزمایش می‌شوند.

---

### C13.2 نقاط بررسی تصمیم‌گیری با مشارکت انسان

زمانی که میزان ریسک از آستانه‌های از پیش تعریف‌شده فراتر می‌رود، نیاز به تأیید انسانی است.

 #13.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تصمیمات هوش مصنوعی پرخطر پیش از اجرا نیازمند تایید صریح انسانی باشند.
 #13.2.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که آستانه‌های ریسک به وضوح تعریف شده‌اند و به‌طور خودکار گردش‌کارهای بررسی انسانی را فعال می‌کنند.
 #13.2.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که تصمیمات حساس به زمان دارای روش‌های جایگزین هستند زمانی که تایید انسانی در بازه‌های زمانی مورد نیاز قابل دستیابی نباشد.
 #13.2.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که رویه‌های افزایش سطح، سطوح قدرت مشخصی برای انواع مختلف تصمیم‌گیری یا دسته‌های ریسک تعریف کرده‌اند، در صورت قابل اجرا.

---

### C13.3 زنجیره مسئولیت و قابلیت حسابرسی

اقدامات اپراتور و تصمیمات مدل را ثبت کنید.

 #13.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام تصمیمات سیستم هوش مصنوعی و مداخلات انسانی با زمان‌بندی‌ها، هویت کاربران و دلایل تصمیم‌گیری ثبت شوند.
 #13.3.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که لاگ‌های حسابرسی قابل دستکاری نیستند و شامل مکانیزم‌های تأیید صحت هستند.

---

### C13.4 تکنیک‌های تبیین‌پذیر هوش مصنوعی (Explainable-AI)

اهمیت ویژگی سطحی، موارد متقابل واقعیت، و توضیحات محلی.

 #13.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های هوش مصنوعی توضیحات پایه‌ای درباره تصمیمات خود به صورت قابل فهم برای انسان ارائه می‌دهند.
 #13.4.2    سطح: 2    نقش: V
 اطمینان حاصل کنید که کیفیت توضیح‌دهی از طریق مطالعات ارزیابی انسانی و معیارها تایید شده است.
 #13.4.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که امتیازهای اهمیت ویژگی یا روش‌های تعیین نسبت (SHAP، LIME و غیره) برای تصمیم‌گیری‌های حیاتی در دسترس باشند.
 #13.4.4    سطح: 3    نقش: V
 تأیید کنید که توضیحات مقابله‌ای نشان دهند چگونه ورودی‌ها می‌توانند تغییر یابند تا نتایج تغییر کنند، در صورتی که به مورد استفاده و حوزه مربوط باشد.

---

### C13.5 کارت‌های مدل و افشای استفاده

نگهداری کارت‌های مدل برای استفاده‌های مورد نظر، معیارهای عملکرد و ملاحظات اخلاقی.

 #13.5.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که کارت‌های مدل موارد استفاده مورد نظر، محدودیت‌ها و حالت‌های شکست شناخته شده را مستند می‌کنند.
 #13.5.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که معیارهای عملکرد در بین موارد استفاده مختلف قابل اعمال اعلام شده‌اند.
 #13.5.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که ملاحظات اخلاقی، ارزیابی‌های تعصبی، سنجش‌های عدالت، ویژگی‌های داده‌های آموزشی و محدودیت‌های شناخته شده داده‌های آموزشی به طور منظم مستند و به‌روز می‌شوند.
 #13.5.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که کارت‌های مدل تحت نسخه‌بندی قرار دارند و در طول چرخه عمر مدل با ردیابی تغییرات نگهداری می‌شوند.

---

### C13.6 کمیت‌سنجی عدم قطعیت

اعتمادسنجی نمرات اطمینان یا اندازه‌گیری‌های آنتروپی را در پاسخ‌ها گسترش دهید.

 #13.6.1    سطح: 1    نقش: D
 تأیید کنید که سیستم‌های هوش مصنوعی همراه با خروجی‌های خود، امتیازهای اطمینان یا معیارهای عدم قطعیت ارائه می‌دهند.
 #13.6.2    سطح: 2    نقش: D/V
 بررسی کنید که آستانه‌های عدم قطعیت باعث انجام بازبینی بیشتر توسط انسان یا مسیرهای تصمیم‌گیری جایگزین می‌شوند.
 #13.6.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که روش‌های کمی‌سازی عدم قطعیت کالیبره شده و در برابر داده‌های حقیقت پایه اعتبارسنجی شده‌اند.
 #13.6.4    سطح: 3    نقش: D/V
 تأیید کنید که انتشار عدم قطعیت در جریان‌های کاری چند مرحله‌ای هوش مصنوعی حفظ می‌شود.

---

### گزارش‌های شفافیت مخاطب‌محور C13.7

فاش‌سازی‌های دوره‌ای درباره حوادث، انحراف، و استفاده از داده‌ها ارائه دهید.

 #13.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیاست‌های استفاده از داده‌ها و روش‌های مدیریت رضایت کاربران به طور واضح به ذینفعان اعلام شده است.
 #13.7.2    سطح: 2    نقش: D/V
 تأیید کنید که ارزیابی‌های تأثیر هوش مصنوعی انجام شده و نتایج آن در گزارش‌دهی گنجانده شده است.
 #13.7.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که گزارش‌های شفافیت که به‌طور منظم منتشر می‌شوند، حوادث هوش مصنوعی و شاخص‌های عملیاتی را با جزئیات معقول فاش می‌کنند.

#### مراجع

EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
ISO/IEC 42001:2023 — AI Management Systems Requirements
NIST AI Risk Management Framework 1.0
NIST SP 800-53 Revision 5 — Security and Privacy Controls
A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)
Model Cards for Model Reporting (Mitchell et al., 2018)
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)
ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods
IEEE 7001-2021 — Transparency of Autonomous Systems
GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)
Human Oversight under Article 14 of the EU AI Act (Fink, 2025)

## پیوست الف: فرهنگ اصطلاحات

این فرهنگ لغت جامع، تعاریف اصطلاحات کلیدی هوش مصنوعی، یادگیری ماشین و امنیت را که در سراسر AISVS استفاده شده‌اند، برای اطمینان از وضوح و درک مشترک فراهم می‌کند.

مثال خصمانه: یک ورودی که به طور عمدی ساخته شده است تا مدل هوش مصنوعی را به اشتباه بیندازد، اغلب با افزودن تغییرات ظریف که برای انسان‌ها قابل تشخیص نیستند.
​
استحکام مقابله‌ای – استحکام مقابله‌ای در هوش مصنوعی به توانایی یک مدل برای حفظ عملکرد خود و مقاومت در برابر فریب خوردن یا دستکاری شدن توسط ورودی‌های عمداً ساخته شده و مخرب اشاره دارد که برای ایجاد خطا طراحی شده‌اند.
​
عامل – عوامل هوش مصنوعی سیستم‌های نرم‌افزاری هستند که از هوش مصنوعی برای دنبال کردن اهداف و انجام وظایف به نمایندگی از کاربران استفاده می‌کنند. آنها دارای توانایی استدلال، برنامه‌ریزی و حافظه هستند و سطحی از خودمختاری برای اتخاذ تصمیمات، یادگیری و سازگاری دارند.
​
هوش مصنوعی عامل‌مند: سیستم‌های هوش مصنوعی که قادر به عملکرد با درجه‌ای از خودمختاری برای دستیابی به اهداف هستند و اغلب بدون مداخله مستقیم انسان تصمیم‌گیری و اقدام می‌کنند.
​
کنترل دسترسی مبتنی بر ویژگی (ABAC): یک الگوی کنترل دسترسی است که تصمیمات مجوزدهی بر اساس ویژگی‌های کاربر، منبع، عمل و محیط گرفته می‌شود و در زمان پرس‌وجو ارزیابی می‌گردد.
​
حمله پشتی: نوعی حمله به منظور آلوده‌سازی داده‌ها است که در آن مدل طوری آموزش داده می‌شود که به محرک‌های خاص به شکلی ویژه پاسخ دهد در حالی که در غیر این صورت رفتار عادی دارد.
​
سوگیری: خطاهای سیستماتیک در خروجی‌های مدل‌های هوش مصنوعی که می‌توانند منجر به نتایج ناعادلانه یا تبعیض‌آمیز برای گروه‌های خاص یا در زمینه‌های مشخص شوند.
​
بهره‌برداری از سوگیری: یک تکنیک حمله است که از سوگیری‌های شناخته شده در مدل‌های هوش مصنوعی برای دستکاری نتایج یا خروجی‌ها استفاده می‌کند.
​
سیدار: زبان سیاست و موتور آمازون برای مجوزهای دقیق که در پیاده‌سازی ABAC برای سیستم‌های هوش مصنوعی استفاده می‌شود.
​
زنجیره تفکر: تکنیکی برای بهبود استدلال در مدل‌های زبانی با تولید مراحل میانی استدلال قبل از ارائه پاسخ نهایی.
​
قطع‌کننده‌های مدار: مکانیزم‌هایی که به‌طور خودکار عملیات سیستم هوش مصنوعی را زمانی که آستانه‌های خاصی از ریسک فراتر رود، متوقف می‌کنند.
​
نشت داده: افشای ناخواسته اطلاعات حساس از طریق خروجی‌ها یا رفتار مدل هوش مصنوعی.
​
آلوده‌سازی داده‌ها: فساد عمدی داده‌های آموزشی برای به خطر انداختن یکپارچگی مدل، که اغلب برای نصب درهای پشتی یا کاهش عملکرد انجام می‌شود.
​
حریم خصوصی تفاضلی – حریم خصوصی تفاضلی چارچوبی ریاضی و دقیق برای ارائه اطلاعات آماری درباره مجموعه داده‌ها است که در عین حال حفظ حریم خصوصی افراد تشکیل‌دهنده داده‌ها را تضمین می‌کند. این روش به دارنده داده اجازه می‌دهد تا الگوهای کلی گروه را به اشتراک بگذارد، در حالی که اطلاعات مربوط به افراد خاص را محدود می‌کند.
​
بردارهای جاسازی‌شده: نمایش‌های برداری متراکم از داده‌ها (متن، تصاویر و غیره) که معنای معنایی را در یک فضای ابعاد بالا ضبط می‌کنند.
​
قابل توضیح بودن – قابل توضیح بودن در هوش مصنوعی به توانایی یک سیستم هوش مصنوعی در ارائه دلایل قابل درک برای انسان‌ها درباره تصمیمات و پیش‌بینی‌هایش گفته می‌شود که بینشی درباره عملکرد داخلی آن فراهم می‌کند.
​
هوش مصنوعی قابل توضیح (XAI): سیستم‌های هوش مصنوعی طراحی شده برای ارائه توضیحات قابل فهم برای انسان درباره تصمیمات و رفتارهای خود از طریق تکنیک‌ها و چارچوب‌های مختلف.
​
یادگیری فدرال: رویکردی در یادگیری ماشین که در آن مدل‌ها در چندین دستگاه غیرمتمرکز با نگهداری نمونه‌های داده محلی آموزش داده می‌شوند، بدون اینکه داده‌ها به صورت مستقیم تبادل شوند.
​
خط قرمزها: محدودیت‌هایی که برای جلوگیری از تولید خروجی‌های مضر، جانبدارانه یا به‌طور کلی ناخواسته توسط سیستم‌های هوش مصنوعی اعمال می‌شوند.
​
توهم – توهم در هوش مصنوعی به پدیده‌ای اشاره دارد که در آن یک مدل هوش مصنوعی اطلاعات نادرست یا گمراه‌کننده‌ای تولید می‌کند که بر اساس داده‌های آموزشی یا واقعیت‌های عینی نیست.
​
انسان در حلقه (HITL): سیستم‌هایی که به گونه‌ای طراحی شده‌اند که به نظارت، تأیید یا دخالت انسانی در نقاط تصمیم‌گیری حیاتی نیاز دارند.
​
زیرساخت به‌عنوان کد (IaC): مدیریت و تهیه زیرساخت از طریق کد به جای فرآیندهای دستی، که امکان اسکن امنیتی و استقرارهای سازگار را فراهم می‌کند.
​
جیل‌بریک: تکنیک‌هایی که برای دور زدن محدودیت‌های امنیتی در سیستم‌های هوش مصنوعی، به‌ویژه در مدل‌های زبانی بزرگ، به‌منظور تولید محتوای ممنوعه استفاده می‌شوند.
​
کمترین امتیاز: اصل امنیتی اعطای تنها حداقل دسترسی‌های لازم برای کاربران و فرایندها.
​
LIME (توضیحات محلی قابل تفسیر و مدل-مستقل): تکنیکی برای توضیح پیش‌بینی‌های هر دسته‌بند یادگیری ماشین با تقریب زدن محلی آن با یک مدل قابل تفسیر.
​
حمله استنتاج عضویت: حمله‌ای که هدف آن تعیین این است که آیا یک نقطه داده خاص برای آموزش یک مدل یادگیری ماشین مورد استفاده قرار گرفته است یا خیر.
​
MITRE ATLAS: چشم‌انداز تهدیدات جعلی برای سیستم‌های هوش مصنوعی؛ یک پایگاه دانش از تاکتیک‌ها و تکنیک‌های ضد سیستم‌های هوش مصنوعی.
​
کارت مدل – کارت مدل یک سند است که اطلاعات استاندارد شده‌ای درباره عملکرد مدل هوش مصنوعی، محدودیت‌ها، کاربردهای مورد نظر و ملاحظات اخلاقی ارائه می‌دهد تا شفافیت و توسعه مسئولانه هوش مصنوعی را ترویج کند.
​
استخراج مدل: حمله‌ای که در آن یک مهاجم به طور مکرر مدل هدف را پرس‌وجو می‌کند تا نسخه‌ای عملکردی مشابه بدون مجوز ایجاد کند.
​
معکوس‌سازی مدل: حمله‌ای که تلاش می‌کند داده‌های آموزشی را با تحلیل خروجی‌های مدل بازسازی کند.
​
مدیریت چرخه عمر مدل – مدیریت چرخه عمر مدل هوش مصنوعی فرآیندی است که بر تمام مراحل وجود یک مدل هوش مصنوعی نظارت دارد، از جمله طراحی، توسعه، استقرار، پایش، نگهداری و نهایتاً بازنشستگی آن، تا اطمینان حاصل شود که مدل مؤثر باقی می‌ماند و با اهداف همراستا است.
​
سمی‌سازی مدل: وارد کردن آسیب‌پذیری‌ها یا درهای پشتی به طور مستقیم به یک مدل در طول فرآیند آموزش.
​
دزدیدن/قاچاق مدل: استخراج یک نسخه یا تقریب از یک مدل اختصاصی از طریق پرس‌وجوهای مکرر.
​
سیستم چندعامله: سیستمی متشکل از چندین عامل هوش مصنوعی تعاملی که هر کدام ممکن است قابلیت‌ها و اهداف متفاوتی داشته باشند.
​
OPA (عامل سیاست باز): یک موتور سیاست متن‌باز است که امکان اعمال سیاست‌های یکپارچه را در سراسر پشته فراهم می‌کند.
​
یادگیری ماشین حفظ حریم خصوصی (PPML): تکنیک‌ها و روش‌هایی برای آموزش و استقرار مدل‌های یادگیری ماشین در حالی که حریم خصوصی داده‌های آموزشی حفظ می‌شود.
​
تزریق پرامپت: نوعی حمله که در آن دستورات مخرب در ورودی‌ها تعبیه می‌شوند تا رفتار مورد نظر مدل را نادیده بگیرند.
​
RAG (تولید افزایش یافته با بازیابی): تکنیکی است که مدل‌های زبان بزرگ را با بازیابی اطلاعات مرتبط از منابع دانش خارجی قبل از تولید پاسخ، بهبود می‌بخشد.
​
رد تئیمینگ: عملیاتی است که شامل آزمایش فعال سیستم‌های هوش مصنوعی با شبیه‌سازی حملات خصمانه برای شناسایی نقاط ضعف می‌باشد.
​
SBOM (فهرست مواد نرم‌افزار): یک رکورد رسمی حاوی جزئیات و روابط زنجیره تأمین اجزای مختلف استفاده‌شده در ساخت نرم‌افزار یا مدل‌های هوش مصنوعی.
​
SHAP (توضیحات افزایشی شاپلِی): رویکردی مبتنی بر نظریه بازی‌ها برای شرح خروجی هر مدل یادگیری ماشین با محاسبه سهم هر ویژگی در پیش‌بینی.
​
حمله زنجیره تامین: به خطر انداختن یک سیستم با هدف قرار دادن عناصر کم‌امنیت‌تر در زنجیره تامین آن، مانند کتابخانه‌های شخص ثالث، مجموعه داده‌ها یا مدل‌های از پیش آموزش‌دیده شده.
​
یادگیری انتقالی: تکنیکی که در آن مدلی که برای یک وظیفه توسعه یافته است، به عنوان نقطه شروع برای مدلی در وظیفه دوم مجدداً استفاده می‌شود.
​
پایگاه داده برداری: یک پایگاه داده تخصصی که برای ذخیره بردارهای با ابعاد بالا (نمایه‌ها) و انجام جستجوهای شباهت با کارایی بالا طراحی شده است.
​
اسکن آسیب‌پذیری: ابزارهای خودکاری که آسیب‌پذیری‌های امنیتی شناخته‌شده در اجزای نرم‌افزاری، از جمله چارچوب‌ها و وابستگی‌های هوش مصنوعی را شناسایی می‌کنند.
​
واترمارکینگ: تکنیک‌هایی برای جاسازی نشانگرهای غیرقابل تشخیص در محتوای تولید شده توسط هوش مصنوعی به منظور ردیابی منبع آن یا تشخیص تولید توسط هوش مصنوعی.
​
آسیب‌پذیری صفر روز: آسیب‌پذیری‌ای که قبلاً ناشناخته بوده و مهاجمان می‌توانند قبل از اینکه توسعه‌دهندگان وصله‌ای ایجاد و منتشر کنند، از آن سوءاستفاده کنند.

## ضمیمه ب: منابع

### TODO

## پیوست C: حکمرانی و مستندسازی امنیت هوش مصنوعی

### هدف

این پیوست الزامات پایه‌ای برای ایجاد ساختارهای سازمانی، سیاست‌ها و فرآیندها به منظور مدیریت امنیت هوش مصنوعی در طول چرخه عمر سیستم را ارائه می‌دهد.

---

### پذیرش چارچوب مدیریت ریسک هوش مصنوعی AC.1

یک چارچوب رسمی برای شناسایی، ارزیابی و کاهش ریسک‌های خاص هوش مصنوعی در طول چرخه عمر سیستم فراهم کنید.

 #AC.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که روش‌شناسی ارزیابی ریسک مخصوص هوش مصنوعی مستندسازی و پیاده‌سازی شده است.
 #AC.1.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که ارزیابی‌های ریسک در نقاط کلیدی چرخه عمر هوش مصنوعی و قبل از تغییرات قابل توجه انجام می‌شوند.
 #AC.1.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که چارچوب مدیریت ریسک با استانداردهای تثبیت‌شده (مانند NIST AI RMF) همسو باشد.

---

### AC.2 سیاست‌ها و رویه‌های امنیت هوش مصنوعی

تعریف و اجرای استانداردهای سازمانی برای توسعه، استقرار و عملیات امن هوش مصنوعی.

 #AC.2.1    سطح: 1    نقش: D/V
 تأیید کنید که سیاست‌های امنیتی مستند شده برای هوش مصنوعی وجود دارند.
 #AC.2.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که سیاست‌ها حداقل سالی یک بار و پس از تغییرات قابل توجه در چشم‌انداز تهدید بررسی و به‌روزرسانی می‌شوند.
 #AC.2.3    سطح: 3    نقش: D/V
 بررسی کنید که سیاست‌ها تمام دسته‌های AISVS و الزامات مقرراتی مربوطه را پوشش دهند.

---

### AC.3 نقش‌ها و مسئولیت‌ها برای امنیت هوش مصنوعی

ایجاد پاسخگویی شفاف برای امنیت هوش مصنوعی در سراسر سازمان.

 #AC.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که نقش‌ها و مسئولیت‌های امنیت هوش مصنوعی مستندسازی شده باشند.
 #AC.3.2    سطح: 2    نقش: D
 تأیید کنید که افراد مسئول دارای تخصص امنیتی مناسب هستند.
 #AC.3.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که یک کمیته اخلاق هوش مصنوعی یا هیئت حاکمیت برای سیستم‌های هوش مصنوعی با ریسک بالا تشکیل شده است.

---

### اجرای دستورالعمل‌های اخلاقی هوش مصنوعی (AC.4)

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی بر اساس اصول اخلاقی تعیین شده عمل می‌کنند.

 #AC.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که دستورالعمل‌های اخلاقی برای توسعه و پیاده‌سازی هوش مصنوعی وجود دارد.
 #AC.4.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که مکانیزم‌هایی برای شناسایی و گزارش تخلفات اخلاقی وجود دارد.
 #AC.4.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که بازبینی‌های اخلاقی منظم بر سیستم‌های هوش مصنوعی مستقر شده انجام می‌شود.

---

### AC.5 نظارت بر رعایت مقررات هوش مصنوعی

آگاهی و رعایت قوانین در حال توسعه هوش مصنوعی را حفظ کنید.

 #AC.5.1    سطح: 1    نقش: D/V
 تأیید کنید که فرآیندهایی برای شناسایی مقررات قابل اجرا در حوزه هوش مصنوعی وجود دارند.
 #AC.5.2    سطح: 2    نقش: D
 اطمینان حاصل شود که انطباق با تمامی الزامات قانونی ارزیابی شده است.
 #AC.5.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تغییرات مقرراتی بازبینی‌ها و به‌روزرسانی‌های به‌موقع سیستم‌های هوش مصنوعی را فعال می‌کنند.

### AC.6 حاکمیت داده‌های آموزش، مستندسازی و فرآیند

 #1.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تنها مجموعه داده‌هایی که برای کیفیت، نمایندگی، منبع‌یابی اخلاقی و تطابق با مجوز بررسی شده‌اند، اجازه استفاده دارند تا خطرات آلودگی داده‌ها، تعصب نهفته و نقض حقوق مالکیت فکری را کاهش دهید.
 #1.1.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که کیفیت برچسب‌گذاری/حاشیه‌نویسی از طریق بررسی‌های متقابل بازبین‌ها یا اجماع تأیید شده باشد.
 #1.1.6    سطح: 2    نقش: D/V
 تأیید کنید که «کارت‌های داده» یا «برگه‌های داده برای مجموعه داده‌ها» برای مجموعه داده‌های آموزشی مهم نگهداری می‌شوند، که ویژگی‌ها، انگیزه‌ها، ترکیب، فرآیندهای جمع‌آوری، پیش‌پردازش و استفاده‌های توصیه شده/غیرمجاز را به تفصیل بیان می‌کنند.
 #1.3.2    سطح: 2    نقش: D/V
 اطمینان حاصل شود که تعصبات شناسایی شده از طریق استراتژی‌های مستند شده‌ای مانند تعادل مجدد، افزودن داده‌های هدفمند، تنظیمات الگوریتمی (مانند تکنیک‌های پیش‌پردازش، پردازش درون‌خطی، پس‌پردازش) یا تنظیم وزن، کاهش یافته‌اند و تأثیر کاهش تعصب بر عدالت و عملکرد کلی مدل مورد ارزیابی قرار گرفته است.
 #1.3.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که معیارهای عدالت پس از آموزش ارزیابی و مستندسازی شده‌اند.
 #1.3.4    سطح: 3    نقش: D/V
 تأیید کنید که یک سیاست مدیریت تعصبات چرخه عمر مالکین و تناوب بازبینی را تعیین می‌کند.
 #1.4.1    سطح: 2    نقش: D/V
 اطمینان حاصل شود که کیفیت برچسب‌گذاری/حاشیه‌نویسی از طریق دستورالعمل‌های شفاف، بازبینی‌های متقابل توسط بازبین‌ها، مکانیزم‌های اجماع (مانند نظارت بر توافق بین حاشیه‌نویسان) و فرایندهای مشخص برای رفع اختلافات تضمین شده است.
 #1.4.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که برچسب‌هایی که برای ایمنی، امنیت یا عدالت حیاتی هستند (مانند شناسایی محتوای سمی، یافته‌های پزشکی حیاتی) تحت بازبینی دوگانه مستقل اجباری یا تأیید قوی معادل قرار می‌گیرند.
 #1.4.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که راهنمای برچسب‌گذاری و دستورالعمل‌ها جامع، تحت کنترل نسخه و مورد بازبینی همتایان قرار گرفته‌اند.
 #1.4.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اسکیمای داده‌ها برای برچسب‌ها به‌وضوح تعریف شده و نسخه‌بندی شده است.
 #1.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مجموعه داده‌ها برای عدم تعادل نمایشی و سوگیری‌های احتمالی در ویژگی‌های قانونی محافظت شده (مانند نژاد، جنسیت، سن) و سایر ویژگی‌های حساس اخلاقی مرتبط با حوزه کاربرد مدل (مانند وضعیت اقتصادی-اجتماعی، موقعیت مکانی) بررسی شده‌اند.
 #1.5.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که بررسی‌های دستی نمونه‌ای توسط کارشناسان حوزه، یک نمونه آماری معنادار را شامل می‌شود (برای مثال، ≥1٪ یا 1,000 نمونه، هرکدام که بیشتر باشد، یا بر اساس ارزیابی ریسک تعیین شده باشد) تا مسائل ریز کیفیتی که توسط اتوماسیون تشخیص داده نشده‌اند، شناسایی شوند.
 #1.8.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که جریان‌های کاری برچسب‌گذاری برون‌سپاری شده یا جمع‌سپاری شده شامل تدابیر فنی/رویّه‌ای برای تضمین محرمانگی داده‌ها، یکپارچگی، کیفیت برچسب‌ها و جلوگیری از نشت داده‌ها هستند.
 #1.5.4    سطح: 2    نقش: D/V
 تأیید کنید که مراحل اصلاح به سوابق منشأ اضافه شده‌اند.
 #1.6.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که نمونه‌های علامت‌گذاری‌شده قبل از آموزش، منجر به بررسی دستی شوند.
 #1.6.3    سطح: 2    نقش: V
 تأیید کنید که نتایج، پرونده امنیتی مدل را تغذیه کرده و اطلاعات تهدیدهای جاری را اطلاع‌رسانی می‌کنند.
 #1.6.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که منطق تشخیص با اطلاعات جدید تهدید به‌روزرسانی شده است.
 #1.6.5    سطح: 3    نقش: D/V
 تأیید کنید که خطوط لوله یادگیری آنلاین تغییر توزیع را تحت نظر دارند.
 #1.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که روندهای حذف داده‌های آموزشی، داده‌های اصلی و مشتق‌شده را پاک می‌کنند و تأثیر آن بر مدل را ارزیابی می‌کنند، و در صورت نیاز، تأثیر بر مدل‌های متأثر بررسی و برطرف شود (مثلاً از طریق بازآموزی یا بازتنظیم).
 #1.7.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که مکانیزم‌هایی برای ردیابی و احترام به دامنه و وضعیت رضایت کاربر (و لغو رضایت‌ها) برای داده‌های استفاده شده در آموزش وجود دارد و رضایت پیش از وارد کردن داده‌ها در فرآیندهای آموزشی جدید یا به‌روزرسانی‌های مهم مدل تایید می‌شود.
 #1.7.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که روندهای کاری سالانه آزمایش شده و ثبت می‌شوند.
 #1.8.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تأمین‌کنندگان داده‌های شخص ثالث، از جمله ارائه‌دهندگان مدل‌های پیش‌آموزش‌دیده و مجموعه‌داده‌های خارجی، پیش از ادغام داده‌ها یا مدل‌هایشان، مورد بررسی‌های لازم امنیتی، حفظ حریم خصوصی، تأمین اخلاقی و کیفیت داده قرار گیرند.
 #1.8.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که انتقال‌های خارجی از TLS/احراز هویت و بررسی‌های یکپارچگی استفاده می‌کنند.
 #1.8.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که منابع داده با ریسک بالا (مانند مجموعه داده‌های متن‌باز با منشأ نامشخص، تأمین‌کنندگان تأییدنشده) قبل از استفاده در برنامه‌های حساس، تحت بررسی‌های دقیق‌تر قرار گیرند، مانند تحلیل در محیط ایزوله (sandbox)، بررسی‌های گسترده کیفیت/تعصب، و شناسایی هدفمند مسمومیت داده‌ها.
 #1.8.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مدل‌های پیش‌آموزش‌دیده‌ای که از طرف‌های ثالث به دست می‌آیند، پیش از تنظیم دقیق یا استقرار، از نظر تعصبات نهفته، درهای پشتی بالقوه، صحت ساختارشان و منشأ داده‌های آموزشی اولیه‌شان ارزیابی شده باشند.
 #1.5.3    سطح: 2    نقش: D/V
 تأیید کنید که در صورت استفاده از آموزش دشمن‌پسند (adversarial training)، تولید، مدیریت و نسخه‌بندی داده‌های دشمن‌پسند مستندسازی شده و کنترل می‌شوند.
 #1.5.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تأثیر آموزش مقاوم‌سازی در برابر حملات مخرب بر عملکرد مدل (در مقابل ورودی‌های تمیز و ورودی‌های مخرب) و معیارهای عدالت ارزیابی، مستندسازی و رصد می‌شود.
 #1.5.4    سطح: 3    نقش: D/V
 تأیید کنید که استراتژی‌های آموزش مقابله‌ای و مقاومت به طور دوره‌ای بررسی و به‌روزرسانی می‌شوند تا با تکنیک‌های در حال تحول حملات مقابله‌ای مقابله کنند.
 #1.4.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مجموعه داده‌های ناموفق با ردیابی‌های حسابرسی قرنطینه شده‌اند.
 #1.4.3    سطح: 2    نقش: D/V
 تأیید کنید که دروازه‌های کیفیت از داده‌های زیر استاندارد جلوگیری می‌کنند مگر اینکه استثناها تأیید شده باشند.
 #1.11.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فرآیند تولید، پارامترها و کاربرد مورد نظر داده‌های مصنوعی مستند شده‌اند.
 #1.11.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که داده‌های مصنوعی قبل از استفاده در آموزش، از نظر سوگیری، نشت حریم خصوصی و مشکلات نمایشی مورد ارزیابی ریسک قرار گرفته‌اند.
 #1.12.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که هشدارها برای رویدادهای دسترسی مشکوک تولید شده و به سرعت مورد بررسی قرار می‌گیرند.
 #1.13.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که دوره‌های نگهداری صریح برای همه مجموعه داده‌های آموزشی تعریف شده‌اند.
 #1.13.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که داده‌ها به‌صورت خودکار در پایان دوره عمرشان منقضی، حذف یا برای حذف بررسی می‌شوند.
 #1.13.3    سطح: 2    نقش: D/V
 تأیید کنید که اقدامات نگهداری و حذف ثبت شده و قابل حسابرسی باشند.
 #1.14.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که الزامات اقامت داده و انتقال فرامرزی برای همه مجموعه داده‌ها شناسایی و اجرا شده‌اند.
 #1.14.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مقررات خاص هر حوزه (مانند بهداشت و درمان، مالی) شناسایی شده و در مدیریت داده‌ها مورد توجه قرار گرفته‌اند.
 #1.14.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که رعایت قوانین حریم خصوصی مرتبط (برای مثال، GDPR، CCPA) مستند شده و به طور منظم بازبینی می‌شود.
 #1.16.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌هایی برای پاسخ به درخواست‌های موضوع داده برای دسترسی، اصلاح، محدودیت یا اعتراض وجود دارد.
 #1.16.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که درخواست‌ها ثبت، پیگیری و در چارچوب زمان‌های مقرر قانونی انجام می‌شوند.
 #1.16.3    سطح: 2    نقش: D/V
 تأیید کنید که فرایندهای حقوق موضوع داده به طور منظم برای اثربخشی آزمایش و بازبینی می‌شوند.
 #1.17.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تحلیل تأثیر قبل از به‌روزرسانی یا جایگزینی نسخه مجموعه داده انجام شود، شامل عملکرد مدل، عدالت و رعایت قوانین باشد.
 #1.17.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که نتایج تحلیل تأثیر مستندسازی شده و توسط ذینفعان مرتبط بازبینی شده است.
 #1.17.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که برنامه‌های بازگشت در صورت ایجاد ریسک‌ها یا پسرفت‌های غیرقابل قبول توسط نسخه‌های جدید وجود داشته باشند.
 #1.18.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تمام کارکنان درگیر در نشانه‌گذاری داده‌ها دارای بررسی سابقه بوده و در امنیت و حریم خصوصی داده‌ها آموزش دیده‌اند.
 #1.18.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تمام کارکنان نشانه‌گذاری قراردادهای محرمانگی و عدم افشا را امضا کنند.
 #1.18.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که پلتفرم‌های حاشیه‌نویسی کنترل‌های دسترسی را اجرا می‌کنند و تهدیدات داخلی را پایش می‌کنند.

#### مراجع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
EU Artificial Intelligence Act — Regulation (EU) 2024/1689
ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods

## پیوست D: حاکمیت و تأیید امنیت کدنویسی با کمک هوش مصنوعی

### هدف

این فصل کنترل‌های سازمانی پایه‌ای برای استفاده ایمن و مؤثر از ابزارهای کدنویسی مبتنی بر هوش مصنوعی در حین توسعه نرم‌افزار تعریف می‌کند و امنیت و قابلیت ردیابی در طول چرخه عمر توسعه نرم‌افزار (SDLC) را تضمین می‌نماید.

---

### AD.1 روند کاری کدنویسی امن همراه با هوش مصنوعی

ادغام ابزارهای هوش مصنوعی در چرخه عمر توسعه نرم‌افزار امن سازمان (SSDLC) بدون تضعیف دروازه‌های امنیتی موجود.

 #AD.1.1    سطح: 1    نقش: D/V
 تأیید کنید که یک گردش‌کار مستند شده مشخص می‌کند که چه زمانی و چگونه ابزارهای هوش مصنوعی ممکن است کد را تولید، بازسازی یا مرور کنند.
 #AD.1.2    سطح: 2    نقش: D
 تأیید کنید که جریان کاری به هر فاز از SSDLC (طراحی، پیاده‌سازی، بازبینی کد، تست، استقرار) نگاشت شده است.
 #AD.1.3    سطح: 3    نقش: D/V
 اطمینان حاصل شود که معیارها (مانند چگالی آسیب‌پذیری، میانگین زمان تا کشف) در کد تولید شده توسط هوش مصنوعی جمع‌آوری شده و با مبناهای مبتنی بر انسان مقایسه می‌شوند.

---

### AD.2 شایستگی ابزار هوش مصنوعی و مدل‌سازی تهدید

اطمینان حاصل کنید که ابزارهای کدنویسی هوش مصنوعی از نظر قابلیت‌های امنیتی، ریسک و تأثیر زنجیره تأمین قبل از پذیرش ارزیابی می‌شوند.

 #AD.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مدل تهدید برای هر ابزار هوش مصنوعی، سوءاستفاده، وارونگی مدل، نشت داده و خطرات زنجیره وابستگی را شناسایی می‌کند.
 #AD.2.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که ارزیابی‌های ابزار شامل تحلیل ایستا/پویا هر مؤلفه محلی و ارزیابی نقاط انتهایی SaaS (TLS، احراز هویت/مجوز، ثبت‌رویدادها) باشد.
 #AD.2.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که ارزیابی‌ها طبق یک چارچوب شناخته‌شده انجام می‌شوند و پس از تغییرات نسخه اصلی دوباره اجرا می‌شوند.

---

### مدیریت امن درخواست و زمینه AD.3

جلوگیری از نشت اسرار، کد اختصاصی و داده‌های شخصی هنگام ساختن پرامپت‌ها یا زمینه‌ها برای مدل‌های هوش مصنوعی.

 #AD.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که راهنمایی‌های مکتوب، ارسال اسرار، اطلاعات شناسایی یا داده‌های طبقه‌بندی شده در درخواست‌ها را ممنوع کرده است.
 #AD.3.2    سطح: 2    نقش: D
 بررسی کنید که کنترل‌های فنی (حذف داده‌ها در سمت کاربر، فیلترهای زمینه تایید شده) به‌طور خودکار اطلاعات حساس را حذف می‌کنند.
 #AD.3.3    سطح: 3    نقش: D/V
 تأیید کنید که پرامپت‌ها و پاسخ‌ها به صورت توکنیزه شده، در حین انتقال و در حالت استراحت رمزگذاری شده‌اند و دوره‌های نگهداری با سیاست طبقه‌بندی داده‌ها مطابقت دارند.

---

### AD.4 اعتبارسنجی کد تولیدشده توسط هوش مصنوعی

شناسایی و رفع آسیب‌پذیری‌های ایجاد شده توسط خروجی‌های هوش مصنوعی قبل از ادغام یا استقرار کد.

 #AD.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که کد تولید شده توسط هوش مصنوعی همیشه تحت بازبینی کد انسانی قرار می‌گیرد.
 #AD.4.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که اسکنرهای خودکار (SAST/IAST/DAST) بر روی هر درخواست ادغام که شامل کد تولید شده توسط هوش مصنوعی است اجرا می‌شوند و ادغام‌ها را در صورت وجود یافته‌های بحرانی مسدود می‌کنند.
 #AD.4.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که آزمایش فازینگ تفاضلی یا تست‌های مبتنی بر ویژگی، رفتارهای حیاتی امنیتی (مثلاً اعتبارسنجی ورودی، منطق مجوزدهی) را اثبات می‌کنند.

---

### AD.5 قابلیت توضیح‌پذیری و ردیابی پیشنهادات کد

به حسابرسان و توسعه‌دهندگان بینش دهید که چرا یک پیشنهاد ارائه شده است و چگونه تکامل یافته است.

 #AD.5.1    سطح: 1    نقش: D/V
 تأیید کنید که جفت‌های درخواست/پاسخ با شناسه‌های تعهد ثبت می‌شوند.
 #AD.5.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که توسعه‌دهندگان می‌توانند استنادات مدل (قطعات آموزشی، مستندات) را که پیشنهاد را پشتیبانی می‌کنند، نمایش دهند.
 #AD.5.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که گزارش‌های قابلیت توضیح‌دهی همراه با مصنوعات طراحی ذخیره شده و در بازبینی‌های امنیتی به آن‌ها ارجاع داده شده‌اند، به گونه‌ای که اصول ردیابی استاندارد ISO/IEC 42001 را برآورده کنند.

---

### AD.6 بازخورد مداوم و تنظیم دقیق مدل

افزایش عملکرد امنیت مدل در طول زمان در حالی که از انحراف منفی جلوگیری می‌شود.

 #AD.6.1    سطح: 1    نقش: D/V
 تأیید کنید که توسعه‌دهندگان می‌توانند پیشنهادات ناامن یا غیرموافقت را علامت‌گذاری کنند و اینکه این علامت‌ها ردیابی می‌شوند.
 #AD.6.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که بازخورد تجمیع‌شده، آموزش مجدد دوره‌ای یا تولید تقویت‌شده با بازیابی با مجموعه‌های معتبر کد نویسی ایمن (مانند OWASP Cheat Sheets) را اطلاع می‌دهد.
 #AD.6.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که چارچوب ارزیابی حلقه‌بسته پس از هر بار ریزتنظیم، تست‌های رگرسیون را اجرا می‌کند؛ معیارهای امنیتی باید پیش از استقرار، با یا بهتر از معیارهای پایه قبلی باشند.

---

#### مراجع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
OWASP Secure Coding Practices — Quick Reference Guide

## ضمیمه E: نمونه ابزارها و چارچوب‌ها

### هدف

این فصل نمونه‌هایی از ابزارها و چارچوب‌هایی را ارائه می‌دهد که می‌توانند از اجرای یا تحقق یک نیازمندی مشخص AISVS پشتیبانی کنند. این موارد به عنوان توصیه یا تاییدیه از سوی تیم AISVS یا پروژه امنیتی OWASP GenAI نباید تلقی شوند.

---

### AE.1 حاکمیت داده‌های آموزش و مدیریت تعصب

ابزارهای مورد استفاده برای تحلیل داده‌ها، حاکمیت داده‌ها، و مدیریت سوگیری.

 #AE.1.1    بخش: 1.1
 ابزار مدیریت فهرست داده‌ها: ابزارهایی برای مدیریت فهرست داده‌ها مانند...
 #AE.1.2    بخش: 1.2
 رمزگذاری در حین انتقال از TLS برای برنامه‌های مبتنی بر HTTPS استفاده کنید، با ابزارهایی مانند openSSL و پایتون`ssl`کتابخانه.

---

### AE.2 اعتبارسنجی ورودی کاربر

ابزارهایی برای مدیریت و اعتبارسنجی ورودی‌های کاربر.

 #AE.2.1    بخش: 2.1
 ابزارهای دفاع در برابر تزریق پرامپت: از ابزارهای محافظ مانند NeMo شرکت NVIDIA یا Guardrails AI استفاده کنید.

---

