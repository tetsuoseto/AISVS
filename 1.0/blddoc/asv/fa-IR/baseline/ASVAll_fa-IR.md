## صفحه‌ی عنوان

### درباره استاندارد

استاندارد تأیید امنیت هوش مصنوعی (AISVS) یک فهرست جامعه‌محور از الزامات امنیتی است که دانشمندان داده، مهندسان MLOps، معماران نرم‌افزار، توسعه‌دهندگان، تست‌کنندگان، متخصصان امنیت، فروشندگان ابزار، تنظیم‌کنندگان مقررات و مصرف‌کنندگان می‌توانند برای طراحی، ساخت، آزمون و تأیید سیستم‌ها و برنامه‌های کاربردی قابل اعتماد مبتنی بر هوش مصنوعی از آن استفاده کنند. این استاندارد زبان مشترکی برای مشخص کردن کنترل‌های امنیتی در سراسر چرخه عمر هوش مصنوعی ارائه می‌دهد—از جمع‌آوری داده‌ها و توسعه مدل تا استقرار و نظارت مستمر—تا سازمان‌ها بتوانند مقاومت، حریم خصوصی و ایمنی راه‌حل‌های هوش مصنوعی خود را اندازه‌گیری و بهبود بخشند.

### حق نشر و مجوز

نسخه 0.1 (اولین پیش‌نویس عمومی - در دست انجام)، 2025  

![license](images/license.png)
حق نشر © 2025 پروژه AISVS.  

منتشر شده تحت Creative Commons Attribution‑ShareAlike 4.0 International License.
برای هرگونه استفاده مجدد یا توزیع، باید شرایط مجوز این اثر را به طور واضح به دیگران اطلاع دهید.

### رهبران پروژه

جیم مانیكو
آراس "راس" ممیسی‌یازیچی

### مشارکت‌کنندگان و بازبین‌ها

https://github.com/ottosulin
https://github.com/mbhatt1
https://github.com/vineethsai
https://github.com/cciprofm
https://github.com/deepakrpandey12


---

AISVS یک استاندارد کاملاً جدید است که به طور خاص برای پرداختن به چالش‌های امنیتی منحصر به فرد سیستم‌های هوش مصنوعی ایجاد شده است. در حالی که از بهترین شیوه‌های کلی امنیت الهام گرفته شده است، هر نیاز در AISVS از پایه توسعه یافته تا نمایانگر چشم‌انداز تهدیدات هوش مصنوعی باشد و به سازمان‌ها کمک کند تا راه‌حل‌های هوش مصنوعی ایمن‌تر و مقاوم‌تری بسازند.

## پیشگفتار

به استاندارد تایید امنیت هوش مصنوعی (AISVS) نسخه 1.0 خوش آمدید!

### مقدمه

AISVS که در سال 2025 از طریق یک تلاش مشترک جامعه تأسیس شد، الزامات امنیتی را که باید هنگام طراحی، توسعه، استقرار و بهره‌برداری از مدل‌های مدرن هوش مصنوعی، خطوط لوله و خدمات فعال‌شده با هوش مصنوعی در نظر گرفته شوند، تعریف می‌کند.

AISVS نسخه 1.0 نمایانگر کار مشترک سرپرستان پروژه، گروه کاری و مشارکت‌کنندگان گسترده‌تر جامعه برای ایجاد یک معیار پایه عملی و قابل آزمایش برای امنیت سیستم‌های هوش مصنوعی است.

هدف ما در این نسخه این است که AISVS را به‌سادگی قابل استفاده کنیم و در عین حال با تمرکز دقیق روی حوزه تعریف‌شده آن و پرداختن به چشم‌انداز خطرات به‌سرعت در حال تحول که مختص هوش مصنوعی است، پیش رویم.

### اهداف کلیدی برای نسخه 1.0 AISVS

نسخه 1.0 با چندین اصل راهنما ایجاد خواهد شد.

#### دامنه تعریف‌شده واضح

هر الزام باید با نام و مأموریت AISVS همسو باشد:

هوش مصنوعی – کنترل‌ها در لایه‌ی AI/ML (داده، مدل، خط لوله، یا استنتاج) عمل می‌کنند و مسئولیت آن‌ها با متخصصان هوش مصنوعی است.
امنیت – الزامات به طور مستقیم خطرات شناسایی شده امنیتی، حریم خصوصی یا ایمنی را کاهش می‌دهند.
تأیید - زبان به گونه‌ای نوشته شده است که تطابق آن بتواند به طور عینی اعتبارسنجی شود.
استاندارد – بخش‌ها ساختار و اصطلاحات ثابتی دارند تا یک مرجع منسجم را شکل دهند.
​
---

با پیروی از AISVS، سازمان‌ها می‌توانند به‌طور سیستماتیک وضعیت امنیتی راه‌حل‌های هوش مصنوعی خود را ارزیابی و تقویت کنند و فرهنگ مهندسی امن هوش مصنوعی را پرورش دهند.

## استفاده از AISVS

استاندارد اعتبارسنجی امنیت هوش مصنوعی (AISVS) نیازمندی‌های امنیتی مربوط به برنامه‌ها و خدمات مدرن هوش مصنوعی را تعریف می‌کند و بر جنبه‌هایی تمرکز دارد که در کنترل توسعه‌دهندگان برنامه هستند.

AISVS برای هر کسی که در حال توسعه یا ارزیابی امنیت برنامه‌های هوش مصنوعی است، از جمله توسعه‌دهندگان، معماران، مهندسین امنیت و ممیزان، طراحی شده است. این فصل ساختار و نحوه استفاده از AISVS را معرفی می‌کند، از جمله سطوح تأیید و موارد استفاده مدنظر آن.

### سطوح تأیید امنیتی هوش مصنوعی

AISVS سه سطح افزایشی از تأییدیه امنیتی را تعریف می‌کند. هر سطح عمق و پیچیدگی را افزایش می‌دهد و به سازمان‌ها امکان می‌دهد موضع امنیتی خود را متناسب با سطح ریسک سیستم‌های هوش مصنوعی خود تنظیم کنند.

سازمان‌ها ممکن است از سطح 1 شروع کنند و به تدریج سطوح بالاتر را با افزایش بلوغ امنیتی و میزان تهدیدات اتخاذ نمایند.

#### تعریف سطوح

هر نیازمندی در AISVS نسخه ۱.۰ به یکی از سطوح زیر اختصاص داده می‌شود:

 الزامات سطح 1

سطح 1 شامل مهم‌ترین و اساسی‌ترین نیازهای امنیتی است. این سطح بر جلوگیری از حملات رایج که به پیش‌شرط‌ها یا آسیب‌پذیری‌های دیگر وابسته نیستند تمرکز دارد. بیشتر کنترل‌های سطح 1 یا اجرای ساده‌ای دارند یا به اندازه کافی حیاتی هستند که صرف زمان و تلاش را توجیه می‌کنند.

 الزامات سطح 2

سطح ۲ به حملات پیشرفته‌تر یا کمتر رایج‌تر می‌پردازد و همچنین دفاع‌های چندلایه در برابر تهدیدات گسترده را شامل می‌شود. این الزامات ممکن است منطق پیچیده‌تری داشته باشند یا پیش‌شرط‌های خاص حمله را هدف قرار دهند.

 الزامات سطح 3

سطح 3 شامل کنترل‌هایی است که معمولاً پیاده‌سازی آنها دشوارتر است یا کاربرد موقعیتی دارند. این کنترل‌ها اغلب مکانیزم‌های دفاع در عمق یا تدابیری در برابر حملات خاص، هدفمند یا با پیچیدگی بالا را نمایندگی می‌کنند.

#### نقش (D/V)

هر نیازمندی AISVS بر اساس مخاطب اصلی مشخص شده است:

D – نیازمندی‌های متمرکز بر توسعه‌دهنده
V – الزامات متمرکز بر تأییدکننده/ممتحن
D/V – مرتبط با هر دو توسعه‌دهندگان و بررسی‌کنندگان

## حکمرانی داده‌های آموزش C1 و مدیریت تعصب

### هدف کنترل

داده‌های آموزش باید به گونه‌ای تأمین، مدیریت و نگهداری شوند که منشأ، امنیت، کیفیت و عدالت را حفظ کنند. انجام این کار وظایف قانونی را برآورده ساخته و خطرات تعصب، مسمومیت یا نقض حریم خصوصی که در طول آموزش ظاهر می‌شوند و می‌توانند کل چرخه عمر هوش مصنوعی را تحت تأثیر قرار دهند، کاهش می‌دهد.

---

### C1.1 منبع داده‌های آموزش

نگهداری یک فهرست قابل تأیید از تمام داده‌ها، پذیرش تنها منابع مورد اعتماد، و ثبت هر تغییر برای قابلیت بررسی و ممیزی.

 #1.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که یک فهرست به‌روز از هر منبع داده آموزشی (مبدا، متولی/مالک، مجوز، روش جمع‌آوری، محدودیت‌های استفاده مورد نظر، و سابقه پردازش) نگهداری می‌شود.
 #1.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که فرآیندهای آموزش داده‌ها شامل حذف ویژگی‌ها، خصوصیات یا فیلدهای غیرضروری (مانند فراداده‌های استفاده‌نشده، اطلاعات شناسایی حساس، داده‌های آزمون نشت‌یافته) هستند.
 #1.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تمام تغییرات داده‌ها تحت یک روند تایید ثبت‌شده قرار دارند.
 #1.1.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که داده‌ها یا زیرمجموعه‌ها در صورت امکان دارای واترمارک یا اثر انگشت دیجیتال باشند.

---

### C1.2 امنیت و تمامیت داده‌های آموزشی

دسترسی به داده‌های آموزش را محدود کنید، آن‌ها را در حالت ذخیره و انتقال رمزگذاری کنید، و صحت آن‌ها را برای جلوگیری از دستکاری، سرقت یا مسمومیت داده‌ها اعتبارسنجی کنید.

 #1.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که کنترل‌های دسترسی از ذخیره‌سازی داده‌های آموزشی و خطوط لوله محافظت می‌کنند.
 #1.2.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تمام دسترسی‌ها به داده‌های آموزش ثبت می‌شوند، از جمله کاربر، زمان و اقدام انجام شده.
 #1.2.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که داده‌های آموزشی در انتقال و در حالت استراحت با استفاده از الگوریتم‌های رمزنگاری استاندارد صنعتی و روش‌های مدیریت کلید رمزگذاری شده‌اند.
 #1.2.4    سطح: 2    نقش: D/V
 بررسی کنید که هش‌های رمزنگاری یا امضاهای دیجیتال برای اطمینان از صحت داده‌ها هنگام ذخیره‌سازی و انتقال داده‌های آموزشی استفاده می‌شوند.
 #1.2.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تکنیک‌های تشخیص خودکار برای محافظت در برابر تغییرات یا فساد غیرمجاز داده‌های آموزشی اعمال شده‌اند.
 #1.2.6    سطح: 2    نقش: D/V
 تأیید کنید که داده‌های آموزشی منسوخ به طور ایمن پاک‌سازی یا ناشناس‌سازی شده‌اند.
 #1.2.7    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تمامی نسخه‌های مجموعه داده‌های آموزشی به‌صورت یکتا شناسایی شده، به‌طور غیرقابل تغییر ذخیره می‌شوند و قابلیت حسابرسی دارند تا از بازگردانی و تحلیل قضایی پشتیبانی کنند.

---

### C1.3 کیفیت، یکپارچگی و امنیت برچسب‌گذاری داده‌های آموزشی

برچسب‌ها را محافظت کنید و برای داده‌های حیاتی بررسی فنی را الزامی کنید.

 #1.3.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که هش‌های رمزنگاری یا امضاهای دیجیتال برای برچسب زدن آثار به منظور تضمین صحت و اصالت آنها اعمال شده‌اند.
 #1.3.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که رابط‌ها و پلتفرم‌های برچسب‌گذاری کنترل‌های دسترسی قوی را اجرا می‌کنند، سوابق حسابرسی مقاوم در برابر دستکاری از تمام فعالیت‌های برچسب‌گذاری نگهداری می‌کنند و در برابر تغییرات غیرمجاز محافظت می‌کنند.
 #1.3.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که اطلاعات حساس در برچسب‌ها در سطح فیلد داده در حالت سکون و در انتقال، حذف شده، ناشناس‌سازی شده یا رمزگذاری شده‌اند.

---

### C1.4 کیفیت داده‌های آموزشی و تضمین امنیت

ادغام اعتبارسنجی خودکار، بررسی‌های دستی تصادفی و ثبت اقدامات اصلاحی برای تضمین اطمینان از صحت داده‌ها.

 #1.4.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که تست‌های خودکار خطاهای فرمت و مقدارهای تهی را در هر بار ورودی داده یا تبدیل داده‌های مهم شناسایی می‌کنند.
 #1.4.2    سطح: 2    نقش: D/V
 تأیید کنید که خط‌مشی‌های آموزش و ریزتنظیم مدل‌های زبان بزرگ (LLM) تشخیص مسمومیت و اعتبارسنجی یکپارچگی داده‌ها (مانند روش‌های آماری، تشخیص نقاط دورافتاده، تحلیل جاسازی‌ها) را پیاده‌سازی می‌کنند تا حملات احتمالی مسمومیت (مانند تغییر برچسب‌ها، درج محرک در پشتی، دستورات تغییر نقش، حملات نمونه‌های تأثیرگذار) یا فساد غیرعمدی داده‌ها در داده‌های آموزشی شناسایی شود.
 #1.4.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تدابیر دفاعی مناسب، مانند آموزش مقابله‌ای (استفاده از نمونه‌های مقابله‌ای تولید شده)، افزایش داده با ورودی‌های دستکاری‌شده، یا تکنیک‌های بهینه‌سازی مقاوم، برای مدل‌های مرتبط بر اساس ارزیابی ریسک پیاده‌سازی و تنظیم شده‌اند.
 #1.4.4    سطح: 2    نقش: D/V
 تأیید کنید که برچسب‌های به‌صورت خودکار تولید شده (به‌عنوان مثال، از طریق مدل‌های زبان بزرگ یا نظارت ضعیف) مشمول آستانه‌های اطمینان و بررسی‌های سازگاری هستند تا برچسب‌های توهمی، گمراه‌کننده یا کم‌اعتماد شناسایی شوند.
 #1.4.5    سطح: 3    نقش: D
 اطمینان حاصل کنید که تست‌های خودکار برچسب‌های ناهماهنگ را در هر بار وارد کردن داده یا تبدیل داده‌های مهم تشخیص می‌دهند.

---

### C1.5 ردیابی و ریشه‌یابی داده‌ها

مسیر کامل هر نقطه داده را از منبع تا ورودی مدل برای قابلیت حسابرسی و پاسخ به حوادث دنبال کنید.

 #1.5.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که ریشه هر نقطه داده، شامل همه تبدیل‌ها، افزوده‌ها و ادغام‌ها، ثبت شده و قابل بازسازی باشد.
 #1.5.2    سطح: 2    نقش: D/V
 تأیید کنید که رکوردهای خط سیر تغییرناپذیر، به‌صورت امن ذخیره شده و برای حسابرسی‌ها قابل دسترسی هستند.
 #1.5.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که رهگیری نسل داده‌ها شامل داده‌های مصنوعی تولید شده از طریق تکنیک‌های حفظ حریم خصوصی یا تولیدی باشد و همه داده‌های مصنوعی در سراسر خط لوله به وضوح برچسب‌گذاری شده و از داده‌های واقعی قابل تمایز باشند.

---

### مراجع

NIST AI Risk Management Framework
EU AI Act – Article 10: Data & Data Governance
MITRE ATLAS: Adversary Tactics for AI
Survey of ML Bias Mitigation Techniques – MDPI
Data Provenance & Lineage Best Practices – Nightfall AI
Data Labeling Quality Standards – LabelYourData
Training Data Poisoning Guide – Lakera.ai
CISA Advisory: Securing Data for AI Systems
ISO/IEC 23053: AI Management Systems Framework
IBM: What is AI Governance?
Google AI Principles
GDPR & AI Training Data – DataProtectionReport
Supply-Chain Security for AI Data – AppSOC
OpenAI Privacy Center – Data Deletion Controls
Adversarial ML Dataset – Kaggle

## اعتبارسنجی ورود داده‌های کاربر C2

### هدف کنترل

اعتبارسنجی قوی ورودی کاربران نخستین خط دفاع در برابر برخی از مخرب‌ترین حملات به سیستم‌های هوش مصنوعی است. حملات تزریق فرمان می‌توانند دستورالعمل‌های سیستم را بازنویسی کنند، داده‌های حساس را افشا کنند، یا مدل را به سمت رفتاری هدایت کنند که مجاز نیست. مگر اینکه فیلترهای ویژه و سلسله‌مراتب دستورالعمل‌ها برقرار شده باشند، تحقیقات نشان می‌دهد که «دورهای چندگانه» فرار از محدودیت که از پنجره‌های متن بسیار طولانی بهره می‌برند مؤثر خواهند بود. همچنین، حملات تغییرات ظریف متخاصم—مانند جابجایی حروف مشابه (homoglyph) یا گفتار رمزآمیز (leetspeak)—می‌توانند به طور بی‌صدا تصمیمات مدل را تغییر دهند.

---

### C2.1 دفاع در برابر تزریق پرامپت

تزریق پرامپت یکی از بزرگ‌ترین ریسک‌ها برای سیستم‌های هوش مصنوعی است. دفاع در برابر این تاکتیک از ترکیبی از فیلترهای الگوهای ایستا، دسته‌بندهای پویا و اجرای سلسله‌مراتبی دستورات استفاده می‌کند.

 #2.1.1    سطح: 1    نقش: D/V
 بررسی کنید که ورودی‌های کاربر در برابر یک کتابخانه به‌روز شده مداوم از الگوهای شناخته شده تزریق پرامپت (کلیدواژه‌های فرار از محدودیت، "نادیده گرفتن قبل"، زنجیره‌های نقش‌آفرینی، حملات غیرمستقیم HTML/URL) مورد بررسی قرار می‌گیرند.
 #2.1.2    سطح: 1    نقش: D/V
 تأیید کنید که سیستم سلسله‌مراتب دستورات را به‌گونه‌ای اعمال می‌کند که پیام‌های سیستم یا توسعه‌دهنده، دستورات کاربر را تحت‌الشعاع قرار می‌دهند، حتی پس از گسترش پنجره‌ی زمینه.
 #2.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که ارزیابی‌های خصمانه (مثلاً درخواست‌های "تعداد زیاد" تیم قرمز) قبل از هر انتشار مدل یا قالب درخواست اجرا می‌شوند، با حد آستانه نرخ موفقیت و موانع خودکار برای برگشت‌ها.
 #2.1.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که پرامپت‌هایی که از محتوای شخص ثالث (صفحات وب، فایل‌های PDF، ایمیل‌ها) منشأ می‌گیرند، در یک زمینه تحلیل جداگانه پاک‌سازی شده باشند قبل از اینکه به پرامپت اصلی افزوده شوند.
 #2.1.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که همه به‌روزرسانی‌های قوانین فیلتر پرامپت، نسخه‌های مدل طبقه‌بندی‌کننده و تغییرات فهرست مسدود شده تحت کنترل نسخه بوده و قابل حسابرسی باشند.

---

### C2.2 مقاومت در برابر نمونه‌های خصمانه

مدل‌های پردازش زبان طبیعی (NLP) همچنان در برابر اختلالات ظریف در سطح کاراکتر یا کلمه آسیب‌پذیر هستند که انسان‌ها اغلب آن‌ها را تشخیص نمی‌دهند اما مدل‌ها معمولاً اشتباه طبقه‌بندی می‌کنند.

 #2.2.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که مراحل پایه نرمال‌سازی ورودی (Unicode NFC، نقشه‌برداری هم‌ریخت‌ها، حذف فاصله‌های اضافی) قبل از بخش‌بندی به توکن اجرا شوند.
 #2.2.2    سطح: 2    نقش: D/V
 تأیید کنید که تشخیص ناهنجاری‌های آماری ورودی‌هایی را که فاصله ویرایشی غیرمعمول بالا نسبت به قواعد زبان، تکرار بیش از حد توکن‌ها، یا فاصله‌های تعبیه‌ای غیرعادی دارند، علامت‌گذاری می‌کند.
 #2.2.3    سطح: 2    نقش: D
 بررسی کنید که خط لوله استنتاج از نسخه‌های مدل تقویت‌شده با آموزش مقابله‌ای اختیاری یا لایه‌های دفاعی (مانند تصادفی‌سازی، تقطیر دفاعی) برای نقاط انتهایی با ریسک بالا پشتیبانی می‌کند.
 #2.2.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که ورودی‌های مشکوک به حمله دشمنی قرنطینه شده و با کل بار اطلاعاتی (پس از حذف داده‌های شناسایی شخصی) ثبت می‌شوند.
 #2.2.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که معیارهای مقاومت (نرخ موفقیت مجموعه‌های حمله شناخته‌شده) به مرور زمان رصد می‌شوند و کاهش عملکرد باعث ایجاد مانع در انتشار نسخه می‌شود.

---

### اعتبارسنجی طرح‌واره، نوع و طول C2.3

حملات هوش مصنوعی با ورودی‌های نادرست یا بیش از حد بزرگ می‌توانند باعث خطاهای تجزیه، انتشار درخواست‌ها در بین فیلدها و خستگی منابع شوند. اجرای دقیق اسکیمای داده نیز پیش‌نیازی ضروری هنگام انجام فراخوانی‌های ابزار قطعی است.

 #2.3.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که هر نقطه پایانی تماس با API یا تابع، یک طرح ورودی صریح (JSON Schema، Protobuf یا معادل چند حالته) تعریف می‌کند و ورودی‌ها قبل از ساخت پرسش اعتبارسنجی می‌شوند.
 #2.3.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که ورودی‌هایی که از حداکثر محدودیت‌های توکن یا بایت فراتر می‌روند، با یک خطای ایمن رد می‌شوند و هرگز به‌صورت ناگهانی کوتاه نمی‌شوند.
 #2.3.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که بررسی‌های نوع (مانند دامنه‌های عددی، مقادیر enum، نوع MIME برای تصاویر/صوت) در سمت سرور اعمال می‌شوند و تنها در کد کلاینت نیستند.
 #2.3.4    سطح: 2    نقش: D
 تأیید کنید که اعتبارسنج‌های معنایی (مانند JSON Schema) در زمان ثابت اجرا می‌شوند تا از حملات DoS الگوریتمی جلوگیری شود.
 #2.3.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که خطاهای اعتبارسنجی با بخش‌هایی از بار داده حذف‌شده و کدهای خطای بدون ابهام ثبت می‌شوند تا در بررسی امنیتی کمک کنند.

---

### C2.4 غربالگری محتوا و سیاست‌ها

توسعه‌دهندگان باید قادر باشند درخواست‌های دستوری معتبر که محتوای غیراز مجاز (مانند دستورالعمل‌های غیرقانونی، سخنان نفرت‌پراکنانه، و متن‌های دارای حق نشر) را می‌خواهند شناسایی کنند و سپس از انتشار آن‌ها جلوگیری نمایند.

 #2.4.1    سطح: 1    نقش: D
 تأیید کنید که یک طبقه‌بندی‌کننده محتوا (بدون آموزش قبلی یا با آموزش دقیق شده) هر ورودی را برای خشونت، خودآسیبی، نفرت، محتوای جنسی و درخواست‌های غیرقانونی ارزیابی می‌کند، با آستانه‌های قابل تنظیم.
 #2.4.2    سطح: 1    نقش: D/V
 تأیید کنید که ورودی‌هایی که قوانین را نقض می‌کنند، پاسخ‌های استاندارد شده یا تکمیل‌های ایمن دریافت کنند تا این ورودی‌ها به فراخوانی‌های بعدی مدل‌های زبان بزرگ منتقل نشوند.
 #2.4.3    سطح: 2    نقش: D
 تأیید کنید که مدل غربالگری یا مجموعه قوانین حداقل هر سه ماه یکبار بازآموزی/به‌روزرسانی می‌شود و الگوهای جدید مشاهده‌شده فرار از محدودیت یا دور زدن سیاست‌ها در آن گنجانده شده است.
 #2.4.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که غربالگری قوانین مخصوص به کاربر (سن، محدودیت‌های قانونی منطقه‌ای) را از طریق قواعد مبتنی بر ویژگی که در زمان درخواست حل می‌شوند، رعایت می‌کند.
 #2.4.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که لاگ‌های غربالگری شامل نمرات اطمینان طبقه‌بندی‌کننده و برچسب‌های دسته‌بندی سیاست برای همبستگی SOC و بازپخش تیم قرمز آینده باشد.

---

### محدود کردن نرخ ورودی C2.5 و جلوگیری از سوءاستفاده

توسعه‌دهندگان باید با محدود کردن نرخ ورودی‌ها و شناسایی الگوهای استفاده غیرطبیعی، از سوءاستفاده، خستگی منابع و حملات خودکار علیه سیستم‌های هوش مصنوعی جلوگیری کنند.

 #2.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که محدودیت‌های نرخ برای هر کاربر، هر آی‌پی و هر کلید API برای همه نقطه‌های ورودی اجرا می‌شوند.
 #2.5.2    سطح: 2    نقش: D/V
 تأیید کنید که محدودیت‌های نرخ انفجاری و پایدار به گونه‌ای تنظیم شده‌اند که از حملات انکار سرویس (DoS) و حملات جستجوی بی‌رحمانه (brute force) جلوگیری کنند.
 #2.5.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که الگوهای استفاده ناهنجار (مانند درخواست‌های سریع و پیاپی، سیل ورودی) منجر به مسدودسازی خودکار یا افزایش سطح اقدامات شود.
 #2.5.4    سطح: 3    نقش: V
 تأیید کنید که لاگ‌های پیشگیری از سوءاستفاده نگهداری شده و برای الگوهای حمله نوظهور بررسی می‌شوند.

---

### C2.6 اعتبارسنجی ورودی چندرسانه‌ای

سیستم‌های هوش مصنوعی باید شامل اعتبارسنجی قوی برای ورودی‌های غیر متنی (تصاویر، صدا، فایل‌ها) باشند تا از تزریق، دور زدن یا سوءاستفاده از منابع جلوگیری کنند.

 #2.6.1    سطح: 1    نقش: D
 تأیید کنید که تمام ورودی‌های غیر متنی (تصاویر، صوت، فایل‌ها) از نظر نوع، اندازه و فرمت قبل از پردازش اعتبارسنجی شده باشند.
 #2.6.2    سطح: 2    نقش: D/V
 تأیید کنید که فایل‌ها قبل از ورود برای بدافزار و بارهای نهان‌نگاری شده اسکن می‌شوند.
 #2.6.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که ورودی‌های تصویر/صدا برای اختلالات متخاصم یا الگوهای حمله شناخته شده بررسی شده‌اند.
 #2.6.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که خطاهای اعتبارسنجی ورودی چند‌رسانه‌ای ثبت می‌شوند و هشدارهایی را برای بررسی ایجاد می‌کنند.

---

### C2.7 منشأ ورودی و انتساب

سیستم‌های هوش مصنوعی باید با پایش و برچسب‌گذاری مبدا تمام ورودی‌های کاربران، از حسابرسی، ردیابی سوءاستفاده و انطباق پشتیبانی کنند.

 #2.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام ورودی‌های کاربر با فراداده (شناسه کاربر، جلسه، منبع، زمان‌بندی، آدرس IP) در هنگام دریافت برچسب‌گذاری شده‌اند.
 #2.7.2    سطح: 2    نقش: D/V
 تأیید کنید که فراداده‌های منشاء برای تمام ورودی‌های پردازش‌شده حفظ شده و قابل حسابرسی باشند.
 #2.7.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که منابع ورودی غیرعادی یا غیرقابل اعتماد شناسایی شده و تحت بررسی دقیق‌تر یا مسدودسازی قرار می‌گیرند.

---

### C2.8 شناسایی تهدید تطبیقی بلادرنگ

توسعه‌دهندگان باید از سیستم‌های پیشرفته شناسایی تهدید برای هوش مصنوعی استفاده کنند که به الگوهای حمله جدید سازگار شده و حفاظت به‌موقع با تطبیق الگوهای کامپایل شده را فراهم کنند.

 #2.8.1    سطح: 1    نقش: D/V
 تأیید کنید که الگوهای شناسایی تهدید به موتورهای بهینه‌شده‌ی regex کامپایل شده‌اند تا فیلترینگ بلادرنگ با عملکرد بالا و کمترین تأخیر انجام شود.
 #2.8.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های شناسایی تهدید، کتابخانه‌های الگو جداگانه‌ای برای دسته‌های مختلف تهدید (تزریق فرمان، محتوای مضر، داده‌های حساس، دستورات سیستمی) حفظ می‌کنند.
 #2.8.3    سطح: 2    نقش: D/V
 تأیید کنید که شناسایی تهدید تطبیقی شامل مدل‌های یادگیری ماشین است که حساسیت به تهدید را بر اساس فراوانی حمله و نرخ‌های موفقیت به‌روز می‌کنند.
 #2.8.4    سطح: 2    نقش: D/V
 تأیید کنید که خوراک‌های اطلاعات تهدیدات در زمان واقعی به‌طور خودکار کتابخانه‌های الگو را با امضاهای جدید حمله و شاخص‌های نفوذ (IOCs) به‌روزرسانی می‌کنند.
 #2.8.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که نرخ خطاهای مثبت کاذب در تشخیص تهدیدها به طور مداوم پایش می‌شوند و ویژگی‌های الگو به صورت خودکار تنظیم می‌شوند تا حداقل تداخل با موارد استفاده مشروع را داشته باشند.
 #2.8.6    سطح: 3    نقش: D/V
 تأیید کنید که تحلیل تهدید متنی، منبع ورودی، الگوهای رفتار کاربر و سابقه جلسه را برای بهبود دقت شناسایی در نظر می‌گیرد.
 #2.8.7    سطح: 3    نقش: D/V
 تأیید کنید که معیارهای عملکرد تشخیص تهدید (نرخ شناسایی، تأخیر پردازش، استفاده از منابع) به صورت بلادرنگ پایش و بهینه می‌شوند.

---

### C2.9 خط لوله اعتبارسنجی امنیت چندوجهی

توسعه‌دهندگان باید اعتبارسنجی امنیتی برای متن، تصویر، صوت و سایر روش‌های ورودی هوش مصنوعی را با انواع خاصی از تشخیص تهدید و جداسازی منابع ارائه دهند.

 #2.9.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر حالت ورودی دارای اعتبارسنج‌های امنیتی اختصاصی با الگوهای تهدید مستند شده (متن: تزریق پرامپت، تصاویر: استگانوگرافی، صوت: حملات اسپکتروگرام) و آستانه‌های تشخیص باشد.
 #2.9.2    سطح: 2    نقش: D/V
 تأیید کنید که ورودی‌های چندرسانه‌ای در محیط‌های جداگانه با محدودیت‌های منابع تعریف شده (حافظه، واحد پردازش مرکزی، زمان پردازش) که مختص هر نوع حالت چندرسانه‌ای هستند، پردازش می‌شوند و این موارد در سیاست‌های امنیتی مستند شده‌اند.
 #2.9.3    سطح: 2    نقش: D/V
 تأیید کنید که تشخیص حملات میان‌مدلی، حملات هماهنگ شده‌ای که چندین نوع ورودی را در بر می‌گیرند (مثلاً بارگذاری‌های استگانوگرافیک در تصاویر همراه با تزریق فرمان در متن) با استفاده از قوانین همبستگی و تولید هشدار شناسایی می‌کند.
 #2.9.4    سطح: 3    نقش: D/V
 تأیید کنید که خطاهای اعتبارسنجی چندمدلی باعث فعال شدن ثبت گزارش‌های دقیق شامل تمامی حالت‌های ورودی، نتایج اعتبارسنجی، امتیازهای تهدید، و تحلیل همبستگی با فرمت‌های ثبت ساختاریافته برای یکپارچه‌سازی با SIEM شوند.
 #2.9.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که طبقه‌بندهای محتوای مربوط به مدالیته خاص طبق برنامه‌های مستند شده (حداقل به صورت سه‌ماهه) با الگوهای جدید تهدید، نمونه‌های خصمانه و معیارهای عملکردی به‌روزرسانی شده‌اند و عملکرد آن‌ها بالاتر از آستانه‌های پایه نگه داشته شده است.

---

### مراجع

LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security
Generative AI's Biggest Security Flaw Is Not Easy to Fix
Many-shot jailbreaking \ Anthropic
$PDF$ OpenAI GPT-4.5 System Card
Notebook for the CheckThat Lab at CLEF 2024
Mitigate jailbreaks and prompt injections – Anthropic
Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis
OWASP Top 10 for LLM Applications 2025 – WorldTech IT
OWASP Machine Learning Security Top Ten
Few words about AI Security – Jussi Metso
How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry
Easily enforcing valid JSON schema following – API
AI Safety + Cybersecurity R\&D Tracker – Fairly AI
Anthropic makes 'jailbreak' advance to stop AI models producing harmful results
Pattern matching filter rules - IBM
Real-time Threat Detection

## مدیریت چرخه عمر مدل C3 و کنترل تغییرات

### هدف کنترل

سیستم‌های هوش مصنوعی باید فرآیندهای کنترل تغییر را پیاده‌سازی کنند که از رسیدن تغییرات غیرمجاز یا ناایمن مدل به مرحله تولید جلوگیری می‌کند. این کنترل از تمامیت مدل در طول چرخه عمر آن—از توسعه تا استقرار و از کار اندازی—اطمینان حاصل می‌کند، که امکان پاسخ سریع به حوادث و حفظ مسئولیت‌پذیری برای تمامی تغییرات را فراهم می‌آورد.

هدف اصلی امنیت: تنها مدل‌های مجاز و تأیید شده از طریق فرایندهای کنترل شده که صحت، قابلیت ردیابی و بازیابی را حفظ می‌کنند، به مرحله تولید می‌رسند.

---

### C3.1 مجوزدهی و یکپارچگی مدل

تنها مدل‌های مجاز با یکپارچگی تأیید شده به محیط‌های تولید می‌رسند.

 #3.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که همه آثار مدل (وزن‌ها، پیکربندی‌ها، توکن‌سازها) قبل از استقرار توسط نهادهای مجاز به صورت رمزنگاری شده امضا شده باشند.
 #3.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که صحت مدل در زمان استقرار تأیید می‌شود و شکست در تأیید امضا مانع از بارگذاری مدل می‌شود.
 #3.1.3    سطح: 2    نقش: D/V
 تأیید کنید که سوابق منشأ مدل شامل هویت نهاد مجازکننده، چک‌سام‌های داده‌های آموزشی، نتایج آزمون اعتبارسنجی همراه با وضعیت قبولی/رد، و یک زمان‌سنجی ایجاد باشد.
 #3.1.4    سطح: 2    نقش: D/V
 تأیید کنید که همه مصنوعات مدل از نسخه‌بندی معنایی (MAJOR.MINOR.PATCH) استفاده می‌کنند و معیارهای مستندی که مشخص می‌کند هر مؤلفه نسخه چه زمانی افزایش می‌یابد، وجود دارد.
 #3.1.5    سطح: 2    نقش: V
 تأیید کنید که ردیابی وابستگی یک موجودی به‌روز و در زمان واقعی را حفظ می‌کند که امکان شناسایی سریع تمام سیستم‌های مصرف‌کننده را فراهم می‌آورد.

---

### C3.2 اعتبارسنجی و آزمون مدل

مدل‌ها باید پیش از استقرار، اعتبارسنجی‌های امنیتی و ایمنی تعریف شده را گذرانده باشند.

 #3.2.1    سطح: 1    نقش: D/V
 تأیید کنید که مدل‌ها تحت آزمایش امنیتی خودکار قرار می‌گیرند که شامل اعتبارسنجی ورودی، پاک‌سازی خروجی و ارزیابی‌های ایمنی با آستانه‌های قبلاً توافق شده سازمانی برای قبولی یا رد شدن قبل از استقرار است.
 #3.2.2    سطح: 1    نقش: D/V
 تأیید کنید که شکست‌های اعتبارسنجی پس از تأیید صریح توسط پرسنل مجاز پیش‌تعیین‌شده با مستندات توجیهات تجاری، به‌طور خودکار مانع از استقرار مدل می‌شوند.
 #3.2.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که نتایج آزمایش به صورت رمزنگاری شده امضا شده و به طور غیرقابل تغییر به هش نسخه مدل خاصی که اعتبارسنجی می‌شود، متصل شده‌اند.
 #3.2.4    سطح: 2    نقش: D/V
 تأیید کنید که استقرارهای اضطراری نیازمند ارزیابی ریسک امنیتی مستند و تأیید از سوی مرجع امنیتی پیش‌تعیین‌شده در بازه‌های زمانی از پیش توافق‌شده هستند.

---

### C3.3 استقرار کنترل‌شده و بازگردانی

استقرار مدل‌ها باید کنترل‌شده، نظارت‌شده و قابل بازگشت باشد.

 #3.3.1    سطح: 1    نقش: D
 تأیید کنید که استقرارهای تولید مکانیزم‌های راه‌اندازی تدریجی (استقرارهای کناری، استقرارهای آبی-سبز) را با ماشه‌های بازگشت خودکار بر اساس نرخ‌های خطای از پیش توافق شده، آستانه‌های تأخیر یا معیارهای هشدار امنیتی پیاده‌سازی می‌کنند.
 #3.3.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که قابلیت‌های بازگردانی به صورت اتمیک، وضعیت کامل مدل (وزن‌ها، پیکربندی‌ها، وابستگی‌ها) را در بازه‌های زمانی تعریف‌شده سازمانی بازیابی می‌کنند.
 #3.3.3    سطح: 2    نقش: D/V
 تأیید کنید که فرایندهای استقرار امضاهای رمزنگاری را اعتبارسنجی کرده و چک‌ساب‌های تمامیت را قبل از فعال‌سازی مدل محاسبه می‌کنند، و در صورت هرگونه عدم تطابق، استقرار با شکست مواجه شود.
 #3.3.4    سطح: 2    نقش: D/V
 تأیید کنید که قابلیت‌های خاموش‌کردن اضطراری مدل می‌توانند نقاط انتهایی مدل را در زمان‌های پاسخ پیش‌تعریف‌شده از طریق مدارشکن‌های خودکار یا کلیدهای دستی غیرفعال کنند.
 #3.3.5    سطح: 2    نقش: V
 اطمینان حاصل کنید که آثار بازگشت (نسخه‌های قبلی مدل، پیکربندی‌ها، وابستگی‌ها) مطابق با سیاست‌های سازمانی با استفاده از ذخیره‌سازی غیر قابل تغییر برای پاسخ به حوادث نگهداری می‌شوند.

---

### C3.4 پاسخگویی و حسابرسی تغییرات

تمام تغییرات چرخه عمر مدل باید قابل ردیابی و حسابرسی باشند.

 #3.4.1    سطح: 1    نقش: V
 تأیید کنید که تمام تغییرات مدل (استقرار، پیکربندی، بازنشستگی) سوابق حسابرسی غیرقابل تغییر شامل یک مهر زمانی، هویت بازیگر احراز هویت شده، نوع تغییر و وضعیت‌های قبل/بعد را تولید می‌کنند.
 #3.4.2    سطح: 2    نقش: D/V
 تأیید کنید که دسترسی به گزارش حسابرسی نیازمند مجوز مناسب است و تمام تلاش‌های دسترسی همراه با هویت کاربر و زمان‌سنجی ثبت می‌شوند.
 #3.4.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که قالب‌های فرمان و پیام‌های سیستمی در مخازن گیت تحت کنترل نسخه قرار دارند و پیش از استقرار، مرور کد اجباری و تایید از بررسی‌کنندگان تعیین‌شده دریافت می‌شود.
 #3.4.4    سطح: 2    نقش: V
 تأیید کنید که سوابق حسابرسی شامل جزئیات کافی (هش‌های مدل، عکس‌های لحظه‌ای پیکربندی، نسخه‌های وابستگی) باشد تا امکان بازسازی کامل وضعیت مدل برای هر بازه زمانی در دوره نگهداری فراهم شود.

---

### C3.5 شیوه‌های توسعه امن

فرآیندهای توسعه و آموزش مدل‌ها باید از رویه‌های ایمن پیروی کنند تا از بروز نقص امنیتی جلوگیری شود.

 #3.5.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که محیط‌های توسعه مدل، تست و تولید از نظر فیزیکی یا منطقی جدا شده‌اند. آن‌ها زیرساخت مشترک ندارند، کنترل‌های دسترسی متفاوتی دارند و فروشگاه‌های داده‌ای ایزوله‌شده دارند.
 #3.5.2    سطح: 1    نقش: D
 تأیید کنید که آموزش مدل و بهینه‌سازی دقیق در محیط‌های ایزوله با دسترسی شبکه کنترل‌شده انجام می‌شود.
 #3.5.3    سطح: 1    نقش: D/V
 اطمینان حاصل شود که منابع داده‌های آموزشی از طریق بررسی‌های صحت تأیید شده و از طریق منابع معتبر با زنجیره مستند مالکیت تأیید هویت شده‌اند قبل از استفاده در توسعه مدل.
 #3.5.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که مصنوعات توسعه مدل (ابرپارامترها، اسکریپت‌های آموزش، فایل‌های پیکربندی) در کنترل نسخه ذخیره شده و قبل از استفاده در آموزش نیاز به تایید مرور همتا داشته باشند.

---

### C3.6 بازنشستگی و از کار انداختن مدل

مدل‌ها باید به‌صورت امن بازنشسته شوند زمانی که دیگر به آنها نیازی نیست یا زمانی که مسائل امنیتی شناسایی می‌شوند.

 #3.6.1    سطح: 1    نقش: D
 بررسی کنید که فرآیندهای بازنشستگی مدل به‌صورت خودکار نمودارهای وابستگی را اسکن کرده، تمام سیستم‌های مصرف‌کننده را شناسایی می‌کنند و دوره‌های اطلاع‌رسانی پیش‌توافق‌شده را قبل از بازنشستگی ارائه می‌دهند.
 #3.6.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که آثار مدل بازنشسته شده با استفاده از پاک‌سازی رمزنگاری یا بازنویسی چندگذر طبق سیاست‌های مستند نگهداری داده‌ها به صورت ایمن پاک شده‌اند و دارای گواهی‌های تأیید شده تخریب باشند.
 #3.6.3    سطح: 2    نقش: V
 بررسی کنید که رویدادهای بازنشستگی مدل با زمان‌بندی و هویت بازیگر ثبت شده‌اند و امضاهای مدل برای جلوگیری از استفاده مجدد پس گرفته شده‌اند.
 #3.6.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که بازنشستگی اضطراری مدل می‌تواند دسترسی به مدل را در چارچوب‌های زمانی پاسخ اضطراری از پیش تعیین‌شده از طریق سوئیچ‌های خودکار خاموش کردن، در صورت کشف آسیب‌پذیری‌های بحرانی امنیتی، غیرفعال کند.

---

### مراجع

MLOps Principles
Securing AI/ML Ops – Cisco.com
Audit logs security: cryptographically signed tamper-proof logs
Machine Learning Model Versioning: Top Tools & Best Practices
AI Hygiene Starts with Models and Data Loaders – SEI Blog
How to handle versioning and rollback of a deployed ML model?
Reinforcement fine-tuning – OpenAI API
Auditing Machine Learning models: Governance, Data Security and …
Adversarial Training to Improve Model Robustness
What is AI adversarial robustness? – IBM Research
Exploring Data Provenance: Ensuring Data Integrity and Authenticity
MITRE ATLAS
AWS Prescriptive Guidance – Best practices for retiring applications …

## زیرساخت C4، پیکربندی و امنیت استقرار

### هدف کنترل

زیرساخت هوش مصنوعی باید در برابر افزایش سطح دسترسی، دستکاری زنجیره تامین و حرکت جانبی از طریق پیکربندی امن، جداسازی زمان اجرا، خطوط تولید اعتمادشده و نظارت جامع مقاوم شود. تنها اجزاء و پیکربندی‌های مجاز و معتبر زیرساخت از طریق فرآیندهای کنترل‌شده که امنیت، یکپارچگی و قابلیت حسابرسی را حفظ می‌کنند، به مرحله تولید می‌رسند.

هدف اصلی امنیت: تنها اجزای زیرساختی که با امضای رمزنگاری شده و اسکن شده از نظر آسیب‌پذیری هستند، از طریق خط‌های اعتبارسنجی خودکار که سیاست‌های امنیتی را اعمال کرده و سوابق بازبینی غیرقابل تغییر را حفظ می‌کنند، به محیط تولید می‌رسند.

---

### جدا سازی محیط اجرای C4.1

جلوگیری از فرار از کانتینر و افزایش امتیاز به وسیلهٔ سازوکارهای جداسازی در سطح هسته و کنترل‌های الزامی دسترسی.

 #4.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام کانتینرهای هوش مصنوعی تمامی قابلیت‌های لینوکس را جز CAP_SETUID، CAP_SETGID و قابلیت‌های صریحاً مورد نیاز که در مبناهای امنیتی مستند شده‌اند، غیرفعال کنند.
 #4.1.2    سطح: 1    نقش: D/V
 تأیید کنید که پروفایل‌های seccomp همهٔ فراخوانی‌های سیستمی را به جز آن‌هایی که در لیست‌های مجاز از پیش تایید شده هستند، مسدود می‌کنند، به طوری که تخلفات باعث خاتمه کانتینر و تولید هشدارهای امنیتی شوند.
 #4.1.3    سطح: 2    نقش: D/V
 تأیید کنید که بارهای کاری AI با سیستم‌فایل‌های روت فقط‌خواندنی، tmpfs برای داده‌های موقت و حجم‌های نام‌گذاری‌شده برای داده‌های پایدار اجرا می‌شوند و گزینه‌های mount با noexec اعمال شده‌اند.
 #4.1.4    سطح: 2    نقش: D/V
 تأیید کنید که مانیتورینگ زمان اجرا مبتنی بر eBPF (Falco، Tetragon یا معادل آن) تلاش‌های ارتقاء امتیاز را شناسایی کرده و فرآیندهای متخلف را به‌طور خودکار در چارچوب زمان پاسخ سازمانی متوقف می‌کند.
 #4.1.5    سطح: 3    نقش: D/V
 تأیید کنید که بارهای کاری با ریسک بالا در هوش مصنوعی در محیط‌های جداشده سخت‌افزاری (Intel TXT، AMD SVM، یا گره‌های اختصاصی bare-metal) با تأیید اعتبار اجرا می‌شوند.

---

### C4.2 خطوط لوله ساخت و استقرار امن

تضمین یکپارچگی رمزنگاری و امنیت زنجیره تأمین از طریق ساخت‌های بازتولیدپذیر و مصنوعات امضا شده.

 #4.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که زیرساخت به عنوان کد با استفاده از ابزارهایی مانند tfsec، Checkov یا Terrascan در هر کامیت اسکن می‌شود و ادغام‌ها در صورت وجود یافته‌های با شدت CRITICAL یا HIGH مسدود می‌شوند.
 #4.2.2    سطح: 1    نقش: D/V
 تأیید کنید که ساخت کانتینرها بازتولیدپذیر هستند با هش‌های SHA256 یکسان در طول ساخت‌ها و تصدیقات اثبات منشأ SLSA سطح 3 را که با Sigstore امضاء شده‌اند تولید کنید.
 #4.2.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که ایمیج‌های کانتینر شامل SBOMهای CycloneDX یا SPDX باشند و قبل از ارسال به رجیستری، با Cosign امضا شده‌اند؛ همچنین ایمیج‌های بدون امضا هنگام استقرار رد شوند.
 #4.2.4    سطح: 2    نقش: D/V
 تأیید کنید که خطوط لوله CI/CD از توکن‌های OIDC از HashiCorp Vault، نقش‌های AWS IAM، یا Azure Managed Identity با زمان‌های اعتبار که از محدودیت‌های سیاست امنیتی سازمان فراتر نمی‌رود، استفاده می‌کنند.
 #4.2.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که امضاهای Cosign و منبع SLSA در طی فرایند استقرار قبل از اجرای کانتینر اعتبارسنجی می‌شوند و خطاهای اعتبارسنجی باعث شکست استقرار می‌شوند.
 #4.2.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که محیط‌های ساخت در کانتینرها یا ماشین‌های مجازی موقتی اجرا می‌شوند که فاقد ذخیره‌سازی پایدار بوده و از شبکه‌های VPC تولید به طور جداگانه ایزوله شده‌اند.

---

### C4.3 امنیت شبکه و کنترل دسترسی

اجرای شبکه‌سازی صفر-اعتمادی با سیاست‌های پیش‌فرض-رد و ارتباطات رمزگذاری شده.

 #4.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که NetworkPolicies در Kubernetes یا هر معادل آن، دسترسی پیش‌فرض را به صورت deny برای ingress/egress پیاده‌سازی کرده و قوانین اجازه صریح برای پورت‌های موردنیاز (443، 8080 و غیره) تعریف شده باشد.
 #4.3.2    سطح: 1    نقش: D/V
 تأیید کنید که SSH (پورت 22)، RDP (پورت 3389) و نقاط انتهایی متادیتای ابری (169.254.169.254) مسدود شده‌اند یا نیاز به احراز هویت مبتنی بر گواهی‌نامه دارند.
 #4.3.3    سطح: 2    نقش: D/V
 تأیید کنید که ترافیک خروجی از طریق پراکسی‌های HTTP/HTTPS (Squid، Istio، یا دروازه‌های NAT ابر) با فهرست‌های مجاز دامنه فیلتر می‌شود و درخواست‌های مسدود شده ثبت می‌گردند.
 #4.3.4    سطح: 2    نقش: D/V
 تأیید کنید که ارتباط بین سرویس‌ها از mutual TLS استفاده می‌کند و گواهی‌ها طبق سیاست سازمانی چرخش داده می‌شوند و اعتبارسنجی گواهی اعمال می‌شود (بدون استفاده از فلگ‌های skip-verify).
 #4.3.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که زیرساخت هوش مصنوعی در VPCها/VNetهای اختصاصی اجرا می‌شود بدون دسترسی مستقیم به اینترنت و تنها از طریق دروازه‌های NAT یا میزبان‌های بسطی ارتباط برقرار می‌کند.

---

### C4.4 مدیریت رازها و کلیدهای رمزنگاری

محافظت از اطلاعات ورود با استفاده از ذخیره‌سازی پشتیبانی شده توسط سخت‌افزار و گردش خودکار با دسترسی صفر اعتماد.

 #4.4.1    سطح: 1    نقش: D/V
 تأیید کنید که اسرار در HashiCorp Vault، AWS Secrets Manager، Azure Key Vault، یا Google Secret Manager با رمزنگاری در حالت استراحت با استفاده از AES-256 ذخیره شده‌اند.
 #4.4.2    سطح: 1    نقش: D/V
 تأیید کنید که کلیدهای رمزنگاری در HSMهای سطح 2 مطابق استاندارد FIPS 140-2 (AWS CloudHSM، Azure Dedicated HSM) ایجاد می‌شوند و چرخش کلیدها مطابق با سیاست رمزنگاری سازمانی انجام می‌شود.
 #4.4.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که گردش کلیدهای مخفی به‌صورت خودکار با استقرار بدون توقف و چرخش فوری که توسط تغییرات پرسنلی یا حوادث امنیتی تحریک می‌شود، انجام می‌شود.
 #4.4.4    سطح: 2    نقش: D/V
 تأیید کنید که تصاویر کانتینر با ابزارهایی مانند GitLeaks، TruffleHog، یا detect-secrets اسکن شوند تا ساخت‌هایی که شامل کلیدهای API، گذرواژه‌ها یا گواهی‌نامه‌ها هستند، مسدود شوند.
 #4.4.5    سطح: 2    نقش: D/V
 تأیید کنید که دسترسی به کلیدهای محرمانه تولید مستلزم استفاده از MFA با توکن‌های سخت‌افزاری (YubiKey، FIDO2) است و این دسترسی‌ها توسط لاگ‌های حسابرسی غیرقابل تغییر با هویت کاربران و زمان‌های ثبت شده ضبط می‌شوند.
 #4.4.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اسرار از طریق اسرار Kubernetes، حجم‌های مونت شده، یا کانتینرهای init تزریق شده‌اند و مطمئن شوید که اسرار هرگز در متغیرهای محیطی یا ایمیج‌ها جایگذاری نشده‌اند.

---

### جعبه شنی‌سازی و اعتبارسنجی بار کاری هوش مصنوعی C4.5

مدل‌های هوش مصنوعی غیرقابل اعتماد را در محیط‌های ایمن جدا کنید و آن‌ها را با تحلیل رفتاری جامع ارزیابی نمایید.

 #4.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مدل‌های هوش مصنوعی خارجی در gVisor، میکروVMها (مانند Firecracker، CrossVM) یا کانتینرهای داکر با گزینه‌های --security-opt=no-new-privileges و --read-only اجرا می‌شوند.
 #4.5.2    سطح: 1    نقش: D/V
 تأیید کنید که محیط‌های سندباکس هیچ اتصال شبکه‌ای نداشته باشند (--network=none) یا فقط به localhost دسترسی داشته باشند و همه درخواست‌های خارجی توسط قوانین iptables مسدود شده باشند.
 #4.5.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اعتبارسنجی مدل هوش مصنوعی شامل آزمون خودکار تیم قرمز با پوشش آزمون تعریف شده سازمانی و تحلیل رفتاری برای شناسایی درب پشتی است.
 #4.5.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که قبل از ارتقاء یک مدل هوش مصنوعی به محیط تولید، نتایج محیط آزمایشی آن توسط پرسنل امنیتی مجاز به صورت رمزنگاری شده امضا شده و در لاگ‌های حسابرسی غیرقابل تغییر ذخیره شده باشند.
 #4.5.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که محیط‌های سندباکس بین ارزیابی‌ها نابود و دوباره از تصاویر گلدن بازسازی می‌شوند، همراه با پاک‌سازی کامل فایل سیستم و حافظه.

---

### C4.6 پایش امنیت زیرساخت

زیرساخت را به طور مداوم با بازسازی خودکار و هشدار در زمان واقعی اسکن و نظارت کنید.

 #4.6.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تصاویر کانتینر بر اساس برنامه‌های سازمانی اسکن می‌شوند و آسیب‌پذیری‌های بحرانی (CRITICAL) که باعث قطع فرآیند استقرار می‌شوند، طبق آستانه‌های ریسک سازمانی مسدود شوند.
 #4.6.2    سطح: 1    نقش: D/V
 تأیید کنید که زیرساخت از معیارهای CIS Benchmarks یا کنترل‌های NIST 800-53 با آستانه‌های تطبیق تعریف‌شده سازمانی و اصلاح خودکار برای بررسی‌های ناموفق عبور می‌کند.
 #4.6.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که آسیب‌پذیری‌های با شدت بالا طبق جدول‌های زمانی مدیریت ریسک سازمانی وصله می‌شوند و برای CVEهای فعال که در حال سوءاستفاده هستند، رویه‌های اضطراری اعمال می‌شود.
 #4.6.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که هشدارهای امنیتی با پلتفرم‌های SIEM (مانند Splunk، Elastic، یا Sentinel) با استفاده از فرمت‌های CEF یا STIX/TAXII و به‌صورت خودکار غنی‌سازی شده، یکپارچه می‌شوند.
 #4.6.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که معیارهای زیرساخت به سیستم‌های نظارتی (Prometheus، DataDog) با داشبوردهای SLA و گزارش‌دهی اجرایی صادر می‌شوند.
 #4.6.6    سطح: 2    نقش: D/V
 تأیید کنید که تغییرات پیکربندی با استفاده از ابزارها (Chef InSpec، AWS Config) مطابق با الزامات نظارت سازمانی شناسایی می‌شوند و بازگشت خودکار برای تغییرات غیرمجاز انجام می‌شود.

---

### مدیریت منابع زیرساخت هوش مصنوعی C4.7

جلوگیری از حملات تخلیه منابع و اطمینان از تخصیص عادلانه منابع از طریق سهمیه‌ها و نظارت.

 #4.7.1    سطح: 1    نقش: D/V
 تأیید کنید که استفاده از GPU/TPU با هشدارهایی که در آستانه‌های تعریف شده سازمانی فعال می‌شوند، نظارت می‌شود و مقیاس‌بندی خودکار یا متعادل‌سازی بار بر اساس سیاست‌های مدیریت ظرفیت فعال شده است.
 #4.7.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که معیارهای بار کاری هوش مصنوعی (تاخیر استنتاج، توان عملیاتی، نرخ خطا) مطابق با الزامات نظارتی سازمانی جمع‌آوری شده و با استفاده زیرساخت مرتبط شده‌اند.
 #4.7.3    سطح: 2    نقش: D/V
 تأیید کنید که Kubernetes ResourceQuotas یا معادل آن، محدودیت‌های سخت‌گیرانه را برای بارهای کاری فردی بر اساس سیاست‌های تخصیص منابع سازمانی اعمال می‌کنند.
 #4.7.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که مانیتورینگ هزینه، هزینه‌ها را به ازای هر بار کاری/مستأجر رصد می‌کند، با هشدارهایی بر اساس آستانه‌های بودجه سازمانی و کنترل‌های خودکار برای تجاوز از بودجه.
 #4.7.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که برنامه‌ریزی ظرفیت از داده‌های تاریخی با دوره‌های پیش‌بینی تعریف‌شده سازمانی و تأمین منابع خودکار بر اساس الگوهای تقاضا استفاده می‌کند.
 #4.7.6    سطح: 2    نقش: D/V
 تأیید کنید که خستگی منابع باعث فعال شدن مدار شکن‌ها طبق الزامات پاسخ سازمانی می‌شود، شامل محدودیت نرخ بر اساس سیاست‌های ظرفیت و جداسازی بار کاری.

---

### C4.8 تفکیک محیط و کنترل‌های ارتقاء

اجرای مرزهای محیطی سختگیرانه با دروازه‌های ترویج خودکار و اعتبارسنجی امنیتی.

 #4.8.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که محیط‌های توسعه/آزمایش/تولید در VPCها/VNetهای جداگانه اجرا می‌شوند و هیچ نقش IAM، گروه‌های امنیتی، یا اتصال شبکه مشترکی ندارند.
 #4.8.2    سطح: 1    نقش: D/V
 تأیید کنید که ارتقاء محیط نیازمند تأیید از سوی افراد مجاز تعریف شده سازمانی با امضاهای رمزنگاری شده و سابقه‌های حسابرسی غیرقابل تغییر است.
 #4.8.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که محیط‌های تولید دسترسی SSH را مسدود می‌کنند، نقاط انتهایی دیباگ را غیرفعال می‌کنند و درخواست‌های تغییر را با الزامات اطلاع‌رسانی قبلی سازمانی به جز موارد اضطراری، الزام می‌کنند.
 #4.8.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تغییرات زیرساخت به عنوان کد قبل از ادغام به شاخه اصلی، نیازمند بازبینی همتا همراه با آزمایش‌های خودکار و اسکن امنیتی هستند.
 #4.8.5    سطح: 2    نقش: D/V
 اطمینان حاصل شود که داده‌های غیرتولیدی مطابق با الزامات حفظ حریم خصوصی سازمانی ناشناس‌سازی شده‌اند، تولید داده‌های مصنوعی انجام شده یا ماسک‌گذاری کامل داده‌ها با حذف اطلاعات شناسایی شخصی (PII) تایید شده است.
 #4.8.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که دروازه‌های ارتقا شامل تست‌های امنیتی خودکار (SAST، DAST، اسکن کانتینر) با نیاز به صفر یافته بحرانی برای تأیید هستند.

---

### C4.9 پشتیبان‌گیری و بازیابی زیرساخت

اطمینان از تاب‌آوری زیرساخت از طریق پشتیبان‌گیری خودکار، آزمایش روش‌های بازیابی و قابلیت‌های بازیابی از بحران.

 #4.9.1    سطح: 1    نقش: D/V
 تأیید کنید که پیکربندی‌های زیرساختی مطابق با برنامه‌های پشتیبان‌گیری سازمانی به مناطق جغرافیایی جداگانه با پیاده‌سازی استراتژی پشتیبان‌گیری 3-2-1 پشتیبان‌گیری شده‌اند.
 #4.9.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های پشتیبان‌گیری در شبکه‌های جداگانه با اعتبارنامه‌های مجزا و ذخیره‌سازی ایزوله (air-gapped) برای محافظت در برابر باج‌افزارها اجرا می‌شوند.
 #4.9.3    سطح: 2    نقش: V
 تأیید کنید که روندهای بازیابی بر اساس برنامه‌های سازمانی با اهداف RTO و RPO که با نیازهای سازمانی مطابقت دارند، از طریق آزمون‌های خودکار آزمایش و اعتبارسنجی شده‌اند.
 #4.9.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که بازیابی پس از حادثه شامل راهنماهای مخصوص هوش مصنوعی با بازسازی وزن مدل، بازسازی خوشه GPU و نقشه‌برداری وابستگی خدمات باشد.

---

### C4.10 انطباق و حاکمیت زیرساخت

رعایت مقررات از طریق ارزیابی مداوم، مستندسازی، و کنترل‌های خودکار حفظ شود.

 #4.10.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که انطباق زیرساخت مطابق با برنامه‌های سازمانی و کنترل‌های SOC 2، ISO 27001، یا FedRAMP با جمع‌آوری خودکار شواهد ارزیابی می‌شود.
 #4.10.2    سطح: 2    نقش: V
 بررسی کنید که مستندات زیرساخت شامل نمودارهای شبکه، نقشه‌های جریان داده و مدل‌های تهدید باشد که مطابق با الزامات مدیریت تغییر سازمانی به‌روزرسانی شده‌اند.
 #4.10.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تغییرات زیرساختی تحت ارزیابی خودکار تأثیر انطباق با جریان‌های کاری تأییدیه مقررات برای اصلاحات پرخطر قرار می‌گیرند.

---

### C4.11 امنیت سخت‌افزار هوش مصنوعی

قطعات سخت‌افزاری مخصوص هوش مصنوعی ایمن از جمله GPUها، TPUها و شتاب‌دهنده‌های تخصصی هوش مصنوعی را ایمن کنید.

 #4.11.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که میان‌افزار شتاب‌دهنده‌های هوش مصنوعی (BIOS کارت گرافیک، میان‌افزار TPU) با امضاهای رمزنگاری شده تأیید شده و مطابق با جدول زمانی مدیریت پچ سازمانی به‌روزرسانی می‌شوند.
 #4.11.2    سطح: 2    نقش: D/V
 تأیید کنید که قبل از اجرای بار کاری، یکپارچگی شتاب‌دهنده هوش مصنوعی با استفاده از تأیید اعتبار سخت‌افزاری از طریق TPM 2.0، Intel TXT، یا AMD SVM ارزیابی شده باشد.
 #4.11.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که حافظه GPU بین بارهای کاری با استفاده از SR-IOV، MIG (GPU چند نمونه‌ای) یا تفکیک سخت‌افزاری معادل با پاک‌سازی حافظه بین وظایف، ایزوله شده است.
 #4.11.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که زنجیره تأمین سخت‌افزار هوش مصنوعی شامل تایید اصالت با گواهی‌های تولیدکننده و اعتبارسنجی بسته‌بندی مقاوم در برابر دستکاری باشد.
 #4.11.5    سطح: 3    نقش: D/V
 تأیید کنید که ماژول‌های امنیت سخت‌افزاری (HSM) وزن‌های مدل هوش مصنوعی و کلیدهای رمزنگاری را با گواهی‌نامه FIPS 140-2 سطح 3 یا معیار مشترک EAL4+ محافظت می‌کنند.

---

### C4.12 زیرساخت هوش مصنوعی لبه و توزیع‌شده

استقرار امن هوش مصنوعی توزیع‌شده شامل محاسبات لبه، یادگیری فدرال و معماری‌های چندسایتی.

 #4.12.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که دستگاه‌های هوش مصنوعی لبه‌ای با استفاده از TLS متقابل و با گواهی‌های دستگاه که مطابق با سیاست مدیریت گواهی سازمانی تعویض می‌شوند، به زیرساخت مرکزی احراز هویت می‌کنند.
 #4.12.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که دستگاه‌های لبه‌ای بوت امن با امضاهای تایید شده و محافظت در برابر بازگردانی را پیاده‌سازی می‌کنند تا از حملات کاهش نسخه فریم‌ور جلوگیری شود.
 #4.12.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که هماهنگی هوش مصنوعی توزیع‌شده از الگوریتم‌های اجماع تحمل خطای بیزانتی استفاده می‌کند که شامل اعتبارسنجی شرکت‌کنندگان و شناسایی گره‌های مخرب است.
 #4.12.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که ارتباط بین لبه و ابر شامل محدودسازی پهنای باند، فشرده‌سازی داده‌ها، و قابلیت‌های عملیات آفلاین با ذخیره‌سازی محلی امن باشد.

---

### C4.13 امنیت زیرساخت‌های چندابری و ترکیبی

بارکاری‌های ایمنی هوش مصنوعی را در چندین ارائه‌دهنده‌ی ابر و استقرارهای ترکیبی ابر-درون‌سازمانی امن کنید.

 #4.13.1    سطح: 2    نقش: D/V
 تأیید کنید که استقرارهای هوش مصنوعی چندابری از اتحاد هویتی مستقل از ابر (OIDC، SAML) با مدیریت سیاست متمرکز در سراسر ارائه‌دهندگان استفاده می‌کنند.
 #4.13.2    سطح: 2    نقش: D/V
 تأیید کنید که انتقال داده بین ابرها از رمزگذاری انتها به انتها با کلیدهای مدیریت‌شده توسط مشتری و کنترل‌های محل اقامت داده‌ها مطابق با حوزه قضایی اعمال می‌شود.
 #4.13.3    سطح: 2    نقش: D/V
 تأیید کنید که بارهای کاری هوش مصنوعی در فضای ابری ترکیبی، سیاست‌های امنیتی یکسان را در محیط‌های محلی و ابری پیاده‌سازی می‌کنند و از نظارت و هشداردهی یکپارچه برخوردار هستند.
 #4.13.4    سطح: 3    نقش: V
 تأیید کنید که جلوگیری از قفل شدن به فروشنده ابر شامل زیرساخت قابل حمل به عنوان کد، APIهای استاندارد شده و قابلیت‌های خروجی داده با ابزارهای تبدیل فرمت باشد.
 #4.13.5    سطح: 3    نقش: V
 تأیید کنید که بهینه‌سازی هزینه چندابری شامل کنترل‌های امنیتی است که از پراکندگی منابع جلوگیری می‌کند و همچنین از هزینه‌های انتقال داده غیرمجاز بین ابرها جلوگیری می‌کند.

---

### C4.14 امنیت خودکارسازی زیرساخت و GitOps

خطوط لوله اتوماسیون زیرساخت ایمن و گردش‌کارهای GitOps برای مدیریت زیرساخت هوش مصنوعی.

 #4.14.1    سطح: 2    نقش: D/V
 بررسی کنید که مخازن GitOps نیازمند تعهدات امضاشده با کلیدهای GPG باشند و قوانین حفاظت از شاخه که مانع از ارسال مستقیم به شاخه‌های اصلی می‌شوند را داشته باشند.
 #4.14.2    سطح: 2    نقش: D/V
 تأیید کنید که خودکارسازی زیرساخت شامل شناسایی انحراف با قابلیت‌های اصلاح خودکار و بازگردانی است که بر اساس نیازهای پاسخ سازمانی به تغییرات غیرمجاز فعال می‌شوند.
 #4.14.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تأمین زیرساخت خودکار شامل اعتبارسنجی سیاست امنیتی با مسدود کردن استقرار برای پیکربندی‌های غیرمجاز است.
 #4.14.4    سطح: 2    نقش: D/V
 تأیید کنید که اسرار مربوط به خودکارسازی زیرساخت از طریق اپراتورهای اسرار خارجی (External Secrets Operator, Bank-Vaults) با چرخش خودکار مدیریت می‌شوند.
 #4.14.5    سطح: 3    نقش: V
 تأیید کنید که زیرساخت خودترمیم شامل همبستگی رویدادهای امنیتی با پاسخ خودکار به حادثه و گردش‌کار اطلاع‌رسانی به ذینفعان است.

---

### C4.15 امنیت زیرساخت مقاوم در برابر کوانتومی

زیرساخت هوش مصنوعی را برای تهدیدات محاسبات کوانتومی از طریق رمزنگاری پساکوانتومی و پروتکل‌های ایمن در برابر کوانتوم آماده کنید.

 #4.15.1    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که زیرساخت هوش مصنوعی الگوریتم‌های پست‌کوانتومی رمزنگاری تایید شده توسط NIST (CRYSTALS-Kyber، CRYSTALS-Dilithium، SPHINCS+) را برای تبادل کلید و امضاهای دیجیتال پیاده‌سازی می‌کند.
 #4.15.2    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های توزیع کلید کوانتومی (QKD) برای ارتباطات هوش مصنوعی با امنیت بالا با پروتکل‌های مدیریت کلید کوانتومی-امن پیاده‌سازی شده‌اند.
 #4.15.3    سطح: 3    نقش: D/V
 تأیید کنید که چارچوب‌های چابکی رمزنگاری امکان مهاجرت سریع به الگوریتم‌های جدید پساکوانتومی را با چرخش خودکار گواهی‌نامه و کلید فراهم می‌کنند.
 #4.15.4    سطح: 3    نقش: V
 تأیید کنید که مدل‌سازی تهدیدات کوانتومی آسیب‌پذیری زیرساخت هوش مصنوعی در برابر حملات کوانتومی را با جدول زمانی مهاجرت مستند شده و ارزیابی‌های ریسک بررسی می‌کند.
 #4.15.5    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های رمزنگاری ترکیبی کلاسیک-کوانتومی در طول دوره انتقال کوانتومی با نظارت بر عملکرد، دفاع در عمق را فراهم می‌کنند.

---

### C4.16 محاسبات محرمانه و خوشه‌های امن

محافظت از بارهای کاری هوش مصنوعی و وزن‌های مدل با استفاده از محیط‌های اجرای مورد اعتماد مبتنی بر سخت‌افزار و فناوری‌های محاسبات محرمانه.

 #4.16.1    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مدل‌های حساس هوش مصنوعی در محیط‌های امن Intel SGX enclaves، AMD SEV-SNP، یا ARM TrustZone با حافظه رمزگذاری شده و تأیید اعتبار اجرا می‌شوند.
 #4.16.2    سطح: 3    نقش: D/V
 بررسی کنید که کانتینرهای محرمانه (Kata Containers، gVisor با پردازش محرمانه) بارهای کاری هوش مصنوعی را با رمزنگاری حافظه تحمیلی توسط سخت‌افزار ایزوله می‌کنند.
 #4.16.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که استناد از راه دور صحت محیط محدود (enclave) را قبل از بارگذاری مدل‌های هوش مصنوعی با اثبات رمزنگاری شده اصالت محیط اجرای آن تأیید می‌کند.
 #4.16.4    سطح: 3    نقش: D/V
 تأیید کنید که خدمات استنتاج محرمانه هوش مصنوعی با استفاده از محاسبات رمزگذاری شده با وزن‌های مدل مهر و موم‌شده و اجرای محافظت‌شده، از استخراج مدل جلوگیری می‌کنند.
 #4.16.5    سطح: 3    نقش: D/V
 تأیید کنید که ارکستراسیون محیط اجرای مورد اعتماد چرخه عمر انکلایو امن را با ارزیابی از راه دور و کانال‌های ارتباطی رمزنگاری شده مدیریت می‌کند.
 #4.16.6    سطح: 3    نقش: D/V
 تأیید کنید که محاسبات چندجانبه امن (SMPC) امکان آموزش مشترک هوش مصنوعی را بدون افشای داده‌های فردی یا پارامترهای مدل فراهم می‌کند.

---

### C4.17 زیرساخت دانش صفر

سیستم‌های اثبات دانش صفر را برای تایید و احراز هویت هوش مصنوعی با حفظ حریم خصوصی و بدون افشای اطلاعات حساس پیاده‌سازی کنید.

 #4.17.1    سطح: 3    نقش: D/V
 تأیید کنید که اثبات‌های دانش صفر (ZK-SNARKها، ZK-STARKها) صحت مدل هوش مصنوعی و سابقه آموزش را بدون افشای وزن‌های مدل یا داده‌های آموزش بررسی می‌کنند.
 #4.17.2    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های احراز هویت مبتنی بر ZK امکان تأیید هویت کاربران با حفظ حریم خصوصی برای خدمات هوش مصنوعی را بدون افشای اطلاعات مربوط به هویت فراهم می‌کنند.
 #4.17.3    سطح: 3    نقش: D/V
 بررسی کنید که پروتکل‌های اشتراک مجموعه خصوصی (PSI) امکان تطبیق امن داده‌ها در هوش مصنوعی اشتراکی را بدون افشای مجموعه‌های داده فردی فراهم می‌کنند.
 #4.17.4    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های یادگیری ماشین دانش-صفر (ZKML) اعتبار پیش‌بینی‌های هوش مصنوعی را با اثبات رمزنگاری شده از محاسبات صحیح امکان‌پذیر می‌سازند.
 #4.17.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که ZK-rollups پردازش تراکنش‌های هوش مصنوعی مقیاس‌پذیر و حفظ حریم خصوصی را با تأیید دسته‌ای و کاهش سربار محاسباتی فراهم می‌کنند.

---

### C4.18 جلوگیری از حملات کانال جانبی

زیرساخت‌های هوش مصنوعی را در برابر حملات جانبی مبتنی بر زمان‌بندی، توان، الکترومغناطیسی و کش که ممکن است اطلاعات حساس را افشا کنند، محافظت کنید.

 #4.18.1    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که زمان‌بندی استنتاج هوش مصنوعی با استفاده از الگوریتم‌های زمان‌ثابت و پرکردن با داده‌های اضافی نرمال‌سازی شده است تا از حملات استخراج مدل مبتنی بر زمان جلوگیری شود.
 #4.18.2    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که محافظت در برابر تحلیل توان شامل تزریق نویز، فیلتر کردن خطوط توان و الگوهای اجرای تصادفی برای سخت‌افزار هوش مصنوعی است.
 #4.18.3    سطح: 3    نقش: D/V
 تأیید کنید که مقابله با کانال جانبی مبتنی بر کش از تقسیم‌بندی کش، تصادفی‌سازی و دستورات پاک‌سازی برای جلوگیری از نشت اطلاعات استفاده می‌کند.
 #4.18.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که حفاظت در برابر نشر امواج الکترومغناطیسی شامل شیلدینگ، فیلترینگ سیگنال و پردازش تصادفی برای جلوگیری از حملات به سبک TEMPEST می‌باشد.
 #4.18.5    سطح: 3    نقش: D/V
 تأیید کنید که دفاع‌های جانبی میکرومعماری شامل کنترل‌های اجرای گمانه‌زنی شده و ابهام‌سازی الگوهای دسترسی به حافظه هستند.

---

### C4.19 امنیت سخت‌افزار عصبی‌شکل و تخصصی هوش مصنوعی

امن‌سازی معماری‌های سخت‌افزاری نوظهور هوش مصنوعی شامل تراشه‌های نورومورفیک، FPGAها، ASICهای سفارشی و سیستم‌های محاسبات نوری.

 #4.19.1    سطح: 3    نقش: D/V
 تأیید کنید که امنیت چیپ نورومورفیک شامل رمزگذاری الگوهای اسپایک، محافظت از وزن سیناپسی و اعتبارسنجی قوانین یادگیری مبتنی بر سخت‌افزار است.
 #4.19.2    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که شتاب‌دهنده‌های هوش مصنوعی مبتنی بر FPGA از رمزگذاری بیت‌استریم، مکانیزم‌های ضد دستکاری و بارگذاری پیکربندی امن با به‌روزرسانی‌های تأیید شده پشتیبانی می‌کنند.
 #4.19.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که امنیت ASIC سفارشی شامل پردازنده‌های امنیتی روی چیپ، ریشه اعتماد سخت‌افزاری و ذخیره‌سازی کلید ایمن با قابلیت تشخیص دستکاری باشد.
 #4.19.4    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های محاسبات اپتیکی رمزنگاری اپتیکی ایمن کوانتومی، سوئیچینگ فوتونیکی امن، و پردازش سیگنال اپتیکی محافظت‌شده را پیاده‌سازی می‌کنند.
 #4.19.5    سطح: 3    نقش: D/V
 تأیید کنید که چیپ‌های هوش مصنوعی هیبرید آنالوگ-دیجیتال شامل محاسبات امن آنالوگ، ذخیره‌سازی وزن محافظت‌شده و تبدیل آنالوگ به دیجیتال تأییدشده باشند.

---

### زیرساخت محاسباتی حفظ حریم خصوصی C4.20

پیاده‌سازی کنترل‌های زیرساختی برای محاسبات حفظ حریم خصوصی به منظور محافظت از داده‌های حساس در طول پردازش و تحلیل هوش مصنوعی.

 #4.20.1    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که زیرساخت رمزنگاری همومورفیک امکان محاسبات رمزنگاری شده بر روی بارهای کاری حساس هوش مصنوعی را با تأیید یکپارچگی رمزنگاری و نظارت بر عملکرد فراهم می‌کند.
 #4.20.2    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های بازیابی اطلاعات خصوصی امکان اجرای پرس‌وجوهای پایگاه داده را بدون افشای الگوهای پرس‌وجو فراهم می‌کنند، همراه با حفاظت رمزنگاری شده از الگوهای دسترسی.
 #4.20.3    سطح: 3    نقش: D/V
 تأیید کنید که پروتکل‌های محاسبات چندجانبه امن، امکان استنتاج هوش مصنوعی حفظ حریم خصوصی را بدون افشای ورودی‌های فردی یا محاسبات میانی فراهم می‌کنند.
 #4.20.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مدیریت کلید حفظ حریم خصوصی شامل تولید کلید توزیع شده، رمزنگاری آستانه‌ای، و گردش کلید ایمن با محافظت مبتنی بر سخت‌افزار است.
 #4.20.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که عملکرد محاسباتی حفظ حریم خصوصی از طریق دسته‌بندی، ذخیره‌سازی موقت (کش) و شتاب‌دهی سخت‌افزاری بهینه شده است در حالی که تضمین‌های امنیت رمزنگاری حفظ می‌شوند.

---

### امنیت ادغام ابری چارچوب عامل C4.15 و استقرار ترکیبی

کنترل‌های امنیتی برای چارچوب‌های عامل یکپارچه با ابر با معماری‌های ترکیبی محلی/ابر.

 #4.15.1    سطح: 1    نقش: D/V
 تأیید کنید که یکپارچه‌سازی ذخیره‌سازی ابری از رمزگذاری سرتاسر (end-to-end) با مدیریت کلید تحت کنترل عامل استفاده می‌کند.
 #4.15.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مرزهای امنیتی استقرار هیبرید به وضوح تعریف شده‌اند و کانال‌های ارتباطی رمزگذاری شده‌اند.
 #4.15.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که دسترسی به منابع ابری شامل تأیید هویت صفراعتمادی با احراز هویت مستمر است.
 #4.15.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که الزامات محل اقامت داده‌ها با تاییدات رمزنگاری مکان‌های ذخیره‌سازی اعمال می‌شوند.
 #4.15.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که ارزیابی‌های امنیتی ارائه‌دهنده‌ی خدمات ابری شامل مدل‌سازی تهدیدات خاص عامل و ارزیابی ریسک می‌باشد.

---

### مراجع

NIST Cybersecurity Framework 2.0
CIS Controls v8
OWASP Container Security Verification Standard
Kubernetes Security Best Practices
SLSA Supply Chain Security Framework
NIST SP 800-190: Application Container Security Guide
Cloud Security Alliance: Cloud Controls Matrix
ENISA: Secure Infrastructure Design
NIST SP 800-53: Security Controls for Federal Information Systems
ISO 27001:2022 Information Security Management
NIST AI Risk Management Framework
CIS Kubernetes Benchmark
FIPS 140-2 Security Requirements
NIST SP 800-207: Zero Trust Architecture
IEEE 2857: Privacy Engineering for AI Systems
NIST SP 800-161: Cybersecurity Supply Chain Risk Management
NIST Post-Quantum Cryptography Standards
Intel SGX Developer Guide
AMD SEV-SNP White Paper
ARM TrustZone Technology
ZK-SNARKs: A Gentle Introduction
NIST SP 800-57: Cryptographic Key Management
Side-Channel Attack Countermeasures
Neuromorphic Computing Security Challenges
FPGA Security: Fundamentals, Evaluation, and Countermeasures
Microsoft SEAL: Homomorphic Encryption Library
HElib: Homomorphic Encryption Library
PALISADE Lattice Cryptography Library
Differential Privacy: A Survey of Results
Secure Aggregation for Federated Learning
Private Information Retrieval: Concepts and Constructions

## کنترل دسترسی C5 و هویت برای مولفه‌ها و کاربران هوش مصنوعی

### هدف کنترل

کنترل دسترسی مؤثر برای سیستم‌های هوش مصنوعی نیازمند مدیریت هویت قوی، مجوزدهی آگاه به زمینه و اجرای در زمان اجرا بر اساس اصول اعتماد صفر است. این کنترل‌ها اطمینان می‌دهند که انسان‌ها، سرویس‌ها و عوامل خودران تنها در محدوده‌های صریحاً اعطا شده با مدل‌ها، داده‌ها و منابع محاسباتی تعامل دارند، همراه با قابلیت‌های تأیید و حسابرسی مداوم.

---

### C5.1 مدیریت هویت و احراز هویت

ایجاد هویت‌های مبتنی بر رمزنگاری برای تمام موجودیت‌ها با استفاده از احراز هویت چندعاملی برای عملیات دارای امتیاز ویژه.

 #5.1.1    سطح: 1    نقش: D/V
 تأیید کنید که همه کاربران انسانی و اصول سرویس از طریق یک ارائه‌دهنده هویت سازمانی متمرکز (IdP) با استفاده از پروتکل‌های OIDC/SAML احراز هویت می‌کنند، به طوری که نگاشت‌های منحصر به فرد هویت به توکن وجود داشته باشد (هیچ حساب یا مدرک مشترکی وجود نداشته باشد).
 #5.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که عملیات پرخطر (استقرار مدل، صادرات وزن، دسترسی به داده‌های آموزش، تغییرات پیکربندی تولید) نیازمند احراز هویت چندمرحله‌ای یا احراز هویت افزایش سطح با اعتبارسنجی مجدد جلسه باشد.
 #5.1.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که مدیران جدید قبل از دریافت دسترسی به سیستم تولید، فرآیند اثبات هویت را بر اساس استانداردهای NIST 800-63-3 IAL-2 یا معادل آن انجام دهند.
 #5.1.4    سطح: 2    نقش: V
 تأیید کنید که مرورهای دسترسی به صورت فصلی انجام می‌شود و شامل تشخیص خودکار حساب‌های غیرفعال، اعمال چرخش اطلاعات اعتباری، و جریان‌های کاری حذف دسترسی است.
 #5.1.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که عامل‌های هوش مصنوعی فدرال از طریق اثبات‌های JWT امضا شده که حداکثر طول عمر 24 ساعت دارند و شامل اثبات رمزنگاری شده منبع هستند، احراز هویت می‌شوند.

---

### C5.2 مجوز دسترسی به منابع و حداقل امتیاز

اجرای کنترل دسترسی دقیق برای تمامی منابع هوش مصنوعی با مدل‌های اجازه صریح و سوابق بازرسی.

 #5.2.1    سطح: 1    نقش: D/V
 تأیید کنید که هر منبع هوش مصنوعی (مجموعه داده‌ها، مدل‌ها، نقاط انتهایی، مجموعه‌های برداری، شاخص‌های جاسازی، نمونه‌های محاسباتی) کنترل‌های دسترسی مبتنی بر نقش را با فهرست‌های صریح مجاز و سیاست‌های پیش‌فرض عدم اجازه اعمال می‌کند.
 #5.2.2    سطح: 1    نقش: D/V
 تأیید کنید که اصول کمترین سطح دسترسی به طور پیش‌فرض برای حساب‌های سرویس اعمال می‌شود، به طوری که دسترسی‌ها از سطح فقط خواندنی شروع شده و برای دسترسی نوشتن، توجیه تجاری مستند شده لازم است.
 #5.2.3    سطح: 1    نقش: V
 تأیید کنید که تمام تغییرات کنترل دسترسی به درخواست‌های تغییر تأیید شده مرتبط هستند و به صورت غیرقابل تغییر با زمان‌بندی‌ها، هویت‌های عامل، شناسه‌های منابع و تغییرات مجوزها ثبت شده‌اند.
 #5.2.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که برچسب‌های طبقه‌بندی داده‌ها (PII، PHI، تحت کنترل صادرات، مالکیتی) به صورت خودکار به منابع مشتق شده (تعبیه‌ها، حافظه‌های کش درخواست‌ها، خروجی‌های مدل) منتقل شده و با اجرای سیاست‌های یکسان اعمال می‌شوند.
 #5.2.5    سطح: 2    نقش: D/V
 تأیید کنید که تلاش‌های دسترسی غیرمجاز و رویدادهای افزایش سطح دسترسی، هشدارهای بلادرنگ با فراداده متنی مربوطه را در عرض 5 دقیقه به سیستم‌های SIEM ارسال می‌کنند.

---

### C5.3 ارزیابی خط‌مشی پویا

استقرار موتورهای کنترل دسترسی مبتنی بر ویژگی (ABAC) برای تصمیم‌گیری‌های مجوزدهی آگاه از زمینه همراه با قابلیت‌های حسابرسی.

 #5.3.1    سطح: 1    نقش: D/V
 تأیید کنید که تصمیمات مجوزدهی به یک موتور سیاست اختصاصی (مانند OPA، Cedar یا معادل آن) که از طریق APIهای احراز هویت شده و با حفاظت یکپارچگی رمزنگاری شده قابل دسترسی است، منتقل شده‌اند.
 #5.3.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیاست‌ها ویژگی‌های پویا را در زمان اجرا ارزیابی می‌کنند، از جمله سطح دسترسی کاربر، طبقه‌بندی حساسیت منبع، زمینه درخواست، جداسازی مستاجران و محدودیت‌های زمانی.
 #5.3.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که تعاریف سیاست‌ها تحت کنترل نسخه، بازبینی شده توسط هم‌رده‌ها و از طریق تست‌های خودکار در خطوط CI/CD قبل از استقرار در تولید، معتبر شده‌اند.
 #5.3.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که نتایج ارزیابی سیاست شامل دلایل تصمیم‌گیری ساختاریافته هستند و برای تجزیه و تحلیل همبستگی و گزارش‌دهی انطباق به سیستم‌های SIEM ارسال می‌شوند.
 #5.3.5    سطح: 3    نقش: D/V
 تأیید کنید که مقادیر زمان زندگی کش سیاست (TTL) برای منابع با حساسیت بالا بیش از 5 دقیقه و برای منابع استاندارد با قابلیت ابطال کش بیش از 1 ساعت نشود.

---

### C5.4 اعمال امنیت در زمان پرس‌وجو

اجرای کنترل‌های امنیتی لایه پایگاه داده با فیلترینگ اجباری و سیاست‌های امنیت سطح ردیف.

 #5.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام کوئری‌های پایگاه داده برداری و SQL شامل فیلترهای امنیتی اجباری (شناسه مستاجر، برچسب‌های حساسیت، دامنه کاربر) باشند که در سطح موتور پایگاه داده اعمال می‌شوند و نه در کد برنامه.
 #5.4.2    سطح: 1    نقش: D/V
 تأیید کنید که سیاست‌های امنیت سطح ردیف (RLS) و ماسک‌گذاری سطح فیلد با ارث‌بری سیاست برای تمامی پایگاه‌های داده برداری، شاخص‌های جستجو و داده‌های آموزشی فعال شده‌اند.
 #5.4.3    سطح: 2    نقش: D
 تأیید کنید که ارزیابی‌های مجوز ناموفق از «حملات معاون سردرگم» جلوگیری می‌کنند با اینکه به محض مواجهه با این وضعیت، پرس‌وجوها را فوراً متوقف کرده و کدهای خطای مجوز صریح را بازمی‌گردانند، به جای بازگرداندن مجموعه نتایج خالی.
 #5.4.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که تاخیر در ارزیابی سیاست به طور مداوم با هشدارهای خودکار برای شرایط تایم اوت که ممکن است باعث عبور غیرمجاز از مجوز شود، تحت نظارت قرار دارد.
 #5.4.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های تلاش مجدد پرس‌وجو (query retry) سیاست‌های مجوزدهی را مجدداً ارزیابی می‌کنند تا تغییرات پویا در دسترسی‌ها در طول جلسات فعال کاربر در نظر گرفته شود.

---

### فیلتر خروجی C5.5 و پیشگیری از از دست دادن داده‌ها

استقرار کنترل‌های پس‌پردازش برای جلوگیری از افشای داده‌های غیرمجاز در محتوای تولیدشده توسط هوش مصنوعی.

 #5.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های فیلترینگ پس از استنتاج، اطلاعات شناسایی شخصی غیرمجاز، اطلاعات طبقه‌بندی‌شده و داده‌های مالکیتی را قبل از ارائه محتوا به درخواست‌کنندگان، اسکن و حذف می‌کنند.
 #5.5.2    سطح: 1    نقش: D/V
 تأیید کنید که ارجاعات، مآخذ و نسبت‌دهی منابع در خروجی‌های مدل مطابق با مجوزهای فراخواننده بررسی شده و در صورت تشخیص دسترسی غیرمجاز حذف شوند.
 #5.5.3    سطح: 2    نقش: D
 تأیید کنید که محدودیت‌های فرمت خروجی (PDFهای تصفیه‌شده، تصاویر فاقد فراداده، انواع فایل‌های تأییدشده) بر اساس سطوح دسترسی کاربران و رده‌بندی داده‌ها اعمال می‌شوند.
 #5.5.4    سطح: 2    نقش: V
 تأیید کنید که الگوریتم‌های پوشش اطلاعات به صورت قطعی، کنترل نسخه شده و دارای گزارش‌های ممیزی برای پشتیبانی از تحقیقات انطباق و تحلیل‌های جنایی باشند.
 #5.5.5    سطح: 3    نقش: V
 تأیید کنید که رویدادهای حذف اطلاعات با ریسک بالا، لاگ‌های تطبیقی تولید می‌کنند که شامل هش‌های رمزنگاری شده از محتوای اصلی برای بازیابی جرم‌شناسی بدون افشای داده‌ها هستند.

---

### C5.6 ایزولاسیون چند مستاجری

اطمینان از جداسازی رمزنگاری و منطقی بین مستاجران در زیرساخت مشترک هوش مصنوعی.

 #5.6.1    سطح: 1    نقش: D/V
 تأیید کنید که فضاهای حافظه، ذخیره‌گاه‌های تعبیه‌شده، ورودی‌های کش و فایل‌های موقت به‌صورت جداشده بر اساس فضای نام هر مستأجر نگهداری شده و پس از حذف مستأجر یا خاتمه جلسه به‌صورت ایمن پاک‌سازی می‌شوند.
 #5.6.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر درخواست API شامل یک شناسه مستأجر احراز هویت شده باشد که به‌طور رمزنگاری شده در برابر زمینه نشست و مجوزهای کاربر اعتبارسنجی شده است.
 #5.6.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که سیاست‌های شبکه قوانین پیش‌فرض-رد را برای ارتباط بین مستاجرها در درون سرویس مش‌ها و پلتفرم‌های ارکستراسیون کانتینرها اعمال می‌کنند.
 #5.6.4    سطح: 3    نقش: D
 تأیید کنید که کلیدهای رمزنگاری برای هر مستأجر منحصر به فرد هستند و از کلید مدیریت شده توسط مشتری (CMK) پشتیبانی می‌شود و ایزولاسیون رمزنگاری بین مخازن داده‌های مستأجران وجود دارد.

---

### C5.7 مجوز عامل خودمختار

کنترل مجوزها برای عامل‌های هوش مصنوعی و سیستم‌های خودکار از طریق توکن‌های قابلیت محدود شده و تأیید مداوم.

 #5.7.1    سطح: 1    نقش: D/V
 تأیید کنید که عامل‌های خودکار توکن‌های قابلیت محدوده‌دار دریافت می‌کنند که به‌صراحت اقدامات مجاز، منابع قابل دسترسی، محدودیت‌های زمانی و محدودیت‌های عملیاتی را فهرست می‌کنند.
 #5.7.2    سطح: 1    نقش: D/V
 تأیید کنید که قابلیت‌های پرریسک (دسترسی به سیستم فایل، اجرای کد، تماس با APIهای خارجی، تراکنش‌های مالی) به‌طور پیش‌فرض غیرفعال بوده و برای فعال‌سازی نیاز به مجوزهای صریح همراه با توجیهات کسب‌وکاری دارند.
 #5.7.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که توکن‌های قابلیت به نشست‌های کاربری متصل شده‌اند، شامل حفاظت از صحت رمزنگاری هستند و تضمین کنید که نمی‌توان آن‌ها را در سناریوهای آفلاین ذخیره یا مجدداً استفاده کرد.
 #5.7.4    سطح: 2    نقش: V
 تأیید کنید که اقدامات آغاز شده توسط عامل، از طریق موتور سیاست ABAC با ارزیابی کامل زمینه و ثبت گزارش بازبینی، مورد تایید ثانویه قرار می‌گیرند.
 #5.7.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که شرایط خطاهای عامل و مدیریت استثناها شامل اطلاعات حوزه قابلیت‌ها باشد تا از تحلیل حادثه و تحقیقات جنایی پشتیبانی کند.

---

### مراجع

#### استانداردها و چهارچوب‌ها

NIST SP 800-63-3: Digital Identity Guidelines
Zero Trust Architecture – NIST SP 800-207
OWASP Application Security Verification Standard (AISVS)
​
#### راهنمای پیاده‌سازی

Identity and Access Management in the AI Era: 2025 Guide – IDSA
Attribute-Based Access Control with OPA – Permify
How We Designed Cedar to Be Intuitive, Fast, and Safe – AWS
​
#### امنیت خاص هوش مصنوعی

Row Level Security in Vector DBs for RAG – Bluetuple.ai
Tenant Isolation in Multi-Tenant Systems – WorkOS
Handling AI Agent Permissions – Stytch
OWASP Top 10 for Large Language Model Applications

## امنیت زنجیره تامین C6 برای مدل‌ها، چارچوب‌ها و داده‌ها

### هدف کنترل

حملات زنجیره تأمین هوش مصنوعی از مدل‌ها، چارچوب‌ها یا مجموعه‌داده‌های شخص ثالث سوءاستفاده می‌کنند تا درهای پشتی، تعصب یا کد قابل بهره‌برداری را جاسازی کنند. این کنترل‌ها ردیابی جامع، مدیریت آسیب‌پذیری و نظارت را برای محافظت از کل چرخه عمر مدل فراهم می‌کنند.

---

### C6.1 بررسی مدل‌های از پیش آموزش‌دیده و منشأ آنها

اصالت و منبع مدل‌های شخص ثالث، مجوزها و رفتارهای پنهان آن‌ها را پیش از هر گونه تنظیم دقیق یا استقرار ارزیابی و تأیید کنید.

 #6.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر اثر مدل شخص ثالث شامل یک رکورد منشاء امضاء شده باشد که مخزن منبع و هش کامیت را مشخص می‌کند.
 #6.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مدل‌ها با استفاده از ابزارهای خودکار قبل از وارد کردن، برای لایه‌های مخرب یا محرک‌های تروجان اسکن شده‌اند.
 #6.1.3    سطح: 2    نقش: D
 تأیید کنید که ریزتنظیم‌های یادگیری انتقالی از ارزیابی مقابله‌ای عبور می‌کنند تا رفتارهای پنهان را شناسایی کنند.
 #6.1.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که مجوزهای مدل، برچسب‌های کنترل صادرات، و بیانیه‌های منشأ داده در یک ورودی ML‑BOM ثبت شده‌اند.
 #6.1.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مدل‌های پرخطر (وزن‌های بارگذاری شده به‌صورت عمومی، سازندگان تأییدنشده) تا زمان بازبینی و تایید انسانی قرنطینه باقی بمانند.

---

### C6.2 اسکن چارچوب و کتابخانه

مداوم فریم‌ورک‌ها و کتابخانه‌های یادگیری ماشین را برای CVEها و کدهای مخرب اسکن کنید تا پشته زمان اجرا ایمن بماند.

 #6.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که خطوط لوله CI اسکنرهای وابستگی را بر روی چارچوب‌های هوش مصنوعی و کتابخانه‌های حیاتی اجرا می‌کنند.
 #6.2.2    سطح: 1    نقش: D/V
 تأیید کنید که آسیب‌پذیری‌های بحرانی (CVSS ≥ 7.0) باعث جلوگیری از ترفیع به تصاویر تولید می‌شوند.
 #6.2.3    سطح: 2    نقش: D
 تأیید کنید که تجزیه و تحلیل کد ایستا بر روی کتابخانه‌های یادگیری ماشین منشعب شده یا واگذار شده اجرا می‌شود.
 #6.2.4    سطح: 2    نقش: V
 تأیید کنید که پیشنهادهای ارتقاء چهارچوب شامل ارزیابی تاثیر امنیتی با ارجاع به منابع عمومی CVE باشد.
 #6.2.5    سطح: 3    نقش: V
 تأیید کنید که حسگرهای زمان اجرا در بارگذاری‌های غیرمنتظره کتابخانه‌های پویا که از SBOM امضا شده منحرف می‌شوند، هشدار می‌دهند.

---

### C6.3 ثابت نگه داشتن و تایید وابستگی‌ها

تمام وابستگی‌ها را به صورت گسسته و غیرقابل تغییر پین کنید و بازتولیدهای ساخت را انجام دهید تا آثار کاملاً مشابه و بدون دستکاری تضمین شود.

 #6.3.1    سطح: 1    نقش: D/V
 بررسی کنید که آیا همه مدیران بسته‌ها اعمال پین‌کردن نسخه را از طریق فایل‌های قفل اجرا می‌کنند.
 #6.3.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که در ارجاعات کانتینر از خلاصه‌های غیرقابل تغییر به جای برچسب‌های قابل تغییر استفاده شده است.
 #6.3.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که بررسی‌های ساخت بازتولیدپذیر، هش‌ها را در اجراهای CI مقایسه می‌کنند تا خروجی‌های یکسان تضمین شود.
 #6.3.4    سطح: 2    نقش: V
 تأیید کنید که تصدیق‌های ساخت به مدت 18 ماه برای قابلیت ردیابی حسابرسی ذخیره می‌شوند.
 #6.3.5    سطح: 3    نقش: D
 تأیید کنید که وابستگی‌های منقضی شده باعث ایجاد درخواست‌های خودکار برای به‌روزرسانی یا انشعاب نسخه‌های پین‌شده می‌شوند.

---

### C6.4 اجرای منبع مورد اعتماد

دانلود آثار فقط از منابع تأییدشده رمزنگاری شده و سازمانی مجاز را مجاز کنید و بقیه را مسدود کنید.

 #6.4.1    سطح: 1    نقش: D/V
 تأیید کنید که وزن‌های مدل، مجموعه داده‌ها و کانتینرها تنها از دامنه‌های تایید شده یا رجیستری‌های داخلی دانلود شوند.
 #6.4.2    سطح: 1    نقش: D/V
 تأیید کنید که امضاهای Sigstore/Cosign هویت ناشر را قبل از اینکه آثار به صورت محلی کش شوند، اعتبارسنجی می‌کنند.
 #6.4.3    سطح: 2    نقش: D
 تأیید کنید که پراکسی‌های خروجی دانلودهای بدون تأیید هویت شده‌ی آثار را مسدود می‌کنند تا سیاست منبع مورد اعتماد را اعمال کنند.
 #6.4.4    سطح: 2    نقش: V
 تأیید کنید که فهرست‌های مجاز مخزن به صورت سه‌ماهه بازبینی می‌شوند و برای هر ورودی دلیل کسب‌وکاری قابل اثبات وجود دارد.
 #6.4.5    سطح: 3    نقش: V
 تأیید کنید که نقض سیاست‌ها باعث قرنطینه شدن آثار و بازگردانی اجرای خطوط لوله وابسته می‌شود.

---

### C6.5 ارزیابی ریسک مجموعه داده‌های شخص ثالث

داده‌های خارجی را از نظر آلودگی، تعصب و تطابق قانونی ارزیابی کرده و در طول چرخه عمر آن‌ها را پایش کنید.

 #6.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که داده‌های مجموعه‌های خارجی تحت امتیازدهی ریسک مسمومیت قرار می‌گیرند (برای مثال، اثرانگشت داده، تشخیص نقاط دورافتاده).
 #6.5.2    سطح: 1    نقش: D
 تأیید کنید که معیارهای تبعیض (تساوی جمعیتی، فرصت برابر) قبل از تأیید مجموعه داده محاسبه شده‌اند.
 #6.5.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که منبع و شرایط مجوز داده‌ها در ورودی‌های ML‑BOM ثبت شده‌اند.
 #6.5.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که پایش دوره‌ای تغییر یا فساد در داده‌های میزبانی شده را تشخیص می‌دهد.
 #6.5.5    سطح: 3    نقش: D
 اطمینان حاصل کنید که محتوای غیرمجاز (حق نشر، اطلاعات شخصی شناسایی‌پذیر) از طریق پاک‌سازی خودکار قبل از آموزش حذف شده باشد.

---

### C6.6 نظارت بر حمله به زنجیره تامین

تهدیدات زنجیره تامین را از طریق فیدهای CVE، تحلیل‌های لاگ‌های حسابرسی و شبیه‌سازی‌های تیم قرمز زودهنگام شناسایی کنید.

 #6.6.1    سطح: 1    نقش: V
 تأیید کنید که لاگ‌های ممیزی CI/CD به جریان کشف‌های SIEM برای کشش‌های بسته غیرمعمول یا مراحل ساخت دستکاری شده منتقل می‌شوند.
 #6.6.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که کتاب‌های راهنمای واکنش به حادثه شامل روش‌های بازگردانی برای مدل‌ها یا کتابخانه‌های آسیب‌دیده هستند.
 #6.6.3    سطح: 3    نقش: V
 اعتبارسنجی کنید که تگ‌های غنی‌سازی اطلاعات تهدید، شاخص‌های اختصاصی یادگیری ماشینی (برای مثال، IoCهای مربوط به مسموم‌سازی مدل) را در فرآیند سه‌مرحله‌ای هشدارها علامت‌گذاری می‌کنند.

---

### C6.7 لیست مواد ماشین لرنینگ (ML-BOM) برای مصنوعات مدل

تولید و امضای SBOMهای خاص یادگیری ماشین (ML-BOMها) به‌صورت دقیق تا مصرف‌کنندگان پایین‌دست بتوانند صحت اجزا را در زمان استقرار تأیید کنند.

 #6.7.1    سطح: 1    نقش: D/V
 تأیید کنید که هر نمونه مدل یک ML‑BOM منتشر می‌کند که شامل مجموعه داده‌ها، وزن‌ها، ابرپارامترها و مجوزها باشد.
 #6.7.2    سطح: 1    نقش: D/V
 تأیید کنید که تولید ML‑BOM و امضای Cosign در فرآیند CI خودکار شده و برای ادغام الزامی است.
 #6.7.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که بررسی‌های کامل بودن ML‑BOM در صورت فقدان هر گونه متاداده مؤلفه (هش، مجوز) فرآیند ساخت را متوقف می‌کنند.
 #6.7.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که مصرف‌کنندگان پایین‌دستی می‌توانند از طریق API به ML-BOMها پرس‌وجو کنند تا مدل‌های وارد شده را در زمان استقرار اعتبارسنجی کنند.
 #6.7.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که ML-BOMها تحت نسخه کنترل قرار دارند و تفاوت‌های آن‌ها بررسی می‌شود تا تغییرات غیرمجاز شناسایی شود.

---

### مراجع

ML Supply Chain Compromise – MITRE ATLAS
Supply‑chain Levels for Software Artifacts (SLSA)
CycloneDX – Machine Learning Bill of Materials
What is Data Poisoning? – SentinelOne
Transfer Learning Attack – OWASP ML Security Top 10
AI Data Security Best Practices – CISA
Secure CI/CD Supply Chain – Sumo Logic
AI & Transparency: Protect ML Models – ReversingLabs
SBOM Overview – CISA
Training Data Poisoning Guide – Lakera.ai
Dependency Pinning for Reproducible Python – Medium

## رفتار مدل C7، کنترل خروجی و تضمین ایمنی

### هدف کنترل

خروجی‌های مدل باید ساختارمند، قابل اعتماد، ایمن، قابل توضیح و به‌طور مداوم در محیط تولید نظارت شده باشند. انجام این کار موجب کاهش توهمات، نفوذهای حریم خصوصی، محتوای مضر و اقدامات کنترل‌نشده می‌شود و همزمان اعتماد کاربران و انطباق با مقررات را افزایش می‌دهد.

---

### C7.1 اجرای قالب خروجی

طرح‌های ساختاری سختگیرانه، رمزگشایی محدود شده و اعتبارسنجی پس‌زمینه باعث جلوگیری از انتشار محتوای نادرست یا مخرب می‌شوند.

 #7.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که طرح‌های پاسخ (مثلاً JSON Schema) در فرمان سیستمی ارائه شده‌اند و هر خروجی به‌طور خودکار اعتبارسنجی می‌شود؛ خروجی‌های ناسازگار موجب تعمیر یا رد شدن می‌شوند.
 #7.1.2    سطح: 1    نقش: D/V
 تأیید کنید که رمزگشایی محدود شده (توقف توکن‌ها، عبارات منظم، حداکثر توکن‌ها) فعال باشد تا از سرریز یا کانال‌های جانبی تزریق ورودی جلوگیری شود.
 #7.1.3    سطح: 2    نقش: D/V
 تأیید کنید که مؤلفه‌های پایین‌دست خروجی‌ها را به‌عنوان داده‌های غیرقابل اعتماد در نظر می‌گیرند و آن‌ها را در برابر شِماها یا دِسریالایزرهای ایمن در برابر تزریق اعتبارسنجی می‌کنند.
 #7.1.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که رویدادهای خروجی نادرست ثبت، محدودیت نرخ اعمال شده و به نظارت ارائه می‌شوند.

---

### C7.2 تشخیص و کاهش هذیان

برآورد عدم قطعیت و استراتژی‌های جایگزین پاسخ‌های ساختگی را محدود می‌کنند.

 #7.2.1    سطح: 1    نقش: D/V
 تأیید کنید که احتمال‌های لگاریتمی در سطح توکن، انسجام خود مجموعه‌ای، یا آشکارسازهای تجربه‌ی دقیق تنظیم‌شده، امتیاز اطمینان را به هر پاسخ اختصاص می‌دهند.
 #7.2.2    سطح: 1    نقش: D/V
 تأیید کنید که پاسخ‌های زیر آستانه اطمینان قابل تنظیم، فرآیندهای جایگزین (مانند تولید تقویت‌شده با بازیابی، مدل ثانویه، یا بازبینی انسانی) را فعال می‌کنند.
 #7.2.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که حوادث توهم با فراداده علت اصلی برچسب‌گذاری شده و به خطوط لوله پس از رخداد و تنظیم دقیق داده می‌شوند.
 #7.2.4    سطح: 3    نقش: D/V
 تأیید کنید که آستانه‌ها و آشکارسازها پس از به‌روزرسانی‌های عمده مدل یا پایگاه دانش دوباره کالیبره شده باشند.
 #7.2.5    سطح: 3    نقش: V
 تأیید کنید که تجسم‌های داشبورد نرخ‌های توهم زایی را رهگیری می‌کنند.

---

### C7.3 فیلتر کردن ایمنی و حفظ حریم خصوصی خروجی

فیلترهای سیاستی و پوشش تیم قرمز از کاربران و داده‌های محرمانه محافظت می‌کنند.

 #7.3.1    سطح: 1    نقش: D/V
 تأیید کنید که دسته‌بندهای قبل و بعد از تولید، محتوای نفرت‌انگیز، آزاردهنده، خودآزار، افراطی و محتوای جنسی صریح را که با سیاست همسو است، مسدود می‌کنند.
 #7.3.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که شناسایی PII/PCI و حذف خودکار در هر پاسخ اجرا می‌شود؛ تخلفات منجر به ایجاد حادثه حفظ حریم خصوصی می‌گردد.
 #7.3.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که برچسب‌های محرمانگی (مانند اسرار تجاری) در تمامی حالت‌ها منتقل می‌شوند تا از نشت اطلاعات در متن، تصاویر یا کد جلوگیری شود.
 #7.3.4    سطح: 3    نقش: D/V
 تأیید کنید که تلاش‌های عبور از فیلتر یا طبقه‌بندی‌های پرخطر نیاز به تأیید ثانویه یا احراز هویت مجدد کاربر دارند.
 #7.3.5    سطح: 3    نقش: D/V
 تأیید کنید که آستانه‌های فیلتر کردن منعکس‌کننده حوزه‌های قضایی قانونی و زمینه سُنی/نقش کاربر باشند.

---

### C7.4 محدودسازی خروجی و اقدام

محدودیت‌های نرخ و دروازه‌های تأیید از سوء استفاده و خودمختاری بیش از حد جلوگیری می‌کنند.

 #7.4.1    سطح: 1    نقش: D
 تأیید کنید که سهمیه‌های هر کاربر و هر کلید API درخواست‌ها، توکن‌ها و هزینه‌ها را با استفاده از روش عقب‌نشینی نمایی در مواجهه با خطاهای 429 محدود می‌کنند.
 #7.4.2    سطح: 1    نقش: D/V
 تأیید کنید که اقدامات ویژه (نوشتن فایل، اجرای کد، تماس‌های شبکه) نیازمند تأیید مبتنی بر سیاست یا دخالت انسانی هستند.
 #7.4.3    سطح: 2    نقش: D/V
 تأیید کنید که بررسی‌های هم‌سویی بین حالت‌ها (cross-modal consistency checks) اطمینان حاصل می‌کنند که تصاویر، کد و متن تولید شده برای یک درخواست مشابه، نمی‌توانند برای قاچاق محتوای مخرب استفاده شوند.
 #7.4.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که عمق واگذاری نماینده، محدودیت‌های بازگشتی، و فهرست ابزارهای مجاز به صورت صریح پیکربندی شده‌اند.
 #7.4.5    سطح: 3    نقش: V
 تأیید کنید که نقض محدودیت‌ها رویدادهای امنیتی ساخت‌یافته برای جذب در SIEM صادر می‌کند.

---

### C7.5 قابلیت توضیح خروجی

سیگنال‌های شفاف به بهبود اعتماد کاربران و اشکال‌زدایی داخلی کمک می‌کنند.

 #7.5.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که امتیازات اطمینان نمایش داده شده برای کاربر یا خلاصه‌های کوتاه استدلال زمانی که ارزیابی ریسک مناسب تشخیص داده می‌شود، نمایش داده می‌شوند.
 #7.5.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که توضیحات تولید شده از افشای دستورات حساس سیستم یا داده‌های اختصاصی جلوگیری می‌کنند.
 #7.5.3    سطح: 3    نقش: D
 اطمینان حاصل کنید که سیستم احتمال‌های لگاریتمی در سطح توکن یا نقشه‌های توجه را ضبط کرده و آن‌ها را برای بازرسی مجاز ذخیره می‌کند.
 #7.5.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که آثار توضیح‌پذیری به همراه نسخه‌های مدل برای قابلیت حسابرسی تحت کنترل نسخه قرار دارند.

---

### C7.6 یکپارچه‌سازی نظارت

قابلیت مشاهده در زمان واقعی حلقه ارتباط بین توسعه و تولید را می‌بندد.

 #7.6.1    سطح: 1    نقش: D
 تأیید کنید که معیارها (نقض‌های طرح، نرخ هالوسینیشن، سمیت، نشت اطلاعات شناسایی شخصی، تأخیر، هزینه) به یک پلتفرم مرکزی نظارتی ارسال می‌شوند.
 #7.6.2    سطح: 1    نقش: V
 تأیید کنید که آستانه‌های هشدار برای هر معیار ایمنی تعریف شده‌اند و مسیرهای ارتقاء برای تماس در دسترس قرار گرفته‌اند.
 #7.6.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که داشبوردها ناهنجاری‌های خروجی را با مدل/نسخه، پرچم ویژگی و تغییرات داده‌های بالادستی مرتبط می‌کنند.
 #7.6.4    سطح: 2    نقش: D/V
 تأیید کنید که داده‌های مانیتورینگ به بازآموزی، تنظیم دقیق یا به‌روزرسانی قوانین درون یک جریان کاری مستند MLOps بازمی‌گردند.
 #7.6.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که پایپلاین‌های نظارتی تحت آزمایش نفوذ قرار گرفته و کنترل دسترسی شده‌اند تا از نشت گزارش‌های حساس جلوگیری شود.

---

### 7.7 تدابیر حفاظتی رسانه‌های مولد

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی محتوای رسانه‌ای غیرقانونی، مضر یا غیرمجاز تولید نکنند، از طریق اعمال محدودیت‌های سیاستی، اعتبارسنجی خروجی و قابلیت ردیابی.

 #7.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که دستورات سیستم و راهنمایی‌های کاربر صراحتاً تولید رسانه‌های دیپ‌فیک غیرقانونی، مضر یا بدون رضایت (مانند تصویر، ویدیو، صدا) را ممنوع می‌دانند.
 #7.7.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که درخواست‌ها برای تلاش در تولید جعل هویت، دیپ‌فیک‌های جنسی صریح، یا رسانه‌هایی که افراد واقعی را بدون رضایت نشان می‌دهند، فیلتر می‌شوند.
 #7.7.3    سطح: 2    نقش: V
 تأیید کنید که سیستم از هش درک‌شده، تشخیص علامت آبی، یا اثرانگشت دیجیتال برای جلوگیری از بازتولید غیرمجاز رسانه‌های دارای حق نشر استفاده می‌کند.
 #7.7.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تمام رسانه‌های تولید شده رمزنگاری شده، دارای واترمارک یا شامل فراداده‌های منشأ مقاوم در برابر دستکاری برای قابلیت ردیابی در مراحل بعدی باشند.
 #7.7.5    سطح: 3    نقش: V
 تأیید کنید که تلاش‌های دورزدن (مثلاً مبهم‌سازی فرمان، زبان عامیانه، بیان معارض) شناسایی، ثبت لاگ، و محدودیت نرخ اعمال می‌شوند؛ سوءاستفاده مکرر به سیستم‌های نظارتی گزارش داده می‌شود.

### مراجع

NIST AI Risk Management Framework
ISO/IEC 42001:2023 – AI Management System
OWASP Top-10 for Large Language Model Applications (2025)
Improper Output Handling – OWASP LLM05:2025
Practical Techniques to Constrain LLM Output
Dataiku – Structured Text Generation Guide
VL-Uncertainty: Detecting Hallucinations
HaDeMiF: Hallucination Detection & Mitigation
Building Confidence in LLM Outputs
Explainable AI & LLMs
LLM Red-Teaming Guide
Sensitive Information Disclosure in LLMs
LangChain – Chat Model Rate Limiting
OpenAI Rate-Limit & Exponential Back-off
Arize AI – LLM Observability Platform

## امنیت حافظه C8، تعبیه‌ها و پایگاه داده‌های برداری

### هدف کنترل

تعبیه‌ها و فروشگاه‌های برداری به عنوان "حافظه زنده" سیستم‌های هوش مصنوعی معاصر عمل می‌کنند که به طور مداوم داده‌های ارائه شده توسط کاربر را می‌پذیرند و آن‌ها را از طریق تولید تقویت‌شده با بازیابی (RAG) به بستر مدل بازمی‌گردانند. اگر این حافظه بدون کنترل رها شود، ممکن است اطلاعات شناسایی شخصی (PII) نشت کند، رضایت نقض شود یا بتواند برای بازسازی متن اصلی معکوس شود. هدف این خانواده کنترل، سخت‌کردن خط‌های لوله حافظه و پایگاه‌های داده برداری است به طوری که دسترسی با حداقل امتیاز باشد، تعبیه‌ها حفظ حریم خصوصی را تضمین کنند، بردارهای ذخیره‌شده منقضی شوند یا در صورت درخواست قابل لغو باشند، و حافظه کاربر به صورت جداگانه از داده‌های دیگر کاربران محافظت شود تا هیچ آلودگی در پرسش‌ها یا تکمیل‌های دیگر کاربران رخ ندهد.

---

### C8.1 کنترل‌های دسترسی بر حافظه و نمایه‌های RAG

اجرای کنترل‌های دسترسی دقیق و جزئی بر روی هر مجموعه برداری.

 #8.1.1    سطح: 1    نقش: D/V
 تأیید کنید که قوانین کنترل دسترسی در سطح ردیف/فضای نام، عملیات درج، حذف و پرس‌وجو را بر اساس مستاجر، مجموعه یا برچسب سند محدود می‌کنند.
 #8.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که کلیدهای API یا JWT دارای ادعاهای محدوده‌دار (مانند شناسه‌های مجموعه، افعال عملیاتی) هستند و حداقل هر سه ماه یکبار تعویض می‌شوند.
 #8.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تلاش‌های افزایش دسترسی (مثلاً پرس‌وجوهای مشابهت در فضای نام‌های مختلف) طی ۵ دقیقه شناسایی و در یک سیستم مدیریت اطلاعات و رویدادهای امنیتی (SIEM) ثبت شوند.
 #8.1.4    سطح: 2    نقش: D/V
 بررسی کنید که پایگاه داده برداری (vector DB) سوابق ممیزی شامل شناسه موضوع، عملیات، شناسه/نام فضای بردار، آستانه شباهت، و تعداد نتایج را ثبت کند.
 #8.1.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که تصمیمات دسترسی به منظور بررسی نقص‌های عبور (bypass flaws) هر زمان که موتور‌ها به‌روزرسانی می‌شوند یا قوانین تقسیم‌بندی ایندکس تغییر می‌کنند، آزمایش می‌شوند.

---

### C8.2 پاکسازی و اعتبارسنجی جاسازی‌ها

متن را قبل از بردارسازی برای اطلاعات شناسایی شخصی (PII) پیش‌پردازش کنید، آن را حذف یا شبه‌نام‌گذاری کنید و به طور اختیاری پس از بردارسازی، تعبیه‌ها را پردازش کنید تا سیگنال‌های باقیمانده حذف شوند.

 #8.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که داده‌های شخصی شناسایی‌پذیر (PII) و داده‌های تنظیم‌شده توسط طبقه‌بندهای خودکار شناسایی شده و پیش از جاسازی، به صورت ماسک شده، توکنیزه شده یا حذف شده‌اند.
 #8.2.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که خطوط پردازش تعبیه‌ها ورودی‌هایی که حاوی کد اجرایی یا آثار غیر UTF-8 هستند و می‌توانند اندیس را مسموم کنند را رد یا قرنطینه می‌کنند.
 #8.2.3    سطح: 2    نقش: D/V
 تأیید کنید که پاک‌سازی حریم خصوصی تفاضلی محلی یا معیار به تعبیه‌های جمله اعمال شده باشد که فاصله آن‌ها با هر توکن اطلاعات شناسایی شخصی (PII) شناخته شده کمتر از یک آستانه قابل تنظیم باشد.
 #8.2.4    سطح: 2    نقش: V
 تأیید کنید که اثربخشی پاک‌سازی (مثلاً یادآوری حذف اطلاعات شخصی حساس، انحراف معنایی) حداقل هر شش ماه یک‌بار بر اساس مجموعه‌های مرجع ارزیابی می‌شود.
 #8.2.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که پیکربندی‌های پاکسازی تحت کنترل نسخه هستند و تغییرات آن‌ها تحت بررسی همتا قرار می‌گیرد.

---

### C8.3 انقضای حافظه، لغو و حذف

قانون GDPR درباره «حق فراموش شدن» و قوانین مشابه نیازمند پاک‌سازی به موقع است؛ بنابراین، فروشگاه‌های وکتور باید از TTLها، حذف‌های سخت و تخریب تدریجی پشتیبانی کنند تا وکتورهای لغو شده نتوانند بازیابی یا دوباره فهرست‌بندی شوند.

 #8.3.1    سطح: 1    نقش: D/V
 تأیید کنید که هر وکتور و رکورد متادیتا برچسب TTL یا نگهداری صریحی دارد که توسط عملیات پاک‌سازی خودکار رعایت می‌شود.
 #8.3.2    سطح: 1    نقش: D/V
 تأیید کنید که درخواست‌های حذف شده توسط کاربر، بردارها، فراداده‌ها، نسخه‌های کش و شاخص‌های مشتق شده را ظرف 30 روز پاکسازی می‌کنند.
 #8.3.3    سطح: 2    نقش: D
 تأیید کنید که حذف‌های منطقی با از بین بردن رمزنگاری‌شده بلوک‌های ذخیره‌سازی در صورت پشتیبانی سخت‌افزار، یا با تخریب کلید در کلیدخانه همراه هستند.
 #8.3.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که بردارهای منقضی شده در کمتر از 500 میلی‌ثانیه پس از انقضا از نتایج جستجوی نزدیک‌ترین همسایه حذف می‌شوند.

---

### C8.4 جلوگیری از وارونگی و نشت جاسازی

دفاع‌های اخیر—تقویت نویز، شبکه‌های پروجکشن، اختلال نورون حریم خصوصی، و رمزگذاری در لایه برنامه—می‌توانند نرخ معکوس‌سازی در سطح توکن را به کمتر از ۵٪ کاهش دهند.

 #8.4.1    سطح: 1    نقش: V
 اطمینان حاصل کنید که مدل تهدید رسمی شامل حملات وارونگی، عضویت و استنباط ویژگی وجود دارد و سالانه بررسی می‌شود.
 #8.4.2    سطح: 2    نقش: D/V
 تأیید کنید که رمزگذاری در لایه برنامه یا رمزگذاری قابل جستجو، بردارها را از خوانش مستقیم توسط مدیران زیرساخت یا کارکنان ابر محافظت می‌کند.
 #8.4.3    سطح: 3    نقش: V
 اطمینان حاصل کنید که پارامترهای دفاعی (ε برای DP، نویز σ، رتبه تصویر k) تعادلی بین حفظ حریم خصوصی ≥ ۹۹٪ حفاظت از توکن و بهره‌وری ≤ ۳٪ کاهش دقت برقرار کنند.
 #8.4.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که معیارهای مقاومت در برابر وارونگی جزئی از دروازه‌های انتشار به‌روزرسانی مدل هستند، با بودجه‌های رگرسیون مشخص شده.

---

### C8.5 اجرای محدوده برای حافظه مختص به کاربر

نشت بین مشتریان مختلف هنوز هم یکی از بزرگ‌ترین ریسک‌های RAG است: جستجوهای شبیه‌سازی به‌طور نادرست فیلتر شده می‌تواند اسناد خصوصی مشتری دیگری را نمایش دهد.

 #8.5.1    سطح: 1    نقش: D/V
 تأیید کنید که هر پرس‌و‌جوی بازیابی قبل از ارسال به درخواست LLM، توسط شناسه مستاجر/کاربر پس‌پردازش (post-filter) شده باشد.
 #8.5.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که نام‌های مجموعه یا شناسه‌های فضای نام‌گذاری شده به ازای هر کاربر یا مستأجر جدا شده‌اند تا بردارها در سطوح مختلف با هم تداخل نداشته باشند.
 #8.5.3    سطح: 2    نقش: D/V
 تأیید کنید که نتایج شباهت بالاتر از یک آستانه فاصله قابل تنظیم اما خارج از حوزه تماس‌گیرنده، رد شده و هشدارهای امنیتی را فعال می‌کنند.
 #8.5.4    سطح: 2    نقش: V
 تأیید کنید که آزمایش‌های فشار چند مستاجری، پرسش‌های خصمانه‌ای که تلاش می‌کنند اسناد خارج از حوزه را بازیابی کنند شبیه‌سازی می‌کنند و نشت صفر را نشان می‌دهند.
 #8.5.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که کلیدهای رمزگذاری به ازای هر مستأجر جدا شده‌اند، به گونه‌ای که جداسازی رمزنگاری حتی در صورت اشتراک‌گذاری ذخیره‌سازی فیزیکی برقرار باشد.

---

### C8.6 امنیت پیشرفته سامانه حافظه

کنترل‌های امنیتی برای معماری‌های پیچیده حافظه شامل حافظه اپیزودیک، معنایی و کاری با نیازهای خاص جداسازی و اعتبارسنجی.

 #8.6.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که انواع مختلف حافظه (اپیزودیک، معنایی، کاری) دارای زمینه‌های امنیتی مجزا با کنترل‌های دسترسی مبتنی بر نقش، کلیدهای رمزنگاری جداگانه، و الگوهای دسترسی مستند شده برای هر نوع حافظه هستند.
 #8.6.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فرآیندهای تثبیت حافظه شامل اعتبارسنجی امنیتی برای جلوگیری از تزریق خاطرات مخرب از طریق تصفیه محتوا، تأیید منبع و بررسی‌های صحت قبل از ذخیره‌سازی می‌باشد.
 #8.6.3    سطح: 2    نقش: D/V
 تأیید کنید که پرس‌وجوهای بازیابی حافظه اعتبارسنجی و پاک‌سازی شده‌اند تا از استخراج اطلاعات غیرمجاز از طریق تحلیل الگوی پرس‌وجو، اعمال کنترل دسترسی و فیلتر کردن نتایج جلوگیری شود.
 #8.6.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های فراموشی حافظه اطلاعات حساس را با تضمین‌های حذف رمزنگاری‌شده به‌طور ایمن حذف می‌کنند، از جمله حذف کلید، بازنویسی چندباره، یا حذف ایمن مبتنی بر سخت‌افزار با گواهی‌های تأیید.
 #8.6.5    سطح: 3    نقش: D/V
 تأیید کنید که صحت سیستم حافظه به طور مداوم برای تغییرات یا فساد غیرمجاز از طریق بررسی چک‌سام‌ها، گزارش‌های حسابرسی و هشدارهای خودکار در صورت تغییر محتوای حافظه خارج از عملیات معمول، تحت نظارت قرار دارد.

---

### مراجع

Vector database security: Pinecone – IronCore Labs
Securing the Backbone of AI: Safeguarding Vector Databases and Embeddings – Privacera
Enhancing Data Security with RBAC of Qdrant Vector Database – AI Advances
Mitigating Privacy Risks in LLM Embeddings from Embedding Inversion – arXiv
DPPN: Detecting and Perturbing Privacy-Sensitive Neurons – OpenReview
Art. 17 GDPR – Right to Erasure
Sensitive Data in Text Embeddings Is Recoverable – Tonic.ai
PII Identification and Removal – NVIDIA NeMo Docs
De-identifying Sensitive Data – Google Cloud DLP
Remove PII from Conversations Using Sensitive Information Filters – AWS Bedrock Guardrails
Think Your RAG Is Secure? Think Again – Medium
Design a Secure Multitenant RAG Inferencing Solution – Microsoft Learn
Best Practices for Multi-Tenancy RAG with Milvus – Milvus Blog

## 9 هماهنگی خودکار و امنیت عملکرد عاملی

### هدف کنترل

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی خودکار یا چندعامله تنها قادر به اجرای اقداماتی باشند که به‌طور صریح مورد نظر، تأیید شده، قابل حسابرسی و در محدوده هزینه و ریسک مشخص باشند. این محافظت در برابر تهدیدهایی مانند نفوذ به سیستم خودکار، سوءاستفاده از ابزار، تشخیص حلقه عوامل، ربایش ارتباطات، جعل هویت، دستکاری گروهی و دستکاری قصد است.

---

### 9.1 بودجه‌های برنامه‌ریزی وظایف عامل و بازگشت‌دهی

سرعت برنامه‌های بازگشتی را کاهش دهید و برای اقدامات با امتیاز ویژه نقاط بازبینی انسانی اجباری ایجاد کنید.

 #9.1.1    سطح: 1    نقش: D/V
 تأیید کنید که حداکثر عمق بازگشت، پهنا، زمان دیوارساعت، توکن‌ها و هزینه مالی هر اجرای عامل به صورت مرکزی پیکربندی و کنترل نسخه شده‌اند.
 #9.1.2    سطح: 1    نقش: D/V
 تأیید کنید که اقدامات دارای امتیاز ویژه یا غیرقابل برگشت (مانند تعهدات کد، انتقالات مالی) قبل از اجرا نیاز به تأیید صریح انسانی از طریق یک کانال قابل حسابرسی دارند.
 #9.1.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که مانیتورهای منابع زمان واقعی هنگامی که هر آستانه بودجه‌ای شکسته می‌شود، وقفه مدار قطع‌کننده را فعال می‌کنند و از گسترش بیشتر وظیفه جلوگیری می‌کنند.
 #9.1.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که رویدادهای قطع‌کننده مدار با شناسه عامل، شرایط محرک و وضعیت برنامه ضبط شده برای بررسی‌های جنایی ثبت می‌شوند.
 #9.1.5    سطح: 3    نقش: V
 تأیید کنید که تست‌های امنیتی شامل سناریوهای اتمام بودجه و برنامه‌ی فراری باشند و توقف ایمن بدون از دست دادن داده تضمین شود.
 #9.1.6    سطح: 3    نقش: D
 تأیید کنید که سیاست‌های بودجه به صورت سیاست-به-کد بیان شده و در CI/CD اعمال می‌شوند تا از انحراف تنظیمات جلوگیری شود.

---

### 9.2 جعبه‌شن برای افزونه ابزار

تعاملات ابزار را ایزوله کنید تا از دسترسی غیرمجاز به سیستم یا اجرای کد جلوگیری شود.

 #9.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر ابزار/افزونه در داخل یک سیستم‌عامل، کانتینر، یا محیط ایزوله سطح WASM اجرا می‌شود که سیاست‌های حداقل امتیاز برای سیستم‌فایل، شبکه و فراخوانی‌های سیستمی اعمال شده باشد.
 #9.2.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سهمیه‌های منابع سندباکس (CPU، حافظه، دیسک، خروجی شبکه) و زمان‌های اجرای محدود شده اعمال و ثبت شده‌اند.
 #9.2.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فایل‌های اجرایی ابزار یا توصیف‌گرها به‌صورت دیجیتالی امضا شده‌اند؛ امضاها قبل از بارگذاری تأیید می‌شوند.
 #9.2.4    سطح: 2    نقش: V
 تأیید کنید که داده‌های تله‌متری سندباکس به یک سیستم مدیریت و تحلیل رویدادهای امنیتی (SIEM) ارسال می‌شود؛ ناهنجاری‌ها (مانند تلاش برای اتصال‌های خروجی) هشدار تولید می‌کنند.
 #9.2.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که افزونه‌های پرخطر قبل از استقرار در محیط تولید، مورد بررسی امنیتی و آزمایش نفوذ قرار می‌گیرند.
 #9.2.6    سطح: 3    نقش: D/V
 تأیید کنید که تلاش‌های فرار از سندباکس به‌طور خودکار مسدود شده و افزونه خاطی در انتظار بررسی در قرنطینه قرار می‌گیرد.

---

### 9.3 حلقه خودگردان و محدود کردن هزینه

تشخیص و توقف بازگشت کنترل‌نشده عامل به عامل و انفجار هزینه‌ها.

 #9.3.1    سطح: 1    نقش: D/V
 تأیید کنید که تماس‌های بین عامل‌ها شامل یک محدودیت پرش یا TTL باشد که زمان اجرا آن را کاهش داده و اعمال می‌کند.
 #9.3.2    سطح: 2    نقش: D
 تأیید کنید که عوامل یک شناسه یکتا برای گراف فراخوانی حفظ می‌کنند تا خودفراخوانی یا الگوهای چرخه‌ای را شناسایی کنند.
 #9.3.3    سطح: 2    نقش: D/V
 تأیید کنید که شمارنده‌های تجمعی واحد محاسبات و هزینه به ازای هر زنجیره درخواست پیگیری می‌شوند؛ عبور از حد مجاز باعث قطع زنجیره می‌شود.
 #9.3.4    سطح: 3    نقش: V
 تأیید کنید که تحلیل رسمی یا بررسی مدل، عدم وجود بازگشت نامحدود در پروتکل‌های عامل را نشان می‌دهد.
 #9.3.5    سطح: 3    نقش: D
 تأیید کنید که رویدادهای قطع حلقه هشدارها را تولید کرده و معیارهای بهبود مستمر را تغذیه می‌کنند.

---

### 9.4 حفاظت در سطح پروتکل در برابر سوءاستفاده

کانال‌های ارتباطی امن بین عوامل و سیستم‌های خارجی برای جلوگیری از ربوده شدن یا دستکاری.

 #9.4.1    سطح: 1    نقش: D/V
 تأیید کنید که تمامی پیام‌های بین عامل به ابزار و عامل به عامل احراز هویت شده باشند (برای مثال، TLS متقابل یا JWT) و از انتها به انتها رمزگذاری شده باشند.
 #9.4.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که اسکیم‌ها به‌طور دقیق اعتبارسنجی می‌شوند؛ فیلدهای ناشناخته یا پیام‌های معیوب رد می‌شوند.
 #9.4.3    سطح: 2    نقش: D/V
 تأیید کنید که بررسی‌های یکپارچگی (MACها یا امضاهای دیجیتال) کل بار پیام از جمله پارامترهای ابزار را شامل می‌شوند.
 #9.4.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که حفاظت در برابر پخش مجدد (نانس‌ها یا پنجره‌های زمان‌بندی) در لایه پروتکل اعمال شده است.
 #9.4.5    سطح: 3    نقش: V
 تأیید کنید که پیاده‌سازی‌های پروتکل تحت آزمایش حبابی (fuzzing) و تحلیل ایستا برای یافتن آسیب‌پذیری‌های تزریق یا نادرستی سری‌زدایی قرار گیرند.

---

### 9.5 هویت عامل و شواهد تغییرناپذیری

اطمینان حاصل کنید که اقدامات قابل انتساب و تغییرات قابل تشخیص باشند.

 #9.5.1    سطح: 1    نقش: D/V
 تأیید کنید که هر نمونه از عامل دارای یک هویت رمزنگاری منحصر به فرد (جفت کلید یا اعتبارنامه مبتنی بر سخت‌افزار) است.
 #9.5.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تمام اقدامات عامل دارای امضا و تاریخ‌زمان باشند؛ لاگ‌ها شامل امضا برای جلوگیری از انکار هستند.
 #9.5.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که لاگ‌های قابل تشخیص دستکاری در یک رسانه فقط افزودنی یا نوشتنی-یکباره ذخیره شده‌اند.
 #9.5.4    سطح: 3    نقش: D
 تأیید کنید که کلیدهای هویتی طبق یک برنامه زمان‌بندی مشخص و در صورت وجود شاخص‌های نفوذ، چرخش می‌کنند.
 #9.5.5    سطح: 3    نقش: D/V
 تأیید کنید که تلاش‌های جعل یا تعارض کلید باعث قرنطینه فوری عامل متاثر شده می‌شود.

---

### 9.6 کاهش ریسک گروهی چندعامله

کاهش خطرات رفتار جمعی از طریق ایزوله‌سازی و مدل‌سازی رسمی ایمنی.

 #9.6.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که عوامل فعال در حوزه‌های امنیتی مختلف در محیط‌های اجرای جداشده به صورت ساندباکس یا بخش‌های شبکه ایزوله اجرا می‌شوند.
 #9.6.2    سطح: 3    نقش: V
 اطمینان حاصل کنید که رفتارهای گروهی مدل‌سازی شده و به صورت رسمی برای زنده‌مانی و ایمنی قبل از استقرار تأیید شده‌اند.
 #9.6.3    سطح: 3    نقش: D
 تأیید کنید که مانیتورهای زمان اجرا الگوهای ناایمن نوظهور (مانند نوسانات، بن‌بست‌ها) را شناسایی کرده و اقدام اصلاحی را آغاز می‌کنند.

---

### 9.7 تصدیق هویت / اجازه دسترسی کاربر و ابزار

کنترل‌های دسترسی قوی برای هر اقدام فعال‌شده توسط عامل پیاده‌سازی کنید.

 #9.7.1    سطح: 1    نقش: D/V
 تأیید کنید که عوامل به عنوان نمایندگان درجه یک به سیستم‌های پایین‌دستی احراز هویت می‌کنند و هرگز از اعتبارنامه‌های کاربر نهایی مجدداً استفاده نمی‌کنند.
 #9.7.2    سطح: 2    نقش: D
 بررسی کنید که سیاست‌های مجوزدهی دقیق تعیین کنند که کدام ابزارها توسط یک عامل می‌توانند فراخوانی شوند و کدام پارامترها می‌توانند ارائه شوند.
 #9.7.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که بررسی‌های امتیازات در هر فراخوانی دوباره ارزیابی می‌شوند (مجازسازی مداوم)، و نه فقط در ابتدای جلسه.
 #9.7.4    سطح: 3    نقش: D
 اطمینان حاصل کنید که امتیازات واگذار شده به طور خودکار منقضی می‌شوند و پس از پایان مهلت یا تغییر دامنه، نیاز به موافقت مجدد دارند.

---

### 9.8 امنیت ارتباط عامل به عامل

تمام پیام‌های بین عوامل را رمزنگاری کرده و از صحت آنها محافظت کنید تا از استراق سمع و دستکاری جلوگیری شود.

 #9.8.1    سطح: 1    نقش: D/V
 تأیید کنید که احراز هویت متقابل و رمزنگاری با راز پیشرو کامل (مانند TLS 1.3) برای کانال‌های عامل الزامی هستند.
 #9.8.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که صحت پیام و مبدأ آن قبل از پردازش تأیید شده باشد؛ در صورت شکست، هشدارها صادر شده و پیام حذف می‌شود.
 #9.8.3    سطح: 2    نقش: D/V
 تأیید کنید که متاداده‌های ارتباطی (زمان‌سنجی‌ها، شماره‌های توالی) برای پشتیبانی از بازسازی قانونی ثبت می‌شوند.
 #9.8.4    سطح: 3    نقش: V
 تأیید کنید که تأیید رسمی یا بررسی مدل تایید می‌کند که ماشین‌های حالت پروتکل نمی‌توانند به حالت‌های ناامن رانده شوند.

---

### 9.9 تایید نیت و اعمال محدودیت‌ها

اعتبارسنجی کنید که اقدامات عامل با نیت اعلام شده کاربر و محدودیت‌های سیستم هم‌راستا باشد.

 #9.9.1    سطح: 1    نقش: D
 تأیید کنید که حل‌کننده‌های محدودیت پیش‌اجرا، اقدامات پیشنهادی را با قوانین ایمنی و سیاست سخت‌رمزه شده بررسی می‌کنند.
 #9.9.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اقدامات با تاثیر بالا (مالی، مخرب، حساس به حریم خصوصی) نیاز به تایید صریح نیت از سوی کاربر آغازکننده دارند.
 #9.9.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که بررسی‌های پس‌شرط تایید می‌کنند که اقدامات انجام شده اثرات مورد نظر را بدون عوارض جانبی به‌دست آورده‌اند؛ در صورت وجود اختلاف، بازگشت به حالت قبل فعال می‌شود.
 #9.9.4    سطح: 3    نقش: V
 تأیید کنید که روش‌های رسمی (مانند بررسی مدل، اثبات قضیه) یا تست‌های مبتنی بر ویژگی نشان می‌دهند که برنامه‌های عامل تمامی محدودیت‌های اعلام‌شده را برآورده می‌کنند.
 #9.9.5    سطح: 3    نقش: D
 اطمینان حاصل کنید که حوادث ناسازگاری نیت یا نقض محدودیت، چرخه‌های بهبود مستمر و اشتراک‌گذاری اطلاعات تهدید را تغذیه می‌کنند.

---

### 9.10 استراتژی امنیت استدلال عامل

انتخاب و اجرای امن استراتژی‌های استدلال مختلف از جمله روش‌های ReAct، Chain-of-Thought و Tree-of-Thoughts.

 #9.10.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که انتخاب استراتژی استدلال از معیارهای قطعی (پیچیدگی ورودی، نوع وظیفه، زمینه امنیتی) استفاده می‌کند و ورودی‌های یکسان در همان زمینه امنیتی منجر به انتخاب استراتژی‌های یکسان می‌شوند.
 #9.10.2    سطح: 1    نقش: D/V
 بررسی کنید که هر استراتژی استدلالی (ReAct، Chain-of-Thought، Tree-of-Thoughts) دارای اعتبارسنجی ورودی اختصاصی، پاک‌سازی خروجی و محدودیت‌های زمان اجرا باشد که متناسب با رویکرد شناختی خاص آن است.
 #9.10.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که انتقال استراتژی استدلال با زمینه کامل شامل ویژگی‌های ورودی، مقادیر معیارهای انتخاب و فراداده‌های اجرای برای بازسازی سوابق حسابرسی ثبت شده است.
 #9.10.4    سطح: 2    نقش: D/V
 تأیید کنید که استدلال درخت افکار شامل مکانیزم‌های هرس شاخه است که بررسی را زمانی که تخلفات سیاست، محدودیت‌های منابع، یا مرزهای ایمنی شناسایی می‌شوند، متوقف می‌کند.
 #9.10.5    سطح: 2    نقش: D/V
 تأیید کنید که چرخه‌های ReAct (استدلال-عمل-مشاهده) شامل نقاط بررسی اعتبارسنجی در هر مرحله هستند: تأیید گام استدلال، تأیید مجوز عمل، و تصفیه مشاهده قبل از ادامه.
 #9.10.6    سطح: 3    نقش: D/V
 اطمینان حاصل شود که معیارهای عملکرد استراتژی استدلال (زمان اجرا، مصرف منابع، کیفیت خروجی) با هشدارهای خودکار هنگام انحراف معیارها فراتر از آستانه‌های پیکربندی شده، مانیتور می‌شوند.
 #9.10.7    سطح: 3    نقش: D/V
 تأیید کنید که روش‌های استدلال ترکیبی که چندین استراتژی را با هم ترکیب می‌کنند، اعتبارسنجی ورودی و محدودیت‌های خروجی همه استراتژی‌های تشکیل‌دهنده را حفظ می‌کنند بدون اینکه هیچ یک از کنترل‌های امنیتی را دور بزنند.
 #9.10.8    سطح: 3    نقش: D/V
 بررسی کنید که تست امنیت استراتژی استدلال شامل آزمایش با ورودی‌های خراب‌شده (fuzzing)، پرامپت‌های دشمنانه طراحی شده برای اجبار به تغییر استراتژی، و تست شرایط مرزی برای هر روش شناختی باشد.

---

### 9.11 مدیریت وضعیت چرخه عمر عامل و امنیت

راه‌اندازی ایمن عامل، انتقال حالت‌ها و خاتمه با ردپای حسابرسی رمزنگاری شده و رویه‌های بازیابی مشخص شده.

 #9.11.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که راه‌اندازی عامل شامل ایجاد هویت رمزنگاری‌شده با مدارک پشتیبانی‌شده توسط سخت‌افزار و لاگ‌های حسابرسی شروع غیرقابل تغییر است که شامل شناسه عامل، زمان‌بندی، هش پیکربندی و پارامترهای راه‌اندازی می‌باشد.
 #9.11.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که انتقال‌های حالت عامل به‌صورت رمزنگاری شده امضا شده، با مهر زمان ثبت شده و با زمینه کامل از جمله رویدادهای محرک، هش حالت قبلی، هش حالت جدید و اعتبارسنجی‌های امنیتی انجام شده، لاگ شوند.
 #9.11.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که رویه‌های خاموش کردن عامل شامل پاک‌سازی امن حافظه با استفاده از حذف رمزنگاری شده یا بازنویسی چندگذره، ابطال اعتبارنامه‌ها با اطلاع‌رسانی به مرجع صدور گواهی، و تولید گواهی‌های پایان کار که قابل اثبات دستکاری باشند، می‌باشد.
 #9.11.4    سطح: 3    نقش: D/V
 تأیید کنید که مکانیزم‌های بازیابی عامل، صحت وضعیت را با استفاده از چک‌سام‌های رمزنگاری شده (حداقل SHA-256) اعتبارسنجی می‌کنند و در صورت تشخیص فساد، به وضعیت‌های شناخته‌شده و سالم بازگردانده می‌شوند، همراه با هشدارهای خودکار و نیاز به تایید دستی.
 #9.11.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های ماندگاری عامل داده‌های حساس وضعیت را با کلیدهای AES-256 اختصاصی هر عامل رمزگذاری می‌کنند و چرخش امن کلید را در برنامه‌های زمان‌بندی قابل تنظیم (حداکثر 90 روز) با استقرار بدون قطعی پیاده‌سازی می‌کنند.

---

### ۹.۱۲ چارچوب امنیتی یکپارچه‌سازی ابزار

کنترل‌های امنیتی برای بارگذاری ابزار پویا، اجرا و اعتبارسنجی نتایج با فرایندهای ارزیابی ریسک و تأیید مشخص شده.

 #9.12.1    سطح: 1    نقش: D/V
 اعتبارسنجی کنید که توضیحات ابزار شامل فراداده امنیتی باشد که دسترسی‌های لازم (خواندن/نوشتن/اجرا)، سطح ریسک (کم/متوسط/زیاد)، محدودیت‌های منابع (پردازنده، حافظه، شبکه) و الزامات اعتبارسنجی مستندسازی شده در مانیفست‌های ابزار را مشخص می‌کند.
 #9.12.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که نتایج اجرای ابزارها بر اساس طرح‌های مورد انتظار (JSON Schema، XML Schema) و سیاست‌های امنیتی (پاک‌سازی خروجی، طبقه‌بندی داده‌ها) قبل از ادغام با محدودیت‌های زمانی و رویه‌های مدیریت خطا، اعتبارسنجی می‌شوند.
 #9.12.3    سطح: 2    نقش: D/V
 تأیید کنید که لاگ‌های تعامل با ابزار شامل زمینه امنیتی دقیق، از جمله استفاده از سطح دسترسی‌ها، الگوهای دسترسی به داده‌ها، زمان اجرای فرایند، مصرف منابع و کدهای بازگشتی با لاگ‌گیری ساخت‌یافته برای ادغام در SIEM باشد.
 #9.12.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های بارگذاری ابزارهای پویا امضاهای دیجیتال را با استفاده از زیرساخت PKI اعتبارسنجی می‌کنند و پروتکل‌های بارگذاری امن با جداسازی در محیط ایزوله (sandbox) و تأیید دسترسی‌ها قبل از اجرا را پیاده‌سازی می‌کنند.
 #9.12.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که ارزیابی‌های امنیتی ابزار به صورت خودکار برای نسخه‌های جدید با دروازه‌های تأیید اجباری شامل تحلیل ایستا، آزمون پویا و بازبینی تیم امنیتی با معیارهای تأیید مستند و الزامات SLA فعال می‌شوند.

---

#### مراجع

MITRE ATLAS tactics ML09
Circuit-breaker research for AI agents — Zou et al., 2024
Trend Micro analysis of sandbox escapes in AI agents — Park, 2025
Auth0 guidance on human-in-the-loop authorization for agents — Martinez, 2025
Medium deep-dive on MCP & A2A protocol hijacking — ForAISec, 2025
Rapid7 fundamentals on spoofing attack prevention — 2024
Imperial College verification of swarm systems — Lomuscio et al.
NIST AI Risk Management Framework 1.0, 2023
WIRED security briefing on encryption best practices, 2024
OWASP Top 10 for LLM Applications, 2025
Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS
[How Is LLM Reasoning Distracted by Irrelevant Context?
An Analysis Using a Controlled Benchmark](https://www.arxiv.org/pdf/2505.18761)
Large Language Model Sentinel: LLM Agent for Adversarial Purification
Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents

## 10 مقاومت در مقابل حملات متقابل و دفاع از حریم خصوصی

### هدف کنترل

اطمینان حاصل کنید که مدل‌های هوش مصنوعی هنگام مواجهه با حملات دور زدن، استنتاج، استخراج، یا مسموم‌سازی، قابل اعتماد، حفظ‌کننده حریم خصوصی و مقاوم در برابر سوءاستفاده باقی بمانند.

---

### ۱۰.۱ همسویی مدل و ایمنی

مراقب خروجی‌های مضر یا نقض‌کننده سیاست‌ها باشید.

 #10.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که یک مجموعه آزمون هم‌راستایی (دستورات تیم قرمز، آزمایش‌های فرار از محدودیت، محتوای ممنوعه) نسخه‌گذاری شده و در هر انتشار مدل اجرا می‌شود.
 #10.1.2    سطح: 1    نقش: D
 تأیید کنید که موانع جلوگیری از انکار و تکمیل ایمن اجرا شده باشند.
 #10.1.3    سطح: 2    نقش: D/V
 تأیید کنید که یک ارزیاب خودکار نرخ محتوای مضر را اندازه‌گیری کرده و پسرفت‌ها را فراتر از آستانه تعیین‌شده علامت‌گذاری می‌کند.
 #10.1.4    سطح: 2    نقش: D
 تأیید کنید که آموزش ضد شکستن محدودیت‌ها مستند و قابل تکرار است.
 #10.1.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که اثبات‌های رسمی انطباق با سیاست یا نظارت گواهی‌شده، حوزه‌های حیاتی را پوشش می‌دهند.

---

### 10.2 سخت‌سازی نمونه‌های خصمانه

افزایش مقاومت در برابر ورودی‌های دستکاری‌شده. آموزش مقاومتی پیشرفته و امتیازدهی معیارهای ارزیابی، بهترین روش فعلی هستند.

 #10.2.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که مخازن پروژه شامل پیکربندی‌های آموزش خصمانه با بذرهای قابل تکرار هستند.
 #10.2.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تشخیص نمونه‌های خصمانه در خطوط تولید هشدارهای مسدودکننده ایجاد می‌کند.
 #10.2.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که اثبات‌های پایداری تاییدشده یا گواهی‌های محدودبندی فاصله حداقل کلاس‌های بحرانی برتر را پوشش می‌دهند.
 #10.2.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که تست‌های رگرسیون از حملات تطبیقی استفاده می‌کنند تا عدم وجود کاهش قابل اندازه‌گیری در مقاومت را تایید کنند.

---

### 10.3 کاهش استنباط عضویت

محدود کردن توانایی تصمیم‌گیری درباره اینکه آیا یک رکورد در داده‌های آموزشی بوده است. حفظ حریم خصوصی تفاضلی و پوشش‌دهی امتیاز اطمینان همچنان مؤثرترین دفاع‌های شناخته‌شده هستند.

 #10.3.1    سطح: 1    نقش: D
 تأیید کنید که منظم‌سازی آنتروپی به ازای هر پرسش یا مقیاس‌بندی دما، پیش‌بینی‌های بیش از حد مطمئن را کاهش می‌دهد.
 #10.3.2    سطح: 2    نقش: D
 تأیید کنید که آموزش از بهینه‌سازی تفاضلی-خصوصی با حد ε برای داده‌های حساس استفاده می‌کند.
 #10.3.3    سطح: 2    نقش: V
 تأیید کنید که شبیه‌سازی‌های حمله (مدل سایه یا جعبه‌سیاه) نشان دهند که AUC حمله کمتر یا مساوی 0.60 روی داده‌های نگه‌داشته شده است.

---

### ۱۰.۴ مقاومت در برابر برعکس‌سازی مدل

جلوگیری از بازسازی ویژگی‌های خصوصی. بررسی‌های اخیر تأکید می‌کنند که قطع خروجی و تضمین‌های DP به عنوان دفاع‌های عملی استفاده می‌شوند.

 #10.4.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که ویژگی‌های حساس هرگز به طور مستقیم خروجی داده نمی‌شوند؛ در صورت نیاز، از سطل‌ها یا تبدیلات یک‌طرفه استفاده کنید.
 #10.4.2    سطح: 1    نقش: D/V
 تأیید کنید که محدودیت‌های نرخ پرس‌وجو، پرس‌وجوهای تطبیقی مکرر از همان اصل را محدود می‌کنند.
 #10.4.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که مدل با نویز حفظ حریم خصوصی آموزش داده شده است.

---

### 10.5 دفاع استخراج مدل

شناسایی و جلوگیری از کلون‌سازی غیرمجاز. استفاده از نشانه‌گذاری دیجیتال و تحلیل الگوهای پرس‌وجو پیشنهاد می‌شود.

 #10.5.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که دروازه‌های استنتاج محدودیت‌های نرخ کلی و محدودیت‌های نرخ مخصوص به هر کلید API را که متناسب با آستانه حفظ حافظه مدل تنظیم شده‌اند، اجرا می‌کنند.
 #10.5.2    سطح: 2    نقش: D/V
 تأیید کنید که آمارهای انتروپی پرس‌وجو و جمع‌گرایی ورودی، یک آشکارساز استخراج خودکار را تغذیه می‌کنند.
 #10.5.3    سطح: 2    نقش: V
 تأیید کنید که نشان‌های آبی شکننده یا احتمالاتی می‌توانند با p < 0.01 در ≤ 1 000 پرس‌وجو علیه یک کلون مشکوک اثبات شوند.
 #10.5.4    سطح: 3    نقش: D
 اطمینان حاصل کنید که کلیدهای واترمارک و مجموعه‌های تریگر در یک ماژول امنیت سخت‌افزاری ذخیره شده و به صورت سالانه تغییر داده می‌شوند.
 #10.5.5    سطح: 3    نقش: V
 تأیید کنید که رویدادهای استخراج-هشدار شامل پرس‌وجوهای متخلف بوده و با کتابچه‌های پاسخ به حادثه ادغام شده‌اند.

---

### 10.6 تشخیص داده‌های آلوده در زمان استنتاج

شناسایی و خنثی‌سازی ورودی‌های دارای درب پشتی یا آلوده.

 #10.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که ورودی‌ها قبل از استنتاج مدل از طریق یک آشکارساز ناهنجاری (مثلاً STRIP، امتیازدهی سازگاری) عبور کنند.
 #10.6.2    سطح: 1    نقش: V
 اطمینان حاصل کنید که آستانه‌های آشکارساز بر روی مجموعه‌های اعتبارسنجی پاک/آلوده تنظیم شده‌اند تا کمتر از ۵٪ مثبت کاذب داشته باشند.
 #10.6.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که ورودی‌هایی که به عنوان مسموم علامت‌گذاری شده‌اند، باعث فعال‌شدن فرایندهای مسدودسازی نرم و بازبینی انسانی می‌شوند.
 #10.6.4    سطح: 2    نقش: V
 تأیید کنید که آشکارسازها با حملات در پشتی تطبیقی بدون ماشه تحت فشار قرار گرفته‌اند.
 #10.6.5    سطح: 3    نقش: D
 اطمینان حاصل کنید که معیارهای اثربخشی تشخیص ثبت می‌شوند و به‌طور دوره‌ای با اطلاعات تهدید تازه مجدداً ارزیابی می‌شوند.

---

### 10.7 سازگارسازی پویای سیاست‌های امنیتی

به‌روزرسانی‌های سیاست امنیتی در زمان واقعی بر اساس اطلاعات تهدید و تحلیل رفتاری.

 #10.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیاست‌های امنیتی می‌توانند به صورت پویا بدون راه‌اندازی مجدد عامل به‌روز شوند در حالی که صحت نسخه سیاست حفظ می‌شود.
 #10.7.2    سطح: 2    نقش: D/V
 تأیید کنید که به‌روزرسانی‌های سیاست به‌صورت رمزنگاری‌شده توسط پرسنل امنیتی مجاز امضا شده و قبل از اعمال اعتبارسنجی می‌شوند.
 #10.7.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تغییرات سیاست‌های پویا با داشتن مسیرهای کامل حسابرسی شامل توجیه، زنجیره‌های تایید و روش‌های بازگردانی، ثبت می‌شوند.
 #10.7.4    سطح: 3    نقش: D/V
 تأیید کنید که مکانیزم‌های امنیتی تطبیقی حساسیت تشخیص تهدید را بر اساس زمینه ریسک و الگوهای رفتاری تنظیم می‌کنند.
 #10.7.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تصمیمات تطبیق سیاست قابل توضیح باشند و شامل شواهد مستند برای بررسی تیم امنیتی باشند.

---

### 10.8 تحلیل امنیت مبتنی بر بازتاب (Reflection-Based Security Analysis)

اعتبارسنجی امنیت از طریق خودبازتابی عامل و تحلیل فراتفکری.

 #10.8.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های بازتاب عامل شامل ارزیابی خود متمرکز بر امنیت از تصمیمات و اقدامات هستند.
 #10.8.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که خروجی‌های بازتابی اعتبارسنجی شده‌اند تا از دستکاری مکانیزم‌های خودارزیابی توسط ورودی‌های خصمانه جلوگیری شود.
 #10.8.3    سطح: 2    نقش: D/V
 بررسی کنید که تحلیل امنیت فراشناختی، سوگیری احتمالی، دستکاری یا نفوذ در فرآیندهای استدلال عامل را شناسایی می‌کند.
 #10.8.4    سطح: 3    نقش: D/V
 تأیید کنید که هشدارهای امنیتی مبتنی بر انعکاس، پایش پیشرفته و جریان‌های کاری احتمالی مداخله انسانی را فعال می‌کنند.
 #10.8.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که یادگیری مداوم از بازتاب‌های امنیتی تشخیص تهدید را بهبود می‌بخشد بدون اینکه عملکردهای مشروع را تضعیف کند.

---

### 10.9 تکامل و امنیت خودبهبودی

کنترل‌های امنیتی برای سیستم‌های عاملی که قادر به خود-تغییر و تکامل هستند.

 #10.9.1    سطح: 1    نقش: D/V
 تأیید کنید که قابلیت‌های خود-تغییر محدود به مناطق ایمن تعیین‌شده با مرزهای تأیید رسمی باشد.
 #10.9.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که پیشنهادهای تکاملی پیش از اجرا تحت ارزیابی تأثیر امنیتی قرار می‌گیرند.
 #10.9.3    سطح: 2    نقش: D/V
 تأیید کنید که مکانیسم‌های خودبهبودی شامل قابلیت‌های بازگشت به حالت قبلی همراه با تأیید صحت باشند.
 #10.9.4    سطح: 3    نقش: D/V
 تأیید کنید که امنیت متا-یادگیری از دستکاری مخرب الگوریتم‌های بهبود جلوگیری می‌کند.
 #10.9.5    سطح: 3    نقش: D/V
 تأیید کنید که بهبود بازگشتی خودکار تحت محدودیت‌های ایمنی رسمی محدود شده است با اثبات‌های ریاضی همگرایی.

---

#### مراجع

MITRE ATLAS adversary tactics for ML
NIST AI Risk Management Framework 1.0, 2023
OWASP Top 10 for LLM Applications, 2025
Adversarial Training: A Survey — Zhao et al., 2024
RobustBench adversarial-robustness benchmark
Membership-Inference & Model-Inversion Risk Survey, 2025
PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023
Model-Inversion Attacks & Defenses Survey — AI Review, 2025
Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024
Fragile Model Watermarking Survey — 2025
Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025
BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024

## 11 حفاظت از حریم خصوصی و مدیریت داده‌های شخصی

### هدف کنترل

اطمینان کامل از حفظ محرمانگی در سراسر چرخه عمر هوش مصنوعی—جمع‌آوری، آموزش، استنتاج، و پاسخ به رخداد—به‌گونه‌ای که داده‌های شخصی فقط با رضایت صریح، کمترین دامنه لازم، حذف قابل اثبات، و تضمین‌های رسمی حفظ حریم خصوصی پردازش شوند.

---

### 11.1 ناشناس‌سازی و حداقلسازی داده‌ها

 #11.1.1    سطح: 1    نقش: D/V
 تأیید کنید که شناسه‌های مستقیم و شبه‌شناسه‌ها حذف یا هش شده‌اند.
 #11.1.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که حسابرسی‌های خودکار، اندازه‌گیری k-ناشناس بودن/l-تنوع را انجام داده و زمانی که آستانه‌ها به زیر سیاست تنظیم شده کاهش می‌یابند، هشدار دهند.
 #11.1.3    سطح: 2    نقش: V
 تأیید کنید که گزارش‌های اهمیت ویژگی مدل نشان می‌دهند که نشتی شناسه فراتر از ε = 0.01 اطلاعات متقابل وجود ندارد.
 #11.1.4    سطح: 3    نقش: V
 تأیید کنید که اثبات‌های رسمی یا گواهی‌نامه داده‌های مصنوعی نشان‌دهنده خطر بازشناسایی ≤ 0.05 حتی تحت حملات لینک‌سازی باشند.

---

### 11.2 حق فراموش شدن و اجرای حذف

 #11.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که درخواست‌های حذف داده‌های موضوعی به داده‌های خام، نقاط بازشناسی، جاسازی‌ها، گزارش‌ها و نسخه‌های پشتیبان، در چارچوب توافقات سطح سرویس کمتر از 30 روز منتقل می‌شوند.
 #11.2.2    سطح: 2    نقش: D
 تأیید کنید که رویه‌های «فراموشی ماشینی» به‌طور فیزیکی مجدداً آموزش می‌دهند یا حذف تقریبی را با استفاده از الگوریتم‌های فراموشی تایید شده انجام می‌دهند.
 #11.2.3    سطح: 2    نقش: V
 تأیید کنید که ارزیابی مدل-سایه ثابت می‌کند سوابق فراموش‌شده کمتر از 1٪ از خروجی‌ها را پس از فراموشی تحت تاثیر قرار می‌دهند.
 #11.2.4    سطح: 3    نقش: V
 تأیید کنید که رویدادهای حذف به صورت غیرقابل تغییر ثبت می‌شوند و برای تنظیم‌کنندگان قابل بازبینی هستند.

---

### 11.3 تدابیر حفظ حریم خصوصی متفاوت

 #11.3.1    سطح: 2    نقش: D/V
 تأیید کنید که داشبوردهای حسابداری از دست دادن حریم خصوصی هنگامی که مجموع ε از آستانه‌های سیاست فراتر می‌رود، هشدار دهند.
 #11.3.2    سطح: 2    نقش: V
 تأیید کنید که حسابرسی‌های حریم خصوصی به صورت جعبه سیاه، ε̂ را در حدود 10٪ از مقدار اعلام شده تخمین بزنند.
 #11.3.3    سطح: 3    نقش: V
 تأیید کنید که اثبات‌های رسمی تمامی تنظیم‌های دقیق پس از آموزش و جاسازی‌ها را پوشش می‌دهند.

---

### 11.4 محدودیت هدف و محافظت در برابر گسترش دامنه

 #11.4.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که هر مجموعه داده و نقطه بازبینی مدل دارای برچسب هدف قابل خواندن توسط ماشین باشد که با رضایت اصلی هم‌راستا باشد.
 #11.4.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مانیتورهای زمان اجرا پرس‌وجوهایی که با هدف اعلام شده ناسازگار هستند را تشخیص می‌دهند و باعث رد نرم می‌شوند.
 #11.4.3    سطح: 3    نقش: D
 اطمینان حاصل کنید که دروازه‌های سیاست به عنوان کد، از استقرار مجدد مدل‌ها به حوزه‌های جدید بدون بازبینی DPIA جلوگیری می‌کنند.
 #11.4.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که اثبات‌های ردیابی رسمی نشان می‌دهند هر چرخه عمر داده‌های شخصی در محدوده رضایت داده شده باقی می‌ماند.

---

### 11.5 مدیریت رضایت و ردیابی مبتنی بر مبنای قانونی

 #11.5.1    سطح: 1    نقش: D/V
 تأیید کنید که یک پلتفرم مدیریت رضایت (CMP) وضعیت پذیرفتن (opt-in)، هدف و دوره نگهداری را برای هر موضوع داده ثبت می‌کند.
 #11.5.2    سطح: 2    نقش: D
 تأیید کنید که APIها توکن‌های رضایت را افشا می‌کنند؛ مدل‌ها باید قبل از استنتاج، دامنه توکن را اعتبارسنجی کنند.
 #11.5.3    سطح: 2    نقش: D/V
 تأیید کنید که موافقت رد شده یا پس گرفته شده، خطوط پردازش را در عرض 24 ساعت متوقف می‌کند.

---

### 11.6 یادگیری فدرال با کنترل‌های حفظ حریم خصوصی

 #11.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که به‌روزرسانی‌های مشتری پیش از جمع‌بندی، شامل افزودن نویز محلی با حفظ حریم خصوصی تفاضلی هستند.
 #11.6.2    سطح: 2    نقش: D/V
 تأیید کنید که معیارهای آموزش دارای حفظ حریم خصوصی تفاضلی هستند و هرگز ضرر تک‌مشتری را فاش نمی‌کنند.
 #11.6.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که تجمیع مقاوم در برابر مسموم‌سازی (مانند Krum/Trimmed-Mean) فعال شده است.
 #11.6.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که اثبات‌های رسمی نشان‌دهنده بودجه کلی ε با کمتر از 5 واحد کاهش کارایی هستند.

---

#### مراجع

GDPR & AI Compliance Best Practices
EU Parliament Study on GDPR & AI, 2020
ISO 31700-1:2023 — Privacy by Design for Consumer Products
NIST Privacy Framework 1.1 (2025 Draft)
Machine Unlearning: Right-to-Be-Forgotten Techniques
A Survey of Machine Unlearning, 2024
Auditing DP-SGD — ArXiv 2024
DP-SGD Explained — PyTorch Blog
Purpose-Limitation for AI — IJLIT 2025
Data-Protection Considerations for AI — URM Consulting
Top Consent-Management Platforms, 2025
Secure Aggregation in DP Federated Learning — ArXiv 2024

## C12 نظارت، ثبت وقایع و شناسایی ناهنجاری

### هدف کنترل

این بخش الزامات ارائه دید بلادرنگ و قضایی نسبت به آنچه مدل و دیگر اجزای هوش مصنوعی می‌بینند، انجام می‌دهند و بازمی‌گردانند را ارائه می‌دهد، تا تهدیدات بتوانند شناسایی، اولویت‌بندی و از آنها یاد گرفته شود.

### C12.1 ثبت درخواست و پاسخ

 #12.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام دستورات کاربر و پاسخ‌های مدل با فراداده‌های مناسب (مانند زمان‌سنجی، شناسه کاربر، شناسه جلسه، نسخه مدل) ثبت شده‌اند.
 #12.1.2    سطح: 1    نقش: D/V
 بررسی کنید که لاگ‌ها در مخازن امن و دارای کنترل دسترسی با سیاست‌های نگهداری مناسب و روش‌های پشتیبان‌گیری ذخیره شوند.
 #12.1.3    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های ذخیره‌سازی لاگ، رمزنگاری در حالت استراحت و در انتقال را برای محافظت از اطلاعات حساس موجود در لاگ‌ها اعمال می‌کنند.
 #12.1.4    سطح: 1    نقش: D/V
 تأیید کنید که داده‌های حساس در درخواست‌ها و خروجی‌ها به‌طور خودکار قبل از ثبت لاگ، حذف یا مخفی می‌شوند، با قوانین قابل تنظیم برای حذف اطلاعات شناسایی شخصی (PII)، گواهی‌نامه‌ها و اطلاعات مالکیتی.
 #12.1.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تصمیمات سیاستی و اقدامات فیلترینگ ایمنی با جزئیات کافی ثبت می‌شوند تا امکان بررسی و اشکال‌زدایی سیستم‌های نظارت بر محتوا فراهم شود.
 #12.1.6    سطح: 2    نقش: D/V
 تأیید کنید که یکپارچگی گزارش‌ها از طریق مثلاً امضاهای رمزنگاری شده یا ذخیره‌سازی فقط‌نوشتنی محافظت می‌شود.

---

### C12.2 تشخیص و هشدار سوءاستفاده

 #12.2.1    سطح: 1    نقش: D/V
 تأیید کنید که سیستم الگوهای شناخته شده فرار از محدودیت (jailbreak)، تلاش‌های تزریق درخواست (prompt injection) و ورودی‌های خصمانه را با استفاده از شناسایی مبتنی بر امضا تشخیص داده و هشدار می‌دهد.
 #12.2.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم با استفاده از فرمت‌ها و پروتکل‌های استاندارد گزارش، با پلتفرم‌های موجود مدیریت اطلاعات و رویدادهای امنیتی (SIEM) ادغام می‌شود.
 #12.2.3    سطح: 2    نقش: D/V
 تأیید کنید که رویدادهای امنیتی غنی‌شده شامل زمینه‌های خاص هوش مصنوعی مانند شناسه‌های مدل، نمره‌های اطمینان، و تصمیمات فیلتر ایمنی باشد.
 #12.2.4    سطح: 2    نقش: D/V
 تأیید کنید که تشخیص ناهنجاری رفتاری الگوهای غیرمعمول مکالمه، تلاش‌های مکرر بیش از حد یا رفتارهای کاوش سیستماتیک را شناسایی می‌کند.
 #12.2.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های هشدار به‌صورت زنده تیم‌های امنیتی را هنگام شناسایی نقض‌های احتمالی سیاست یا تلاش‌های حمله آگاه می‌کنند.
 #12.2.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که قوانین سفارشی برای شناسایی الگوهای تهدید خاص هوش مصنوعی از جمله تلاش‌های هماهنگ برای فرار از محدودیت‌ها (jailbreak)، کمپین‌های تزریق پرامپت و حملات استخراج مدل گنجانده شده‌اند.
 #12.2.7    سطح: 3    نقش: D/V
 تأیید کنید که گردش‌کارهای پاسخ خودکار به حادثه می‌توانند مدل‌های به‌خطر افتاده را جدا کنند، کاربران مخرب را مسدود کنند، و رویدادهای امنیتی بحرانی را ارتقا دهند.

---

### کشف تغییر مدل C12.3

 #12.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم معیارهای اساسی عملکرد مانند دقت، امتیازهای اطمینان، تأخیر و نرخ خطا را در نسخه‌های مدل و دوره‌های زمانی مختلف ردیابی می‌کند.
 #12.3.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که هشدار خودکار هنگامی که شاخص‌های عملکرد از آستانه‌های تخریب از پیش تعریف شده فراتر می‌روند یا به طور قابل توجهی از خطوط مبنا منحرف می‌شوند، فعال می‌شود.
 #12.3.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مانیتورهای تشخیص هذیان، مواردی را که خروجی‌های مدل حاوی اطلاعات نادرست، ناسازگار یا ساختگی هستند، شناسایی کرده و علامت‌گذاری می‌کنند.

---

### C12.4 عملکرد و تله‌متری رفتار

 #12.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که معیارهای عملیاتی از جمله تأخیر درخواست، مصرف توکن، استفاده از حافظه، و توان عملیاتی به طور مداوم جمع‌آوری و نظارت می‌شوند.
 #12.4.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که نرخ‌های موفقیت و شکست با دسته‌بندی انواع خطاها و علل اصلی آنها ردیابی می‌شوند.
 #12.4.3    سطح: 2    نقش: D/V
 تأیید کنید که پایش استفاده از منابع شامل مصرف GPU/CPU، مصرف حافظه و نیازهای ذخیره‌سازی باشد و هشداردهی در هنگام عبور از آستانه‌ها انجام شود.

---

### C12.5 برنامه‌ریزی و اجرای واکنش به حوادث هوش مصنوعی

 #12.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که برنامه‌های واکنش به حادثه به‌طور خاص حوادث امنیتی مرتبط با هوش مصنوعی از جمله نفوذ به مدل، آلوده‌سازی داده‌ها و حملات خصمانه را مورد بررسی قرار می‌دهند.
 #12.5.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تیم‌های واکنش به حوادث به ابزارها و تخصص‌های خاص جرم‌شناسی هوش مصنوعی دسترسی داشته باشند تا رفتار مدل و مسیرهای حمله را بررسی کنند.
 #12.5.3    سطح: 3    نقش: D/V
 تأیید کنید که تحلیل پس از حادثه شامل ملاحظات بازآموزی مدل، به‌روزرسانی فیلترهای ایمنی، و ادغام درس‌های آموخته شده در کنترل‌های امنیتی باشد.

---

### C12.5 تشخیص کاهش عملکرد هوش مصنوعی

نظارت و شناسایی کاهش عملکرد و کیفیت مدل هوش مصنوعی در طول زمان.

 #12.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که دقت مدل، دقت (precision)، بازیابی (recall) و نمره F1 به طور مداوم پایش شده و با آستانه‌های پایه مقایسه می‌شوند.
 #12.5.2    سطح: 1    نقش: D/V
 تأیید کنید که تشخیص انحراف داده تغییرات توزیع ورودی را که ممکن است بر عملکرد مدل تأثیر بگذارد، نظارت می‌کند.
 #12.5.3    سطح: 2    نقش: D/V
 تأیید کنید که تشخیص تغییر مفهوم، تغییرات در رابطه بین ورودی‌ها و خروجی‌های مورد انتظار را شناسایی می‌کند.
 #12.5.4    سطح: 2    نقش: D/V
 تأیید کنید که افت عملکرد باعث فعال‌سازی هشدارهای خودکار شده و روندهای بازآموزی یا جایگزینی مدل را آغاز می‌کند.
 #12.5.5    سطح: 3    نقش: V
 تأیید کنید که تحلیل ریشه‌ای کاهش عملکرد ارتباط بین کاهش عملکرد را با تغییرات داده‌ها، مشکلات زیرساخت یا عوامل خارجی برقرار می‌کند.

---

### C12.6 تجسم DAG و امنیت جریان کاری

سیستم‌های تصویری‌سازی جریان‌کار را در برابر نشت اطلاعات و حملات دستکاری محافظت کنید.

 #12.6.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که داده‌های مصورسازی DAG پاک‌سازی شده‌اند تا اطلاعات حساس قبل از ذخیره‌سازی یا انتقال حذف شوند.
 #12.6.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که کنترل‌های دسترسی به مصورسازی جریان کاری تضمین می‌کنند تنها کاربران مجاز قادر به مشاهده مسیرهای تصمیم‌گیری عامل و ردگیری‌های استدلالی باشند.
 #12.6.3    سطح: 2    نقش: D/V
 تأیید کنید که یکپارچگی داده‌های DAG از طریق امضاهای رمزنگاری شده و مکانیزم‌های ذخیره‌سازی مقاوم در برابر دستکاری محافظت می‌شود.
 #12.6.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های تجسم گردش کار، اعتبارسنجی ورودی را پیاده‌سازی می‌کنند تا از حملات تزریق از طریق داده‌های ساختاریافته گره یا یال جلوگیری شود.
 #12.6.5    سطح: 3    نقش: D/V
 تأیید کنید که به‌روزرسانی‌های DAG در زمان واقعی دارای محدودیت نرخ و اعتبارسنجی شده‌اند تا از حملات انکار سرویس به سیستم‌های تصویری جلوگیری شود.

---

### C12.7 نظارت پیشگیرانه بر رفتارهای امنیتی

شناسایی و پیشگیری از تهدیدات امنیتی از طریق تحلیل رفتار پیشگیرانه عامل.

 #12.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که رفتارهای عامل پیشگیرانه قبل از اجرا با ارزیابی ریسک یکپارچه شده، از نظر امنیتی تأیید شده‌اند.
 #12.7.2    سطح: 2    نقش: D/V
 تأیید کنید که محرک‌های ابتکار خودمختار شامل ارزیابی زمینه امنیتی و ارزیابی منظره تهدیدات می‌شود.
 #12.7.3    سطح: 2    نقش: D/V
 تأیید کنید که الگوهای رفتار پیش‌دستانه برای پیامدهای احتمالی امنیتی و عواقب ناخواسته تجزیه و تحلیل شوند.
 #12.7.4    سطح: 3    نقش: D/V
 تأیید کنید که اقدامات پیشگیرانه بحرانی امنیتی نیازمند زنجیره‌های تصویب صریح با ردپاهای حسابرسی هستند.
 #12.7.5    سطح: 3    نقش: D/V
 تأیید کنید که شناسایی ناهنجاری رفتاری انحرافات در الگوهای عامل فعال را که ممکن است نشانه‌ی نفوذ باشد، تشخیص می‌دهد.

---

### مراجع

NIST AI Risk Management Framework 1.0 - Manage 4.1 and 4.3
ISO/IEC 42001:2023 — AI Management Systems Requirements - Annex B 6.2.6
EU AI Act — Article 12, 13, 16 and 19 on Logging and Record-keeping

## C13 نظارت انسانی، مسئولیت‌پذیری و حاکمیت

### هدف کنترل

این فصل نیازمندی‌هایی را برای حفظ نظارت انسانی و زنجیره‌های واضح پاسخگویی در سیستم‌های هوش مصنوعی ارائه می‌دهد و اطمینان حاصل می‌کند که توضیح‌پذیری، شفافیت و مدیریت اخلاقی در سراسر چرخه عمر هوش مصنوعی رعایت شود.

---

### C13.1 مکانیزم‌های قتل-سوییچ و لغو کنترل

زمانی که رفتار ناایمن سیستم هوش مصنوعی مشاهده شد، مسیرهای خاموش‌سازی یا بازگشت (rollback) را فراهم کنید.

 #13.1.1    سطح: 1    نقش: D/V
 تأیید کنید که یک مکانیزم کشتن دستی وجود دارد که فوراً استنتاج و خروجی‌های مدل هوش مصنوعی را متوقف کند.
 #13.1.2    سطح: 1    نقش: D
 تأیید کنید که کنترل‌های بازنویسی فقط برای افراد مجاز قابل دسترسی باشند.
 #13.1.3    سطح: 3    نقش: D/V
 تأیید کنید که رویه‌های بازگردانی (rollback) قادر به بازگشت به نسخه‌های قبلی مدل یا عملیات حالت امن باشند.
 #13.1.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که مکانیسم‌های بازنویسی به طور منظم آزمایش می‌شوند.

---

### C13.2 نقاط بررسی تصمیم‌گیری با دخالت انسان در حلقه

زمانی که میزان ریسک از حد آستانه‌های از پیش تعریف‌شده فراتر رود، نیاز به تایید انسانی است.

 #13.2.1    سطح: 1    نقش: D/V
 تأیید کنید که تصمیمات با ریسک بالا در هوش مصنوعی قبل از اجرا نیاز به تأیید صریح انسانی دارند.
 #13.2.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که آستانه‌های ریسک به‌وضوح تعریف شده‌اند و به‌صورت خودکار روندهای بررسی توسط انسان را فعال می‌کنند.
 #13.2.3    سطح: 2    نقش: D
 تأیید کنید که تصمیمات حساس به زمان دارای رویه‌های جایگزین باشند وقتی تأیید انسانی در بازه‌های زمانی مورد نیاز قابل دستیابی نباشد.
 #13.2.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که رویه‌های افزایش سطح، سطوح اختیارات واضح برای انواع مختلف تصمیم‌گیری یا دسته‌بندی‌های ریسک را تعریف می‌کنند، در صورت امکان.

---

### C13.3 زنجیره مسئولیت و قابلیت حسابرسی

ثبت اقدامات اپراتور و تصمیمات مدل.

 #13.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که همه تصمیمات سیستم هوش مصنوعی و مداخلات انسانی با زمان‌بندی، هویت کاربران و دلایل تصمیم ثبت می‌شوند.
 #13.3.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که لاگ‌های حسابرسی قابل تغییر نیستند و مکانیزم‌های صحت‌سنجی یکپارچگی را شامل می‌شوند.

---

### C13.4 تکنیک‌های هوش مصنوعی قابل توضیح

اهمیت ویژگی‌های سطحی، ضدواقعیت‌ها، و توضیحات محلی.

 #13.4.1    سطح: 1    نقش: D/V
 تأیید کنید که سیستم‌های هوش مصنوعی توضیحات پایه‌ای از تصمیمات خود را به صورت قابل فهم برای انسان ارائه می‌دهند.
 #13.4.2    سطح: 2    نقش: V
 تأیید کنید که کیفیت توضیح از طریق مطالعات و معیارهای ارزیابی انسانی مورد اعتبارسنجی قرار گرفته است.
 #13.4.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که امتیازهای اهمیت ویژگی یا روش‌های نسبت‌دهی (مانند SHAP، LIME و غیره) برای تصمیمات حیاتی در دسترس هستند.
 #13.4.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که توضیحات کانتر فاکتوال نشان می‌دهند چگونه ورودی‌ها می‌توانند برای تغییر نتایج تغییر یابند، در صورتی که برای مورد استفاده و دامنه کاربرد قابل اجرا باشد.

---

### C13.5 کارت‌های مدل و افشای استفاده

نگهداری کارت‌های مدل برای استفاده مورد نظر، معیارهای عملکرد و ملاحظات اخلاقی.

 #13.5.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که کارت‌های مدل موارد استفاده مورد نظر، محدودیت‌ها و حالت‌های شکست شناخته شده را مستند می‌کنند.
 #13.5.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که معیارهای عملکرد در موارد کاربردی مختلف مرتبط افشا شده‌اند.
 #13.5.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که ملاحظات اخلاقی، ارزیابی‌های سوگیری، ارزیابی‌های عدالت، ویژگی‌های داده‌های آموزشی و محدودیت‌های شناخته شده داده‌های آموزشی به‌طور مرتب مستندسازی و به‌روزرسانی می‌شوند.
 #13.5.4    سطح: 2    نقش: D/V
 تأیید کنید که کارت‌های مدل تحت کنترل نسخه قرار دارند و در طول چرخه عمر مدل با ردیابی تغییرات نگهداری می‌شوند.

---

### C13.6 کمی‌سازی عدم قطعیت

انتشار نمرات اطمینان یا معیارهای آنتروپی در پاسخ‌ها.

 #13.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که سیستم‌های هوش مصنوعی همراه با خروجی‌های خود نمرات اطمینان یا معیارهای عدم قطعیت را ارائه می‌دهند.
 #13.6.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که آستانه‌های عدم قطعیت باعث فعال شدن بازبینی انسانی اضافی یا مسیرهای تصمیم‌گیری جایگزین می‌شوند.
 #13.6.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که روش‌های کمیت‌سنجی عدم قطعیت کالیبره شده و در برابر داده‌های حقیقت زمینه‌ای اعتبارسنجی شده‌اند.
 #13.6.4    سطح: 3    نقش: D/V
 تأیید کنید که انتقال عدم قطعیت در فرآیندهای چند مرحله‌ای هوش مصنوعی حفظ می‌شود.

---

### C13.7 گزارش‌های شفافیت برای کاربر

اطلاعات دوره‌ای درباره حوادث، انحراف‌ها و استفاده از داده‌ها ارائه دهید.

 #13.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیاست‌های استفاده از داده و شیوه‌های مدیریت رضایت کاربران به وضوح برای ذینفعان اطلاع‌رسانی شده‌اند.
 #13.7.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که ارزیابی‌های تأثیر هوش مصنوعی انجام شده و نتایج آن در گزارش‌دهی گنجانده شده است.
 #13.7.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که گزارش‌های شفافیت منتشر شده به‌طور منظم، حوادث هوش مصنوعی و شاخص‌های عملیاتی را با جزئیات معقول افشا می‌کنند.

#### مراجع

EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
ISO/IEC 42001:2023 — AI Management Systems Requirements
NIST AI Risk Management Framework 1.0
NIST SP 800-53 Revision 5 — Security and Privacy Controls
A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)
Model Cards for Model Reporting (Mitchell et al., 2018)
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)
ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods
IEEE 7001-2021 — Transparency of Autonomous Systems
GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)
Human Oversight under Article 14 of the EU AI Act (Fink, 2025)

## پیوست الف: واژه‌نامه

این واژه‌نامه جامع، تعاریف اصطلاحات کلیدی هوش مصنوعی، یادگیری ماشین، و امنیت را که در سراسر AISVS به کار رفته‌اند ارائه می‌دهد تا وضوح و درک مشترک را تضمین کند.

مثال خصمانه: ورودی که عمداً طراحی شده تا مدل هوش مصنوعی را به اشتباه انداخته و معمولاً با افزودن اختلالات ظریف که برای انسان‌ها غیرقابل تشخیص هستند، انجام می‌شود.
​
استحکام مقابله‌ای – استحکام مقابله‌ای در هوش مصنوعی به توانایی یک مدل در حفظ عملکرد خود و مقاومت در برابر فریب دادن یا دستکاری با ورودی‌های عمدی و مخرب طراحی شده برای ایجاد خطا اشاره دارد.
​
عامل – عوامل هوش مصنوعی سیستم‌های نرم‌افزاری هستند که از هوش مصنوعی برای دنبال کردن اهداف و انجام وظایف به نمایندگی از کاربران استفاده می‌کنند. این عوامل دارای توانایی استدلال، برنامه‌ریزی و حافظه هستند و سطحی از خودمختاری برای تصمیم‌گیری، یادگیری و تطبیق دارند.
​
هوش مصنوعی عاملی: سیستم‌های هوش مصنوعی که می‌توانند با درجه‌ای از خودمختاری عمل کنند تا به اهداف دست یابند، که اغلب تصمیم‌گیری می‌کنند و بدون مداخله مستقیم انسان اقدامات انجام می‌دهند.
​
کنترل دسترسی مبتنی بر ویژگی (ABAC): یک پارادایم کنترل دسترسی که در آن تصمیمات اجازه دسترسی بر اساس ویژگی‌های کاربر، منبع، عمل و محیط، در زمان پرس‌وجو ارزیابی می‌شوند.
​
حمله درب پشتی: نوعی از حملات مسموم‌سازی داده که در آن مدل به گونه‌ای آموزش داده می‌شود که به محرک‌های خاص به طور مشخص پاسخ دهد در حالی که در سایر مواقع به طور عادی رفتار می‌کند.
​
جانبداری: خطاهای سیستماتیک در خروجی مدل هوش مصنوعی که می‌توانند به نتایج ناعادلانه یا تبعیض‌آمیز برای گروه‌های خاص یا در زمینه‌های خاص منجر شوند.
​
بهره‌برداری از سوگیری: یک تکنیک حمله که از سوگیری‌های شناخته‌شده در مدل‌های هوش مصنوعی برای دستکاری خروجی‌ها یا نتایج استفاده می‌کند.
​
سدار: زبان سیاست و موتور آمازون برای مجوزهای دقیق که در پیاده‌سازی ABAC برای سیستم‌های هوش مصنوعی استفاده می‌شود.
​
زنجیره تفکر: تکنیکی برای بهبود استدلال در مدل‌های زبان با تولید مراحل استدلال میانی قبل از ارائه پاسخ نهایی.
​
مدار شکن‌ها: مکانیزم‌هایی که به طور خودکار عملیات سیستم هوش مصنوعی را زمانی که آستانه‌های خطر خاصی فراتر می‌رود، متوقف می‌کنند.
​
نشتی داده: افشای ناخواسته اطلاعات حساس از طریق خروجی‌ها یا رفتار مدل هوش مصنوعی.
​
آلودگی داده: فساد عمدی داده‌های آموزشی برای به خطر انداختن صحت مدل، معمولاً برای نصب درهای پشتی یا کاهش عملکرد.
​
حریم خصوصی تفاضلی – حریم خصوصی تفاضلی چارچوبی ریاضیاتی دقیق برای انتشار اطلاعات آماری درباره مجموعه داده‌هاست در حالی که حریم خصوصی افراد حاضر در داده‌ها را حفظ می‌کند. این روش به دارنده داده اجازه می‌دهد الگوهای کلی گروه را به اشتراک بگذارد در حالی که اطلاعات فاش‌شده درباره افراد خاص را محدود می‌کند.
​
تعبیه‌ها: نمایش‌های برداری متراکم از داده‌ها (متن، تصاویر و غیره) که معنی معنایی را در فضای با ابعاد بالا ضبط می‌کنند.
​
قابل تفسیر بودن – قابل تفسیر بودن در هوش مصنوعی به توانایی یک سیستم هوش مصنوعی برای ارائه دلایل قابل فهم توسط انسان برای تصمیمات و پیش‌بینی‌های خود گفته می‌شود، که بینشی نسبت به عملکرد داخلی آن ارائه می‌دهد.
​
هوش مصنوعی قابل توضیح (XAI): سیستم‌های هوش مصنوعی که به گونه‌ای طراحی شده‌اند تا از طریق تکنیک‌ها و چارچوب‌های مختلف، توضیحات قابل فهم برای انسان درباره تصمیمات و رفتارهای خود ارائه دهند.
​
یادگیری فدراسیون شده: رویکردی در یادگیری ماشین که در آن مدل‌ها به‌صورت توزیع‌شده و بر روی چندین دستگاه غیرمتمرکز که نمونه‌های داده محلی را نگه می‌دارند، آموزش داده می‌شوند، بدون اینکه داده‌ها به خودی خود تبادل شوند.
​
گاردریل‌ها: محدودیت‌هایی که برای جلوگیری از تولید خروجی‌های مضر، مغرضانه یا به نحوی ناخواسته توسط سیستم‌های هوش مصنوعی اعمال می‌شوند.
​
توهم – توهم در هوش مصنوعی به مفهوم پدیده‌ای اشاره دارد که در آن یک مدل هوش مصنوعی اطلاعات نادرست یا گمراه‌کننده‌ای تولید می‌کند که بر اساس داده‌های آموزشی یا واقعیت‌های عینی نیست.
​
انسان-در-حلقه (HITL): سیستم‌هایی که به گونه‌ای طراحی شده‌اند که نیازمند نظارت، تایید، یا دخالت انسان در نقاط بحرانی تصمیم‌گیری باشند.
​
زیرساخت به عنوان کد (IaC): مدیریت و تأمین زیرساخت از طریق کد به جای فرآیندهای دستی، که امکان اسکن امنیتی و استقرارهای یکنواخت را فراهم می‌کند.
​
Jailbreak: تکنیک‌هایی که برای دور زدن محدودیت‌های ایمنی در سیستم‌های هوش مصنوعی، به ویژه در مدل‌های زبان بزرگ، جهت تولید محتوای ممنوعه استفاده می‌شوند.
​
کمترین امتیاز: اصل امنیتی اعطای حداقل دسترسی‌های لازم به کاربران و فرآیندها.
​
LIME (توضیحات محلی مدل‌ناشناس قابل تفسیر): یک تکنیک برای توضیح پیش‌بینی‌های هر طبقه‌بندی‌کننده یادگیری ماشین است که با تقریب دادن محلی آن با یک مدل قابل تفسیر انجام می‌شود.
​
حمله استنتاج عضویت: حمله‌ای که هدف آن تعیین این است که آیا یک نقطه داده خاص برای آموزش یک مدل یادگیری ماشین استفاده شده است یا نه.
​
MITRE ATLAS: چشم‌انداز تهدیدات خصمانه برای سیستم‌های هوش مصنوعی؛ یک پایگاه دانش از تاکتیک‌ها و تکنیک‌های خصمانه علیه سیستم‌های هوش مصنوعی.
​
کارت مدل – کارت مدل یک سند است که اطلاعات استاندارد شده درباره عملکرد یک مدل هوش مصنوعی، محدودیت‌ها، کاربردهای مورد نظر و ملاحظات اخلاقی آن را فراهم می‌کند تا شفافیت و توسعه مسئولانه هوش مصنوعی را ترویج دهد.
​
استخراج مدل: حمله‌ای که در آن یک مهاجم به طور مکرر از مدل هدف پرسش می‌کند تا یک کپی عملکردی مشابه بدون اجازه ایجاد کند.
​
وارونگی مدل: حمله‌ای که تلاش می‌کند با تحلیل خروجی‌های مدل، داده‌های آموزشی را بازسازی کند.
​
مدیریت چرخه عمر مدل – مدیریت چرخه عمر مدل هوش مصنوعی فرآیند نظارت بر تمام مراحل وجود یک مدل هوش مصنوعی است که شامل طراحی، توسعه، استقرار، پایش، نگهداری و در نهایت بازنشستگی آن می‌شود تا اطمینان حاصل شود که مدل همچنان مؤثر و هماهنگ با اهداف باقی می‌ماند.
​
سم‌پاشی مدل: وارد کردن آسیب‌پذیری‌ها یا درهای پشتی به طور مستقیم در یک مدل در طول فرآیند آموزش.
​
دزدی/سرقت مدل: استخراج یک نسخه یا تقریب از یک مدل اختصاصی از طریق پرسش‌های مکرر.
​
سیستم چندعامله: سیستمی متشکل از چندین عامل هوش مصنوعی که با یکدیگر تعامل دارند و هر کدام ممکن است قابلیت‌ها و اهداف متفاوتی داشته باشند.
​
OPA (Open Policy Agent): یک موتور سیاست متن‌باز است که اجرای یکنواخت سیاست‌ها را در سراسر پشته امکان‌پذیر می‌کند.
​
یادگیری ماشین حفظ حریم خصوصی (PPML): تکنیک‌ها و روش‌هایی برای آموزش و استقرار مدل‌های یادگیری ماشین در حالی که حریم خصوصی داده‌های آموزشی حفظ می‌شود.
​
تزریق پرامپت: حمله‌ای که در آن دستورات مخرب در ورودی‌ها جاسازی می‌شوند تا رفتار مورد نظر مدل را نادیده بگیرند.
​
RAG (تولید تقویت‌شده با بازیابی): تکنیکی که مدل‌های زبان بزرگ را با بازیابی اطلاعات مرتبط از منابع دانش خارجی قبل از تولید پاسخ تقویت می‌کند.
​
تیم قرمز: عملیاتی است که در آن به طور فعال سیستم‌های هوش مصنوعی با شبیه‌سازی حملات خصمانه تست می‌شوند تا آسیب‌پذیری‌ها شناسایی شوند.
​
SBOM (فهرست مواد نرم‌افزار): یک رکورد رسمی شامل جزئیات و روابط زنجیره تامین اجزای مختلف استفاده شده در ساخت نرم‌افزار یا مدل‌های هوش مصنوعی.
​
SHAP (توضیحات جمع‌پذیر شاپلی): یک رویکرد نظریه بازی‌ها برای تبیین خروجی هر مدل یادگیری ماشین از طریق محاسبه سهم هر ویژگی در پیش‌بینی.
​
حمله زنجیره تامین: به خطر انداختن یک سیستم با هدف قرار دادن عناصر کم‌امنیت‌تر در زنجیره تأمین آن، مانند کتابخانه‌های شخص ثالث، مجموعه داده‌ها، یا مدل‌های از پیش آموزش‌دیده شده.
​
یادگیری انتقالی: تکنیکی که در آن یک مدل توسعه یافته برای یک وظیفه به عنوان نقطه شروع برای مدلی در وظیفه دوم دوباره مورد استفاده قرار می‌گیرد.
​
پایگاه داده وکتور: یک پایگاه داده تخصصی طراحی شده برای ذخیره بردارهای با بعد بالا (امبدینگ‌ها) و انجام جستجوهای مشابهت بهینه.
​
اسکن آسیب‌پذیری: ابزارهای خودکاری که آسیب‌پذیری‌های امنیتی شناخته شده در اجزای نرم‌افزاری، از جمله چارچوب‌های هوش مصنوعی و وابستگی‌ها را شناسایی می‌کنند.
​
واترمارکینگ: تکنیک‌هایی برای قرار دادن نشانگرهای غیرقابل تشخیص در محتوای تولید شده توسط هوش مصنوعی به منظور ردیابی منبع آن یا شناسایی تولید توسط هوش مصنوعی.
​
آسیب‌پذیری روز صفر: یک آسیب‌پذیری ناشناخته قبلی که مهاجمان می‌توانند قبل از اینکه توسعه‌دهندگان وصله‌ای ایجاد و مستقر کنند، از آن بهره‌برداری کنند.

## پیوست ب: منابع

### TODO

## پیوست ج: حاکمیت و مستندسازی امنیت هوش مصنوعی

### هدف

این پیوست الزامات پایه‌ای برای ایجاد ساختارهای سازمانی، سیاست‌ها و فرآیندها جهت مدیریت امنیت هوش مصنوعی در طول چرخه عمر سیستم را فراهم می‌کند.

---

### پذیرش چارچوب مدیریت ریسک هوش مصنوعی AC.1

ارائه یک چارچوب رسمی برای شناسایی، ارزیابی و کاهش خطرات خاص هوش مصنوعی در طول چرخه عمر سیستم.

 #AC.1.1    سطح: 1    نقش: D/V
 تأیید کنید که یک روش‌شناسی ارزیابی ریسک خاص هوش مصنوعی مستندسازی و اجرا شده است.
 #AC.1.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که ارزیابی‌های ریسک در نقاط کلیدی در چرخه عمر هوش مصنوعی و پیش از تغییرات مهم انجام می‌شوند.
 #AC.1.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که چارچوب مدیریت ریسک با استانداردهای تعیین شده (مانند NIST AI RMF) هم‌راستا است.

---

### AC.2 سیاست‌ها و رویه‌های امنیت هوش مصنوعی

تعریف و اعمال استانداردهای سازمانی برای توسعه، استقرار و عملیات امن هوش مصنوعی.

 #AC.2.1    سطح: 1    نقش: D/V
 تأیید کنید که سیاست‌های مستند امنیت هوش مصنوعی وجود دارد.
 #AC.2.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که سیاست‌ها حداقل سالیانه و پس از تغییرات قابل توجه در چشم‌انداز تهدیدات، مرور و به‌روزرسانی می‌شوند.
 #AC.2.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که سیاست‌ها تمام دسته‌های AISVS و الزامات نظارتی قابل اجرا را پوشش می‌دهند.

---

### AC.3 نقش‌ها و مسئولیت‌ها برای امنیت هوش مصنوعی

ایجاد مسئولیت شفاف برای امنیت هوش مصنوعی در سراسر سازمان.

 #AC.3.1    سطح: 1    نقش: D/V
 بررسی کنید که نقش‌ها و مسئولیت‌های امنیتی هوش مصنوعی مستند شده باشند.
 #AC.3.2    سطح: 2    نقش: D
 تأیید کنید که افراد مسئول دارای تخصص امنیتی مناسب هستند.
 #AC.3.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که یک کمیته اخلاق هوش مصنوعی یا هیئت حکمرانی برای سیستم‌های هوش مصنوعی با ریسک بالا تأسیس شده است.

---

### اجرای دستورالعمل‌های اخلاقی هوش مصنوعی AC.4

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی بر اساس اصول اخلاقی تثبیت‌شده عمل می‌کنند.

 #AC.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که دستورالعمل‌های اخلاقی برای توسعه و استقرار هوش مصنوعی وجود دارد.
 #AC.4.2    سطح: 2    نقش: D
 تأیید کنید که مکانیزم‌هایی برای شناسایی و گزارش تخلفات اخلاقی وجود دارد.
 #AC.4.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که بررسی‌های منظم اخلاقی سیستم‌های هوش مصنوعی پیاده‌سازی شده انجام می‌شود.

---

### AC.5 نظارت بر انطباق مقرراتی هوش مصنوعی

آگاهی و رعایت مقررات در حال تحول هوش مصنوعی را حفظ کنید.

 #AC.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که فرآیندهایی برای شناسایی مقررات مربوط به هوش مصنوعی وجود دارند.
 #AC.5.2    سطح: 2    نقش: D
 تأیید کنید که انطباق با تمامی الزامات قانونی مورد ارزیابی قرار گرفته است.
 #AC.5.3    سطح: 3    نقش: D/V
 تأیید کنید که تغییرات مقرراتی موجب بررسی‌ها و به‌روزرسانی‌های به موقع سیستم‌های هوش مصنوعی می‌شوند.

### AC.6 حکمرانی داده‌های آموزشی، مستندسازی و فرایند

 #1.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تنها مجموعه داده‌هایی که از نظر کیفیت، نمایندگی، منبع‌یابی اخلاقی و رعایت مجوز تأیید شده‌اند، مجاز باشند، تا ریسک‌های مسمومیت، تعصب نهفته و تخلف از حقوق مالکیت فکری کاهش یابد.
 #1.1.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که کیفیت برچسب‌گذاری/حاشیه‌نویسی از طریق بازبینی و بررسی متقابل یا اجماع تایید می‌شود.
 #1.1.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که «کارت‌های داده» یا «برگه‌های داده برای مجموعه‌های داده» برای مجموعه‌های داده آموزشی مهم نگهداری می‌شوند، که ویژگی‌ها، انگیزه‌ها، ترکیب، فرآیندهای جمع‌آوری، پیش‌پردازش، و استفاده‌های توصیه‌شده/ناکافی را به‌صورت دقیق شرح می‌دهند.
 #1.3.2    سطح: 2    نقش: D/V
 تأیید کنید که سوگیری‌های شناسایی‌شده از طریق استراتژی‌های مستند شده مانند تعادل مجدد، افزایش هدفمند داده‌ها، تنظیمات الگوریتمی (مثلاً تکنیک‌های پیش‌پردازش، پردازش درون‌خطی، پس‌پردازش) یا وزن‌دهی مجدد کاهش یافته‌اند و تأثیر کاهش سوگیری هم بر عدالت و هم بر عملکرد کلی مدل ارزیابی شده است.
 #1.3.3    سطح: 2    نقش: D/V
 تأیید کنید که معیارهای عدالت پس از آموزش ارزیابی و مستندسازی شده‌اند.
 #1.3.4    سطح: 3    نقش: D/V
 تأیید کنید که یک سیاست مدیریت سوگیری چرخه عمر، مالک‌ها و دوره بازبینی را تعیین می‌کند.
 #1.4.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که کیفیت برچسب‌گذاری/حاشیه‌نویسی از طریق دستورالعمل‌های واضح، بررسی‌های متقابل بازبینان، مکانیسم‌های اجماع (مثلاً نظارت بر توافق بین حاشیه‌نویسان) و فرایندهای تعریف‌شده برای حل اختلافات تضمین شده است.
 #1.4.4    سطح: 3    نقش: D/V
 تأیید کنید که برچسب‌های حیاتی برای ایمنی، امنیت یا انصاف (مانند شناسایی محتوای سمی، یافته‌های پزشکی بحرانی) تحت بازبینی مستقل دوگانه اجباری یا معادل آن با تایید قوی قرار می‌گیرند.
 #1.4.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که راهنمای برچسب‌گذاری و دستورالعمل‌ها کامل، تحت کنترل نسخه و توسط همتایان بررسی شده باشند.
 #1.4.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که طرح‌های داده برای برچسب‌ها به‌وضوح تعریف شده‌اند و مدیریت نسخه دارند.
 #1.3.1    سطح: 1    نقش: D/V
 تأیید کنید که داده‌ها برای عدم تعادل نمایشی و تعصبات احتمالی در سراسر ویژگی‌های محافظت‌شده قانونی (مانند نژاد، جنسیت، سن) و سایر ویژگی‌های حساس اخلاقی مرتبط با حوزه کاربرد مدل (مانند وضعیت اقتصادی-اجتماعی، محل سکونت) پروفایل شده باشند.
 #1.5.3    سطح: 2    نقش: V
 تأیید کنید که بررسی‌های دستی نقطه‌ای توسط کارشناسان حوزه، نمونه‌ای با اهمیت آماری را پوشش می‌دهد (مثلاً ≥1٪ یا 1,000 نمونه، هر کدام که بزرگتر باشد، یا بر اساس ارزیابی ریسک تعیین شده باشد) تا مشکلات ظریف کیفیت که توسط اتوماسیون شناسایی نشده‌اند را شناسایی کند.
 #1.8.4    سطح: 2    نقش: D/V
 تأیید کنید که جریان‌های کاری برچسب‌گذاری برون‌سپاری شده یا جمع‌سپاری شده شامل تدابیر فنی/روال‌های حفاظتی برای اطمینان از محرمانگی داده‌ها، صحت داده‌ها، کیفیت برچسب‌ها و جلوگیری از نشت داده‌ها هستند.
 #1.5.4    سطح: 2    نقش: D/V
 تأیید کنید که مراحل اصلاح به سوابق منشا افزوده شده‌اند.
 #1.6.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که نمونه‌های علامت‌گذاری شده قبل از آموزش، بازبینی دستی را فعال می‌کنند.
 #1.6.3    سطح: 2    نقش: V
 تأیید کنید که نتایج به پرونده امنیتی مدل وارد شده و اطلاعات تهدیدات در حال انجام را مطلع سازد.
 #1.6.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که منطق تشخیص با اطلاعات تهدید جدید به‌روزرسانی شده است.
 #1.6.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که خطوط پردازش یادگیری آنلاین تغییر توزیع داده‌ها را کنترل می‌کنند.
 #1.7.1    سطح: 1    نقش: D/V
 تأیید کنید که گردش‌های کاری حذف داده‌های آموزشی داده‌های اصلی و مشتق شده را پاک می‌کنند و تأثیر آن بر مدل ارزیابی می‌شود، و همچنین تأثیر بر مدل‌های متاثر شده بررسی شده و در صورت لزوم رفع می‌شود (مثلاً از طریق بازآموزی یا بازتنظیم).
 #1.7.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که مکانیزم‌هایی برای پیگیری و رعایت دامنه و وضعیت رضایت کاربر (و کنسلی‌ها) برای داده‌های مورد استفاده در آموزش وجود دارد و اینکه رضایت قبل از وارد کردن داده‌ها به فرایندهای آموزش جدید یا به‌روزرسانی‌های مهم مدل تأیید می‌شود.
 #1.7.3    سطح: 2    نقش: V
 تأیید کنید که گردش‌های کاری سالانه آزمایش شده و ثبت می‌شوند.
 #1.8.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تأمین‌کنندگان داده‌های ثالث، از جمله ارائه‌دهندگان مدل‌های پیش‌آموزش‌دیده و مجموعه داده‌های خارجی، قبل از ادغام داده‌ها یا مدل‌هایشان، تحت بررسی‌های لازم در زمینه امنیت، حریم خصوصی، تأمین اخلاقی و کیفیت داده قرار گرفته‌اند.
 #1.8.2    سطح: 1    نقش: D
 تأیید کنید که انتقالات خارجی از TLS/احراز هویت و بررسی‌های صحت استفاده می‌کنند.
 #1.8.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که منابع داده پرخطر (به عنوان مثال، مجموعه داده‌های متن‌باز با منشأ ناشناخته، تأمین‌کنندگان تاییدنشده) قبل از استفاده در کاربردهای حساس، تحت بررسی‌های دقیق‌تری مانند تحلیل در محیط ایزوله، بررسی‌های گسترده کیفیت/تبعیض، و تشخیص هدفمند سم‌زدایی قرار گیرند.
 #1.8.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مدل‌های پیش‌آموزش‌دیده شده که از طرف‌های ثالث به دست آمده‌اند، قبل از تنظیم مجدد یا استقرار، از نظر تعصبات نهفته، پشتی‌های پنهان احتمالی، صحت ساختار آنها و منشاء داده‌های آموزشی اولیه‌شان ارزیابی شده باشند.
 #1.5.3    سطح: 2    نقش: D/V
 تأیید کنید که در صورت استفاده از آموزش خصمانه، تولید، مدیریت و نسخه‌بندی مجموعه‌داده‌های خصمانه مستند شده و کنترل می‌شوند.
 #1.5.3    سطح: 3    نقش: D/V
 اطمینان حاصل شود که تأثیر آموزش مقاوم‌سازی دربرابر حملات خصمانه بر عملکرد مدل (در برابر ورودی‌های تمیز و خصمانه) و شاخص‌های عدالت بررسی، مستند و پایش می‌شود.
 #1.5.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که استراتژی‌های آموزش خصمانه و مقاومت به طور دوره‌ای بازبینی و به‌روزرسانی می‌شوند تا با تکنیک‌های در حال توسعه حملات خصمانه مقابله کنند.
 #1.4.2    سطح: 2    نقش: D/V
 تأیید کنید که داده‌های ناموفق با ردپای حسابرسی قرنطینه شده‌اند.
 #1.4.3    سطح: 2    نقش: D/V
 تأیید کنید که دروازه‌های کیفیت، مجموعه داده‌های کم‌کیفیت را مسدود می‌کنند مگر اینکه استثنائات تأیید شده باشند.
 #1.11.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فرایند تولید، پارامترها و استفاده مورد نظر از داده‌های مصنوعی مستندسازی شده‌اند.
 #1.11.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که داده‌های مصنوعی قبل از استفاده در آموزش، از نظر ریسک‌های جانبداری، نشت حریم خصوصی و مسائل نمایشی مورد ارزیابی قرار گرفته‌اند.
 #1.12.3    سطح: 2    نقش: D/V
 بررسی کنید که هشدارهایی برای رویدادهای دسترسی مشکوک ایجاد شده و به سرعت مورد بررسی قرار گیرند.
 #1.13.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که دوره‌های نگهداری صریح برای تمام مجموعه داده‌های آموزش تعریف شده‌اند.
 #1.13.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که داده‌ها در پایان دوره عمرشان به طور خودکار منقضی، حذف یا برای حذف بررسی می‌شوند.
 #1.13.3    سطح: 2    نقش: D/V
 تأیید کنید که اقدامات نگهداری و حذف ثبت و قابل حسابرسی باشند.
 #1.14.1    سطح: 2    نقش: D/V
 تأیید کنید که الزامات محل نگهداری داده و انتقال فرامرزی برای تمامی مجموعه داده‌ها شناسایی و اجرا شده باشند.
 #1.14.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مقررات خاص بخش‌ها (مانند مراقبت‌های بهداشتی، مالی) در مدیریت داده‌ها شناسایی و مورد توجه قرار گرفته‌اند.
 #1.14.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که رعایت قوانین مرتبط با حفظ حریم خصوصی (مانند GDPR، CCPA) مستندسازی شده و به‌طور منظم بازبینی می‌شود.
 #1.16.1    سطح: 2    نقش: D/V
 تأیید کنید که مکانیسم‌هایی برای پاسخ به درخواست‌های موضوع داده‌ها جهت دسترسی، اصلاح، محدودیت یا اعتراض وجود دارد.
 #1.16.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که درخواست‌ها در چارچوب زمانی تعیین‌شده قانونی ثبت، پیگیری و انجام می‌شوند.
 #1.16.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فرآیندهای حقوق موضوع داده به طور منظم برای اثربخشی آزمایش و بررسی می‌شوند.
 #1.17.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که قبل از به‌روزرسانی یا جایگزینی نسخه یک مجموعه داده، تحلیل اثر انجام شده باشد که شامل عملکرد مدل، عدالت و تطابق می‌باشد.
 #1.17.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که نتایج تحلیل تأثیرات مستندسازی شده و توسط ذینفعان مربوطه بازبینی شده‌اند.
 #1.17.3    سطح: 2    نقش: D/V
 تأیید کنید که برنامه‌های بازگشت وجود دارند در صورتی که نسخه‌های جدید ریسک‌ها یا پسرفت‌های غیرقابل قبول را ایجاد کنند.
 #1.18.1    سطح: 2    نقش: D/V
 تأیید کنید که تمام کارکنان درگیر در برچسب‌گذاری داده‌ها، پیش‌زمینه چک شده و در امنیت داده‌ها و حریم خصوصی آموزش دیده باشند.
 #1.18.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تمام پرسنل حاشیه‌نویسی قراردادهای محرمانگی و عدم افشای اطلاعات را امضا کرده‌اند.
 #1.18.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که پلتفرم‌های حاشیه‌نویسی کنترل‌های دسترسی را اعمال می‌کنند و تهدیدات داخلی را نظارت می‌کنند.

#### مراجع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
EU Artificial Intelligence Act — Regulation (EU) 2024/1689
ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods

## پیوست D: حاکمیت و تایید کدگذاری امن با کمک هوش مصنوعی

### هدف

این فصل کنترل‌های سازمانی پایه را برای استفاده ایمن و مؤثر از ابزارهای کدنویسی همراه با هوش مصنوعی در طول توسعه نرم‌افزار تعریف می‌کند، به‌گونه‌ای که امنیت و قابلیت ردیابی در سراسر چرخه حیات توسعه نرم‌افزار (SDLC) تضمین شود.

---

### AD.1 جریان کاری کدنویسی ایمن با کمک هوش مصنوعی

ادغام ابزارهای هوش مصنوعی در چرخه عمر توسعه نرم‌افزار امن سازمان (SSDLC) بدون تضعیف دروازه‌های امنیتی موجود.

 #AD.1.1    سطح: 1    نقش: D/V
 تأیید کنید که یک گردش کار مستند شده توضیح می‌دهد چه زمانی و چگونه ابزارهای هوش مصنوعی ممکن است کد تولید، بازسازی یا بازبینی کنند.
 #AD.1.2    سطح: 2    نقش: D
 تأیید کنید که جریان کاری به هر مرحله از SSDLC (طراحی، پیاده‌سازی، بازبینی کد، تست، استقرار) نگاشت شده است.
 #AD.1.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که معیارها (مانند چگالی آسیب‌پذیری، میانگین زمان تشخیص) بر روی کد تولید شده توسط هوش مصنوعی جمع‌آوری شده و با مبناهای صرفاً انسانی مقایسه می‌شوند.

---

### AD.2 ارزیابی ابزار هوش مصنوعی و مدل‌سازی تهدید

اطمینان حاصل کنید که ابزارهای برنامه‌نویسی هوش مصنوعی پیش از استفاده از نظر قابلیت‌های امنیتی، ریسک و تأثیر زنجیره تأمین ارزیابی شوند.

 #AD.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مدل تهدید برای هر ابزار هوش مصنوعی سوءاستفاده، وارونگی مدل، نشت داده‌ها و ریسک‌های زنجیره وابستگی را شناسایی کند.
 #AD.2.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که ارزیابی‌های ابزار شامل تحلیل استاتیک/دینامیک هر مؤلفه محلی و ارزیابی نقاط انتهایی SaaS (TLS، احراز هویت/مجوزدهی، ثبت لاگ) باشد.
 #AD.2.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که ارزیابی‌ها طبق یک چارچوب معتبر انجام می‌شوند و پس از تغییرات عمده نسخه دوباره انجام می‌شوند.

---

### مدیریت امن فرمان و زمینه AD.3

جلوگیری از نشت اسرار، کد اختصاصی و داده‌های شخصی هنگام ساختن پرامپت‌ها یا زمینه‌ها برای مدل‌های هوش مصنوعی.

 #AD.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که دستورالعمل‌های کتبی ارسال اسرار، اطلاعات احراز هویت یا داده‌های محرمانه را در درخواست‌ها ممنوع می‌کند.
 #AD.3.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که کنترل‌های فنی (حذف خودکار سمت مشتری، فیلترهای زمینه تأیید شده) به‌طور خودکار موارد حساس را حذف می‌کنند.
 #AD.3.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که دستورات و پاسخ‌ها توکنیزه شده، در حین انتقال و در حالت استراحت رمزگذاری شده‌اند و دوره‌های نگهداری با سیاست طبقه‌بندی داده‌ها مطابقت دارند.

---

### AD.4 اعتبارسنجی کد تولید شده توسط هوش مصنوعی

شناسایی و رفع آسیب‌پذیری‌های ایجاد شده توسط خروجی هوش مصنوعی قبل از ادغام یا استقرار کد.

 #AD.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که کد تولید شده توسط هوش مصنوعی همیشه تحت بازبینی کد توسط انسان قرار گیرد.
 #AD.4.2    سطح: 2    نقش: D
 تأیید کنید که اسکنرهای خودکار (SAST/IAST/DAST) روی هر درخواست کششی که شامل کد تولید شده توسط هوش مصنوعی است اجرا شوند و ادغام‌ها را در صورت وجود یافته‌های بحرانی مسدود کنند.
 #AD.4.3    سطح: 3    نقش: D/V
 تأیید کنید که آزمایش فازینگ تفاضلی یا تست‌های مبتنی بر ویژگی، رفتارهای حیاتی امنیتی (مثلاً اعتبارسنجی ورودی، منطق مجوزدهی) را ثابت می‌کنند.

---

### AD.5 توضیح‌پذیری و قابلیت ردیابی پیشنهادات کد

به حسابرسان و توسعه‌دهندگان بینشی ارائه دهید که چرا یک پیشنهاد ارائه شده است و چگونه تکامل یافته است.

 #AD.5.1    سطح: 1    نقش: D/V
 تأیید کنید که جفت‌های درخواست/پاسخ با شناسه‌های تعهد (commit IDs) ثبت می‌شوند.
 #AD.5.2    سطح: 2    نقش: D
 تأیید کنید که توسعه‌دهندگان قادر به نمایش استنادهای مدل (قطعات آموزش، مستندات) که پیشنهاد را پشتیبانی می‌کنند، باشند.
 #AD.5.3    سطح: 3    نقش: D/V
 تأیید کنید که گزارش‌های قابلیت توضیح همراه با مصنوعات طراحی ذخیره شده و در بازبینی‌های امنیتی به آنها اشاره شده است، به‌طوری که اصول ردیابی ISO/IEC 42001 را برآورده سازد.

---

### AD.6 بازخورد مداوم و بهینه‌سازی مدل

بهبود عملکرد امنیت مدل در طول زمان در حالی که از انحراف منفی جلوگیری می‌شود.

 #AD.6.1    سطح: 1    نقش: D/V
 بررسی کنید که توسعه‌دهندگان قادر به علامت‌گذاری پیشنهادات ناامن یا غیرمطابق باشند و اینکه این علامت‌ها پیگیری شوند.
 #AD.6.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که بازخورد تجمیع شده به تنظیم دوره‌ای دقیق یا تولید افزایش‌یافته بازیابی شده با مجموعه داده‌های کدنویسی امن معتبر (مانند OWASP Cheat Sheets) اطلاع می‌دهد.
 #AD.6.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که یک چارچوب ارزیابی حلقه‌بسته پس از هر تنظیم دقیق، آزمایش‌های رگرسیون را اجرا می‌کند؛ معیارهای امنیتی باید قبل از استقرار، با معیارهای پایه قبلی برابر یا بهتر باشند.

---

#### مراجع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
OWASP Secure Coding Practices — Quick Reference Guide

## پیوست E: نمونه ابزارها و چارچوب‌ها

### هدف

این فصل مثال‌هایی از ابزارها و چارچوب‌هایی ارائه می‌دهد که می‌توانند از پیاده‌سازی یا تحقق یک نیازمندی مشخص AISVS پشتیبانی کنند. این موارد نباید به‌عنوان توصیه یا تأیید از سوی تیم AISVS یا پروژه امنیتی OWASP GenAI تلقی شوند.

---

### AE.1 حاکمیت داده‌های آموزشی و مدیریت سوگیری

ابزارهای مورد استفاده برای تحلیل داده‌ها، حاکمیت داده و مدیریت تعصب.

 #AE.1.1    بخش: 1.1
 ابزارهای مدیریت موجودی داده: ابزارهای مدیریت موجودی داده مانند...
 #AE.1.2    بخش: 1.2
 رمزنگاری در حین انتقال از TLS برای برنامه‌های مبتنی بر HTTPS استفاده کنید، با ابزارهایی مانند openSSL و کتابخانه پایتون`ssl`کتابخانه.

---

### AE.2 اعتبارسنجی ورودی کاربر

ابزارهایی برای مدیریت و اعتبارسنجی ورودی‌های کاربر.

 #AE.2.1    بخش: 2.1
 ابزارهای دفاعی در برابر تزریق پرامپت: از ابزارهای محافظتی مانند NeMo شرکت NVIDIA یا Guardrails AI استفاده کنید.

---

