## صفحه عنوان

### درباره استاندارد

استاندارد ارزیابی امنیت هوش مصنوعی (AISVS) یک فهرست مبتنی بر جامعه از الزامات امنیتی است که دانشمندان داده، مهندسان MLOps، معماران نرم‌افزار، توسعه‌دهندگان، آزمایش‌کنندگان، متخصصان امنیت، فروشندگان ابزار، تنظیم‌کنندگان مقررات و مصرف‌کنندگان می‌توانند از آن برای طراحی، ساخت، آزمایش و تأیید سیستم‌ها و برنامه‌های کاربردی قابل اعتماد مبتنی بر هوش مصنوعی استفاده کنند. این استاندارد زبان مشترکی برای مشخص کردن کنترل‌های امنیتی در سراسر چرخه عمر هوش مصنوعی فراهم می‌کند—از جمع‌آوری داده‌ها و توسعه مدل تا استقرار و نظارت مداوم—تا سازمان‌ها بتوانند تاب‌آوری، حریم خصوصی و ایمنی راه‌حل‌های هوش مصنوعی خود را اندازه‌گیری و بهبود بخشند.

### حق نشر و مجوز

نسخه 0.1 (اولین پیش‌نویس عمومی - در حال کار)، 2025  

![license](images/license.png)
کپی‌رایت © 2025 پروژه AISVS.  

منتشر شده تحتCreative Commons Attribution‑ShareAlike 4.0 International License.
برای هر گونه استفاده مجدد یا توزیع، باید شرایط مجوز این اثر را به‌طور واضح به دیگران اطلاع دهید.

### رهبران پروژه

جیم مانیكو
آراس «راس» ممیزیازیکی

### مشارکت‌کنندگان و بازبینی‌کنندگان

https://github.com/ottosulin
https://github.com/mbhatt1
https://github.com/vineethsai
https://github.com/cciprofm
https://github.com/deepakrpandey12


---

AISVS یک استاندارد کاملاً جدید است که به طور خاص برای رسیدگی به چالش‌های منحصر به فرد امنیتی سیستم‌های هوش مصنوعی ایجاد شده است. در حالی که از بهترین شیوه‌های امنیتی گسترده‌تر الهام گرفته است، هر نیازمندی در AISVS از پایه توسعه یافته است تا بازتاب دهنده چشم‌انداز تهدیدهای هوش مصنوعی باشد و به سازمان‌ها کمک کند راه‌حل‌های هوش مصنوعی امن‌تر و مقاوم‌تری بسازند.

## مقدمه

به استاندارد تأیید امنیت هوش مصنوعی (AISVS) نسخه 1.0 خوش آمدید!

### مقدمه

AISVS که در سال 2025 از طریق یک تلاش مشترک جامعه‌ای تاسیس شد، الزامات امنیتی را که باید هنگام طراحی، توسعه، استقرار و بهره‌برداری از مدل‌های هوش مصنوعی مدرن، خطوط لوله و خدمات فعال‌شده توسط هوش مصنوعی در نظر گرفته شود، تعریف می‌کند.

AISVS v1.0 نمایانگر همکاری مشترک رهبران پروژه، گروه کاری و مشارکت‌کنندگان گسترده‌تر جامعه برای ایجاد یک مبنای عملی و قابل آزمایش در زمینه امنیت سیستم‌های هوش مصنوعی است.

هدف ما در این نسخه این است که AISVS را به‌گونه‌ای ساده برای پذیرش ارائه دهیم در حالی که تمرکز دقیقی بر دامنه تعریف‌شده آن داشته و به چشم‌انداز ریسک‌های به سرعت در حال تحول که منحصر به هوش مصنوعی است، پاسخ دهیم.

### اهداف کلیدی برای نسخه 1.0 AISVS

نسخه 1.0 با چندین اصل راهنما ایجاد خواهد شد.

#### دامنه مشخص و واضح

هر الزامی باید با نام و ماموریت AISVS همسو باشد:

هوش مصنوعی – کنترل‌ها در لایه AI/ML (داده، مدل، خط لوله، یا استنتاج) عمل می‌کنند و مسئولیت آن‌ها بر عهده متخصصان هوش مصنوعی است.
امنیت – الزامات به‌طور مستقیم خطرات شناسایی‌شده در زمینه امنیت، حریم خصوصی یا ایمنی را کاهش می‌دهند.
اعتبارسنجی – زبان به گونه‌ای نوشته شده است که انطباق آن بتواند به صورت عینی تأیید شود.
استاندارد – بخش‌ها ساختار و اصطلاحات ثابتی را دنبال می‌کنند تا یک مرجع منسجم ایجاد کنند.
​
---

با پیروی از AISVS، سازمان‌ها می‌توانند به‌طور سیستماتیک وضعیت امنیتی راهکارهای هوش مصنوعی خود را ارزیابی و تقویت کنند و فرهنگ مهندسی هوش مصنوعی امن را ترویج دهند.

## استفاده از AISVS

استاندارد تأیید امنیت هوش مصنوعی (AISVS) الزامات امنیتی برای برنامه‌ها و خدمات مدرن هوش مصنوعی را تعریف می‌کند و بر جنبه‌هایی تمرکز دارد که در کنترل توسعه‌دهندگان برنامه است.

AISVS برای هر کسی که در حال توسعه یا ارزیابی امنیت برنامه‌های هوش مصنوعی است، از جمله توسعه‌دهندگان، معماران، مهندسان امنیت و حسابرسان، طراحی شده است. این فصل ساختار و استفاده از AISVS را معرفی می‌کند، از جمله سطوح تأیید آن و موارد استفاده مورد نظر.

### سطوح تایید امنیت هوش مصنوعی

AISVS سه سطح صعودی از تایید امنیت را تعریف می‌کند. هر سطح عمق و پیچیدگی بیشتری اضافه می‌کند و به سازمان‌ها امکان می‌دهد وضعیت امنیتی خود را با سطح ریسک سیستم‌های هوش مصنوعی خود تطبیق دهند.

سازمان‌ها ممکن است از سطح 1 شروع کنند و به تدریج سطوح بالاتر را با افزایش بلوغ امنیتی و میزان تهدیدات اتخاذ نمایند.

#### تعریف سطوح

هر نیازمندی در AISVS نسخه 1.0 به یکی از سطوح زیر تخصیص داده شده است:

 الزامات سطح 1

سطح 1 شامل حیاتی‌ترین و اساسی‌ترین الزامات امنیتی است. این سطح بر جلوگیری از حملات رایجی تمرکز دارد که نیازی به شرایط اولیه یا آسیب‌پذیری‌های دیگر ندارند. بیشتر کنترل‌های سطح 1 یا به‌طور ساده قابل پیاده‌سازی هستند یا به اندازه کافی ضروری هستند که انجام آنها توجیه‌پذیر باشد.

 الزامات سطح 2

سطح 2 به حملات پیشرفته‌تر یا کمتر رایج‌تر و همچنین دفاع‌های لایه‌ای در برابر تهدیدات گسترده می‌پردازد. این الزامات ممکن است شامل منطق پیچیده‌تر یا هدف قرار دادن پیش‌نیازهای خاص حمله باشند.

##### نیازمندی‌های سطح ۳

سطح 3 شامل کنترل‌هایی است که معمولاً اجرای آن‌ها سخت‌تر است یا در موارد خاص کاربرد دارند. این کنترل‌ها اغلب نمایانگر مکانیزم‌های دفاع به‌عمق یا کاهش ریسک در برابر حملات خاص، هدفمند یا با پیچیدگی بالا هستند.

#### نقش (D/V)

هر الزام AISVS مطابق با مخاطب اصلی علامت‌گذاری شده است:

D – نیازمندی‌های متمرکز بر توسعه‌دهنده
V – نیازمندی‌های متمرکز بر راستی‌آزما/ممیزی‌کننده
D/V – مرتبط با هر دو توسعه‌دهندگان و تأییدکنندگان

## مدیریت حاکمیت داده‌های آموزش C1 و مدیریت تعصب

### هدف کنترل

داده‌های آموزشی باید به گونه‌ای تهیه، مدیریت و نگهداری شوند که اصالت، امنیت، کیفیت و عدالت آن‌ها حفظ شود. انجام این کار وظایف قانونی را برآورده می‌کند و ریسک‌های تعصب، آلوده‌سازی یا نقض حریم خصوصی که در طول آموزش ظاهر می‌شوند و می‌توانند کل چرخه عمر هوش مصنوعی را تحت تأثیر قرار دهند، کاهش می‌دهد.

---

### C1.1 منشاء داده‌های آموزشی

یک فهرست قابل تأیید از تمام مجموعه داده‌ها نگه دارید، فقط منابع مورد اعتماد را قبول کنید و هر تغییر را برای قابلیت بررسی ثبت کنید.

 #1.1.1    سطح: 1    نقش: D/V
 تأیید کنید که موجودی به‌روز از هر منبع داده آموزشی (مبدأ، مسئول/مالک، مجوز، روش جمع‌آوری، محدودیت‌های استفاده مورد نظر، و تاریخچه پردازش) حفظ می‌شود.
 #1.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که فرایندهای داده‌های آموزشی شامل ویژگی‌ها، خصوصیات یا فیلدهای غیرضروری نیستند (مانند متادیتای استفاده‌نشده، اطلاعات شناسایی شخصی حساس، داده‌های آزمایشی نشت شده).
 #1.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تمامی تغییرات در داده‌ها تحت یک فرآیند تایید ثبت‌شده قرار دارند.
 #1.1.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مجموعه داده‌ها یا زیرمجموعه‌ها در صورت امکان علامت‌گذاری شده یا اثر انگشت دیجیتال دارند.

---

### C1.2 امنیت و یکپارچگی داده‌های آموزشی

دسترسی به داده‌های آموزشی را محدود کنید، آن‌ها را در حالت استراحت و در انتقال رمزگذاری کنید، و صحت آن‌ها را برای جلوگیری از دستکاری، سرقت یا مسمومیت داده‌ها تأیید کنید.

 #1.2.1    سطح: 1    نقش: D/V
 بررسی کنید که کنترل‌های دسترسی از ذخیره‌سازی داده‌های آموزش و خطوط لوله محافظت می‌کنند.
 #1.2.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که همه دسترسی‌ها به داده‌های آموزشی ثبت می‌شوند، از جمله کاربر، زمان و اقدام.
 #1.2.3    سطح: 2    نقش: D/V
 تأیید کنید که مجموعه داده‌های آموزش در حین انتقال و در حالت استراحت رمزگذاری شده‌اند، با استفاده از الگوریتم‌های رمزنگاری استاندارد صنعتی و روش‌های مدیریت کلید.
 #1.2.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که هش‌های رمزنگاری شده یا امضاهای دیجیتال برای تضمین صحت داده‌ها در هنگام ذخیره و انتقال داده‌های آموزشی استفاده می‌شوند.
 #1.2.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تکنیک‌های شناسایی خودکار برای محافظت در برابر تغییرات غیرمجاز یا فساد داده‌های آموزشی اعمال شده‌اند.
 #1.2.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که داده‌های آموزشی منسوخ شده به طور ایمن حذف یا ناشناس‌سازی شده‌اند.
 #1.2.7    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تمام نسخه‌های مجموعه داده آموزشی به‌طور یکتا شناسایی شده، به صورت غیرقابل تغییر ذخیره شده و قابل حسابرسی هستند تا از بازگردانی و تحلیل‌های قضایی پشتیبانی کنند.

---

### C1.3 کیفیت، یکپارچگی و امنیت برچسب‌گذاری داده‌های آموزشی

حفاظت از برچسب‌ها و الزام به بررسی فنی برای داده‌های حیاتی.

 #1.3.1    سطح: 2    نقش: D/V
 تأیید کنید که هش‌های رمزنگاری شده یا امضاهای دیجیتال به آثار برچسب‌گذاری شده اعمال شده‌اند تا از صحت و اصالت آن‌ها اطمینان حاصل شود.
 #1.3.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که رابط‌ها و پلتفرم‌های برچسب‌گذاری کنترل‌های دسترسی قوی را اجرا می‌کنند، گزارش‌های حسابرسی مقاوم در برابر دست‌کاری از تمام فعالیت‌های برچسب‌گذاری را حفظ می‌کنند و از تغییرات غیرمجاز محافظت می‌کنند.
 #1.3.3    سطح: 3    نقش: D/V
 تأیید کنید که اطلاعات حساس در برچسب‌ها در سطح فیلد داده‌ها، هم در حالت استراحت و هم در حال انتقال، حذف، ناشناس‌سازی یا رمزگذاری شده باشند.

---

### C1.4 کیفیت داده‌های آموزش و تضمین امنیت

ترکیب اعتبارسنجی خودکار، بررسی‌های نقطه‌ای دستی، و اصلاحات ثبت‌شده برای تضمین قابلیت اطمینان داده‌ها.

 #1.4.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که تست‌های خودکار خطاهای قالب‌بندی و مقادیر تهی را در هر بار وارد کردن داده یا تبدیل مهم داده‌ها شناسایی می‌کنند.
 #1.4.2    سطح: 2    نقش: D/V
 تأیید کنید که خطوط لوله آموزش و تنظیم دقیق مدل‌های زبان بزرگ (LLM) شامل شناسایی مسموم‌سازی و اعتبارسنجی یکپارچگی داده‌ها (مانند روش‌های آماری، شناسایی نقاط دورافتاده، تحلیل تعبیه‌ها) باشند تا حملات احتمالی مسموم‌سازی (مانند تغییر برچسب، درج محرک درب پشتی، فرمان‌های تغییر نقش، حملات نمونه‌های تأثیرگذار) یا فساد ناخواسته داده‌ها در داده‌های آموزش تشخیص داده شوند.
 #1.4.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که دفاع‌های مناسب، مانند آموزش مقابله‌ای (استفاده از نمونه‌های مقابله‌ای تولید شده)، افزایش داده‌ها با ورودی‌های تغییر یافته، یا تکنیک‌های بهینه‌سازی مقاوم، بر اساس ارزیابی ریسک برای مدل‌های مرتبط پیاده‌سازی و تنظیم شده‌اند.
 #1.4.4    سطح: 2    نقش: D/V
 تأیید کنید که برچسب‌های تولید شده به‌صورت خودکار (مثلاً از طریق مدل‌های زبان بزرگ یا نظارت ضعیف) مشمول آستانه‌های اطمینان و بررسی‌های سازگاری برای شناسایی برچسب‌های توهمی، گمراه‌کننده یا با اطمینان پایین هستند.
 #1.4.5    سطح: 3    نقش: D
 اطمینان حاصل کنید که تست‌های خودکار تغییرات نامتوازن برچسب‌ها را در هر بار دریافت داده یا تغییر داده قابل توجه تشخیص می‌دهند.

---

### C1.5 ردیابی و خط سیر داده‌ها

ردیابی کامل مسیر هر داده از منبع تا ورودی مدل برای قابلیت بازبینی و پاسخ به حادثه.

 #1.5.1    سطح: 2    نقش: D/V
 تأیید کنید که خط سیر هر داده، شامل تمامی تبدیلات، افزایش‌ها و ادغام‌ها، ثبت شده و قابل بازسازی باشد.
 #1.5.2    سطح: 2    نقش: D/V
 تأیید کنید که سوابق نسبیت تغییرناپذیر، به‌صورت ایمن ذخیره شده و برای ممیزی‌ها قابل دسترسی هستند.
 #1.5.3    سطح: 2    نقش: D/V
 تأیید کنید که ردیابی منشأ داده شامل داده‌های مصنوعی تولید شده از طریق تکنیک‌های حفظ حریم خصوصی یا تولیدی باشد و تمام داده‌های مصنوعی به‌صورت واضح برچسب‌گذاری شده و در سراسر خط لوله قابل تمایز از داده‌های واقعی باشند.

---

### مراجع

NIST AI Risk Management Framework
EU AI Act – Article 10: Data & Data Governance
MITRE ATLAS: Adversary Tactics for AI
Survey of ML Bias Mitigation Techniques – MDPI
Data Provenance & Lineage Best Practices – Nightfall AI
Data Labeling Quality Standards – LabelYourData
Training Data Poisoning Guide – Lakera.ai
CISA Advisory: Securing Data for AI Systems
ISO/IEC 23053: AI Management Systems Framework
IBM: What is AI Governance?
Google AI Principles
GDPR & AI Training Data – DataProtectionReport
Supply-Chain Security for AI Data – AppSOC
OpenAI Privacy Center – Data Deletion Controls
Adversarial ML Dataset – Kaggle

## اعتبارسنجی ورودی کاربر C2

### هدف کنترل

اعتبارسنجی قوی ورودی کاربر یک خط دفاع اولیه در برابر برخی از مخرب‌ترین حملات به سیستم‌های هوش مصنوعی است. حملات تزریق دستورالعمل می‌تواند دستورات سیستم را بازنویسی کند، داده‌های حساس را نشت دهد یا مدل را به سمتی هدایت کند که رفتار غیرمجاز داشته باشد. مگر اینکه فیلترهای اختصاصی و سلسله مراتب دستورالعمل‌ها به کار گرفته شده باشند، تحقیقات نشان می‌دهد که «جلبریک‌»های چندمرحله‌ای که از پنجره‌های زمینه‌ای بسیار طولانی بهره می‌برند، موثر خواهند بود. همچنین، حملات تغییرات ظریف و متخاصم—مانند جایگزینی‌های هم‌نُمایه یا زبان لیت—می‌توانند بدون صدا تصمیمات مدل را تغییر دهند.

---

### C2.1 دفاع در برابر تزریق پرامپت

تزریق پرامپت یکی از بزرگ‌ترین ریسک‌ها برای سیستم‌های هوش مصنوعی است. دفاع در برابر این تاکتیک از ترکیبی از فیلترهای الگوی ایستا، طبقه‌بندهای پویا و اجرای سلسله‌مراتب دستورالعمل‌ها استفاده می‌کند.

 #2.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که ورودی‌های کاربر در برابر یک کتابخانه به‌روز شده مداوم از الگوهای شناخته شده تزریق پرامپت (کلمات کلیدی فرار از محدودیت، "نادیده گرفتن قبلی"، زنجیره‌های نقش‌آفرینی، حملات غیرمستقیم HTML/URL) بررسی می‌شوند.
 #2.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم یک سلسله‌مراتب دستوری را اجرا می‌کند که در آن پیام‌های سیستم یا توسعه‌دهنده، دستورالعمل‌های کاربر را حتی پس از گسترش پنجره زمینه، لغو می‌کنند.
 #2.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تست‌های ارزیابی خصمانه (برای مثال، پرامپت‌های "چند-شات" تیم قرمز) پیش از هر انتشار مدل یا قالب پرامپت اجرا می‌شوند، با آستانه‌های نرخ موفقیت و مسدودکننده‌های خودکار برای پسرفت‌ها.
 #2.1.4    سطح: 2    نقش: D
 تأیید کنید که درخواست‌هایی که از محتوای شخص ثالث (صفحات وب، فایل‌های PDF، ایمیل‌ها) منشأ می‌گیرند، در یک زمینه پارسینگ ایزوله شده تصفیه شوند قبل از اینکه به درخواست اصلی الحاق شوند.
 #2.1.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تمامی به‌روزرسانی‌های قوانین فیلتر پرامپت، نسخه‌های مدل طبقه‌بندی‌کننده و تغییرات فهرست مسدودسازی، دارای کنترل نسخه و قابل ممیزی هستند.

---

### C2.2 مقاومت در برابر مثال‌های خصمانه

مدل‌های پردازش زبان طبیعی (NLP) همچنان نسبت به تغییرات ظریف در سطح حروف یا کلمات آسیب‌پذیر هستند که انسان‌ها اغلب متوجه آنها نمی‌شوند اما مدل‌ها تمایل دارند آنها را به اشتباه طبقه‌بندی کنند.

 #2.2.1    سطح: 1    نقش: D
 تأیید کنید که مراحل پایه نرمال‌سازی ورودی (Unicode NFC، نگاشت هم‌ریخت‌ها، برداشت فضای خالی) قبل از توکنیزاسیون اجرا شوند.
 #2.2.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تشخیص ناهنجاری آماری ورودی‌هایی را علامت‌گذاری می‌کند که فاصله ویرایشی غیرمعمول بالا نسبت به هنجارهای زبانی، توکن‌های تکراری بیش از حد یا فاصله‌های جاسازی غیرعادی دارند.
 #2.2.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که خط لوله استنتاج از نسخه‌های مدل مقاوم‌شده با آموزش خصمانه اختیاری یا لایه‌های دفاعی (مثلاً تصادفی‌سازی، تقطیر دفاعی) برای نقاط پایانی با ریسک بالا پشتیبانی می‌کند.
 #2.2.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که ورودی‌های مشکوک به حملات خصمانه در قرنطینه قرار گرفته، همراه با کل داده‌های بار (پس از حذف اطلاعات شناسایی شخصی) ثبت شوند.
 #2.2.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که معیارهای استحکام (نرخ موفقیت مجموعه‌های حمله شناخته‌شده) در طول زمان پیگیری می‌شوند و هرگونه پسرفت منجر به مسدودکننده انتشار می‌شود.

---

### اعتبارسنجی طرح‌واره، نوع و طول C2.3

حملات هوش مصنوعی که شامل ورودی‌های نادرست یا خیلی بزرگ هستند می‌توانند باعث بروز خطاهای تجزیه، نشت درخواست در بین فیلدها و خستگی منابع شوند. اجرای سختگیرانه‌ی ساختار (اسکیما) نیز پیش‌نیاز انجام فراخوانی‌های ابزار قطعی است.

 #2.3.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که هر نقطه پایانی فراخوانی API یا تابع، یک اسکیمای ورودی صریح (JSON Schema، Protobuf یا معادل چندمودالی آن) را تعریف کند و ورودی‌ها قبل از ترکیب پرامپت اعتبارسنجی شوند.
 #2.3.2    سطح: 1    نقش: D/V
 بررسی کنید که ورودی‌هایی که از حد مجاز توکن یا بایت فراتر می‌روند، با یک خطای ایمن رد شوند و هرگز به طور خاموش قطع نشوند.
 #2.3.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که بررسی‌های نوع (برای مثال، بازه‌های عددی، مقادیر enum، نوع‌های MIME برای تصاویر/صدا) در سمت سرور اعمال می‌شوند و نه تنها در کد کلاینت.
 #2.3.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که اعتبارسنج‌های معنایی (مانند JSON Schema) در زمان ثابت اجرا می‌شوند تا از حملات DoS الگوریتمی جلوگیری شود.
 #2.3.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که خطاهای اعتبارسنجی با قطعات داده‌های بازنویسی‌شده و کدهای خطای بی‌ابهام ثبت می‌شوند تا به طبقه‌بندی امنیتی کمک کنند.

---

### C2.4 غربالگری محتوا و سیاست

توسعه‌دهندگان باید قادر باشند درخواست‌های معتبر نحوی که محتوای ممنوعه (مانند دستورالعمل‌های غیرمجاز، گفتار نفرت‌انگیز، و متون دارای حق نشر) را درخواست می‌کنند، شناسایی کرده و از انتشار آن‌ها جلوگیری کنند.

 #2.4.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که یک طبقه‌بند محتوا (بدون آموزش قبلی یا آموزش دیده) هر ورودی را برای خشونت، خودآسیب‌رسانی، نفرت، محتوای جنسی و درخواست‌های غیرقانونی امتیازدهی می‌کند، با آستانه‌های قابل تنظیم.
 #2.4.2    سطح: 1    نقش: D/V
 تأیید کنید که ورودی‌هایی که قوانین را نقض می‌کنند، پاسخ‌های استاندارد شده امتناع یا تکمیل‌های ایمن دریافت خواهند کرد تا به تماس‌های بعدی مدل‌های زبانی بزرگ منتقل نشوند.
 #2.4.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که مدل غربالگری یا مجموعه قوانین حداقل هر سه ماه یکبار دوباره آموزش داده شده یا به‌روزرسانی می‌شود، به‌طوری که الگوهای جدید مشاهده‌شده از دور زدن محدودیت یا نقض سیاست را در بر بگیرد.
 #2.4.4    سطح: 2    نقش: D
 تأیید کنید که غربالگری قوانین مخصوص به کاربر (سن، محدودیت‌های قانونی منطقه‌ای) را از طریق قوانین مبتنی بر ویژگی که در زمان درخواست حل می‌شوند، رعایت می‌کند.
 #2.4.5    سطح: 3    نقش: V
 تأیید کنید که لاگ‌های اسکرینینگ شامل امتیازهای اطمینان طبقه‌بندی‌کننده و برچسب‌های دسته‌بندی سیاست برای همبستگی SOC و پخش مجدد تیم قرمز در آینده باشند.

---

### محدودیت نرخ ورودی C2.5 و پیشگیری از سوء استفاده

توسعه‌دهندگان باید از سوءاستفاده، خستگی منابع و حملات خودکار علیه سیستم‌های هوش مصنوعی جلوگیری کنند، از طریق محدود کردن نرخ ورودی‌ها و شناسایی الگوهای استفاده غیرعادی.

 #2.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که محدودیت‌های نرخ برای هر کاربر، هر آی‌پی و هر کلید API برای تمام نقطه‌های ورودی اعمال می‌شوند.
 #2.5.2    سطح: 2    نقش: D/V
 تأیید کنید که محدودیت‌های نرخ انفجار و نرخ پایدار تنظیم شده‌اند تا از حملات انکار سرویس (DoS) و حملات نیروی بی‌رحمانه جلوگیری کنند.
 #2.5.3    سطح: 2    نقش: D/V
 تأیید کنید که الگوهای استفاده غیرطبیعی (مانند درخواست‌های سریع متوالی، پرکردن ورودی) باعث فعال شدن مسدودسازی‌های خودکار یا افزایش سطح هشدار شوند.
 #2.5.4    سطح: 3    نقش: V
 تأیید کنید که لاگ‌های جلوگیری از سوءاستفاده نگهداری شده و برای الگوهای حمله نوظهور مرور می‌شوند.

---

### C2.6 اعتبارسنجی ورودی چند حالته

سیستم‌های هوش مصنوعی باید اعتبارسنجی قوی برای ورودی‌های غیر متنی (تصاویر، صدا، فایل‌ها) داشته باشند تا از تزریق، گریز یا سوء استفاده از منابع جلوگیری شود.

 #2.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که همه ورودی‌های غیر متنی (تصاویر، صوت، فایل‌ها) قبل از پردازش از نظر نوع، اندازه و فرمت بررسی و تایید می‌شوند.
 #2.6.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فایل‌ها قبل از ورود اسکن شده و از نظر بدافزارها و بارهای مخفی‌نگاری شده بررسی شده‌اند.
 #2.6.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که ورودی‌های تصویر/صدا برای تغییرات مخرب یا الگوهای حمله شناخته شده بررسی می‌شوند.
 #2.6.4    سطح: 3    نقش: V
 تأیید کنید که خطاهای اعتبارسنجی ورودی چند‌حالتی ثبت شده و هشدارهایی برای بررسی ایجاد می‌کنند.

---

### C2.7 منشأ و نسبت‌دهی ورودی

سیستم‌های هوش مصنوعی باید از حسابرسی، ردیابی سوء‌استفاده و تطبیق با قوانین پشتیبانی کنند، از طریق نظارت و برچسب‌گذاری مبدا همه ورودی‌های کاربر.

 #2.7.1    سطح: 1    نقش: D/V
 تأیید کنید که تمام ورودی‌های کاربر با فراداده (شناسه کاربر، جلسه، منبع، زمان‌سنجی، آدرس IP) هنگام ورود داده‌ها برچسب‌گذاری شده‌اند.
 #2.7.2    سطح: 2    نقش: D/V
 تأیید کنید که متاداده منبع برای همه ورودی‌های پردازش شده حفظ شده و قابل حسابرسی باشد.
 #2.7.3    سطح: 2    نقش: D/V
 بررسی کنید که منابع ورودی غیرعادی یا غیرقابل اعتماد علامت‌گذاری شده و تحت بررسی دقیق‌تر یا مسدودسازی قرار گیرند.

---

### C2.8 شناسایی تهدید تطبیقی در زمان واقعی

توسعه‌دهندگان باید از سیستم‌های پیشرفته شناسایی تهدید برای هوش مصنوعی استفاده کنند که به الگوهای حمله جدید سازگار شده و با تطبیق الگوهای کامپایل شده، حفاظت بلادرنگ ارائه دهند.

 #2.8.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که الگوهای شناسایی تهدید به موتورهای بهینه‌شده عبارات منظم (regex) تبدیل شده‌اند تا فیلترکردن بلادرنگ با عملکرد بالا و کمترین تأثیر تأخیر انجام شود.
 #2.8.2    سطح: 1    نقش: D/V
 تأیید کنید که سیستم‌های تشخیص تهدید، کتابخانه‌های الگویی جداگانه برای دسته‌های مختلف تهدید (تزریق درخواست، محتوای مضر، داده‌های حساس، دستورات سیستم) حفظ می‌کنند.
 #2.8.3    سطح: 2    نقش: D/V
 تأیید کنید که تشخیص تهدید تطبیقی شامل مدل‌های یادگیری ماشین است که حساسیت تهدید را بر اساس فرکانس و نرخ موفقیت حملات به‌روزرسانی می‌کنند.
 #2.8.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که خوراک‌های اطلاعات تهدید بلادرنگ به‌طور خودکار کتابخانه‌های الگو را با امضای حملات جدید و شاخص‌های نفوذ (IOCs) به‌روزرسانی می‌کنند.
 #2.8.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که نرخ‌های مثبت کاذب در تشخیص تهدید به‌طور مداوم نظارت می‌شوند و ویژگی‌های الگو به‌طور خودکار تنظیم می‌شوند تا حداقل تداخل را با موارد استفاده قانونی داشته باشند.
 #2.8.6    سطح: 3    نقش: D/V
 تأیید کنید که تحلیل تهدید زمینه‌ای منبع ورودی، الگوهای رفتار کاربر و تاریخچه جلسه را برای بهبود دقت تشخیص در نظر می‌گیرد.
 #2.8.7    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که معیارهای عملکرد تشخیص تهدید (نرخ تشخیص، تأخیر پردازش، استفاده از منابع) به‌صورت بلادرنگ نظارت و بهینه‌سازی می‌شوند.

---

### C2.9 خط لوله اعتبارسنجی امنیت چند-رسانه‌ای

توسعه‌دهندگان باید اعتبارسنجی امنیتی برای ورودی‌های متنی، تصویری، صوتی و دیگر مدالیت‌های ورودی هوش مصنوعی را با استفاده از انواع خاصی از شناسایی تهدید و ایزوله‌سازی منابع ارائه دهند.

 #2.9.1    سطح: 1    نقش: D/V
 تأیید کنید که هر مدالیته ورودی دارای اعتبارسنج‌های امنیتی اختصاصی با الگوهای تهدید مستند شده (متن: تزریق پرامپت، تصاویر: استگانوگرافی، صوت: حملات اسپکتروگرام) و آستانه‌های تشخیص باشد.
 #2.9.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که ورودی‌های چندوجهی در محیط‌های ایزوله با محدودیت‌های منابع مشخص (حافظه، پردازنده، زمان پردازش) که مختص هر نوع وجه هستند، پردازش می‌شوند و این موارد در سیاست‌های امنیتی مستند شده‌اند.
 #2.9.3    سطح: 2    نقش: D/V
 تأیید کنید که تشخیص حملات چندوجهی، حملات هماهنگ‌شده‌ای که شامل چندین نوع ورودی هستند (مثلاً بارهای پنهان‌سازی‌شده در تصاویر همراه با تزریق پرامپت در متن) را با استفاده از قواعد همبستگی و تولید هشدار شناسایی می‌کند.
 #2.9.4    سطح: 3    نقش: D/V
 بررسی کنید که خطاهای اعتبارسنجی چندحالته باعث ثبت دقیق و مفصل لوگ‌ها شوند، شامل تمام حالت‌های ورودی، نتایج اعتبارسنجی، امتیازهای تهدید، و تحلیل همبستگی با فرمت‌های ساختاریافتهٔ لوگ برای یکپارچه‌سازی با SIEM.
 #2.9.5    سطح: 3    نقش: D/V
 تأیید کنید که دسته‌بندهای محتوای مربوط به هر حالت بر اساس برنامه‌های مستند شده (حداقل فصلی) با الگوهای جدید تهدید، نمونه‌های مخرب و معیارهای عملکرد که بالاتر از آستانه‌های پایه حفظ شده‌اند، به‌روزرسانی می‌شوند.

---

### مراجع

LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security
Generative AI's Biggest Security Flaw Is Not Easy to Fix
Many-shot jailbreaking \ Anthropic
$PDF$ OpenAI GPT-4.5 System Card
Notebook for the CheckThat Lab at CLEF 2024
Mitigate jailbreaks and prompt injections – Anthropic
Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis
OWASP Top 10 for LLM Applications 2025 – WorldTech IT
OWASP Machine Learning Security Top Ten
Few words about AI Security – Jussi Metso
How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry
Easily enforcing valid JSON schema following – API
AI Safety + Cybersecurity R\&D Tracker – Fairly AI
Anthropic makes 'jailbreak' advance to stop AI models producing harmful results
Pattern matching filter rules - IBM
Real-time Threat Detection

## مدیریت چرخه عمر مدل C3 و کنترل تغییرات

### هدف کنترل

سیستم‌های هوش مصنوعی باید فرآیندهای کنترل تغییر را پیاده‌سازی کنند که از رسیدن تغییرات غیرمجاز یا ناایمن مدل به محیط تولید جلوگیری کند. این کنترل از صحت و تمامیت مدل در سراسر چرخه عمر آن—از توسعه تا استقرار و ازکارگیری—اطمینان حاصل می‌کند که پاسخ سریع به رویدادها را ممکن ساخته و مسئولیت‌پذیری برای همه تغییرات را حفظ می‌کند.

هدف اصلی امنیت: تنها مدل‌های مجاز و تأیید شده از طریق فرآیندهای کنترل شده که صحت، ردیابی‌پذیری و بازیابی‌پذیری را حفظ می‌کنند، به مرحله تولید می‌رسند.

---

### C3.1 مجوز مدل و یکپارچگی

تنها مدل‌های مجاز با صحت تایید شده به محیط‌های تولید می‌رسند.

 #3.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام مصنوعات مدل (وزن‌ها، پیکربندی‌ها، توکنایزرها) قبل از استقرار توسط نهادهای مجاز به صورت رمزنگاری‌شده امضا شده‌اند.
 #3.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که صحت مدل در زمان استقرار تأیید می‌شود و خطاهای تأیید امضا مانع بارگذاری مدل می‌شوند.
 #3.1.3    سطح: 2    نقش: D/V
 تأیید کنید که سوابق منشاء مدل شامل هویت نهاد مجازکننده، چکسام‌های داده‌های آموزشی، نتایج آزمون اعتبارسنجی با وضعیت قبول/رد، و یک نشان‌زمان ایجاد باشد.
 #3.1.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که همه مصنوعات مدل از نسخه‌بندی معنایی (MAJOR.MINOR.PATCH) استفاده می‌کنند و معیارهای مستندی برای مشخص کردن زمان افزایش هر جزء نسخه وجود دارد.
 #3.1.5    سطح: 2    نقش: V
 اطمینان حاصل کنید که پیگیری وابستگی، یک موجودی لحظه‌ای را حفظ می‌کند که امکان شناسایی سریع همه سیستم‌های مصرف‌کننده را فراهم می‌آورد.

---

### C3.2 اعتبارسنجی و تست مدل

مدل‌ها باید قبل از استقرار، آزمایش‌های تأیید امنیت و ایمنی تعریف‌شده را گذرانده باشند.

 #3.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل شود که مدل‌ها قبل از استقرار تحت آزمایش‌های امنیتی خودکار قرار می‌گیرند که شامل اعتبارسنجی ورودی، پاک‌سازی خروجی و ارزیابی‌های ایمنی با آستانه‌های قبلاً توافق‌شده سازمانی برای قبول یا رد می‌باشند.
 #3.2.2    سطح: 1    نقش: D/V
 تأیید کنید که خطاهای اعتبارسنجی به‌صورت خودکار پس از تأیید صریح و تغییر تصمیم توسط افراد مجاز پیش‌تعیین‌شده با توجیهات مستند کسب‌وکار، مانع از استقرار مدل می‌شوند.
 #3.2.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که نتایج آزمون به صورت رمزنگاری شده امضا شده و به طور غیرقابل تغییر به هش نسخه مدل خاصی که مورد اعتبارسنجی قرار می‌گیرد، متصل شده‌اند.
 #3.2.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که استقرارهای اضطراری نیازمند ارزیابی مستند ریسک امنیتی و تأیید از سوی یک مرجع امنیتی پیش‌تعیین‌شده در بازه‌های زمانی از پیش توافق شده هستند.

---

### C3.3 استقرار کنترل‌شده و بازگردانی

پیاده‌سازی مدل‌ها باید کنترل‌شده، زیر نظر گرفته‌شده و قابل بازگشت باشد.

 #3.3.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که استقرارهای تولید مکانیزم‌های راه‌اندازی تدریجی (استقرارهای کناری، استقرارهای آبی-سبز) را با فعال‌کننده‌های بازگردانی خودکار بر اساس نرخ‌های خطای پیش‌توافق شده، آستانه‌های تأخیر، یا معیارهای هشدار امنیتی پیاده‌سازی کرده‌اند.
 #3.3.2    سطح: 1    نقش: D/V
 بررسی کنید که قابلیت‌های بازگردانی به‌طور اتمیک وضعیت کامل مدل (وزن‌ها، پیکربندی‌ها، وابستگی‌ها) را در بازه‌های زمانی سازمانی پیش‌تعریف شده بازیابی می‌کنند.
 #3.3.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فرآیندهای استقرار امضاهای رمزنگاری شده را تأیید کرده و چک‌سام‌های صحت را قبل از فعال‌سازی مدل محاسبه می‌کنند، و در صورت هرگونه عدم تطابق، استقرار انجام نشود.
 #3.3.4    سطح: 2    نقش: D/V
 تأیید کنید که قابلیت‌های خاموشی اضطراری مدل می‌توانند نقاط انتهایی مدل را در مدت زمان پاسخ تعریف‌شده از پیش، از طریق قطع‌کننده‌های مدار خودکار یا کلیدهای کشتن دستی غیرفعال کنند.
 #3.3.5    سطح: 2    نقش: V
 اطمینان حاصل کنید که آثار بازگشتی (نسخه‌های قبلی مدل، پیکربندی‌ها، وابستگی‌ها) مطابق با سیاست‌های سازمانی با ذخیره‌سازی غیرقابل تغییر برای پاسخ به حادثه نگهداری می‌شوند.

---

### C3.4 مسئولیت تغییر و ممیزی

تمام تغییرات در چرخه عمر مدل باید قابل ردیابی و حسابرسی باشند.

 #3.4.1    سطح: 1    نقش: V
 اطمینان حاصل کنید که تمام تغییرات مدل (استقرار، پیکربندی، بازنشستگی) سوابق حسابرسی غیرقابل تغییر ایجاد می‌کنند که شامل یک زمان‌سنجی، هویت بازیگر تاییدشده، نوع تغییر، و وضعیت‌های قبل/بعد هستند.
 #3.4.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که دسترسی به گزارش حسابرسی نیازمند مجوز مناسب است و تمام تلاش‌های دسترسی با هویت کاربر و زمان‌بندی ثبت می‌شوند.
 #3.4.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که قالب‌های پرامپت و پیام‌های سیستم در مخازن گیت نسخه‌بندی شده‌اند و بازبینی کد اجباری و تأیید از سوی بازبینان تعیین‌شده پیش از استقرار انجام می‌شود.
 #3.4.4    سطح: 2    نقش: V
 تأیید کنید که سوابق حسابرسی شامل جزئیات کافی (هش‌های مدل، عکس‌های پیکربندی، نسخه‌های وابستگی) باشد تا امکان بازسازی کامل وضعیت مدل برای هر بازه زمانی در دوره نگهداری فراهم شود.

---

### C3.5 شیوه‌های توسعه امن

فرآیندهای توسعه و آموزش مدل باید از روش‌های امن پیروی کنند تا از به خطر افتادن جلوگیری شود.

 #3.5.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که محیط‌های توسعه مدل، آزمایش و تولید از نظر فیزیکی یا منطقی جدا شده‌اند. آنها زیرساخت مشترک ندارند، کنترل‌های دسترسی متفاوتی دارند و ذخیره‌سازی داده‌ها به صورت ایزوله است.
 #3.5.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که آموزش مدل و تنظیم دقیق در محیط‌های ایزوله با دسترسی کنترل‌شده به شبکه انجام می‌شود.
 #3.5.3    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که منابع داده‌های آموزشی از طریق بررسی‌های صحت اعتبارسنجی شده و از طریق منابع معتبر با زنجیره نگهداری مستند تأیید شده باشند قبل از استفاده در توسعه مدل.
 #3.5.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که آثار توسعه مدل (ابرپارامترها، اسکریپت‌های آموزش، فایل‌های پیکربندی) در کنترل نسخه ذخیره شده و قبل از استفاده در آموزش، نیاز به تایید بررسی همتایان دارند.

---

### بازنشستگی و از خدمت خارج کردن مدل C3.6

مدل‌ها باید زمانی که دیگر نیازی به آنها نیست یا مشکلات امنیتی شناسایی می‌شوند، به طور ایمن بازنشسته شوند.

 #3.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که فرآیندهای بازنشستگی مدل به طور خودکار نمودارهای وابستگی را اسکن می‌کنند، تمام سیستم‌های مصرف‌کننده را شناسایی می‌کنند و دوره‌های اطلاع‌رسانی از پیش توافق‌شده را قبل از بازنشستگی ارائه می‌دهند.
 #3.6.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که آثار مدل بازنشسته با استفاده از پاک‌سازی رمزنگاری شده یا بازنویسی چندباره طبق سیاست‌های مستند نگهداری داده‌ها با گواهی‌های تأیید شده تخریب، به طور ایمن پاک‌سازی شده‌اند.
 #3.6.3    سطح: 2    نقش: V
 تأیید کنید که رویدادهای بازنشستگی مدل با زمان‌سنجی و هویت بازیگر ثبت شده‌اند و امضاهای مدل برای جلوگیری از استفاده مجدد لغو شده‌اند.
 #3.6.4    سطح: 2    نقش: D/V
 تأیید کنید که بازنشستگی اضطراری مدل می‌تواند دسترسی به مدل را در بازه‌های زمانی پاسخ اضطراری از پیش تعیین شده از طریق سوئیچ‌های خودکار غیرفعال کند اگر آسیب‌پذیری‌های امنیتی حیاتی کشف شوند.

---

### مراجع

MLOps Principles
Securing AI/ML Ops – Cisco.com
Audit logs security: cryptographically signed tamper-proof logs
Machine Learning Model Versioning: Top Tools & Best Practices
AI Hygiene Starts with Models and Data Loaders – SEI Blog
How to handle versioning and rollback of a deployed ML model?
Reinforcement fine-tuning – OpenAI API
Auditing Machine Learning models: Governance, Data Security and …
Adversarial Training to Improve Model Robustness
What is AI adversarial robustness? – IBM Research
Exploring Data Provenance: Ensuring Data Integrity and Authenticity
MITRE ATLAS
AWS Prescriptive Guidance – Best practices for retiring applications …

## امنیت زیرساخت، پیکربندی و استقرار C4

### هدف کنترل

زیرساخت هوش مصنوعی باید از طریق پیکربندی امن، جداسازی زمان اجرا، خطوط تولید استقرار مورد اعتماد، و نظارت جامع، در برابر افزایش امتیازات، دستکاری زنجیره تامین، و حرکت جانبی مقاومت یابد. تنها اجزای زیرساخت و پیکربندی‌های معتبر و مجاز از طریق فرآیندهای کنترل شده که امنیت، یکپارچگی، و قابل‌پیگیری بودن را حفظ می‌کنند، به مرحله تولید می‌رسند.

هدف اصلی امنیت: تنها اجزای زیرساختی که به صورت رمزنگاری شده امضا شده‌اند و از نظر آسیب‌پذیری اسکن شده‌اند، از طریق خطوط اعتبارسنجی خودکار که سیاست‌های امنیتی را اجرا می‌کنند و سوابق حسابرسی غیرقابل تغییر را حفظ می‌کنند، به محیط تولید می‌رسند.

---

### C4.1 جداسازی محیط زمان اجرا

جلوگیری از فرار از کانتینر و افزایش دسترسی غیرمجاز از طریق اصول جداسازی در سطح کرنل و کنترل‌های دسترسی اجباری.

 #4.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام کانتینرهای هوش مصنوعی تمامی قابلیت‌های لینوکس را به جز CAP_SETUID، CAP_SETGID و قابلیت‌های مورد نیاز صریحاً مستند شده در خط‌مشی‌های امنیتی رها می‌کنند.
 #4.1.2    سطح: 1    نقش: D/V
 تأیید کنید که پروفایل‌های seccomp تمام فراخوانی‌های سیستم را به جز آن‌هایی که در فهرست‌های سفید از پیش تأیید شده قرار دارند، مسدود می‌کنند، به طوری که تخلفات باعث خاتمه کانتینر و ایجاد هشدارهای امنیتی می‌شود.
 #4.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که بارهای کاری هوش مصنوعی با سیستم‌فایل ریشه فقط‌خواندنی، tmpfs برای داده‌های موقتی، و حجم‌های نام‌گذاری شده برای داده‌های پایدار اجرا می‌شوند و گزینه‌های mount با noexec اعمال شده‌اند.
 #4.1.4    سطح: 2    نقش: D/V
 تأیید کنید که پایش زمان‌اجرای مبتنی بر eBPF (مانند Falco، Tetragon، یا معادل آن) تلاش‌های ارتقاء اختیارات را شناسایی کرده و فرآیندهای متخلف را به‌صورت خودکار در بازه زمانی پاسخ سازمانی متوقف می‌کند.
 #4.1.5    سطح: 3    نقش: D/V
 تأیید کنید که بارهای کاری هوش مصنوعی با ریسک بالا در محیط‌های جداشده سخت‌افزاری (Intel TXT، AMD SVM، یا گره‌های اختصاصی bare-metal) با تأیید اعتبار اجرا می‌شوند.

---

### C4.2 خطوط لوله ساخت و استقرار امن

از صحت رمزنگاری و امنیت زنجیره تأمین از طریق ساخت‌های قابل بازتولید و آثار امضا شده اطمینان حاصل کنید.

 #4.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که زیرساخت به‌عنوان کد با استفاده از ابزارهایی مانند tfsec، Checkov، یا Terrascan در هر کامیت اسکن می‌شود و ادغام‌هایی که شامل یافته‌های با شدت CRITICAL یا HIGH هستند را مسدود می‌کند.
 #4.2.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که ساخت کانتینرها قابل بازتولید هستند و هش‌های SHA256 یکسانی در همه ساخت‌ها تولید می‌کنند و همچنین گواهی‌های منشأ SLSA سطح 3 را که با Sigstore امضا شده‌اند، تولید کنید.
 #4.2.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تصاویر کانتینر شامل SBOMهای CycloneDX یا SPDX بوده و قبل از ارسال به رجیستری با Cosign امضا شده‌اند، به طوری که تصاویر بدون امضا در زمان استقرار رد شوند.
 #4.2.4    سطح: 2    نقش: D/V
 تائید کنید که خط لوله‌های CI/CD از توکن‌های OIDC متعلق به HashiCorp Vault، نقش‌های IAM در AWS، یا هویت مدیریت‌شده Azure استفاده می‌کنند که زمان عمر آنها از محدودیت‌های سیاست امنیتی سازمان فراتر نمی‌رود.
 #4.2.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که امضاهای Cosign و صحت‌سنجی SLSA در طی فرآیند استقرار قبل از اجرای کانتینر تأیید می‌شوند و خطاهای تأیید منجر به شکست استقرار می‌گردند.
 #4.2.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که محیط‌های ساخت در کانتینرهای موقت یا ماشین‌های مجازی اجرا می‌شوند که ذخیره‌سازی دائمی ندارند و از شبکه‌های تولیدی VPCها جدا شده‌اند.

---

### C4.3 امنیت شبکه و کنترل دسترسی

پیاده‌سازی شبکه با رویکرد اعتماد صفر با سیاست‌های پیش‌فرض انکار و ارتباطات رمزنگاری‌شده.

 #4.3.1    سطح: 1    نقش: D/V
 تأیید کنید که NetworkPolicies در Kubernetes یا هر معادل دیگری، پیاده‌سازی پیش‌فرض انکار ورودی/خروجی را با قوانین صریح اجازه برای پورت‌های مورد نیاز (443، 8080 و غیره) انجام می‌دهد.
 #4.3.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که SSH (پورت 22)، RDP (پورت 3389) و نقاط پایانی متادیتای ابر (169.254.169.254) مسدود شده‌اند یا نیاز به احراز هویت بر اساس گواهی‌نامه دارند.
 #4.3.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که ترافیک خروجی از طریق پراکسی‌های HTTP/HTTPS (Squid، Istio یا دروازه‌های NAT ابری) با فهرست‌های مجاز دامنه فیلتر شده و درخواست‌های مسدود شده ثبت می‌شوند.
 #4.3.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که ارتباط بین سرویس‌ها از mutual TLS با گواهی‌نامه‌هایی که طبق سیاست سازمانی چرخش می‌یابند استفاده می‌کند و اعتبارسنجی گواهی‌نامه به‌صورت اجباری انجام می‌شود (بدون استفاده از گزینه‌های skip-verify).
 #4.3.5    سطح: 2    نقش: D/V
 تأیید کنید که زیرساخت هوش مصنوعی در VPCها/VNetهای اختصاصی بدون دسترسی مستقیم به اینترنت اجرا می‌شود و تنها از طریق دروازه‌های NAT یا میزبان‌های باسشن ارتباط برقرار می‌کند.

---

### C4.4 مدیریت اسرار و کلیدهای رمزنگاری

حفاظت از مدارک با استفاده از ذخیره‌سازی پشتیبانی شده توسط سخت‌افزار و چرخش خودکار با دسترسی صفر-اعتمادی.

 #4.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که اسرار در HashiCorp Vault، AWS Secrets Manager، Azure Key Vault، یا Google Secret Manager با رمزنگاری در حالت استراحت با استفاده از AES-256 ذخیره شده‌اند.
 #4.4.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که کلیدهای رمزنگاری در HSMهای سطح 2 FIPS 140-2 (AWS CloudHSM، Azure Dedicated HSM) تولید شده و چرخش کلید مطابق با سیاست رمزنگاری سازمانی انجام می‌شود.
 #4.4.3    سطح: 2    نقش: D/V
 تأیید کنید که چرخش اسرار به‌صورت خودکار با استقرار بدون توقف و چرخش فوری که توسط تغییرات پرسنلی یا حوادث امنیتی تحریک می‌شود، انجام می‌شود.
 #4.4.4    سطح: 2    نقش: D/V
 تأیید کنید که تصاویر کانتینر با استفاده از ابزارهایی مانند GitLeaks، TruffleHog یا detect-secrets اسکن می‌شوند و ساخت‌هایی که حاوی کلیدهای API، گذرواژه‌ها یا گواهی‌ها هستند را مسدود می‌کنند.
 #4.4.5    سطح: 2    نقش: D/V
 تأیید کنید که دسترسی به اسرار تولیدی نیازمند احراز هویت چندعاملی (MFA) با توکن‌های سخت‌افزاری (YubiKey، FIDO2) است و توسط گزارش‌های حسابرسی غیرقابل تغییر با هویت کاربران و زمان‌های ثبت شده ضبط می‌شود.
 #4.4.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اسرار از طریق اسرار Kubernetes، حجم‌های نصب شده یا کانتینرهای ابتدای راه‌انداز تزریق شده‌اند و تضمین کنید که اسرار هرگز در متغیرهای محیطی یا تصاویر جاسازی نشوند.

---

### ایزوله‌سازی و اعتبارسنجی بار کاری هوش مصنوعی C4.5

مدل‌های هوش مصنوعی غیرقابل اعتماد را در فضای امن جداسازی کنید و تجزیه و تحلیل رفتاری جامع را انجام دهید.

 #4.5.1    سطح: 1    نقش: D/V
 تأیید کنید که مدل‌های هوش مصنوعی خارجی در gVisor، میکروVMها (مانند Firecracker، CrossVM) یا کانتینرهای داکر با گزینه‌های --security-opt=no-new-privileges و --read-only اجرا شوند.
 #4.5.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که محیط‌های سندباکس هیچ اتصال شبکه‌ای ندارند (--network=none) یا فقط به localhost دسترسی دارند و تمام درخواست‌های خارجی توسط قوانین iptables مسدود شده‌اند.
 #4.5.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اعتبارسنجی مدل هوش مصنوعی شامل تست خودکار تیم قرمز با پوشش آزمایشی تعریف شده سازمانی و تحلیل رفتاری برای شناسایی درپشتی باشد.
 #4.5.4    سطح: 2    نقش: D/V
 اطمینان حاصل شود که قبل از ارتقاء یک مدل هوش مصنوعی به محیط تولید، نتایج سندباکس آن توسط پرسنل امنیتی مجاز به صورت رمزنگاری شده امضا شده و در گزارش‌های حسابرسی تغییرناپذیر ذخیره می‌شود.
 #4.5.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که محیط‌های سندباکس بین ارزیابی‌ها با پاک‌سازی کامل سیستم فایل و حافظه، از تصاویر طلایی نابود و مجدداً ایجاد می‌شوند.

---

### C4.6 نظارت بر امنیت زیرساخت

زیرساخت را به طور مداوم اسکن و نظارت کنید همراه با اصلاح خودکار و هشداردهی در زمان واقعی.

 #4.6.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تصاویر کانتینر طبق برنامه‌های سازمانی اسکن شده‌اند و آسیب‌پذیری‌های بحرانی (CRITICAL) بر اساس آستانه‌های ریسک سازمانی مانع از استقرار می‌شوند.
 #4.6.2    سطح: 1    نقش: D/V
 تأیید کنید که زیرساخت‌ها با معیارهای CIS یا کنترل‌های NIST 800-53 با آستانه‌های تطبیق تعریف‌شده سازمانی و اصلاح خودکار برای بررسی‌های ناموفق مطابقت دارند.
 #4.6.3    سطح: 2    نقش: D/V
 تأیید کنید که آسیب‌پذیری‌های با شدت HIGH مطابق با جدول زمانی مدیریت ریسک سازمانی رفع شده‌اند و برای CVEهای فعال در حال سوءاستفاده، رویه‌های اضطراری وجود دارد.
 #4.6.4    سطح: 2    نقش: V
 تأیید کنید که هشدارهای امنیتی با استفاده از فرمت‌های CEF یا STIX/TAXII و با غنی‌سازی خودکار، در پلتفرم‌های SIEM مانند Splunk، Elastic یا Sentinel ادغام شده‌اند.
 #4.6.5    سطح: 3    نقش: V
 تأیید کنید که متریک‌های زیرساخت به سیستم‌های نظارتی (Prometheus، DataDog) با داشبوردهای SLA و گزارش‌دهی اجرایی صادر می‌شوند.
 #4.6.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که انحراف پیکربندی با استفاده از ابزارها (Chef InSpec، AWS Config) مطابق با الزامات نظارتی سازمانی شناسایی شده و بازگردانی خودکار برای تغییرات غیرمجاز انجام می‌شود.

---

### مدیریت منابع زیرساخت هوش مصنوعی C4.7

جلوگیری از حملات تخلیه منابع و اطمینان از تخصیص عادلانه منابع از طریق سهمیه‌بندی و نظارت.

 #4.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مصرف GPU/TPU با هشدارهایی که در آستانه‌های تعریف شده توسط سازمان فعال می‌شوند، نظارت می‌شود و مقیاس‌گذاری خودکار یا تعادل بار بر اساس سیاست‌های مدیریت ظرفیت فعال می‌گردد.
 #4.7.2    سطح: 1    نقش: D/V
 تأیید کنید که معیارهای بار کاری هوش مصنوعی (زمان تأخیر استنتاج، توان عملیاتی، نرخ خطاها) طبق الزامات نظارتی سازمانی جمع‌آوری شده و با استفاده از زیرساخت همبسته شده‌اند.
 #4.7.3    سطح: 2    نقش: D/V
 تأیید کنید که Kubernetes ResourceQuotas یا معادل آن بارهای کاری فردی را مطابق با سیاست‌های تخصیص منابع سازمانی محدود کرده و محدودیت‌های سخت‌گیرانه اعمال می‌کنند.
 #4.7.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که پایش هزینه‌ها، هزینه‌ها را به ازای هر بار کاری/مستأجر ردیابی می‌کند و هشدارهایی بر اساس آستانه‌های بودجه سازمانی و کنترل‌های خودکار برای تجاوز از بودجه ارائه می‌دهد.
 #4.7.5    سطح: 3    نقش: V
 تأیید کنید که برنامه‌ریزی ظرفیت از داده‌های تاریخی با دوره‌های پیش‌بینی تعریف‌شده توسط سازمان و تأمین منابع خودکار بر اساس الگوهای تقاضا استفاده می‌کند.
 #4.7.6    سطح: 2    نقش: D/V
 تأیید کنید که کاهش منابع باعث فعال شدن قطع‌کننده‌های مدار طبق نیازهای پاسخ سازمانی شود، از جمله محدودیت نرخ بر اساس سیاست‌های ظرفیت و جداسازی بار کاری.

---

### C4.8 جداسازی محیط و کنترل‌های ارتقا

اجرای مرزهای محیطی سختگیرانه با استفاده از دروازه‌های ارتقاء خودکار و اعتبارسنجی امنیتی.

 #4.8.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که محیط‌های توسعه/آزمایش/تولید در VPCها/VNetهای جداگانه اجرا شوند و نقش‌های IAM، گروه‌های امنیتی، یا اتصال شبکه اشتراکی نداشته باشند.
 #4.8.2    سطح: 1    نقش: D/V
 بررسی کنید که ارتقاء محیط نیاز به تأیید از سوی پرسنل مجاز تعریف شده سازمانی با امضاهای رمزنگاری شده و سوابق حسابرسی تغییرناپذیر دارد.
 #4.8.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که محیط‌های تولیدی دسترسی SSH را مسدود کرده‌اند، نقاط انتهایی دیباگ را غیرفعال کرده‌اند و درخواست‌های تغییر را با الزامات اطلاع‌رسانی از پیش سازمانی به جز موارد اضطراری، الزامی کرده‌اند.
 #4.8.4    سطح: 2    نقش: D/V
 تأیید کنید که تغییرات زیرساخت به عنوان کد نیازمند بازبینی همتا با آزمایش خودکار و اسکن امنیتی قبل از ادغام با شاخه اصلی است.
 #4.8.5    سطح: 2    نقش: D/V
 تأیید کنید که داده‌های غیرتولیدی مطابق با الزامات حفظ حریم خصوصی سازمانی ناشناس‌سازی شده باشند، تولید داده‌های مصنوعی صورت گرفته باشد، یا ماسک‌گذاری کامل داده‌ها با حذف اطلاعات شناسایی شخصی (PII) تأیید شده باشد.
 #4.8.6    سطح: 2    نقش: D/V
 تأیید کنید که دروازه‌های ارتقاء شامل تست‌های امنیتی خودکار (SAST، DAST، اسکن کانتینر) هستند و برای تأیید، هیچ یافته بحرانی CRITICAL وجود ندارد.

---

### پشتیبان‌گیری و بازیابی زیرساخت C4.9

اطمینان از تاب‌آوری زیرساخت از طریق پشتیبان‌گیری خودکار، آزمایش روش‌های بازیابی و قابلیت‌های بازیابی از فاجعه.

 #4.9.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که پیکربندی‌های زیرساخت طبق برنامه‌های پشتیبان‌گیری سازمانی به مناطق جغرافیایی جدا شده با اجرای استراتژی پشتیبان‌گیری 3-2-1 پشتیبان‌گیری می‌شوند.
 #4.9.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های پشتیبان‌گیری در شبکه‌های جداگانه با مدارک هویتی مستقل و ذخیره‌سازی ایزوله‌شده (air-gapped) برای محافظت در برابر باج‌افزارها اجرا می‌شوند.
 #4.9.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که رویه‌های بازیابی از طریق تست خودکار طبق برنامه‌های سازمانی با اهداف RTO و RPO که مطابق با نیازهای سازمانی هستند، آزمایش و اعتبارسنجی می‌شوند.
 #4.9.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که بازیابی بلایا شامل کتاب‌های راهنمای خاص هوش مصنوعی با بازیابی وزن مدل، بازسازی خوشه GPU، و نقشه‌برداری وابستگی‌های سرویس می‌باشد.

---

### C4.10 تطبیق و حاکمیت زیرساخت

رعایت انطباق با مقررات را از طریق ارزیابی مداوم، مستندسازی و کنترل‌های خودکار حفظ کنید.

 #4.10.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که انطباق زیرساخت‌ها مطابق با برنامه‌های سازمانی و بر اساس کنترل‌های SOC 2، ISO 27001، یا FedRAMP با جمع‌آوری خودکار مدارک ارزیابی می‌شود.
 #4.10.2    سطح: 2    نقش: V
 تأیید کنید که مستندات زیرساخت شامل نمودارهای شبکه، نقشه‌های جریان داده و مدل‌های تهدید باشد که مطابق با الزامات مدیریت تغییر سازمانی به‌روزرسانی شده‌اند.
 #4.10.3    سطح: 3    نقش: D/V
 تأیید کنید که تغییرات زیرساختی تحت ارزیابی تأثیر تطابق خودکار با جریان‌های کاری تأیید مقررات برای اصلاحات پرخطر قرار می‌گیرند.

---

### C4.11 امنیت سخت‌افزار هوش مصنوعی

قطعات سخت‌افزاری خاص AI شامل GPUها، TPUها، و تسریع‌کننده‌های تخصصی AI را امن کنید.

 #4.11.1    سطح: 2    نقش: D/V
 تأیید کنید که فرم‌ور شتاب‌دهنده‌های هوش مصنوعی (BIOS کارت گرافیک، فرم‌ور TPU) با امضاهای رمزنگاری شده تأیید شده و مطابق با جدول زمانی مدیریت وصله‌های سازمان به‌روزرسانی می‌شوند.
 #4.11.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که قبل از اجرای بار کاری، صحت شتاب‌دهنده هوش مصنوعی با استفاده از تایید سخت‌افزاری توسط TPM 2.0، Intel TXT، یا AMD SVM بررسی شده است.
 #4.11.3    سطح: 2    نقش: D/V
 تأیید کنید که حافظه GPU بین بارهای کاری با استفاده از SR-IOV، MIG (GPU چند نمونه‌ای) یا تقسیم‌بندی سخت‌افزاری معادل با پاک‌سازی حافظه بین وظایف ایزوله شده است.
 #4.11.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که زنجیره تامین سخت‌افزار هوش مصنوعی شامل تایید اصالت با گواهی‌های سازنده و اعتبارسنجی بسته‌بندی مقاوم در برابر دستکاری است.
 #4.11.5    سطح: 3    نقش: D/V
 تأیید کنید که ماژول‌های امنیت سخت‌افزاری (HSMها) وزن‌های مدل هوش مصنوعی و کلیدهای رمزنگاری را با گواهی FIPS 140-2 سطح 3 یا Common Criteria EAL4+ محافظت می‌کنند.

---

### C4.12 زیرساخت هوش مصنوعی لبه‌ای و توزیع‌شده

استقرارهای ایمن هوش مصنوعی توزیع‌شده شامل محاسبات لبه‌ای، یادگیری فدرال و معماری‌های چندسایتی.

 #4.12.1    سطح: 2    نقش: D/V
 تأیید کنید که دستگاه‌های لبه هوش مصنوعی (Edge AI) با استفاده از TLS متقابل و گواهی‌های دستگاه که مطابق با سیاست مدیریت گواهی سازمانی چرخش می‌کنند، به زیرساخت مرکزی احراز هویت می‌شوند.
 #4.12.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که دستگاه‌های لبه‌ای بوت امن با امضاهای تایید شده و حفاظت از بازگشت به نسخه قبلی را پیاده‌سازی می‌کنند تا از حملات کاهش نسخه نرم‌افزار سیستم جلوگیری شود.
 #4.12.3    سطح: 3    نقش: D/V
 تأیید کنید که هماهنگی هوش مصنوعی توزیع‌شده از الگوریتم‌های توافق مقاوم در برابر خطای بیزانتی با اعتبارسنجی شرکت‌کنندگان و شناسایی گره‌های مخرب استفاده می‌کند.
 #4.12.4    سطح: 3    نقش: D/V
 تأیید کنید که ارتباط لبه به ابر شامل محدودیت پهنای باند، فشرده‌سازی داده‌ها و قابلیت‌های عملکرد آفلاین با ذخیره‌سازی محلی امن باشد.

---

### C4.13 امنیت زیرساخت چندابری و ترکیبی

بارهای کاری هوش مصنوعی را در چندین ارائه‌دهنده ابری و استقرارهای ترکیبی ابری-محلی امن کنید.

 #4.13.1    سطح: 2    نقش: D/V
 تأیید کنید که استقرارهای چندابری هوش مصنوعی از فدراسیون هویت مستقل از ابر (OIDC، SAML) با مدیریت سیاست متمرکز در بین ارائه‌دهندگان استفاده می‌کنند.
 #4.13.2    سطح: 2    نقش: D/V
 تأیید کنید که انتقال داده بین ابرها از رمزگذاری سرتاسر با کلیدهای مدیریت‌شده توسط مشتری و کنترل‌های محل نگهداری داده که مطابق با هر حوزه قضایی اعمال می‌شود، استفاده می‌کند.
 #4.13.3    سطح: 2    نقش: D/V
 تأیید کنید که بارکاری‌های هوش مصنوعی ابری ترکیبی سیاست‌های امنیتی یکسانی را در محیط‌های محلی و ابری اجرا می‌کنند، به همراه نظارت و هشداردهی یکپارچه.
 #4.13.4    سطح: 3    نقش: V
 تأیید کنید که پیشگیری از قفل‌شدگی فروشنده ابر شامل زیرساخت قابل حمل به‌عنوان کد، APIهای استاندارد و قابلیت‌های صادرات داده با ابزارهای تبدیل فرمت است.
 #4.13.5    سطح: 3    نقش: V
 تأیید کنید که بهینه‌سازی هزینه‌های چندابری شامل کنترل‌های امنیتی است که از پراکندگی منابع جلوگیری می‌کند و همچنین هزینه‌های انتقال داده‌های غیرمجاز بین ابرهای مختلف را محدود می‌کند.

---

### C4.14 امنیت اتوماسیون زیرساخت و GitOps

خطوط لوله خودکارسازی زیرساخت ایمن و جریان‌های کاری GitOps برای مدیریت زیرساخت هوش مصنوعی.

 #4.14.1    سطح: 2    نقش: D/V
 بررسی کنید که مخازن GitOps نیازمند کامیت‌های امضا شده با کلیدهای GPG و قوانین حفاظت از شاخه باشند که از ارسال مستقیم به شاخه‌های اصلی جلوگیری می‌کند.
 #4.14.2    سطح: 2    نقش: D/V
 تأیید کنید که خودکارسازی زیرساخت شامل شناسایی انحراف (drift detection) با قابلیت‌های اصلاح خودکار و بازگردانی است که بر اساس نیازهای پاسخ سازمانی برای تغییرات غیرمجاز فعال می‌شود.
 #4.14.3    سطح: 2    نقش: D/V
 تأیید کنید که تأمین زیرساخت خودکار شامل اعتبارسنجی سیاست امنیتی همراه با مسدود کردن استقرار برای پیکربندی‌های غیرمطابق باشد.
 #4.14.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اسرار خودکارسازی زیرساخت از طریق عامل‌های مدیریت اسرار خارجی (External Secrets Operator، Bank-Vaults) با چرخش خودکار مدیریت می‌شوند.
 #4.14.5    سطح: 3    نقش: V
 تأیید کنید که زیرساخت خودترمیم شامل همبستگی رویدادهای امنیتی با پاسخ خودکار به حادثه و گردش کار اطلاع‌رسانی به ذینفعان است.

---

### C4.15 امنیت زیرساخت مقاوم در برابر کوانتومی

آمادگی زیرساخت هوش مصنوعی برای تهدیدات محاسبات کوانتومی از طریق رمزنگاری پساکوانتومی و پروتکل‌های ایمن در برابر کوانتوم.

 #4.15.1    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که زیرساخت هوش مصنوعی الگوریتم‌های رمزنگاری پساکوانتومی مورد تایید NIST (CRYSTALS-Kyber، CRYSTALS-Dilithium، SPHINCS+) را برای تبادل کلید و امضاهای دیجیتال پیاده‌سازی می‌کند.
 #4.15.2    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های توزیع کلید کوانتومی (QKD) برای ارتباطات هوش مصنوعی با امنیت بالا با پروتکل‌های مدیریت کلید کوانتومی-ایمن پیاده‌سازی شده‌اند.
 #4.15.3    سطح: 3    نقش: D/V
 تأیید کنید که چارچوب‌های انعطاف‌پذیری رمزنگاری امکان مهاجرت سریع به الگوریتم‌های پساکوانتومی جدید با چرخش خودکار گواهی و کلید را فراهم می‌کنند.
 #4.15.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که مدل‌سازی تهدید کوانتومی آسیب‌پذیری زیرساخت‌های هوش مصنوعی در برابر حملات کوانتومی را با زمان‌بندی‌های مستند مهاجرت و ارزیابی‌های ریسک بررسی می‌کند.
 #4.15.5    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های رمزنگاری ترکیبی کلاسیک-کوانتومی در دوره انتقال کوانتومی با نظارت بر عملکرد، دفاع در عمق را فراهم می‌کنند.

---

### C4.16 محاسبات محرمانه و محیط‌های امن

از محیط‌های اجرای مورد اعتماد مبتنی بر سخت‌افزار و فناوری‌های محاسبات محرمانه برای محافظت از بارهای کاری هوش مصنوعی و وزن‌های مدل استفاده کنید.

 #4.16.1    سطح: 3    نقش: D/V
 تأیید کنید که مدل‌های حساس هوش مصنوعی در محیط‌های محیطی Intel SGX، AMD SEV-SNP، یا ARM TrustZone با حافظه رمزگذاری شده و تأیید اعتبار اجرا می‌شوند.
 #4.16.2    سطح: 3    نقش: D/V
 تأیید کنید که کانتینرهای محرمانه (Kata Containers، gVisor با محاسبات محرمانه) بارهای کاری هوش مصنوعی را با رمزنگاری حافظه تحمیل شده توسط سخت‌افزار ایزوله می‌کنند.
 #4.16.3    سطح: 3    نقش: D/V
 تأیید کنید که تصدیق از راه دور، صحت انکلِیو را قبل از بارگذاری مدل‌های هوش مصنوعی با اثبات رمزنگاری‌شده از اعتبار محیط اجرایی تایید می‌کند.
 #4.16.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که خدمات استنتاج AI محرمانه از استخراج مدل از طریق محاسبات رمزنگاری‌شده با وزن‌های مدل مهر و موم‌شده و اجرای محافظت‌شده جلوگیری می‌کنند.
 #4.16.5    سطح: 3    نقش: D/V
 تأیید کنید که ارکستراسیون محیط اجرای مورد اعتماد، چرخه عمر انکلیو امن را با بررسی اعتبار از راه دور و کانال‌های ارتباطی رمزگذاری شده مدیریت می‌کند.
 #4.16.6    سطح: 3    نقش: D/V
 تأیید کنید که محاسبه چندجانبه امن (SMPC) امکان آموزش مشترک هوش مصنوعی را بدون آشکارسازی داده‌های فردی یا پارامترهای مدل فراهم می‌کند.

---

### C4.17 زیرساخت دانش-صفر

پیاده‌سازی سیستم‌های اثبات دانش صفر برای احراز هویت و تأیید هوش مصنوعی حفظ‌کننده حریم خصوصی بدون افشای اطلاعات حساس.

 #4.17.1    سطح: 3    نقش: D/V
 تأیید کنید که اثبات‌های دانش صفر (ZK-SNARKها، ZK-STARKها) صحت مدل هوش مصنوعی و منشأ آموزش را بدون افشای وزن‌های مدل یا داده‌های آموزشی تأیید می‌کنند.
 #4.17.2    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های احراز هویت مبتنی بر ZK اجازه می‌دهند تا تأیید هویت کاربران به صورت حفظ‌کننده حریم خصوصی برای خدمات هوش مصنوعی انجام شود بدون افشای اطلاعات مرتبط با هویت.
 #4.17.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که پروتکل‌های اشتراک دیتاست خصوصی (PSI) امکان تطبیق امن داده‌ها برای هوش مصنوعی فدرال را فراهم می‌کنند بدون اینکه داده‌های فردی را افشا کنند.
 #4.17.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های یادگیری ماشین دانش‌صفر (ZKML) برهان رمزنگاری شده‌ای از محاسبه صحیح ارائه می‌دهند که قابلیت تایید استنتاج‌های هوش مصنوعی را فراهم می‌کند.
 #4.17.5    سطح: 3    نقش: D/V
 تأیید کنید که ZK-rollups پردازش تراکنش‌های هوش مصنوعی را به صورت مقیاس‌پذیر و حفظ حریم خصوصی با تأیید دسته‌ای و کاهش بار محاسباتی ارائه می‌دهند.

---

### C4.18 پیشگیری از حملات کانال جانبی

زیرساخت هوش مصنوعی را از حملات کانال‌جانبی مبتنی بر زمان‌بندی، توان، الکترومغناطیسی و کش که ممکن است اطلاعات حساس را فاش کنند محافظت کنید.

 #4.18.1    سطح: 3    نقش: D/V
 تأیید کنید که زمان‌بندی استنتاج هوش مصنوعی با استفاده از الگوریتم‌های زمان ثابت و پدینگ نرمال شده است تا از حملات استخراج مدل مبتنی بر زمان جلوگیری شود.
 #4.18.2    سطح: 3    نقش: D/V
 تأیید کنید که حفاظت در برابر تحلیل توان شامل تزریق نویز، فیلتر کردن خطوط توان و الگوهای اجرای تصادفی برای سخت‌افزار هوش مصنوعی می‌شود.
 #4.18.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که کاهش کانال جانبی مبتنی بر کش از تقسیم‌بندی کش، تصادفی‌سازی و دستورالعمل‌های تخلیه برای جلوگیری از نشت اطلاعات استفاده می‌کند.
 #4.18.4    سطح: 3    نقش: D/V
 تأیید کنید که حفاظت در برابر انتشار الکترومغناطیسی شامل پوشش‌دهی (شیلدینگ)، فیلتر کردن سیگنال و پردازش تصادفی برای جلوگیری از حملات به سبک TEMPEST است.
 #4.18.5    سطح: 3    نقش: D/V
 تأیید کنید که دفاعیات جانبی میکرومعماری شامل کنترل‌های اجرای حدسی و پنهان‌سازی الگوی دسترسی به حافظه می‌باشند.

---

### C4.19 امنیت سخت‌افزار نورومورفیک و هوش مصنوعی تخصصی

امن‌سازی معماری‌های سخت‌افزاری نوظهور هوش مصنوعی شامل تراشه‌های نورومورفیک، FPGAها، ASICهای سفارشی و سیستم‌های محاسبات نوری.

 #4.19.1    سطح: 3    نقش: D/V
 تأیید کنید که امنیت تراشه نورومورفیک شامل رمزنگاری الگوهای پالس، حفاظت از وزن‌های سیناپسی و اعتبارسنجی قوانین یادگیری مبتنی بر سخت‌افزار است.
 #4.19.2    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که شتاب‌دهنده‌های هوش مصنوعی مبتنی بر FPGA رمزنگاری بیت‌استریم، مکانیزم‌های ضد دستکاری و بارگذاری پیکربندی امن با به‌روزرسانی‌های تأیید شده را پیاده‌سازی می‌کنند.
 #4.19.3    سطح: 3    نقش: D/V
 تأیید کنید که امنیت ASIC سفارشی شامل پردازنده‌های امنیتی روی تراشه، ریشه اعتماد سخت‌افزاری و ذخیره‌سازی کلید امن با قابلیت تشخیص دستکاری است.
 #4.19.4    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های محاسبات نوری رمزنگاری نوری مقاوم در برابر کوانتوم، سوئیچینگ فوتونیکی امن، و پردازش سیگنال نوری محافظت‌شده را پیاده‌سازی می‌کنند.
 #4.19.5    سطح: 3    نقش: D/V
 تأیید کنید که تراشه‌های هوش مصنوعی هیبریدی آنالوگ-دیجیتال شامل محاسبات امن آنالوگ، ذخیره‌سازی وزن محافظت‌شده، و تبدیل آنالوگ به دیجیتال معتبر باشند.

---

### C4.20 زیرساخت محاسباتی حفظ حریم خصوصی

پیاده‌سازی کنترل‌های زیرساختی برای محاسبات حفظ حریم خصوصی به منظور حفاظت از داده‌های حساس در طول پردازش و تحلیل هوش مصنوعی.

 #4.20.1    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که زیرساخت رمزنگاری همومورفیک امکان محاسبات رمزنگاری شده بر روی بارهای کاری حساس هوش مصنوعی را با تأیید صحت رمزنگاری شده و پایش عملکرد فراهم می‌کند.
 #4.20.2    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های بازیابی اطلاعات خصوصی امکان انجام پرس‌وجوهای پایگاه داده را بدون افشای الگوهای پرس‌وجو با حفاظت رمزنگاری‌شده از الگوهای دسترسی فراهم می‌کنند.
 #4.20.3    سطح: 3    نقش: D/V
 تأیید کنید که پروتکل‌های محاسبات چندجانبه امن امکان استنتاج هوش مصنوعی حفظ‌کننده حریم خصوصی را بدون افشای ورودی‌های فردی یا محاسبات میانی فراهم می‌کنند.
 #4.20.4    سطح: 3    نقش: D/V
 تأیید کنید که مدیریت کلید حفظ حریم خصوصی شامل تولید کلید توزیع‌شده، رمزنگاری آستانه‌ای و چرخش امن کلید با محافظت مبتنی بر سخت‌افزار است.
 #4.20.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که عملکرد محاسبات حفظ حریم خصوصی از طریق دسته‌بندی، کشینگ و تسریع سخت‌افزاری بهینه شده است، در حالی که تضمین‌های امنیت رمزنگاری حفظ می‌شود.

---

### چارچوب عامل C4.15 امنیت یکپارچه‌سازی ابری و استقرار ترکیبی

کنترل‌های امنیتی برای چارچوب‌های عامل یکپارچه با ابر با معماری‌های ترکیبی در محل/ابر.

 #4.15.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که ادغام ذخیره‌سازی ابری از رمزنگاری انتها به انتها با مدیریت کلید تحت کنترل نماینده استفاده می‌کند.
 #4.15.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مرزهای امنیتی استقرار هیبرید به‌وضوح تعریف شده‌اند و از کانال‌های ارتباطی رمزنگاری‌شده استفاده می‌شود.
 #4.15.3    سطح: 2    نقش: D/V
 تأیید کنید که دسترسی به منابع ابری شامل تأیید هویت بدون اعتماد با احراز هویت مداوم است.
 #4.15.4    سطح: 3    نقش: D/V
 تأیید کنید که الزامات محل اقامت داده‌ها توسط گواهی رمزنگاری شده از مکان‌های ذخیره‌سازی اعمال می‌شود.
 #4.15.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که ارزیابی‌های امنیتی ارائه‌دهنده خدمات ابری شامل مدل‌سازی تهدیدهای خاص عامل و ارزیابی ریسک می‌باشد.

---

### مراجع

NIST Cybersecurity Framework 2.0
CIS Controls v8
OWASP Container Security Verification Standard
Kubernetes Security Best Practices
SLSA Supply Chain Security Framework
NIST SP 800-190: Application Container Security Guide
Cloud Security Alliance: Cloud Controls Matrix
ENISA: Secure Infrastructure Design
NIST SP 800-53: Security Controls for Federal Information Systems
ISO 27001:2022 Information Security Management
NIST AI Risk Management Framework
CIS Kubernetes Benchmark
FIPS 140-2 Security Requirements
NIST SP 800-207: Zero Trust Architecture
IEEE 2857: Privacy Engineering for AI Systems
NIST SP 800-161: Cybersecurity Supply Chain Risk Management
NIST Post-Quantum Cryptography Standards
Intel SGX Developer Guide
AMD SEV-SNP White Paper
ARM TrustZone Technology
ZK-SNARKs: A Gentle Introduction
NIST SP 800-57: Cryptographic Key Management
Side-Channel Attack Countermeasures
Neuromorphic Computing Security Challenges
FPGA Security: Fundamentals, Evaluation, and Countermeasures
Microsoft SEAL: Homomorphic Encryption Library
HElib: Homomorphic Encryption Library
PALISADE Lattice Cryptography Library
Differential Privacy: A Survey of Results
Secure Aggregation for Federated Learning
Private Information Retrieval: Concepts and Constructions

## کنترل دسترسی C5 و هویت برای اجزاء و کاربران هوش مصنوعی

### هدف کنترل

کنترل دسترسی مؤثر برای سیستم‌های هوش مصنوعی نیازمند مدیریت هویت قوی، تأیید مجوز آگاه به زمینه و اجرای زمان اجرا طبق اصول اعتماد صفر است. این کنترل‌ها تضمین می‌کنند که انسان‌ها، خدمات و عامل‌های خودمختار تنها در محدوده‌های صریحاً مجاز شده با مدل‌ها، داده‌ها و منابع محاسباتی تعامل داشته باشند، همراه با قابلیت‌های تأیید و بررسی مداوم.

---

### C5.1 مدیریت هویت و احراز هویت

ایجاد هویت‌های مبتنی بر رمزنگاری برای همه نهادها با احراز هویت چندعاملی برای عملیات دارای امتیاز ویژه.

 #5.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که همه کاربران انسانی و اصول خدماتی از طریق یک ارائه‌دهنده هویت سازمانی متمرکز (IdP) با استفاده از پروتکل‌های OIDC/SAML احراز هویت می‌کنند، با نگاشت‌های یکتای هویت به توکن (عدم استفاده از حساب‌ها یا اعتبارنامه‌های مشترک).
 #5.1.2    سطح: 1    نقش: D/V
 تأیید کنید که عملیات‌های پرخطر (استقرار مدل، صدور وزن، دسترسی به داده‌های آموزش، تغییرات پیکربندی تولید) نیازمند احراز هویت چندعاملی یا احراز هویت افزایشی با بازتأیید جلسه باشند.
 #5.1.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که مدیران جدید قبل از دسترسی به سیستم تولید، فرآیند احراز هویت هویتی را مطابق با استانداردهای NIST 800-63-3 IAL-2 یا معادل آن گذرانده باشند.
 #5.1.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که بازبینی‌های دسترسی به صورت فصلی انجام می‌شود با تشخیص خودکار حساب‌های غیرفعال، اجرای چرخش اعتبارات و جریان‌های کاری حذف دسترسی.
 #5.1.5    سطح: 3    نقش: D/V
 تأیید کنید که عوامل هوش مصنوعی فدرال از طریق ادعاهای JWT امضا شده که حداکثر مدت زمان زندگی آنها 24 ساعت است و شامل اثبات رمزنگاری شده منبع می‌باشند، احراز هویت می‌شوند.

---

### C5.2 مجوز دسترسی منابع و حداقل امتیاز

اجرای کنترل‌های دسترسی دقیق برای تمام منابع هوش مصنوعی با مدل‌های اجازه صریح و مسیرهای حسابرسی.

 #5.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر منبع هوش مصنوعی (مجموعه‌داده‌ها، مدل‌ها، نقاط پایانی، مجموعه‌های برداری، شاخص‌های جاسازی‌شده، نمونه‌های محاسباتی) کنترل‌های دسترسی مبتنی بر نقش را با فهرست‌های اجازه صریح و سیاست‌های پیش‌فرض انکار اجرا می‌کند.
 #5.2.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که اصول حداقل امتیاز به طور پیش‌فرض با حساب‌های سرویس اجرا می‌شوند، به گونه‌ای که مجوزهای فقط خواندنی در ابتدا اعمال شده و مستندات توجیه کسب‌وکار برای دسترسی نوشتن لازم است.
 #5.2.3    سطح: 1    نقش: V
 تأیید کنید که تمامی تغییرات کنترل دسترسی به درخواست‌های تغییر تأیید شده مرتبط هستند و به‌صورت غیرقابل تغییر با زمان‌سنجی، هویت بازیگر، شناسه‌های منابع و تفاوت‌های مجوز ثبت شده‌اند.
 #5.2.4    سطح: 2    نقش: D
 تأیید کنید که برچسب‌های طبقه‌بندی داده‌ها (PII، PHI، کنترل شده توسط صادرات، مالکیتی) به‌طور خودکار به منابع مشتق شده (تعبیه‌ها، کش‌های پرامپت، خروجی‌های مدل) با رعایت سیاست‌های سازگار منتقل می‌شوند.
 #5.2.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تلاش‌های دسترسی غیرمجاز و رویدادهای افزایش امتیازات، هشدارهای بلادرنگ با متادیتای متنی به سیستم‌های SIEM را ظرف 5 دقیقه ایجاد می‌کنند.

---

### C5.3 ارزیابی سیاست پویا

موتورهای کنترل دسترسی مبتنی بر ویژگی (ABAC) را برای تصمیم‌گیری‌های مجوزدهی مبتنی بر زمینه با قابلیت‌های حسابرسی مستقر کنید.

 #5.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تصمیمات مجوزدهی به یک موتور سیاست اختصاصی (OPA، Cedar، یا معادل آن) که از طریق APIهای احراز هویت‌شده با حفاظت از صحت رمزنگاری قابل دسترسی است، برون‌سپاری شده‌اند.
 #5.3.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیاست‌ها هنگام اجرا ویژگی‌های پویا مانند سطح دسترسی کاربر، طبقه‌بندی حساسیت منابع، زمینه درخواست، جداسازی مستاجر و محدودیت‌های زمانی را ارزیابی می‌کنند.
 #5.3.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که تعاریف سیاست‌ها تحت کنترل نسخه، بررسی‌شده توسط همتایان، و از طریق تست‌های خودکار در خطوط لوله CI/CD قبل از استقرار در محیط تولید معتبر شده‌اند.
 #5.3.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که نتایج ارزیابی سیاست شامل دلایل ساختاریافته برای تصمیم‌گیری است و به سیستم‌های SIEM برای تحلیل همبستگی و گزارش‌دهی انطباق ارسال می‌شود.
 #5.3.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مقادیر زمان حیات کش سیاست (TTL) برای منابع با حساسیت بالا از 5 دقیقه تجاوز نکند و برای منابع استاندارد با قابلیت ابطال کش از 1 ساعت بیشتر نشود.

---

### اجرای امنیت در زمان اجرای پرس‌وجو C5.4

کنترل‌های امنیتی لایه پایگاه داده را با فیلترینگ اجباری و سیاست‌های امنیتی سطح ردیف پیاده‌سازی کنید.

 #5.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که همه پرس‌وجوهای پایگاه داده برداری و SQL شامل فیلترهای امنیتی اجباری (شناسه مستاجر، برچسب‌های حساسیت، دامنه کاربر) هستند که در سطح موتور پایگاه داده اعمال می‌شوند و نه در کد برنامه.
 #5.4.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیاست‌های امنیت سطح ردیف (RLS) و ماسک‌گذاری سطح فیلد با ارث‌بری سیاست برای تمام پایگاه‌های داده وکتور، شاخص‌های جستجو و مجموعه داده‌های آموزشی فعال شده باشند.
 #5.4.3    سطح: 2    نقش: D
 تأیید کنید که ارزیابی‌های مجوز ناموفق از حملات «معاون سردرگم» جلوگیری می‌کنند با قطع فوری پرس‌وجوها و بازگرداندن کدهای خطای مجوز صریح به جای بازگرداندن مجموعه نتایج خالی.
 #5.4.4    سطح: 2    نقش: V
 اطمینان حاصل شود که تأخیر ارزیابی سیاست به طور مستمر با هشدارهای خودکار برای شرایط تایم‌اوت که ممکن است امکان دور زدن مجوز را فراهم کنند، نظارت می‌شود.
 #5.4.5    سطح: 3    نقش: D/V
 تأیید کنید که مکانیزم‌های تلاش مجدد پرس‌و‌جو سیاست‌های مجوزدهی را مجدداً ارزیابی می‌کنند تا تغییرات دینامیکی دسترسی‌ها در طی جلسات فعال کاربر در نظر گرفته شوند.

---

### فیلتر خروجی C5.5 و پیشگیری از نشت داده‌ها

کنترل‌های پس‌پردازش را برای جلوگیری از افشای غیرمجاز داده‌ها در محتوای تولید شده توسط هوش مصنوعی پیاده‌سازی کنید.

 #5.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های فیلترینگ پس از استنتاج، اطلاعات شخصی شناسایی‌نشده (PII)، اطلاعات طبقه‌بندی‌شده و داده‌های مالیکی را قبل از تحویل محتوا به درخواست‌کنندگان، اسکن و حذف می‌کنند.
 #5.5.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که ارجاعات، منابع و انتساب‌های منبع در خروجی‌های مدل بر اساس مجوزهای فراخواننده اعتبارسنجی شده و در صورت شناسایی دسترسی غیرمجاز حذف شوند.
 #5.5.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که محدودیت‌های فرمت خروجی (PDFهای پاک‌سازی شده، تصاویر بدون متادیتا، انواع فایل‌های تأیید شده) بر اساس سطوح دسترسی کاربران و طبقه‌بندی داده‌ها اعمال می‌شوند.
 #5.5.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که الگوریتم‌های حذف اطلاعات تعیین‌پذیر، کنترل‌شده به‌وسیله نسخه، و دارای ثبت گزارش‌های حسابرسی هستند تا از تحقیقات تطابق و تجزیه و تحلیل قانونی پشتیبانی نمایند.
 #5.5.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که رویدادهای حذف اطلاعات با ریسک بالا، لاگ‌های تطبیقی تولید می‌کنند که شامل هش‌های رمزنگاری شده از محتوای اصلی برای بازیابی قانونی بدون افشای داده‌ها باشند.

---

### C5.6 جداسازی چندمستاجری

اطمینان حاصل کنید که جداسازی رمزنگاری و منطقی بین مستاجرها در زیرساخت مشترک هوش مصنوعی برقرار باشد.

 #5.6.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که فضاهای حافظه، ذخیره‌سازی‌های جاسازی، ورودی‌های کش و فایل‌های موقت به‌طور جداگانه براساس فضای نام هر مستأجر تفکیک شده‌اند و پاک‌سازی ایمن هنگام حذف مستأجر یا پایان جلسه انجام می‌شود.
 #5.6.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر درخواست API شامل یک شناسه مستأجر احراز هویت شده باشد که به صورت رمزنگاری شده با زمینه جلسه و مجوزهای کاربر اعتبارسنجی شده است.
 #5.6.3    سطح: 2    نقش: D
 تأیید کنید که سیاست‌های شبکه قوانین پیش‌فرض رد کردن (default-deny) را برای ارتباطات بین مستاجران (cross-tenant) درون شبکه‌های سرویس و پلتفرم‌های ارکستراسیون کانتینر پیاده‌سازی می‌کنند.
 #5.6.4    سطح: 3    نقش: D
 اطمینان حاصل کنید که کلیدهای رمزگذاری برای هر مستأجر یکتا هستند، با پشتیبانی از کلید مدیریت شده توسط مشتری (CMK) و جداسازی رمزنگاری بین مخازن داده‌های مستأجران.

---

### C5.7 مجوز عامل خودکار

کنترل مجوزها برای عوامل هوش مصنوعی و سیستم‌های خودمختار از طریق توکن‌های قابلیت محدود شده و احراز هویت مستمر.

 #5.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که عوامل خودمختار توکن‌های قابلیت محدود شده دریافت می‌کنند که اقدامات مجاز، منابع قابل دسترسی، محدوده‌های زمانی و محدودیت‌های عملیاتی را به‌طور صریح فهرست می‌کنند.
 #5.7.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که قابلیت‌های پرخطر (دسترسی به سیستم فایل، اجرای کد، تماس‌های API خارجی، تراکنش‌های مالی) به‌طور پیش‌فرض غیرفعال بوده و برای فعال‌سازی آن‌ها مجوزهای صریح همراه با توجیهات تجاری لازم است.
 #5.7.3    سطح: 2    نقش: D
 تأیید کنید که توکن‌های قابلیت به جلسات کاربری متصل شده‌اند، شامل حفاظت از صحت رمزنگاری هستند و اطمینان حاصل شود که نمی‌توان آنها را در سناریوهای آفلاین ذخیره یا مجدداً استفاده کرد.
 #5.7.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که اقدامات آغاز شده توسط عامل از طریق موتور سیاست ABAC با ارزیابی کامل زمینه و ثبت لاگ حسابرسی، تحت تأیید ثانویه قرار می‌گیرند.
 #5.7.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که شرایط خطای عامل و مدیریت استثنا شامل اطلاعات دامنه قابلیت برای پشتیبانی از تحلیل حادثه و بررسی جرم‌شناسی باشد.

---

### مراجع

#### استانداردها و چارچوب‌ها

NIST SP 800-63-3: Digital Identity Guidelines
Zero Trust Architecture – NIST SP 800-207
OWASP Application Security Verification Standard (AISVS)
​
#### راهنمای پیاده‌سازی

Identity and Access Management in the AI Era: 2025 Guide – IDSA
Attribute-Based Access Control with OPA – Permify
How We Designed Cedar to Be Intuitive, Fast, and Safe – AWS
​
#### امنیت ویژه هوش مصنوعی

Row Level Security in Vector DBs for RAG – Bluetuple.ai
Tenant Isolation in Multi-Tenant Systems – WorkOS
Handling AI Agent Permissions – Stytch
OWASP Top 10 for Large Language Model Applications

## امنیت زنجیره تأمین C6 برای مدل‌ها، چارچوب‌ها و داده‌ها

### هدف کنترل

حملات زنجیره تأمین هوش مصنوعی از مدل‌ها، چارچوب‌ها یا مجموعه داده‌های شخص ثالث سوءاستفاده می‌کنند تا درهای پشتی، تعصب یا کدهای قابل سوءاستفاده را جاسازی کنند. این کنترل‌ها منشأ انتها به انتها، مدیریت آسیب‌پذیری و نظارت را فراهم می‌کنند تا از کل چرخه عمر مدل محافظت کنند.

---

### C6.1 ارزیابی و منشأ مدل پیش‌آموزش‌دیده

قبل از هرگونه ریزتنظیم یا استقرار، منشاء مدل‌های شخص ثالث، مجوزها و رفتارهای پنهان آن‌ها را ارزیابی و تایید کنید.

 #6.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر اثر مدل شخص ثالث شامل یک رکورد منشأ امضا شده است که مخزن منبع و هش کامیت را شناسایی می‌کند.
 #6.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مدل‌ها قبل از وارد شدن با استفاده از ابزارهای خودکار برای لایه‌های مخرب یا محرک‌های تروجان اسکن شده باشند.
 #6.1.3    سطح: 2    نقش: D
 تأیید کنید که تنظیم دقیق در یادگیری انتقالی توانایی عبور از ارزیابی خصمانه برای شناسایی رفتارهای پنهان را دارد.
 #6.1.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که مجوزهای مدل، برچسب‌های کنترل صادرات، و بیانیه‌های منشأ داده در یک ورودی ML-BOM ثبت شده‌اند.
 #6.1.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مدل‌های پرخطر (وزن‌های بارگذاری شده عمومی، سازندگان تایید نشده) تا زمان بررسی و تایید انسانی در قرنطینه باقی بمانند.

---

### C6.2 اسکن فریم‌ورک و کتابخانه

به‌طور مداوم چارچوب‌ها و کتابخانه‌های یادگیری ماشین را برای CVEها و کدهای مخرب اسکن کنید تا لایه اجرای برنامه امن باقی بماند.

 #6.2.1    سطح: 1    نقش: D/V
 تأیید کنید که خط‌های لوله CI اسکنرهای وابستگی را روی چارچوب‌های هوش مصنوعی و کتابخانه‌های حیاتی اجرا می‌کنند.
 #6.2.2    سطح: 1    نقش: D/V
 تأیید کنید که آسیب‌پذیری‌های بحرانی (CVSS ≥ 7.0) از ارتقاء به تصاویر تولیدی جلوگیری می‌کنند.
 #6.2.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که تجزیه و تحلیل کد ایستا بر روی کتابخانه‌های یادگیری ماشین شاخه‌گیری شده یا وارد شده اجرا می‌شود.
 #6.2.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که پیشنهادهای ارتقاء چارچوب شامل ارزیابی تأثیر امنیتی با ارجاع به منابع عمومی CVE باشد.
 #6.2.5    سطح: 3    نقش: V
 تأیید کنید که سنسورهای زمان اجرا نسبت به بارگذاری‌های غیرمنتظره کتابخانه‌های پویا که از SBOM امضا شده انحراف دارند، هشدار دهند.

---

### C6.3 ثابت‌سازی و تأیید وابستگی‌ها

تمام وابستگی‌ها را به صورت بلادرنگ و غیرقابل تغییر قفل کنید و ساخت‌ها را بازتولید کنید تا اطمینان حاصل شود که مصنوعات به صورت یکسان و بدون تغییر هستند.

 #6.3.1    سطح: 1    نقش: D/V
 تأیید کنید که همه مدیران بسته‌ها اعمال قفل نسخه (version pinning) را از طریق فایل‌های قفل انجام می‌دهند.
 #6.3.2    سطح: 1    نقش: D/V
 تأیید کنید که در مراجع کانتینر به‌جای برچسب‌های قابل تغییر، خلاصه‌های تغییرناپذیر استفاده شده است.
 #6.3.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که بررسی‌های ساخت قابل تولید، هش‌ها را در اجرای مداوم CI مقایسه می‌کنند تا خروجی‌های یکسان را تضمین کنند.
 #6.3.4    سطح: 2    نقش: V
 تأیید کنید که تصدیق‌های ساخت به مدت 18 ماه برای ردیابی حسابرسی ذخیره می‌شوند.
 #6.3.5    سطح: 3    نقش: D
 تأیید کنید که وابستگی‌های منقضی شده درخواست‌های کشش خودکاری را برای به‌روزرسانی یا فورک نسخه‌های پین‌شده تحریک می‌کنند.

---

### C6.4 اجرای منبع مورد اعتماد

دانلود آرتیفکت‌ها را فقط از منابع تأیید شده رمزنگاری شده و مورد تأیید سازمان مجاز کنید و همه چیزهای دیگر را مسدود نمایید.

 #6.4.1    سطح: 1    نقش: D/V
 تأیید کنید که وزن‌های مدل، مجموعه داده‌ها و کانتینرها فقط از دامنه‌های تأیید شده یا ثبت‌کننده‌های داخلی دانلود می‌شوند.
 #6.4.2    سطح: 1    نقش: D/V
 تأیید کنید که امضاهای Sigstore/Cosign هویت ناشر را قبل از ذخیره محلی آثار اعتبارسنجی می‌کنند.
 #6.4.3    سطح: 2    نقش: D
 تأیید کنید که پراکسی‌های خروجی دانلودهای بدون احراز هویت آثار را مسدود می‌کنند تا سیاست منبع قابل اعتماد را اجرا کنند.
 #6.4.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که فهرست‌های مجاز مخزن به صورت سه‌ماهه بازبینی شده‌اند و برای هر ورودی مدارک توجیه کسب‌وکار ارائه شده است.
 #6.4.5    سطح: 3    نقش: V
 تأیید کنید که نقض سیاست‌ها باعث قرنطینه شدن آثار و بازگردانی اجرای خطوط لوله وابسته می‌شود.

---

### C6.5 ارزیابی ریسک مجموعه داده‌های شخص ثالث

داده‌های خارجی را از نظر آلودگی، جانب داری و انطباق قانونی ارزیابی کرده و آنها را در طول چرخه عمرشان تحت نظارت قرار دهید.

 #6.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل شود که مجموعه داده‌های خارجی تحت ارزیابی ریسک دستکاری قرار می‌گیرند (مانند اثر انگشت داده‌ها، تشخیص نمونه‌های پرت).
 #6.5.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که معیارهای سوگیری (توازن جمعیتی، فرصت برابر) قبل از تایید مجموعه داده محاسبه شده‌اند.
 #6.5.3    سطح: 2    نقش: V
 تأیید کنید که اطلاعات منبع و شرایط مجوز برای مجموعه داده‌ها در ورودی‌های ML‑BOM ثبت شده باشند.
 #6.5.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که نظارت دوره‌ای باعث شناسایی انحراف یا فساد در مجموعه داده‌های میزبانی شده می‌شود.
 #6.5.5    سطح: 3    نقش: D
 اطمینان حاصل کنید که محتوای ممنوعه (حق نشر، اطلاعات شناسایی شخصی) قبل از آموزش از طریق پاک‌سازی خودکار حذف شده است.

---

### C6.6 نظارت بر حملات زنجیره تامین

تشخیص زودهنگام تهدیدات زنجیره تأمین از طریق خوراک‌های CVE، تحلیل‌های لاگ‌های حسابرسی، و شبیه‌سازی‌های تیم قرمز.

 #6.6.1    سطح: 1    نقش: V
 اطمینان حاصل کنید که لاگ‌های حسابرسی CI/CD به صورت جریان به تشخیص‌های SIEM برای کشش‌های بسته نامعمول یا مراحل ساخت دستکاری شده ارسال می‌شوند.
 #6.6.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که کتابچه‌های عملیات پاسخ به حوادث شامل روندهای بازگشت به وضعیت قبلی برای مدل‌ها یا کتابخانه‌های دچار اختلال هستند.
 #6.6.3    سطح: 3    نقش: V
 اطمینان حاصل کنید که برچسب‌های غنی‌سازی اطلاعات تهدید، شاخص‌های خاص یادگیری ماشین (مثلاً IoCهای مربوط به مسمومیت مدل) را در دسته‌بندی هشدار مشخص می‌کنند.

---

### C6.7 لیست مواد ماشین لرنینگ (ML-BOM) برای آثار مدل

تولید و امضای SBOMهای خاص یادگیری ماشین (ML-BOMها) با جزئیات دقیق تا مصرف‌کنندگان پایین‌دست بتوانند در زمان استقرار، صحت اجزا را تأیید کنند.

 #6.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر مدل مصنوعی یک ML-BOM منتشر می‌کند که شامل دیتاست‌ها، وزن‌ها، ابرپارامترها و مجوزها باشد.
 #6.7.2    سطح: 1    نقش: D/V
 تأیید کنید که تولید ML‑BOM و امضای Cosign در CI خودکار شده و برای ادغام الزامی است.
 #6.7.3    سطح: 2    نقش: D
 بررسی کنید که چک‌های کامل بودن ML‑BOM در صورت فقدان هرگونه فراداده مؤلفه (هش، مجوز) منجر به شکست ساخت شوند.
 #6.7.4    سطح: 2    نقش: V
 تأیید کنید که مصرف‌کنندگان پایین‌دستی می‌توانند از طریق API به ML-BOMها پرس‌وجو کنند تا مدل‌های واردشده را در زمان استقرار اعتبارسنجی کنند.
 #6.7.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که ML‑BOMها نسخه‌بندی شده و به منظور تشخیص تغییرات غیرمجاز، مقایسه شده‌اند.

---

### مراجع

ML Supply Chain Compromise – MITRE ATLAS
Supply‑chain Levels for Software Artifacts (SLSA)
CycloneDX – Machine Learning Bill of Materials
What is Data Poisoning? – SentinelOne
Transfer Learning Attack – OWASP ML Security Top 10
AI Data Security Best Practices – CISA
Secure CI/CD Supply Chain – Sumo Logic
AI & Transparency: Protect ML Models – ReversingLabs
SBOM Overview – CISA
Training Data Poisoning Guide – Lakera.ai
Dependency Pinning for Reproducible Python – Medium

## رفتار مدل C7، کنترل خروجی و تضمین ایمنی

### هدف کنترل

خروجی‌های مدل باید ساختاریافته، قابل‌اطمینان، ایمن، قابل‌توضیح و به‌طور مداوم در تولید پایش شوند. انجام این کار باعث کاهش توهم‌ها، نشت‌های حریم خصوصی، محتوای مضر و اقدامات کنترل‌نشده می‌شود، در حالی که اعتماد کاربران و تطابق با مقررات را افزایش می‌دهد.

---

### C7.1 اجرای فرمت خروجی

اسکیم‌های سخت‌گیرانه، رمزگشایی محدود شده و اعتبارسنجی مرحله بعدی مانع از انتشار محتوای نادرست یا مخرب می‌شوند.

 #7.1.1    سطح: 1    نقش: D/V
 بررسی کنید که اسکیماهای پاسخ (مانند JSON Schema) در فرمان سیستم ارائه شده باشند و هر خروجی به طور خودکار اعتبارسنجی شود؛ خروجی‌هایی که با آن مطابقت نداشته باشند موجب تعمیر یا رد شدن شوند.
 #7.1.2    سطح: 1    نقش: D/V
 تأیید کنید که رمزگشایی محدود شده (توکن‌های توقف، عبارات منظم، حداکثر توکن‌ها) فعال است تا از سرریز یا کانال‌های جانبی تزریق پراپمت جلوگیری شود.
 #7.1.3    سطح: 2    نقش: D/V
 تأیید کنید که اجزای پایین‌دستی خروجی‌ها را به‌عنوان ناامن در نظر گرفته و آن‌ها را در برابر طرح‌واره‌ها یا د-سریالایزرهای ایمن در برابر تزریق اعتبارسنجی کنند.
 #7.1.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که رویدادهای خروجی نامناسب ثبت، محدودسازی نرخ شده و به نظارت نمایش داده می‌شوند.

---

### C7.2 تشخیص و کاهش هذیان

برآورد عدم قطعیت و استراتژی‌های پشتیبان پاسخ‌های ساختگی را مهار می‌کنند.

 #7.2.1    سطح: 1    نقش: D/V
 تأیید کنید که احتمال‌های لگاریتمی در سطح توکن، انسجام خود گروهی ансамбلی، یا آشکارسازهای هذیان تنظیم‌شده به‌دقت، به هر پاسخ امتیاز اعتماد اختصاص می‌دهند.
 #7.2.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که پاسخ‌هایی با اطمینان کمتر از آستانه قابل تنظیم، جریان‌های کاری جایگزین را فعال می‌کنند (مثلاً تولید افزوده به بازیابی، مدل ثانویه، یا بازبینی انسانی).
 #7.2.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که حوادث هذیان با متادیتای علت ریشه‌ای برچسب‌گذاری شده و به خطوط لوله پسامرتیم و تنظیم دقیق داده می‌شوند.
 #7.2.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که پس از به‌روزرسانی‌های عمده مدل یا پایگاه دانش، آستانه‌ها و آشکارسازها دوباره کالیبره شده‌اند.
 #7.2.5    سطح: 3    نقش: V
 تأیید کنید که تجسم‌های داشبورد میزان توهم‌سازی را ردیابی می‌کنند.

---

### فیلترینگ ایمنی و حفظ حریم خصوصی خروجی C7.3

فیلترهای سیاستی و پوشش تیم قرمز از کاربران و داده‌های محرمانه محافظت می‌کنند.

 #7.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که طبقه‌بندهای پیش و پس از تولید، محتوای نفرت‌انگیز، آزاردهنده، خودآسیب‌رسان، تندروانه و دارای محتوای جنسی صریح که با سیاست‌ها تطابق دارد را مسدود می‌کنند.
 #7.3.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که شناسایی PII/PCI و پاک‌سازی خودکار در هر پاسخ اجرا می‌شود؛ تخلفات منجر به بروز حادثه حفظ حریم خصوصی می‌شود.
 #7.3.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که برچسب‌های محرمانگی (مانند اسرار تجاری) در تمام مدالیته‌ها منتقل می‌شوند تا از نشت اطلاعات در متن، تصاویر یا کد جلوگیری شود.
 #7.3.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تلاش‌های عبور از فیلتر یا دسته‌بندی‌های پرخطر نیازمند تایید ثانویه یا دوباره‌تصدیق کاربر هستند.
 #7.3.5    سطح: 3    نقش: D/V
 تأیید کنید که آستانه‌های فیلترسازی بازتاب‌دهنده حوزه‌های قضایی قانونی و زمینه سنی/نقشی کاربر باشند.

---

### C7.4 محدودسازی خروجی و عمل

محدودیت‌های نرخ و دروازه‌های تایید از سوءاستفاده و خودمختاری بیش از حد جلوگیری می‌کنند.

 #7.4.1    سطح: 1    نقش: D
 تأیید کنید که سهمیه‌های هر کاربر و هر کلید API درخواست‌ها، توکن‌ها و هزینه‌ها را با توقف نمایی در صورت خطاهای 429 محدود می‌کنند.
 #7.4.2    سطح: 1    نقش: D/V
 تأیید کنید که اقدامات پرامتیاز (نوشتن فایل، اجرای کد، تماس‌های شبکه) نیازمند تأیید مبتنی بر سیاست یا دخالت انسانی هستند.
 #7.4.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که بررسی‌های تطابق بین‌مدالی تضمین می‌کنند که تصاویر، کد و متنی که برای یک درخواست مشابه تولید می‌شوند، نمی‌توانند برای قاچاق محتوای مخرب استفاده شوند.
 #7.4.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که عمق واگذاری نماینده، محدودیت‌های بازگشتی و فهرست ابزارهای مجاز به طور صریح تنظیم شده‌اند.
 #7.4.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که نقض محدودیت‌ها رویدادهای امنیتی ساختاریافته‌ای را برای ورود به SIEM ارسال می‌کند.

---

### قابل توضیح بودن خروجی C7.5

سیگنال‌های شفاف باعث افزایش اعتماد کاربران و تسهیل رفع اشکال داخلی می‌شوند.

 #7.5.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که امتیازات اطمینان نمایش داده شده به کاربر یا خلاصه‌های کوتاه استدلال زمانی که ارزیابی ریسک مناسب تشخیص داده شود، ارائه می‌شوند.
 #7.5.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که توضیحات تولید شده از فاش کردن دستورات حساس سیستم یا داده‌های اختصاصی خودداری می‌کنند.
 #7.5.3    سطح: 3    نقش: D
 اطمینان حاصل کنید که سیستم احتمال‌های لاگ در سطح توکن یا نقشه‌های توجه را ضبط می‌کند و آن‌ها را برای بازرسی مجاز ذخیره می‌کند.
 #7.5.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که مصنوعات توضیح‌پذیری همزمان با انتشار مدل‌ها تحت کنترل نسخه قرار دارند تا قابلیت حسابرسی فراهم شود.

---

### C7.6 یکپارچه‌سازی نظارت

قابلیت مشاهده در زمان واقعی حلقه بین توسعه و تولید را می‌بندد.

 #7.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که معیارها (نقض‌های ساختار داده، نرخ توهم، سمی بودن، نشت اطلاعات شناسایی شخصی، تأخیر، هزینه) به یک پلتفرم مرکزی نظارت ارسال می‌شوند.
 #7.6.2    سطح: 1    نقش: V
 اطمینان حاصل کنید که آستانه‌های هشدار برای هر معیار ایمنی تعریف شده باشد و مسیرهای تصعید برای تماس اضطراری مشخص شده باشند.
 #7.6.3    سطح: 2    نقش: V
 تأیید کنید که داشبوردها ناهنجاری‌های خروجی را با مدل/نسخه، علامت ویژگی و تغییرات داده‌های ورودی مرتبط می‌سازند.
 #7.6.4    سطح: 2    نقش: D/V
 تأیید کنید که داده‌های نظارتی به بازآموزی، تنظیم دقیق یا به‌روزرسانی قوانین در یک گردش کار مستند MLOps بازخورد داده می‌شوند.
 #7.6.5    سطح: 3    نقش: V
 تأیید کنید که خطوط لوله نظارتی از نظر نفوذ تست شده و کنترل دسترسی دارند تا از نشت لاگ‌های حساس جلوگیری شود.

---

### 7.7 تدابیر حفاظتی رسانه‌های مولد

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی محتوای رسانه‌ای غیرقانونی، مضر یا غیرمجاز تولید نکنند، از طریق اعمال محدودیت‌های سیاستی، اعتبارسنجی خروجی و قابلیت ردیابی.

 #7.7.1    سطح: 1    نقش: D/V
 تأیید کنید که دستورهای سیستم و راهنمایی‌های کاربر به‌طور صریح تولید رسانه‌های دیپ‌فیک غیرقانونی، مضر یا بدون رضایت (مانند تصویر، ویدئو، صدا) را ممنوع می‌کنند.
 #7.7.2    سطح: 2    نقش: D/V
 تأیید کنید که درخواست‌ها برای تلاش‌های ایجاد تقلید از شخصیت‌ها، تصاویر جعلی جنسی صریح، یا رسانه‌هایی که افراد واقعی را بدون رضایت نشان می‌دهند، فیلتر می‌شوند.
 #7.7.3    سطح: 2    نقش: V
 تأیید کنید که سیستم از هش گیری ادراکی، تشخیص نشان‌گذاری یا اثرانگشت‌گذاری برای جلوگیری از تکثیر غیرمجاز رسانه‌های دارای حق نشر استفاده می‌کند.
 #7.7.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تمام رسانه‌های تولید شده به‌طور رمزنگاری امضا شده، دارای علامت آبی (واترمارک)، یا همراه با متادیتای اثبات منبع مقاوم در برابر دستکاری برای ردیابی در مراحل بعدی باشند.
 #7.7.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که تلاش‌های دور زدن (مانند مبهم‌سازی دستورات، زبان عامیانه، عبارت‌بندی خصمانه) شناسایی، ثبت و نرخ محدود می‌شوند؛ سوءاستفاده مکرر به سیستم‌های نظارتی گزارش داده می‌شود.

### مراجع

NIST AI Risk Management Framework
ISO/IEC 42001:2023 – AI Management System
OWASP Top-10 for Large Language Model Applications (2025)
Improper Output Handling – OWASP LLM05:2025
Practical Techniques to Constrain LLM Output
Dataiku – Structured Text Generation Guide
VL-Uncertainty: Detecting Hallucinations
HaDeMiF: Hallucination Detection & Mitigation
Building Confidence in LLM Outputs
Explainable AI & LLMs
LLM Red-Teaming Guide
Sensitive Information Disclosure in LLMs
LangChain – Chat Model Rate Limiting
OpenAI Rate-Limit & Exponential Back-off
Arize AI – LLM Observability Platform

## امنیت حافظه C8، تعبیه‌ها و پایگاه داده‌های برداری

### هدف کنترل

تعبیه‌ها و فروشگاه‌های برداری به‌عنوان «حافظه زنده» سیستم‌های هوش مصنوعی معاصر عمل می‌کنند، به‌طور مستمر داده‌های ارائه شده توسط کاربر را دریافت کرده و از طریق تولید تقویت‌شده با بازیابی (RAG) آن‌ها را دوباره در زمینه‌های مدل نمایش می‌دهند. اگر این حافظه بدون نظارت باقی بماند، ممکن است اطلاعات شناسایی شخصی (PII) را نشت دهد، رضایت را نقض کند یا به‌صورت معکوس برای بازسازی متن اصلی استفاده شود. هدف این خانواده کنترل‌ها، تقویت خطوط انتقال حافظه و پایگاه‌های داده برداری است به‌گونه‌ای که دسترسی حداقل مجاز باشد، تعبیه‌ها حریم خصوصی را حفظ کنند، بردارهای ذخیره‌شده منقضی شوند یا در صورت درخواست لغو شوند، و حافظه هر کاربر هرگز باعث آلودگی پیام‌ها یا تکمیل‌های کاربران دیگر نشود.

---

### C8.1 کنترل‌های دسترسی بر حافظه و شاخص‌های RAG

اجرای کنترل‌های دسترسی دقیق و ریزبر به هر مجموعه برداری.

 #8.1.1    سطح: 1    نقش: D/V
 تأیید کنید که قوانین کنترل دسترسی در سطح ردیف/ Namespace، عملیات درج، حذف و پرس‌وجو را برای هر مستاجر، مجموعه یا برچسب سند محدود می‌کنند.
 #8.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که کلیدهای API یا JWT دارای ادعاهای محدودشده (مانند شناسه‌های مجموعه، افعال عملیاتی) هستند و حداقل هر سه ماه یکبار تعویض می‌شوند.
 #8.1.3    سطح: 2    نقش: D/V
 تأیید کنید که تلاش‌های افزایش امتیاز (مانند کوئری‌های تشابه در میان فضاهای نام مختلف) شناسایی شده و ظرف ۵ دقیقه به سیستم مدیریت اطلاعات و رویدادهای امنیتی (SIEM) گزارش شوند.
 #8.1.4    سطح: 2    نقش: D/V
 بررسی کنید که پایگاه داده برداری گزارش‌های ممیزی شامل شناسه موضوع، عملیات، شناسه بردار/فضای نام، آستانه شباهت و تعداد نتایج را ثبت می‌کند.
 #8.1.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که تصمیمات دسترسی برای نقص‌های دورزدن هرگاه موتور‌ها به‌روزرسانی می‌شوند یا قوانین تقسیم‌بندی شاخص تغییر می‌کنند، آزمایش می‌شوند.

---

### C8.2 پاک‌سازی و اعتبارسنجی جاسازی‌ها

متن را برای اطلاعات شناسایی شخصی (PII) پیش‌غربالگری کنید، قبل از تبدیل به بردار، آن را سانسور یا شبه‌نام‌گذاری کنید و در صورت تمایل پس از پردازش تعبیه‌ها، سیگنال‌های باقی‌مانده را حذف کنید.

 #8.2.1    سطح: 1    نقش: D/V
 تأیید کنید که داده‌های شناسایی شخصی (PII) و داده‌های تنظیم‌شده از طریق طبقه‌بندهای خودکار شناسایی شده و پیش از جاسازی، به صورت ماسک‌شده، توکنیزه شده یا حذف شده باشند.
 #8.2.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که پایپلاین‌های تعبیه‌سازی ورودی‌هایی که حاوی کد اجرایی یا آثار غیر UTF-8 هستند و ممکن است ایندکس را آلوده کنند، رد یا قرنطینه می‌کنند.
 #8.2.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که پاک‌سازی حریم خصوصی تفاضلی محلی یا متریکی روی تعبیه‌های جمله‌ای اعمال شده است که فاصله‌شان با هر توکن شناخته‌شده اطلاعات شناسایی شخصی (PII) کمتر از یک آستانه قابل تنظیم باشد.
 #8.2.4    سطح: 2    نقش: V
 تأیید کنید که اثربخشی پاک‌سازی (مثلاً بازیابی حذف اطلاعات شناسایی شخصی، انحراف معنایی) حداقل نیم‌سالانه بر اساس متون معیار ارزیابی شود.
 #8.2.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تنظیمات پاک‌سازی تحت کنترل نسخه قرار دارند و تغییرات آن‌ها مورد بازبینی همتا قرار می‌گیرد.

---

### C8.3 انقضای حافظه، لغو و حذف

قوانین GDPR مبنی بر «حق فراموش شدن» و قوانین مشابه، نیاز به حذف به موقع دارند؛ بنابراین فروشگاه‌های وکتور باید از TTLها، حذف‌های سخت و تدفین (tomb-stoning) پشتیبانی کنند تا وکتورهای لغو شده قابل بازیابی یا دوباره نمایه‌سازی نباشند.

 #8.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر رکورد بردار و فراداده دارای یک TTL یا برچسب نگهداری صریح است که توسط وظایف پاک‌سازی خودکار رعایت می‌شود.
 #8.3.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که درخواست‌های حذف شده توسط کاربر، بردارها، فراداده‌ها، نسخه‌های کش و شاخص‌های مشتق شده را ظرف 30 روز پاک می‌کنند.
 #8.3.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که حذف‌های منطقی پس از آن با تخریب رمزنگاری‌شده بلوک‌های ذخیره‌سازی در صورتی که سخت‌افزار از آن پشتیبانی کند، یا با نابودی کلیدهای مخزن کلید انجام شود.
 #8.3.4    سطح: 3    نقش: D/V
 تأیید کنید که بردارهای منقضی‌شده ظرف کمتر از ۵۰۰ میلی‌ثانیه پس از انقضا از نتایج جستجوی نزدیک‌ترین همسایه حذف می‌شوند.

---

### C8.4 جلوگیری از معکوس‌سازی جاسازی و نشت‌ها

دفاع‌های اخیر—هم‌پوشانی نویز، شبکه‌های نگاشت، برهم‌نهی نورون حریم خصوصی، و رمزگذاری لایه کاربرد—می‌توانند نرخ‌های معکوس‌سازی در سطح توکن را به زیر 5% برسانند.

 #8.4.1    سطح: 1    نقش: V
 تأیید کنید که یک مدل تهدید رسمی که حملات معکوس، عضویت و استنتاج ویژگی‌ها را پوشش می‌دهد، وجود دارد و هر سال بازبینی می‌شود.
 #8.4.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که رمزنگاری در سطح لایه برنامه یا رمزنگاری قابل جستجو، بردارها را از خوانش مستقیم توسط مدیران زیرساخت یا کارکنان ابر محافظت می‌کند.
 #8.4.3    سطح: 3    نقش: V
 تأیید کنید که پارامترهای دفاعی (ε برای DP، نویز σ، رتبه پروجکشن k) تعادل بین حریم خصوصی ≥ ۹۹٪ حفاظت از توکن و کاربردپذیری ≤ ۳٪ کاهش دقت را برقرار می‌کنند.
 #8.4.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که معیارهای مقاومت در برابر وارونگی بخشی از دروازه‌های انتشار برای به‌روزرسانی‌های مدل هستند، همراه با بودجه‌های رگرسیون تعریف‌شده.

---

### C8.5 اعمال محدودیت برای حافظه اختصاصی کاربر

نشت اطلاعات میان مستاجرها همچنان یکی از مهم‌ترین ریسک‌های RAG است: کوئری‌های شباهت که به درستی فیلتر نشده باشند می‌توانند اسناد خصوصی مشتری دیگر را نشان دهند.

 #8.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر پرس و جوی بازیابی قبل از ارسال به پیشنهاد LLM، توسط شناسه مستأجر/کاربر پس پردازش می‌شود.
 #8.5.2    سطح: 1    نقش: D
 تأیید کنید که نام‌های مجموعه یا شناسه‌های نام‌فضا شده به ازای هر کاربر یا مستأجر به صورت نمک‌دار (salted) باشند تا بردارها در محدوده‌های مختلف تداخل نداشته باشند.
 #8.5.3    سطح: 2    نقش: D/V
 تأیید کنید که نتایج شباهت بالاتر از آستانه فاصله قابل تنظیم اما خارج از حوزه تماس‌گیرنده حذف شده و هشدارهای امنیتی را فعال می‌کنند.
 #8.5.4    سطح: 2    نقش: V
 تأیید کنید که تست‌های فشار چند مستاجمی شبیه‌سازی پرسش‌های خصمانه‌ای هستند که تلاش می‌کنند اسناد خارج از حوزه را بازیابی کنند و نشان دهند که هیچ نشت اطلاعاتی وجود ندارد.
 #8.5.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که کلیدهای رمزنگاری به‌طور جداگانه برای هر مستاجر تفکیک شده‌اند، تا جداسازی رمزنگاری حتی در صورت اشتراک ذخیره‌سازی فیزیکی تضمین شود.

---

### C8.6 امنیت پیشرفته سیستم حافظه

کنترل‌های امنیتی برای معماری‌های پیچیده حافظه از جمله حافظه اپیزودیک، معنایی و کاری با نیازهای خاص ایزولاسیون و اعتبارسنجی.

 #8.6.1    سطح: 1    نقش: D/V
 تأیید کنید که انواع مختلف حافظه (اپیزودیک، معنایی، کاری) دارای زمینه‌های امنیتی مجزا با کنترل‌های دسترسی مبتنی بر نقش، کلیدهای رمزگذاری مجزا و الگوهای دسترسی مستندسازی شده برای هر نوع حافظه هستند.
 #8.6.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فرآیندهای تثبیت حافظه شامل اعتبارسنجی امنیتی برای جلوگیری از تزریق حافظه‌های مخرب از طریق پاک‌سازی محتوا، تأیید منبع و بررسی‌های صحت قبل از ذخیره‌سازی می‌باشند.
 #8.6.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که پرس‌وجوهای بازیابی حافظه اعتبارسنجی و پاک‌سازی می‌شوند تا از استخراج اطلاعات غیرمجاز از طریق تحلیل الگوهای پرس‌وجو، اعمال کنترل دسترسی و فیلتر کردن نتایج جلوگیری شود.
 #8.6.4    سطح: 3    نقش: D/V
 تأیید کنید که مکانیزم‌های فراموشی حافظه اطلاعات حساس را با تضمین‌های حذف رمزنگاری شده به‌صورت ایمن حذف می‌کنند، از جمله حذف کلید، بازنویسی چند مرحله‌ای، یا حذف ایمن مبتنی بر سخت‌افزار همراه با گواهی‌های تأیید.
 #8.6.5    سطح: 3    نقش: D/V
 تأیید کنید که یکپارچگی سیستم حافظه به طور مداوم برای تغییرات غیرمجاز یا فساد از طریق جمع‌های کنترلی (checksum)، گزارش‌های بازرسی (audit logs)، و هشدارهای خودکار هنگام تغییر محتوای حافظه خارج از عملیات عادی، پایش می‌شود.

---

### مراجع

Vector database security: Pinecone – IronCore Labs
Securing the Backbone of AI: Safeguarding Vector Databases and Embeddings – Privacera
Enhancing Data Security with RBAC of Qdrant Vector Database – AI Advances
Mitigating Privacy Risks in LLM Embeddings from Embedding Inversion – arXiv
DPPN: Detecting and Perturbing Privacy-Sensitive Neurons – OpenReview
Art. 17 GDPR – Right to Erasure
Sensitive Data in Text Embeddings Is Recoverable – Tonic.ai
PII Identification and Removal – NVIDIA NeMo Docs
De-identifying Sensitive Data – Google Cloud DLP
Remove PII from Conversations Using Sensitive Information Filters – AWS Bedrock Guardrails
Think Your RAG Is Secure? Think Again – Medium
Design a Secure Multitenant RAG Inferencing Solution – Microsoft Learn
Best Practices for Multi-Tenancy RAG with Milvus – Milvus Blog

## ۹ هماهنگ‌سازی خودگردان و امنیت اقدام عاملیت‌دار

### هدف کنترل

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی خودکار یا چندعامله تنها اقداماتی را اجرا می‌کنند که صراحتاً مد نظر هستند، تأیید شده‌اند، قابل حسابرسی هستند و در محدوده هزینه و آستانه‌های ریسک تعیین شده قرار دارند. این موضوع در برابر تهدیداتی مانند نقص سیستم خودکار، سوءاستفاده از ابزارها، شناسایی حلقه‌های عامل، ربودن ارتباطات، جعل هویت، دستکاری گروهی و دستکاری نیت محافظت می‌کند.

---

### 9.1 بودجه‌های برنامه‌ریزی وظایف عامل و بازگشت

تثبیت مسیرهای بازگشتی و اجبار به ایستگاه‌های انسانی برای اقدامات دارای امتیاز ویژه.

 #9.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که عمق حداکثر بازگشت، پهنا، زمان ساعت دیواری، توکن‌ها و هزینه مالی هر اجرای عامل به‌طور مرکزی پیکربندی شده و تحت کنترل نسخه قرار دارند.
 #9.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که اقدامات دارای امتیاز یا غیرقابل بازگشت (مانند ارسال‌های کد، انتقال‌های مالی) نیاز به تأیید صریح انسانی از طریق یک کانال قابل حسابرسی قبل از اجرا دارند.
 #9.1.3    سطح: 2    نقش: D
 تأیید کنید که مانیتورهای منابع در زمان واقعی هنگام عبور هر گونه آستانه بودجه‌ای، وقفه مدار شکن را فعال می‌کنند و از گسترش بیشتر وظایف جلوگیری می‌شود.
 #9.1.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که رویدادهای مدار شکن با شناسه عامل، شرایط فعال‌سازی و وضعیت برنامه ضبط‌شده برای بررسی قانونی ثبت می‌شوند.
 #9.1.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که تست‌های امنیتی شامل سناریوهای Exhaustion بودجه و طرح‌های runaway می‌شوند، و توقف ایمن بدون از دست رفتن داده‌ها را تأیید می‌کنند.
 #9.1.6    سطح: 3    نقش: D
 اطمینان حاصل کنید که سیاست‌های بودجه به صورت سیاست-به-کد بیان شده‌اند و در CI/CD اجرا می‌شوند تا از انحراف تنظیمات جلوگیری کنند.

---

### 9.2 ایزوله‌سازی افزونه ابزار

تعامل ابزارها را جدا کنید تا از دسترسی غیرمجاز به سیستم یا اجرای کد جلوگیری شود.

 #9.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر ابزار/افزونه در داخل یک سیستم‌عامل، کانتینر، یا سندباکس سطح WASM با سیاست‌های حداقل دسترسی برای سیستم‌فایل، شبکه، و فراخوانی‌های سیستم اجرا شود.
 #9.2.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سهمیه‌های منابع سندباکس (CPU، حافظه، دیسک، خروجی شبکه) و تایم‌اوت‌های اجرای برنامه اعمال و ثبت می‌شوند.
 #9.2.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که باینری‌ها یا توصیف‌گرهای ابزار به صورت دیجیتال امضا شده‌اند؛ امضاها قبل از بارگذاری تأیید شوند.
 #9.2.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که داده‌های تلومتری سندباکس به یک سیستم مدیریت اطلاعات و رویداد امنیتی (SIEM) ارسال می‌شود؛ ناهنجاری‌ها (مثلاً تلاش برای برقراری اتصالات خروجی) هشدار ایجاد می‌کنند.
 #9.2.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که پلاگین‌های با ریسک بالا قبل از استقرار در محیط تولید، مورد بازبینی امنیتی و تست نفوذ قرار گیرند.
 #9.2.6    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تلاش‌های فرار از سندباکس به‌طور خودکار مسدود می‌شوند و افزونه متخلف تا زمان بررسی در قرنطینه قرار می‌گیرد.

---

### 9.3 حلقه خودکار و محدود کردن هزینه

تشخیص و توقف بازگشت‌های غیرمحدود شده عامل به عامل و انفجار هزینه‌ها.

 #9.3.1    سطح: 1    نقش: D/V
 تأیید کنید که تماس‌های بین عامل‌ها شامل یک محدودیت پرش یا TTL باشند که زمان اجرا آن را کاهش دهد و اجرا کند.
 #9.3.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که عامل‌ها یک شناسه گراف فراخوانی منحصربه‌فرد را حفظ می‌کنند تا فراخوانی‌های خودی یا الگوهای چرخه‌ای را شناسایی کنند.
 #9.3.3    سطح: 2    نقش: D/V
 تأیید کنید که شمارنده‌های تجمعی واحد محاسبات و هزینه برای هر زنجیره درخواست جداگانه پیگیری می‌شوند؛ تجاوز از حد مجاز باعث قطع شدن زنجیره می‌شود.
 #9.3.4    سطح: 3    نقش: V
 تأیید کنید که تحلیل رسمی یا بررسی مدل، عدم وجود بازگشت نامحدود در پروتکل‌های عامل را نشان می‌دهد.
 #9.3.5    سطح: 3    نقش: D
 اطمینان حاصل کنید که رویدادهای قطع حلقه هشدارها را ایجاد کرده و معیارهای بهبود مستمر را تغذیه می‌کنند.

---

### 9.4 محافظت در برابر استفاده نادرست در سطح پروتکل

کانال‌های ارتباطی امن بین عامل‌ها و سیستم‌های خارجی برای جلوگیری از ربوده شدن یا دستکاری.

 #9.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام پیام‌ها بین عامل و ابزار و همچنین بین عوامل به صورت احراز هویت شده (مانند TLS دوطرفه یا JWT) و رمزگذاری شده از ابتدا تا انتها باشند.
 #9.4.2    سطح: 1    نقش: D
 تأیید کنید که اسکیم‌ها به طور دقیق اعتبارسنجی می‌شوند؛ فیلدهای ناشناخته یا پیام‌های نادرست رد می‌شوند.
 #9.4.3    سطح: 2    نقش: D/V
 تأیید کنید که بررسی‌های صحت (MACها یا امضاهای دیجیتال) کل بار پیام از جمله پارامترهای ابزار را پوشش می‌دهند.
 #9.4.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که حفاظت در برابر پخش مجدد (شمارنده‌های غیرتکراری یا بازه‌های زمانی) در لایه پروتکل اعمال می‌شود.
 #9.4.5    سطح: 3    نقش: V
 تأیید کنید که پیاده‌سازی‌های پروتکل تحت فرآیند فازینگ و تحلیل ایستا برای شناسایی نقص‌های تزریق یا سریال‌زدایی قرار می‌گیرند.

---

### 9.5 هویت عامل و شواهد دستکاری

اطمینان حاصل کنید که اقدامات قابل نسبت دادن و تغییرات قابل شناسایی باشند.

 #9.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر نمونه عامل دارای یک هویت رمزنگاری منحصربه‌فرد (جفت کلید یا مدرک مبتنی بر سخت‌افزار) باشد.
 #9.5.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که همه اقدامات نماینده امضا شده و زمان‌گذاری شده باشند؛ گزارش‌ها شامل امضا برای عدم انکار باشند.
 #9.5.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که گزارش‌های دارای قابلیت تشخیص دستکاری در یک محیط فقط افزایشی یا نوشتنی-یک‌بار ذخیره می‌شوند.
 #9.5.4    سطح: 3    نقش: D
 اطمینان حاصل کنید که کلیدهای هویت طبق برنامه تعیین‌شده و در صورت وجود نشانگرهای نفوذ، چرخش می‌کنند.
 #9.5.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تلاش‌های جعل هویت یا تعارض کلید باعث قرنطینه فوری عامل متاثر شده می‌شود.

---

### 9.6 کاهش ریسک گروهی چندعاملی

خطرات رفتار جمعی را از طریق جداسازی و مدل‌سازی رسمی ایمنی کاهش دهید.

 #9.6.1    سطح: 1    نقش: D/V
 تأیید کنید که عامل‌هایی که در حوزه‌های امنیتی مختلف فعالیت می‌کنند، در محیط‌های اجرای جداسازی شده یا بخش‌های شبکه جداگانه اجرا شوند.
 #9.6.2    سطح: 3    نقش: V
 اطمینان حاصل کنید که رفتارهای ازدحام مدل‌سازی شده و به‌طور رسمی برای پویایی (liveness) و ایمنی (safety) قبل از استقرار تأیید شده‌اند.
 #9.6.3    سطح: 3    نقش: D
 تأیید کنید که مانیتورهای زمان اجرا الگوهای ناایمن نوظهور (مانند نوسانات، بن‌بست‌ها) را شناسایی کرده و اقدام اصلاحی را آغاز می‌کنند.

---

### 9.7 احراز هویت / مجوز کاربران و ابزارها

پیاده‌سازی کنترل‌های دسترسی مقاوم برای هر عملی که توسط عامل فعال می‌شود.

 #9.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که عوامل به عنوان نمایندگان درجه یک به سیستم‌های پایین‌دستی احراز هویت می‌کنند و هرگز از مدارک اعتبار کاربر نهایی مجدداً استفاده نمی‌کنند.
 #9.7.2    سطح: 2    نقش: D
 تأیید کنید که سیاست‌های مجوزدهی دقیق محدود می‌کنند که یک عامل کدام ابزارها را می‌تواند فراخوانی کند و کدام پارامترها را می‌تواند تامین کند.
 #9.7.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که بررسی‌های امتیاز دسترسی در هر فراخوانی مجدداً ارزیابی می‌شوند (مجوزدهی مداوم)، نه فقط در شروع جلسه.
 #9.7.4    سطح: 3    نقش: D
 تأیید کنید که امتیازات واگذار شده به‌طور خودکار پس از انقضا منقضی می‌شوند و پس از زمان‌بندی مجدد یا تغییر دامنه نیاز به موافقت مجدد دارند.

---

### 9.8 امنیت ارتباط عامل به عامل

تمام پیام‌های بین عامل‌ها را رمزگذاری و با حفاظت از صحت آنها محافظت کنید تا از استراق سمع و دستکاری جلوگیری شود.

 #9.8.1    سطح: 1    نقش: D/V
 تأیید کنید که احراز هویت دوطرفه و رمزگذاری پیشرفته با حفظ امانت کامل (مانند TLS 1.3) برای کانال‌های عامل اجباری هستند.
 #9.8.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که صحت و منشاء پیام قبل از پردازش تایید می‌شوند؛ در صورت عدم موفقیت، هشدارها صادر شده و پیام حذف می‌شود.
 #9.8.3    سطح: 2    نقش: D/V
 تأیید کنید که فراداده‌های ارتباطی (زمان‌سنجی‌ها، شماره‌های توالی) برای پشتیبانی از بازسازی قانونی ثبت شده باشند.
 #9.8.4    سطح: 3    نقش: V
 تأیید کنید که تایید رسمی یا مدل‌سازی تایید می‌کند که ماشین‌های حالت پروتکل نمی‌توانند به حالت‌های ناامن رانده شوند.

---

### 9.9 تأیید قصد و اعمال محدودیت‌ها

اعتبارسنجی کنید که اقدامات عامل با نیت اعلام شده کاربر و محدودیت‌های سیستم همخوانی داشته باشد.

 #9.9.1    سطح: 1    نقش: D
 تأیید کنید که حل‌کننده‌های محدودیت قبل از اجرا، اقدامات پیشنهادی را با قوانین سخت‌کد شده ایمنی و سیاست‌ها بررسی می‌کنند.
 #9.9.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اقدامات با تأثیر بالا (مالی، تخریبی، حساس به حریم خصوصی) نیازمند تایید قصد صریح از سوی کاربر شروع‌کننده هستند.
 #9.9.3    سطح: 2    نقش: V
 تأیید کنید که بررسی‌های پس‌شرط صحت اقدام‌های انجام شده را که اهداف مورد نظر را بدون اثرات جانبی محقق کرده‌اند، تضمین می‌کند؛ هرگونه اختلاف باعث بازگردانی می‌شود.
 #9.9.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که روش‌های رسمی (مانند بررسی مدل، اثبات قضیه) یا آزمایش‌های مبتنی بر ویژگی نشان می‌دهند که برنامه‌های عامل تمامی محدودیت‌های اعلام‌شده را برآورده می‌کنند.
 #9.9.5    سطح: 3    نقش: D
 تأیید کنید که حوادث ناسازگاری هدف یا تخلف از محدودیت‌ها به چرخه‌های بهبود مستمر و اشتراک‌گذاری اطلاعات تهدیدها خوراک می‌دهند.

---

### 9.10 امنیت استراتژی استدلال عامل

انتخاب و اجرای ایمن استراتژی‌های مختلف استدلال از جمله روش‌های ReAct، Chain-of-Thought و Tree-of-Thoughts.

 #9.10.1    سطح: 1    نقش: D/V
 تأیید کنید که انتخاب استراتژی استدلال از معیارهای قطعی (پیچیدگی ورودی، نوع وظیفه، زمینه امنیتی) استفاده می‌کند و ورودی‌های یکسان در همان زمینه امنیتی منجر به انتخاب‌های استراتژی یکسان می‌شوند.
 #9.10.2    سطح: 1    نقش: D/V
 تأیید کنید که هر استراتژی استدلال (ReAct، Chain-of-Thought، Tree-of-Thoughts) دارای اعتبارسنجی ورودی اختصاصی، پاک‌سازی خروجی و محدودیت‌های زمان اجرا خاص به رویکرد شناختی خود باشد.
 #9.10.3    سطح: 2    نقش: D/V
 تأیید کنید که انتقالات استراتژی استدلال با زمینه کامل، شامل ویژگی‌های ورودی، مقادیر معیارهای انتخاب و متادیتای اجرایی برای بازسازی مسیر حسابرسی ثبت می‌شوند.
 #9.10.4    سطح: 2    نقش: D/V
 تأیید کنید که روش استدلال درخت-از-اندیشه شامل مکانیزم‌های هرس شاخه است که کاوش را هنگام شناسایی نقض سیاست‌ها، محدودیت‌های منابع یا مرزهای ایمنی متوقف می‌کنند.
 #9.10.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که چرخه‌های ReAct (استدلال-عمل-مشاهده) شامل نقاط تأیید اعتبار در هر مرحله هستند: بررسی گام استدلال، مجوز انجام عمل، و پاکسازی مشاهده قبل از ادامه دادن.
 #9.10.6    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که معیارهای عملکرد استراتژی استدلال (زمان اجرا، استفاده از منابع، کیفیت خروجی) با هشدارهای خودکار زمانی که معیارها از حد آستانه‌های پیکربندی شده فراتر می‌روند، نظارت می‌شوند.
 #9.10.7    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که رویکردهای استدلال ترکیبی که چندین استراتژی را با هم ادغام می‌کنند، اعتبارسنجی ورودی و محدودیت‌های خروجی همه استراتژی‌های تشکیل‌دهنده را حفظ می‌کنند بدون اینکه هیچ‌یک از کنترل‌های امنیتی را دور بزنند.
 #9.10.8    سطح: 3    نقش: D/V
 تأیید کنید که آزمون امنیتی استراتژی استدلال شامل فازینگ با ورودی‌های معیوب، فرمان‌های خصمانه طراحی شده برای مجبور کردن به تغییر استراتژی، و آزمون شرایط مرزی برای هر رویکرد شناختی باشد.

---

### 9.11 مدیریت وضعیت چرخه عمر عامل و امنیت

راه‌اندازی امن عامل، گذارهای حالت و خاتمه با مسیرهای حسابرسی رمزنگاری شده و رویه‌های بازیابی تعریف‌شده.

 #9.11.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که راه‌اندازی عامل شامل ایجاد هویت رمزنگاری شده با اعتبارات پشتیبانی‌شده توسط سخت‌افزار و گزارش‌های ناگزارشی راه‌اندازی غیرقابل تغییر است که شامل شناسه عامل، زمان‌سنجی، هش پیکربندی و پارامترهای راه‌اندازی می‌باشد.
 #9.11.2    سطح: 2    نقش: D/V
 تأیید کنید که انتقال‌های وضعیت عامل به صورت رمزنگاری‌شده امضا شده، با مهرزمان ثبت شده و با زمینه کامل شامل رویدادهای محرک، هش وضعیت قبلی، هش وضعیت جدید و اعتبارسنجی‌های امنیتی انجام شده، ثبت می‌شوند.
 #9.11.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که رویه‌های خاموش‌سازی عامل شامل پاک‌سازی امن حافظه با استفاده از حذف رمزنگاری شده یا بازنویسی چندگانه، لغو مجوزها با اطلاع‌رسانی به مرجع صدور گواهی، و تولید گواهی‌نامه‌های خاتمه با قابلیت تشخیص دست‌کاری می‌باشد.
 #9.11.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های بازیابی عامل، صحت وضعیت را با استفاده از چک‌سم‌های رمزنگاری شده (حداقل SHA-256) اعتبارسنجی می‌کنند و هنگام تشخیص فساد، به وضعیت‌های مشخص و سالم بازگردانده می‌شوند، همراه با هشدارهای خودکار و نیاز به تأیید دستی.
 #9.11.5    سطح: 3    نقش: D/V
 تأیید کنید که مکانیزم‌های پایداری عامل داده‌های حساس حالت را با کلیدهای AES-256 منحصر به هر عامل رمزنگاری می‌کنند و چرخش امن کلید را بر اساس برنامه‌های قابل تنظیم (حداکثر ۹۰ روز) با استقرار بدون توقف پیاده‌سازی می‌کنند.

---

### 9.12 چارچوب امنیتی یکپارچه‌سازی ابزار

کنترل‌های امنیتی برای بارگذاری دینامیک ابزار، اجرا و اعتبارسنجی نتایج همراه با فرآیندهای ارزیابی ریسک تعریف‌شده و تاییدیه‌ها.

 #9.12.1    سطح: 1    نقش: D/V
 تأیید کنید که توصیف‌گرهای ابزار شامل متاداده‌های امنیتی باشند که حقوق دسترسی موردنیاز (خواندن/نوشتن/اجرا)، سطح ریسک (کم/متوسط/زیاد)، محدودیت‌های منابع (پردازنده، حافظه، شبکه) و نیازمندی‌های اعتبارسنجی را که در مانیفست‌های ابزار مستند شده‌اند، مشخص کنند.
 #9.12.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که نتایج اجرای ابزار قبل از ادغام با محدودیت‌های زمانی و روش‌های مدیریت خطا، بر اساس اسکیمای‌های مورد انتظار (JSON Schema، XML Schema) و سیاست‌های امنیتی (پاک‌سازی خروجی، طبقه‌بندی داده‌ها) اعتبارسنجی می‌شوند.
 #9.12.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که لاگ‌های تعامل ابزار شامل زمینه امنیتی دقیق از جمله استفاده از امتیازات، الگوهای دسترسی به داده‌ها، زمان اجرا، مصرف منابع و کدهای بازگشتی با لاگ‌برداری ساختاریافته برای ادغام با SIEM باشد.
 #9.12.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های بارگذاری ابزار پویا امضاهای دیجیتال را با استفاده از زیرساخت PKI اعتبارسنجی می‌کنند و پروتکل‌های بارگذاری امن با جداسازی سندباکس و بررسی مجوز قبل از اجرا را پیاده‌سازی می‌نمایند.
 #9.12.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که ارزیابی‌های امنیتی ابزار به صورت خودکار برای نسخه‌های جدید با دروازه‌های تأیید اجباری شامل تحلیل ایستا، آزمایش پویا و بازبینی تیم امنیتی با معیارهای تأیید مستند شده و الزامات SLA، راه‌اندازی می‌شوند.

---

#### مراجع

MITRE ATLAS tactics ML09
Circuit-breaker research for AI agents — Zou et al., 2024
Trend Micro analysis of sandbox escapes in AI agents — Park, 2025
Auth0 guidance on human-in-the-loop authorization for agents — Martinez, 2025
Medium deep-dive on MCP & A2A protocol hijacking — ForAISec, 2025
Rapid7 fundamentals on spoofing attack prevention — 2024
Imperial College verification of swarm systems — Lomuscio et al.
NIST AI Risk Management Framework 1.0, 2023
WIRED security briefing on encryption best practices, 2024
OWASP Top 10 for LLM Applications, 2025
Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS
[How Is LLM Reasoning Distracted by Irrelevant Context?
An Analysis Using a Controlled Benchmark](https://www.arxiv.org/pdf/2505.18761)
Large Language Model Sentinel: LLM Agent for Adversarial Purification
Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents

## 10 مقاومت خصمانه و دفاع از حریم خصوصی

### هدف کنترل

اطمینان حاصل کنید که مدل‌های هوش مصنوعی هنگام مواجهه با حملات گریز، استنباط، استخراج یا مسموم‌سازی، قابل اعتماد، حفظ‌کننده حریم خصوصی و مقاوم در برابر سوءاستفاده باقی بمانند.

---

### 10.1 هم‌راستایی مدل و ایمنی

جلوگیری از خروجی‌های مضر یا مغایر با سیاست‌ها.

 #10.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که یک مجموعه آزمایش هم‌راستایی (پرامپت‌های تیم قرمز، آزمایش‌های ورود به سیستم، محتوای مجاز نشده) نسخه‌بندی شده و در هر انتشار مدل اجرا می‌شود.
 #10.1.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که موانع امتناع و تکمیل ایمن اعمال شده‌اند.
 #10.1.3    سطح: 2    نقش: D/V
 تأیید کنید که یک ارزیاب خودکار نرخ محتوای مضر را اندازه‌گیری کرده و بازگشت‌ها (Regression) را که فراتر از یک آستانه مشخص هستند، علامت‌گذاری می‌کند.
 #10.1.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که آموزش مقابله با فرار از زندان مستند و قابل تکرار باشد.
 #10.1.5    سطح: 3    نقش: V
 تأیید کنید که اثبات‌های رسمی انطباق با سیاست یا نظارت دارای گواهی، حوزه‌های حیاتی را پوشش می‌دهند.

---

### 10.2 سخت‌سازی نمونه‌های مخرب

افزایش مقاومت در برابر ورودی‌های دست‌کاری شده. آموزش مقابله‌ای مقاوم و امتیازدهی معیارهای ارزیابی، بهترین روش‌های فعلی هستند.

 #10.2.1    سطح: 1    نقش: D
 بررسی کنید که مخازن پروژه شامل پیکربندی‌های آموزش خصمانه با دانه‌های قابل بازتولید باشند.
 #10.2.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تشخیص نمونه‌های مخرب هشدارهای مسدودکننده را در خطوط لوله تولید ایجاد می‌کند.
 #10.2.4    سطح: 3    نقش: V
 تأیید کنید که اثبات‌های استحکام دارای گواهی یا گواهینامه‌های بازه‌ای حداقل کلاس‌های بحرانی برتر را پوشش می‌دهند.
 #10.2.5    سطح: 3    نقش: V
 تأیید کنید که آزمون‌های رگرسیون از حملات تطبیقی برای تأیید عدم وجود کاهش قابل اندازه‌گیری در استحکام استفاده می‌کنند.

---

### 10.3 کاهش استنتاج عضویت

محدود کردن توانایی تشخیص اینکه آیا یک رکورد در داده‌های آموزش وجود داشته است. حفظ حریم خصوصی تفاضلی و ماسک‌گذاری امتیاز اطمینان همچنان موثرترین دفاع‌های شناخته شده باقی می‌مانند.

 #10.3.1    سطح: 1    نقش: D
 تأیید کنید که تنظیم منظم انتروپی به ازای هر پرس‌وجو یا مقیاس‌بندی دما پیش‌بینی‌های بیش از حد اطمینان را کاهش می‌دهد.
 #10.3.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که آموزش از بهینه‌سازی متفاوت-محافظت‌شده با حد ε برای داده‌های حساس استفاده می‌کند.
 #10.3.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که شبیه‌سازی‌های حمله (مدل سایه یا جعبه سیاه) شاخص AUC حمله را بر داده‌های نگهداری‌شده کمتر یا مساوی 0.60 نشان می‌دهند.

---

### 10.4 مقاومت در برابر معکوس‌سازی مدل

جلوگیری از بازسازی ویژگی‌های خصوصی. بررسی‌های اخیر تأکید می‌کنند که قطع کردن خروجی و تضمین‌های حفظ حریم خصوصی تفاضلی (DP) به عنوان دفاع‌های عملی محسوب می‌شوند.

 #10.4.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که ویژگی‌های حساس هرگز به طور مستقیم نمایش داده نمی‌شوند؛ در صورت نیاز از سطل‌ها یا تبدیلات یک‌طرفه استفاده کنید.
 #10.4.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که نرخ محدودیت‌های پرس‌وجو، پرس‌وجوهای تطبیقی مکرر از همان شخص اصلی را محدود می‌کنند.
 #10.4.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که مدل با نویز حفظ حریم خصوصی آموزش دیده است.

---

### 10.5 دفاع استخراج مدل

شناسایی و جلوگیری از کلون‌سازی غیرمجاز. استفاده از علامت‌گذاری آب و تحلیل الگوی پرس‌وجو توصیه می‌شود.

 #10.5.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که دروازه‌های استنتاج محدودیت‌های نرخ کلی و محدودیت‌های نرخ هر کلید API را که متناسب با آستانه یادسپاری مدل تنظیم شده‌اند، اعمال می‌کنند.
 #10.5.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که آمارهای انتروپی پرس‌وجو و کثرت ورودی، یک آشکارساز استخراج خودکار را تغذیه می‌کنند.
 #10.5.3    سطح: 2    نقش: V
 تأیید کنید که واترمارک‌های شکننده یا احتمالاتی را می‌توان با p < 0.01 در ≤ 1 000 پرس‌وجو علیه یک کپی مشکوک اثبات کرد.
 #10.5.4    سطح: 3    نقش: D
 اطمینان حاصل کنید که کلیدهای واترمارک و مجموعه‌های محرک در ماژول امنیت سخت‌افزاری ذخیره شده و سالیانه چرخش می‌یابند.
 #10.5.5    سطح: 3    نقش: V
 تأیید کنید که رویدادهای extraction-alert شامل کوئری‌های متخلف بوده و با کتاب‌های راهنمای پاسخ به حادثه ادغام شده‌اند.

---

### 10.6 تشخیص داده‌های آلوده در زمان استنتاج

شناسایی و خنثی‌سازی ورودی‌های دارای در پشتی یا آلوده.

 #10.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که ورودی‌ها قبل از استنتاج مدل از طریق یک شناسگر ناهنجاری (مثلاً STRIP، امتیازدهی سازگاری) عبور کنند.
 #10.6.2    سطح: 1    نقش: V
 اطمینان حاصل کنید که آستانه‌های تشخیص‌دهنده بر روی مجموعه‌های اعتبارسنجی تمیز/آلوده تنظیم شده‌اند تا کمتر از ۵٪ مثبت کاذب به دست آید.
 #10.6.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که ورودی‌هایی که به عنوان مسموم‌شده علامت‌گذاری شده‌اند، باعث فعال شدن نرم‌مسدودسازی و گردش‌های کاری بازبینی انسانی می‌شوند.
 #10.6.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که آشکارسازها با حملات بک‌دور تطبیقی و بدون نیاز به تریگر به طور کامل تحت فشار قرار گرفته‌اند.
 #10.6.5    سطح: 3    نقش: D
 اطمینان حاصل کنید که معیارهای اثربخشی تشخیص ثبت شده و به صورت دوره‌ای با اطلاعات جدید تهدید بازبینی می‌شوند.

---

### 10.7 تطبیق پویا سیاست‌های امنیتی

به‌روزرسانی‌های سیاست امنیتی در زمان واقعی بر اساس اطلاعات تهدید و تحلیل رفتاری.

 #10.7.1    سطح: 1    نقش: D/V
 تأیید کنید که سیاست‌های امنیتی می‌توانند به صورت پویا بدون نیاز به راه‌اندازی مجدد عامل به‌روزرسانی شوند در حالی که یکپارچگی نسخه سیاست حفظ می‌شود.
 #10.7.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که به‌روزرسانی‌های سیاست‌ها توسط پرسنل امنیتی مجاز به صورت رمزنگاری شده امضا شده و قبل از اعمال اعتبارسنجی می‌شوند.
 #10.7.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تغییرات دینامیک سیاست با سوابق کامل حسابرسی شامل توجیه، زنجیره‌های تصویب، و روش‌های بازگردانی ثبت می‌شوند.
 #10.7.4    سطح: 3    نقش: D/V
 تأیید کنید که مکانیزم‌های امنیتی تطبیقی حساسیت شناسایی تهدید را بر اساس زمینه ریسک و الگوهای رفتاری تنظیم می‌کنند.
 #10.7.5    سطح: 3    نقش: D/V
 تأیید کنید که تصمیمات تطبیق سیاست قابل توضیح باشند و شامل مسیرهای شواهد برای بازبینی تیم امنیتی باشند.

---

### 10.8 تحلیل امنیت مبتنی بر بازتاب

اعتبارسنجی امنیت از طریق خودبازتابی عامل و تحلیل فراشناختی.

 #10.8.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های بازتاب عامل شامل ارزیابی خودمتمرکز امنیتی از تصمیمات و اقدامات باشد.
 #10.8.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که خروجی‌های بازتابی برای جلوگیری از دستکاری مکانیزم‌های خودارزیابی توسط ورودی‌های خصمانه اعتبارسنجی می‌شوند.
 #10.8.3    سطح: 2    نقش: D/V
 تأیید کنید که تحلیل امنیت متا-شناختی، سوگیری، دستکاری یا به خطر افتادن احتمالی در فرآیندهای استدلال عامل را شناسایی می‌کند.
 #10.8.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که هشدارهای امنیتی مبتنی بر بازتاب باعث فعال شدن نظارت پیشرفته و فرآیندهای احتمالی دخالت انسانی می‌شوند.
 #10.8.5    سطح: 3    نقش: D/V
 تأیید کنید که یادگیری مداوم از بازتاب‌های امنیتی، تشخیص تهدید را بهبود می‌بخشد بدون اینکه عملکرد مشروع را کاهش دهد.

---

### ۱۰.۹ امنیت تکامل و خودبهبودی

کنترل‌های امنیتی برای سیستم‌های عامل که قادر به خودتغییری و تکامل هستند.

 #10.9.1    سطح: 1    نقش: D/V
 تأیید کنید که قابلیت‌های خودتعدیلی به مناطق ایمن تعیین شده با مرزهای رسمی تأیید محدود شده‌اند.
 #10.9.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که پیشنهادهای توسعه قبل از اجرا مورد ارزیابی تأثیر امنیتی قرار گیرند.
 #10.9.3    سطح: 2    نقش: D/V
 تأیید کنید که مکانیسم‌های خودبهبودی شامل قابلیت‌های بازگشت به حالت قبلی با بررسی صحت داده‌ها هستند.
 #10.9.4    سطح: 3    نقش: D/V
 تأیید کنید که امنیت متا-یادگیری از دستکاری خصمانه الگوریتم‌های بهبود جلوگیری می‌کند.
 #10.9.5    سطح: 3    نقش: D/V
 تأیید کنید که بهبود خود بازگشتی توسط محدودیت‌های رسمی ایمنی محدود شده است با اثبات‌های ریاضی همگرایی.

---

#### مراجع

MITRE ATLAS adversary tactics for ML
NIST AI Risk Management Framework 1.0, 2023
OWASP Top 10 for LLM Applications, 2025
Adversarial Training: A Survey — Zhao et al., 2024
RobustBench adversarial-robustness benchmark
Membership-Inference & Model-Inversion Risk Survey, 2025
PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023
Model-Inversion Attacks & Defenses Survey — AI Review, 2025
Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024
Fragile Model Watermarking Survey — 2025
Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025
BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024

## ۱۱ حفاظت از حریم خصوصی و مدیریت داده‌های شخصی

### هدف کنترل

حفظ تضمین‌های دقیق حریم خصوصی در سراسر چرخه عمر هوش مصنوعی—جمع‌آوری، آموزش، استنتاج و پاسخ به حادثه—به گونه‌ای که داده‌های شخصی تنها با رضایت روشن، دامنه حداقلی مورد نیاز، حذف قابل اثبات و تضمین‌های رسمی حریم خصوصی پردازش شوند.

---

### 11.1 ناشناس‌سازی و کمینه‌سازی داده‌ها

 #11.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که شناسه‌های مستقیم و شبه‌شناسه‌ها حذف شده یا هش شده‌اند.
 #11.1.2    سطح: 2    نقش: D/V
 تأیید کنید که حسابرسی‌های خودکار میزان k-ناشناس‌سازی/l-تنوع را اندازه‌گیری می‌کنند و هنگام کاهش این مقادیر به زیر آستانه‌های تعیین‌شده توسط سیاست، هشدار می‌دهند.
 #11.1.3    سطح: 2    نقش: V
 تأیید کنید که گزارش‌های اهمیت ویژگی مدل اثبات می‌کنند که هیچ نشت شناسه‌ای فراتر از ε = 0.01 اطلاعات متقابل وجود ندارد.
 #11.1.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که اثبات‌های رسمی یا گواهی‌های داده‌های مصنوعی نشان می‌دهند ریسک شناسایی مجدد ≤ 0.05 حتی در شرایط حملات پیوندی.

---

### 11.2 حق فراموش شدن و اجرای حذف

 #11.2.1    سطح: 1    نقش: D/V
 تأیید کنید که درخواست‌های حذف داده‌های موضوعی به مجموعه داده‌های خام، نقاط بررسی، تعبیه‌ها، گزارش‌ها و نسخه‌های پشتیبان در چارچوب توافق‌نامه‌های سطح خدمات کمتر از 30 روز منتقل می‌شوند.
 #11.2.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که روش‌های "یادگیری معکوس ماشین" به‌صورت فیزیکی بازآموزی می‌شوند یا حذف تقریباً به‌کمک الگوریتم‌های یادگیری معکوس تاییدشده انجام می‌شود.
 #11.2.3    سطح: 2    نقش: V
 تأیید کنید که ارزیابی مدل سایه اثبات می‌کند رکوردهای فراموش شده کمتر از 1٪ از خروجی‌ها را پس از فراموش‌کردن تحت تأثیر قرار می‌دهند.
 #11.2.4    سطح: 3    نقش: V
 تأیید کنید که رویدادهای حذف به طور غیرقابل تغییر ثبت شده و برای ناظران قابل حسابرسی باشند.

---

### 11.3 حفاظت‌های حریم خصوصی تفاضلی

 #11.3.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که داشبوردهای حسابداری خسارت حریم خصوصی هنگامی که مجموع ε از آستانه‌های سیاست فراتر می‌رود، هشدار می‌دهند.
 #11.3.2    سطح: 2    نقش: V
 تأیید کنید که ممیزی‌های حفظ حریم خصوصی جعبه سیاه، ε̂ را در حدود ۱۰٪ از مقدار اعلام‌شده برآورد می‌کنند.
 #11.3.3    سطح: 3    نقش: V
 تأیید کنید که اثبات‌های رسمی تمامی تنظیم‌های دقیق پس از آموزش و جاسازی‌ها را پوشش می‌دهند.

---

### 11.4 محدودیت هدف و حفاظت از گسترش دامنه

 #11.4.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که هر مجموعه داده و نقطه بازبینی مدل دارای برچسب هدف قابل‌خواندن توسط ماشین است که با رضایت اولیه هم‌راستا باشد.
 #11.4.2    سطح: 1    نقش: D/V
 تأیید کنید که پایشگرهای زمان اجرا پرس‌وجوهای ناسازگار با هدف اعلام شده را تشخیص داده و باعث رد نرم شوند.
 #11.4.3    سطح: 3    نقش: D
 تأیید کنید که دروازه‌های سیاست-به-کد از تجدید استقرار مدل‌ها به دامنه‌های جدید بدون بررسی DPIA جلوگیری می‌کنند.
 #11.4.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که اثبات‌های ردیابی رسمی نشان می‌دهند که هر چرخه عمر داده‌های شخصی در محدوده موافقت‌شده باقی می‌ماند.

---

### 11.5 مدیریت رضایت و ردیابی مبتنی بر مبنای قانونی

 #11.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که یک پلتفرم مدیریت رضایت (CMP) وضعیت رضایت، هدف و دوره نگهداری داده را برای هر موضوع داده ثبت می‌کند.
 #11.5.2    سطح: 2    نقش: D
 تأیید کنید که APIها توکن‌های رضایت را نمایش می‌دهند؛ مدل‌ها باید قبل از استنتاج دامنه توکن را اعتبارسنجی کنند.
 #11.5.3    سطح: 2    نقش: D/V
 بررسی کنید که رد یا پس گرفتن رضایت، خطوط پردازش را ظرف 24 ساعت متوقف می‌کند.

---

### 11.6 یادگیری فدراسیونی با کنترل‌های حریم خصوصی

 #11.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که به‌روزرسانی‌های کلاینت قبل از تجمیع، از افزودن نویز به صورت حریم خصوصی تفاضلی محلی استفاده می‌کنند.
 #11.6.2    سطح: 2    نقش: D/V
 تأیید کنید که معیارهای آموزش دارای حریم خصوصی متفاوت بوده و هرگز خسارت یک تک‌مشتری را فاش نمی‌کنند.
 #11.6.3    سطح: 2    نقش: V
 تأیید کنید که تجمیع مقاوم در برابر سم‌پاشی (مثلاً Krum/Trimmed-Mean) فعال باشد.
 #11.6.4    سطح: 3    نقش: V
 تأیید کنید که اثبات‌های رسمی بودجه کلی ε را با کمتر از ۵ کاهش بهره‌وری نشان می‌دهند.

---

#### مراجع

GDPR & AI Compliance Best Practices
EU Parliament Study on GDPR & AI, 2020
ISO 31700-1:2023 — Privacy by Design for Consumer Products
NIST Privacy Framework 1.1 (2025 Draft)
Machine Unlearning: Right-to-Be-Forgotten Techniques
A Survey of Machine Unlearning, 2024
Auditing DP-SGD — ArXiv 2024
DP-SGD Explained — PyTorch Blog
Purpose-Limitation for AI — IJLIT 2025
Data-Protection Considerations for AI — URM Consulting
Top Consent-Management Platforms, 2025
Secure Aggregation in DP Federated Learning — ArXiv 2024

## C12 نظارت، ثبت لاگ و تشخیص ناهنجاری

### هدف کنترل

این بخش الزامات ارائه دیدگاه بلادرنگ و قانونی درباره اینکه مدل و سایر اجزای هوش مصنوعی چه می‌بینند، انجام می‌دهند و برمی‌گردانند را فراهم می‌کند تا تهدیدها شناسایی، اولویت‌بندی و از آنها درس گرفته شود.

### C12.1 ثبت درخواست و پاسخ

 #12.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که همه درخواست‌های کاربر و پاسخ‌های مدل با متادیتای مناسب (مانند زمان ثبت، شناسه کاربر، شناسه جلسه، نسخه مدل) ثبت می‌شوند.
 #12.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که لاگ‌ها در مخازن امن و با کنترل دسترسی ذخیره شده‌اند که دارای سیاست‌های نگهداری مناسب و روش‌های پشتیبان‌گیری باشند.
 #12.1.3    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های ذخیره‌سازی لاگ، رمزگذاری هنگام ذخیره (at rest) و در انتقال (in transit) را برای محافظت از اطلاعات حساس موجود در لاگ‌ها پیاده‌سازی می‌کنند.
 #12.1.4    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که داده‌های حساس در پرامپت‌ها و خروجی‌ها به‌طور خودکار قبل از ثبت، حذف یا ماسک می‌شوند، با قوانین حذف قابل تنظیم برای اطلاعات شناسایی شخصی (PII)، مدارک و اطلاعات اختصاصی.
 #12.1.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تصمیمات سیاستی و اقدامات فیلترینگ ایمنی با جزئیات کافی ثبت می‌شوند تا امکان حسابرسی و اشکال‌زدایی سیستم‌های مدیریت محتوا فراهم گردد.
 #12.1.6    سطح: 2    نقش: D/V
 بررسی کنید که یکپارچگی لاگ‌ها از طریق مثلاً امضاهای رمزنگاری‌شده یا ذخیره‌سازی فقط‌نوشتنی محافظت می‌شود.

---

### C12.2 شناسایی سوءاستفاده و هشداردهی

 #12.2.1    سطح: 1    نقش: D/V
 تأیید کنید که سیستم با استفاده از تشخیص مبتنی بر امضا، الگوهای شناخته شده فرار از سیستم (jailbreak)، تلاش‌های تزریق دستورات (prompt injection) و ورودی‌های خصمانه را شناسایی و هشدار می‌دهد.
 #12.2.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم با استفاده از قالب‌ها و پروتکل‌های استاندارد لاگ، با پلتفرم‌های مدیریت اطلاعات امنیتی و رویدادها (SIEM) موجود، یکپارچه می‌شود.
 #12.2.3    سطح: 2    نقش: D/V
 بررسی کنید که رویدادهای امنیتی غنی‌شده شامل زمینه‌های خاص هوش مصنوعی مانند شناسه‌های مدل، امتیازهای اطمینان و تصمیمات فیلتر ایمنی باشند.
 #12.2.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تشخیص ناهنجاری رفتاری الگوهای غیرمعمول گفتگو، تلاش‌های مکرر بیش از حد، یا رفتارهای بررسی سیستماتیک را شناسایی می‌کند.
 #12.2.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های هشداردهی در زمان واقعی، تیم‌های امنیتی را هنگام شناسایی تخلفات احتمالی سیاست یا تلاش‌های حمله، اطلاع‌رسانی می‌کنند.
 #12.2.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که قوانین سفارشی برای شناسایی الگوهای تهدید خاص هوش مصنوعی از جمله تلاش‌های هماهنگ برای فرار از محدودیت‌ها (jailbreak)، کمپین‌های تزریق دستورات (prompt injection) و حملات استخراج مدل (model extraction) شامل شده‌اند.
 #12.2.7    سطح: 3    نقش: D/V
 تأیید کنید که گردش کارهای پاسخ به حادثه خودکار قادر به جداسازی مدل‌های به خطر افتاده، مسدود کردن کاربران مخرب و ارجاع رویدادهای امنیتی حیاتی هستند.

---

### C12.3 تشخیص تغییر مدل

 #12.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم معیارهای عملکرد پایه‌ای مانند دقت، امتیازهای اطمینان، تأخیر و نرخ خطاها را در نسخه‌های مدل و بازه‌های زمانی مختلف پیگیری می‌کند.
 #12.3.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که هشدارهای خودکار زمانی فعال می‌شوند که معیارهای عملکرد از آستانه‌های کاهش عملکرد از پیش تعیین‌ شده فراتر روند یا به طور قابل توجهی از مبناها انحراف داشته باشند.
 #12.3.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مانیتورهای شناسایی توهم مواردی را که خروجی‌های مدل حاوی اطلاعات نادرست از نظر واقعی، ناسازگار یا ساختگی هستند، شناسایی و علامت‌گذاری کنند.

---

### C12.4 عملکرد و تلومتری رفتار

 #12.4.1    سطح: 1    نقش: D/V
 تأیید کنید که متریک‌های عملیاتی شامل تأخیر درخواست، مصرف توکن، استفاده از حافظه و توان عملیاتی به‌طور مداوم جمع‌آوری و نظارت می‌شوند.
 #12.4.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که نرخ‌های موفقیت و شکست با دسته‌بندی انواع خطاها و علل اصلی آنها ردیابی می‌شوند.
 #12.4.3    سطح: 2    نقش: D/V
 تأیید کنید که نظارت بر استفاده از منابع شامل استفاده از GPU/CPU، مصرف حافظه و نیازهای ذخیره‌سازی باشد و هشدار در صورت عبور از آستانه‌ها فعال باشد.

---

### C12.5 برنامه‌ریزی و اجرای پاسخ به حادثه هوش مصنوعی

 #12.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که طرح‌های واکنش به حادثه به‌طور خاص به رویدادهای امنیتی مرتبط با هوش مصنوعی شامل نفوذ به مدل، مسموم‌سازی داده‌ها، و حملات خصمانه پرداخته‌اند.
 #12.5.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تیم‌های پاسخ به حادثه به ابزارها و تخصص‌های خاص مقوله هوش مصنوعی برای بررسی رفتار مدل و بردارهای حمله دسترسی دارند.
 #12.5.3    سطح: 3    نقش: D/V
 بررسی کنید که تحلیل پس از حادثه شامل ملاحظات بازآموزی مدل، به‌روزرسانی فیلترهای ایمنی، و ادغام درس‌های آموخته شده در کنترل‌های امنیتی باشد.

---

### C12.5 تشخیص کاهش عملکرد AI

نظارت و شناسایی کاهش عملکرد و کیفیت مدل هوش مصنوعی در طول زمان.

 #12.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که دقت مدل، دقت، بازیابی و نمرات F1 به طور مداوم نظارت شده و با آستانه‌های پایه مقایسه می‌شوند.
 #12.5.2    سطح: 1    نقش: D/V
 تأیید کنید که تشخیص تغییر داده، تغییرات توزیع ورودی که ممکن است بر عملکرد مدل تأثیر بگذارد را نظارت می‌کند.
 #12.5.3    سطح: 2    نقش: D/V
 بررسی کنید که تشخیص انحراف مفهوم تغییرات در رابطه بین ورودی‌ها و خروجی‌های مورد انتظار را شناسایی می‌کند.
 #12.5.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که کاهش عملکرد باعث ایجاد هشدارهای خودکار شده و فرآیندهای بازآموزی یا جایگزینی مدل را آغاز می‌کند.
 #12.5.5    سطح: 3    نقش: V
 تأیید کنید که تحلیل علت ریشه‌ای کاهش کیفیت با افت عملکرد مرتبط با تغییرات داده، مشکلات زیرساخت یا عوامل خارجی همبستگی دارد.

---

### C12.6 تجسم DAG و امنیت گردش‌کار

سیستم‌های تجسم جریان کاری را در برابر نشت اطلاعات و حملات دستکاری محافظت کنید.

 #12.6.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که داده‌های تصویری DAG پیش از ذخیره‌سازی یا ارسال، به منظور حذف اطلاعات حساس پاک‌سازی شده‌اند.
 #12.6.2    سطح: 1    نقش: D/V
 تأیید کنید که کنترل‌های دسترسی به تجسم گردش کار اطمینان می‌دهند فقط کاربران مجاز قادر به مشاهده مسیرهای تصمیم‌گیری عامل و ردپاهای استدلال باشند.
 #12.6.3    سطح: 2    نقش: D/V
 تأیید کنید که یکپارچگی داده‌های DAG از طریق امضاهای رمزنگاری شده و مکانیزم‌های ذخیره‌سازی مقاوم در برابر دستکاری محافظت شده است.
 #12.6.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های نمایش جریان کاری اعتبارسنجی ورودی را اجرا می‌کنند تا از حملات تزریقی از طریق داده‌های طراحی شده گره یا یال جلوگیری شود.
 #12.6.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که به‌روزرسانی‌های DAG در زمان واقعی محدودیت نرخ دارند و اعتبارسنجی می‌شوند تا از حملات انکار سرویس به سیستم‌های تصویری جلوگیری شود.

---

### C12.7 نظارت پیشگیرانه بر رفتار امنیتی

شناسایی و پیشگیری از تهدیدات امنیتی از طریق تحلیل رفتاری فعال و پیشگیرانه عامل.

 #12.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که رفتارهای پیشگیرانه عامل قبل از اجرا با ادغام ارزیابی ریسک از نظر امنیتی تایید شده‌اند.
 #12.7.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که محرک‌های ابتکار خودمختار شامل ارزیابی زمینه امنیتی و تحلیل چشم‌انداز تهدید هستند.
 #12.7.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که الگوهای رفتار پیشگیرانه برای پیامدهای احتمالی امنیتی و عواقب ناخواسته تحلیل شده‌اند.
 #12.7.4    سطح: 3    نقش: D/V
 تأیید کنید که اقدامات پیشگیرانه حساس به امنیت نیازمند زنجیره‌های تأیید صریح با سوابق حسابرسی هستند.
 #12.7.5    سطح: 3    نقش: D/V
 تأیید کنید که شناسایی ناهنجاری رفتاری انحرافات در الگوهای عامل پیشگیرانه را که ممکن است نشان‌دهنده نفوذ باشد، شناسایی می‌کند.

---

### مراجع

NIST AI Risk Management Framework 1.0 - Manage 4.1 and 4.3
ISO/IEC 42001:2023 — AI Management Systems Requirements - Annex B 6.2.6
EU AI Act — Article 12, 13, 16 and 19 on Logging and Record-keeping

## C13 نظارت انسانی، مسئولیت‌پذیری و حاکمیت

### هدف کنترل

این فصل الزامات حفظ نظارت انسانی و زنجیره‌های مسئولیت شفاف در سیستم‌های هوش مصنوعی را ارائه می‌دهد و اطمینان حاصل می‌کند که در طول چرخه عمر هوش مصنوعی، قابلیت توضیح، شفافیت و مدیریت اخلاقی رعایت شود.

---

### C13.1 مکانیزم‌های کلید قطع اضطراری و جایگزین

ارائه مسیرهای خاموش‌سازی یا بازگشت زمانی که رفتار ناامن سیستم هوش مصنوعی مشاهده می‌شود.

 #13.1.1    سطح: 1    نقش: D/V
 تأیید کنید که مکانیزم قطع‌کردن دستی برای توقف فوری استنتاج و خروجی‌های مدل هوش مصنوعی وجود دارد.
 #13.1.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که کنترل‌های بازنویسی فقط برای پرسنل مجاز قابل دسترسی هستند.
 #13.1.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که روندهای بازگردانی قادر به بازگرداندن به نسخه‌های قبلی مدل یا عملیات حالت امن هستند.
 #13.1.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که مکانیزم‌های نادیده‌گیری به‌طور منظم آزمایش می‌شوند.

---

### C13.2 نقاط بررسی تصمیم‌گیری با حضور انسان در حلقه

وقتی که میزان ریسک از آستانه‌های تعیین‌شده فراتر رود، نیاز به تأییدات انسانی است.

 #13.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تصمیمات هوش مصنوعی با ریسک بالا قبل از اجرا نیاز به تأیید صریح انسانی دارند.
 #13.2.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که آستانه‌های ریسک به‌طور واضح تعریف شده‌اند و به‌صورت خودکار فرآیندهای بازبینی انسانی را فعال می‌کنند.
 #13.2.3    سطح: 2    نقش: D
 تأیید کنید که تصمیمات حساس به زمان دارای روش‌های جایگزین باشند زمانی که تأیید انسانی در بازه‌های زمانی مورد نیاز قابل دریافت نباشد.
 #13.2.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که رویه‌های ارتقا، سطوح صلاحیت واضحی برای انواع مختلف تصمیم‌ها یا دسته‌بندی‌های ریسک تعیین کرده‌اند، در صورت امکان.

---

### C13.3 زنجیره مسئولیت و قابلیت حسابرسی

اقدامات اپراتور و تصمیمات مدل را ثبت کنید.

 #13.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمامی تصمیمات سیستم هوش مصنوعی و مداخلات انسانی با زمان ثبت شده، هویت کاربران، و دلایل تصمیم‌گیری ثبت می‌شوند.
 #13.3.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که لاگ‌های حسابرسی قابل تغییر نیستند و شامل مکانیزم‌های تایید صحت باشند.

---

### C13.4 تکنیک‌های هوش مصنوعی قابل توضیح

اهمیت ویژگی‌های سطحی، ضد واقعیات، و توضیحات محلی.

 #13.4.1    سطح: 1    نقش: D/V
 تأیید کنید که سیستم‌های هوش مصنوعی توضیحات پایه‌ای برای تصمیمات خود به صورت قابل خواندن توسط انسان ارائه می‌دهند.
 #13.4.2    سطح: 2    نقش: V
 اطمینان حاصل کنید که کیفیت توضیحات از طریق مطالعات و معیارهای ارزیابی انسانی تایید شده است.
 #13.4.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که امتیازهای اهمیت ویژگی یا روش‌های تخصیص (SHAP، LIME و غیره) برای تصمیمات حیاتی در دسترس هستند.
 #13.4.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که توضیحات کانترفاكت چگونه می‌توانند ورودی‌ها را تغییر دهند تا نتایج تغییر کنند، در صورت کاربرد برای مورد استفاده و حوزه مربوطه.

---

### C13.5 کارت‌های مدل و افشای نحوه استفاده

کارت‌های مدل را برای استفاده مورد نظر، معیارهای عملکرد و ملاحظات اخلاقی نگهداری کنید.

 #13.5.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که کارت‌های مدل موارد استفاده مورد نظر، محدودیت‌ها و حالت‌های شکست شناخته‌شده را مستند می‌کنند.
 #13.5.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که معیارهای عملکرد در کاربردهای مختلف قابل اجرا فاش شده‌اند.
 #13.5.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که ملاحظات اخلاقی، ارزیابی‌های تعصب، ارزیابی‌های عدالت، ویژگی‌های داده‌های آموزش و محدودیت‌های شناخته‌شده داده‌های آموزش مستندسازی شده و به طور منظم به‌روزرسانی می‌شوند.
 #13.5.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که کارت‌های مدل تحت کنترل نسخه قرار دارند و در طول دوره عمر مدل با پیگیری تغییرات نگهداری می‌شوند.

---

### C13.6 کمیت‌سنجی عدم قطعیت

امتیازهای اطمینان یا معیارهای آنتروپی را در پاسخ‌ها منتقل کنید.

 #13.6.1    سطح: 1    نقش: D
 تأیید کنید که سیستم‌های هوش مصنوعی امتیازهای اطمینان یا معیارهای عدم قطعیت را همراه با خروجی‌های خود ارائه می‌دهند.
 #13.6.2    سطح: 2    نقش: D/V
 تأیید کنید که آستانه‌های عدم قطعیت منجر به بررسی بیشتر توسط انسان یا مسیرهای تصمیم‌گیری جایگزین می‌شوند.
 #13.6.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که روش‌های تعیین کمیت عدم قطعیت کالیبره شده و در برابر داده‌های واقعی تأیید شده‌اند.
 #13.6.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که انتشار عدم قطعیت در طول جریان‌های کاری چندمرحله‌ای هوش مصنوعی حفظ می‌شود.

---

### C13.7 گزارش‌های شفافیت مقابل کاربر

افشای دوره‌ای در مورد حوادث، تغییرات (دریفت) و استفاده از داده‌ها ارائه دهید.

 #13.7.1    سطح: 1    نقش: D/V
 تأیید کنید که سیاست‌های استفاده از داده‌ها و روش‌های مدیریت رضایت کاربر به‌طور واضح به ذینفعان اطلاع‌رسانی شده است.
 #13.7.2    سطح: 2    نقش: D/V
 تأیید کنید که ارزیابی‌های تأثیر هوش مصنوعی انجام شده و نتایج آن در گزارش‌دهی درج شده باشد.
 #13.7.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که گزارش‌های شفافیت منتشر شده به‌طور منظم، حوادث هوش مصنوعی و شاخص‌های عملیاتی را با جزئیات معقول افشا می‌کنند.

#### مراجع

EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
ISO/IEC 42001:2023 — AI Management Systems Requirements
NIST AI Risk Management Framework 1.0
NIST SP 800-53 Revision 5 — Security and Privacy Controls
A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)
Model Cards for Model Reporting (Mitchell et al., 2018)
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)
ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods
IEEE 7001-2021 — Transparency of Autonomous Systems
GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)
Human Oversight under Article 14 of the EU AI Act (Fink, 2025)

## ضمیمه الف: واژه‌نامه

این واژه‌نامه جامع، تعاریف اصطلاحات کلیدی هوش مصنوعی، یادگیری ماشین و امنیت را که در سراسر AISVS به کار رفته‌اند، برای اطمینان از وضوح و درک مشترک ارائه می‌دهد.

مثال معارض: ورودی‌ای که به طور عمدی ساخته شده است تا باعث شود یک مدل هوش مصنوعی اشتباه کند، اغلب با افزودن تغییرات ظریف که برای انسان‌ها قابل تشخیص نیستند.
​
مقاومت در برابر حملات مخرب – مقاومت در برابر حملات مخرب در هوش مصنوعی به توانایی یک مدل اشاره دارد که عملکرد خود را حفظ کند و در برابر ورودی‌های عمدتاً طراحی‌شده و مخرب که هدفشان ایجاد اشتباه است، فریب خوردن یا دستکاری شدن مقاومت کند.
​
عامل – عوامل هوش مصنوعی سیستم‌های نرم‌افزاری هستند که از هوش مصنوعی برای دنبال کردن اهداف و انجام وظایف به نمایندگی از کاربران استفاده می‌کنند. آن‌ها توانایی استدلال، برنامه‌ریزی و حافظه را دارند و دارای درجه‌ای از خودمختاری برای تصمیم‌گیری، یادگیری و سازگاری هستند.
​
هوش مصنوعی عاملیت‌دار: سیستم‌های هوش مصنوعی که می‌توانند با درجه‌ای از خودمختاری برای دستیابی به اهداف عمل کنند و اغلب بدون دخالت مستقیم انسان تصمیم‌گیری و اقدام می‌کنند.
​
کنترل دسترسی مبتنی بر ویژگی (ABAC): یک پارادایم کنترل دسترسی که در آن تصمیمات مجوزدهی بر اساس ویژگی‌های کاربر، منبع، عمل و محیط، در زمان پرس‌وجو ارزیابی می‌شود.
​
حمله درب‌پشتی: نوعی حمله مسموم‌سازی داده است که در آن مدل طوری آموزش داده می‌شود که به محرک‌های خاص به صورت مشخصی پاسخ دهد در حالی که در سایر موارد به طور عادی رفتار می‌کند.
​
تعصب: خطاهای سیستماتیک در خروجی‌های مدل هوش مصنوعی که می‌توانند به نتایج ناعادلانه یا تبعیض‌آمیز برای گروه‌های خاص یا در زمینه‌های خاص منجر شوند.
​
استفاده از سوگیری: یک تکنیک حمله که از سوگیری‌های شناخته شده در مدل‌های هوش مصنوعی بهره می‌برد تا خروجی‌ها یا نتایج را دستکاری کند.
​
سدار: زبان و موتور سیاست‌های آمازون برای مجوزهای دقیق که در اجرای مدل کنترل دسترسی مبتنی بر ویژگی‌ها (ABAC) برای سیستم‌های هوش مصنوعی استفاده می‌شود.
​
زنجیره تفکر: یک تکنیک برای بهبود استدلال در مدل‌های زبانی از طریق تولید گام‌های میانی استدلال قبل از ارائه پاسخ نهایی‌.
​
قطع‌کننده‌های مدار: مکانیزم‌هایی که به‌صورت خودکار عملیات سیستم هوش مصنوعی را زمانی که آستانه‌های خطر خاصی عبور کنند، متوقف می‌کنند.
​
نشت داده: افشای ناخواسته اطلاعات حساس از طریق خروجی‌ها یا رفتار مدل هوش مصنوعی.
​
آلوده‌سازی داده: فساد عمدی داده‌های آموزشی به منظور به خطر انداختن یکپارچگی مدل، اغلب برای نصب درهای پشتی یا کاهش عملکرد.
​
حریم خصوصی تفاضلی – حریم خصوصی تفاضلی یک چارچوب ریاضی دقیق برای ارائه اطلاعات آماری درباره مجموعه داده‌ها است که در عین حال از حریم خصوصی افراد داده شده محافظت می‌کند. این امکان را برای دارنده داده فراهم می‌کند تا الگوهای کلی گروه را به اشتراک بگذارد و در عین حال اطلاعات فاش شده درباره افراد خاص را محدود کند.
​
تعبیه‌ها: نمایش‌های برداری چگال از داده‌ها (متن، تصاویر و غیره) که معنی معنایی را در یک فضای چندبعدی بالا به‌دست می‌آورند.
​
قابل توضیح بودن – قابل توضیح بودن در هوش مصنوعی به توانایی یک سیستم هوش مصنوعی در ارائه دلایل قابل فهم برای انسان‌ها درباره تصمیمات و پیش‌بینی‌هایش اشاره دارد که بینش‌هایی در مورد عملکرد داخلی آن ارائه می‌دهد.
​
هوش مصنوعی قابل توضیح (XAI): سیستم‌های هوش مصنوعی طراحی شده برای ارائه توضیحات قابل فهم توسط انسان درباره تصمیمات و رفتارهای خود از طریق روش‌ها و چارچوب‌های مختلف.
​
یادگیری فدرال: روشی در یادگیری ماشین که در آن مدل‌ها در چندین دستگاه غیرمتمرکز با داده‌های محلی آموزش داده می‌شوند، بدون اینکه خود داده‌ها تبادل شوند.
​
گاردریل‌ها: محدودیت‌هایی که برای جلوگیری از تولید خروجی‌های مضر، جانبدارانه یا به هر نحو نامطلوب توسط سامانه‌های هوش مصنوعی پیاده‌سازی شده‌اند.
​
هالوژنیشن – هالوژنیشن در هوش مصنوعی به پدیده‌ای اطلاق می‌شود که در آن مدل هوش مصنوعی اطلاعات نادرست یا گمراه‌کننده‌ای تولید می‌کند که بر اساس داده‌های آموزشی یا واقعیت‌های عینی نیست.
​
انسان در حلقه (HITL): سیستم‌هایی که به گونه‌ای طراحی شده‌اند که نیاز به نظارت، تأیید یا مداخله انسانی در نقاط تصمیم‌گیری حیاتی دارند.
​
زیرساخت به عنوان کد (IaC): مدیریت و فراهم‌سازی زیرساخت از طریق کد به جای فرآیندهای دستی، که امکان اسکن امنیتی و استقرارهای یکنواخت را فراهم می‌کند.
​
شکنجه: تکنیک‌هایی که برای دور زدن موانع ایمنی در سیستم‌های هوش مصنوعی، به ویژه در مدل‌های زبانی بزرگ، به منظور تولید محتوای ممنوعه استفاده می‌شوند.
​
حداقل امتیاز: اصل امنیتی اعطای کمترین حقوق دسترسی لازم برای کاربران و فرآیندها.
​
LIME (توضیحات محلی قابل تفسیر و مستقل از مدل): تکنیکی برای توضیح پیش‌بینی‌های هر طبقه‌بند یادگیری ماشین با تقریب زدن محلی آن با یک مدل قابل تفسیر.
​
حمله استنتاج عضویت: حمله‌ای که هدف آن تعیین این است که آیا یک داده خاص برای آموزش مدل یادگیری ماشین استفاده شده است یا خیر.
​
MITRE ATLAS: چشم‌انداز تهدیدهای خصمانه برای سیستم‌های هوش مصنوعی؛ یک پایگاه دانش از تاکتیک‌ها و تکنیک‌های خصمانه علیه سیستم‌های هوش مصنوعی.
​
کارت مدل – کارت مدل سندی است که اطلاعات استاندارد شده‌ای درباره عملکرد، محدودیت‌ها، کاربردهای مورد نظر و ملاحظات اخلاقی یک مدل هوش مصنوعی ارائه می‌دهد تا شفافیت و توسعه مسئولانه هوش مصنوعی را ترویج کند.
​
استخراج مدل: حمله‌ای که در آن یک مهاجم به طور مکرر مدل هدف را پرس‌وجو می‌کند تا یک نسخه مشابه عملکردی بدون مجوز ایجاد کند.
​
وارونه‌سازی مدل: حمله‌ای که سعی دارد داده‌های آموزشی را با تحلیل خروجی‌های مدل بازسازی کند.
​
مدیریت چرخه عمر مدل – مدیریت چرخه عمر مدل هوش مصنوعی فرآیند نظارت بر تمامی مراحل وجود یک مدل هوش مصنوعی است، شامل طراحی، توسعه، استقرار، نظارت، نگهداری و در نهایت بازنشستگی آن، تا تضمین شود که مدل مؤثر باقی می‌ماند و با اهداف هماهنگ است.
​
تسمم مدل: وارد کردن آسیب‌پذیری‌ها یا درهای پشتی به‌طور مستقیم در مدل در طی فرآیند آموزش.
​
سرقت/کپی‌برداری مدل: استخراج یک نسخه یا تقریب از یک مدل مالکیتی از طریق سوالات مکرر.
​
سیستم چندعامله: سیستمی متشکل از چندین عامل هوش مصنوعی که هر کدام ممکن است قابلیت‌ها و اهداف متفاوتی داشته باشند و با هم تعامل دارند.
​
OPA (Open Policy Agent): یک موتور سیاست متن‌باز است که امکان اجرای یکپارچه سیاست‌ها را در سراسر لایه‌ها فراهم می‌کند.
​
یادگیری ماشین حفظ حریم خصوصی (PPML): تکنیک‌ها و روش‌هایی برای آموزش و اجرای مدل‌های یادگیری ماشین در حالی که حریم خصوصی داده‌های آموزشی حفظ می‌شود.
​
تزریق فرمان: حمله‌ای که در آن دستورهای مخرب در ورودی‌ها جاسازی شده‌اند تا رفتار مورد نظر مدل را نادیده بگیرند.
​
RAG (تولید افزوده‌شده با بازیابی): روشی که مدل‌های زبان بزرگ را با بازیابی اطلاعات مرتبط از منابع دانش خارجی قبل از تولید پاسخ، بهبود می‌بخشد.
​
رد-تیمینگ: عملیاتی که شامل تست فعال سیستم‌های هوش مصنوعی با شبیه‌سازی حملات خصمانه برای شناسایی آسیب‌پذیری‌ها است.
​
SBOM (فهرست مواد نرم‌افزار): یک رکورد رسمی شامل جزئیات و روابط زنجیره تأمین اجزای مختلف مورد استفاده در ساخت نرم‌افزار یا مدل‌های هوش مصنوعی.
​
SHAP (توضیحات جمع‌شونده شاپلی): رویکردی مبتنی بر نظریه بازی‌ها برای توضیح خروجی هر مدل یادگیری ماشین با محاسبه سهم هر ویژگی در پیش‌بینی.
​
حمله زنجیره تامین: نفوذ به یک سیستم از طریق هدف قرار دادن عناصر کمتر امن در زنجیره تامین آن، مانند کتابخانه‌های شخص ثالث، مجموعه داده‌ها، یا مدل‌های از پیش آموزش‌دیده شده.
​
یادگیری انتقالی: تکنیکی که در آن یک مدل توسعه یافته برای یک وظیفه به عنوان نقطه شروع برای مدل در یک وظیفه دوم مجدداً استفاده می‌شود.
​
پایگاه داده برداری: یک پایگاه داده تخصصی طراحی شده برای ذخیره بردارهای با ابعاد بالا (تعبیه‌ها) و انجام جستجوهای شباهت به‌صورت کارآمد.
​
اسکن آسیب‌پذیری: ابزارهای خودکاری که آسیب‌پذیری‌های امنیتی شناخته شده در اجزای نرم‌افزاری، از جمله چارچوب‌ها و وابستگی‌های هوش مصنوعی را شناسایی می‌کنند.
​
واترمارکینگ: تکنیک‌هایی برای جاسازی نشانگرهای غیرقابل تشخیص در محتوای تولید شده توسط هوش مصنوعی به منظور ردیابی منبع آن یا شناسایی تولید توسط هوش مصنوعی.
​
آسیب‌پذیری صفر روز: یک آسیب‌پذیری ناشناخته که مهاجمان می‌توانند قبل از اینکه توسعه‌دهندگان وصله‌ای برای آن ایجاد و اعمال کنند، از آن سوءاستفاده کنند.

## پیوست ب: مراجع

### TODO

## پیوست C: حاکمیت و مستندسازی امنیت هوش مصنوعی

### هدف

این پیوست، الزامات اساسی برای ایجاد ساختارهای سازمانی، سیاست‌ها و فرایندها به منظور مدیریت امنیت هوش مصنوعی در سراسر چرخه عمر سیستم را ارائه می‌دهد.

---

### AC.1 پذیرش چارچوب مدیریت ریسک هوش مصنوعی

یک چارچوب رسمی برای شناسایی، ارزیابی و کاهش ریسک‌های خاص هوش مصنوعی در طول چرخه عمر سیستم ارائه دهید.

 #AC.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که یک روش‌شناسی ارزیابی ریسک خاص هوش مصنوعی مستند شده و اجرا شده باشد.
 #AC.1.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که ارزیابی‌های ریسک در نقاط کلیدی چرخه عمر هوش مصنوعی و پیش از تغییرات مهم انجام می‌شوند.
 #AC.1.3    سطح: 3    نقش: D/V
 تأیید کنید که چارچوب مدیریت ریسک با استانداردهای تثبیت‌شده مانند NIST AI RMF هماهنگ باشد.

---

### AC.2 سیاست‌ها و رویه‌های امنیتی هوش مصنوعی

تعریف و اجرای استانداردهای سازمانی برای توسعه، استقرار و بهره‌برداری امن هوش مصنوعی.

 #AC.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیاست‌های مستند شده امنیت هوش مصنوعی وجود دارد.
 #AC.2.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که سیاست‌ها حداقل سالی یک بار و پس از تغییرات قابل توجه در چشم‌انداز تهدید بازبینی و به‌روزرسانی می‌شوند.
 #AC.2.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که سیاست‌ها تمام دسته‌های AISVS و الزامات قانونی قابل اجرا را پوشش می‌دهند.

---

### AC.3 نقش‌ها و مسئولیت‌ها در امنیت هوش مصنوعی

ایجاد مسئولیت شفاف برای امنیت هوش مصنوعی در سراسر سازمان.

 #AC.3.1    سطح: 1    نقش: D/V
 تأیید کنید که نقش‌ها و مسئولیت‌های امنیتی هوش مصنوعی مستندسازی شده‌اند.
 #AC.3.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که افراد مسئول دارای تخصص مناسب در زمینه امنیت هستند.
 #AC.3.3    سطح: 3    نقش: D/V
 تأیید کنید که یک کمیته اخلاق هوش مصنوعی یا هیئت حاکمیتی برای سیستم‌های هوش مصنوعی پرخطر تأسیس شده باشد.

---

### اجرای دستورالعمل‌های اخلاقی هوش مصنوعی AC.4

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی مطابق با اصول اخلاقی تثبیت‌شده عمل کنند.

 #AC.4.1    سطح: 1    نقش: D/V
 تأیید کنید که دستورالعمل‌های اخلاقی برای توسعه و به‌کارگیری هوش مصنوعی وجود دارد.
 #AC.4.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که مکانیسم‌هایی برای شناسایی و گزارش تخلفات اخلاقی وجود دارد.
 #AC.4.3    سطح: 3    نقش: D/V
 تأیید کنید که بررسی‌های اخلاقی منظم بر روی سیستم‌های هوش مصنوعی مستقر شده انجام می‌شود.

---

### AC.5 نظارت بر انطباق مقررات هوش مصنوعی

آگاهی و رعایت قوانین رو به توسعه هوش مصنوعی را حفظ کنید.

 #AC.5.1    سطح: 1    نقش: D/V
 تأیید کنید که فرآیندهایی برای شناسایی مقررات مرتبط با هوش مصنوعی وجود دارند.
 #AC.5.2    سطح: 2    نقش: D
 اطمینان حاصل شود که رعایت تمام الزامات قانونی ارزیابی شده است.
 #AC.5.3    سطح: 3    نقش: D/V
 تأیید کنید که تغییرات قانونی، بازبینی‌ها و به‌روزرسانی‌های به‌موقع سیستم‌های هوش مصنوعی را تحریک می‌کنند.

### AC.6 حاکمیت داده‌های آموزش، مستندسازی و فرایند

 #1.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تنها مجموعه داده‌هایی که از نظر کیفیت، نمایندگی، منبع‌یابی اخلاقی و انطباق با مجوز بررسی شده‌اند، مجاز باشند، تا خطرات مسمومیت، تعصب نهفته و تخلف از حقوق مالکیت فکری کاهش یابد.
 #1.1.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که کیفیت برچسب‌گذاری/حاشیه‌نویسی از طریق بازبینی‌های متقابل بازبین‌ها یا اجماع تضمین شده است.
 #1.1.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که «کارت‌های داده» یا «برگه‌های داده برای مجموعه‌های داده» برای مجموعه داده‌های آموزشی مهم نگهداری می‌شوند، که ویژگی‌ها، انگیزه‌ها، ترکیب، فرآیندهای جمع‌آوری، پیش‌پردازش و استفاده‌های پیشنهادی/غیردوستانه را به تفصیل شرح می‌دهند.
 #1.3.2    سطح: 2    نقش: D/V
 تأیید کنید که تعصبات شناسایی شده از طریق استراتژی‌های مستند شده‌ای مانند تعدیل تعادل داده‌ها، افزایش داده هدفمند، تنظیمات الگوریتمی (مانند تکنیک‌های پیش‌پردازش، پردازش در حین اجرا، پس‌پردازش) یا تعیین وزن مجدد برطرف شده‌اند و تأثیر این تعدیل‌ها بر عدالت و عملکرد کلی مدل ارزیابی شده است.
 #1.3.3    سطح: 2    نقش: D/V
 تأیید کنید که معیارهای عدالت پس از آموزش ارزیابی و مستندسازی شده‌اند.
 #1.3.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که یک سیاست مدیریت سوگیری چرخه عمر، مالکان و دوره بازبینی را تعیین می‌کند.
 #1.4.1    سطح: 2    نقش: D/V
 اطمینان حاصل شود که کیفیت برچسب‌گذاری/حاشیه‌نویسی از طریق راهنمایی‌های واضح، بررسی‌های متقابل توسط بازبین‌ها، مکانیزم‌های اجماع (مانند پایش توافق بین حاشیه‌نویسان) و فرآیندهای تعریف شده برای حل اختلافات تضمین شده است.
 #1.4.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که برچسب‌های حیاتی برای ایمنی، امنیت یا عدالت (مانند شناسایی محتوای سمی، یافته‌های پزشکی حیاتی) تحت بازبینی مستقل دوگانه الزامی یا تایید قوی معادل قرار گیرند.
 #1.4.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که راهنمای برچسب‌گذاری و دستورالعمل‌ها جامع، کنترل شده توسط نسخه و بررسی شده توسط همتایان باشند.
 #1.4.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که طرح‌های داده‌ای برای برچسب‌ها به‌طور واضح تعریف شده‌اند و نسخه‌بندی می‌شوند.
 #1.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که داده‌ها از نظر عدم تعادل نمایشی و سوگیری‌های بالقوه در ویژگی‌های محافظت شده قانونی (مانند نژاد، جنسیت، سن) و دیگر ویژگی‌های حساس اخلاقی مرتبط با حوزه کاربرد مدل (مانند وضعیت اجتماعی-اقتصادی، مکان) پروفایل شده‌اند.
 #1.5.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که بررسی‌های دستی نقطه‌ای توسط کارشناسان حوزه، نمونه‌ای با اهمیت آماری را پوشش می‌دهد (مثلاً ≥1% یا 1,000 نمونه، هر کدام که بیشتر باشد، یا طبق ارزیابی ریسک تعیین شده) تا مسائل کیفی ظریف که توسط اتوماسیون شناسایی نشده‌اند، شناسایی شوند.
 #1.8.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که گردش‌کارهای برچسب‌گذاری برون‌سپاری شده یا جمع‌سپاری شده شامل تدابیر فنی/روشی برای تضمین محرمانگی داده‌ها، یکپارچگی داده‌ها، کیفیت برچسب‌ها و جلوگیری از نشت داده‌ها باشند.
 #1.5.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مراحل اصلاح به سوابق منشاء اضافه شده‌اند.
 #1.6.2    سطح: 2    نقش: D/V
 تأیید کنید که نمونه‌های علامت‌گذاری شده، قبل از آموزش منجر به بازبینی دستی شوند.
 #1.6.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که نتایج، پرونده امنیتی مدل را تغذیه می‌کنند و اطلاعات تهدید در حال انجام را اطلاع‌رسانی می‌کنند.
 #1.6.4    سطح: 3    نقش: D/V
 تأیید کنید که منطق تشخیص با اطلاعات تهدید جدید به‌روزرسانی شده است.
 #1.6.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که لوله‌های یادگیری آنلاین تغییر توزیع را نظارت می‌کنند.
 #1.7.1    سطح: 1    نقش: D/V
 تأیید کنید که روندهای حذف داده‌های آموزش، داده‌های اصلی و مشتق شده را پاک می‌کنند و تأثیر آن بر مدل را ارزیابی می‌کنند، و همچنین تأثیر بر مدل‌های متاثر شده بررسی و در صورت لزوم، مانند بازآموزی یا تنظیم مجدد، برطرف می‌شود.
 #1.7.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که مکانیزم‌هایی برای پیگیری و احترام به دامنه و وضعیت رضایت کاربر (و پس‌گیری‌ها) برای داده‌های استفاده‌شده در آموزش وجود دارد، و اینکه رضایت قبل از به‌کارگیری داده‌ها در فرآیندهای آموزش جدید یا به‌روزرسانی‌های مهم مدل تأیید می‌شود.
 #1.7.3    سطح: 2    نقش: V
 تأیید کنید که گردش‌های کاری به‌صورت سالانه آزمایش شده و ثبت شده‌اند.
 #1.8.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تامین‌کنندگان داده‌های شخص ثالث، از جمله ارائه‌دهندگان مدل‌های پیش‌آموزش دیده و مجموعه داده‌های خارجی، قبل از ادغام داده‌ها یا مدل‌هایشان، مورد بررسی دقیق امنیت، حفظ حریم خصوصی، تأمین اخلاقی و کیفیت داده قرار می‌گیرند.
 #1.8.2    سطح: 1    نقش: D
 تأیید کنید که انتقال‌های خارجی از TLS/احراز هویت و بررسی‌های یکپارچگی استفاده می‌کنند.
 #1.8.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که منابع داده پرخطر (به عنوان مثال، مجموعه داده‌های متن‌باز با منشأ نامشخص، تأمین‌کنندگان غیرتأییدشده) قبل از استفاده در کاربردهای حساس، تحت بررسی‌های دقیق‌تر قرار گیرند، مانند تحلیل در محیط ایزوله (sandbox)، بررسی‌های گسترده کیفیت/سوگیری، و تشخیص هدفمند مسموم‌سازی داده.
 #1.8.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مدل‌های از پیش آموزش‌دیده شده‌ای که از طرف‌های ثالث به دست می‌آیند، قبل از آموزش نهایی یا استقرار، از نظر سوگیری‌های نهفته، پشتی‌های احتمالی، صحت ساختارشان و منشأ داده‌های آموزشی اصلی‌شان ارزیابی شده باشند.
 #1.5.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که در صورت استفاده از آموزش مقابله‌ای (adversarial training)، فرایند تولید، مدیریت، و نسخه‌بندی داده‌های مقابله‌ای مستندسازی شده و تحت کنترل است.
 #1.5.3    سطح: 3    نقش: D/V
 تأیید کنید که تأثیر آموزش مقاومت در برابر حملات مخرب بر عملکرد مدل (در برابر ورودی‌های پاک و مخرب) و معیارهای عدالت ارزیابی، مستندسازی و رصد می‌شود.
 #1.5.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که استراتژی‌های آموزش خصمانه و مقاومت به‌طور دوره‌ای بازبینی و به‌روزرسانی می‌شوند تا تکنیک‌های حمله خصمانه در حال تکامل را مقابله کنند.
 #1.4.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که داده‌های ناموفق با ردیابی‌های ممیزی قرنطینه شده‌اند.
 #1.4.3    سطح: 2    نقش: D/V
 تأیید کنید که گیت‌های کیفیت داده‌های زیر استاندارد را مسدود می‌کنند مگر اینکه استثناها تصویب شده باشند.
 #1.11.2    سطح: 2    نقش: D/V
 تأیید کنید که فرآیند تولید، پارامترها و استفاده مورد نظر از داده‌های مصنوعی مستندسازی شده است.
 #1.11.3    سطح: 2    نقش: D/V
 تأیید کنید که داده‌های مصنوعی پیش از استفاده در آموزش، از نظر ریسک‌های تعصب، نشت حریم خصوصی و مسائل نمایش ارزیابی شده باشند.
 #1.12.3    سطح: 2    نقش: D/V
 تأیید کنید که هشدارها برای رویدادهای دسترسی مشکوک ایجاد شده و به سرعت بررسی شوند.
 #1.13.1    سطح: 1    نقش: D/V
 تأیید کنید که دوره‌های نگهداری صریح برای همه مجموعه‌های داده‌های آموزش تعریف شده‌اند.
 #1.13.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مجموعه داده‌ها در پایان چرخه عمرشان به‌طور خودکار منقضی، حذف یا برای حذف بررسی می‌شوند.
 #1.13.3    سطح: 2    نقش: D/V
 تأیید کنید که اقدامات نگهداری و حذف ثبت شده و قابل حسابرسی هستند.
 #1.14.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که الزامات محل اقامت داده‌ها و انتقال فرامرزی برای همه مجموعه داده‌ها شناسایی و اجرا شده‌اند.
 #1.14.2    سطح: 2    نقش: D/V
 بررسی کنید که مقررات خاص هر بخش (مثلاً بهداشت و درمان، مالی) شناسایی شده و در مدیریت داده‌ها مورد توجه قرار گرفته باشد.
 #1.14.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که رعایت قوانین مربوط به حفظ حریم خصوصی (مانند GDPR، CCPA) مستندسازی شده و به‌طور منظم مورد بازبینی قرار می‌گیرد.
 #1.16.1    سطح: 2    نقش: D/V
 تأیید کنید که مکانیسم‌هایی برای پاسخ به درخواست‌های افراد موضوع داده برای دسترسی، اصلاح، محدودیت یا اعتراض وجود دارد.
 #1.16.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که درخواست‌ها در بازه‌های زمانی الزام‌آور قانونی ثبت، پیگیری و انجام می‌شوند.
 #1.16.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فرآیندهای حقوق موضوع داده به طور منظم برای اثربخشی آزمایش و بازبینی می‌شوند.
 #1.17.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که قبل از به‌روزرسانی یا جایگزینی نسخه داده‌ها، تحلیل تأثیر انجام شده است که شامل عملکرد مدل، عدالت و تطابق است.
 #1.17.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که نتایج تحلیل اثر مستندسازی شده و توسط ذینفعان مربوطه بازبینی شده است.
 #1.17.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که طرح‌های بازگشت وجود دارد تا در صورت وارد کردن نسخه‌های جدید ریسک‌ها یا بازگشت‌های غیرقابل قبول، بتوان به نسخه قبلی بازگشت.
 #1.18.1    سطح: 2    نقش: D/V
 تأیید کنید که تمام پرسنل دخیل در برچسب‌گذاری داده‌ها، بررسی‌های پیش‌زمینه را گذرانده و در زمینه امنیت داده و حفظ حریم خصوصی آموزش دیده‌اند.
 #1.18.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تمام پرسنل حاشیه‌نویسی قراردادهای محرمانگی و عدم افشا را امضا کرده‌اند.
 #1.18.3    سطح: 2    نقش: D/V
 تأیید کنید که پلتفرم‌های حاشیه‌نویسی کنترل‌های دسترسی را اعمال می‌کنند و تهدیدهای داخلی را نظارت می‌کنند.

#### مراجع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
EU Artificial Intelligence Act — Regulation (EU) 2024/1689
ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods

## ضمیمه د: حاکمیت و تایید برنامه‌نویسی امن با کمک هوش مصنوعی

### هدف

این فصل کنترل‌های سازمانی پایه برای استفاده ایمن و مؤثر از ابزارهای کدنویسی مبتنی بر هوش مصنوعی در طول توسعه نرم‌افزار را تعریف می‌کند، به‌گونه‌ای که امنیت و قابلیت ردگیری در سراسر چرخه عمر توسعه نرم‌افزار (SDLC) تضمین شود.

---

### AD.1 روند کدنویسی امن با کمک هوش مصنوعی

ابزارهای هوش مصنوعی را در چرخه حیات توسعه نرم‌افزار امن (SSDLC) سازمان ادغام کنید بدون اینکه نقاط کنترل امنیتی موجود را تضعیف نمایید.

 #AD.1.1    سطح: 1    نقش: D/V
 تایید کنید که یک جریان کاری مستند شده، زمان و نحوه استفاده از ابزارهای هوش مصنوعی برای تولید، بازسازی یا بررسی کد را توصیف می‌کند.
 #AD.1.2    سطح: 2    نقش: D
 تأیید کنید که جریان کاری به هر مرحله از SSDLC (طراحی، پیاده‌سازی، بازبینی کد، تست، استقرار) منطبق باشد.
 #AD.1.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که معیارها (مانند چگالی آسیب‌پذیری، میانگین زمان تشخیص) برای کد تولید شده توسط هوش مصنوعی جمع‌آوری شده و با مبناهای صرفاً انسانی مقایسه می‌شوند.

---

### شایستگی ابزار AI AD.2 و مدل‌سازی تهدید

اطمینان حاصل کنید که ابزارهای کدنویسی هوش مصنوعی از نظر قابلیت‌های امنیتی، ریسک و تأثیر زنجیره تأمین پیش از پذیرش، ارزیابی شوند.

 #AD.2.1    سطح: 1    نقش: D/V
 تأیید کنید که مدل تهدید برای هر ابزار هوش مصنوعی سوءاستفاده، معکوس‌سازی مدل، نشت داده و ریسک‌های زنجیره وابستگی را شناسایی می‌کند.
 #AD.2.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که ارزیابی‌های ابزار شامل تحلیل ایستا/پویا از هر مؤلفه محلی و ارزیابی نقاط انتهایی SaaS (TLS، تأیید هویت/مجوز، ثبت لاگ) باشد.
 #AD.2.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که ارزیابی‌ها از چارچوبی شناخته شده پیروی می‌کنند و پس از تغییرات عمده نسخه، مجدداً انجام می‌شوند.

---

### مدیریت امن فرمان و زمینه AD.3

جلوگیری از نشت اسرار، کد اختصاصی و داده‌های شخصی هنگام ساختن پرامپت‌ها یا زمینه‌ها برای مدل‌های هوش مصنوعی.

 #AD.3.1    سطح: 1    نقش: D/V
 تأیید کنید که راهنمایی‌های نوشته‌شده ارسال اسرار، مدارک شناسایی یا داده‌های طبقه‌بندی‌شده را در درخواست‌ها ممنوع می‌کند.
 #AD.3.2    سطح: 2    نقش: D
 تأیید کنید که کنترل‌های فنی (اصلاح سمت مشتری، فیلترهای زمینه تأیید شده) به‌طور خودکار عناصر حساس را حذف می‌کنند.
 #AD.3.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که پرامپت‌ها و پاسخ‌ها توکنیزه شده، در حین انتقال و در حالت استراحت رمزگذاری شده‌اند و دوره‌های نگهداری با سیاست طبقه‌بندی داده‌ها مطابقت دارند.

---

### AD.4 اعتبارسنجی کد تولیدشده توسط هوش مصنوعی

شناسایی و رفع آسیب‌پذیری‌های ناشی از خروجی هوش مصنوعی پیش از ادغام یا استقرار کد.

 #AD.4.1    سطح: 1    نقش: D/V
 تأیید کنید که کد تولید شده توسط هوش مصنوعی همیشه تحت بررسی کد انسانی قرار می‌گیرد.
 #AD.4.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که اسکنرهای خودکار (SAST/IAST/DAST) روی هر درخواست کششی که شامل کد تولید شده توسط هوش مصنوعی است اجرا شوند و ادغام‌ها را در صورت وجود یافته‌های حیاتی مسدود کنند.
 #AD.4.3    سطح: 3    نقش: D/V
 تأیید کنید که آزمایش‌های فازی تفاضلی یا آزمایش‌های مبتنی بر خاصیت رفتارهای حیاتی برای امنیت (مانند اعتبارسنجی ورودی، منطق مجوزدهی) را اثبات می‌کنند.

---

### AD.5 قابلیت توضیح‌پذیری و ردیابی پیشنهادهای کد

به حسابرسان و توسعه‌دهندگان بینشی درباره اینکه چرا یک پیشنهاد ارائه شده است و چگونه تکامل یافته است، ارائه دهید.

 #AD.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که جفت‌های پرامپت/پاسخ با شناسه‌های کامیت ثبت می‌شوند.
 #AD.5.2    سطح: 2    نقش: D
 تایید کنید که توسعه‌دهندگان قادرند ارجاعات مدل (قطعات آموزشی، مستندات) را که از یک پیشنهاد پشتیبانی می‌کند، نمایش دهند.
 #AD.5.3    سطح: 3    نقش: D/V
 تأیید کنید که گزارش‌های شفافیت همراه با مصنوعات طراحی ذخیره شده و در بازبینی‌های امنیتی مورد ارجاع قرار می‌گیرند، به طوری که اصول قابل پیگیری بودن ISO/IEC 42001 را برآورده کنند.

---

### AD.6 بازخورد مستمر و تنظیم دقیق مدل

عملکرد امنیت مدل را در طول زمان بهبود دهید در حالی که از انحراف منفی جلوگیری می‌کنید.

 #AD.6.1    سطح: 1    نقش: D/V
 بررسی کنید که توسعه‌دهندگان قادر به علامت‌گذاری پیشنهادهای ناامن یا غیرمطابق هستند و اینکه این علامت‌ها پیگیری می‌شوند.
 #AD.6.2    سطح: 2    نقش: D
 تأیید کنید که بازخورد تجمیعی، فاینتیونینگ دوره‌ای یا تولید تقویت‌شده با بازیابی با مجموعه‌های کد‌نویسی امن تأیید شده (مانند OWASP Cheat Sheets) را مطلع می‌کند.
 #AD.6.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که یک چارچوب ارزیابی حلقه بسته پس از هر تنظیم دقیق، تست‌های رگرسیون را اجرا می‌کند؛ شاخص‌های امنیتی باید قبل از استقرار، با معیارهای پایه قبلی برابر یا بهتر باشند.

---

#### مراجع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
OWASP Secure Coding Practices — Quick Reference Guide

## ضمیمه E: نمونه ابزارها و چارچوب‌ها

### هدف

این فصل مثال‌هایی از ابزارها و چارچوب‌هایی را که می‌توانند در پیاده‌سازی یا تحقق یک نیازمندی مشخص از AISVS پشتیبانی کنند، ارائه می‌دهد. این موارد نباید به عنوان توصیه یا تأییدیه‌ای از سوی تیم AISVS یا پروژه امنیت GenAI در OWASP دیده شوند.

---

### AE.1 حاکمیت داده‌های آموزشی و مدیریت سوگیری

ابزارهای مورد استفاده برای تحلیل داده‌ها، حاکمیت داده‌ها، و مدیریت سوگیری.

 #AE.1.1    بخش: 1.1
 ابزار مدیریت فهرست داده‌ها: ابزارهای مدیریت فهرست داده مانند...
 #AE.1.2    بخش: 1.2
 رمزنگاری در حال انتقال از TLS برای برنامه‌های مبتنی بر HTTPS استفاده کنید، با ابزارهایی مانند openSSL و پایتون`ssl`کتابخانه.

---

### AE.2 اعتبارسنجی ورودی کاربر

ابزارهایی برای مدیریت و اعتبارسنجی ورودی‌های کاربران.

 #AE.2.1    بخش: 2.1
 ابزارهای دفاع در برابر تزریق پرامپت: از ابزارهای محافظتی مانند NeMo شرکت NVIDIA یا Guardrails AI استفاده کنید.

---

