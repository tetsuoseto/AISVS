## صفحه عنوان

### درباره استاندارد

استاندارد بررسی امنیت هوش مصنوعی (AISVS) یک فهرست مبتنی بر جامعه از الزامات امنیتی است که دانشمندان داده، مهندسان MLOps، معماران نرم‌افزار، توسعه‌دهندگان، آزمون‌گران، متخصصان امنیت، فروشندگان ابزار، تنظیم‌کنندگان و کاربران می‌توانند از آن برای طراحی، ساخت، آزمایش و تأیید سیستم‌ها و برنامه‌های قابل اعتماد مجهز به هوش مصنوعی استفاده کنند. این استاندارد زبان مشترکی برای تعیین کنترل‌های امنیتی در سراسر چرخه عمر هوش مصنوعی ارائه می‌دهد — از جمع‌آوری داده‌ها و توسعه مدل تا استقرار و نظارت مداوم — تا سازمان‌ها بتوانند مقاومت، حریم خصوصی و ایمنی راه‌حل‌های هوش مصنوعی خود را اندازه‌گیری و بهبود بخشند.

### حق نشر و مجوز

نسخه 0.1 (اولین پیش‌نویس عمومی - در حال کار)، 2025  

![license](images/license.png)
کپی‌رایت © 2025 پروژه AISVS.  

منتشر شده تحتCreative Commons Attribution‑ShareAlike 4.0 International License.
برای هرگونه استفاده مجدد یا توزیع، شما باید شرایط مجوز این اثر را به‌طور واضح به دیگران اعلام کنید.

### رهبران پروژه

جیم مانیكو
آراس "راس" ممیزیاقی

### مشارکت‌کنندگان و بازبین‌ها

https://github.com/ottosulin
https://github.com/mbhatt1
https://github.com/vineethsai
https://github.com/cciprofm
https://github.com/deepakrpandey12


---

AISVS یک استاندارد کاملاً جدید است که به‌طور خاص برای پاسخ به چالش‌های امنیتی منحصربه‌فرد سیستم‌های هوش مصنوعی ایجاد شده است. در حالی که از بهترین شیوه‌های امنیتی گسترده‌تر الهام می‌گیرد، هر الزامی در AISVS از ابتدا به گونه‌ای توسعه یافته است که چشم‌انداز تهدیدات هوش مصنوعی را منعکس کند و به سازمان‌ها کمک کند تا راه‌حل‌های هوش مصنوعی ایمن‌تر و مقاوم‌تری بسازند.

## مقدمه

به استاندارد تایید امنیت هوش مصنوعی (AISVS) نسخه 1.0 خوش آمدید!

### مقدمه

AISVS که در سال 2025 از طریق همکاری جامعه شکل گرفت، الزامات امنیتی را که باید هنگام طراحی، توسعه، استقرار و بهره‌برداری از مدل‌های مدرن هوش مصنوعی، خطوط لوله و خدمات فعال‌شده با هوش مصنوعی در نظر گرفته شوند، تعریف می‌کند.

AISVS v1.0 نمایانگر همکاری مشترک رهبران پروژه، گروه کاری و مشارکت‌کنندگان گسترده‌تر جامعه است تا یک پایه عملی و قابل آزمایش برای ایمن‌سازی سیستم‌های هوش مصنوعی ارائه دهد.

هدف ما در این نسخه این است که AISVS را به گونه‌ای ارائه دهیم که استفاده از آن ساده باشد، در حالی که به طور دقیق بر دامنه تعریف شده آن متمرکز مانده و به چشم‌انداز ریسک به سرعت در حال تحول که منحصربه‌فرد هوش مصنوعی است، پرداخته شود.

### اهداف کلیدی برای نسخه 1.0 AISVS

نسخه 1.0 با چندین اصل راهنما ایجاد خواهد شد.

#### حوزه مشخص و تعریف شده

هر الزام باید با نام و مأموریت AISVS هماهنگ باشد:

هوش مصنوعی – کنترل‌ها در لایه AI/ML (داده، مدل، خط لوله، یا استنتاج) عمل می‌کنند و مسئولیت آن‌ها بر عهده متخصصان هوش مصنوعی است.
امنیت – الزامات به‌طور مستقیم خطرات شناسایی‌شده امنیتی، حریم خصوصی یا ایمنی را کاهش می‌دهند.
اعتبارسنجی – زبان به گونه‌ای نوشته شده است که انطباق آن بتواند به طور عینی تایید شود.
استاندارد – بخش‌ها ساختار و اصطلاحات یکسانی را دنبال می‌کنند تا مرجع منسجمی ایجاد کنند.
​
---

با پیروی از AISVS، سازمان‌ها می‌توانند به‌طور سیستماتیک وضعیت امنیتی راه‌حل‌های هوش مصنوعی خود را ارزیابی و تقویت کنند و فرهنگ مهندسی امن هوش مصنوعی را ترویج دهند.

## استفاده از AISVS

استاندارد تأیید امنیت هوش مصنوعی (AISVS) الزامات امنیتی برای برنامه‌ها و خدمات هوش مصنوعی مدرن را تعریف می‌کند و بر جنبه‌هایی تمرکز دارد که در کنترل توسعه‌دهندگان برنامه است.

AISVS برای هر کسی که در حال توسعه یا ارزیابی امنیت برنامه‌های هوش مصنوعی است، از جمله توسعه‌دهندگان، معماران، مهندسان امنیت و حسابرسان، در نظر گرفته شده است. این فصل ساختار و نحوه استفاده از AISVS را معرفی می‌کند، شامل سطوح تایید و موارد استفاده مورد نظر آن.

### سطوح تأیید امنیت هوش مصنوعی

AISVS سه سطح تصاعدی از تأیید امنیت را تعریف می‌کند. هر سطح عمق و پیچیدگی بیشتری می‌افزاید و به سازمان‌ها امکان می‌دهد وضعیت امنیتی خود را متناسب با سطح ریسک سیستم‌های هوش مصنوعی خود تنظیم کنند.

سازمان‌ها ممکن است از سطح 1 شروع کنند و به تدریج با افزایش بلوغ امنیتی و مواجهه با تهدیدات، سطوح بالاتری را اتخاذ کنند.

#### تعریف سطوح

هر نیازمندی در AISVS نسخه 1.0 به یکی از سطوح زیر اختصاص داده شده است:

 الزامات سطح 1

سطح 1 شامل حیاتی‌ترین و بنیادی‌ترین نیازهای امنیتی است. این سطح بر جلوگیری از حملات رایج که به شرایط یا آسیب‌پذیری‌های دیگر وابسته نیستند، تمرکز دارد. اکثر کنترل‌های سطح 1 یا اجرای ساده‌ای دارند یا به اندازه کافی اساسی هستند که توجیه‌کننده صرف تلاش باشند.

 الزامات سطح 2

سطح 2 به حملات پیشرفته‌تر یا کمتر رایج، و همچنین دفاع‌های چندلایه در برابر تهدیدات گسترده می‌پردازد. این الزامات ممکن است شامل منطق پیچیده‌تر یا هدف قرار دادن پیش‌نیازهای خاص حمله باشند.

 الزامات سطح 3

سطح ۳ شامل کنترل‌هایی است که معمولاً پیاده‌سازی آنها دشوارتر یا کاربرد آنها موقعیتی است. این‌ها اغلب مکانیزم‌های دفاع در عمق یا کاهش‌دهنده‌هایی در برابر حملات خاص، هدفمند یا با پیچیدگی بالا هستند.

#### نقش (D/V)

هر الزام AISVS بر اساس مخاطب اصلی علامت‌گذاری شده است:

D – نیازمندی‌های متمرکز بر توسعه‌دهنده
V – الزامات متمرکز بر تاییدکننده/ممیز
D/V – مرتبط با هر دو توسعه‌دهندگان و تاییدکنندگان

## حاکمیت داده‌های آموزش C1 و مدیریت تعصب

### هدف کنترل

داده‌های آموزشی باید به گونه‌ای تأمین، مدیریت و نگهداری شوند که منشاء، امنیت، کیفیت و انصاف را حفظ کنند. انجام این کار وظایف قانونی را برآورده کرده و خطرات تعصب، سم‌پاشی یا نقض حریم خصوصی که در طول آموزش ظهور می‌یابند و می‌توانند بر کل چرخه عمر هوش مصنوعی تأثیر بگذارند، کاهش می‌دهد.

---

### C1.1 منشاء داده‌های آموزش

نگهداری یک فهرست قابل تأیید از تمام داده‌ها، پذیرش فقط منابع مورد اعتماد، و ثبت هر تغییر برای قابلیت حسابرسی.

 #1.1.1    سطح: 1    نقش: D/V
 تأیید کنید که یک موجودی به‌روز از هر منبع داده‌ی آموزشی (مبدا، مسئول/مالک، مجوز، روش جمع‌آوری، محدودیت‌های استفاده مورد نظر و تاریخچه پردازش) نگهداری می‌شود.
 #1.1.2    سطح: 1    نقش: D/V
 تأیید کنید که فرایندهای داده‌های آموزشی شامل ویژگی‌ها، خصوصیات یا فیلدهای غیرضروری نباشند (مانند متادیتای استفاده‌نشده، داده‌های حساس اطلاعات شناسایی شخصی، داده‌های نشت یافته از آزمون).
 #1.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که همه تغییرات داده‌ها مشمول یک گردش کار تأیید ثبت‌شده هستند.
 #1.1.4    سطح: 3    نقش: D/V
 تأیید کنید که داده‌ها یا زیرمجموعه‌ها در صورت امکان دارای نشان‌گذاری آبی (واترمارک) یا اثر انگشتی باشند.

---

### C1.2 امنیت و یکپارچگی داده‌های آموزش

دسترسی به داده‌های آموزشی را محدود کنید، آن‌ها را در حالت استراحت و انتقال رمزگذاری کنید، و صحت آن‌ها را برای جلوگیری از دستکاری، سرقت یا مسمومیت داده‌ها تأیید کنید.

 #1.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که کنترل‌های دسترسی، ذخیره‌سازی داده‌های آموزشی و خطوط لوله را محافظت می‌کنند.
 #1.2.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که همه دسترسی‌ها به داده‌های آموزشی ثبت شده است، از جمله کاربر، زمان و عملیات انجام شده.
 #1.2.3    سطح: 2    نقش: D/V
 تأیید کنید که مجموعه داده‌های آموزشی هنگام انتقال و در حالت استراحت با استفاده از الگوریتم‌های رمزنگاری استاندارد صنعتی و روش‌های مدیریت کلید رمزگذاری شده باشند.
 #1.2.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که هش‌های رمزنگاری شده یا امضاهای دیجیتال برای تضمین صحت داده‌ها در حین ذخیره‌سازی و انتقال داده‌های آموزش استفاده می‌شوند.
 #1.2.5    سطح: 2    نقش: D/V
 تأیید کنید که تکنیک‌های تشخیص خودکار برای محافظت در برابر تغییرات یا فساد غیرمجاز داده‌های آموزشی اعمال شده‌اند.
 #1.2.6    سطح: 2    نقش: D/V
 اطمینان حاصل شود که داده‌های آموزشی قدیمی به‌طور امن پاک‌سازی یا ناشناس‌سازی شده‌اند.
 #1.2.7    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تمام نسخه‌های مجموعه داده آموزشی به طور منحصربه‌فرد شناسایی شده، به صورت غیرقابل تغییر ذخیره شده و قابل حسابرسی هستند تا از پشتیبانی بازگشت به عقب و تحلیل قانونی برخوردار باشند.

---

### C1.3 کیفیت، یکپارچگی و امنیت برچسب‌گذاری داده‌های آموزشی

برچسب‌ها را محافظت کنید و برای داده‌های حیاتی نیازمند بازبینی فنی باشید.

 #1.3.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که هش‌های رمزنگاری یا امضاهای دیجیتال بر روی مصنوعات برچسب‌گذاری شده اعمال شده‌اند تا یکپارچگی و اصالت آنها تضمین شود.
 #1.3.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که رابط‌ها و پلتفرم‌های برچسب‌گذاری کنترل‌های دسترسی قوی را اعمال می‌کنند، سوابق حسابرسی دارای قابلیت تشخیص دستکاری از تمامی فعالیت‌های برچسب‌گذاری را حفظ می‌کنند و در برابر تغییرات غیرمجاز محافظت می‌کنند.
 #1.3.3    سطح: 3    نقش: D/V
 تأیید کنید که اطلاعات حساس در برچسب‌ها در سطح فیلد داده‌ها، هم در حالت استراحت و هم در حین انتقال، حذف‌شده، ناشناس‌سازی شده یا رمزگذاری شده‌اند.

---

### C1.4 تضمین کیفیت و امنیت داده‌های آموزشی

ترکیب اعتبارسنجی خودکار، بررسی‌های دستی نمونه‌ای و ثبت اصلاحات به منظور تضمین قابلیت اطمینان مجموعه داده‌ها.

 #1.4.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که تست‌های خودکار خطاهای قالب و مقادیر خالی را در هر بار ورود داده یا تبدیل داده‌های مهم شناسایی می‌کنند.
 #1.4.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که خط‌مشی‌های آموزش و تنظیم دقیق LLM شامل تشخیص مسمومیت و اعتبارسنجی یکپارچگی داده‌ها (مانند روش‌های آماری، شناسایی نقاط دورافتاده، تحلیل جاسازی‌ها) برای شناسایی حملات احتمالی مسمومیت (مانند جابجایی برچسب، وارد کردن محرک در پشتی، دستورات تعویض نقش، حملات موارد تاثیرگذار) یا خرابی غیرعمدی داده‌ها در داده‌های آموزشی اجرا شده‌اند.
 #1.4.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تدابیر دفاعی مناسبی مانند آموزش مقابله‌ای (استفاده از نمونه‌های مقابله‌ای تولید شده)، افزایش داده‌ها با ورودی‌های تغییر یافته، یا تکنیک‌های بهینه‌سازی مقاوم، برای مدل‌های مربوطه بر اساس ارزیابی ریسک اجرا و تنظیم شده‌اند.
 #1.4.4    سطح: 2    نقش: D/V
 تأیید کنید که برچسب‌های تولیدشده به‌صورت خودکار (برای مثال، از طریق مدل‌های زبانی بزرگ یا نظارت ضعیف) تحت آستانه‌های اطمینان و بررسی‌های سازگاری قرار دارند تا برچسب‌های توهم‌زده، گمراه‌کننده یا با اطمینان پایین شناسایی شوند.
 #1.4.5    سطح: 3    نقش: D
 اطمینان حاصل کنید که تست‌های خودکار انحراف‌های برچسب را در هر بار ورود داده یا تغییرات قابل توجه داده‌ها شناسایی می‌کنند.

---

### C1.5 خط سیر داده و قابلیت پیگیری

ردیابی کامل مسیر هر نقطه داده از منبع تا ورودی مدل برای قابلیت حسابرسی و پاسخ به حوادث.

 #1.5.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که شجره‌نامه هر نقطه داده، شامل همه تحولات، افزوده‌ها و ادغام‌ها، ثبت شده و قابل بازسازی باشد.
 #1.5.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که سوابق شجره‌ای تغییرناپذیر، به‌طور امن ذخیره شده و برای بررسی‌ها قابل دسترسی باشند.
 #1.5.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که پیگیری منشا داده شامل داده‌های مصنوعی تولید شده از طریق تکنیک‌های حفظ حریم خصوصی یا تولیدی می‌شود و تمام داده‌های مصنوعی به وضوح برچسب‌گذاری شده و در تمام مراحل پردازش از داده‌های واقعی قابل تمایز باشند.

---

### مراجع

NIST AI Risk Management Framework
EU AI Act – Article 10: Data & Data Governance
MITRE ATLAS: Adversary Tactics for AI
Survey of ML Bias Mitigation Techniques – MDPI
Data Provenance & Lineage Best Practices – Nightfall AI
Data Labeling Quality Standards – LabelYourData
Training Data Poisoning Guide – Lakera.ai
CISA Advisory: Securing Data for AI Systems
ISO/IEC 23053: AI Management Systems Framework
IBM: What is AI Governance?
Google AI Principles
GDPR & AI Training Data – DataProtectionReport
Supply-Chain Security for AI Data – AppSOC
OpenAI Privacy Center – Data Deletion Controls
Adversarial ML Dataset – Kaggle

## اعتبارسنجی ورودی کاربر در C2

### هدف کنترل

اعتبارسنجی محکم ورودی کاربر، اولین خط دفاع در برابر برخی از مخرب‌ترین حملات به سیستم‌های هوش مصنوعی است. حملات تزریق فرمان می‌توانند دستورالعمل‌های سیستم را لغو کنند، اطلاعات حساس را فاش سازند یا مدل را به سمت رفتاری سوق دهند که مجاز نیست. مگر اینکه فیلترهای اختصاصی و سلسله‌مراتب دستورالعمل‌ها وجود داشته باشد، تحقیقات نشان می‌دهد که هک‌های "چندضربه‌ای" که از پنجره‌های متن بسیار طولانی بهره می‌برند، مؤثر خواهند بود. همچنین، حملات perturbation مخفیانه و خصمانه مانند جابجایی‌های هم‌ریش (homoglyph) یا نوشتار leetspeak می‌توانند تصمیمات مدل را به‌طور خاموش تغییر دهند.

---

### دفاع در برابر تزریق فرمان C2.1

تزریق پرامپت یکی از بزرگ‌ترین ریسک‌ها برای سیستم‌های هوش مصنوعی است. دفاع در برابر این تاکتیک از ترکیبی از فیلترهای الگوهای ایستا، دسته‌بندهای پویا و اجرای سلسله‌مراتبی دستورات استفاده می‌کند.

 #2.1.1    سطح: 1    نقش: D/V
 تائید کنید که ورودی‌های کاربر در برابر یک کتابخانه به‌روز شده مداوم از الگوهای شناخته شده تزریق پرامپت (کلیدواژه‌های جیل‌بریک، "ignore previous"، زنجیره‌های نقش‌آفرینی، حملات غیرمستقیم HTML/URL) بررسی می‌شوند.
 #2.1.2    سطح: 1    نقش: D/V
 تأیید کنید که سیستم یک سلسله مراتب دستوری را اعمال می‌کند که در آن پیام‌های سیستم یا توسعه‌دهنده بر دستورالعمل‌های کاربر اولویت دارند، حتی پس از گسترش پنجره زمینه.
 #2.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که آزمایش‌های ارزیابی مقابله‌ای (مانند درخواست‌های "چند نمونه‌ای" تیم قرمز) قبل از هر نسخه مدل یا قالب درخواست اجرا می‌شوند، با آستانه‌های نرخ موفقیت و مسدودکننده‌های خودکار برای بازگشت به عقب.
 #2.1.4    سطح: 2    نقش: D
 تأیید کنید که درخواست‌هایی که از محتوای شخص ثالث (صفحات وب، فایل‌های PDF، ایمیل‌ها) می‌آیند، در یک محیط تجزیه جدا شده پاک‌سازی شوند قبل از اینکه به درخواست اصلی اضافه شوند.
 #2.1.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که همه به‌روزرسانی‌های قوانین فیلتر پرامپت، نسخه‌های مدل طبقه‌بندی‌کننده و تغییرات فهرست مسدود شده به صورت کنترل نسخه شده و قابل حسابرسی هستند.

---

### C2.2 مقاومت در برابر نمونه‌های خصمانه

مدل‌های پردازش زبان طبیعی (NLP) همچنان در برابر تغییرات ظریف در سطح کاراکتر یا کلمه آسیب‌پذیر هستند که انسان‌ها اغلب آن‌ها را متوجه نمی‌شوند اما مدل‌ها به طور معمول آن‌ها را به اشتباه طبقه‌بندی می‌کنند.

 #2.2.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که مراحل پایه نرمال‌سازی ورودی (NFC یونیکد، نگاشت هم‌ریشه‌ها، حذف فاصله‌های اضافی) قبل از توکنیزه کردن اجرا شوند.
 #2.2.2    سطح: 2    نقش: D/V
 تأیید کنید که تشخیص ناهنجاری آماری ورودی‌هایی را که فاصله ویرایشی به‌طور غیرمعمول بالا نسبت به هنجارهای زبانی دارند، توکن‌های بیش از حد تکراری یا فاصله‌های تعبیه غیرعادی نشان می‌دهد.
 #2.2.3    سطح: 2    نقش: D
 تأیید کنید که خط لوله استنتاج از نسخه‌های مدل مقاوم‌شده به آموزش خصمانه اختیاری یا لایه‌های دفاعی (مانند تصادفی‌سازی، تقطیر دفاعی) برای نقاط پایانی با ریسک بالا پشتیبانی می‌کند.
 #2.2.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که ورودی‌های مشکوک به مهاجمان در قرنطینه قرار می‌گیرند و با بار کامل داده‌ها (پس از حذف اطلاعات شناسایی شخصی) ثبت می‌شوند.
 #2.2.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که معیارهای استحکام (نرخ موفقیت مجموعه‌های حمله شناخته شده) در طول زمان ردیابی شوند و بازگشت‌ها باعث ایجاد مانع برای انتشار شوند.

---

### C2.3 اعتبارسنجی طرح‌واره، نوع و طول

حملات هوش مصنوعی با ورودی‌های نامنظم یا بزرگ می‌توانند باعث خطاهای تجزیه، نشت دستورالعمل در زمینه‌ها و خستگی منابع شوند. اعمال دقیق طرح‌واره همچنین پیش‌نیاز لازم هنگام انجام فراخوانی‌های ابزار قطعی است.

 #2.3.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که هر نقطه پایان فراخوانی API یا تابع، یک طرح ورودی صریح (JSON Schema، Protobuf یا معادل چندرسانه‌ای) تعریف می‌کند و ورودی‌ها قبل از ساخت پرامپت اعتبارسنجی می‌شوند.
 #2.3.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که ورودی‌هایی که از حد مجاز توکن یا بایت عبور می‌کنند، با یک خطای ایمن رد می‌شوند و هرگز به‌طور بی‌صدا کوتاه نمی‌شوند.
 #2.3.3    سطح: 2    نقش: D/V
 بررسی کنید که چک‌های نوع (مانند محدوده‌های عددی، مقادیر enum، نوع MIME برای تصاویر/صوت) در سمت سرور اعمال شوند و نه فقط در کد سمت کلاینت.
 #2.3.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که اعتبارسنج‌های معنایی (مانند JSON Schema) در زمان ثابت اجرا می‌شوند تا از حملات DoS الگوریتمی جلوگیری شود.
 #2.3.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که شکست‌های اعتبارسنجی با قطعات پالود داده شده و کدهای خطای بدون ابهام ثبت می‌شوند تا در بررسی امنیتی کمک کنند.

---

### C2.4 غربالگری محتوا و سیاست‌ها

توسعه‌دهندگان باید قادر باشند پرسش‌های نحوی صحیح که درخواست محتوای ممنوعه (مانند دستورالعمل‌های غیرقانونی، گفتار نفرت‌انگیز و متون دارای حق کپی‌رایت) را دارند، شناسایی کرده و سپس از گسترش آنها جلوگیری کنند.

 #2.4.1    سطح: 1    نقش: D
 تأیید کنید که یک طبقه‌بند محتوا (صفر شات یا آموزش دیده شده) هر ورودی را برای خشونت، خودآسیبی، نفرت، محتوای جنسی و درخواست‌های غیرقانونی با آستانه‌های قابل تنظیم ارزیابی کند.
 #2.4.2    سطح: 1    نقش: D/V
 تأیید کنید که ورودی‌هایی که قوانین را نقض می‌کنند، پاسخ‌های استاندارد شده یا تکمیل‌های ایمن دریافت خواهند کرد تا به فراخوانی‌های بعدی مدل زبان بزرگ منتقل نشوند.
 #2.4.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که مدل غربالگری یا مجموعه قوانین حداقل به صورت فصلی بازآموزی/به‌روزرسانی شود و الگوهای تازه مشاهده شده فرار از محدودیت یا دورزدن سیاست‌ها را در بر گیرد.
 #2.4.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که غربالگری، سیاست‌های خاص کاربر (سن، محدودیت‌های قانونی منطقه‌ای) را از طریق قوانین مبتنی بر ویژگی که در زمان درخواست حل می‌شوند، رعایت می‌کند.
 #2.4.5    سطح: 3    نقش: V
 تأیید کنید که گزارش‌های غربالگری شامل نمرات اطمینان طبقه‌بندی‌کننده و برچسب‌های دسته‌بندی سیاست برای همبستگی SOC و پخش مجدد تیم قرمز در آینده باشد.

---

### C2.5 محدود کردن نرخ ورودی و پیشگیری از سوء استفاده

توسعه‌دهندگان باید از سوءاستفاده، خستگی منابع و حملات خودکار علیه سیستم‌های هوش مصنوعی با محدود کردن نرخ ورودی‌ها و شناسایی الگوهای استفاده غیرعادی جلوگیری کنند.

 #2.5.1    سطح: 1    نقش: D/V
 تأیید کنید که محدودیت‌های نرخ برای هر کاربر، هر آدرس IP و هر کلید API برای تمامی نقاط ورود داده اعمال می‌شوند.
 #2.5.2    سطح: 2    نقش: D/V
 تأیید کنید که محدودیت‌های نرخ انفجاری و مداوم به گونه‌ای تنظیم شده‌اند که از حملات انکار سرویس (DoS) و حملات brute force جلوگیری کنند.
 #2.5.3    سطح: 2    نقش: D/V
 تأیید کنید که الگوهای استفاده غیرمعمول (برای مثال، درخواست‌های سریع متوالی، اشباع ورودی) باعث فعال شدن مسدودسازی‌های خودکار یا افزایش سطح رسیدگی شوند.
 #2.5.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که گزارش‌های پیشگیری از سوءاستفاده حفظ شده و برای الگوهای حمله در حال ظهور بررسی می‌شوند.

---

### C2.6 اعتبارسنجی ورودی چندوجهی

سیستم‌های هوش مصنوعی باید اعتبارسنجی قوی برای ورودی‌های غیرمتنی (تصاویر، صدا، فایل‌ها) شامل شوند تا از تزریق، فرار یا سوءاستفاده از منابع جلوگیری شود.

 #2.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که تمامی ورودی‌های غیر متنی (تصاویر، صدا، فایل‌ها) از نظر نوع، اندازه و فرمت قبل از پردازش بررسی و اعتبارسنجی شده‌اند.
 #2.6.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فایل‌ها قبل از بارگذاری، جهت شناسایی بدافزارها و بارهای استگانولوژیک اسکن می‌شوند.
 #2.6.3    سطح: 2    نقش: D/V
 تأیید کنید که ورودی‌های تصویر/صدا برای اختلالات مخرب یا الگوهای حمله شناخته شده بررسی شده باشند.
 #2.6.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که شکست‌های اعتبارسنجی ورودی چندمودالی ثبت شده و هشدارهایی را برای بررسی ایجاد می‌کنند.

---

### C2.7 منشأ ورودی و انتساب

سیستم‌های هوش مصنوعی باید از طریق نظارت و برچسب‌گذاری منابع تمام ورودی‌های کاربران، از ممیزی، پیگیری سوء استفاده و تطابق پشتیبانی کنند.

 #2.7.1    سطح: 1    نقش: D/V
 تأیید کنید که تمام ورودی‌های کاربر هنگام دریافت با متادیتا (شناسه کاربر، نشست، منبع، زمان‌بندی، نشانی IP) برچسب‌گذاری شده باشند.
 #2.7.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فراداده منشا برای تمام ورودی‌های پردازش شده حفظ شده و قابل بررسی باشد.
 #2.7.3    سطح: 2    نقش: D/V
 مطمئن شوید که منابع ورودی غیرعادی یا غیرقابل اعتماد علامت‌گذاری شده و تحت بررسی دقیق‌تر یا مسدودسازی قرار می‌گیرند.

---

### C2.8 تشخیص تهدید تطبیقی در زمان واقعی

توسعه‌دهندگان باید از سیستم‌های پیشرفته شناسایی تهدید برای هوش مصنوعی استفاده کنند که به الگوهای جدید حمله سازگار شده و حفاظت در زمان واقعی با تطبیق الگوی کامپایل شده ارائه دهند.

 #2.8.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که الگوهای تشخیص تهدید به موتورهای regex بهینه‌شده تبدیل شده‌اند تا فیلترینگ بلادرنگ با عملکرد بالا و تأثیر حداقلی بر تأخیر انجام شود.
 #2.8.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های تشخیص تهدید، کتابخانه‌های الگو جداگانه برای دسته‌های مختلف تهدید (تزریق فرمان، محتوای مضر، داده‌های حساس، دستورات سیستم) حفظ می‌کنند.
 #2.8.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تشخیص تهدید تطبیقی شامل مدل‌های یادگیری ماشین است که حساسیت تهدید را بر اساس فراوانی حمله و نرخ موفقیت به‌روزرسانی می‌کنند.
 #2.8.4    سطح: 2    نقش: D/V
 تأیید کنید که خوراک‌های اطلاعات تهدید به‌صورت بلادرنگ به‌طور خودکار کتابخانه‌های الگو را با امضاهای حمله جدید و شاخص‌های نفوذ (IOC) به‌روزرسانی می‌کنند.
 #2.8.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که نرخ‌های مثبت کاذب در تشخیص تهدید به طور مداوم نظارت می‌شوند و ویژگی‌های الگو به طور خودکار تنظیم می‌شوند تا حداقل تداخل با موارد استفاده قانونی را داشته باشند.
 #2.8.6    سطح: 3    نقش: D/V
 بررسی کنید که تحلیل تهدید متنی منبع ورودی، الگوهای رفتار کاربر و تاریخچه جلسه را برای بهبود دقت تشخیص در نظر می‌گیرد.
 #2.8.7    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که معیارهای عملکرد شناسایی تهدید (نرخ شناسایی، تأخیر پردازش، استفاده از منابع) به صورت آنلاین مانیتور شده و بهینه‌سازی می‌شوند.

---

### C2.9 خط لوله اعتبارسنجی امنیت چند حالته

توسعه‌دهندگان باید اعتبارسنجی امنیتی برای ورودی‌های متنی، تصویری، صوتی و سایر حالت‌های ورودی هوش مصنوعی با استفاده از انواع مشخصی از تشخیص تهدید و جداسازی منابع ارائه دهند.

 #2.9.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر روش ورودی دارای اعتبارسنج‌های امنیتی اختصاصی با الگوهای تهدید مستند شده (متن: تزریق پرامپت، تصاویر: پنهان‌نگاری، صوت: حملات طیف‌نگار) و آستانه‌های تشخیص می‌باشد.
 #2.9.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که ورودی‌های چند حالته در محیط‌های ایزوله با محدودیت‌های منابع مشخص (حافظه، CPU، زمان پردازش) که به هر نوع حالت اختصاص داده شده‌اند، پردازش می‌شوند و این موارد در سیاست‌های امنیتی مستندسازی شده‌اند.
 #2.9.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تشخیص حمله چندوجهی، حملات هماهنگ شده که چندین نوع ورودی را شامل می‌شوند (به عنوان مثال، بارهای نهان‌نگاری شده در تصاویر همراه با تزریق درخواست در متن) را با استفاده از قوانین همبستگی و تولید هشدار شناسایی می‌کند.
 #2.9.4    سطح: 3    نقش: D/V
 تأیید کنید که شکست‌های اعتبارسنجی چندوجهی باعث ثبت دقیق گزارش‌ها می‌شوند، از جمله همه حالت‌های ورودی، نتایج اعتبارسنجی، نمرات تهدید و تحلیل همبستگی با فرمت‌های گزارش ساختاریافته برای یکپارچگی با SIEM.
 #2.9.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که دسته‌بندهای محتوای اختصاصی مدالیته مطابق با برنامه‌های مستند (حداقل فصلی) با الگوهای تهدید جدید، نمونه‌های متخاصم و معیارهای عملکرد که بالاتر از آستانه‌های پایه نگهداری می‌شوند، به‌روزرسانی می‌شوند.

---

### مراجع

LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security
Generative AI's Biggest Security Flaw Is Not Easy to Fix
Many-shot jailbreaking \ Anthropic
$PDF$ OpenAI GPT-4.5 System Card
Notebook for the CheckThat Lab at CLEF 2024
Mitigate jailbreaks and prompt injections – Anthropic
Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis
OWASP Top 10 for LLM Applications 2025 – WorldTech IT
OWASP Machine Learning Security Top Ten
Few words about AI Security – Jussi Metso
How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry
Easily enforcing valid JSON schema following – API
AI Safety + Cybersecurity R\&D Tracker – Fairly AI
Anthropic makes 'jailbreak' advance to stop AI models producing harmful results
Pattern matching filter rules - IBM
Real-time Threat Detection

## مدیریت چرخه عمر مدل C3 و کنترل تغییرات

### هدف کنترل

سیستم‌های هوش مصنوعی باید فرآیندهای کنترل تغییر را پیاده‌سازی کنند که از رسیدن تغییرات مدل غیرمجاز یا ناایمن به مرحله تولید جلوگیری کند. این کنترل، صحت مدل را در سراسر چرخه عمر—از توسعه تا استقرار و از کار اندازی—تضمین می‌کند که پاسخ سریع به حوادث را ممکن ساخته و مسئولیت‌پذیری برای تمامی تغییرات را حفظ می‌کند.

هدف اصلی امنیت: تنها مدل‌های مجاز و تأیید شده با استفاده از فرایندهای کنترل‌شده که یکپارچگی، قابلیت ردیابی و قابلیت بازیابی را حفظ می‌کنند، به مرحله تولید می‌رسند.

---

### C3.1 مجوز مدل و صحت آن

تنها مدل‌های مجاز با صحت معتبر به محیط‌های تولید می‌رسند.

 #3.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام مصنوعات مدل (وزن‌ها، پیکربندی‌ها، توکنیزرها) پیش از استقرار توسط نهادهای مجاز به صورت رمزنگاری شده امضاء شده‌اند.
 #3.1.2    سطح: 1    نقش: D/V
 تأیید کنید که صحت مدل در زمان استقرار ارزیابی شده و خطاهای تأیید امضا مانع بارگذاری مدل می‌شوند.
 #3.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که سوابق منشأ مدل شامل هویت نهاد مجازکننده، مجموع‌های بازبینی داده‌های آموزشی، نتایج تست اعتبارسنجی با وضعیت قبول/رد و یک مهر زمانی ایجاد باشد.
 #3.1.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تمام آثار مدل از نسخه‌بندی معنایی (MAJOR.MINOR.PATCH) استفاده می‌کنند و معیارهای مستندی برای مشخص کردن زمان افزایش هر بخش نسخه وجود دارد.
 #3.1.5    سطح: 2    نقش: V
 تأیید کنید که ردیابی وابستگی‌ها یک موجودی به‌روز و هم‌زمان را حفظ می‌کند که شناسایی سریع تمامی سیستم‌های مصرف‌کننده را ممکن می‌سازد.

---

### C3.2 اعتبارسنجی و آزمایش مدل

مدل‌ها باید قبل از استقرار، اعتبارسنجی‌های امنیتی و ایمنی تعریف‌شده را پشت سر بگذارند.

 #3.2.1    سطح: 1    نقش: D/V
 تأیید کنید که مدل‌ها تحت آزمایش امنیتی خودکار قرار می‌گیرند که شامل اعتبارسنجی ورودی، تصفیه خروجی و ارزیابی‌های ایمنی با آستانه‌های قبلاً توافق‌شده سازمانی برای قبولی یا رد قبل از استقرار است.
 #3.2.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که خطاهای اعتبارسنجی به‌طور خودکار پس از تأیید تجاوز صریح از طرف افراد مجاز پیش تعیین‌شده با دلایل کسب‌وکار مستندسازی‌شده، مانع از استقرار مدل می‌شوند.
 #3.2.3    سطح: 2    نقش: V
 تأیید کنید که نتایج تست به صورت رمزنگاری شده امضا شده و به طور تغییرناپذیر به هش نسخه مدل خاص در حال اعتبارسنجی متصل شده‌اند.
 #3.2.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که استقرارهای اضطراری نیازمند ارزیابی مستند ریسک امنیتی و تأییدیه از یک مرجع امنیتی پیش‌تعیین‌شده در بازه‌های زمانی از پیش توافق شده هستند.

---

### C3.3 استقرار کنترل شده و بازگردانی

استقرار مدل‌ها باید کنترل‌شده، تحت نظارت و قابل بازگشت باشد.

 #3.3.1    سطح: 1    نقش: D
 تأیید کنید که استقرارهای تولید مکانیزم‌های راه‌اندازی تدریجی (استقرارهای کاناری، استقرارهای آبی-سبز) را با مکانیزم‌های بازگشت خودکار بر اساس نرخ خطاهای توافق‌شده قبلی، آستانه‌های تأخیر، یا معیارهای هشدار امنیتی پیاده‌سازی کرده باشند.
 #3.3.2    سطح: 1    نقش: D/V
 تأیید کنید که قابلیت‌های بازگردانی به صورت اتمی وضعیت کامل مدل (وزن‌ها، پیکربندی‌ها، وابستگی‌ها) را در چارچوب زمانی تعریف‌شده سازمانی بازیابی می‌کنند.
 #3.3.3    سطح: 2    نقش: D/V
 تأیید کنید که فرآیندهای استقرار امضاهای رمزنگاری شده را بررسی کرده و چک‌سام‌های صحت را پیش از فعال‌سازی مدل محاسبه می‌کنند و در صورت هر گونه عدم تطابق، استقرار را متوقف می‌کنند.
 #3.3.4    سطح: 2    نقش: D/V
 تأیید کنید که قابلیت‌های خاموش کردن اضطراری مدل بتوانند نقاط پایانی مدل را در زمان‌های پاسخ از پیش تعریف شده، از طریق مدار شکن‌های خودکار یا سوئیچ‌های دستی، غیرفعال کنند.
 #3.3.5    سطح: 2    نقش: V
 تأیید کنید که اشیاء بازگردانی (نسخه‌های قبلی مدل، پیکربندی‌ها، وابستگی‌ها) طبق سیاست‌های سازمانی حفظ شده‌اند، با استفاده از ذخیره‌سازی غیرقابل تغییر برای پاسخ به حوادث.

---

### C3.4 تغییر مسئولیت‌پذیری و حسابرسی

تمام تغییرات چرخه عمر مدل باید قابل ردیابی و حسابرسی باشد.

 #3.4.1    سطح: 1    نقش: V
 اطمینان حاصل کنید که تمامی تغییرات مدل (استقرار، پیکربندی، بازنشستگی) سوابق حسابرسی غیرقابل تغییر شامل یک زمان‌سنجی، هویت معتبر شده بازیگر، نوع تغییر، و وضعیت‌های قبل/بعد را تولید می‌کنند.
 #3.4.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که دسترسی به گزارش حسابرسی نیازمند مجوز مناسب است و همه تلاش‌های دسترسی با هویت کاربر و مهر زمانی ثبت می‌شوند.
 #3.4.3    سطح: 2    نقش: D/V
 تأیید کنید که قالب‌های پرامپت و پیام‌های سیستمی در مخازن گیت کنترل نسخه شده‌اند و بازبینی کد و تأیید اجباری از سوی بررسی‌کنندگان تعیین شده قبل از استقرار انجام می‌شود.
 #3.4.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که سوابق حسابرسی شامل جزئیات کافی (هش‌های مدل، عکس‌های پیکربندی، نسخه‌های وابستگی) برای امکان بازسازی کامل وضعیت مدل در هر زمان مشخص در دوره نگهداری باشد.

---

### C3.5 روش‌های توسعه ایمن

فرایندهای توسعه و آموزش مدل باید از روش‌های امن پیروی کنند تا از نفوذ جلوگیری شود.

 #3.5.1    سطح: 1    نقش: D
 تأیید کنید که محیط‌های توسعه مدل، آزمایش و تولید به صورت فیزیکی یا منطقی از هم جدا باشند. این محیط‌ها باید زیرساخت مشترک نداشته باشند، کنترل‌های دسترسی متفاوتی داشته باشند و بانک‌های داده‌ای جداگانه و ایزوله شده داشته باشند.
 #3.5.2    سطح: 1    نقش: D
 تأیید کنید که آموزش مدل و تنظیم دقیق آن در محیط‌های جدا شده با دسترسی کنترل‌شده به شبکه انجام می‌شود.
 #3.5.3    سطح: 1    نقش: D/V
 تأیید کنید که منابع داده‌های آموزش از طریق بررسی‌های صحت و اعتبارسنجی شده و توسط منابع معتبر با زنجیره مستندسازی Custody قبل از استفاده در توسعه مدل احراز هویت شده‌اند.
 #3.5.4    سطح: 2    نقش: D
 تأیید کنید که مصنوعات توسعه مدل (ابرپارامترها، اسکریپت‌های آموزش، فایل‌های پیکربندی) در سیستم کنترل نسخه ذخیره شده‌اند و قبل از استفاده در آموزش نیاز به تأیید بازبینی همتا دارند.

---

### C3.6 بازنشستگی و از کار انداختن مدل

مدل‌ها باید هنگامی که دیگر مورد نیاز نیستند یا زمانی که مشکلات امنیتی شناسایی می‌شوند، به‌طور ایمن بازنشسته شوند.

 #3.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که فرایندهای بازنشستگی مدل به‌طور خودکار نمودارهای وابستگی را اسکن می‌کنند، همه سیستم‌های مصرف‌کننده را شناسایی می‌کنند و دوره‌های اطلاع قبلی توافق‌شده را قبل از از رده خارج کردن فراهم می‌آورند.
 #3.6.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که آثار مدل بازنشسته به‌طور ایمن با استفاده از پاک‌سازی رمزنگاری یا بازنویسی چندگانه مطابق با سیاست‌های مستند حفظ داده‌ها پاک شده‌اند و دارای گواهی‌های تأیید شده تخریب باشند.
 #3.6.3    سطح: 2    نقش: V
 تأیید کنید که رویدادهای بازنشستگی مدل با زمان‌بندی و هویت بازیگر ثبت می‌شوند و امضاهای مدل لغو می‌شوند تا از استفاده مجدد جلوگیری گردد.
 #3.6.4    سطح: 2    نقش: D/V
 تأیید کنید که بازنشستگی مدل اضطراری می‌تواند دسترسی به مدل را در چارچوب زمانی پاسخ اضطراری از پیش تعیین شده از طریق سوئیچ‌های قطع خودکار در صورت کشف آسیب‌پذیری‌های امنیتی بحرانی، غیرفعال کند.

---

### مراجع

MLOps Principles
Securing AI/ML Ops – Cisco.com
Audit logs security: cryptographically signed tamper-proof logs
Machine Learning Model Versioning: Top Tools & Best Practices
AI Hygiene Starts with Models and Data Loaders – SEI Blog
How to handle versioning and rollback of a deployed ML model?
Reinforcement fine-tuning – OpenAI API
Auditing Machine Learning models: Governance, Data Security and …
Adversarial Training to Improve Model Robustness
What is AI adversarial robustness? – IBM Research
Exploring Data Provenance: Ensuring Data Integrity and Authenticity
MITRE ATLAS
AWS Prescriptive Guidance – Best practices for retiring applications …

## زیرساخت C4، پیکربندی و امنیت استقرار

### هدف کنترل

زیرساخت هوش مصنوعی باید در برابر ارتقای سطح دسترسی، دستکاری زنجیره تامین و حرکت جانبی از طریق پیکربندی ایمن، ایزولاسیون در زمان اجرا، خطوط تولید مورد اعتماد و نظارت جامع مستحکم شود. تنها اجزا و پیکربندی‌های زیرساخت مجاز و معتبر شده از طریق فرآیندهای کنترل‌شده که امنیت، یکپارچگی و قابلیت حسابرسی را حفظ می‌کنند، به محیط تولید می‌رسند.

هدف اصلی امنیتی: تنها اجزای زیرساختی که از نظر رمزنگاری امضا شده و از نظر آسیب‌پذیری اسکن شده‌اند، از طریق خطوط تأیید خودکار که سیاست‌های امنیتی را اجرا می‌کنند و سوابق حسابرسی تغییرناپذیر را حفظ می‌کنند، به محیط تولید می‌رسند.

---

### C4.1 جداسازی محیط اجرای زمان اجرا

از فرار از کانتینر و ارتقای اختیارات جلوگیری کنید از طریق ابتداییات جداسازی در سطح کرنل و کنترل‌های دسترسی اجباری.

 #4.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام کانتینرهای AI تمام قابلیت‌های لینوکس را به جز CAP_SETUID، CAP_SETGID و قابلیت‌های به‌طور صریح مورد نیاز و مستند شده در خطوط پایه امنیتی، حذف کرده‌اند.
 #4.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که پروفایل‌های seccomp تمامی فراخوانی‌های سیستم (syscalls) را به جز آن‌هایی که در فهرست‌های اجازه‌ی از پیش تایید شده قرار دارند، مسدود می‌کنند، به گونه‌ای که در صورت نقض، کانتینر متوقف شده و هشدارهای امنیتی تولید شود.
 #4.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که بارهای کاری هوش مصنوعی با سیستم فایل ریشه فقط خواندنی، tmpfs برای داده‌های موقتی، و حجم‌های نام‌گذاری شده برای داده‌های پایدار اجرا شوند و گزینه‌های mount با noexec اعمال شده باشند.
 #4.1.4    سطح: 2    نقش: D/V
 بررسی کنید که پایش زمان‌اجرایی مبتنی بر eBPF (مانند Falco، Tetragon یا معادل آن) تلاش‌های افزایش سطح دسترسی را شناسایی کرده و فرآیندهای متخلف را به طور خودکار در چارچوب زمان پاسخگویی سازمان متوقف کند.
 #4.1.5    سطح: 3    نقش: D/V
 تأیید کنید که بارهای کاری هوش مصنوعی با ریسک بالا در محیط‌های ایزوله شده سخت‌افزاری (Intel TXT، AMD SVM، یا نودهای اختصاصی bare-metal) با تأیید استناد اجرا می‌شوند.

---

### C4.2 خطوط لوله ساخت و استقرار امن

حفظ صحت رمزنگاری و امنیت زنجیره تأمین از طریق ساخت‌های قابل تولید مجدد و آثار امضا شده.

 #4.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که زیرساخت به عنوان کد با استفاده از ابزارهایی مانند tfsec، Checkov، یا Terrascan در هر تعهد (commit) اسکن می‌شود و ادغام‌ها در صورت وجود یافته‌های با شدت CRITICAL یا HIGH مسدود می‌گردند.
 #4.2.2    سطح: 1    نقش: D/V
 تأیید کنید که ساخت کانتینرها با هش‌های SHA256 یکسان در سراسر ساخت‌ها تکرارپذیر باشد و تصدیقات منشأ SLSA سطح 3 را با امضای Sigstore تولید کنید.
 #4.2.3    سطح: 2    نقش: D/V
 تأیید کنید که تصاویر کانتینر شامل SBOMهای CycloneDX یا SPDX باشند و قبل از ارسال به رجیستری با Cosign امضا شده باشند، به‌طوری‌که تصاویر بدون امضا در زمان استقرار رد شوند.
 #4.2.4    سطح: 2    نقش: D/V
 تأیید کنید که خطوط لوله CI/CD از توکن‌های OIDC از HashiCorp Vault، نقش‌های IAM در AWS، یا Managed Identity در Azure با طول عمرهایی که از محدودیت‌های سیاست امنیتی سازمان فراتر نمی‌روند، استفاده می‌کنند.
 #4.2.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که امضاهای Cosign و منشأ SLSA در طول فرآیند استقرار قبل از اجرای کانتینر اعتبارسنجی می‌شوند و خطاهای اعتبارسنجی باعث شکست استقرار می‌شوند.
 #4.2.6    سطح: 2    نقش: D/V
 تأیید کنید که محیط‌های ساخت در کانتینرها یا ماشین‌های مجازی زودگذر اجرا شوند که فاقد ذخیره‌سازی دائمی و با ایزولاسیون شبکه از VPCهای تولید باشند.

---

### C4.3 امنیت شبکه و کنترل دسترسی

شبکه‌سازی بدون اعتماد را با سیاست‌های پیش‌فرض-رد و ارتباطات رمزنگاری‌شده پیاده‌سازی کنید.

 #4.3.1    سطح: 1    نقش: D/V
 بررسی کنید که آیا Kubernetes NetworkPolicies یا هر معادل آن، قوانین پیش‌فرض جلوگیری از ورود/خروج را با قوانین صریح اجازه برای پورت‌های مورد نیاز (443، 8080 و غیره) پیاده‌سازی می‌کند یا خیر.
 #4.3.2    سطح: 1    نقش: D/V
 تأیید کنید که پورت SSH (پورت 22)، RDP (پورت 3389)، و نقاط پایانی متادیتای ابری (169.254.169.254) مسدود شده‌اند یا نیاز به تأیید هویت مبتنی بر گواهینامه دارند.
 #4.3.3    سطح: 2    نقش: D/V
 تأیید کنید که ترافیک خروجی از طریق پراکسی‌های HTTP/HTTPS (مانند Squid، Istio، یا دروازه‌های NAT ابری) با فهرست‌های مجاز دامنه فیلتر شده و درخواست‌های مسدود شده ثبت می‌شوند.
 #4.3.4    سطح: 2    نقش: D/V
 بررسی کنید که ارتباط بین سرویس‌ها از TLS دوطرفه استفاده می‌کند، با گواهی‌نامه‌هایی که بر اساس سیاست سازمانی به‌صورت دوره‌ای تعویض می‌شوند و اعتبارسنجی گواهی‌نامه‌ها اعمال می‌شود (بدون استفاده از فلگ‌های skip-verify).
 #4.3.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که زیرساخت هوش مصنوعی در VPCها/VNetهای اختصاصی اجرا می‌شود که دسترسی مستقیم به اینترنت ندارند و تنها از طریق دروازه‌های NAT یا میزبان‌های باسیون ارتباط برقرار می‌کند.

---

### C4.4 مدیریت اسرار و کلیدهای رمزنگاری

حفاظت از مدارک اعتباری از طریق ذخیره‌سازی مبتنی بر سخت‌افزار و چرخش خودکار با دسترسی صفر اعتماد.

 #4.4.1    سطح: 1    نقش: D/V
 اعتبارسنجی کنید که اسرار در HashiCorp Vault، AWS Secrets Manager، Azure Key Vault یا Google Secret Manager با رمزگذاری در حالت استراحت با استفاده از AES-256 ذخیره شده‌اند.
 #4.4.2    سطح: 1    نقش: D/V
 تأیید کنید که کلیدهای رمزنگاری در HSMهای سطح 2 مطابق با استاندارد FIPS 140-2 (مانند AWS CloudHSM، Azure Dedicated HSM) تولید می‌شوند و چرخش کلیدها مطابق با سیاست رمزنگاری سازمانی انجام می‌پذیرد.
 #4.4.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که چرخش اسرار به‌صورت خودکار با استقرار بدون قطعی و چرخش فوری که توسط تغییرات پرسنلی یا حوادث امنیتی آغاز می‌شود، انجام می‌گیرد.
 #4.4.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تصاویر کانتینری با ابزارهایی مانند GitLeaks، TruffleHog، یا detect-secrets اسکن می‌شوند تا ساخت‌هایی که شامل کلیدهای API، رمز عبورها یا گواهینامه‌ها هستند، مسدود شوند.
 #4.4.5    سطح: 2    نقش: D/V
 تصدیق کنید که دسترسی به اسرار تولیدی نیازمند احراز هویت چندمرحله‌ای (MFA) با توکن‌های سخت‌افزاری (YubiKey، FIDO2) است و این دسترسی توسط لاگ‌های ممیزی غیرقابل تغییر با شناسه‌های کاربری و زمان‌ها ثبت می‌شود.
 #4.4.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اسرار از طریق Kubernetes secrets، حجم‌های نصب شده یا init containers تزریق می‌شوند و مطمئن شوید که اسرار هرگز در متغیرهای محیطی یا تصاویر جاسازی نمی‌شوند.

---

### ایزوله سازی و اعتبارسنجی بار کاری هوش مصنوعی C4.5

مدل‌های هوش مصنوعی غیرقابل اعتماد را در محیط‌های امن ایزوله کنید و با تحلیل رفتاری جامع بررسی نمایید.

 #4.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مدل‌های هوش مصنوعی خارجی در gVisor، میکروVM‌ها (مانند Firecracker، CrossVM) یا کانتینرهای داکر با گزینه‌های --security-opt=no-new-privileges و --read-only اجرا می‌شوند.
 #4.5.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که محیط‌های سندباکس هیچ اتصال شبکه‌ای ندارند (--network=none) یا فقط به localhost دسترسی دارند و تمام درخواست‌های خارجی توسط قواعد iptables مسدود شده‌اند.
 #4.5.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اعتبارسنجی مدل هوش مصنوعی شامل آزمایش تیم قرمز خودکار با پوشش آزمون تعریف شده توسط سازمان و تحلیل رفتاری برای شناسایی درب پشتی است.
 #4.5.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که قبل از ارتقاء یک مدل هوش مصنوعی به مرحله تولید، نتایج آزمایشگاه کنترل شده آن توسط مسئولان امنیتی مجاز به صورت رمزنگاری‌شده امضا شده و در لاگ‌های حسابرسی غیرقابل تغییر ذخیره می‌شود.
 #4.5.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که محیط‌های سندباکس بین ارزیابی‌ها با تخریب و بازسازی از تصاویر گلدن با پاکسازی کامل سیستم فایل و حافظه بازنشانی می‌شوند.

---

### C4.6 نظارت بر امنیت زیرساخت

پایدار زیرساخت را با اصلاح خودکار و هشداردهی در زمان واقعی به صورت مداوم اسکن و نظارت کنید.

 #4.6.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تصاویر کانتینر بر اساس برنامه‌های سازمانی اسکن می‌شوند و آسیب‌پذیری‌های CRITICAL بر اساس آستانه‌های ریسک سازمانی، مانع از استقرار می‌شوند.
 #4.6.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که زیرساخت از معیارهای CIS Benchmarks یا کنترل‌های NIST 800-53 با آستانه‌های تطبیق تعریف‌شده سازمانی و اصلاح خودکار برای بررسی‌های ناموفق عبور کند.
 #4.6.3    سطح: 2    نقش: D/V
 تأیید کنید که آسیب‌پذیری‌های با شدت بالا مطابق با جدول زمانی مدیریت ریسک سازمانی وصله شده‌اند و برای CVEهای فعال که در حال بهره‌برداری هستند، رویه‌های اضطراری اعمال شده‌اند.
 #4.6.4    سطح: 2    نقش: V
 تأیید کنید که هشدارهای امنیتی با پلتفرم‌های SIEM (اسپلانک، الاستیک یا سنتینل) با استفاده از فرمت‌های CEF یا STIX/TAXII و با غنی‌سازی خودکار یکپارچه می‌شوند.
 #4.6.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که متریک‌های زیرساخت به سیستم‌های نظارتی (Prometheus، DataDog) با داشبوردهای SLA و گزارش‌دهی اجرایی صادر می‌شوند.
 #4.6.6    سطح: 2    نقش: D/V
 تأیید کنید که تغییر پیکربندی با استفاده از ابزارها (Chef InSpec، AWS Config) بر اساس الزامات نظارتی سازمان تشخیص داده می‌شود و بازگردانی خودکار برای تغییرات غیرمجاز انجام می‌گردد.

---

### مدیریت منابع زیرساخت هوش مصنوعی C4.7

جلوگیری از حملات از طریق تخلیه منابع و اطمینان از تخصیص عادلانه منابع از طریق سهمیه‌بندی و پایش.

 #4.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که استفاده از GPU/TPU با هشدارهایی که در آستانه‌های تعریف شده توسط سازمان فعال می‌شوند، نظارت می‌شود و مقیاس‌بندی خودکار یا تعادل بار بر اساس سیاست‌های مدیریت ظرفیت فعال شده است.
 #4.7.2    سطح: 1    نقش: D/V
 تائید کنید که معیارهای بار کاری هوش مصنوعی (تاخیر استنتاج، توان عملیاتی، نرخ خطاها) مطابق با الزامات نظارتی سازمانی جمع‌آوری شده و با استفاده از زیرساخت مرتبط شده‌اند.
 #4.7.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که Kubernetes ResourceQuotas یا معادل آن، بارهای کاری فردی را مطابق با سیاست‌های تخصیص منابع سازمانی محدود می‌کنند و محدودیت‌های سخت اعمال شده‌اند.
 #4.7.4    سطح: 2    نقش: V
 تأیید کنید که نظارت بر هزینه، هزینه‌ها را به ازای هر بار کاری/مستأجر پیگیری می‌کند با هشدارهایی بر اساس آستانه‌های بودجه سازمانی و کنترل‌های خودکار برای تجاوز از بودجه.
 #4.7.5    سطح: 3    نقش: V
 تأیید کنید که برنامه‌ریزی ظرفیت از داده‌های تاریخی با دوره‌های پیش‌بینی تعیین‌شده سازمانی و تأمین خودکار منابع بر اساس الگوهای تقاضا استفاده می‌کند.
 #4.7.6    سطح: 2    نقش: D/V
 تأیید کنید که تمام شدن منابع باعث فعال شدن مدار شکن‌ها بر اساس الزامات واکنش سازمانی می‌شود، از جمله محدودیت نرخ بر اساس سیاست‌های ظرفیت و ایزولاسیون بار کاری.

---

### C4.8 جداسازی محیط و کنترل‌های ارتقاء

اجرای مرزهای محیطی سخت‌گیرانه با دروازه‌های ارتقاء خودکار و اعتبارسنجی امنیتی.

 #4.8.1    سطح: 1    نقش: D/V
 تأیید کنید که محیط‌های توسعه/آزمایش/تولید در VPCها یا VNetهای جداگانه اجرا می‌شوند و هیچ نقش IAM مشترک، گروه‌های امنیتی، یا ارتباط شبکه‌ای مشترکی ندارند.
 #4.8.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که ترفیع محیط نیازمند تأیید از طرف افراد مجاز تعریف شده سازمانی با امضاهای رمزنگاری شده و سوابق حسابرسی غیرقابل تغییر است.
 #4.8.3    سطح: 2    نقش: D/V
 تأیید کنید که محیط‌های تولید دسترسی SSH را مسدود می‌کنند، نقاط پایانی اشکال‌زدایی را غیرفعال می‌کنند و درخواست‌های تغییر را با نیازمندی‌های اطلاع‌رسانی پیش از سازمان به جز موارد اضطراری می‌پذیرند.
 #4.8.4    سطح: 2    نقش: D/V
 تأیید کنید که تغییرات زیرساخت به‌عنوان‌کد نیازمند بازبینی همتا با آزمایش خودکار و اسکن امنیتی قبل از ادغام به شاخه اصلی باشند.
 #4.8.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که داده‌های غیرتولیدی مطابق با الزامات حریم خصوصی سازمان، تولید داده‌های مصنوعی یا پنهان‌سازی کامل داده‌ها با حذف اطلاعات شناسایی شخصی (PII) ناشناس‌سازی شده‌اند.
 #4.8.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که دروازه‌های ترفیع شامل تست‌های امنیتی خودکار (SAST، DAST، اسکن کانتینر) هستند و برای تایید، هیچ یافته بحرانی (CRITICAL) وجود نداشته باشد.

---

### پشتیبان‌گیری و بازیابی زیرساخت C4.9

تضمین انعطاف‌پذیری زیرساخت از طریق پشتیبان‌گیری خودکار، آزمایش روش‌های بازیابی و قابلیت‌های بازیابی در شرایط بحرانی.

 #4.9.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که پیکربندی‌های زیرساخت طبق برنامه‌های پشتیبان‌گیری سازمانی به مناطق جغرافیایی جداگانه پشتیبان‌گیری شده‌اند با اجرای استراتژی پشتیبان‌گیری 3-2-1.
 #4.9.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های پشتیبان‌گیری در شبکه‌های ایزوله با اعتبارنامه‌های جداگانه و ذخیره‌سازی ایربَند برای محافظت در برابر باج‌افزار اجرا می‌شوند.
 #4.9.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که رویه‌های بازیابی از طریق آزمایش خودکار مطابق با برنامه‌های سازمانی با اهداف RTO و RPO که مطابق با الزامات سازمانی هستند، آزمایش و تایید شده‌اند.
 #4.9.4    سطح: 3    نقش: V
 تأیید کنید که بازیابی فاجعه شامل دفترچه‌های راهنمای مخصوص هوش مصنوعی با بازگردانی وزن مدل، بازسازی کلاستر GPU و نقشه‌برداری وابستگی سرویس‌ها باشد.

---

### C4.10 انطباق زیرساخت و حاکمیت

رعایت انطباق مقررات از طریق ارزیابی مداوم، مستندسازی، و کنترل‌های خودکار را حفظ کنید.

 #4.10.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تطابق زیرساخت طبق برنامه‌های سازمانی بر اساس کنترل‌های SOC 2، ISO 27001 یا FedRAMP با جمع‌آوری خودکار شواهد ارزیابی می‌شود.
 #4.10.2    سطح: 2    نقش: V
 اطمینان حاصل کنید که مستندات زیرساخت شامل نمودارهای شبکه، نقشه‌های جریان داده و مدل‌های تهدید به‌روزرسانی شده مطابق با الزامات مدیریت تغییر سازمانی باشد.
 #4.10.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تغییرات زیرساختی از طریق ارزیابی خودکار تأثیر انطباق و فرآیندهای تصویب مقررات برای اصلاحات پرخطر عبور می‌کنند.

---

### C4.11 امنیت سخت‌افزار هوش مصنوعی

قطعات سخت‌افزاری خاص هوش مصنوعی از جمله GPUها، TPUها، و شتاب‌دهنده‌های تخصصی هوش مصنوعی را ایمن کنید.

 #4.11.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فریمور شتاب‌دهنده هوش مصنوعی (BIOS کارت گرافیک، فریمور TPU) با امضاهای رمزنگاری شده تأیید شده و مطابق با زمان‌بندی‌های مدیریت وصله سازمان به‌روزرسانی می‌شود.
 #4.11.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که پیش از اجرای بار کاری، صحت شتاب‌دهنده هوش مصنوعی از طریق تأیید سخت‌افزاری با استفاده از TPM 2.0، Intel TXT، یا AMD SVM اعتبارسنجی شده است.
 #4.11.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که حافظه GPU بین بارهای کاری با استفاده از SR-IOV، MIG (GPU چند نمونه‌ای) یا تقسیم‌بندی سخت‌افزاری معادل با پاکسازی حافظه بین وظایف ایزوله شده باشد.
 #4.11.4    سطح: 3    نقش: V
 تأیید کنید که زنجیره تأمین سخت‌افزار هوش مصنوعی شامل تأیید اصالت با گواهی‌های تولیدکننده و اعتبارسنجی بسته‌بندی ضد دستکاری باشد.
 #4.11.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که ماژول‌های امنیت سخت‌افزاری (HSM) وزن‌های مدل AI و کلیدهای رمزنگاری را با گواهی FIPS 140-2 سطح 3 یا معیار مشترک EAL4+ محافظت می‌کنند.

---

### زیرساخت هوش مصنوعی لبه‌ای و توزیع‌شده C4.12

استقرار ایمن هوش مصنوعی توزیع‌شده شامل رایانش لبه، یادگیری فدرال و معماری‌های چندسایتی.

 #4.12.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که دستگاه‌های Edge AI با استفاده از TLS متقابل و با گواهی‌نامه‌های دستگاهی که مطابق با سیاست مدیریت گواهی سازمانی چرخش داده می‌شوند، به زیرساخت مرکزی احراز هویت می‌کنند.
 #4.12.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که دستگاه‌های لبه‌ای بوت امن را با امضاهای تأیید شده و حفاظت در برابر بازگشت نسخه اجرا می‌کنند تا از حملات کاهش نسخه فرم‌ویر جلوگیری شود.
 #4.12.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که هماهنگی هوش مصنوعی توزیع‌شده از الگوریتم‌های اجماع تحمل‌پذیر خطای بیزانسی با اعتبارسنجی شرکت‌کنندگان و شناسایی گره‌های مخرب استفاده می‌کند.
 #4.12.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که ارتباط لبه به ابر شامل محدودیت پهنای باند، فشرده‌سازی داده‌ها و قابلیت‌های عملیات آفلاین با ذخیره‌سازی ایمن محلی است.

---

### C4.13 امنیت زیرساخت چندابری و ترکیبی

بارهای کاری هوش مصنوعی را در چندین ارائه‌دهنده خدمات ابری و استقرارهای ترکیبی ابری-محلی ایمن کنید.

 #4.13.1    سطح: 2    نقش: D/V
 تأیید کنید که استقرارهای چند ابری هوش مصنوعی از فدراسیون هویت مستقل از ابر (OIDC، SAML) با مدیریت سیاست متمرکز در بین ارائه‌دهندگان استفاده می‌کنند.
 #4.13.2    سطح: 2    نقش: D/V
 تأیید کنید که انتقال داده‌های بین ابرها از رمزگذاری انتها به انتها با کلیدهای مدیریت‌شده توسط مشتری و کنترل‌های محل اقامت داده‌ها که بر اساس حوزه قضایی اعمال می‌شوند، استفاده می‌کند.
 #4.13.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که بارهای کاری هوش مصنوعی در ابر هیبریدی سیاست‌های امنیتی سازگاری را در محیط‌های در محل و ابری با نظارت و هشداردهی یکپارچه اجرا می‌کنند.
 #4.13.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که پیشگیری از قفل شدن به فروشنده ابر شامل زیرساخت قابل حمل به صورت کد (infrastructure-as-code)، APIهای استاندارد و قابلیت‌های صادرات داده با ابزارهای تبدیل فرمت می‌باشد.
 #4.13.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که بهینه‌سازی هزینه چندابری شامل کنترل‌های امنیتی جلوگیری از پراکندگی منابع و همچنین هزینه‌های انتقال داده غیرمجاز بین ابرها است.

---

### C4.14 امنیت خودکارسازی زیرساخت و GitOps

ایجاد خطوط لوله خودکار ایمن زیرساخت و جریان‌های کاری GitOps برای مدیریت زیرساخت هوش مصنوعی.

 #4.14.1    سطح: 2    نقش: D/V
 تأیید کنید که مخازن GitOps نیازمند کامیت‌های امضاشده با کلیدهای GPG و قوانین حفاظت از شاخه هستند که مانع از انجام مستقیم push به شاخه‌های اصلی می‌شوند.
 #4.14.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اتوماسیون زیرساخت شامل تشخیص انحراف با قابلیت‌های خودکار اصلاح و بازگردانی است که بر اساس الزامات پاسخ سازمانی برای تغییرات غیرمجاز فعال می‌شود.
 #4.14.3    سطح: 2    نقش: D/V
 تأیید کنید که فراهم‌آوری خودکار زیرساخت شامل اعتبارسنجی سیاست امنیتی با مسدودسازی استقرار برای پیکربندی‌های غیرسازگار باشد.
 #4.14.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اسرار خودکارسازی زیرساخت از طریق اپراتورهای اسرار خارجی (External Secrets Operator، Bank-Vaults) با چرخش خودکار مدیریت می‌شوند.
 #4.14.5    سطح: 3    نقش: V
 تأیید کنید که زیرساخت خودترمیم شامل همبستگی رویدادهای امنیتی همراه با پاسخ خودکار به حادثه و گردش‌کار اعلان به ذینفعان باشد.

---

### C4.15 امنیت زیرساخت مقاوم در برابر کوانتومی

آماده‌سازی زیرساخت هوش مصنوعی برای تهدیدات محاسبات کوانتومی از طریق رمزنگاری پساکوانتومی و پروتکل‌های کوانتومی امن.

 #4.15.1    سطح: 3    نقش: D/V
 تأیید کنید که زیرساخت هوش مصنوعی الگوریتم‌های رمزنگاری پساکوانتومی تأییدشده توسط NIST (CRYSTALS-Kyber، CRYSTALS-Dilithium، SPHINCS+) را برای تبادل کلید و امضاهای دیجیتال پیاده‌سازی کرده باشد.
 #4.15.2    سطح: 3    نقش: D/V
 بررسی کنید که سیستم‌های توزیع کلید کوانتومی (QKD) برای ارتباطات هوش مصنوعی با امنیت بالا با پروتکل‌های مدیریت کلید مقاوم در برابر کوانتوم پیاده‌سازی شده‌اند.
 #4.15.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که چارچوب‌های چابکی رمزنگاری امکان مهاجرت سریع به الگوریتم‌های جدید پساکوانتومی را با گردش خودکار گواهی و کلید فراهم می‌کنند.
 #4.15.4    سطح: 3    نقش: V
 تأیید کنید که مدل‌سازی تهدید کوانتومی آسیب‌پذیری زیرساخت هوش مصنوعی در برابر حملات کوانتومی را با زمان‌بندی‌های مستند مهاجرت و ارزیابی‌های ریسک بررسی می‌کند.
 #4.15.5    سطح: 3    نقش: D/V
 تایید کنید که سیستم‌های رمزنگاری ترکیبی کلاسیک-کوانتومی در دوره انتقال کوانتومی با نظارت بر عملکرد، حفاظت در عمق را فراهم می‌کنند.

---

### C4.16 محاسبات محرمانه و محفظه‌های امن

محافظت از بارهای کاری هوش مصنوعی و وزن‌های مدل با استفاده از محیط‌های اجرای مورد اعتماد مبتنی بر سخت‌افزار و فناوری‌های محاسبات محرمانه.

 #4.16.1    سطح: 3    نقش: D/V
 تأیید کنید که مدل‌های حساس هوش مصنوعی در محفظه‌های Intel SGX، AMD SEV-SNP، یا ARM TrustZone با حافظه رمزگذاری شده و تأیید صحت اجرا شوند.
 #4.16.2    سطح: 3    نقش: D/V
 تأیید کنید که کانتینرهای محرمانه (Kata Containers، gVisor با محاسبات محرمانه) بارهای کاری هوش مصنوعی را با استفاده از رمزگذاری حافظه اعمال‌شده توسط سخت‌افزار ایزوله می‌کنند.
 #4.16.3    سطح: 3    نقش: D/V
 تأیید کنید که تأیید از راه دور صحت انکلیو را قبل از بارگذاری مدل‌های هوش مصنوعی با اثبات رمزنگاری شده از اصالت محیط اجرای آن، اعتبارسنجی می‌کند.
 #4.16.4    سطح: 3    نقش: D/V
 تأیید کنید که خدمات استنتاج هوش مصنوعی محرمانه از استخراج مدل از طریق محاسبات رمزگذاری شده با وزن‌های مدل مهروموم‌شده و اجرای محافظت‌شده جلوگیری می‌کنند.
 #4.16.5    سطح: 3    نقش: D/V
 تأیید کنید که ارکستراسیون محیط اجرای مورد اعتماد چرخه عمر انکلب امن را با استفاده از تایید از راه دور و کانال‌های ارتباطی رمزگذاری‌شده مدیریت می‌کند.
 #4.16.6    سطح: 3    نقش: D/V
 تأیید کنید که محاسبات چندجانبه امن (SMPC) امکان آموزش مشترک هوش مصنوعی را بدون افشای مجموعه داده‌ها یا پارامترهای مدل فردی فراهم می‌کند.

---

### C4.17 زیرساخت دانش صفر

سیستم‌های اثبات دانش صفر را برای تأیید و احراز هویت هوش مصنوعی با حفظ حریم خصوصی و بدون افشای اطلاعات حساس پیاده‌سازی کنید.

 #4.17.1    سطح: 3    نقش: D/V
 بررسی کنید که اثبات‌های دانش صفر (ZK-SNARKs، ZK-STARKs) صحت مدل هوش مصنوعی و منشا آموزش را بدون افشای وزن‌های مدل یا داده‌های آموزشی تأیید می‌کنند.
 #4.17.2    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های احراز هویت مبتنی بر ZK امکان احراز هویت کاربران به‌صورت حفظ حریم خصوصی برای خدمات هوش مصنوعی را فراهم می‌کنند بدون اینکه اطلاعات مرتبط با هویت فاش شود.
 #4.17.3    سطح: 3    نقش: D/V
 تأیید کنید که پروتکل‌های تقاطع مجموعه خصوصی (PSI) امکان تطبیق داده‌های امن برای هوش مصنوعی فدرال را بدون افشای مجموعه داده‌های فردی فراهم می‌کنند.
 #4.17.4    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های یادگیری ماشین با دانش صفر (ZKML) استنتاج‌های هوش مصنوعی قابل تأیید را با اثبات رمزنگاری شده از صحت محاسبه امکان‌پذیر می‌سازند.
 #4.17.5    سطح: 3    نقش: D/V
 تأیید کنید که ZK-rollups پردازش تراکنش‌های هوش مصنوعی مقیاس‌پذیر و حفظ حریم خصوصی را با تأیید دسته‌ای و کاهش بار محاسباتی فراهم می‌کنند.

---

### C4.18 پیشگیری از حملات کانال جانبی

حفاظت از زیرساخت هوش مصنوعی در برابر حملات کانال جانبی مبتنی بر زمان، توان، الکترومغناطیسی و حافظه نهان که می‌توانند اطلاعات حساس را نشت دهند.

 #4.18.1    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که زمان‌بندی استنتاج هوش مصنوعی با استفاده از الگوریتم‌های زمان‌ثابت و پرکردن (padding) نرمال‌سازی شده است تا از حملات استخراج مدل مبتنی بر زمان جلوگیری شود.
 #4.18.2    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که حفاظت از تحلیل توان شامل تزریق نویز، فیلترینگ خط توان و الگوهای اجرای تصادفی برای سخت‌افزار هوش مصنوعی باشد.
 #4.18.3    سطح: 3    نقش: D/V
 تأیید کنید که کاهش ریسک کانال جانبی مبتنی بر حافظه پنهان از تقسیم‌بندی حافظه پنهان، تصادفی‌سازی و دستورات پاک‌سازی برای جلوگیری از نشت اطلاعات استفاده می‌کند.
 #4.18.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که حفاظت در برابر تابش الکترومغناطیسی شامل شیلدینگ، فیلتراسیون سیگنال و پردازش تصادفی برای جلوگیری از حملات نوع TEMPEST است.
 #4.18.5    سطح: 3    نقش: D/V
 تأیید کنید که دفاع‌های کانال جانبی ریزمعماری شامل کنترل‌های اجرای احتمالی و مبهم‌سازی الگوی دسترسی به حافظه هستند.

---

### C4.19 امنیت سخت‌افزار نورومورفیک و هوش مصنوعی تخصصی

معماری‌های سخت‌افزاری نوظهور هوش مصنوعی شامل تراشه‌های نورومورفیک، FPGAها، ASICهای سفارشی و سیستم‌های محاسبات نوری را ایمن کنید.

 #4.19.1    سطح: 3    نقش: D/V
 تأیید کنید که امنیت تراشه نورومورفیک شامل رمزنگاری الگوهای اسپایک، حفاظت وزن‌های سیناپسی، و اعتبارسنجی قوانین یادگیری مبتنی بر سخت‌افزار است.
 #4.19.2    سطح: 3    نقش: D/V
 تأیید کنید که شتاب‌دهنده‌های مبتنی بر FPGA در پردازش هوش مصنوعی از رمزنگاری بیت‌استریم، مکانیزم‌های ضد دستکاری، و بارگذاری پیکربندی امن با به‌روزرسانی‌های احراز هویت شده استفاده می‌کنند.
 #4.19.3    سطح: 3    نقش: D/V
 تأیید کنید که امنیت ASIC سفارشی شامل پردازنده‌های امنیتی روی تراشه، ریشه اعتماد سخت‌افزاری و ذخیره‌سازی کلید ایمن با تشخیص دستکاری باشد.
 #4.19.4    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های محاسبات نوری، رمزنگاری نوری ایمن در برابر کوانتوم، سوئیچینگ فوتونیکی امن، و پردازش سیگنال نوری محافظت‌شده را پیاده‌سازی می‌کنند.
 #4.19.5    سطح: 3    نقش: D/V
 تأیید کنید که تراشه‌های هوش مصنوعی هیبریدی آنالوگ-دیجیتال شامل محاسبات امن آنالوگ، ذخیره وزن محافظت‌شده و تبدیل آنالوگ به دیجیتال تأیید شده باشند.

---

### زیرساخت محاسبات حفظ حریم خصوصی C4.20

پیاده‌سازی کنترل‌های زیرساختی برای محاسبات حفظ حریم خصوصی به منظور محافظت از داده‌های حساس در حین پردازش و تحلیل هوش مصنوعی.

 #4.20.1    سطح: 3    نقش: D/V
 تأیید کنید که زیرساخت رمزنگاری همومورفیک امکان انجام محاسبات رمزنگاری‌شده روی بارهای کاری حساس هوش مصنوعی را با تأیید صحت رمزنگاری و نظارت بر عملکرد فراهم می‌کند.
 #4.20.2    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های بازیابی اطلاعات خصوصی امکان انجام جستجوهای پایگاه داده را بدون افشای الگوهای جستجو فراهم می‌کنند، همراه با محافظت رمزنگاری شده از الگوهای دسترسی.
 #4.20.3    سطح: 3    نقش: D/V
 تأیید کنید که پروتکل‌های محاسبات چندجانبه امن امکان انجام استنتاج هوش مصنوعی با حفظ حریم خصوصی را بدون افشای ورودی‌های فردی یا محاسبات میانی فراهم می‌کنند.
 #4.20.4    سطح: 3    نقش: D/V
 بررسی کنید که مدیریت کلید حفظ حریم خصوصی شامل تولید کلید توزیع شده، رمزنگاری آستانه‌ای و چرخش امن کلید با حفاظت پشتیبانی شده توسط سخت‌افزار باشد.
 #4.20.5    سطح: 3    نقش: D/V
 تأیید کنید که عملکرد محاسبات حفظ حریم خصوصی از طریق دسته‌بندی، ذخیره‌سازی موقت و تسریع سخت‌افزاری بهینه شده است در حالی که تضمین‌های امنیت رمزنگاری حفظ می‌شود.

---

### چارچوب عامل C4.15 امنیت یکپارچه‌سازی ابری و استقرار هیبریدی

کنترل‌های امنیتی برای چارچوب‌های عامل یکپارچه با فضای ابری در معماری‌های ترکیبی محلی/ابری.

 #4.15.1    سطح: 1    نقش: D/V
 تأیید کنید که ادغام ذخیره‌سازی ابری از رمزگذاری انتها به انتها با مدیریت کلید کنترل شده توسط عامل استفاده می‌کند.
 #4.15.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مرزهای امنیتی استقرار ترکیبی به وضوح تعریف شده‌اند و کانال‌های ارتباطی رمزگذاری شده هستند.
 #4.15.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که دسترسی به منابع ابری شامل صحت‌سنجی صفر-اعتمادی با احراز هویت مداوم است.
 #4.15.4    سطح: 3    نقش: D/V
 تأیید کنید که الزامات اقامت داده‌ها از طریق تصدیق رمزنگاری مکان‌های ذخیره‌سازی اعمال می‌شوند.
 #4.15.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که ارزیابی‌های امنیتی ارائه‌دهنده خدمات ابری شامل مدل‌سازی تهدیدات خاص عامل و ارزیابی ریسک است.

---

### مراجع

NIST Cybersecurity Framework 2.0
CIS Controls v8
OWASP Container Security Verification Standard
Kubernetes Security Best Practices
SLSA Supply Chain Security Framework
NIST SP 800-190: Application Container Security Guide
Cloud Security Alliance: Cloud Controls Matrix
ENISA: Secure Infrastructure Design
NIST SP 800-53: Security Controls for Federal Information Systems
ISO 27001:2022 Information Security Management
NIST AI Risk Management Framework
CIS Kubernetes Benchmark
FIPS 140-2 Security Requirements
NIST SP 800-207: Zero Trust Architecture
IEEE 2857: Privacy Engineering for AI Systems
NIST SP 800-161: Cybersecurity Supply Chain Risk Management
NIST Post-Quantum Cryptography Standards
Intel SGX Developer Guide
AMD SEV-SNP White Paper
ARM TrustZone Technology
ZK-SNARKs: A Gentle Introduction
NIST SP 800-57: Cryptographic Key Management
Side-Channel Attack Countermeasures
Neuromorphic Computing Security Challenges
FPGA Security: Fundamentals, Evaluation, and Countermeasures
Microsoft SEAL: Homomorphic Encryption Library
HElib: Homomorphic Encryption Library
PALISADE Lattice Cryptography Library
Differential Privacy: A Survey of Results
Secure Aggregation for Federated Learning
Private Information Retrieval: Concepts and Constructions

## کنترل دسترسی C5 و هویت برای مؤلفه‌ها و کاربران هوش مصنوعی

### هدف کنترل

کنترل دسترسی موثر برای سیستم‌های هوش مصنوعی نیازمند مدیریت هویت قوی، مجوزدهی مبتنی بر زمینه و اعمال در زمان اجرا بر اساس اصول اعتماد صفر است. این کنترل‌ها تضمین می‌کنند که انسان‌ها، سرویس‌ها و عامل‌های خودمختار فقط در محدوده‌هایی که صراحتاً اعطا شده‌اند با مدل‌ها، داده‌ها و منابع محاسباتی تعامل داشته باشند، همراه با قابلیت‌های تأیید مستمر و حسابرسی.

---

### C5.1 مدیریت هویت و احراز هویت

شناسایی‌های مبتنی بر رمزنگاری را برای همه موجودیت‌ها با استفاده از تأیید هویت چندعاملی برای عملیات ممتاز برقرار کنید.

 #5.1.1    سطح: 1    نقش: D/V
 تأیید کنید که همه کاربران انسانی و اصول‌گرایان خدماتی از طریق یک ارائه‌دهنده هویت سازمانی متمرکز (IdP) با استفاده از پروتکل‌های OIDC/SAML احراز هویت می‌کنند و نگاشت‌های منحصر به فرد هویت به توکن دارند (بدون حساب‌ها یا مدارک مشترک).
 #5.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که عملیات با ریسک بالا (استقرار مدل، صادرات وزن، دسترسی به داده‌های آموزشی، تغییرات پیکربندی تولید) نیازمند احراز هویت چند عاملی یا احراز هویت پله‌ای همراه با بازتأیید جلسه است.
 #5.1.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که مدیران جدید قبل از دریافت دسترسی به سیستم تولید، از فرآیند اثبات هویت مطابق با استانداردهای NIST 800-63-3 IAL-2 یا استانداردهای معادل آن عبور کنند.
 #5.1.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که بازبینی‌های دسترسی به صورت فصلی انجام می‌شود و شامل شناسایی خودکار حساب‌های غیرفعال، اجرای چرخش اعتبارنامه‌ها و فرآیندهای حذف دسترسی است.
 #5.1.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که عوامل هوش مصنوعی فدرال از طریق ادعاهای JWT امضا شده که حداکثر عمر آنها 24 ساعت است و شامل اثبات رمزنگاری شده منشأ می‌باشند، احراز هویت می‌کنند.

---

### C5.2 مجوز دسترسی به منابع و حداقل امتیاز لازم

پیاده‌سازی کنترل‌های دسترسی دقیق برای تمام منابع هوش مصنوعی با مدل‌های اجازه صریح و ردهای ممیزی.

 #5.2.1    سطح: 1    نقش: D/V
 تأیید کنید که هر منبع هوش مصنوعی (مجموعه داده‌ها، مدل‌ها، نقطه‌های انتهایی، مجموعه‌های برداری، شاخص‌های تعبیه شده، نمونه‌های محاسباتی) کنترل‌های دسترسی مبتنی بر نقش را با فهرست‌های اجازه صریح و سیاست‌های پیش‌فرض جلوگیری اعمال می‌کند.
 #5.2.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که اصول حداقل امتیاز به طور پیش‌فرض برای حساب‌های سرویس اجرا می‌شود، به‌طوری که از دسترسی فقط‌خواندنی شروع شده و مستندات توجیه تجاری برای دسترسی نوشتن مورد نیاز باشد.
 #5.2.3    سطح: 1    نقش: V
 تأیید کنید که تمامی تغییرات کنترل دسترسی به درخواست‌های تغییر تأیید شده مرتبط باشند و به صورت غیرقابل تغییر با زمان‌بندی‌ها، شناسه‌های عامل، شناسه‌های منابع و اختلاف‌های دسترسی، ثبت شده باشند.
 #5.2.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که برچسب‌های طبقه‌بندی داده‌ها (PII, PHI, کنترل‌شده برای صادرات، مالکیتی) به‌صورت خودکار به منابع مشتق‌شده (تعبیه‌ها، حافظه‌های کش درخواست، خروجی‌های مدل) منتقل می‌شوند و اعمال سیاست به‌صورت یکنواخت انجام می‌شود.
 #5.2.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تلاش‌های دسترسی غیرمجاز و رویدادهای افزایش سطح دسترسی، هشدارهای هم‌زمان با متادیتای زمینه‌ای به سیستم‌های SIEM در عرض ۵ دقیقه ارسال می‌کنند.

---

### C5.3 ارزیابی سیاست پویا

پیاده‌سازی موتورهای کنترل دسترسی مبتنی بر ویژگی (ABAC) برای تصمیم‌گیری‌های مجوزدهی آگاه از زمینه با قابلیت‌های حسابرسی.

 #5.3.1    سطح: 1    نقش: D/V
 تأیید کنید که تصمیمات مجوزدهی به یک موتور سیاست اختصاصی (OPA، Cedar، یا معادل آن) برون‌سپاری شده‌اند که از طریق APIهای احراز هویت شده با حفاظت یکپارچگی رمزنگاری‌شده قابل دسترسی باشد.
 #5.3.2    سطح: 1    نقش: D/V
 تأیید کنید که سیاست‌ها در زمان اجرا ویژگی‌های پویا را ارزیابی می‌کنند، از جمله سطح دسترسی کاربر، طبقه‌بندی حساسیت منبع، زمینه درخواست، جداسازی مستأجر و محدودیت‌های زمانی.
 #5.3.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که تعریف‌های سیاست‌ها کنترل نسخه شده، بازبینی توسط همتا انجام شده و از طریق تست‌های خودکار در خطوط CI/CD قبل از استقرار در محیط تولید تأیید شده‌اند.
 #5.3.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که نتایج ارزیابی سیاست شامل دلایل منطقی تصمیم‌گیری ساختاریافته باشد و برای تحلیل همبستگی و گزارش‌دهی تطابق به سیستم‌های SIEM ارسال شود.
 #5.3.5    سطح: 3    نقش: D/V
 تأیید کنید که مقادیر زمان زندگی (TTL) کش سیاست برای منابع با حساسیت بالا از ۵ دقیقه و برای منابع استاندارد با قابلیت‌های باطل‌سازی کش از ۱ ساعت تجاوز نکند.

---

### C5.4 اجرای امنیت در زمان پرس‌وجو

اجرای کنترل‌های امنیتی در لایه پایگاه داده با فیلترینگ اجباری و سیاست‌های امنیتی در سطح ردیف.

 #5.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که همه پرس‌وجوهای پایگاه داده برداری و SQL شامل فیلترهای امنیتی اجباری (شناسه مستاجر، برچسب‌های حساسیت، حوزه کاربر) هستند که در سطح موتور پایگاه داده اعمال می‌شوند، نه کد برنامه.
 #5.4.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیاست‌های امنیت سطح سطر (RLS) و ماسک‌گذاری سطح فیلد با ارث‌بری سیاست برای همه پایگاه‌های داده برداری، شاخص‌های جستجو و مجموعه‌داده‌های آموزشی فعال شده‌اند.
 #5.4.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که ارزیابی‌های ناموفق مجوز، از حملات "معاون سردرگم" با قطع فوری پرس‌وجوها و بازگرداندن کدهای خطای مجوز صریح به جای بازگرداندن مجموعه نتایج خالی، جلوگیری می‌کنند.
 #5.4.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که تأخیر ارزیابی سیاست به‌طور مستمر با هشدارهای خودکار برای شرایط تایم‌اوت که ممکن است باعث دورزدن مجوزها شود، پایش می‌شود.
 #5.4.5    سطح: 3    نقش: D/V
 تأیید کنید که مکانیزم‌های تلاش مجدد درخواست، سیاست‌های مجوزدهی را مجدداً ارزیابی می‌کنند تا تغییرات پویا در دسترسی‌ها را در جلسات فعال کاربر در نظر بگیرند.

---

### فیلتر خروجی C5.5 و جلوگیری از از دست دادن داده‌ها

استقرار کنترل‌های پس‌پردازش برای جلوگیری از افشای غیرمجاز داده‌ها در محتوای تولیدشده توسط هوش مصنوعی.

 #5.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های فیلترینگ پس از استنتاج، اطلاعات شناسایی شخصی غیرمجاز (PII)، اطلاعات طبقه‌بندی‌شده و داده‌های مالکیتی را قبل از تحویل محتوا به درخواست‌کنندگان، اسکن و حذف می‌کنند.
 #5.5.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که استنادات، مراجعات و نسبت‌های منبع در خروجی‌های مدل بر اساس مجوزهای فراخواننده اعتبارسنجی شده و در صورت شناسایی دسترسی غیرمجاز حذف شوند.
 #5.5.3    سطح: 2    نقش: D
 تأیید کنید که محدودیت‌های فرمت خروجی (PDFهای پاک‌سازی شده، تصاویر بدون فراداده، انواع فایل‌های تأیید شده) بر اساس سطوح اجازه کاربران و طبقه‌بندی داده‌ها اعمال می‌شوند.
 #5.5.4    سطح: 2    نقش: V
 تأیید کنید که الگوریتم‌های مخفی‌سازی تعیین‌پذیر، کنترل‌شده با نسخه، و دارای سابقه‌های حسابرسی هستند تا از تحقیقات انطباق و تحلیل‌های جرم‌شناسی پشتیبانی کنند.
 #5.5.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که رویدادهای حذف اطلاعات با ریسک بالا، گزارش‌های تطبیقی تولید می‌کنند که شامل هش‌های رمزنگاری‌شده از محتوای اصلی برای بازیابی قانونی بدون افشای داده‌ها باشد.

---

### C5.6 ایزولاسیون چند مستاجری

اطمینان از جداسازی رمزنگاری و منطقی بین مستاجران در زیرساخت مشترک هوش مصنوعی.

 #5.6.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که فضای حافظه، فروشگاه‌های جاسازی، داده‌های کش و فایل‌های موقت به صورت جداگانه برای هر مستأجر (tenant) تفکیک شده‌اند و پاک‌سازی ایمن هنگام حذف مستأجر یا پایان جلسه انجام می‌شود.
 #5.6.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر درخواست API شامل یک شناسه مستاجر تایید شده است که به صورت رمزنگاری شده در برابر زمینه جلسه و مجوزهای کاربر اعتبارسنجی می‌شود.
 #5.6.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که سیاست‌های شبکه قوانین پیش‌فرض انکار را برای ارتباطات بین مستاجران در داخل سرویس مش‌ها و پلتفرم‌های ارکستراسیون کانتینرها پیاده‌سازی می‌کنند.
 #5.6.4    سطح: 3    نقش: D
 تأیید کنید که کلیدهای رمزنگاری برای هر مستأجر منحصر به فرد باشند، با پشتیبانی از کلید مدیریت شده توسط مشتری (CMK) و جداسازی رمزنگاری بین مخازن داده‌های مستأجر.

---

### C5.7 مجوز عامل خودمختار

کنترل مجوزها برای عوامل هوش مصنوعی و سیستم‌های خودران از طریق توکن‌های قابلیت با دامنه محدود و مجوزدهی پیوسته.

 #5.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که عامل‌های خودران توکن‌های قابلیت محدوده‌بندی شده دریافت می‌کنند که به‌طور صریح اقدامات مجاز، منابع قابل دسترسی، محدوده‌های زمانی و محدودیت‌های عملیاتی را فهرست می‌کند.
 #5.7.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که قابلیت‌های پرخطر (دسترسی به سیستم فایل، اجرای کد، تماس‌های API خارجی، تراکنش‌های مالی) به طور پیش‌فرض غیرفعال شده‌اند و برای فعال‌سازی نیازمند مجوزهای صریح همراه با توجیهات کسب‌وکاری هستند.
 #5.7.3    سطح: 2    نقش: D
 تأیید کنید که توکن‌های قابلیت به نشست‌های کاربری متصل شده‌اند، حفاظت از صحت رمزنگاری را شامل می‌شوند و اطمینان حاصل کنید که نمی‌توانند در سناریوهای آفلاین ذخیره یا مجدداً استفاده شوند.
 #5.7.4    سطح: 2    نقش: V
 تأیید کنید که اقدامات آغاز شده توسط عامل از طریق موتور سیاست ABAC با ارزیابی کامل زمینه و ثبت گزارش حسابرسی، مجوز ثانویه دریافت می‌کنند.
 #5.7.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که شرایط خطای عامل و مدیریت استثنا شامل اطلاعات دامنه قابلیت برای پشتیبانی از تحلیل حادثه و تحقیقات جنایی باشد.

---

### مراجع

#### استانداردها و چهارچوب‌ها

NIST SP 800-63-3: Digital Identity Guidelines
Zero Trust Architecture – NIST SP 800-207
OWASP Application Security Verification Standard (AISVS)
​
#### راهنمای پیاده‌سازی

Identity and Access Management in the AI Era: 2025 Guide – IDSA
Attribute-Based Access Control with OPA – Permify
How We Designed Cedar to Be Intuitive, Fast, and Safe – AWS
​
#### امنیت مخصوص هوش مصنوعی

Row Level Security in Vector DBs for RAG – Bluetuple.ai
Tenant Isolation in Multi-Tenant Systems – WorkOS
Handling AI Agent Permissions – Stytch
OWASP Top 10 for Large Language Model Applications

## امنیت زنجیره تأمین C6 برای مدل‌ها، چارچوب‌ها و داده‌ها

### هدف کنترل

حملات زنجیره تأمین هوش مصنوعی از مدل‌ها، چارچوب‌ها یا مجموعه داده‌های شخص ثالث سوء استفاده می‌کنند تا درهای پشتی، تعصب یا کد قابل بهره‌برداری را جاسازی کنند. این کنترل‌ها شفافیت کامل منبع، مدیریت آسیب‌پذیری و نظارت را فراهم می‌کنند تا از کل چرخه عمر مدل محافظت شود.

---

### C6.1 بررسی و اصالت مدل‌های از پیش آموزش‌دیده‌شده

قبل از هرگونه تنظیم دقیق یا استقرار، منشاء، مجوزها و رفتارهای پنهان مدل‌های شخص ثالث را ارزیابی و تأیید کنید.

 #6.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر اثر مدل شخص ثالث شامل یک رکورد اصالت امضا شده باشد که مخزن منبع و هش کامیت را شناسایی می‌کند.
 #6.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مدل‌ها قبل از وارد کردن، با استفاده از ابزارهای خودکار برای لایه‌های مخرب یا محرک‌های تروجان بررسی می‌شوند.
 #6.1.3    سطح: 2    نقش: D
 تأیید کنید که آموزش مجدد با انتقال یادگیری، ارزیابی ضد حمله را پشت سر می‌گذارد تا رفتارهای پنهان را شناسایی کند.
 #6.1.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که مجوزهای مدل، برچسب‌های کنترل صادرات، و بیانیه‌های منبع داده در یک ورودی ML-BOM ثبت شده‌اند.
 #6.1.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مدل‌های پرخطر (وزن‌های بارگذاری شده به صورت عمومی، سازندگان تاییدنشده) تا زمان بررسی و تایید توسط انسان در قرنطینه باقی می‌مانند.

---

### اسکن چارچوب و کتابخانه C6.2

به‌طور مداوم چارچوب‌ها و کتابخانه‌های یادگیری ماشین را برای آسیب‌پذیری‌های امنیتی (CVE) و کدهای مخرب اسکن کنید تا پشته زمان اجرا را امن نگه دارید.

 #6.2.1    سطح: 1    نقش: D/V
 تأیید کنید که خطوط لوله CI اسکنرهای وابستگی را بر روی چارچوب‌های هوش مصنوعی و کتابخانه‌های حیاتی اجرا می‌کنند.
 #6.2.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که آسیب‌پذیری‌های بحرانی (CVSS ≥ 7.0) باعث جلوگیری از ارتقاء به تصاویر تولیدی می‌شوند.
 #6.2.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که تحلیل ایستا کد بر روی کتابخانه‌های ML تقسیم‌شده یا فروشنده انجام می‌شود.
 #6.2.4    سطح: 2    نقش: V
 تأیید کنید که پیشنهادهای ارتقاء چارچوب شامل ارزیابی تأثیر امنیتی با ارجاع به فیدهای عمومی CVE باشد.
 #6.2.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که حسگرهای زمان اجرا در صورت بارگذاری‌های غیرمنتظره کتابخانه‌های پویا که با SBOM امضا شده مطابقت ندارند، هشدار می‌دهند.

---

### C6.3 تثبیت و تأیید وابستگی‌ها

تمام وابستگی‌ها را به هش‌های غیرقابل تغییر قفل کنید و بازسازی‌های تولید را انجام دهید تا از تولید مصنوعات مشابه و بدون دستکاری اطمینان حاصل شود.

 #6.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که همه مدیران بسته نسخه‌بندی از طریق فایل‌های قفل را اعمال می‌کنند.
 #6.3.2    سطح: 1    نقش: D/V
 تأیید کنید که به جای برچسب‌های قابل تغییر، از چکیده‌های غیرقابل تغییر در ارجاعات کانتینر استفاده شده باشد.
 #6.3.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که بررسی‌های ساخت قابل‌تکرار، هش‌ها را در اجرای CI مقایسه می‌کنند تا خروجی‌های یکسان تضمین شوند.
 #6.3.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که تاییدیه‌های ساخت به مدت 18 ماه برای ردیابی ممیزی ذخیره می‌شوند.
 #6.3.5    سطح: 3    نقش: D
 تأیید کنید که وابستگی‌های منقضی شده، درخواست‌های کشش خودکار را برای به‌روزرسانی یا انشعاب نسخه‌های ثابت شده فعال می‌کنند.

---

### C6.4 اجرای منبع مورد اعتماد

دانلود آثار فقط از منابعی که توسط سازمان به صورت رمزنگاری شده تأیید شده‌اند مجاز است و همه موارد دیگر مسدود شود.

 #6.4.1    سطح: 1    نقش: D/V
 تأیید کنید که وزن‌های مدل، مجموعه‌داده‌ها و کانتینرها فقط از دامنه‌های مورد تایید یا رجیستری‌های داخلی دانلود می‌شوند.
 #6.4.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که امضاهای Sigstore/Cosign قبل از ذخیره محلی آثار، هویت ناشر را تأیید می‌کنند.
 #6.4.3    سطح: 2    نقش: D
 تأیید کنید که پراکسی‌های خروجی دانلودهای بدون احراز هویت آثار را مسدود می‌کنند تا سیاست منبع مورد اعتماد را اعمال کنند.
 #6.4.4    سطح: 2    نقش: V
 بررسی کنید که فهرست‌های مجاز مخزن به صورت سه‌ماهه بازبینی می‌شوند و برای هر ورودی، شواهدی از توجیه کسب‌وکار وجود دارد.
 #6.4.5    سطح: 3    نقش: V
 تأیید کنید که نقض سیاست‌ها موجب قرنطینه شدن آثار و بازگردانی اجرای خط‌لوله‌های وابسته می‌شود.

---

### C6.5 ارزیابی ریسک داده‌های شخص ثالث

داده‌های خارجی را از نظر آلودگی، تعصب و تطابق قانونی ارزیابی کرده و در طول دوره عمر آن‌ها را نظارت کنید.

 #6.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که داده‌های خارجی مورد ارزیابی ریسک آلودگی قرار می‌گیرند (مانند اثرانگشت داده‌ها، تشخیص نقاط دورافتاده).
 #6.5.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که معیارهای تبعیض (برابری جمعیتی، فرصت برابر) قبل از تصویب مجموعه داده محاسبه شده‌اند.
 #6.5.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که منشاء و شرایط مجوز برای مجموعه داده‌ها در ورودی‌های ML‑BOM ثبت شده است.
 #6.5.4    سطح: 2    نقش: V
 تأیید کنید که پایش دوره‌ای تغییر یا فساد در مجموعه داده‌های میزبانی‌شده را شناسایی می‌کند.
 #6.5.5    سطح: 3    نقش: D
 اطمینان حاصل کنید که محتوای غیرمجاز (حق چاپ، اطلاعات شخصی شناسایی شده) از طریق پاکسازی خودکار پیش از آموزش حذف شده است.

---

### C6.6 نظارت بر حملات زنجیره تامین

تهدیدهای زنجیره تامین را از طریق خوراک‌های CVE، تحلیل‌های گزارش حسابرسی، و شبیه‌سازی‌های تیم قرمز به‌صورت زودهنگام شناسایی کنید.

 #6.6.1    سطح: 1    نقش: V
 بررسی کنید که لاگ‌های ممیزی CI/CD به صورت جریان به تشخیص‌های SIEM برای کشیدن بسته‌های غیرعادی یا مراحل ساخت دستکاری‌شده منتقل می‌شوند.
 #6.6.2    سطح: 2    نقش: D
 تأیید کنید که راهنماهای واکنش به حادثه شامل روش‌های بازگردانی برای مدل‌ها یا کتابخانه‌های به خطر افتاده باشند.
 #6.6.3    سطح: 3    نقش: V
 تأیید کنید که برچسب‌های غنی‌سازی تهدید-اطلاعات، شاخص‌های اختصاصی یادگیری ماشین (مثلاً IoCهای مسموم‌سازی مدل) را در دسته‌بندی هشدار علامت‌گذاری می‌کنند.

---

### C6.7 لیست مواد ماشین لرنینگ (ML‑BOM) برای مصنوعات مدل

تولید و امضای SBOMهای تخصصی ML (ML‑BOMها) به‌صورت دقیق تا مصرف‌کنندگان پایین‌دستی بتوانند صحت مؤلفه‌ها را در زمان استقرار تأیید کنند.

 #6.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر اثر مدل یک ML‑BOM منتشر می‌کند که شامل مجموعه داده‌ها، وزن‌ها، ابرپارامترها و مجوزها است.
 #6.7.2    سطح: 1    نقش: D/V
 تأیید کنید که تولید ML‑BOM و امضای Cosign در CI خودکار شده و برای ادغام ضروری است.
 #6.7.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که بررسی‌های کامل بودن ML‑BOM در صورتی که هر گونه فراداده مؤلفه (هش، مجوز) مفقود باشد، فرایند ساخت را ناموفق می‌کند.
 #6.7.4    سطح: 2    نقش: V
 تأیید کنید که مصرف‌کنندگان پایین‌دستی بتوانند از طریق API به ML-BOMها پرس‌وجو کنند تا مدل‌های واردشده را در زمان استقرار اعتبارسنجی کنند.
 #6.7.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که ML‑BOMها تحت کنترل نسخه قرار دارند و برای شناسایی تغییرات غیرمجاز، تفاوت‌گیری می‌شوند.

---

### مراجع

ML Supply Chain Compromise – MITRE ATLAS
Supply‑chain Levels for Software Artifacts (SLSA)
CycloneDX – Machine Learning Bill of Materials
What is Data Poisoning? – SentinelOne
Transfer Learning Attack – OWASP ML Security Top 10
AI Data Security Best Practices – CISA
Secure CI/CD Supply Chain – Sumo Logic
AI & Transparency: Protect ML Models – ReversingLabs
SBOM Overview – CISA
Training Data Poisoning Guide – Lakera.ai
Dependency Pinning for Reproducible Python – Medium

## رفتار مدل C7، کنترل خروجی و تضمین ایمنی

### هدف کنترل

خروجی‌های مدل باید ساختاریافته، قابل اطمینان، ایمن، قابل توضیح و به طور مداوم در محیط تولید تحت نظارت باشند. انجام این کار باعث کاهش توهمات، نشت حریم خصوصی، محتوای مضر و اقدامات خارج از کنترل می‌شود و در عین حال اعتماد کاربران و تطابق با مقررات را افزایش می‌دهد.

---

### C7.1 اعمال قالب خروجی

طرح‌های سخت‌گیرانه، رمزگشایی محدود شده، و اعتبارسنجی پس‌رو محتواهای نادرست یا مخرب را پیش از گسترش متوقف می‌کنند.

 #7.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که طرحواره‌های پاسخ (مانند JSON Schema) در پیام سیستم ارائه شده‌اند و هر خروجی به‌طور خودکار اعتبارسنجی می‌شود؛ خروجی‌هایی که با طرحواره همخوانی ندارند، باعث تعمیر یا رد شدن می‌شوند.
 #7.1.2    سطح: 1    نقش: D/V
 تأیید کنید که رمزگشایی محدود شده (توکن‌های توقف، عبارت‌های منظم، حداکثر توکن‌ها) فعال است تا از سرریز یا کانال‌های جانبی تزریق پرامپت جلوگیری شود.
 #7.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اجزای پایین‌دستی خروجی‌ها را به عنوان نامطمئن در نظر می‌گیرند و آن‌ها را بر اساس طرح‌واره‌ها یا د-سریالایزرهای ضد تزریق معتبر می‌سازند.
 #7.1.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که رویدادهای خروجی نامناسب ثبت، محدودیت نرخ شده و به نظارت ارجاع داده می‌شوند.

---

### C7.2 تشخیص و کاهش هالوسیناسیون

برآورد عدم قطعیت و استراتژی‌های جایگزین پاسخ‌های ساختگی را محدود می‌کنند.

 #7.2.1    سطح: 1    نقش: D/V
 تأیید کنید که احتمال‌های لگاریتمی در سطح توکن، انسجام خود-تجمعی مجموعه، یا آشکارسازهای هذیان تنظیم‌شده دقیق، نمره اطمینان را به هر پاسخ اختصاص می‌دهند.
 #7.2.2    سطح: 1    نقش: D/V
 تأیید کنید که پاسخ‌هایی با سطح اطمینان کمتر از آستانه قابل تنظیم، فرآیندهای جایگزین را فعال می‌کنند (مانند تولید افزوده به بازیابی، مدل ثانویه، یا بازبینی انسانی).
 #7.2.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که وقایع هالوسیناسیون با فراداده ریشه‌ای برچسب‌گذاری شده و به پایپلاین‌های بررسی پس از وقوع و تنظیم دقیق داده می‌شوند.
 #7.2.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که پس از به‌روزرسانی‌های عمده مدل یا پایگاه دانش، آستانه‌ها و آشکارسازها مجدداً کالیبره می‌شوند.
 #7.2.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که تجسم‌های داشبورد نرخ‌های توهم‌زایی را ردیابی می‌کنند.

---

### C7.3 فیلترسازی ایمنی و حریم خصوصی خروجی

فیلترهای سیاست‌گذاری و پوشش تیم قرمز از کاربران و داده‌های محرمانه محافظت می‌کنند.

 #7.3.1    سطح: 1    نقش: D/V
 تأیید کنید که طبقه‌بندهای پیش و پس از تولید، محتوای نفرت‌انگیز، آزاردهنده، خودآسیب‌رسان، افراطی و جنسی صریح مطابق با سیاست را مسدود می‌کنند.
 #7.3.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تشخیص PII/PCI و سانسور خودکار در هر پاسخ اجرا می‌شود؛ نقض‌ها موجب ایجاد حادثه حریم خصوصی می‌شوند.
 #7.3.3    سطح: 2    نقش: D
 تأیید کنید که برچسب‌های محرمانگی (مثلاً اسرار تجاری) در سراسر مدالیت‌ها منتقل می‌شوند تا از نشت اطلاعات در متن، تصاویر یا کد جلوگیری شود.
 #7.3.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تلاش‌های عبور از فیلتر یا دسته‌بندی‌های با ریسک بالا نیازمند تایید ثانویه یا اعتبارسنجی مجدد کاربر هستند.
 #7.3.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که آستانه‌های فیلترینگ منعکس‌کننده حوزه‌های قضایی قانونی و زمینه سن/نقش کاربر باشند.

---

### C7.4 محدود کردن خروجی و عملیات

محدودیت‌های نرخ و دروازه‌های تأیید از سوء استفاده و خودمختاری بیش از حد جلوگیری می‌کنند.

 #7.4.1    سطح: 1    نقش: D
 تأیید کنید که سهمیه‌های هر کاربر و هر کلید API درخواست‌ها، توکن‌ها و هزینه‌ها را با استفاده از بازگشت نمایی (exponential back-off) در مواجهه با خطاهای 429 محدود می‌کنند.
 #7.4.2    سطح: 1    نقش: D/V
 تأیید کنید که اقدامات ویژه (نوشتن فایل، اجرای کد، تماس‌های شبکه) نیاز به تایید بر اساس سیاست یا دخالت انسانی دارند.
 #7.4.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که بررسی‌های سازگاری چندوجهی تضمین می‌کنند تصاویر، کد و متنی که برای یک درخواست یکسان تولید شده‌اند، نمی‌توانند برای قاچاق محتوای مخرب استفاده شوند.
 #7.4.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که عمق واگذاری نماینده، محدودیت‌های بازگشتی و فهرست ابزارهای مجاز به‌طور صریح پیکربندی شده‌اند.
 #7.4.5    سطح: 3    نقش: V
 تأیید کنید که نقض محدودیت‌ها رویدادهای امنیتی ساختاریافته‌ای را برای وارد شدن به سیستم‌های مدیریت اطلاعات امنیتی (SIEM) ارسال می‌کند.

---

### توضیح‌پذیری خروجی C7.5

سیگنال‌های شفاف اعتماد کاربر و عیب‌یابی داخلی را بهبود می‌بخشند.

 #7.5.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که امتیازهای اطمینان قابل مشاهده توسط کاربر یا خلاصه‌های کوتاه استدلال زمانی که ارزیابی ریسک مناسب تشخیص داده می‌شود، ارائه می‌گردد.
 #7.5.2    سطح: 2    نقش: D/V
 تأیید کنید که توضیحات تولیدشده از افشای پرامپت‌های حساس سیستم یا داده‌های مالکیتی جلوگیری می‌کنند.
 #7.5.3    سطح: 3    نقش: D
 اطمینان حاصل کنید که سیستم احتمال‌های لگاریتمی در سطح توکن یا نقشه‌های توجه را ضبط کرده و برای بازبینی مجاز ذخیره می‌کند.
 #7.5.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که آثار توضیح‌پذیری همراه با نسخه‌های مدل برای قابلیت ممیزی نسخه‌بندی شده‌اند.

---

### C7.6 یکپارچه‌سازی نظارت

نظارت لحظه‌ای حلقه بین توسعه و تولید را می‌بندد.

 #7.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که معیارها (نقض‌های طرح‌واره، نرخ هذیان، سمی بودن، نشت اطلاعات شناسایی شخصی، تأخیر، هزینه) به یک پلتفرم نظارتی مرکزی ارسال می‌شوند.
 #7.6.2    سطح: 1    نقش: V
 اطمینان حاصل کنید که آستانه‌های هشدار برای هر معیار ایمنی تعریف شده‌اند و مسیرهای افزایش تماس در صورت نیاز مشخص شده‌اند.
 #7.6.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که داشبوردها ناهنجاری‌های خروجی را با مدل/نسخه، پرچم ویژگی، و تغییرات داده‌های بالادستی همبسته می‌کنند.
 #7.6.4    سطح: 2    نقش: D/V
 تأیید کنید که داده‌های نظارتی به‌عنوان بازخورد در فرایند آموزش مجدد، تنظیم دقیق یا به‌روزرسانی قوانین در چارچوب مستند شده MLOps وارد می‌شوند.
 #7.6.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که خطوط لوله نظارتی از نظر نفوذ تست شده و دسترسی به آنها کنترل شده باشد تا از نشت لاگ‌های حساس جلوگیری شود.

---

### 7.7 تدابیر حفاظتی رسانه‌های مولد

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی محتوای رسانه‌ای غیرقانونی، مضر یا غیرمجاز تولید نکنند با اجرای محدودیت‌های سیاست، اعتبارسنجی خروجی و قابلیت ردیابی.

 #7.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که فرمان‌های سیستمی و دستورالعمل‌های کاربر به طور صریح تولید رسانه‌های دیپ‌فیک غیرقانونی، مضر یا بدون رضایت (مانند تصویر، ویدیو، صدا) را ممنوع اعلام می‌کنند.
 #7.7.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که درخواست‌ها برای تلاش‌های تولید تقلید شخصیت‌ها، تصاویر جعلی جنسی صریح، یا رسانه‌هایی که افراد واقعی را بدون رضایت نشان می‌دهند، فیلتر شده‌اند.
 #7.7.3    سطح: 2    نقش: V
 بررسی کنید که سیستم از هش ادراکی، تشخیص واترمارک، یا اثر انگشتی برای جلوگیری از تکثیر غیرمجاز محتوای دارای حق کپی رایت استفاده می‌کند.
 #7.7.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تمامی رسانه‌های تولید شده به صورت رمزنگاری‌شده امضا شده، واترمارک شده یا با متادیتای منبع مقاوم در برابر دستکاری برای رصدپذیری در مراحل بعدی جاسازی شده‌اند.
 #7.7.5    سطح: 3    نقش: V
 تأیید کنید که تلاش‌های دور زدن (مانند مبهم‌سازی پرامپت، زبان عامیانه، عباراتی با نیت خصمانه) شناسایی، ثبت و با محدودیت نرخ مواجه می‌شوند؛ سوءاستفاده‌های مکرر به سیستم‌های نظارتی گزارش داده می‌شود.

### مراجع

NIST AI Risk Management Framework
ISO/IEC 42001:2023 – AI Management System
OWASP Top-10 for Large Language Model Applications (2025)
Improper Output Handling – OWASP LLM05:2025
Practical Techniques to Constrain LLM Output
Dataiku – Structured Text Generation Guide
VL-Uncertainty: Detecting Hallucinations
HaDeMiF: Hallucination Detection & Mitigation
Building Confidence in LLM Outputs
Explainable AI & LLMs
LLM Red-Teaming Guide
Sensitive Information Disclosure in LLMs
LangChain – Chat Model Rate Limiting
OpenAI Rate-Limit & Exponential Back-off
Arize AI – LLM Observability Platform

## امنیت حافظه C8، تعبیه‌ها و پایگاه داده‌های برداری

### هدف کنترل

امبدینگ‌ها و فروشگاه‌های وکتور به‌مثابه «حافظه زنده» سیستم‌های هوش مصنوعی معاصر عمل می‌کنند و به‌طور مداوم داده‌های ارائه‌شده توسط کاربر را می‌پذیرند و از طریق تولید تقویت‌شده با بازیابی (RAG) آن‌ها را به متون مدل برمی‌گردانند. اگر این حافظه بدون کنترل باقی بماند، ممکن است اطلاعات شناسایی شخصی (PII) نشت کند، حقوق رضایت نقض شود یا متن اصلی به‌صورت معکوس بازسازی شود. هدف این مجموعه کنترل‌ها، مقاوم‌سازی خطوط انتقال حافظه و پایگاه‌های داده وکتور است به‌گونه‌ای که دسترسی، حداقل مجوز را داشته باشد، امبدینگ‌ها حفظ حریم خصوصی را تضمین کنند، وکتورهای ذخیره‌شده منقضی شوند یا به‌صورت درخواستی لغو گردند و حافظه هر کاربر، هرگز درخواست‌ها یا تکمیل‌های کاربران دیگر را آلوده نکند.

---

### C8.1 کنترل‌های دسترسی روی حافظه و شاخص‌های RAG

اعمال کنترل‌های دسترسی دقیق و جزئی بر روی هر مجموعه برداری.

 #8.1.1    سطح: 1    نقش: D/V
 تأیید کنید که قوانین کنترل دسترسی در سطح ردیف/فضای نام، عملیات درج، حذف و پرس‌وجو را برای هر مستأجر، مجموعه یا برچسب سند محدود می‌کنند.
 #8.1.2    سطح: 1    نقش: D/V
 تأیید کنید که کلیدهای API یا JWT دارای ادعاهای محدوده‌بندی شده (مانند شناسه‌های مجموعه، افعال عملیاتی) هستند و حداقل هر فصل یکبار تعویض می‌شوند.
 #8.1.3    سطح: 2    نقش: D/V
 تأیید کنید که تلاش‌های افزایش دسترسی (مانند پرس‌وجوهای شباهت بین فضای نام‌ها) در طی ۵ دقیقه شناسایی و در سیستم مدیریت اطلاعات و رویدادهای امنیتی (SIEM) ثبت شوند.
 #8.1.4    سطح: 2    نقش: D/V
 تأیید کنید که پایگاه داده برداری، شناسه موضوع، عملیات، شناسه/فضای نام بردار، آستانه شباهت و تعداد نتایج لاگ را بررسی می‌کند.
 #8.1.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که تصمیمات دسترسی برای نقص‌های دور زدن هر زمان که موتور‌ها به‌روزرسانی می‌شوند یا قوانین تقسیم‌بندی نمایه تغییر می‌کنند، آزمایش می‌شوند.

---

### C8.2 پاک‌سازی و اعتبارسنجی جاسازی‌ها

متن را برای اطلاعات شناسایی شخصی (PII) پیش‌پردازش کنید، قبل از بردارسازی، آن را حذف یا شبه‌نام‌گذاری کنید و به‌طور اختیاری تعبیه‌ها را پس‌پردازش کنید تا سیگنال‌های باقی‌مانده را حذف کنید.

 #8.2.1    سطح: 1    نقش: D/V
 تأیید کنید که داده‌های PII و داده‌های تنظیم‌شده از طریق طبقه‌بندی‌کننده‌های خودکار شناسایی شده و پیش از تعبیه، ماسک شده، توکنیزه شده یا حذف می‌شوند.
 #8.2.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که خطوط لوله تعبیه، ورودی‌هایی که حاوی کد اجرایی یا آثار غیر UTF-8 هستند و ممکن است شاخص را مسموم کنند، رد شده یا قرنطینه می‌شوند.
 #8.2.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تصفیه مبتنی بر حفظ حریم خصوصی محلی یا متریک به بردارهای تعبیه جمله اعمال شود که فاصله آنها تا هر نشانه PII شناخته‌شده کمتر از یک آستانه قابل تنظیم باشد.
 #8.2.4    سطح: 2    نقش: V
 تأیید کنید که اثربخشی پاک‌سازی (مانند یادآوری حذف اطلاعات شناسایی شخصی، انحراف معنایی) حداقل به صورت نیمه‌سالانه در برابر مجموعه‌های معیار مورد ارزیابی قرار می‌گیرد.
 #8.2.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که پیکربندی‌های پاک‌سازی نسخه‌بندی شده‌اند و تغییرات تحت بازبینی همتا قرار می‌گیرند.

---

### C8.3 انقضای حافظه، لغو و حذف

قانون GDPR «حق فراموش شدن» و قوانین مشابه نیازمند حذف به موقع داده‌ها است؛ بنابراین فروشگاه‌های برداری باید از TTLها، حذف سخت، و نشانه‌گذاری قبور پشتیبانی کنند تا بردارهای لغوشده قابل بازیابی یا بازیابی مجدد نباشند.

 #8.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر بردار و رکورد فراداده دارای TTL یا برچسب نگهداری صریح است که توسط وظایف پاک‌سازی خودکار رعایت می‌شود.
 #8.3.2    سطح: 1    نقش: D/V
 تأیید کنید که درخواست‌های حذف مبتنی بر کاربر، بردارها، فراداده‌ها، نسخه‌های کش و شاخص‌های مشتق‌شده را ظرف 30 روز پاک می‌کنند.
 #8.3.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که حذف‌های منطقی با محو رمزنگاری بلاک‌های ذخیره‌سازی در صورت پشتیبانی سخت‌افزار، یا با تخریب کلید مخزن کلید همراه باشند.
 #8.3.4    سطح: 3    نقش: D/V
 تأیید کنید که بردارهای منقضی‌شده در کمتر از 500 میلی‌ثانیه پس از انقضا از نتایج جستجوی نزدیک‌ترین همسایه حذف می‌شوند.

---

### C8.4 جلوگیری از وارونگی و نشت جاسازی

دفاع‌های اخیر — مانند افزودن نویز، شبکه‌های پروجکشن، اختلال در نورون‌های حریم خصوصی، و رمزنگاری در لایه کاربرد — می‌توانند نرخ‌های معکوس‌سازی در سطح توکن را به زیر ۵٪ کاهش دهند.

 #8.4.1    سطح: 1    نقش: V
 اطمینان حاصل کنید که یک مدل تهدید رسمی که شامل حملات معکوس، عضویت و استنتاج ویژگی‌ها است، وجود دارد و سالانه بازبینی می‌شود.
 #8.4.2    سطح: 2    نقش: D/V
 تأیید کنید که رمزنگاری در لایه برنامه یا رمزنگاری جستجوپذیر از خواندن مستقیم وکتورها توسط مدیران زیرساخت یا کارکنان ابر جلوگیری می‌کند.
 #8.4.3    سطح: 3    نقش: V
 تأیید کنید که پارامترهای دفاعی (ε برای DP، نویز σ، رتبه پرجکشن k) تعادل بین حفظ حریم خصوصی ≥ ۹۹٪ حفاظت از توکن و سودمندی ≤ ۳٪ کاهش دقت را برقرار می‌کنند.
 #8.4.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که معیارهای مقاومت در برابر وارونگی بخشی از دروازه‌های انتشار برای به‌روزرسانی‌های مدل هستند و بودجه‌های رگرسیون تعریف شده‌اند.

---

### C8.5 اجرای حوزه برای حافظه مخصوص کاربر

نشت اطلاعات بین مستاجرها همچنان یک ریسک اصلی در RAG است: پرس‌وجوهای شباهت فیلتر نشده به‌درستی می‌توانند اسناد خصوصی مشتری دیگری را نشان دهند.

 #8.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر پرس‌وجوی بازیابی قبل از ارسال به پرامپت LLM، توسط شناسه مستاجر/کاربر پس‌فیلتر شود.
 #8.5.2    سطح: 1    نقش: D
 تأیید کنید که نام‌های مجموعه یا شناسه‌های نام‌گذاری شده به ازای هر کاربر یا مستأجر نمک‌دار شده‌اند تا بردارها در حوزه‌های مختلف با هم تداخل نداشته باشند.
 #8.5.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که نتایج شباهت بالاتر از آستانه فاصله قابل تنظیم اما خارج از محدوده تماس‌دهنده دور ریخته شده و هشدارهای امنیتی را فعال می‌کنند.
 #8.5.4    سطح: 2    نقش: V
 تأیید کنید که تست‌های استرس چنداجاره‌ای پرس‌وجوهای خصمانه‌ای را که تلاش می‌کنند اسناد خارج از محدوده را بازیابی کنند، شبیه‌سازی می‌کنند و نشت صفر را نشان می‌دهند.
 #8.5.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که کلیدهای رمزنگاری به ازای هر مستاجر جدا شده‌اند، به‌طوری که جداسازی رمزنگاری حتی در صورت اشتراک‌گذاری ذخیره‌سازی فیزیکی حفظ شود.

---

### C8.6 امنیت پیشرفته سیستم حافظه

کنترل‌های امنیتی برای معماری‌های پیشرفته حافظه شامل حافظه اپیزودیک، معنایی و کاری با نیازهای خاص ایزولاسیون و اعتبارسنجی.

 #8.6.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که انواع مختلف حافظه (اپیزودیک، معنایی، کاری) دارای زمینه‌های امنیتی جداگانه با کنترل‌های دسترسی مبتنی بر نقش، کلیدهای رمزنگاری مجزا و الگوهای دسترسی مستند شده برای هر نوع حافظه باشند.
 #8.6.2    سطح: 2    نقش: D/V
 تأیید کنید که فرآیندهای تثبیت حافظه شامل اعتبارسنجی امنیتی برای جلوگیری از تزریق خاطرات مخرب از طریق پاکسازی محتوا، تأیید منبع و بررسی‌های صحت قبل از ذخیره‌سازی باشد.
 #8.6.3    سطح: 2    نقش: D/V
 تأیید کنید که پرس‌وجوهای بازیابی حافظه اعتبارسنجی و پاکسازی شده‌اند تا از استخراج اطلاعات غیرمجاز از طریق تحلیل الگوی پرس‌وجو، اعمال کنترل دسترسی و فیلتر کردن نتایج جلوگیری شود.
 #8.6.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های فراموشی حافظه اطلاعات حساس را با تضمین‌های حذف رمزنگاری شده به طور امن حذف می‌کنند، از طریق حذف کلید، بازنویسی چندباره یا حذف امن مبتنی بر سخت‌افزار با گواهی‌های تایید.
 #8.6.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که یکپارچگی سیستم حافظه به طور مداوم برای تغییرات غیرمجاز یا فساد از طریق چک‌سام‌ها، لاگ‌های حسابرسی، و هشدارهای خودکار هنگام تغییر محتوای حافظه خارج از عملیات عادی، رصد می‌شود.

---

### مراجع

Vector database security: Pinecone – IronCore Labs
Securing the Backbone of AI: Safeguarding Vector Databases and Embeddings – Privacera
Enhancing Data Security with RBAC of Qdrant Vector Database – AI Advances
Mitigating Privacy Risks in LLM Embeddings from Embedding Inversion – arXiv
DPPN: Detecting and Perturbing Privacy-Sensitive Neurons – OpenReview
Art. 17 GDPR – Right to Erasure
Sensitive Data in Text Embeddings Is Recoverable – Tonic.ai
PII Identification and Removal – NVIDIA NeMo Docs
De-identifying Sensitive Data – Google Cloud DLP
Remove PII from Conversations Using Sensitive Information Filters – AWS Bedrock Guardrails
Think Your RAG Is Secure? Think Again – Medium
Design a Secure Multitenant RAG Inferencing Solution – Microsoft Learn
Best Practices for Multi-Tenancy RAG with Milvus – Milvus Blog

## 9 امنیت ارکستراسیون خودمختار و اقدام عاملی

### هدف کنترل

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی خودران یا چندعاملی تنها می‌توانند اقداماتی را انجام دهند که به‌طور صریح منظور شده، معتبرسازی شده، قابل حسابرسی باشند و در محدوده هزینه و آستانه‌های ریسک مشخص قرار داشته باشند. این کار از تهدیداتی مانند نقض سیستم خودران، سوء استفاده از ابزار، شناسایی حلقه عامل، ربودن ارتباطات، جعل هویت، دستکاری جمعی و دستکاری نیت جلوگیری می‌کند.

---

### 9.1 بودجه‌های برنامه‌ریزی وظایف عامل و بازگشتی

برنامه‌های بازگشتی را محدود کنید و برای اقدامات دارای امتیاز بالا، توقف‌های انسانی اجباری اعمال کنید.

 #9.1.1    سطح: 1    نقش: D/V
 تأیید کنید که حداکثر عمق بازگشت، پهنا، زمان دیوار-ساعت، توکن‌ها و هزینه مالی هر اجرای عامل به صورت مرکزی پیکربندی و کنترل نسخه شده باشند.
 #9.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که اقدامات دارای امتیاز ویژه یا غیرقابل برگشت (مانند کامیت‌های کد، انتقالات مالی) قبل از اجرا نیازمند تأیید صریح انسانی از طریق یک کانال قابل حسابرسی باشد.
 #9.1.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که مانیتورهای منابع زمان واقعی هنگامی که هر آستانه بودجه‌ای عبور می‌کند، باعث قطع مدار قطع‌کننده می‌شوند و از گسترش بیشتر وظایف جلوگیری می‌کنند.
 #9.1.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که رویدادهای مدار شکن با شناسه عامل، شرط فعال‌سازی و وضعیت برنامه ضبط شده برای بررسی فنی ثبت می‌شوند.
 #9.1.5    سطح: 3    نقش: V
 تأیید کنید که آزمون‌های امنیتی سناریوهای خالی شدن بودجه و طرح فرار را پوشش می‌دهند و توقف ایمن بدون از دست رفتن داده‌ها را تأیید می‌کنند.
 #9.1.6    سطح: 3    نقش: D
 اطمینان حاصل کنید که سیاست‌های بودجه به صورت سیاست-به-کد بیان شده و در CI/CD اعمال می‌شوند تا از انحراف پیکربندی جلوگیری شود.

---

### 9.2 اجرای پلاگین ابزار در محیط جدا شده (Sandboxing)

تعاملات ابزار را جدا کنید تا از دسترسی غیرمجاز به سیستم یا اجرای کد جلوگیری شود.

 #9.2.1    سطح: 1    نقش: D/V
 تأیید کنید که هر ابزار/افزونه در داخل یک سیستم‌عامل، کانتینر، یا سندباکس سطح WASM با سیاست‌های کمترین دسترسی برای سیستم‌فایل، شبکه، و فراخوانی سیستم اجرا می‌شود.
 #9.2.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که محدودیت‌های منابع محیط ایزوله (CPU، حافظه، دیسک، خروجی شبکه) و زمان اجرای تایم‌اوت‌ها اعمال و ثبت شده باشند.
 #9.2.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که باینری‌های ابزار یا توصیف‌گرها به صورت دیجیتالی امضا شده‌اند؛ امضاها قبل از بارگذاری اعتبارسنجی می‌شوند.
 #9.2.4    سطح: 2    نقش: V
 تأیید کنید که داده‌های تلماتری محیط ایزوله‌شده به سیستم مدیریت اطلاعات و رویدادهای امنیتی (SIEM) منتقل می‌شوند؛ ناهنجاری‌ها (مثلاً تلاش برای برقراری ارتباطات خروجی) هشدار ایجاد می‌کنند.
 #9.2.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که پلاگین‌های پرخطر قبل از استقرار در محیط تولید، مورد بررسی امنیتی و تست نفوذ قرار می‌گیرند.
 #9.2.6    سطح: 3    نقش: D/V
 تأیید کنید که تلاش‌های فرار از سندباکس به‌طور خودکار مسدود شده و افزونه متخلف مشروط به بررسی در قرنطینه قرار می‌گیرد.

---

### 9.3 حلقه خودکار و محدود کردن هزینه

شناسایی و متوقف‌سازی بازگشت و انفجار هزینه‌های غیرقابل کنترل بین عوامل.

 #9.3.1    سطح: 1    نقش: D/V
 تأیید کنید که تماس‌های بین عامل‌ها شامل محدودیت پرش یا TTL باشند که زمان اجرا آن را کاهش داده و اعمال می‌کند.
 #9.3.2    سطح: 2    نقش: D
 تأیید کنید که عامِل‌ها یک شناسه گراف فراخوانی منحصر به فرد را حفظ می‌کنند تا خودفراخوانی یا الگوهای چرخه‌ای را شناسایی کنند.
 #9.3.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که شمارنده‌های تجمعی واحد محاسبات و هزینه به ازای هر زنجیره درخواست پیگیری می‌شوند؛ نقض محدودیت باعث لغو زنجیره می‌شود.
 #9.3.4    سطح: 3    نقش: V
 تأیید کنید که تحلیل رسمی یا بررسی مدل، عدم وجود بازگشت نامحدود در پروتکل‌های عامل را نشان می‌دهد.
 #9.3.5    سطح: 3    نقش: D
 اطمینان حاصل کنید که رویدادهای قطع حلقه هشدارها را ایجاد کرده و معیارهای بهبود مستمر را تغذیه می‌کنند.

---

### 9.4 محافظت در برابر سوءاستفاده در سطح پروتکل

کانال‌های ارتباطی ایمن بین عامل‌ها و سیستم‌های خارجی برای جلوگیری از ربایش یا دستکاری.

 #9.4.1    سطح: 1    نقش: D/V
 تأیید کنید که تمام پیام‌های بین عامل و ابزار و بین عامل‌ها احراز هویت شده باشند (مثلاً از طریق TLS متقابل یا JWT) و به‌صورت پایان به پایان رمزنگاری شده باشند.
 #9.4.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که طرح‌ها به‌طور دقیق اعتبارسنجی می‌شوند؛ فیلدهای ناشناخته یا پیام‌های ناصحیح رد می‌شوند.
 #9.4.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که بررسی‌های صحت (MAC ها یا امضاهای دیجیتال) کل بار پیام از جمله پارامترهای ابزار را پوشش می‌دهند.
 #9.4.4    سطح: 2    نقش: D
 تأیید کنید که حفاظت در برابر بازپخش (nonceها یا پنجره‌های زمان‌بندی) در لایه پروتکل اعمال شده است.
 #9.4.5    سطح: 3    نقش: V
 تأیید کنید که پیاده‌سازی‌های پروتکل تحت تست فازی و تحلیل ایستا برای یافتن آسیب‌پذیری‌های تزریق یا ناپیاده‌سازی قرار می‌گیرند.

---

### 9.5 هویت عامل و شواهد دستکاری

اطمینان حاصل کنید که اقدامات قابل انتساب و تغییرات قابل شناسایی باشند.

 #9.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر نمونه عامل دارای یک هویت رمزنگاری یکتا (جفت کلید یا مجوز مبتنی بر سخت‌افزار) باشد.
 #9.5.2    سطح: 2    نقش: D/V
 تأیید کنید که تمامی اقدامات عامل امضا شده و دارای مهر زمانی هستند؛ لاگ‌ها شامل امضا برای جلوگیری از انکار باشد.
 #9.5.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که لاگ‌های قابل تشخیص تغییرات در یک محیط فقط افزایشی یا نوشتنی-یکبار ذخیره می‌شوند.
 #9.5.4    سطح: 3    نقش: D
 اطمینان حاصل کنید که کلیدهای هویت طبق یک برنامه زمان‌بندی مشخص و در صورت وجود شاخص‌های نفوذ، تغییر می‌کنند.
 #9.5.5    سطح: 3    نقش: D/V
 تأیید کنید که تلاش‌های جعل هویت یا تضاد کلید باعث قرنطینه فوری عامل آسیب‌دیده می‌شود.

---

### 9.6 کاهش ریسک ازدحام چندعامل

خطرات رفتار جمعی را از طریق ایزولاسیون و مدل‌سازی ایمنی رسمی کاهش دهید.

 #9.6.1    سطح: 1    نقش: D/V
 تأیید کنید که عامل‌هایی که در حوزه‌های امنیتی مختلف فعالیت می‌کنند، در محیط‌های زمان اجرای جداگانه یا بخش‌های شبکه ایزوله اجرا می‌شوند.
 #9.6.2    سطح: 3    نقش: V
 تأیید کنید که رفتارهای گروهی مدل‌سازی شده و از نظر زنده‌مانی و ایمنی به‌طور رسمی تأیید شده‌اند قبل از استقرار.
 #9.6.3    سطح: 3    نقش: D
 تأیید کنید که مانیتورهای زمان اجرا الگوهای ناایمن نوظهور (مانند نوسانات، بن‌بست‌ها) را تشخیص داده و اقدام اصلاحی را آغاز می‌کنند.

---

### 9.7 احراز هویت / مجوز کاربر و ابزار

اجرای کنترل‌های دسترسی مقاوم برای هر عملی که توسط عامل فعال می‌شود.

 #9.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که عوامل به عنوان ارکان درجه یک به سیستم‌های پایین‌دستی احراز هویت می‌شوند و هرگز از مدارک اعتبار کاربر نهایی مجدداً استفاده نمی‌کنند.
 #9.7.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که سیاست‌های مجوزدهی دقیق محدود می‌کنند که یک عامل کدام ابزارها را می‌تواند فرا بخواند و کدام پارامترها را می‌تواند ارائه دهد.
 #9.7.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که بررسی‌های امتیاز دسترسی در هر فراخوانی مجدداً ارزیابی می‌شوند (مجوزدهی مداوم) و نه تنها در شروع جلسه.
 #9.7.4    سطح: 3    نقش: D
 اطمینان حاصل کنید که امتیازات واگذار شده به طور خودکار منقضی می‌شوند و پس از گذشت زمان یا تغییر دامنه، نیاز به تایید مجدد دارند.

---

### 9.8 امنیت ارتباط عامل به عامل

تمام پیام‌های بین عوامل را رمزنگاری و محافظت از صحت آن‌ها انجام دهید تا از شنود و دستکاری جلوگیری شود.

 #9.8.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که احراز هویت متقابل و رمزگذاری با امنیت پیشرفته کامل (مانند TLS 1.3) برای کانال‌های عامل الزامی باشد.
 #9.8.2    سطح: 1    نقش: D
 تأیید کنید که صحت و منبع پیام قبل از پردازش تأیید شده باشد؛ در صورت عدم صحت، هشدارها صادر شده و پیام رد می‌شود.
 #9.8.3    سطح: 2    نقش: D/V
 تأیید کنید که فراداده‌های ارتباطی (زمان‌های ثبت، شماره‌های دنباله) برای پشتیبانی از بازسازی قضایی ثبت شوند.
 #9.8.4    سطح: 3    نقش: V
 تأیید کنید که تایید رسمی یا بررسی مدل تایید می‌کند که ماشین‌های حالت پروتکل نمی‌توانند به حالت‌های ناامن رانده شوند.

---

### 9.9 تأیید نیت و اعمال محدودیت‌ها

اعتبارسنجی کنید که اقدامات عامل با نیت بیان‌شده کاربر و محدودیت‌های سیستم همسو باشد.

 #9.9.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که حل‌کننده‌های محدودیت پیش‌اجرایی، اقدامات پیشنهادی را در مقابل قوانین سخت‌کد شده ایمنی و سیاست بررسی می‌کنند.
 #9.9.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اقدامات با تاثیر بالا (مالی، مخرب، حساس به حریم خصوصی) نیازمند تأیید صریح نیت از کاربر آغازکننده هستند.
 #9.9.3    سطح: 2    نقش: V
 بررسی کنید که چک‌های پس‌شرط تأیید کنند که اقدامات تکمیل‌شده اثرات مورد نظر را بدون عوارض جانبی محقق کرده‌اند؛ هرگونه اختلافی باعث برگشت عملیات می‌شود.
 #9.9.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که روش‌های رسمی (مانند بررسی مدل، اثبات قضیه) یا آزمون‌های مبتنی بر ویژگی نشان می‌دهند که برنامه‌های عامل تمامی محدودیت‌های اعلام‌شده را برآورده می‌کنند.
 #9.9.5    سطح: 3    نقش: D
 تأیید کنید که حوادث ناهماهنگی نیت یا نقض محدودیت‌ها چرخه‌های بهبود مستمر و اشتراک‌گذاری اطلاعات تهدید را تغذیه می‌کنند.

---

### 9.10 استراتژی استدلال عامل امنیت

انتخاب و اجرای امن استراتژی‌های مختلف استدلال از جمله روش‌های ReAct، زنجیره افکار (Chain-of-Thought) و درخت افکار (Tree-of-Thoughts).

 #9.10.1    سطح: 1    نقش: D/V
 تأیید کنید که انتخاب استراتژی استدلال از معیارهای قطعی (پیچیدگی ورودی، نوع وظیفه، زمینه امنیتی) استفاده می‌کند و ورودی‌های یکسان در همان زمینه امنیتی باعث انتخاب‌های استراتژی یکسان می‌شوند.
 #9.10.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر استراتژی استدلال (ReAct، زنجیره‌ای از تفکر، درخت تفکرات) دارای اعتبارسنجی ورودی اختصاصی، پاک‌سازی خروجی و محدودیت‌های زمان اجرای مشخص و مرتبط با رویکرد شناختی خود باشد.
 #9.10.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که انتقال‌های استراتژی استدلال با زمینه کامل شامل ویژگی‌های ورودی، مقادیر معیارهای انتخاب و فراداده‌های اجرا برای بازسازی مسیر حسابرسی ثبت شده‌اند.
 #9.10.4    سطح: 2    نقش: D/V
 تأیید کنید که استدلال درخت افکار شامل مکانیزم‌های هرس شاخه است که هنگامی که تخلفات سیاست، محدودیت‌های منابع یا مرزهای ایمنی تشخیص داده می‌شوند، اکتشاف را متوقف می‌کنند.
 #9.10.5    سطح: 2    نقش: D/V
 تأیید کنید که چرخه‌های ReAct (استدلال-عمل-مشاهده) شامل نقاط بازبینی اعتبارسنجی در هر مرحله هستند: تأیید گام استدلال، مجوز انجام عمل، و پاک‌سازی مشاهده قبل از ادامه دادن.
 #9.10.6    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که معیارهای عملکرد استراتژی استدلال (زمان اجرا، استفاده از منابع، کیفیت خروجی) با هشدارهای خودکار زمانی که معیارها از آستانه‌های پیکربندی شده فراتر می‌روند، تحت نظارت قرار می‌گیرند.
 #9.10.7    سطح: 3    نقش: D/V
 تأیید کنید که روش‌های استدلال هیبریدی که چندین استراتژی را ترکیب می‌کنند، اعتبارسنجی ورودی و محدودیت‌های خروجی همه استراتژی‌های تشکیل‌دهنده را حفظ می‌کنند بدون اینکه هیچ کنترل امنیتی‌ای را دور بزنند.
 #9.10.8    سطح: 3    نقش: D/V
 تأیید کنید که آزمایش امنیتی استراتژی استدلال شامل فازینگ با ورودی‌های معیوب، پرامپت‌های خصمانه طراحی شده برای مجبور کردن به تغییر استراتژی، و آزمایش شرایط مرزی برای هر روش شناختی است.

---

### 9.11 مدیریت حالت چرخه عمر عامل و امنیت

راه‌اندازی ایمن نماینده، انتقال وضعیت‌ها و خاتمه با ردپای حسابرسی رمزنگاری شده و روش‌های بازیابی تعریف‌شده.

 #9.11.1    سطح: 1    نقش: D/V
 تأیید کنید که راه‌اندازی عامل شامل برقراری هویت رمزنگاری شده با استفاده از اعتبارنامه‌های پشتیبانی شده توسط سخت‌افزار و گزارش‌های حسابرسی راه‌اندازی غیرقابل تغییر باشد که شامل شناسه عامل، زمان‌بندی، هش پیکربندی و پارامترهای راه‌اندازی است.
 #9.11.2    سطح: 2    نقش: D/V
 تأیید کنید که انتقال‌های وضعیت عامل به‌صورت رمزنگاری شده امضا شده، دارای مهر زمانی بوده و با زمینه کامل از جمله رویدادهای محرک، هش وضعیت قبلی، هش وضعیت جدید و اعتبارسنجی‌های امنیتی انجام شده، ثبت شده باشند.
 #9.11.3    سطح: 2    نقش: D/V
 تأیید کنید که فرآیندهای خاموش کردن عامل شامل پاک‌سازی ایمن حافظه با استفاده از حذف رمزنگاری شده یا بازنویسی چندباره، لغو مجوزها با اطلاع‌رسانی به مرجع صدور گواهینامه، و تولید گواهی‌های خاتمه مقاوم در برابر دستکاری باشد.
 #9.11.4    سطح: 3    نقش: D/V
 تایید کنید که مکانیزم‌های بازیابی عامل صحت یکپارچگی وضعیت را با استفاده از چکسام‌های رمزنگاری شده (حداقل SHA-256) اعتبارسنجی می‌کنند و در صورت شناسایی فساد، به حالت‌های شناخته‌شده و سالم بازمی‌گردند، همراه با هشدارهای خودکار و نیاز به تایید دستی.
 #9.11.5    سطح: 3    نقش: D/V
 تأیید کنید که مکانیزم‌های پایداری عامل داده‌های حساس حالت را با کلیدهای AES-256 اختصاصی برای هر عامل رمزنگاری می‌کنند و گردش کلید ایمن را با برنامه‌های زمان‌بندی قابل تنظیم (حداکثر 90 روز) با استقرار بدون توقف اجرا می‌کنند.

---

### چارچوب امنیتی یکپارچه‌سازی ابزار 9.12

کنترل‌های امنیتی برای بارگذاری پویا ابزار، اجرا و اعتبارسنجی نتایج با فرآیندهای تعریف‌شده ارزیابی ریسک و تایید.

 #9.12.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که توصیف‌گرهای ابزار شامل فراداده‌های امنیتی هستند که الزامات دسترسی (خواندن/نوشتن/اجرا)، سطوح ریسک (کم/متوسط/زیاد)، محدودیت‌های منابع (CPU، حافظه، شبکه) و نیازمندی‌های اعتبارسنجی که در مستندات ابزارها ثبت شده‌اند را مشخص می‌کنند.
 #9.12.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که نتایج اجرای ابزار با طرح‌های مورد انتظار (JSON Schema, XML Schema) و سیاست‌های امنیتی (پاک‌سازی خروجی، طبقه‌بندی داده‌ها) قبل از یکپارچه‌سازی با محدودیت‌های زمان‌بندی و روش‌های مدیریت خطا اعتبارسنجی شوند.
 #9.12.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که لاگ‌های تعامل ابزار شامل زمینه امنیتی دقیق از جمله استفاده از امتیازات، الگوهای دسترسی به داده‌ها، زمان اجرای فعالیت‌ها، مصرف منابع و کدهای بازگشتی با ثبت ساختاریافته برای ادغام با سیستم‌های SIEM باشد.
 #9.12.4    سطح: 2    نقش: D/V
 تأیید کنید که مکانیسم‌های بارگذاری دینامیک ابزارها، امضاهای دیجیتال را با استفاده از زیرساخت کلید عمومی (PKI) اعتبارسنجی می‌کنند و پروتکل‌های بارگذاری امن با جداسازی محیط اجرای محدود (sandbox) و تأیید مجوزها قبل از اجرا را پیاده‌سازی می‌کنند.
 #9.12.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که ارزیابی‌های امنیتی ابزار به صورت خودکار برای نسخه‌های جدید با مراحل تایید اجباری شامل تحلیل ایستا، آزمایش پویا و بازبینی تیم امنیتی با معیارهای تایید مستند و الزامات SLA به‌راه‌اندازی می‌شوند.

---

#### مراجع

MITRE ATLAS tactics ML09
Circuit-breaker research for AI agents — Zou et al., 2024
Trend Micro analysis of sandbox escapes in AI agents — Park, 2025
Auth0 guidance on human-in-the-loop authorization for agents — Martinez, 2025
Medium deep-dive on MCP & A2A protocol hijacking — ForAISec, 2025
Rapid7 fundamentals on spoofing attack prevention — 2024
Imperial College verification of swarm systems — Lomuscio et al.
NIST AI Risk Management Framework 1.0, 2023
WIRED security briefing on encryption best practices, 2024
OWASP Top 10 for LLM Applications, 2025
Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS
[How Is LLM Reasoning Distracted by Irrelevant Context?
An Analysis Using a Controlled Benchmark](https://www.arxiv.org/pdf/2505.18761)
Large Language Model Sentinel: LLM Agent for Adversarial Purification
Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents

## ۱۰ مقاومت مقابله‌ای و دفاع از حریم خصوصی

### هدف کنترل

اطمینان حاصل کنید که مدل‌های هوش مصنوعی در مواجهه با حملات دورزدن، استنتاج، استخراج یا مسموم‌سازی، قابل اعتماد، محافظت‌کننده از حریم خصوصی و مقاوم در برابر سوءاستفاده باقی می‌مانند.

---

### 10.1 هم‌راستایی مدل و ایمنی

محافظت در برابر خروجی‌های مضر یا نقض‌کننده سیاست‌ها.

 #10.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که یک مجموعه آزمایش هم‌ترازی (دستورات تیم قرمز، کاوش‌های فرار از محدودیت، محتویات ممنوعه) تحت کنترل نسخه قرار دارد و در هر انتشار مدل اجرا می‌شود.
 #10.1.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که موانع جلوگیری از امتناع و تکمیل ایمن اجرا می‌شوند.
 #10.1.3    سطح: 2    نقش: D/V
 تأیید کنید که یک ارزیاب خودکار نرخ محتوای مضر را اندازه‌گیری کرده و پسرفت‌ها را فراتر از یک آستانه تعیین شده علامت‌گذاری می‌کند.
 #10.1.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که آموزش ضد فرار از زندان مستند و قابل بازتولید است.
 #10.1.5    سطح: 3    نقش: V
 تأیید کنید که اثبات‌های انطباق با سیاست رسمی یا نظارت معتبر حوزه‌های حیاتی را پوشش می‌دهند.

---

### 10.2 سخت‌سازی نمونه‌های خصمانه

افزایش مقاومت در برابر ورودی‌های دستکاری شده. آموزش مقاوم در برابر حملات و ارزیابی معیارها بهترین روش‌های فعلی هستند.

 #10.2.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که مخازن پروژه شامل پیکربندی‌های آموزش مقابله‌ای با دانه‌های قابل بازتولید باشند.
 #10.2.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تشخیص نمونه‌های مخرب در خطوط تولید هشدارهای مسدودکننده ایجاد می‌کند.
 #10.2.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که اثبات‌های صحت مقاومتی تایید شده یا گواهی‌های بازه‌محدود حداقل کلاس‌های بحرانی برتر را پوشش می‌دهند.
 #10.2.5    سطح: 3    نقش: V
 تأیید کنید که آزمون‌های رگرسیون از حملات تطبیقی برای اطمینان از عدم کاهش قابل اندازه‌گیری در مقاومت استفاده می‌کنند.

---

### 10.3 کاهش استنباط عضویت

محدود کردن توانایی تصمیم‌گیری درباره اینکه آیا یک رکورد در داده‌های آموزش بوده است یا خیر. محرمانگی تفاضلی و ماسک‌گذاری امتیاز اطمینان همچنان مؤثرترین دفاع‌های شناخته‌شده هستند.

 #10.3.1    سطح: 1    نقش: D
 تأیید کنید که منظم‌سازی آنتروپی به ازای هر پرس‌وجو یا مقیاس‌بندی دما پیش‌بینی‌های بیش‌اعتماد را کاهش می‌دهد.
 #10.3.2    سطح: 2    نقش: D
 تأیید کنید که آموزش از بهینه‌سازی متفاوت-خصوصی با کران ε برای مجموعه داده‌های حساس استفاده می‌کند.
 #10.3.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که شبیه‌سازی‌های حمله (مدل سایه یا جعبه سیاه) مقدار AUC حمله ≤ 0.60 را روی داده‌های کنار گذاشته شده نشان دهند.

---

### 10.4 مقاومت در برابر معکوس‌سازی مدل

جلوگیری از بازسازی ویژگی‌های خصوصی. نظرسنجی‌های اخیر بر برش خروجی و تضمین‌های DP به‌عنوان دفاع‌های عملی تأکید دارند.

 #10.4.1    سطح: 1    نقش: D
 تأیید کنید که ویژگی‌های حساس هرگز به طور مستقیم خروجی داده نشوند؛ در صورت نیاز، از بکت‌ها یا تبدیلات یک‌طرفه استفاده کنید.
 #10.4.2    سطح: 1    نقش: D/V
 تأیید کنید که محدودیت‌های نرخ پرس‌وجو، پرس‌وجوهای تطبیقی مکرر از همان مرجع را محدود می‌کنند.
 #10.4.3    سطح: 2    نقش: D
 تأیید کنید که مدل با نویز حفظ‌کننده حریم خصوصی آموزش داده شده باشد.

---

### 10.5 دفاع در برابر استخراج مدل

شناسایی و جلوگیری از تکثیر غیرمجاز. علامت‌گذاری آبی (واترمارک) و تحلیل الگوی پرس‌وجو توصیه می‌شود.

 #10.5.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که دروازه‌های استنتاج محدودیت‌های نرخ کلی و محدودیت‌های نرخ خاص هر کلید API را که به آستانه حفظ مدل تنظیم شده‌اند، اعمال می‌کنند.
 #10.5.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که آمارهای انتروپی پرس‌و‌جو و تعداد جمع ورودی در تغذیه یک آشکارساز استخراج خودکار نقش دارند.
 #10.5.3    سطح: 2    نقش: V
 تأیید کنید که واترمارک‌های شکننده یا احتمالاتی می‌توانند با p < 0.01 در ≤ 1 000 پرس‌وجو علیه یک کلون مشکوک اثبات شوند.
 #10.5.4    سطح: 3    نقش: D
 اطمینان حاصل کنید که کلیدهای واترمارک و مجموعه‌های محرک در ماژول امنیت سخت‌افزاری ذخیره شده و سالانه تغییر می‌یابند.
 #10.5.5    سطح: 3    نقش: V
 تأیید کنید که رویدادهای استخراج-هشدار شامل پرس و جوهای تخلف‌کننده باشند و با کتاب‌های راهنمای پاسخ به حادثه یکپارچه شده باشند.

---

### 10.6 تشخیص داده‌های آلوده در زمان استنتاج

ورودی‌های دارای بک‌دور یا آلوده شده را شناسایی و خنثی کنید.

 #10.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که ورودی‌ها قبل از استنتاج مدل از طریق یک آشکارساز ناهنجاری (مثلاً STRIP، امتیازدهی سازگاری) عبور کنند.
 #10.6.2    سطح: 1    نقش: V
 بررسی کنید که آستانه‌های آشکارساز بر روی مجموعه‌های اعتبارسنجی تمیز/آلوده تنظیم شده باشند تا کمتر از ۵٪ مثبت کاذب حاصل شود.
 #10.6.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که ورودی‌هایی که به عنوان آلوده شده علامت‌گذاری شده‌اند، روندهای مسدودسازی نرم و بازبینی انسانی را فعال می‌کنند.
 #10.6.4    سطح: 2    نقش: V
 تأیید کنید که آشکارسازها با حملات پشتی مخفی بدون ماشه و تطبیقی به‌طور تحت فشار آزمون قرار می‌گیرند.
 #10.6.5    سطح: 3    نقش: D
 اطمینان حاصل کنید که معیارهای اثربخشی تشخیص ثبت شده و به طور دوره‌ای با اطلاعات تهدید تازه بازبینی می‌شوند.

---

### 10.7 انطباق پویای سیاست امنیتی

به‌روزرسانی‌های سیاست امنیتی به‌صورت زنده بر اساس اطلاعات تهدید و تحلیل رفتاری.

 #10.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیاست‌های امنیتی می‌توانند به‌صورت پویا بدون راه‌اندازی مجدد عاملی به‌روزرسانی شوند در حالی که صحت نسخه سیاست حفظ می‌شود.
 #10.7.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که به‌روزرسانی‌های سیاست به‌صورت رمزنگاری‌شده توسط کارکنان امنیتی مجاز امضا شده و قبل از اعمال اعتبارسنجی شده‌اند.
 #10.7.3    سطح: 2    نقش: D/V
 تأیید کنید که تغییرات سیاست پویا با سوابق کامل حسابرسی شامل توجیه، زنجیره‌های تأیید و روش‌های بازگشت ثبت می‌شوند.
 #10.7.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های امنیت تطبیقی حساسیت شناسایی تهدید را بر اساس زمینه ریسک و الگوهای رفتاری تنظیم می‌کنند.
 #10.7.5    سطح: 3    نقش: D/V
 تأیید کنید که تصمیمات سازگاری سیاست قابل توضیح باشند و شامل مسیرهای شواهد برای بازبینی تیم امنیتی باشند.

---

### 10.8 تحلیل امنیت مبتنی بر بازتاب

اعتبارسنجی امنیت از طریق خوداندیشی عامل و تحلیل متا-شناختی.

 #10.8.1    سطح: 1    نقش: D/V
 تأیید کنید که مکانیزم‌های بازتاب عامل شامل ارزیابی خودی با تمرکز بر امنیت در تصمیمات و اقدامات می‌باشد.
 #10.8.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که خروجی‌های بازتابی اعتبارسنجی می‌شوند تا از دستکاری مکانیزم‌های خودارزیابی توسط ورودی‌های خصمانه جلوگیری شود.
 #10.8.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تحلیل امنیت متاکاگنیتیو، تعصبات احتمالی، دستکاری یا به خطر افتادن فرآیندهای استدلال عامل را شناسایی می‌کند.
 #10.8.4    سطح: 3    نقش: D/V
 تأیید کنید که هشدارهای امنیتی مبتنی بر بازتاب باعث فعال شدن نظارت پیشرفته و جریان‌های کاری احتمالی مداخله انسانی می‌شوند.
 #10.8.5    سطح: 3    نقش: D/V
 تأیید کنید که یادگیری مداوم از بازتاب‌های امنیتی، تشخیص تهدید را بهبود می‌بخشد بدون اینکه عملکرد قانونی را تخریب کند.

---

### ۱۰.۹ امنیت تکامل و خودبهبود

کنترل‌های امنیتی برای سیستم‌های عامل که قادر به خودتعدیلی و تکامل هستند.

 #10.9.1    سطح: 1    نقش: D/V
 تأیید کنید که قابلیت‌های خود-تغییردهی محدود به نواحی ایمن مشخص شده با مرزهای رسمی تأیید شده باشند.
 #10.9.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که پیشنهادهای تکامل قبل از اجرا تحت ارزیابی تاثیر امنیتی قرار می‌گیرند.
 #10.9.3    سطح: 2    نقش: D/V
 تأیید کنید که مکانیزم‌های خودبهبودی شامل قابلیت‌های بازگشت به عقب همراه با تأیید صحت باشند.
 #10.9.4    سطح: 3    نقش: D/V
 تأیید کنید که امنیت یادگیری فرادانشی از دستکاری مخرب الگوریتم‌های بهبود جلوگیری می‌کند.
 #10.9.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که بهبود خودبازگشتی توسط محدودیت‌های رسمی ایمنی محدود شده است با اثبات‌های ریاضی همگرایی.

---

#### مراجع

MITRE ATLAS adversary tactics for ML
NIST AI Risk Management Framework 1.0, 2023
OWASP Top 10 for LLM Applications, 2025
Adversarial Training: A Survey — Zhao et al., 2024
RobustBench adversarial-robustness benchmark
Membership-Inference & Model-Inversion Risk Survey, 2025
PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023
Model-Inversion Attacks & Defenses Survey — AI Review, 2025
Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024
Fragile Model Watermarking Survey — 2025
Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025
BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024

## 11 حفاظت از حریم خصوصی و مدیریت داده‌های شخصی

### هدف کنترل

حفظ تضمین‌های سختگیرانه حفظ حریم خصوصی در سراسر چرخه عمر هوش مصنوعی—جمع‌آوری، آموزش، استنتاج، و پاسخ به حادثه—به گونه‌ای که داده‌های شخصی فقط با رضایت واضح، حداقل دامنه لازم، حذف قابل اثبات، و تضمین‌های رسمی حریم خصوصی پردازش شوند.

---

### 11.1 ناشناس‌سازی و حداقل‌سازی داده‌ها

 #11.1.1    سطح: 1    نقش: D/V
 بررسی کنید که شناسه‌های مستقیم و شبه‌شناسه‌ها حذف یا هش شده‌اند.
 #11.1.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که بازرسی‌های خودکار میزان k-ناشناس بودن/l-تنوع را اندازه‌گیری کرده و هنگامی که آستانه‌ها به زیر سیاست مقرر کاهش می‌یابند، هشدار می‌دهند.
 #11.1.3    سطح: 2    نقش: V
 تأیید کنید که گزارش‌های اهمیت ویژگی مدل نشان می‌دهند که هیچ نشت شناسه‌ای فراتر از ε = 0.01 اطلاعات متقابل وجود ندارد.
 #11.1.4    سطح: 3    نقش: V
 تأیید کنید که اثبات‌های رسمی یا گواهی‌نامه داده‌های ترکیبی نشان می‌دهند که ریسک بازشناسایی حتی در شرایط حملات پیوندی کمتر یا برابر با 0.05 است.

---

### 11.2 حق به فراموشی و اجرای حذف

 #11.2.1    سطح: 1    نقش: D/V
 تأیید کنید که درخواست‌های حذف داده‌های موضوع، به مجموعه داده‌های خام، نقاط بررسی، توصیف‌ها، لاگ‌ها و نسخه‌های پشتیبان در چارچوب توافق‌نامه‌های سطح خدمات کمتر از 30 روز منتقل می‌شوند.
 #11.2.2    سطح: 2    نقش: D
 تأیید کنید که روتین‌های "فراموشی ماشین" به‌طور فیزیکی بازآموزش می‌دهند یا حذف تقریباً نزدیک را با استفاده از الگوریتم‌های فراموشی معتبر انجام می‌دهند.
 #11.2.3    سطح: 2    نقش: V
 تأیید کنید که ارزیابی مدل سایه‌ای نشان می‌دهد رکوردهای فراموش شده کمتر از 1٪ از خروجی‌ها را پس از فراموشی تحت تأثیر قرار می‌دهند.
 #11.2.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که رویدادهای حذف به صورت غیرقابل تغییر ثبت شده و برای ناظران قابل ممیزی باشد.

---

### 11.3 تدابیر حفظ حریم خصوصی تفاضلی

 #11.3.1    سطح: 2    نقش: D/V
 تأیید کنید که داشبوردهای حسابداری ضرر حریم خصوصی هنگام عبور مقدار تجمعی ε از آستانه‌های سیاست هشدار می‌دهند.
 #11.3.2    سطح: 2    نقش: V
 تأیید کنید که ممیزی‌های خصوصی‌سازی جعبه‌سیاه، ε̂ را در حدود 10٪ از مقدار اعلام‌شده تخمین می‌زنند.
 #11.3.3    سطح: 3    نقش: V
 اطمینان حاصل کنید که اثبات‌های رسمی تمامی تنظیمات دقیق و تعبیه‌های پس از آموزش را پوشش می‌دهند.

---

### 11.4 حفاظت محدودیت هدف و جلوگیری از گسترش دامنه

 #11.4.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که هر مجموعه داده و نقطه بررسی مدل دارای یک برچسب هدف قابل خواندن توسط ماشین است که با رضایت اصلی هماهنگ باشد.
 #11.4.2    سطح: 1    نقش: D/V
 تأیید کنید که مانیتورهای زمان اجرا کوئری‌های ناسازگار با هدف اعلام شده را شناسایی کرده و باعث رد نرم شوند.
 #11.4.3    سطح: 3    نقش: D
 اطمینان حاصل کنید که دروازه‌های سیاست به صورت کد، مانع از استقرار مجدد مدل‌ها در دامنه‌های جدید بدون مرور DPIA می‌شوند.
 #11.4.4    سطح: 3    نقش: V
 تأیید کنید که اثبات‌های رسمی قابلیت ردیابی نشان می‌دهند هر چرخه عمر داده‌های شخصی در محدوده موافقت شده باقی می‌ماند.

---

### 11.5 مدیریت رضایت و ردیابی بر اساس مبنای قانونی

 #11.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که یک پلتفرم مدیریت رضایت (CMP) وضعیت انتخاب (opt-in)، هدف و دوره نگهداری را برای هر موضوع داده ثبت می‌کند.
 #11.5.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که APIها توکن‌های رضایت را افشا می‌کنند؛ مدل‌ها باید دامنه توکن را قبل از استنتاج معتبر سازند.
 #11.5.3    سطح: 2    نقش: D/V
 تأیید کنید که رضایت رد شده یا پس گرفته شده، خطوط پردازش را ظرف 24 ساعت متوقف می‌کند.

---

### 11.6 یادگیری فدراسیون با کنترل‌های حریم خصوصی

 #11.6.1    سطح: 1    نقش: D
 تأیید کنید که به‌روزرسانی‌های کلاینت پیش از تجمیع از افزودن نویز حریم خصوصی تفاضلی محلی استفاده می‌کنند.
 #11.6.2    سطح: 2    نقش: D/V
 تأیید کنید که معیارهای آموزش به صورت خصوصی تفاضلی هستند و هرگز خطای یک مشتری منفرد را فاش نمی‌کنند.
 #11.6.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که تجمیع مقاوم در برابر مسمومیت (مانند Krum/Trimmed-Mean) فعال است.
 #11.6.4    سطح: 3    نقش: V
 تأیید کنید که اثبات‌های رسمی نشان می‌دهند بودجه کلی ε با کمتر از ۵ واحد کاهش کارایی است.

---

#### مراجع

GDPR & AI Compliance Best Practices
EU Parliament Study on GDPR & AI, 2020
ISO 31700-1:2023 — Privacy by Design for Consumer Products
NIST Privacy Framework 1.1 (2025 Draft)
Machine Unlearning: Right-to-Be-Forgotten Techniques
A Survey of Machine Unlearning, 2024
Auditing DP-SGD — ArXiv 2024
DP-SGD Explained — PyTorch Blog
Purpose-Limitation for AI — IJLIT 2025
Data-Protection Considerations for AI — URM Consulting
Top Consent-Management Platforms, 2025
Secure Aggregation in DP Federated Learning — ArXiv 2024

## پایش، ثبت وقایع و تشخیص ناهنجاری C12

### هدف کنترل

این بخش نیازمندی‌هایی را برای ارائه دید زنده و قانونی به آنچه مدل و دیگر اجزای هوش مصنوعی مشاهده، انجام و بازگردانی می‌کنند، فراهم می‌کند تا تهدیدات قابل‌شناسایی، اولویت‌بندی و مورد یادگیری قرار گیرند.

### C12.1 ثبت درخواست و پاسخ

 #12.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام اعلان‌های کاربر و پاسخ‌های مدل با فراداده‌های مناسب (مانند زمان‌سنجی، شناسه کاربر، شناسه جلسه، نسخه مدل) ثبت می‌شوند.
 #12.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که لاگ‌ها در مخازن ایمن با کنترل دسترسی مناسب و سیاست‌های نگهداری و فرآیندهای پشتیبان‌گیری مناسب ذخیره می‌شوند.
 #12.1.3    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های ذخیره‌سازی لاگ، رمزگذاری در حالت استراحت (at rest) و در حین انتقال (in transit) را برای حفاظت از اطلاعات حساس موجود در لاگ‌ها اعمال می‌کنند.
 #12.1.4    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که داده‌های حساس در پرامپت‌ها و خروجی‌ها به‌طور خودکار قبل از ثبت، مخفی یا ماسک می‌شوند، با قوانین قابل تنظیم برای مخفی‌سازی اطلاعات شناسایی شخصی (PII)، مدارک ورود، و اطلاعات مالکیتی.
 #12.1.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تصمیمات سیاستی و اقدامات فیلترینگ ایمنی با جزئیات کافی ثبت می‌شوند تا امکان حسابرسی و اشکال‌زدایی سیستم‌های نظارت بر محتوا فراهم گردد.
 #12.1.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که یکپارچگی گزارش‌ها از طریق مثلاً امضاهای رمزنگاری یا ذخیره‌سازی فقط-نوشتنی محافظت می‌شود.

---

### C12.2 تشخیص سوءاستفاده و هشداردهی

 #12.2.1    سطح: 1    نقش: D/V
 تأیید کنید که سیستم الگوهای شناخته شده جیلبریک، تلاش‌های تزریق درخواست و ورودی‌های دشمنانه را با استفاده از تشخیص مبتنی بر امضا شناسایی و هشدار می‌دهد.
 #12.2.2    سطح: 1    نقش: D/V
 تأیید کنید که سیستم با استفاده از فرمت‌ها و پروتکل‌های استاندارد لاگ، با پلتفرم‌های موجود مدیریت اطلاعات و رویدادهای امنیتی (SIEM) یکپارچه می‌شود.
 #12.2.3    سطح: 2    نقش: D/V
 تأیید کنید که رویدادهای امنیتی غنی‌شده شامل زمینه‌های خاص هوش مصنوعی مانند شناسه‌های مدل، امتیازهای اطمینان، و تصمیمات فیلتر ایمنی باشند.
 #12.2.4    سطح: 2    نقش: D/V
 تأیید کنید که تشخیص ناهنجاری رفتاری الگوهای غیرمعمول گفتگو، تلاش‌های مکرر بیش از حد، یا رفتارهای کاوش سیستماتیک را شناسایی می‌کند.
 #12.2.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های هشدار دهی در زمان واقعی، تیم‌های امنیتی را هنگام شناسایی نقض‌های احتمالی سیاست یا تلاش‌های حمله مطلع می‌کنند.
 #12.2.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که قوانین سفارشی برای شناسایی الگوهای خاص تهدیدات هوش مصنوعی از جمله تلاش‌های هماهنگ شده برای دور زدن محدودیت‌ها (jailbreak)، کمپین‌های تزریق درخواست (prompt injection)، و حملات استخراج مدل گنجانده شده‌اند.
 #12.2.7    سطح: 3    نقش: D/V
 تأیید کنید که گردش‌کارهای واکنش خودکار به حادثه قادر به جداکردن مدل‌های به خطر افتاده، مسدود کردن کاربران مخرب و افزایش رویدادهای امنیتی حیاتی هستند.

---

### C12.3 تشخیص انحراف مدل

 #12.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم معیارهای عملکرد پایه مانند دقت، نمرات اطمینان، تأخیر، و نرخ‌های خطا را در نسخه‌های مدل و بازه‌های زمانی مختلف رصد می‌کند.
 #12.3.2    سطح: 2    نقش: D/V
 تأیید کنید که هشدارهای خودکار زمانی فعال می‌شوند که معیارهای عملکرد از آستانه‌های کاهش تعریف‌شده فراتر رفته یا به‌طور قابل توجهی از خطوط پایه منحرف شوند.
 #12.3.3    سطح: 2    نقش: D/V
 تأیید کنید که مانیتورهای تشخیص هذیان بتوانند مواردی را که خروجی‌های مدل شامل اطلاعات نادرست، ناسازگار یا ساختگی هستند، شناسایی و علامت‌گذاری کنند.

---

### C12.4 داده‌کاوی عملکرد و رفتار

 #12.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که معیارهای عملیاتی شامل تأخیر درخواست، مصرف توکن، استفاده از حافظه، و توان عملیاتی به طور مداوم جمع‌آوری و نظارت می‌شوند.
 #12.4.2    سطح: 1    نقش: D/V
 تایید کنید که نرخ‌های موفقیت و شکست با دسته‌بندی انواع خطاها و علل ریشه‌ای آنها پیگیری می‌شوند.
 #12.4.3    سطح: 2    نقش: D/V
 تأیید کنید که نظارت بر استفاده منابع شامل استفاده از GPU/CPU، مصرف حافظه و نیازهای ذخیره‌سازی باشد و هشدار در صورت عبور از آستانه‌ها فعال باشد.

---

### C12.5 برنامه‌ریزی و اجرای واکنش به حادثه AI

 #12.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که برنامه‌های پاسخ به حادثه به‌طور خاص به رویدادهای امنیتی مرتبط با هوش مصنوعی از جمله نفوذ به مدل، آلودگی داده‌ها، و حملات خصمانه پرداخته‌اند.
 #12.5.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تیم‌های پاسخ به حادثه به ابزارهای پزشکی قانونی مخصوص هوش مصنوعی و تخصص لازم برای بررسی رفتار مدل و بردارهای حمله دسترسی دارند.
 #12.5.3    سطح: 3    نقش: D/V
 تأیید کنید که تحلیل پس از حادثه شامل ملاحظات بازآموزی مدل، به‌روزرسانی فیلترهای ایمنی و ادغام درس‌های آموخته شده در کنترل‌های امنیتی است.

---

### C12.5 تشخیص کاهش عملکرد هوش مصنوعی

نظارت و شناسایی کاهش عملکرد و کیفیت مدل هوش مصنوعی در طول زمان.

 #12.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که دقت مدل، دقت (precision)، بازیابی (recall) و امتیازهای F1 به‌صورت مداوم نظارت شده و با آستانه‌های پایه مقایسه می‌شوند.
 #12.5.2    سطح: 1    نقش: D/V
 تأیید کنید که شناسایی تغییر داده‌ها، تغییرات توزیع ورودی را که ممکن است بر عملکرد مدل تأثیر بگذارد، نظارت می‌کند.
 #12.5.3    سطح: 2    نقش: D/V
 تأیید کنید که تشخیص تغییر مفهوم (concept drift) تغییرات در رابطه بین ورودی‌ها و خروجی‌های مورد انتظار را شناسایی می‌کند.
 #12.5.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که کاهش عملکرد باعث فعال شدن هشدارهای خودکار شده و فرآیندهای بازآموزی یا جایگزینی مدل را آغاز می‌کند.
 #12.5.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که تحلیل ریشه‌ای علت افت کیفیت، کاهش عملکرد را با تغییرات داده، مشکلات زیرساخت یا عوامل خارجی مرتبط می‌سازد.

---

### C12.6 تجسم DAG و امنیت جریان کاری

سیستم‌های تجسم جریان کاری را در برابر نشت اطلاعات و حملات دستکاری محافظت کنید.

 #12.6.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که داده‌های تجسم گراف جهت‌دار غیر循回 (DAG) پیش از ذخیره‌سازی یا انتقال، پاک‌سازی شده و اطلاعات حساس از آن حذف شده باشد.
 #12.6.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که کنترل‌های دسترسی به تجسم جریان کاری تنها به کاربران مجاز اجازه می‌دهند تا مسیرهای تصمیم‌گیری عامل و ردپاهای استدلال را مشاهده کنند.
 #12.6.3    سطح: 2    نقش: D/V
 تأیید کنید که یکپارچگی داده‌های DAG از طریق امضاهای رمزنگاری شده و مکانیزم‌های ذخیره‌سازی قابل تشخیص تغییر محافظت می‌شود.
 #12.6.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های نمایش جریان کاری، اعتبارسنجی ورودی را پیاده‌سازی کرده‌اند تا از حملات تزریق از طریق داده‌های ساختگی گره یا یال جلوگیری کنند.
 #12.6.5    سطح: 3    نقش: D/V
 تأیید کنید که به‌روزرسانی‌های DAG در زمان واقعی محدود به نرخ و معتبر شده‌اند تا از حملات انکار سرویس بر روی سیستم‌های نمایش جلوگیری شود.

---

### C12.7 نظارت پیشگیرانه بر رفتار امنیتی

شناسایی و پیشگیری از تهدیدات امنیتی از طریق تحلیل رفتار پیشگیرانه عامل.

 #12.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که رفتارهای پیشگیرانه عامل قبل از اجرا با ادغام ارزیابی ریسک از نظر امنیتی تایید شده‌اند.
 #12.7.2    سطح: 2    نقش: D/V
 تأیید کنید که محرک‌های ابتکار خودمختار شامل ارزیابی زمینه امنیتی و ارزیابی چشم‌انداز تهدید می‌باشند.
 #12.7.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که الگوهای رفتار فعال برای پیامدهای امنیتی احتمالی و عواقب ناخواسته تحلیل می‌شوند.
 #12.7.4    سطح: 3    نقش: D/V
 تأیید کنید که اقدامات پیشگیرانه بحرانی امنیتی نیازمند زنجیره‌های تصویب صریح همراه با سوابق حسابرسی هستند.
 #12.7.5    سطح: 3    نقش: D/V
 تأیید کنید که تشخیص ناهنجاری رفتاری انحرافات در الگوهای عامل پیشگیرانه را که ممکن است نشان‌دهنده نفوذ باشد، شناسایی می‌کند.

---

### مراجع

NIST AI Risk Management Framework 1.0 - Manage 4.1 and 4.3
ISO/IEC 42001:2023 — AI Management Systems Requirements - Annex B 6.2.6
EU AI Act — Article 12, 13, 16 and 19 on Logging and Record-keeping

## C13 نظارت انسانی، مسئولیت‌پذیری و حاکمیت

### هدف کنترل

این فصل الزامات حفظ نظارت انسانی و زنجیره‌های مسئولیت شفاف در سیستم‌های هوش مصنوعی را فراهم می‌کند، به‌گونه‌ای که قابلیت توضیح‌پذیری، شفافیت و مدیریت اخلاقی در طول چرخه عمر هوش مصنوعی تضمین شود.

---

### C13.1 مکانیزم‌های خاموش‌کننده اضطراری و دسترسی بازنویسی

در صورت مشاهده رفتار ناامن از سیستم هوش مصنوعی، مسیرهای خاموش‌کردن یا بازگشت را فراهم کنید.

 #13.1.1    سطح: 1    نقش: D/V
 بررسی کنید که مکانیزم خاموش‌کن دستی برای توقف فوری استنتاج و خروجی‌های مدل هوش مصنوعی وجود دارد.
 #13.1.2    سطح: 1    نقش: D
 تأیید کنید که کنترل‌های بازنویسی فقط برای پرسنل مجاز قابل دسترسی باشند.
 #13.1.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که رویه‌های بازگشت قادر به بازگرداندن به نسخه‌های قبلی مدل یا عملیات حالت ایمن هستند.
 #13.1.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که مکانیزم‌های جایگزینی به طور منظم آزمایش می‌شوند.

---

### C13.2 نقاط کنترل تصمیم‌گیری با انسان در چرخه

در صورت عبور میزان ریسک از آستانه‌های از پیش تعیین شده، نیاز به تأییدیه انسانی باشد.

 #13.2.1    سطح: 1    نقش: D/V
 تأیید کنید که تصمیمات هوش مصنوعی با ریسک بالا قبل از اجرا نیازمند تأیید صریح انسانی هستند.
 #13.2.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که آستانه‌های ریسک به وضوح تعریف شده‌اند و به‌طور خودکار فرآیندهای بازبینی انسانی را فعال می‌کنند.
 #13.2.3    سطح: 2    نقش: D
 تأیید کنید که تصمیمات حساس به زمان دارای رویه‌های پشتیبان هستند زمانی که تأیید انسانی در بازه‌های زمانی مورد نیاز قابل دستیابی نباشد.
 #13.2.4    سطح: 3    نقش: D/V
 تائید کنید که رویه‌های افزایش سطح اختیارات، سطوح واضحی از قدرت تصمیم‌گیری برای انواع مختلف تصمیمات یا دسته‌بندی‌های ریسک تعریف می‌کنند، در صورت وجود.

---

### C13.3 زنجیره مسئولیت و قابلیت حسابرسی

اقدامات اپراتور و تصمیمات مدل را ثبت کنید.

 #13.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام تصمیمات سیستم هوش مصنوعی و مداخلات انسانی همراه با زمان‌بندی‌های زمانی، هویت کاربران و دلایل تصمیم‌گیری ثبت می‌شوند.
 #13.3.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که لاگ‌های ممیزی قابل دستکاری نباشند و مکانیزم‌های بررسی صحت را شامل شوند.

---

### C13.4 تکنیک‌های هوش مصنوعی قابل توضیح

اهمیت ویژگی سطحی، موارد متضاد، و توضیحات محلی.

 #13.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های هوش مصنوعی توضیحات پایه‌ای درباره تصمیمات خود به صورت قابل خواندن برای انسان ارائه می‌دهند.
 #13.4.2    سطح: 2    نقش: V
 اطمینان حاصل کنید که کیفیت توضیحات از طریق مطالعات و معیارهای ارزیابی انسانی تأیید شده است.
 #13.4.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که نمرات اهمیت ویژگی‌ها یا روش‌های انتساب (SHAP، LIME و غیره) برای تصمیمات حیاتی در دسترس هستند.
 #13.4.4    سطح: 3    نقش: V
 تأیید کنید که توضیحات کانتر فاکچوال نشان می‌دهند چگونه ورودی‌ها می‌توانند اصلاح شوند تا نتایج تغییر کنند، در صورت اعمال به مورد استفاده و حوزه مربوطه.

---

### C13.5 کارت‌های مدل و افشای استفاده

نگهداری کارت‌های مدل برای استفاده مدنظر، معیارهای عملکرد و ملاحظات اخلاقی.

 #13.5.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که کارت‌های مدل موارد استفاده مورد نظر، محدودیت‌ها و حالت‌های شکست شناخته شده را مستند می‌کنند.
 #13.5.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که معیارهای عملکرد در موارد استفاده مختلف قابل اجرا فاش شده‌اند.
 #13.5.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که ملاحظات اخلاقی، ارزیابی‌های تعصب، ارزیابی‌های عدالت، ویژگی‌های داده‌های آموزشی و محدودیت‌های شناخته‌شده داده‌های آموزشی به طور منظم مستندسازی و به‌روزرسانی می‌شوند.
 #13.5.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که کارت‌های مدل تحت کنترل نسخه قرار دارند و در طول چرخه عمر مدل با ردیابی تغییرات نگهداری می‌شوند.

---

### C13.6 کمّی‌سازی عدم قطعیت

اطمینان‌سنجی یا اندازه‌گیری‌های آنتروپی را در پاسخ‌ها انتشار دهید.

 #13.6.1    سطح: 1    نقش: D
 تأیید کنید که سیستم‌های هوش مصنوعی همراه با خروجی‌های خود امتیازهای اطمینان یا معیارهای عدم قطعیت ارائه می‌دهند.
 #13.6.2    سطح: 2    نقش: D/V
 تأیید کنید که آستانه‌های عدم قطعیت موجب بررسی بیشتر توسط انسان یا مسیرهای تصمیم‌گیری جایگزین می‌شوند.
 #13.6.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که روش‌های کمّی‌سازی عدم قطعیت کالیبره شده و در برابر داده‌های حقیقت مبنا اعتبارسنجی شده‌اند.
 #13.6.4    سطح: 3    نقش: D/V
 تأیید کنید که انتشار عدم قطعیت در جریان‌های کاری چند مرحله‌ای هوش مصنوعی حفظ می‌شود.

---

### C13.7 گزارش‌های شفافیت قابل مشاهده برای کاربر

افشای دوره‌ای درباره حوادث، انحراف و استفاده از داده‌ها فراهم کنید.

 #13.7.1    سطح: 1    نقش: D/V
 تأیید کنید که سیاست‌های استفاده از داده‌ها و شیوه‌های مدیریت رضایت کاربران به‌صورت واضح به ذینفعان اطلاع داده شده باشد.
 #13.7.2    سطح: 2    نقش: D/V
 تأیید کنید که ارزیابی‌های تأثیر هوش مصنوعی انجام شده و نتایج در گزارش‌دهی گنجانده شده‌اند.
 #13.7.3    سطح: 2    نقش: D/V
 تأیید کنید که گزارش‌های شفافیت منتشر شده به‌صورت منظم، حوادث هوش مصنوعی و شاخص‌های عملیاتی را با جزئیات معقول افشا می‌کنند.

#### مراجع

EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
ISO/IEC 42001:2023 — AI Management Systems Requirements
NIST AI Risk Management Framework 1.0
NIST SP 800-53 Revision 5 — Security and Privacy Controls
A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)
Model Cards for Model Reporting (Mitchell et al., 2018)
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)
ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods
IEEE 7001-2021 — Transparency of Autonomous Systems
GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)
Human Oversight under Article 14 of the EU AI Act (Fink, 2025)

## ضمیمه A: واژه‌نامه

این واژه‌نامه جامع تعریف‌های اصطلاحات کلیدی هوش مصنوعی، یادگیری ماشینی و امنیت را که در سراسر AISVS استفاده شده‌اند فراهم می‌کند تا وضوح و درک مشترک تضمین شود.

مثال مخرب: ورودی‌ای که به طور عمدی طراحی شده است تا یک مدل هوش مصنوعی را به اشتباه اندازد، معمولاً با افزودن تغییرات ظریف که برای انسان‌ها قابل درک نیستند.
​
استحکام مقابل حملات خصمانه – استحکام مقابل حملات خصمانه در هوش مصنوعی به توانایی یک مدل برای حفظ عملکرد خود و مقاوم بودن در برابر فریب دادن یا دستکاری توسط ورودی‌های عمدی و مخرب طراحی شده برای ایجاد خطا اشاره دارد.
​
عامل – عامل‌های هوش مصنوعی سیستم‌های نرم‌افزاری هستند که از هوش مصنوعی برای دنبال کردن اهداف و انجام وظایف به نمایندگی از کاربران استفاده می‌کنند. آنها دارای قابلیت‌های استدلال، برنامه‌ریزی و حافظه هستند و سطحی از استقلال دارند تا تصمیم گیری کنند، یاد بگیرند و سازگار شوند.
​
هوش مصنوعی عاملی: سیستم‌های هوش مصنوعی که قادر به عمل کردن با درجه‌ای از خودمختاری برای دستیابی به اهداف هستند و اغلب بدون دخالت مستقیم انسان تصمیم‌گیری و اقدام می‌کنند.
​
کنترل دسترسی مبتنی بر صفات (ABAC): یک الگوی کنترل دسترسی که در آن تصمیمات اعطای دسترسی بر اساس صفات کاربر، منبع، عمل و محیط، که در زمان پرس و جو ارزیابی می‌شوند، اتخاذ می‌گردد.
​
حمله درب پشتی: نوعی حمله مسموم‌سازی داده که در آن مدل طوری آموزش داده می‌شود که به صورت خاص به محرک‌های خاص پاسخ دهد در حالی که در غیر این صورت به طور عادی رفتار می‌کند.
​
سوگیری: خطاهای سیستماتیک در خروجی‌های مدل‌های هوش مصنوعی که می‌تواند به نتایج ناعادلانه یا تبعیض‌آمیز برای گروه‌های خاص یا در زمینه‌های مشخص منجر شود.
​
بهره‌برداری از تبعیض: یک تکنیک حمله که از تعصبات شناخته‌شده در مدل‌های هوش مصنوعی برای دستکاری خروجی‌ها یا نتایج استفاده می‌کند.
​
سدار: زبان سیاست و موتور آمازون برای مجوزهای دقیق که در پیاده‌سازی کنترل دسترسی مبتنی بر ویژگی (ABAC) برای سیستم‌های هوش مصنوعی استفاده می‌شود.
​
زنجیره تفکر: تکنیکی برای بهبود استدلال در مدل‌های زبانی با تولید مراحل میانی استدلال قبل از ارائه پاسخ نهایی.
​
قطع‌کننده‌های مدار: مکانیزم‌هایی که به‌طور خودکار عملیات سیستم هوش مصنوعی را زمانی که آستانه‌های ریسک خاصی عبور می‌کنند، متوقف می‌کنند.
​
نشت داده: افشای ناخواسته اطلاعات حساس از طریق خروجی‌ها یا رفتار مدل هوش مصنوعی.
​
آلوده‌سازی داده‌ها: خرابکاری عمدی در داده‌های آموزشی برای به خطر انداختن صحت مدل، که اغلب به منظور نصب درهای پشتی یا کاهش عملکرد انجام می‌شود.
​
حریم خصوصی تفاضلی – حریم خصوصی تفاضلی یک چارچوب دقیق ریاضی برای انتشار اطلاعات آماری درباره مجموعه داده‌ها است که در عین حال از حفظ حریم خصوصی افراد داده شده محافظت می‌کند. این چارچوب به دارنده داده اجازه می‌دهد الگوهای تجمعی گروه را به اشتراک بگذارد در حالی که اطلاعات فاش شده درباره افراد خاص را محدود می‌کند.
​
بردارهای جاسازی‌شده: نمایش‌های برداری متراکم داده‌ها (متن، تصاویر و غیره) که معنای معنایی را در یک فضای با ابعاد بالا به‌دست می‌دهند.
​
قابلیت توضیح‌پذیری – قابلیت توضیح‌پذیری در هوش مصنوعی به توانایی یک سیستم هوش مصنوعی برای ارائه دلایل قابل فهم برای انسان درباره تصمیمات و پیش‌بینی‌های خود گفته می‌شود که بینشی درباره عملکرد داخلی آن فراهم می‌کند.
​
هوش مصنوعی قابل توضیح (XAI): سیستم‌های هوش مصنوعی طراحی شده برای ارائه توضیحات قابل فهم برای انسان درباره تصمیمات و رفتارهای خود از طریق تکنیک‌ها و چارچوب‌های مختلف.
​
یادگیری فدراسیون: رویکردی در یادگیری ماشین که در آن مدل‌ها به صورت توزیع‌شده در چندین دستگاه غیرمتمرکز که نمونه‌های داده محلی را نگهداری می‌کنند، آموزش داده می‌شوند، بدون اینکه داده‌ها مستقیماً تبادل شوند.
​
نرده‌های حفاظتی: محدودیت‌هایی که برای جلوگیری از تولید خروجی‌های مضر، جانبدارانه یا به‌گونه‌ای نامطلوب توسط سیستم‌های هوش مصنوعی اعمال می‌شوند.
​
توهم – توهم در هوش مصنوعی به پدیده‌ای اشاره دارد که در آن یک مدل هوش مصنوعی اطلاعات نادرست یا گمراه‌کننده‌ای تولید می‌کند که بر اساس داده‌های آموزشی یا واقعیت‌های حقیقی نیست.
​
انسان در حلقه (HITL): سیستم‌هایی که به گونه‌ای طراحی شده‌اند که نیازمند نظارت، تأیید یا مداخله انسانی در نقاط تصمیم‌گیری حیاتی هستند.
​
زیرساخت به عنوان کد (IaC): مدیریت و فراهم‌آوری زیرساخت‌ها از طریق کد به جای فرآیندهای دستی، که امکان اسکن امنیتی و استقرارهای سازگار را فراهم می‌کند.
​
Jailbreak: تکنیک‌هایی که برای دور زدن محافظ‌های ایمنی در سیستم‌های هوش مصنوعی، به‌ویژه در مدل‌های زبان بزرگ، استفاده می‌شوند تا محتوای ممنوعه تولید کنند.
​
حداقل دسترسی: اصل امنیتی اعطای تنها حداقل حقوق دسترسی لازم برای کاربران و فرایندها.
​
LIME (توضیحات قابل تفسیر محلی و مستقل از مدل): روشی برای توضیح پیش‌بینی‌های هر طبقه‌بند یادگیری ماشین با تقریب زدن آن به‌صورت محلی با یک مدل قابل تفسیر.
​
حمله استنباط عضویت: حمله‌ای که هدف آن تعیین این است که آیا یک داده خاص برای آموزش مدل یادگیری ماشین استفاده شده است یا خیر.
​
MITRE ATLAS: چشم‌انداز تهدیدهای خصمانه برای سیستم‌های هوش مصنوعی؛ یک پایگاه دانش از تاکتیک‌ها و تکنیک‌های خصمانه علیه سیستم‌های هوش مصنوعی.
​
کارت مدل – کارت مدل یک سند است که اطلاعات استاندارد شده‌ای درباره عملکرد، محدودیت‌ها، کاربردهای مورد نظر و ملاحظات اخلاقی یک مدل هوش مصنوعی ارائه می‌دهد تا شفافیت و توسعه مسئولانه هوش مصنوعی را ترویج کند.
​
استخراج مدل: حمله‌ای که در آن دشمن به طور مکرر از یک مدل هدف پرس‌وجو می‌کند تا یک نسخه عملکردی مشابه بدون مجوز ایجاد کند.
​
وارون‌سازی مدل: حمله‌ای که تلاش می‌کند با تحلیل خروجی‌های مدل، داده‌های آموزشی را بازسازی کند.
​
مدیریت چرخه عمر مدل – مدیریت چرخه عمر مدل هوش مصنوعی فرآیند نظارت بر تمام مراحل وجود یک مدل هوش مصنوعی است، از جمله طراحی، توسعه، استقرار، مانیتورینگ، نگهداری و در نهایت بازنشستگی آن، تا اطمینان حاصل شود که مدل موثر باقی می‌ماند و با اهداف هماهنگ است.
​
مسمومیت مدل: وارد کردن آسیب‌پذیری‌ها یا درهای پشتی مستقیماً به مدل در حین فرایند آموزش.
​
سرقت/ربودن مدل: استخراج نسخه‌ای یا تقریب از یک مدل اختصاصی از طریق پرس‌وجوهای مکرر.
​
سیستم چندعامله: سیستمی متشکل از چندین عامل هوش مصنوعی تعاملی است که هر کدام ممکن است قابلیت‌ها و اهداف متفاوتی داشته باشند.
​
OPA (Open Policy Agent): یک موتور سیاست متن‌باز است که اجرای یکنواخت سیاست‌ها را در تمام لایه‌های سیستم امکان‌پذیر می‌سازد.
​
یادگیری ماشین حفظ حریم خصوصی (PPML): تکنیک‌ها و روش‌هایی برای آموزش و استقرار مدل‌های یادگیری ماشین در حالی که حریم خصوصی داده‌های آموزشی حفظ می‌شود.
​
تزریق فرمان: حمله‌ای که در آن دستورات مخرب در ورودی‌ها جاسازی می‌شوند تا رفتار مورد نظر مدل را نادیده بگیرند.
​
RAG (تولید تقویت‌شده با واکشی): یک تکنیک که مدل‌های بزرگ زبان را با واکشی اطلاعات مرتبط از منابع دانش خارجی قبل از تولید پاسخ، ارتقا می‌دهد.
​
رد-تیمینگ: عملی است که در آن سیستم‌های هوش مصنوعی به‌صورت فعال با شبیه‌سازی حملات مخرب آزمایش می‌شوند تا آسیب‌پذیری‌ها شناسایی شوند.
​
SBOM (فهرست مواد نرم‌افزاری): یک سند رسمی که شامل جزئیات و روابط زنجیره تأمین اجزای مختلف استفاده‌شده در ساخت نرم‌افزار یا مدل‌های هوش مصنوعی است.
​
SHAP (توضیحات افزایشی شاپلی): رویکردی مبتنی بر نظریه بازی‌ها برای توضیح خروجی هر مدل یادگیری ماشین با محاسبه سهم هر ویژگی در پیش‌بینی.
​
حمله زنجیره تامین: نفوذ به سیستم با هدف قرار دادن عناصر کم‌امن‌تر در زنجیره تامین آن، مانند کتابخانه‌های شخص ثالث، مجموعه داده‌ها یا مدل‌های از قبل آموزش‌دیده شده.
​
یادگیری انتقالی: تکنیکی که در آن یک مدل توسعه یافته برای یک وظیفه به عنوان نقطه شروع برای مدل در وظیفه دوم مورد استفاده مجدد قرار می‌گیرد.
​
پایگاه داده برداری: یک پایگاه داده تخصصی طراحی شده برای ذخیره بردارهای با ابعاد بالا (تعبیه‌ها) و انجام جستجوهای شباهت کارآمد.
​
اسکن آسیب‌پذیری: ابزارهای خودکار که آسیب‌پذیری‌های امنیتی شناخته‌شده در اجزای نرم‌افزاری، از جمله چارچوب‌ها و وابستگی‌های هوش مصنوعی را شناسایی می‌کنند.
​
واترمارکینگ: تکنیک‌هایی برای جاسازی علائم نامحسوس در محتوای تولید شده توسط هوش مصنوعی به منظور ردیابی منبع آن یا شناسایی تولید توسط هوش مصنوعی.
​
آسیب‌پذیری صفر روز: یک آسیب‌پذیری ناشناخته قبلی که مهاجمان می‌توانند قبل از اینکه توسعه‌دهندگان پچ ایجاد و اجرا کنند، از آن سوءاستفاده کنند.

## ضمیمه ب: مراجع

### TODO

## ضمیمه C: حکمرانی و مستندسازی امنیت هوش مصنوعی

### هدف

این پیوست الزامات پایه‌ای برای ایجاد ساختارهای سازمانی، سیاست‌ها و فرآیندها به منظور مدیریت امنیت هوش مصنوعی در سراسر چرخه عمر سیستم را فراهم می‌کند.

---

### پذیرش چارچوب مدیریت ریسک AI AC.1

چارچوب رسمی برای شناسایی، ارزیابی و کاهش ریسک‌های خاص هوش مصنوعی در طول چرخه عمر سیستم ارائه دهید.

 #AC.1.1    سطح: 1    نقش: D/V
 تأیید کنید که یک روش ارزیابی ریسک خاص هوش مصنوعی مستند و اجرا شده باشد.
 #AC.1.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که ارزیابی‌های ریسک در نقاط کلیدی چرخه عمر هوش مصنوعی و پیش از تغییرات عمده انجام می‌شوند.
 #AC.1.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که چارچوب مدیریت ریسک با استانداردهای تعیین‌شده (مانند NIST AI RMF) همسو باشد.

---

### AC.2 سیاست‌ها و رویه‌های امنیت هوش مصنوعی

تعریف و اجرای استانداردهای سازمانی برای توسعه، استقرار و عملیات امن هوش مصنوعی.

 #AC.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیاست‌های امنیتی مستند شده برای هوش مصنوعی وجود دارند.
 #AC.2.2    سطح: 2    نقش: D
 تأیید کنید که سیاست‌ها حداقل سالانه و پس از تغییرات قابل توجه در چشم‌انداز تهدید بررسی و به‌روزرسانی می‌شوند.
 #AC.2.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که سیاست‌ها تمامی دسته‌بندی‌های AISVS و الزامات نظارتی قابل اجرا را پوشش می‌دهند.

---

### AC.3 نقش‌ها و مسئولیت‌ها برای امنیت هوش مصنوعی

مسئولیت‌پذیری واضح برای امنیت هوش مصنوعی در سراسر سازمان برقرار کنید.

 #AC.3.1    سطح: 1    نقش: D/V
 تأیید کنید که نقش‌ها و مسئولیت‌های امنیت هوش مصنوعی مستندسازی شده‌اند.
 #AC.3.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که افراد مسئول دارای تخصص مناسب در زمینه امنیت هستند.
 #AC.3.3    سطح: 3    نقش: D/V
 تأیید کنید که یک کمیته اخلاق هوش مصنوعی یا هیئت حاکمیت برای سیستم‌های هوش مصنوعی با ریسک بالا تشکیل شده باشد.

---

### اجرای دستورالعمل‌های اخلاقی هوش مصنوعی AC.4

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی مطابق با اصول اخلاقی تعیین‌شده عمل کنند.

 #AC.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که دستورالعمل‌های اخلاقی برای توسعه و استقرار هوش مصنوعی وجود دارد.
 #AC.4.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که مکانیزم‌هایی برای شناسایی و گزارش نقض‌های اخلاقی وجود دارد.
 #AC.4.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که بازبینی‌های اخلاقی منظم بر سیستم‌های هوش مصنوعی مستقر شده انجام می‌شود.

---

### AC.5 پایش تطبیق‌پذیری قانون‌گذاری هوش مصنوعی

آگاهی و رعایت مقررات در حال تحول هوش مصنوعی را حفظ کنید.

 #AC.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که فرآیندهایی برای شناسایی مقررات مرتبط با هوش مصنوعی وجود دارد.
 #AC.5.2    سطح: 2    نقش: D
 اطمینان حاصل شود که رعایت تمامی الزامات قانونی مورد ارزیابی قرار گرفته است.
 #AC.5.3    سطح: 3    نقش: D/V
 تأیید کنید که تغییرات مقرراتی باعث بررسی‌ها و به‌روزرسانی‌های به موقع سیستم‌های هوش مصنوعی می‌شوند.

### AC.6 حاکمیت داده‌های آموزشی، مستندسازی و فرایند

 #1.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تنها داده‌مجموعه‌هایی که از نظر کیفیت، نمایندگی، منبع‌یابی اخلاقی و تطابق با مجوز مورد بررسی قرار گرفته‌اند، مجاز باشند و این امر باعث کاهش ریسک‌های مسمومیت داده، تعصب نهفته و نقض مالکیت فکری می‌شود.
 #1.1.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که کیفیت برچسب‌گذاری/حاشیه‌نویسی از طریق بررسی‌های متقابل بازبین‌ها یا اجماع تضمین شده است.
 #1.1.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که «کارت‌های داده» یا «برگه‌های داده برای مجموعه داده‌ها» برای مجموعه داده‌های آموزشی مهم نگهداری می‌شوند، که ویژگی‌ها، انگیزه‌ها، ترکیب، فرآیندهای جمع‌آوری، پیش‌پردازش و استفاده‌های توصیه شده/نامطلوب را به‌تفصیل شرح می‌دهند.
 #1.3.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تبعیض‌های شناسایی شده از طریق راهکارهای مستند شده مانند متعادل‌سازی مجدد، تقویت داده هدفمند، تنظیمات الگوریتمی (مانند تکنیک‌های پیش‌پردازش، پردازش درون الگوریتم، پس‌پردازش) یا تغییر وزن‌ها کاهش یافته‌اند و تأثیر کاهش تبعیض هم بر انصاف و هم بر عملکرد کلی مدل ارزیابی شده است.
 #1.3.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که معیارهای عدالت پس از آموزش ارزیابی و مستندسازی شده‌اند.
 #1.3.4    سطح: 3    نقش: D/V
 تأیید کنید که یک سیاست مدیریت سوگیری چرخه عمر، مالکان و تناوب بازبینی را تعیین می‌کند.
 #1.4.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که کیفیت برچسب‌گذاری/حاشیه‌نویسی با استفاده از دستورالعمل‌های واضح، بررسی متقابل توسط بازبین‌ها، مکانیزم‌های توافق (مانند نظارت بر توافق بین حاشیه‌نویسان) و فرآیندهای تعریف‌شده برای حل تضادها تضمین شده است.
 #1.4.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که برچسب‌های حیاتی برای ایمنی، امنیت یا انصاف (برای مثال، شناسایی محتوای سمی، یافته‌های پزشکی بحرانی) نیازمند بازبینی دوگانه مستقل اجباری یا تأیید معادل قوی هستند.
 #1.4.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که راهنماها و دستورالعمل‌های برچسب‌گذاری جامع، کنترل شده از نظر نسخه و مورد بازبینی همتا قرار گرفته‌اند.
 #1.4.6    سطح: 2    نقش: D/V
 تأیید کنید که اسکیمای داده‌ها برای برچسب‌ها به وضوح تعریف شده و تحت کنترل نسخه باشند.
 #1.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که داده‌ها برای عدم تعادل نمایندگی و سوگیری‌های احتمالی در خصوص ویژگی‌های قانونی محافظت‌شده (مانند نژاد، جنسیت، سن) و سایر ویژگی‌های حساس اخلاقی مرتبط با حوزه کاربرد مدل (مانند وضعیت اجتماعی-اقتصادی، موقعیت جغرافیایی) تحلیل شده‌اند.
 #1.5.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که بررسی‌های دستی نمونه‌ای توسط کارشناسان حوزه، نمونه‌ای با حجم آماری معنادار (مثلاً ≥1٪ یا ۱۰۰۰ نمونه، هر کدام که بیشتر است، یا طبق ارزیابی ریسک تعیین شده) را پوشش می‌دهد تا مشکلات کیفی ظریف که توسط خودکارسازی شناسایی نشده‌اند، شناسایی شود.
 #1.8.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که گردش‌های کاری برچسب‌گذاری برون‌سپاری شده یا جمع‌سپاری شده شامل تدابیر فنی/رویّه‌ای برای تضمین محرمانگی داده‌ها، یکپارچگی، کیفیت برچسب و جلوگیری از نشت داده‌ها باشند.
 #1.5.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مراحل اصلاح به سوابق منشأ اضافه شده‌اند.
 #1.6.2    سطح: 2    نقش: D/V
 تأیید کنید که نمونه‌های علامت‌گذاری شده، قبل از آموزش، باعث بررسی دستی می‌شوند.
 #1.6.3    سطح: 2    نقش: V
 تأیید کنید که نتایج پرونده امنیتی مدل را تغذیه می‌کنند و هوش تهدیدات جاری را اطلاع‌رسانی می‌کنند.
 #1.6.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که منطق تشخیص با اطلاعات تهدید جدید به‌روزرسانی شده است.
 #1.6.5    سطح: 3    نقش: D/V
 تأیید کنید که خطوط لوله یادگیری آنلاین تغییر توزیع را نظارت می‌کنند.
 #1.7.1    سطح: 1    نقش: D/V
 تأیید کنید که روندهای حذف داده‌های آموزش، داده‌های اصلی و مشتق شده را پاک‌سازی می‌کنند و تأثیر مدل را ارزیابی می‌کنند، و اینکه تأثیر روی مدل‌های تحت تأثیر ارزیابی شده و در صورت لزوم، اصلاح می‌شود (مثلاً از طریق آموزش مجدد یا بازتنظیم).
 #1.7.2    سطح: 2    نقش: D
 تأیید کنید که مکانیزم‌هایی برای پیگیری و احترام به محدوده و وضعیت رضایت کاربر (و انصراف‌ها) برای داده‌های استفاده‌شده در آموزش وجود دارد، و اینکه رضایت قبل از وارد کردن داده‌ها در فرآیندهای آموزش جدید یا به‌روزرسانی‌های مهم مدل، اعتبارسنجی می‌شود.
 #1.7.3    سطح: 2    نقش: V
 تأیید کنید که گردش‌های کاری سالانه آزمایش شده و ثبت می‌شوند.
 #1.8.1    سطح: 2    نقش: D/V
 تأیید کنید که تأمین‌کنندگان داده‌های شخص ثالث، از جمله ارائه‌دهندگان مدل‌های پیش‌آموزش‌دیده و مجموعه‌داده‌های خارجی، پیش از ادغام داده‌ها یا مدل‌هایشان، مورد بررسی دقیق امنیتی، حریم خصوصی، تأمین اخلاقی و کیفیت داده قرار می‌گیرند.
 #1.8.2    سطح: 1    نقش: D
 تأیید کنید که انتقال‌های خارجی از TLS/احراز هویت و بررسی‌های صحت استفاده می‌کنند.
 #1.8.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که منابع داده پرخطر (به عنوان مثال، مجموعه داده‌های منبع باز با منشأ نامشخص، تأمین‌کنندگان تأییدنشده) تحت بررسی‌های دقیق‌تر قرار می‌گیرند، مانند تحلیل در محیط ایزوله (sandboxed)، بررسی‌های گسترده کیفیت/تعصب، و کشف هدفمند سم‌پاشی، پیش از استفاده در برنامه‌های حساس.
 #1.8.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مدل‌های پیش‌آموزش‌دیده شده که از سوی طرف‌های ثالث به‌دست آمده‌اند، از نظر تعصبات نهفته، پتانسیل درهای پشتی، یکپارچگی ساختار آن‌ها و منبع داده‌های اصلی آموزششان قبل از انجام تنظیمات دقیق یا استقرار، ارزیابی شده باشند.
 #1.5.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اگر از آموزش مقابله‌ای استفاده می‌شود، تولید، مدیریت و نسخه‌بندی مجموعه‌داده‌های مقابله‌ای مستند شده و کنترل می‌شوند.
 #1.5.3    سطح: 3    نقش: D/V
 اطمینان حاصل شود که تأثیر آموزش مقاومت در برابر حملات خصمانه بر عملکرد مدل (در برابر ورودی‌های پاک و خصمانه) و معیارهای عدالت ارزیابی، مستند و نظارت می‌شود.
 #1.5.4    سطح: 3    نقش: D/V
 اطمینان حاصل شود که استراتژی‌های آموزش مقابله‌ای و مقاومت به طور دوره‌ای بازبینی و به‌روزرسانی می‌شوند تا با تکنیک‌های حمله مقابله‌ای در حال تحول مقابله کنند.
 #1.4.2    سطح: 2    نقش: D/V
 تأیید کنید که مجموعه داده‌های ناموفق با مسیرهای حسابرسی قرنطینه شده‌اند.
 #1.4.3    سطح: 2    نقش: D/V
 تأیید کنید که دروازه‌های کیفیت از عبور داده‌های ناقص یا با کیفیت پایین جلوگیری می‌کنند مگر اینکه استثناها تأیید شده باشند.
 #1.11.2    سطح: 2    نقش: D/V
 تأیید کنید که فرآیند تولید، پارامترها و استفاده مورد نظر از داده‌های مصنوعی مستندسازی شده باشد.
 #1.11.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که داده‌های مصنوعی قبل از استفاده در آموزش برای سوگیری، نشت حریم خصوصی و مسائل نمایشی مورد ارزیابی ریسک قرار گرفته‌اند.
 #1.12.3    سطح: 2    نقش: D/V
 تأیید کنید که هشدارها برای رویدادهای دسترسی مشکوک ایجاد شده و به سرعت بررسی شوند.
 #1.13.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که دوره‌های نگهداری صریح برای همه مجموعه داده‌های آموزشی تعریف شده‌اند.
 #1.13.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مجموعه داده‌ها به‌طور خودکار در پایان چرخه عمرشان منقضی، حذف یا برای حذف بازبینی می‌شوند.
 #1.13.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اقدامات نگهداری و حذف ثبت شده و قابل حسابرسی هستند.
 #1.14.1    سطح: 2    نقش: D/V
 اطمینان حاصل شود که الزامات اقامت داده و انتقال فرامرزی برای همه مجموعه داده‌ها شناسایی و اجرا شده‌اند.
 #1.14.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مقررات خاص هر بخش (مانند بهداشت و درمان، مالی) در مدیریت داده‌ها شناسایی و مورد توجه قرار گرفته‌اند.
 #1.14.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که رعایت قوانین مرتبط با حفظ حریم خصوصی (به عنوان مثال، GDPR، CCPA) مستندسازی شده و به‌طور منظم بازبینی می‌شود.
 #1.16.1    سطح: 2    نقش: D/V
 تأیید کنید که مکانیزم‌هایی برای پاسخ به درخواست‌های ذینفع داده‌ها برای دسترسی، اصلاح، محدودیت یا اعتراض وجود دارد.
 #1.16.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که درخواست‌ها در بازه‌های زمانی تعیین شده توسط قانون ثبت، پیگیری و انجام می‌شوند.
 #1.16.3    سطح: 2    نقش: D/V
 تأیید کنید که فرایندهای حقوق صاحب‌داده به طور منظم برای اثربخشی آزمایش و بازبینی می‌شوند.
 #1.17.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که قبل از به‌روزرسانی یا جایگزینی نسخه‌ای از داده‌ها، تحلیل تاثیر انجام شده باشد که شامل عملکرد مدل، عدالت و انطباق باشد.
 #1.17.2    سطح: 2    نقش: D/V
 تأیید کنید که نتایج تحلیل تأثیر مستندسازی شده و توسط ذینفعان مرتبط مورد بازبینی قرار گرفته‌اند.
 #1.17.3    سطح: 2    نقش: D/V
 تأیید کنید که برنامه‌های بازگردانی در صورت معرفی ریسک‌ها یا افت کیفیت غیرقابل قبول توسط نسخه‌های جدید وجود داشته باشد.
 #1.18.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که همه پرسنل دخیل در برچسب‌گذاری داده‌ها، بررسی پیشینه شده و در زمینه امنیت داده‌ها و حریم خصوصی آموزش دیده باشند.
 #1.18.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تمام پرسنل حاشیه‌نویسی توافق‌نامه‌های محرمانگی و عدم افشا را امضا کرده‌اند.
 #1.18.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که پلتفرم‌های حاشیه‌نویسی کنترل‌های دسترسی را اعمال می‌کنند و تهدیدات داخلی را رصد می‌کنند.

#### مراجع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
EU Artificial Intelligence Act — Regulation (EU) 2024/1689
ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods

## ضمیمه د: حاکمیت و تایید کد نویسی امن با کمک هوش مصنوعی

### هدف

این فصل کنترل‌های سازمانی پایه‌ای برای استفاده ایمن و مؤثر از ابزارهای کدنویسی مبتنی بر هوش مصنوعی در طول توسعه نرم‌افزار را تعریف می‌کند، و امنیت و قابلیت ردیابی را در سراسر چرخه عمر توسعه نرم‌افزار تضمین می‌نماید.

---

### AD.1 جریان کاری برنامه‌نویسی امن با کمک هوش مصنوعی

ابزارهای هوش مصنوعی را در چرخه عمر توسعه نرم‌افزار امن سازمان (SSDLC) ادغام کنید بدون اینکه دروازه‌های امنیتی موجود تضعیف شوند.

 #AD.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که یک روند کاری مستند شده توضیح دهد که چه زمانی و چگونه ابزارهای هوش مصنوعی ممکن است کد را تولید، بازسازی یا بررسی کنند.
 #AD.1.2    سطح: 2    نقش: D
 تأیید کنید که جریان کاری به هر مرحله از چرخه توسعه نرم‌افزار امن (SSDLC) نگاشت شده است (طراحی، پیاده‌سازی، بازبینی کد، تست، استقرار).
 #AD.1.3    سطح: 3    نقش: D/V
 تأیید کنید که معیارها (مثلاً تراکم آسیب‌پذیری، میانگین زمان تشخیص) بر روی کد تولید شده توسط هوش مصنوعی جمع‌آوری شده و با مبناهای صرفاً انسانی مقایسه می‌شوند.

---

### AD.2 ابزارهای هوش مصنوعی برای شناسایی صلاحیت و مدل‌سازی تهدید

اطمینان حاصل کنید که ابزارهای کدنویسی هوش مصنوعی پیش از پذیرش، از نظر قابلیت‌های امنیتی، ریسک و تأثیر زنجیره تأمین ارزیابی می‌شوند.

 #AD.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مدل تهدید برای هر ابزار هوش مصنوعی سوء استفاده، وارونگی مدل، نشت داده و ریسک‌های زنجیره وابستگی را شناسایی می‌کند.
 #AD.2.2    سطح: 2    نقش: D
 تأیید کنید که ارزیابی‌های ابزار شامل تحلیل ایستا/پویا از هر مؤلفه محلی و ارزیابی نقاط انتهایی SaaS (TLS، احراز هویت/مجوزدهی، لاگ‌برداری) باشد.
 #AD.2.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که ارزیابی‌ها از یک چارچوب شناخته شده پیروی می‌کنند و پس از تغییرات عمده نسخه، مجدداً انجام می‌شوند.

---

### مدیریت امن درخواست و زمینه AD.3

جلوگیری از نشت اسرار، کد اختصاصی و داده‌های شخصی هنگام ساخت پرسش‌ها یا زمینه‌ها برای مدل‌های هوش مصنوعی.

 #AD.3.1    سطح: 1    نقش: D/V
 بررسی کنید که راهنمایی‌های مکتوب ارسال اسرار، اطلاعات کاربری یا داده‌های طبقه‌بندی‌شده در درخواست‌ها را ممنوع کرده است.
 #AD.3.2    سطح: 2    نقش: D
 تأیید کنید که کنترل‌های فنی (حذف اطلاعات حساس در سمت کلاینت، فیلترهای زمینه تایید شده) به‌صورت خودکار آثار حساس را حذف می‌کنند.
 #AD.3.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که پرامپت‌ها و پاسخ‌ها به توکن تبدیل شده، در هنگام انتقال و در حالت ذخیره‌سازی رمزگذاری شده‌اند و دوره‌های نگهداری با سیاست طبقه‌بندی داده‌ها مطابقت دارند.

---

### AD.4 اعتبارسنجی کد تولیدشده توسط هوش مصنوعی

شناسایی و اصلاح آسیب‌پذیری‌هایی که توسط خروجی هوش مصنوعی ایجاد شده‌اند قبل از اینکه کد ادغام یا عرضه شود.

 #AD.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که کد تولید شده توسط هوش مصنوعی همیشه تحت بازبینی کد توسط انسان قرار می‌گیرد.
 #AD.4.2    سطح: 2    نقش: D
 تأیید کنید که اسکنرهای خودکار (SAST/IAST/DAST) روی هر درخواست کشش حاوی کد تولیدشده توسط هوش مصنوعی اجرا شوند و در صورت یافتن مشکلات بحرانی، ادغام‌ها را مسدود کنند.
 #AD.4.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تست‌های اختلافی فازی یا تست‌های مبتنی بر ویژگی، رفتارهای حیاتی امنیتی (مانند اعتبارسنجی ورودی، منطق مجوزدهی) را اثبات می‌کنند.

---

### AD.5 قابلیت توضیح‌پذیری و ردیابی پیشنهادات کد

به حسابرسان و توسعه‌دهندگان بینش دهید که چرا یک پیشنهاد ارائه شده است و چگونه تکامل یافته است.

 #AD.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که جفت‌های پرسش/پاسخ با شناسه‌های کامیت ثبت می‌شوند.
 #AD.5.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که توسعه‌دهندگان می‌توانند استنادات مدل (قطعات آموزش، مستندات) که از یک پیشنهاد پشتیبانی می‌کنند را نشان دهند.
 #AD.5.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که گزارش‌های قابلیت توضیح‌پذیری همراه با مصنوعات طراحی ذخیره شده و در بررسی‌های امنیتی ارجاع داده شده‌اند، به طوری که اصول قابلیت ردیابی ISO/IEC 42001 را برآورده کنند.

---

### AD.6 بازخورد مستمر و تنظیم دقیق مدل

عملکرد امنیت مدل را در طول زمان بهبود داده و در عین حال از انحراف منفی جلوگیری کنید.

 #AD.6.1    سطح: 1    نقش: D/V
 تأیید کنید که توسعه‌دهندگان قادر به علامت‌گذاری پیشنهادات ناامن یا غیرمطابق هستند و این علامت‌ها ردیابی می‌شوند.
 #AD.6.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که بازخورد تجمیع‌شده، تنظیم دقیق دوره‌ای یا تولید ارتقا یافته با بازیابی از مجموعه‌های کدگذاری امن تأییدشده (مانند OWASP Cheat Sheets) را اطلاع می‌دهد.
 #AD.6.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که یک چارچوب ارزیابی حلقه‌بسته پس از هر تنظیم دقیق، تست‌های رگرسیون را اجرا می‌کند؛ معیارهای امنیتی باید قبل از استقرار به سطح پایه‌های قبلی برسند یا از آنها فراتر روند.

---

#### مراجع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
OWASP Secure Coding Practices — Quick Reference Guide

## ضمیمه E: نمونه ابزارها و چارچوب‌ها

### هدف

این فصل مثال‌هایی برای ابزارها و چارچوب‌هایی ارائه می‌دهد که می‌توانند از پیاده‌سازی یا تحقق یک نیازمندی مشخص از AISVS پشتیبانی کنند. این موارد نباید به عنوان توصیه یا تأییدیه از سوی تیم AISVS یا پروژه امنیتی OWASP GenAI در نظر گرفته شوند.

---

### AE.1 حاکمیت داده‌های آموزش و مدیریت تعصب

ابزارهای مورد استفاده برای تجزیه و تحلیل داده‌ها، حاکمیت، و مدیریت تعصب.

 #AE.1.1    بخش: 1.1
 ابزارهای موجودی داده: ابزارهای مدیریت موجودی داده مانند...
 #AE.1.2    بخش: 1.2
 رمزگذاری در حین انتقال از TLS برای برنامه‌های مبتنی بر HTTPS استفاده کنید، با ابزارهایی مانند openSSL و کتابخانه پایتون`ssl`کتابخانه.

---

### AE.2 اعتبارسنجی ورودی کاربر

ابزارهایی برای مدیریت و اعتبارسنجی ورودی‌های کاربر.

 #AE.2.1    بخش: 2.1
 ابزارهای دفاع در برابر تزریق پرامپت: از ابزارهای محافظتی مانند NeMo شرکت NVIDIA یا Guardrails AI استفاده کنید.

---

