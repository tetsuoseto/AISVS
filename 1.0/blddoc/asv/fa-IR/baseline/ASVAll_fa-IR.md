## صفحه عنوان

### درباره استاندارد

استاندارد تایید امنیت هوش مصنوعی (AISVS) یک فهرست مبتنی بر مشارکت جامعه از الزامات امنیتی است که دانشمندان داده، مهندسان MLOps، معماران نرم‌افزار، توسعه‌دهندگان، آزمون‌گران، متخصصان امنیتی، فروشندگان ابزار، نهادهای نظارتی و مصرف‌کنندگان می‌توانند از آن برای طراحی، ساخت، آزمون و تایید سیستم‌ها و برنامه‌های مبتنی بر هوش مصنوعی قابل اعتماد استفاده کنند. این استاندارد زبان مشترکی برای مشخص کردن کنترل‌های امنیتی در سرتاسر چرخه عمر هوش مصنوعی ارائه می‌دهد—از جمع‌آوری داده و توسعه مدل تا استقرار و پایش مداوم—تا سازمان‌ها بتوانند مقاومت، حریم خصوصی و ایمنی راهکارهای هوش مصنوعی خود را اندازه‌گیری و بهبود بخشند.

### کپی‌رایت و مجوز

نسخه 0.1 (اولین پیش‌نویس عمومی - در حال کار)، 2025  

![license](images/license.png)
حقوق نشر © 2025 پروژه AISVS.  

منتشر شده تحت Creative Commons Attribution‑ShareAlike 4.0 International License.
برای هر گونه استفاده مجدد یا توزیع، باید شرایط مجوز این اثر را به‌طور واضح به دیگران اطلاع دهید.

### رهبران پروژه

جیم مانویکو
آراس "راس" میمیسیازیچی

### مشارکت‌کنندگان و بررسی‌کنندگان

https://github.com/ottosulin
https://github.com/mbhatt1
https://github.com/vineethsai
https://github.com/cciprofm
https://github.com/deepakrpandey12


---

AISVS یک استاندارد کاملاً جدید است که به طور خاص برای مقابله با چالش‌های امنیتی منحصر به فرد سیستم‌های هوش مصنوعی ایجاد شده است. در حالی که از بهترین شیوه‌های امنیتی گسترده‌تر الهام می‌گیرد، هر الزامی در AISVS از پایه توسعه یافته است تا چشم‌انداز تهدیدات هوش مصنوعی را منعکس کند و به سازمان‌ها کمک کند تا راه‌حل‌های هوش مصنوعی ایمن‌تر و مقاوم‌تری بسازند.

## پیش‌گفتار

به استاندارد تأیید امنیت هوش مصنوعی (AISVS) نسخه 1.0 خوش آمدید!

### مقدمه

AISVS که در سال 2025 از طریق یک تلاش جمعی جامعه تأسیس شد، الزامات امنیتی را که باید هنگام طراحی، توسعه، استقرار و راه‌اندازی مدل‌های مدرن هوش مصنوعی، خطوط لوله و خدمات فعال‌شده با هوش مصنوعی در نظر گرفته شوند، تعریف می‌کند.

AISVS v1.0 نمایانگر تلاش مشترک سرپرستان پروژه، گروه کاری و مشارکت‌کنندگان گسترده‌تر جامعه است تا یک خط مبنای عملی و قابل آزمون برای امن‌سازی سیستم‌های هوش مصنوعی ارائه دهد.

هدف ما با این نسخه این است که AISVS را به طور ساده قابل پذیرش کنیم در حالی که به طور دقیق به دامنه تعریف‌شده آن متمرکز بمانیم و به چشم‌انداز ریسک به سرعت در حال تحول که منحصر به هوش مصنوعی است رسیدگی کنیم.

### اهداف کلیدی برای نسخه 1.0 AISVS

نسخه 1.0 با چندین اصول راهنمایی ایجاد خواهد شد.

#### دامنه‌ مشخص و تعریف‌شده

هر الزام باید با نام و مأموریت AISVS همسو باشد:

هوش مصنوعی – کنترل‌ها در لایه هوش مصنوعی/یادگیری ماشین (داده، مدل، خط لوله یا استنتاج) عمل می‌کنند و مسئولیت آن بر عهده متخصصان هوش مصنوعی است.
امنیت – الزامات به طور مستقیم خطرات شناسایی شده امنیتی، حریم خصوصی یا ایمنی را کاهش می‌دهند.
تأیید صحت – زبان به گونه‌ای نوشته شده است که انطباق آن بتواند به‌صورت عینی اعتبارسنجی شود.
استاندارد – بخش‌ها از ساختار و اصطلاحات یکسانی پیروی می‌کنند تا مرجعی منسجم تشکیل دهند.
​
---

با پیروی از AISVS، سازمان‌ها می‌توانند به‌طور سیستماتیک وضعیت امنیتی راه‌حل‌های هوش مصنوعی خود را ارزیابی و تقویت کنند و فرهنگ مهندسی هوش مصنوعی ایمن را ترویج دهند.

## استفاده از AISVS

استاندارد تأیید امنیت هوش مصنوعی (AISVS) الزامات امنیتی را برای برنامه‌ها و خدمات مدرن هوش مصنوعی تعریف می‌کند، با تمرکز بر جنبه‌هایی که در کنترل توسعه‌دهندگان برنامه است.

AISVS برای هر کسی که در حال توسعه یا ارزیابی امنیت برنامه‌های هوش مصنوعی است، از جمله توسعه‌دهندگان، معماران، مهندسان امنیت و حسابرسان، در نظر گرفته شده است. این فصل ساختار و استفاده از AISVS را معرفی می‌کند، از جمله سطوح تأیید آن و موارد استفاده مد نظر.

### سطوح تایید امنیت هوش مصنوعی

AISVS سه سطح صعودی از تأیید امنیت را تعریف می‌کند. هر سطح عمق و پیچیدگی را افزایش می‌دهد و به سازمان‌ها اجازه می‌دهد وضعیت امنیتی خود را متناسب با سطح ریسک سیستم‌های هوش مصنوعی خود تنظیم کنند.

سازمان‌ها ممکن است از سطح 1 شروع کرده و به تدریج سطوح بالاتر را با افزایش بلوغ امنیتی و مواجهه با تهدیدات به‌کار گیرند.

#### تعریف سطوح

هر نیازمندی در AISVS نسخه 1.0 به یکی از سطوح زیر اختصاص داده شده است:

 نیازمندی‌های سطح 1

سطح 1 شامل حیاتی‌ترین و بنیادی‌ترین الزامات امنیتی است. این سطح بر جلوگیری از حملات معمول که به پیش‌شرط‌ها یا آسیب‌پذیری‌های دیگر وابسته نیستند تمرکز دارد. بیشتر کنترل‌های سطح 1 یا به‌راحتی قابل پیاده‌سازی هستند یا از اهمیت کافی برخوردارند که اجرای آن‌ها توجیه‌پذیر باشد.

 نیازمندی‌های سطح 2

سطح ۲ به حملات پیشرفته‌تر یا کمتر رایج‌تر می‌پردازد، همچنین دفاع‌های چندلایه در برابر تهدیدات گسترده را شامل می‌شود. این الزامات ممکن است شامل منطق پیچیده‌تر یا هدف قرار دادن پیش‌نیازهای خاص حمله باشد.

 الزامات سطح 3

سطح 3 شامل کنترل‌هایی است که معمولاً پیاده‌سازی آنها دشوارتر است یا کاربردشان موقعیتی است. این کنترل‌ها اغلب نمایانگر مکانیزم‌های دفاع در عمق یا کاهش خطر در برابر حملات خاص، هدفمند یا با پیچیدگی بالا هستند.

#### نقش (D/V)

هر الزامات AISVS بر اساس مخاطب اصلی علامت‌گذاری شده است:

D – نیازمندی‌های متمرکز بر توسعه‌دهنده
V – الزامات متمرکز بر تاییدکننده/ممیزی‌کننده
D/V – مرتبط با هر دو توسعه‌دهندگان و صحت‌سنج‌ها

## حکمرانی داده‌های آموزشی C1 و مدیریت تعصب

### هدف کنترل

داده‌های آموزشی باید به گونه‌ای تهیه، اداره و نگهداری شوند که اصالت، امنیت، کیفیت و عدالت آن‌ها حفظ شود. انجام این کار وظایف قانونی را برآورده می‌کند و ریسک‌های تعصب، مسمومیت یا نقض حریم خصوصی که در طول آموزش ظاهر می‌شوند و می‌توانند بر کل چرخه عمر هوش مصنوعی تأثیر بگذارند را کاهش می‌دهد.

---

### C1.1 منشاء داده‌های آموزش

نگهداری یک موجودی قابل تأیید از تمام مجموعه داده‌ها، پذیرش فقط منابع مورد اعتماد، و ثبت هر تغییر برای قابلیت بررسی.

 #1.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که یک فهرست به‌روز از هر منبع داده آموزشی (مبدا، مسئول/مالک، مجوز، روش گردآوری، محدودیت‌های استفاده مورد نظر، و تاریخچه پردازش) نگهداری می‌شود.
 #1.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که فرآیندهای داده‌های آموزشی شامل ویژگی‌ها، صفات یا فیلدهای غیرضروری نیستند (به عنوان مثال، فراداده‌های استفاده‌نشده، اطلاعات حساس شناسایی شخصی، داده‌های نشت‌یافته آزمون).
 #1.1.3    سطح: 2    نقش: D/V
 تأیید کنید که تمام تغییرات داده‌ها تحت یک فرآیند تصویب ثبت شده قرار دارند.
 #1.1.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که دیتاست‌ها یا زیرمجموعه‌ها در صورت امکان دارای واترمارک یا اثر انگشت دیجیتال باشند.

---

### C1.2 امنیت و یکپارچگی داده‌های آموزشی

دسترسی به داده‌های آموزشی را محدود کنید، آن‌ها را در حالت استراحت و انتقال رمزگذاری کنید و صحت آن‌ها را بررسی کنید تا از دستکاری، سرقت یا مسمومیت داده‌ها جلوگیری شود.

 #1.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که کنترل‌های دسترسی از ذخیره‌سازی داده‌های آموزشی و خطوط لوله محافظت می‌کنند.
 #1.2.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تمامی دسترسی‌ها به داده‌های آموزش ثبت شده است، شامل کاربر، زمان و اقدام انجام شده.
 #1.2.3    سطح: 2    نقش: D/V
 تأیید کنید که مجموعه‌داده‌های آموزشی در حین انتقال و در حالت ذخیره‌شده، با استفاده از الگوریتم‌های رمزنگاری استاندارد صنعت و روش‌های مدیریت کلید رمزنگاری شده‌اند.
 #1.2.4    سطح: 2    نقش: D/V
 تأیید کنید که هش‌های رمزنگاری شده یا امضاهای دیجیتال برای اطمینان از صحت داده‌ها در طول ذخیره‌سازی و انتقال داده‌های آموزشی استفاده می‌شوند.
 #1.2.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تکنیک‌های تشخیص خودکار برای جلوگیری از تغییرات غیرمجاز یا خراب شدن داده‌های آموزشی اعمال شده‌اند.
 #1.2.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که داده‌های آموزشی منسوخ به‌طور ایمن پاک‌سازی یا ناشناس‌سازی شده‌اند.
 #1.2.7    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تمام نسخه‌های مجموعه داده آموزش به‌صورت یکتا شناسایی شده، به‌طور غیرقابل تغییر ذخیره شده و قابل حسابرسی هستند تا از بازگردانی و تحلیل جنایی پشتیبانی کنند.

---

### C1.3 کیفیت، صحت و امنیت برچسب‌گذاری داده‌های آموزشی

برچسب‌ها را محافظت کنید و برای داده‌های حیاتی، بررسی فنی را الزامی کنید.

 #1.3.1    سطح: 2    نقش: D/V
 تأیید کنید که هش‌های رمزنگاری‌شده یا امضاهای دیجیتال به آثار برچسب‌گذاری شده اعمال شده‌اند تا صحت و اصالت آنها تضمین شود.
 #1.3.2    سطح: 2    نقش: D/V
 تأیید کنید که رابط‌ها و پلتفرم‌های برچسب‌گذاری کنترل‌های دسترسی قوی را اعمال می‌کنند، گزارش‌های حسابرسی مقاوم در برابر دستکاری از تمامی فعالیت‌های برچسب‌گذاری را نگهداری می‌کنند و در برابر تغییرات غیرمجاز محافظت می‌شوند.
 #1.3.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که اطلاعات حساس در برچسب‌ها در سطح فیلد داده‌ها هنگام ذخیره‌سازی و انتقال، محرمانه شده، ناشناس‌سازی شده یا رمزگذاری شده‌اند.

---

### C1.4 کیفیت داده‌های آموزش و تضمین امنیت

ترکیب اعتبارسنجی خودکار، بررسی‌های دستی نمونه‌ای، و ثبت اصلاحات برای تضمین قابلیت اطمینان مجموعه داده.

 #1.4.1    سطح: 1    نقش: D
 تأیید کنید که آزمایش‌های خودکار خطاهای قالب و مقدارهای null را در هر بار وارد کردن داده یا تبدیل مهم داده شناسایی کنند.
 #1.4.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که خط‌مشی‌های آموزش و تنظیم دقیق مدل‌های زبان بزرگ (LLM) شناسایی مسموم‌سازی و اعتبارسنجی یکپارچگی داده‌ها (مانند روش‌های آماری، تشخیص داده‌های پرت، تحلیل جاسازی‌ها) را پیاده‌سازی می‌کنند تا حملات احتمالی مسموم‌سازی (مانند تغییر برچسب‌ها، درج محرک در پشتی، دستورات تغییر نقش، حملات روی نمونه‌های تاثیرگذار) یا فساد غیرعمدی داده‌ها در داده‌های آموزشی را شناسایی کنند.
 #1.4.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که دفاع‌های مناسب، مانند آموزش مقابله‌ای (استفاده از نمونه‌های مقابله‌ای تولید شده)، افزایش داده‌ها با ورودی‌های تغییر یافته، یا تکنیک‌های بهینه‌سازی مقاوم، برای مدل‌های مرتبط بر اساس ارزیابی ریسک پیاده‌سازی و تنظیم شده باشند.
 #1.4.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که برچسب‌های تولید شده به‌طور خودکار (مثلاً از طریق مدل‌های زبانی بزرگ یا نظارت ضعیف) مشمول آستانه‌های اطمینان و بررسی‌های سازگاری برای شناسایی برچسب‌های ساختگی، گمراه‌کننده یا با اطمینان پایین هستند.
 #1.4.5    سطح: 3    نقش: D
 اطمینان حاصل کنید که تست‌های خودکار تغییرات ناصحیح برچسب را در هر بار ورود داده یا تغییرات مهم داده‌ها شناسایی می‌کنند.

---

### C1.5 ردیابی و منشأ داده‌ها

پیگیری کامل مسیر هر داده از منبع تا ورودی مدل برای قابلیت حسابرسی و واکنش به حوادث.

 #1.5.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که سیر تاریخی هر نقطه داده، شامل تمام تبدیلات، افزایش‌ها و ادغام‌ها، ثبت شده و قابل بازسازی باشد.
 #1.5.2    سطح: 2    نقش: D/V
 تأیید کنید که سوابق شجره‌نامه غیرقابل تغییر، به‌طور ایمن ذخیره شده و برای بازرسی‌ها قابل دسترسی باشند.
 #1.5.3    سطح: 2    نقش: D/V
 تأیید کنید که ردیابی خط سیر شامل داده‌های مصنوعی ایجاد شده از طریق تکنیک‌های حفظ حریم خصوصی یا تولیدی باشد و تمام داده‌های مصنوعی به وضوح برچسب‌گذاری شده و در طول کل فرآیند از داده‌های واقعی قابل تمایز باشند.

---

### مراجع

NIST AI Risk Management Framework
EU AI Act – Article 10: Data & Data Governance
MITRE ATLAS: Adversary Tactics for AI
Survey of ML Bias Mitigation Techniques – MDPI
Data Provenance & Lineage Best Practices – Nightfall AI
Data Labeling Quality Standards – LabelYourData
Training Data Poisoning Guide – Lakera.ai
CISA Advisory: Securing Data for AI Systems
ISO/IEC 23053: AI Management Systems Framework
IBM: What is AI Governance?
Google AI Principles
GDPR & AI Training Data – DataProtectionReport
Supply-Chain Security for AI Data – AppSOC
OpenAI Privacy Center – Data Deletion Controls
Adversarial ML Dataset – Kaggle

## اعتبارسنجی ورودی کاربر C2

### هدف کنترل

اعتبارسنجی محکم ورودی کاربر، نخستین خط دفاع در برابر برخی از مخرب‌ترین حملات به سیستم‌های هوش مصنوعی است. حملات تزریق پرامپت می‌توانند دستورالعمل‌های سیستم را نادیده بگیرند، داده‌های حساس را فاش کنند یا مدل را به سمت رفتاری هدایت کنند که مجاز نیست. مگر اینکه فیلترهای اختصاصی و سلسله‌مراتب دستوری برقرار باشد، تحقیقات نشان می‌دهد که «جلبریک‌های چندمرحله‌ای» که از پنجره‌های زمینه بسیار طولانی سوء استفاده می‌کنند، مؤثر خواهند بود. همچنین، حملات تغییرات ظریف خصمانه—مانند تعویض هوموگلیف یا زبان لِتس‌پیک—می‌توانند به‌صورت بی‌صدا تصمیمات مدل را تغییر دهند.

---

### C2.1 دفاع در برابر تزریق پرامپت

تزریق پرامپت یکی از بزرگترین ریسک‌ها برای سیستم‌های هوش مصنوعی است. دفاع در برابر این تاکتیک شامل ترکیبی از فیلترهای الگوی ایستا، طبقه‌بندی‌کننده‌های پویا و اجرای سلسله‌مراتب دستورات است.

 #2.1.1    سطح: 1    نقش: D/V
 تأیید کنید که ورودی‌های کاربر در برابر کتابخانه‌ای که به طور مداوم به‌روزرسانی می‌شود از الگوهای شناخته‌شده تزریق پرامپت (کلمات کلیدی فرار از محدودیت، «نادیده گرفتن قبلی»، زنجیره‌های نقش‌آفرینی، حملات غیرمستقیم HTML/URL) بررسی می‌شوند.
 #2.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم یک سلسله مراتب دستوری را اعمال می‌کند که در آن پیام‌های سیستم یا توسعه‌دهنده دستورالعمل‌های کاربر را لغو می‌کند، حتی پس از گسترش پنجره زمینه.
 #2.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که آزمون‌های ارزیابی مقابله‌ای (مثلاً درخواست‌های "چندشات" تیم قرمز) قبل از هر انتشار مدل یا قالب درخواست اجرا می‌شوند، با تعیین آستانه‌های نرخ موفقیت و مسدودکننده‌های خودکار برای پسرفت‌ها.
 #2.1.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که پرامپت‌های منشأ گرفته از محتوای شخص ثالث (صفحات وب، فایل‌های PDF، ایمیل‌ها) در یک زمینه پارسینگ جداگانه پاک‌سازی شده‌اند قبل از اینکه به پرامپت اصلی الحاق شوند.
 #2.1.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تمامی به‌روزرسانی‌های قوانین فیلتر پرامپت، نسخه‌های مدل طبقه‌بندی‌کننده و تغییرات فهرست مسدودشده تحت کنترل نسخه و قابل حسابرسی باشند.

---

### مقاومت در برابر نمونه‌های تهدیدآمیز (Adversarial-Example Resistance)

مدل‌های پردازش زبان طبیعی (NLP) همچنان در برابر تغییرات ظریف در سطح کاراکتر یا کلمه آسیب‌پذیر هستند که انسان‌ها اغلب آن‌ها را تشخیص نمی‌دهند اما مدل‌ها معمولاً در طبقه‌بندی اشتباه می‌کنند.

 #2.2.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که مراحل پایه نرمال‌سازی ورودی (NFC یونی‌کد، نگاشت هم‌ریشگی، حذف فاصله‌های زائد) قبل از توکنیزاسیون اجرا شوند.
 #2.2.2    سطح: 2    نقش: D/V
 بررسی کنید که تشخیص ناهنجاری آماری ورودی‌هایی را که فاصله ویرایشی غیرمعمول بالا نسبت به معیارهای زبانی، تکرار بیش از حد توکن‌ها، یا فاصله تعبیه نامتعارف دارند علامت‌گذاری کند.
 #2.2.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که خط لوله استنتاج از نسخه‌های مدل سخت‌شده با آموزش مقابله‌ای اختیاری یا لایه‌های دفاعی (برای مثال، تصادفی‌سازی، تقطیر دفاعی) برای نقاط پایانی پرخطر پشتیبانی می‌کند.
 #2.2.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که ورودی‌های مشکوک به عنوان حملات خصمانه قرنطینه شده، با بار کامل (پس از حذف اطلاعات شناسایی شخصی) ثبت می‌شوند.
 #2.2.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که معیارهای استحکام (نرخ موفقیت مجموعه حملات شناخته شده) در طول زمان رصد می‌شوند و پسرفت‌ها باعث ایجاد مانع در انتشار می‌شوند.

---

### C2.3 اعتبارسنجی طرحواره، نوع و طول

حملات هوش مصنوعی که شامل ورودی‌های نادرست یا بزرگ‌نمایی شده هستند می‌توانند باعث خطاهای تجزیه، نفوذ فرمان‌ها به فیلدهای دیگر و خستگی منابع شوند. همچنین، اجرای دقیق قوانین طرح‌واره (schema) هنگام انجام فراخوانی‌های ابزار قطعی ضروری است.

 #2.3.1    سطح: 1    نقش: D
 تأیید کنید که هر نقطه پایان API یا فراخوانی تابع یک طرح ورودی صریح (JSON Schema، Protobuf یا معادل چندوجهی) تعریف کرده است و ورودی‌ها قبل از جمع‌آوری درخواست اعتبارسنجی می‌شوند.
 #2.3.2    سطح: 1    نقش: D/V
 تأیید کنید که ورودی‌هایی که از حداکثر محدودیت توکن یا بایت فراتر می‌روند، با خطای ایمن رد شوند و هرگز به‌طور پنهانی کوتاه نشوند.
 #2.3.3    سطح: 2    نقش: D/V
 تأیید کنید که بررسی‌های نوع (مثلاً محدوده‌های عددی، مقادیر enum، نوع MIME برای تصاویر/صدا) در سمت سرور اعمال می‌شوند و نه فقط در کد کلاینت.
 #2.3.4    سطح: 2    نقش: D
 تأیید کنید که اعتبارسنج‌های معنایی (مانند JSON Schema) در زمان ثابت اجرا می‌شوند تا از حملات DoS الگوریتمی جلوگیری شود.
 #2.3.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که شکست‌های اعتبارسنجی با بخش‌های حذف‌شده از محتوا و کدهای خطای بدون ابهام ثبت می‌شوند تا به فرایند بررسی‌های امنیتی کمک کنند.

---

### C2.4 بررسی محتوا و سیاست‌ها

توسعه‌دهندگان باید بتوانند پرامپت‌های نحوی صحیح که درخواست محتوای غیرمجاز (مانند دستورالعمل‌های غیرقانونی، سخنان نفرت‌انگیز و متن‌های دارای حق کپی‌رایت) را دارند، شناسایی کرده و سپس از انتشار آن‌ها جلوگیری کنند.

 #2.4.1    سطح: 1    نقش: D
 تأیید کنید که یک طبقه‌بند محتوا (صفر شات یا ریزتنظیم شده) هر ورودی را برای خشونت، خودآسیبی، نفرت، محتوای جنسی و درخواست‌های غیرقانونی امتیازدهی می‌کند، با آستانه‌های قابل تنظیم.
 #2.4.2    سطح: 1    نقش: D/V
 تأیید کنید که ورودی‌هایی که سیاست‌ها را نقض می‌کنند، پاسخ‌های استاندارد شده امتناع یا تکمیل‌های ایمن دریافت خواهند کرد تا از انتشار آن‌ها به تماس‌های بعدی مدل زبان بزرگ جلوگیری شود.
 #2.4.3    سطح: 2    نقش: D
 تأیید کنید که مدل غربالگری یا مجموعه قوانین حداقل به‌صورت فصلی بازآموزی/به‌روزرسانی می‌شود و الگوهای جدید مشاهده شده از دورزدن امنیت یا دورزدن سیاست را در بر می‌گیرد.
 #2.4.4    سطح: 2    نقش: D
 تأیید کنید که غربالگری قوانین خاص کاربران (سن، محدودیت‌های قانونی منطقه‌ای) را از طریق قوانین مبتنی بر ویژگی که در زمان درخواست حل می‌شوند، رعایت می‌کند.
 #2.4.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که لاگ‌های غربالگری شامل امتیازهای اطمینان طبقه‌بندی‌کننده و برچسب‌های دسته‌بندی سیاست برای همبستگی SOC و بازپخش تیم قرمز آینده باشند.

---

### C2.5 محدود کردن نرخ ورودی و جلوگیری از سوءاستفاده

توسعه‌دهندگان باید از سوءاستفاده، اتمام منابع و حملات خودکار علیه سیستم‌های هوش مصنوعی با محدود کردن نرخ ورودی‌ها و شناسایی الگوهای استفاده غیرعادی جلوگیری کنند.

 #2.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که محدودیت‌های نرخ برای هر کاربر، هر IP و هر کلید API برای تمام نقاط ورودی اعمال شده‌اند.
 #2.5.2    سطح: 2    نقش: D/V
 تأیید کنید که محدودیت‌های نرخ انفجاری و پایدار به گونه‌ای تنظیم شده‌اند که از حملات انکار سرویس (DoS) و حدس‌های اجباری جلوگیری کنند.
 #2.5.3    سطح: 2    نقش: D/V
 تأیید کنید که الگوهای استفاده غیرمعمول (مثلاً درخواست‌های سریع متوالی، پرکردن ورودی) موجب فعال شدن مسدودسازی‌های خودکار یا افزایش سطح واکنش می‌شوند.
 #2.5.4    سطح: 3    نقش: V
 تأیید کنید که لاگ‌های پیشگیری از سوءاستفاده نگهداری شده و برای الگوهای حمله جدید بازبینی می‌شوند.

---

### C2.6 اعتبارسنجی ورودی چندرسانه‌ای

سیستم‌های هوش مصنوعی باید اعتبارسنجی قوی برای ورودی‌های غیرمتنی (تصاویر، صوت، فایل‌ها) داشته باشند تا از تزریق، فرار یا سوءاستفاده از منابع جلوگیری کنند.

 #2.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که تمام ورودی‌های غیر متنی (تصاویر، صدا، فایل‌ها) از نظر نوع، اندازه و فرمت قبل از پردازش اعتبارسنجی شوند.
 #2.6.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فایل‌ها قبل از ورود، برای بدافزار و بارهای پنهان‌شده استگانوگرافیک اسکن شده‌اند.
 #2.6.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که ورودی‌های تصویر/صدا برای اختلالات دشمن‌گونه یا الگوهای حمله شناخته شده بررسی شوند.
 #2.6.4    سطح: 3    نقش: V
 تأیید کنید که شکست‌های اعتبارسنجی ورودی چندرسانه‌ای ثبت و هشدارهایی برای تحقیق ایجاد می‌شوند.

---

### C2.7 منشاء و انتساب ورودی

سیستم‌های هوش مصنوعی باید از طریق نظارت و برچسب‌گذاری مبدا تمام ورودی‌های کاربران، از حسابرسی، پیگیری سوءاستفاده و انطباق پشتیبانی کنند.

 #2.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که همه ورودی‌های کاربران هنگام ورود با فراداده (شناسه کاربر، نشست، منبع، زمان‌سنجی، آدرس IP) برچسب‌گذاری شده‌اند.
 #2.7.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فراداده منشاء برای تمام ورودی‌های پردازش شده حفظ شده و قابل حسابرسی است.
 #2.7.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که منابع ورودی غیرعادی یا نامعتبر شناسایی شده و تحت بررسی دقیق‌تر یا مسدودسازی قرار گیرند.

---

### C2.8 تشخیص تهدید تطبیقی در زمان واقعی

توسعه‌دهندگان باید از سیستم‌های پیشرفته تشخیص تهدید برای هوش مصنوعی استفاده کنند که به الگوهای جدید حمله سازگار شده و حفاظت بلادرنگ با تطبیق الگوهای کامپایل شده ارائه دهند.

 #2.8.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که الگوهای تشخیص تهدید به موتورهای regex بهینه شده برای فیلتر کردن بلادرنگ با عملکرد بالا و کمترین تأثیر بر تأخیر کامپایل شده‌اند.
 #2.8.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های شناسایی تهدید، کتابخانه‌های الگو جداگانه‌ای برای دسته‌های مختلف تهدید (تزریق فرمان، محتوای مضر، داده‌های حساس، فرمان‌های سیستم) نگهداری می‌کنند.
 #2.8.3    سطح: 2    نقش: D/V
 تأیید کنید که تشخیص تهدید تطبیقی شامل مدل‌های یادگیری ماشین است که حساسیت تهدید را بر اساس فراوانی و نرخ موفقیت حملات به‌روزرسانی می‌کنند.
 #2.8.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فیدهای اطلاعات تهدیدات به‌صورت بلادرنگ به‌طور خودکار کتابخانه‌های الگو را با امضاهای جدید حمله و شاخص‌های نفوذ (IOCها) به‌روزرسانی می‌کنند.
 #2.8.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که نرخ‌های مثبت کاذب شناسایی تهدید به طور مداوم نظارت می‌شوند و ویژگی‌های الگوی تهدید به صورت خودکار تنظیم می‌شوند تا تداخل با موارد استفاده مشروع به حداقل برسد.
 #2.8.6    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تحلیل تهدید متنی منابع ورودی، الگوهای رفتار کاربر و تاریخچه جلسه را برای بهبود دقت تشخیص مدنظر قرار می‌دهد.
 #2.8.7    سطح: 3    نقش: D/V
 تأیید کنید که معیارهای عملکرد شناسایی تهدید (نرخ شناسایی، تأخیر پردازش، استفاده از منابع) به‌صورت بلادرنگ نظارت و بهینه‌سازی می‌شوند.

---

### C2.9 خط لوله اعتبارسنجی امنیت چندوجهی

توسعه‌دهندگان باید اعتبارسنجی امنیتی برای ورودی‌های متنی، تصویری، صوتی و سایر مدالیت‌های ورودی هوش مصنوعی با انواع خاصی از شناسایی تهدید و جداسازی منابع ارائه دهند.

 #2.9.1    سطح: 1    نقش: D/V
 تأیید کنید که هر حالت ورودی دارای اعتبارسنج‌های امنیتی اختصاصی با الگوهای تهدید مستند شده (متن: تزریق درخواست، تصاویر: نهان‌نگاری، صدا: حملات طیف‌نمایی) و آستانه‌های شناسایی باشد.
 #2.9.2    سطح: 2    نقش: D/V
 تأیید کنید که ورودی‌های چندرسانه‌ای در محیط‌های ایزوله شده با محدودیت‌های منابع تعریف‌شده (حافظه، پردازنده، زمان پردازش) که مخصوص هر نوع حالت هستند و در سیاست‌های امنیتی مستندسازی شده‌اند، پردازش می‌شوند.
 #2.9.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که شناسایی حملات چندرسانه‌ای، حملات هماهنگ شده‌ای که شامل چندین نوع ورودی هستند (به عنوان مثال، بارهای پنهان‌شده در تصاویر همراه با تزریق درخواست در متن) را با قوانین همبستگی و تولید هشدار شناسایی می‌کند.
 #2.9.4    سطح: 3    نقش: D/V
 تأیید کنید که خطاهای اعتبارسنجی چندرسانه‌ای باعث ثبت دقیق لاگ شوند که شامل تمام حالت‌های ورودی، نتایج اعتبارسنجی، امتیازهای تهدید و تحلیل همبستگی با فرمت‌های ساختاریافته لاگ برای ادغام با SIEM باشد.
 #2.9.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که طبقه‌بندی‌کننده‌های محتوا مخصوص مدالیتی طبق برنامه‌های مستند شده (حداقل به صورت سه‌ماهه) با الگوهای تهدید جدید، نمونه‌های مقابله‌ای و معیارهای عملکردی که بالاتر از آستانه‌های پایه نگهداری می‌شوند، به‌روزرسانی می‌شوند.

---

### مراجع

LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security
Generative AI's Biggest Security Flaw Is Not Easy to Fix
Many-shot jailbreaking \ Anthropic
$PDF$ OpenAI GPT-4.5 System Card
Notebook for the CheckThat Lab at CLEF 2024
Mitigate jailbreaks and prompt injections – Anthropic
Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis
OWASP Top 10 for LLM Applications 2025 – WorldTech IT
OWASP Machine Learning Security Top Ten
Few words about AI Security – Jussi Metso
How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry
Easily enforcing valid JSON schema following – API
AI Safety + Cybersecurity R\&D Tracker – Fairly AI
Anthropic makes 'jailbreak' advance to stop AI models producing harmful results
Pattern matching filter rules - IBM
Real-time Threat Detection

## مدیریت چرخه عمر مدل C3 و کنترل تغییرات

### هدف کنترل

سیستم‌های هوش مصنوعی باید فرآیندهای کنترل تغییر را پیاده‌سازی کنند که از رسیدن تغییرات غیرمجاز یا ناایمن مدل به محیط تولید جلوگیری کند. این کنترل، یکپارچگی مدل را در طول کل چرخه عمر—از توسعه تا استقرار و خارج‌سازی از خدمت—تضمین می‌کند که پاسخ سریع به حوادث را ممکن ساخته و مسئولیت‌پذیری برای همه تغییرات را حفظ می‌کند.

هدف اصلی امنیت: فقط مدل‌های مجاز و معتبر شده با استفاده از روندهای کنترل شده که صحت، قابلیت ردیابی و بازیابی را حفظ می‌کنند، به مرحله تولید می‌رسند.

---

### C3.1 مجوز مدل و یکپارچگی

فقط مدل‌های مجاز با صحت تایید شده به محیط‌های تولید می‌رسند.

 #3.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام مصنوعات مدل (وزن‌ها، پیکربندی‌ها، توکنایزرها) قبل از استقرار به‌صورت رمزنگاری‌شده توسط نهادهای مجاز امضا شده‌اند.
 #3.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که صحت مدل در زمان استقرار اعتبارسنجی می‌شود و خطاهای تأیید امضاء از بارگذاری مدل جلوگیری می‌کنند.
 #3.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که سوابق منشأ مدل شامل هویت نهاد مجازکننده، چک‌سام‌های داده‌های آموزشی، نتایج آزمون‌های اعتبارسنجی با وضعیت قبول/رد، و یک زمان‌سنجی ایجاد باشد.
 #3.1.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تمام مصنوعات مدل از نسخه بندی معنایی (MAJOR.MINOR.PATCH) استفاده می‌کنند و معیارهای مستند شده‌ای وجود دارد که مشخص می‌کند هر بخش از نسخه کی افزایش می‌یابد.
 #3.1.5    سطح: 2    نقش: V
 اطمینان حاصل کنید که پیگیری وابستگی‌ها یک فهرست واقعی به‌روز را حفظ می‌کند که امکان شناسایی سریع تمام سیستم‌های مصرف‌کننده را فراهم می‌آورد.

---

### C3.2 اعتبارسنجی و آزمون مدل

مدل‌ها باید پیش از استقرار، آزمایش‌های تعریف شده امنیت و ایمنی را با موفقیت پشت سر بگذارند.

 #3.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مدل‌ها قبل از استقرار، تحت آزمایش امنیتی خودکار قرار می‌گیرند که شامل اعتبارسنجی ورودی، پاک‌سازی خروجی، و ارزیابی‌های ایمنی با حد آستانه‌های قبلاً توافق‌شده سازمانی برای قبول یا رد می‌باشد.
 #3.2.2    سطح: 1    نقش: D/V
 تأیید کنید که خطاهای اعتبارسنجی به‌طور خودکار پس از تصویب صریح از سوی پرسنل مجاز پیش‌تعیین‌شده با توجیهات مستند تجاری، مانع استقرار مدل می‌شوند.
 #3.2.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که نتایج آزمون به صورت رمزنگاری شده امضا شده‌اند و به طور غیرقابل تغییر به هش نسخه مشخص مدل که در حال اعتبارسنجی است، متصل شده‌اند.
 #3.2.4    سطح: 2    نقش: D/V
 تأیید کنید که استقرارهای اضطراری نیازمند ارزیابی مستند ریسک امنیتی و تأیید از سوی یک مرجع امنیتی از پیش تعیین‌شده در بازه‌های زمانی از پیش توافق‌شده هستند.

---

### C3.3 استقرار کنترل‌شده و بازگرداندن نسخه

استقرار مدل‌ها باید کنترل‌شده، پایش‌شده و قابلیت بازگشت داشته باشد.

 #3.3.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که استقرارهای تولید مکانیزم‌های انتشار تدریجی (استقرارهای کاناری، استقرارهای آبی-سبز) را با فعال‌سازی خودکار بازگشت به حالت قبل بر اساس نرخ‌های خطای توافق‌شده قبلی، آستانه‌های تأخیر یا معیارهای هشدار امنیتی پیاده‌سازی می‌کنند.
 #3.3.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که قابلیت‌های بازگشت به عقب، وضعیت کامل مدل (وزن‌ها، پیکربندی‌ها، وابستگی‌ها) را به‌صورت اتمی و در بازه‌های زمانی از پیش تعریف شده سازمانی بازیابی می‌کنند.
 #3.3.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فرآیندهای استقرار امضاهای رمزنگاری شده را اعتبارسنجی کرده و قبل از فعال‌سازی مدل، چک‌سام‌های صحت را محاسبه می‌کنند، و در صورت هر گونه مغایرت، استقرار را متوقف می‌کنند.
 #3.3.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که قابلیت‌های توقف اضطراری مدل قادر به غیرفعال کردن نقاط انتهایی مدل در زمان‌های پاسخ از پیش تعیین شده از طریق قطع‌کننده‌های مدار خودکار یا کلیدهای خاموش دستی هستند.
 #3.3.5    سطح: 2    نقش: V
 تأیید کنید که مصنوعات بازگشت به عقب (نسخه‌های قبلی مدل، تنظیمات، وابستگی‌ها) مطابق با سیاست‌های سازمانی با استفاده از ذخیره‌سازی غیرقابل تغییر برای پاسخ به حوادث حفظ شده‌اند.

---

### C3.4 تغییر مسئولیت‌پذیری و حسابرسی

تمام تغییرات در طول چرخه عمر مدل باید قابل ردیابی و حسابرسی باشند.

 #3.4.1    سطح: 1    نقش: V
 اطمینان حاصل کنید که تمام تغییرات مدل (استقرار، پیکربندی، بازنشستگی) سوابق حسابرسی غیرقابل تغییر را ایجاد می‌کنند که شامل یک مهرزمان، هویت بازیگر تأیید شده، نوع تغییر، و وضعیت‌های قبل/بعد باشد.
 #3.4.2    سطح: 2    نقش: D/V
 تأیید کنید که دسترسی به گزارش حسابرسی نیازمند مجوز مناسب است و تمام تلاش‌های دسترسی با هویت کاربر و زمان‌سنجی ثبت می‌شوند.
 #3.4.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که قالب‌های پرامپت و پیام‌های سیستمی در مخازن گیت با کنترل نسخه قرار دارند و بازبینی کد اجباری همراه با تأیید از سوی بازبین‌های تعیین‌شده پیش از استقرار انجام می‌شود.
 #3.4.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که سوابق حسابرسی شامل جزئیات کافی (هش‌های مدل، عکس‌های لحظه‌ای پیکربندی، نسخه‌های وابستگی) باشد تا امکان بازسازی کامل حالت مدل برای هر زمان مشخص در دوره نگهداری فراهم شود.

---

### C3.5 روش‌های توسعه امن

فرآیندهای توسعه و آموزش مدل باید از روش‌های امن پیروی کنند تا از به خطر افتادن جلوگیری شود.

 #3.5.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که محیط‌های توسعه مدل، تست و تولید به صورت فیزیکی یا منطقی جدا شده‌اند. آن‌ها هیچ زیرساخت مشترکی ندارند، کنترل‌های دسترسی متمایز و ذخیره‌سازی داده‌های جداگانه دارند.
 #3.5.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که آموزش مدل و بهینه‌سازی دقیق در محیط‌های جداسازی شده با دسترسی شبکه کنترل شده انجام می‌شود.
 #3.5.3    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که منابع داده‌های آموزشی از طریق بررسی‌های صحت کامل شده و از منابع مورد اعتماد با زنجیره تصدیق مستند قبل از استفاده در توسعه مدل، احراز هویت شده باشند.
 #3.5.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که محصولات توسعه مدل (هایپرپارامترها، اسکریپت‌های آموزش، فایل‌های پیکربندی) در کنترل نسخه ذخیره شده‌اند و قبل از استفاده در آموزش، نیاز به تأیید بازبینی همتا دارند.

---

### C3.6 بازنشستگی و از کار انداختن مدل

مدل‌ها باید به‌صورت امن بازنشسته شوند وقتی دیگر نیازی به آنها نیست یا زمانی که مشکلات امنیتی شناسایی می‌شوند.

 #3.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که فرایندهای بازنشستگی مدل به صورت خودکار نمودارهای وابستگی را اسکن می‌کنند، تمام سیستم‌های مصرف‌کننده را شناسایی می‌کنند و دوره‌های اطلاع‌رسانی قبلی از پیش توافق‌شده را قبل از بازنشستگی ارائه می‌دهند.
 #3.6.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مصنوعات مدل بازنشسته به صورت ایمن با استفاده از پاک‌سازی رمزنگاری شده یا بازنویسی چندباره بر اساس سیاست‌های مستند حفظ داده‌ها و با گواهی‌های تأیید شده تخریب، پاک شده‌اند.
 #3.6.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که رویدادهای بازنشستگی مدل با زمان‌بندی و هویت بازیگر ثبت می‌شوند و امضاهای مدل برای جلوگیری از استفاده مجدد لغو می‌شوند.
 #3.6.4    سطح: 2    نقش: D/V
 تأیید کنید که بازنشستگی اضطراری مدل می‌تواند دسترسی به مدل را در بازه‌های زمانی پاسخ اضطراری از پیش تعیین شده از طریق کلیدهای قطع خودکار غیرفعال کند در صورتی که آسیب‌پذیری‌های امنیتی حیاتی کشف شوند.

---

### مراجع

MLOps Principles
Securing AI/ML Ops – Cisco.com
Audit logs security: cryptographically signed tamper-proof logs
Machine Learning Model Versioning: Top Tools & Best Practices
AI Hygiene Starts with Models and Data Loaders – SEI Blog
How to handle versioning and rollback of a deployed ML model?
Reinforcement fine-tuning – OpenAI API
Auditing Machine Learning models: Governance, Data Security and …
Adversarial Training to Improve Model Robustness
What is AI adversarial robustness? – IBM Research
Exploring Data Provenance: Ensuring Data Integrity and Authenticity
MITRE ATLAS
AWS Prescriptive Guidance – Best practices for retiring applications …

## زیرساخت C4، پیکربندی و امنیت استقرار

### هدف کنترل

زیرساخت هوش مصنوعی باید در برابر افزایش دسترسی‌های غیرمجاز، دستکاری زنجیره تامین و حرکت جانبی از طریق پیکربندی امن، جداسازی در زمان اجرا، خطوط لوله استقرار معتبر و پایش جامع سخت‌گیرانه شود. تنها اجزای زیرساخت و پیکربندی‌های مجاز و معتبر شده از طریق فرآیندهای کنترل شده که امنیت، یکپارچگی و امکان حسابرسی را حفظ می‌کنند، به محیط تولید می‌رسند.

هدف اصلی امنیت: تنها اجزای زیرساختی که به صورت رمزنگاری شده امضاء شده و از نظر آسیب‌پذیری اسکن شده‌اند، از طریق خطوط لوله اعتبارسنجی خودکار که سیاست‌های امنیتی را اجرا می‌کنند و سوابق حسابرسی تغییرناپذیر را حفظ می‌کنند، به محیط تولید می‌رسند.

---

### C4.1 جداسازی محیط اجرای زمان اجرا

جلوگیری از فرار از کانتینر و افزایش امتیاز از طریق ابتداییات ایزوله‌سازی در سطح کرنل و کنترل‌های دسترسی اجباری.

 #4.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام کانتینرهای هوش مصنوعی تمامی قابلیت‌های لینوکس را به استثنای CAP_SETUID، CAP_SETGID، و قابلیت‌های صریحاً مورد نیاز که در مبناهای امنیتی مستند شده‌اند، حذف کنند.
 #4.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که پروفایل‌های seccomp تمامی فراخوانی‌های سیستمی را به جز آن‌هایی که در فهرست‌های مجاز از پیش تعیین‌شده هستند، مسدود می‌کنند، به گونه‌ای که هرگونه تخلف منجر به خاتمه کانتینر و ایجاد هشدارهای امنیتی شود.
 #4.1.3    سطح: 2    نقش: D/V
 بررسی کنید که بارهای کاری هوش مصنوعی با سیستم‌فایل‌های ریشه فقط خواندنی، tmpfs برای داده‌های موقتی، و حجم‌های نامگذاری شده برای داده‌های پایدار با گزینه‌های اتصال noexec اجرا شوند.
 #4.1.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که پایش زمان اجرا مبتنی بر eBPF (مانند Falco، Tetragon یا معادل آن) تلاش‌های افزایش امتیازات دسترسی را شناسایی کرده و فرآیندهای متخلف را به‌طور خودکار در چارچوب زمان پاسخگویی سازمانی خاتمه می‌دهد.
 #4.1.5    سطح: 3    نقش: D/V
 تأیید کنید که بارهای کاری هوش مصنوعی با ریسک بالا در محیط‌های ایزوله سخت‌افزاری (Intel TXT، AMD SVM، یا گره‌های اختصاصی بدون سیستم‌عامل) با تأیید اعتبار اجرا می‌شوند.

---

### C4.2  خطوط لوله ساخت و استقرار ایمن

از طریق ساخت‌های قابل بازتولید و آثار امضا شده، یکپارچگی رمزنگاری و امنیت زنجیره تأمین را تضمین کنید.

 #4.2.1    سطح: 1    نقش: D/V
 تأیید کنید که زیرساخت به‌عنوان کد با ابزارهایی مانند tfsec، Checkov، یا Terrascan در هر مرتبه کامیت اسکن می‌شود و ادغام‌ها در صورت وجود یافته‌های با شدت CRITICAL یا HIGH مسدود می‌شوند.
 #4.2.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که ساخت کانتینرها با هش‌های SHA256 یکسان در تمام ساخت‌ها قابل بازتولید باشند و گواهی‌های اثبات اصالت سطح 3 SLSA با امضای Sigstore تولید شوند.
 #4.2.3    سطح: 2    نقش: D/V
 تأیید کنید که تصاویر کانتینر شامل CycloneDX یا SPDX SBOM‌ها هستند و قبل از ارسال به رجیستری با Cosign امضا شده‌اند، و تصاویر بدون امضا در زمان استقرار رد شوند.
 #4.2.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که خطوط لوله CI/CD از توکن‌های OIDC از HashiCorp Vault، نقش‌های IAM در AWS، یا شناسه مدیریت‌شده Azure استفاده می‌کنند که طول عمر آن‌ها از محدودیت‌های سیاست‌های امنیتی سازمان فراتر نمی‌رود.
 #4.2.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که امضاهای Cosign و منشأ SLSA در طول فرآیند استقرار قبل از اجرای کانتینر اعتبارسنجی می‌شوند و خطاهای تأیید باعث شکست استقرار می‌شوند.
 #4.2.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که محیط‌های ساخت در کانتینرهای موقت یا ماشین‌های مجازی اجرا می‌شوند که ذخیره‌سازی مداوم ندارند و از شبکه‌های VPC تولید به صورت ایزوله جدا شده‌اند.

---

### C4.3 امنیت شبکه و کنترل دسترسی

اجرای شبکه‌سازی اعتماد صفر با سیاست‌های پیش‌فرض انکار و ارتباطات رمزگذاری‌شده.

 #4.3.1    سطح: 1    نقش: D/V
 بررسی کنید که Kubernetes NetworkPolicies یا معادل آن پیاده‌سازی پیش‌فرض مسدودسازی ورودی/خروجی به همراه قوانین صریح اجازه برای پورت‌های مورد نیاز (443، 8080 و غیره) را انجام داده باشد.
 #4.3.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که پورت SSH (پورت 22)، پورت RDP (پورت 3389) و نقاط پایانی متادیتای ابری (169.254.169.254) مسدود شده‌اند یا به احراز هویت مبتنی بر گواهی‌نامه نیاز دارند.
 #4.3.3    سطح: 2    نقش: D/V
 تأیید کنید که ترافیک خروجی از طریق پراکسی‌های HTTP/HTTPS (مانند Squid، Istio، یا دروازه‌های NAT ابری) با استفاده از فهرست‌های مجاز دامنه فیلتر شده و درخواست‌های مسدود شده ثبت شوند.
 #4.3.4    سطح: 2    نقش: D/V
 تأیید کنید که ارتباط بین سرویس‌ها از TLS متقابل با گواهی‌نامه‌هایی که طبق سیاست سازمانی چرخش می‌یابند استفاده می‌کند و اعتبارسنجی گواهی‌نامه‌ها اجرا می‌شود (بدون استفاده از گزینه‌های skip-verify).
 #4.3.5    سطح: 2    نقش: D/V
 تأیید کنید که زیرساخت‌های هوش مصنوعی در VPCها/VNetهای اختصاصی اجرا می‌شوند که دسترسی مستقیم به اینترنت ندارند و فقط از طریق دروازه‌های NAT یا میزبان‌های بستیون ارتباط برقرار می‌کنند.

---

### C4.4 مدیریت اسرار و کلیدهای رمزنگاری

محافظت از اعتبارنامه‌ها از طریق ذخیره‌سازی پشتیبانی‌شده توسط سخت‌افزار و چرخش خودکار با دسترسی مبتنی بر اعتماد صفر.

 #4.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که اسرار در HashiCorp Vault، AWS Secrets Manager، Azure Key Vault یا Google Secret Manager با رمزنگاری در حالت استراحت با استفاده از AES-256 ذخیره شده‌اند.
 #4.4.2    سطح: 1    نقش: D/V
 تأیید کنید که کلیدهای رمزنگاری در HSMهای سطح 2 FIPS 140-2 (AWS CloudHSM، Azure Dedicated HSM) با چرخش کلید مطابق با سیاست رمزنگاری سازمانی تولید شده‌اند.
 #4.4.3    سطح: 2    نقش: D/V
 تأیید کنید که چرخش اسرار به صورت خودکار با استقرار بدون زمان توقف و چرخش فوری ناشی از تغییرات پرسنلی یا رخدادهای امنیتی انجام می‌شود.
 #4.4.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تصاویر کانتینر با ابزارهایی مانند GitLeaks، TruffleHog یا detect-secrets اسکن می‌شوند تا ساخت‌هایی که شامل کلیدهای API، گذرواژه‌ها یا گواهینامه‌ها هستند، مسدود شوند.
 #4.4.5    سطح: 2    نقش: D/V
 تأیید کنید که دسترسی به کلیدهای محرمانه تولیدی مستلزم MFA با توکن‌های سخت‌افزاری (YubiKey، FIDO2) باشد و این دسترسی توسط لاگ‌های حسابرسی غیرقابل تغییر با شناسه کاربران و زمان‌بندی‌ها ثبت گردد.
 #4.4.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اسرار از طریق اسرار Kubernetes، حجم‌های متصل شده یا کانتینرهای init تزریق می‌شوند و مطمئن شوید که اسرار هرگز در متغیرهای محیطی یا ایمیج‌ها جاسازی نشده‌اند.

---

### C4.5 جداسازی و اعتبارسنجی بار کاری هوش مصنوعی

مدل‌های هوش مصنوعی غیرقابل اعتماد را در محیط‌های محافظت‌شده ایزوله کنید و تحلیل رفتاری جامع انجام دهید.

 #4.5.1    سطح: 1    نقش: D/V
 بررسی کنید که مدل‌های هوش مصنوعی خارجی در gVisor، microVMها (مانند Firecracker، CrossVM) یا کانتینرهای داکر با گزینه‌های --security-opt=no-new-privileges و --read-only اجرا می‌شوند.
 #4.5.2    سطح: 1    نقش: D/V
 تأیید کنید که محیط‌های سندباکس هیچ اتصال شبکه‌ای نداشته باشند (--network=none) یا فقط به localhost دسترسی داشته باشند و تمامی درخواست‌های خارجی توسط قوانین iptables مسدود شده باشند.
 #4.5.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اعتبارسنجی مدل هوش مصنوعی شامل آزمایش خودکار تیم قرمز با پوشش تست تعریف شده توسط سازمان و تحلیل رفتاری برای تشخیص درب پشتی است.
 #4.5.4    سطح: 2    نقش: D/V
 تأیید کنید که قبل از ارتقاء یک مدل هوش مصنوعی به محیط تولید، نتایج آن در محیط آزمایشی به‌صورت رمزنگاری شده توسط پرسنل امنیتی مجاز امضا شده و در گزارش‌های حسابرسی غیرقابل تغییر ذخیره شده باشند.
 #4.5.5    سطح: 2    نقش: D/V
 تأیید کنید که محیط‌های سندباکس بین ارزیابی‌ها با تخریب و بازسازی از تصاویر طلایی همراه با پاک‌سازی کامل فایل‌سیستم و حافظه انجام می‌شوند.

---

### C4.6 نظارت بر امنیت زیرساخت

زیرساخت را به‌طور مداوم اسکن و پایش کنید با اصلاح خودکار و هشداردهی در لحظه.

 #4.6.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تصاویر کانتینر طبق برنامه‌های سازمانی اسکن می‌شوند و آسیب‌پذیری‌های بحرانی بر اساس آستانه‌های ریسک سازمانی، مانع از استقرار می‌شوند.
 #4.6.2    سطح: 1    نقش: D/V
 تأیید کنید که زیرساخت‌ها با معیارهای CIS یا کنترل‌های NIST 800-53، همراه با آستانه‌های انطباق تعریف‌شده توسط سازمان و اصلاح خودکار برای بررسی‌های ناموفق، مطابقت دارند.
 #4.6.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که آسیب‌پذیری‌های با شدت بالا بر اساس زمان‌بندی مدیریت ریسک سازمانی رفع شده‌اند و رویه‌های اضطراری برای CVEهای فعال که مورد سوءاستفاده قرار می‌گیرند، اعمال شده است.
 #4.6.4    سطح: 2    نقش: V
 تأیید کنید که هشدارهای امنیتی با پلتفرم‌های SIEM (مانند Splunk، Elastic یا Sentinel) با استفاده از فرمت‌های CEF یا STIX/TAXII و با غنی‌سازی خودکار یکپارچه شده باشند.
 #4.6.5    سطح: 3    نقش: V
 تأیید کنید که معیارهای زیرساخت به سیستم‌های نظارتی (مانند Prometheus، DataDog) صادر می‌شوند و داشبوردهای SLA و گزارش‌گیری مدیریتی نیز فراهم شده‌اند.
 #4.6.6    سطح: 2    نقش: D/V
 تأیید کنید که انحراف پیکربندی با استفاده از ابزارها (Chef InSpec، AWS Config) مطابق با الزامات نظارتی سازمانی شناسایی شود و تغییرات غیرمجاز به‌صورت خودکار بازگردانده شوند.

---

### مدیریت منابع زیرساخت هوش مصنوعی C4.7

جلوگیری از حملات خستگی منابع و اطمینان از تخصیص منصفانه منابع از طریق سهمیه‌بندی و نظارت.

 #4.7.1    سطح: 1    نقش: D/V
 تأیید کنید که استفاده از GPU/TPU زیر نظر گرفته شده است و هشدارها در آستانه‌های تعریف شده سازمانی فعال می‌شوند و مقیاس‌بندی خودکار یا تعادل بار بر اساس سیاست‌های مدیریت ظرفیت انجام می‌گردد.
 #4.7.2    سطح: 1    نقش: D/V
 تأیید کنید که معیارهای بار کاری هوش مصنوعی (تاخیر استنباط، توان عملیاتی، نرخ خطاها) بر اساس الزامات نظارت سازمانی جمع‌آوری شده و با استفاده زیرساختی مرتبط شده‌اند.
 #4.7.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که Kubernetes ResourceQuotas یا معادل آن، بارهای کاری فردی را مطابق با سیاست‌های تخصیص منابع سازمانی با محدودیت‌های سخت‌گیرانه اعمال شده محدود می‌کند.
 #4.7.4    سطح: 2    نقش: V
 تأیید کنید که پایش هزینه، هزینه‌ها را برای هر بار کاری/مستأجر ردیابی می‌کند و هشدارهایی بر اساس آستانه‌های بودجه سازمانی و کنترل‌های خودکار برای تجاوزات بودجه ارائه می‌دهد.
 #4.7.5    سطح: 3    نقش: V
 تأیید کنید که برنامه‌ریزی ظرفیت از داده‌های تاریخی با دوره‌های پیش‌بینی تعریف‌شده سازمانی و تأمین منابع خودکار بر اساس الگوهای تقاضا استفاده می‌کند.
 #4.7.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فرسودگی منابع، قطع‌کننده‌های مدار را مطابق با نیازهای پاسخ سازمانی فعال می‌کند، از جمله محدودیت نرخ بر اساس سیاست‌های ظرفیت و ایزوله‌سازی بار کاری.

---

### C4.8 تفکیک محیط و کنترل‌های ارتقاء

اجرای مرزهای محیطی سختگیرانه با دروازه‌های ارتقاء خودکار و اعتبارسنجی امنیتی.

 #4.8.1    سطح: 1    نقش: D/V
 تأیید کنید که محیط‌های توسعه/تست/تولید در VPCها/VNetهای جداگانه اجرا می‌شوند و هیچ نقش IAM، گروه امنیتی یا اتصال شبکه مشترکی ندارند.
 #4.8.2    سطح: 1    نقش: D/V
 تأیید کنید که ترفیع محیط نیازمند تأییدیه از افراد مجاز تعریف شده توسط سازمان با امضاهای رمزنگاری شده و سوابق بازبینی غیرقابل تغییر باشد.
 #4.8.3    سطح: 2    نقش: D/V
 تأیید کنید که محیط‌های تولیدی دسترسی SSH را مسدود می‌کنند، نقاط اشکال‌زدایی را غیرفعال می‌کنند و درخواست‌های تغییر با الزامات اطلاع قبلی سازمانی، به جز موارد اضطراری، را لازم می‌دانند.
 #4.8.4    سطح: 2    نقش: D/V
 تأیید کنید که تغییرات زیرساخت به‌عنوان‌کد نیازمند بازبینی همتایان همراه با آزمایش خودکار و اسکن امنیتی قبل از ادغام به شاخه اصلی است.
 #4.8.5    سطح: 2    نقش: D/V
 تأیید کنید که داده‌های غیرتولیدی بر اساس الزامات حفظ حریم خصوصی سازمانی ناشناس شده‌اند، تولید داده‌های مصنوعی انجام شده است، یا ماسک‌گذاری کامل داده‌ها با حذف اطلاعات شناسایی شخصی (PII) تأیید شده است.
 #4.8.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که در دروازه‌های ارتقاء، آزمون‌های امنیتی خودکار (SAST، DAST، اسکن کانتینر) شامل شده باشند و هیچ نتیجه بحرانی (CRITICAL) برای تأیید مورد نیاز نباشد.

---

### پشتیبان‌گیری و بازیابی زیرساخت C4.9

اطمینان از مقاومت زیرساخت از طریق پشتیبان‌گیری‌های خودکار، رویه‌های بازیابی آزمایش‌شده و قابلیت‌های بازیابی از فاجعه.

 #4.9.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که پیکربندی‌های زیرساخت مطابق با برنامه‌های پشتیبان‌گیری سازمانی به مناطق جغرافیایی جداگانه پشتیبان‌گیری شده‌اند و استراتژی پشتیبان‌گیری 3-2-1 اجرا شده است.
 #4.9.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های پشتیبان‌گیری در شبکه‌های جداگانه با اعتبارنامه‌های مجزا و ذخیره‌سازی ایزوله شده (air-gapped) برای حفاظت در برابر باج‌افزار اجرا می‌شوند.
 #4.9.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که روش‌های بازیابی از طریق تست خودکار مطابق با برنامه‌های سازمانی و با اهداف RTO و RPO که نیازهای سازمان را برآورده می‌کنند، آزمایش و تأیید شده‌اند.
 #4.9.4    سطح: 3    نقش: V
 تأیید کنید که بازیابی از فاجعه شامل کتابچه‌های راهنمای خاص هوش مصنوعی با بازسازی وزن مدل، بازسازی خوشه GPU، و نقشه‌برداری وابستگی سرویس‌ها باشد.

---

### C4.10 تطابق زیرساخت و حاکمیت

با ارزیابی مداوم، مستندسازی و کنترل‌های خودکار، هماهنگی با قوانین و مقررات را حفظ کنید.

 #4.10.1    سطح: 2    نقش: D/V
 اطمینان حاصل شود که تطابق زیرساخت طبق برنامه‌های سازمان و با استفاده از جمع‌آوری خودکار مدارک، بر اساس کنترل‌های SOC 2، ISO 27001 یا FedRAMP ارزیابی می‌شود.
 #4.10.2    سطح: 2    نقش: V
 تایید کنید که مستندات زیرساخت شامل نمودارهای شبکه، نقشه‌های جریان داده و مدل‌های تهدید به‌روز شده مطابق با الزامات مدیریت تغییر سازمانی باشد.
 #4.10.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تغییرات زیرساختی، ارزیابی تأثیر تطابق خودکار با گردش‌کارهای تأییدیه قانونی برای اصلاحات پرخطر را طی می‌کنند.

---

### C4.11 امنیت سخت‌افزار هوش مصنوعی

حفاظت از سخت‌افزارهای خاص هوش مصنوعی شامل GPUها، TPUها و شتاب‌دهنده‌های تخصصی هوش مصنوعی.

 #4.11.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که سیستم‌عامل تسریع‌کننده هوش مصنوعی (GPU BIOS، سیستم‌عامل TPU) با امضاهای رمزنگاری شده تأیید شده و مطابق با زمان‌بندی مدیریت پچ سازمانی به‌روزرسانی می‌شود.
 #4.11.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که قبل از اجرای بار کاری، یکپارچگی شتاب‌دهنده هوش مصنوعی از طریق تصدیق سخت‌افزاری با استفاده از TPM 2.0، Intel TXT یا AMD SVM تأیید شود.
 #4.11.3    سطح: 2    نقش: D/V
 تأیید کنید که حافظه GPU بین بارهای کاری با استفاده از SR-IOV، MIG (کارت گرافیک چند نمونه‌ای) یا تقسیم‌بندی سخت‌افزاری معادل به همراه پاک‌سازی حافظه بین وظایف ایزوله شده است.
 #4.11.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که زنجیره تامین سخت‌افزار هوش مصنوعی شامل تایید اصالت با گواهی‌های تولیدکننده و اعتبارسنجی بسته‌بندی مقاوم در برابر دستکاری باشد.
 #4.11.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که ماژول‌های امنیت سخت‌افزاری (HSMها) وزن‌های مدل هوش مصنوعی و کلیدهای رمزنگاری را با گواهی‌نامه FIPS 140-2 سطح 3 یا معیارهای عمومی Common Criteria با رتبه EAL4+ محافظت می‌کنند.

---

### C4.12 زیرساخت هوش مصنوعی لبه و توزیع‌شده

استقرارهای ایمن هوش مصنوعی توزیع‌شده از جمله محاسبات لبه، یادگیری فدرال و معماری‌های چندسایتی.

 #4.12.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که دستگاه‌های هوش مصنوعی لبه‌ای از طریق TLS متقابل با زیرساخت مرکزی احراز هویت می‌شوند و گواهی‌های دستگاه مطابق با سیاست مدیریت گواهی سازمانی چرخش می‌یابند.
 #4.12.2    سطح: 2    نقش: D/V
 تأیید کنید که دستگاه‌های لبه‌ای بوت امن را با امضاهای تأیید شده و محافظت در برابر بازگشت به نسخه‌های قبلی (rollback protection) پیاده‌سازی می‌کنند تا از حملات کاهش نسخه فرم‌ور جلوگیری شود.
 #4.12.3    سطح: 3    نقش: D/V
 تأیید کنید که هماهنگی هوش مصنوعی توزیع‌شده از الگوریتم‌های اجماع تحمل خرابی بیزانسی با اعتبارسنجی شرکت‌کنندگان و شناسایی گره‌های مخرب استفاده می‌کند.
 #4.12.4    سطح: 3    نقش: D/V
 تأیید کنید که ارتباط لبه تا ابر شامل محدودیت پهنای باند، فشرده‌سازی داده‌ها و قابلیت‌های عملکرد آفلاین با ذخیره‌سازی محلی ایمن باشد.

---

### C4.13 امنیت زیرساخت چندابری و ترکیبی

بارکاری‌های امن هوش مصنوعی را در چندین ارائه‌دهنده ابری و استقرارهای ترکیبی ابری-محلی تضمین کنید.

 #4.13.1    سطح: 2    نقش: D/V
 بررسی کنید که استقرارهای چندابری هوش مصنوعی از اتحاد هویت مستقل از ابر (OIDC، SAML) با مدیریت سیاست متمرکز در سراسر ارائه‌دهندگان استفاده می‌کنند.
 #4.13.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که انتقال داده‌های بین ابرها از رمزگذاری انتها به انتها با کلیدهای مدیریت شده توسط مشتری و کنترل‌های محل نگهداری داده‌ها مطابق با حوزه قضایی اعمال می‌شود.
 #4.13.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که بارهای کاری هوش مصنوعی در ابر هیبریدی سیاست‌های امنیتی یکسانی را در محیط‌های محلی و ابر پیاده‌سازی می‌کنند، همراه با نظارت و هشداردهی یکپارچه.
 #4.13.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که پیشگیری از قفل شدن در فروشنده ابر شامل زیرساخت قابل حمل به‌صورت کد (infrastructure-as-code)، رابط‌های برنامه‌نویسی استاندارد (APIs) و قابلیت‌های صادرات داده با ابزارهای تبدیل فرمت باشد.
 #4.13.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که بهینه‌سازی هزینه چندابری شامل کنترل‌های امنیتی برای جلوگیری از پراکندگی منابع و همچنین هزینه‌های انتقال داده غیرمجاز بین ابرها است.

---

### امنیت خودکارسازی زیرساخت و GitOps C4.14

خطوط لوله خودکارسازی زیرساخت امن و جریان‌های کاری GitOps برای مدیریت زیرساخت هوش مصنوعی.

 #4.14.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مخازن GitOps نیاز به کامیت‌های امضاشده با کلیدهای GPG دارند و قوانین محافظت از شاخه که از push مستقیم به شاخه‌های اصلی جلوگیری می‌کند، اعمال شده‌اند.
 #4.14.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اتوماسیون زیرساخت شامل تشخیص انحراف با قابلیت اصلاح خودکار و بازگردانی است که بر اساس نیازهای پاسخ سازمانی برای تغییرات غیرمجاز فعال می‌شود.
 #4.14.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فرآیند خودکار تهیه زیرساخت شامل اعتبارسنجی سیاست امنیتی با مسدودسازی استقرار برای پیکربندی‌های غیرمنطبق باشد.
 #4.14.4    سطح: 2    نقش: D/V
 تأیید کنید که اسرار اتوماسیون زیرساخت از طریق اپراتورهای مخفی خارجی (External Secrets Operator، Bank-Vaults) با گردش خودکار مدیریت می‌شوند.
 #4.14.5    سطح: 3    نقش: V
 تأیید کنید که زیرساخت خودترمیم شامل همبستگی رویدادهای امنیتی با پاسخ خودکار به حوادث و گردش‌کارهای اطلاع‌رسانی به ذینفعان باشد.

---

### C4.15 امنیت زیرساخت مقاوم در برابر کوانتوم

آماده‌سازی زیرساخت هوش مصنوعی در برابر تهدیدات محاسبات کوانتومی از طریق رمزنگاری پساکوانتومی و پروتکل‌های ایمن در برابر کوانتوم.

 #4.15.1    سطح: 3    نقش: D/V
 تأیید کنید که زیرساخت هوش مصنوعی الگوریتم‌های رمزنگاری پساکوانتومی تاییدشده توسط NIST (CRYSTALS-Kyber، CRYSTALS-Dilithium، SPHINCS+) را برای تبادل کلید و امضاهای دیجیتال پیاده‌سازی می‌کند.
 #4.15.2    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های توزیع کلید کوانتومی (QKD) برای ارتباطات هوش مصنوعی با امنیت بالا با پروتکل‌های مدیریت کلید کوانتومی ایمن پیاده‌سازی شده‌اند.
 #4.15.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که چارچوب‌های تطبیق‌پذیری رمزنگاری امکان مهاجرت سریع به الگوریتم‌های جدید پساکوانتومی را با چرخش خودکار گواهی‌نامه و کلید فراهم می‌کنند.
 #4.15.4    سطح: 3    نقش: V
 تأیید کنید که مدل‌سازی تهدید کوانتومی آسیب‌پذیری زیرساخت هوش مصنوعی در برابر حملات کوانتومی را با جدول زمانی مهاجرت مستند و ارزیابی‌های ریسک بررسی می‌کند.
 #4.15.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های رمزنگاری هیبریدی کلاسیک-کوانتومی در طول دوره گذار کوانتومی با نظارت بر عملکرد، حفاظت چندلایه فراهم می‌کنند.

---

### C4.16 محاسبات محرمانه و انکلاک‌های امن

محافظت از بارهای کاری هوش مصنوعی و وزن‌های مدل با استفاده از محیط‌های اجرای مورد اعتماد مبتنی بر سخت‌افزار و فناوری‌های محاسبات محرمانه.

 #4.16.1    سطح: 3    نقش: D/V
 تأیید کنید که مدل‌های حساس هوش مصنوعی درون مناطق امن Intel SGX، AMD SEV-SNP، یا ARM TrustZone با حافظه رمزنگاری شده و بررسی تصدیق اجرا می‌شوند.
 #4.16.2    سطح: 3    نقش: D/V
 تأیید کنید که کانتینرهای محرمانه (Kata Containers، gVisor با محاسبات محرمانه) بارهای کاری هوش مصنوعی را با رمزنگاری حافظه سخت‌افزاری ایزوله می‌کنند.
 #4.16.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تصدیق از راه دور اعتبار انسجام محصور را قبل از بارگذاری مدل‌های هوش مصنوعی با اثبات رمزنگاری از اصالت محیط اجرا تایید می‌کند.
 #4.16.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که خدمات استنتاج هوش مصنوعی محرمانه از استخراج مدل از طریق محاسبات رمزگذاری شده با وزن‌های مدل مهر و موم‌شده و اجرای محافظت‌شده جلوگیری می‌کنند.
 #4.16.5    سطح: 3    نقش: D/V
 تأیید کنید که ارکستراسیون محیط اجرای مورد اعتماد (TEE) چرخه عمر ناحیه امن را با تأیید از راه دور و کانال‌های ارتباطی رمزگذاری شده مدیریت می‌کند.
 #4.16.6    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که محاسبات چندجانبه امن (SMPC) امکان آموزش مشترک هوش مصنوعی را بدون افشای داده‌های فردی یا پارامترهای مدل فراهم می‌کند.

---

### C4.17 زیرساخت دانش صفر

پیاده‌سازی سیستم‌های اثبات دانش صفر برای تأیید و احراز هویت هوش مصنوعی با حفظ حریم خصوصی بدون افشای اطلاعات حساس.

 #4.17.1    سطح: 3    نقش: D/V
 تأیید کنید که اثبات‌های دانش صفر (ZK-SNARKs، ZK-STARKs) صحت مدل هوش مصنوعی و منشأ آموزش را بدون افشای وزن‌های مدل یا داده‌های آموزش تأیید می‌کنند.
 #4.17.2    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های احراز هویت مبتنی بر ZK امکان تأیید هویت کاربران با حفظ حریم خصوصی برای خدمات هوش مصنوعی را بدون افشای اطلاعات مربوط به هویت فراهم می‌کنند.
 #4.17.3    سطح: 3    نقش: D/V
 تأیید کنید که پروتکل‌های اشتراک‌گذاری مجموعه خصوصی (PSI) امکان تطبیق امن داده‌ها برای هوش مصنوعی فدرال را بدون افشای مجموعه داده‌های فردی فراهم می‌کنند.
 #4.17.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های یادگیری ماشین صفر-دانش (ZKML) استنباط‌های هوش مصنوعی قابل تأیید را با اثبات رمزنگاری شده از صحت محاسبه امکان‌پذیر می‌سازند.
 #4.17.5    سطح: 3    نقش: D/V
 تأیید کنید که ZK-rollups پردازش تراکنش‌های AI مقیاس‌پذیر و حفظ‌کننده حریم خصوصی را با تأیید دسته‌ای و کاهش بار محاسباتی فراهم می‌کنند.

---

### C4.18 پیشگیری از حملات کانال جانبی

زیرساخت هوش مصنوعی را در برابر حملات کانال جانبی مبتنی بر زمان‌بندی، قدرت، الکترومغناطیسی و حافظه کش که ممکن است اطلاعات حساس را فاش کنند، محافظت کنید.

 #4.18.1    سطح: 3    نقش: D/V
 تأیید کنید که زمان‌بندی استنتاج هوش مصنوعی با استفاده از الگوریتم‌های زمان ثابت و پرکردن (padding) نرمال شده است تا از حملات استخراج مدل مبتنی بر زمان جلوگیری شود.
 #4.18.2    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که حفاظت از تحلیل توان شامل تزریق نویز، فیلتر کردن خطوط برق و الگوهای اجرای تصادفی برای سخت‌افزار هوش مصنوعی است.
 #4.18.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که کاهش کانال جانبی مبتنی بر حافظه نهان از تقسیم‌بندی حافظه نهان، تصادفی‌سازی و دستورالعمل‌های پاک‌سازی برای جلوگیری از نشت اطلاعات استفاده می‌کند.
 #4.18.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که حفاظت در برابر انتشار الکترومغناطیسی شامل محافظت، فیلتر کردن سیگنال و پردازش تصادفی برای جلوگیری از حملات به سبک TEMPEST باشد.
 #4.18.5    سطح: 3    نقش: D/V
 تأیید کنید که دفاع‌های جانبی میکرومعماری شامل کنترل‌های اجرای حدسی و مبهم‌سازی الگوهای دسترسی به حافظه است.

---

### C4.19 امنیت سخت‌افزار تخصصی و نئومورفیک AI

ایمن‌سازی معماری‌های سخت‌افزاری نوظهور هوش مصنوعی شامل تراشه‌های نورومورفی، FPGAها، ASICهای سفارشی و سیستم‌های محاسبات نوری.

 #4.19.1    سطح: 3    نقش: D/V
 تأیید کنید که امنیت تراشه‌های نوروμορفیک شامل رمزنگاری الگوی پالس‌ها، حفاظت از وزن سیناپسی و اعتبارسنجی قانون یادگیری مبتنی بر سخت‌افزار است.
 #4.19.2    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که شتاب‌دهنده‌های هوش مصنوعی مبتنی بر FPGA، رمزنگاری بیت‌استریم، مکانیزم‌های ضد دستکاری و بارگذاری پیکربندی امن با به‌روزرسانی‌های احراز هویت شده را اجرا می‌کنند.
 #4.19.3    سطح: 3    نقش: D/V
 تأیید کنید که امنیت ASIC سفارشی شامل پردازنده‌های امنیتی درون تراشه، ریشه اعتماد سخت‌افزاری و ذخیره کلید امن با قابلیت تشخیص دستکاری باشد.
 #4.19.4    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های محاسبات نوری رمزنگاری نوری ایمن کوانتومی، سوئیچینگ فوتونیک امن، و پردازش سیگنال نوری محافظت‌شده را پیاده‌سازی می‌کنند.
 #4.19.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که چیپ‌های هوش مصنوعی هیبریدی آنالوگ-دیجیتال شامل محاسبات آنالوگ ایمن، ذخیره‌سازی وزن محافظت‌شده و تبدیل آنالوگ به دیجیتال احراز هویت‌شده هستند.

---

### زیرساخت محاسباتی حفاظت از حریم خصوصی C4.20

پیاده‌سازی کنترل‌های زیرساختی برای محاسبات حفظ حریم خصوصی به منظور محافظت از داده‌های حساس در طول پردازش و تحلیل هوش مصنوعی.

 #4.20.1    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که زیرساخت رمزنگاری همومورفیک امکان انجام محاسبات رمزنگاری شده بر روی بارهای کاری حساس AI را با تأیید صحت رمزنگاری و نظارت بر عملکرد فراهم می‌کند.
 #4.20.2    سطح: 3    نقش: D/V
 تأیید کنید که سیستم‌های بازیابی اطلاعات خصوصی امکان انجام پرس‌وجوهای پایگاه داده را بدون افشای الگوهای پرس‌وجو با حفاظت رمزنگاری از الگوهای دسترسی فراهم می‌کنند.
 #4.20.3    سطح: 3    نقش: D/V
 تأیید کنید که پروتکل‌های محاسبات چندجانبه امن امکان استنتاج هوش مصنوعی محافظت‌شده از حریم خصوصی را بدون افشای ورودی‌های فردی یا محاسبات میانی فراهم می‌کنند.
 #4.20.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مدیریت کلید حفظ حریم خصوصی شامل تولید کلید توزیع‌شده، رمزنگاری آستانه‌ای و چرخش ایمن کلید با حفاظت مبتنی بر سخت‌افزار است.
 #4.20.5    سطح: 3    نقش: D/V
 تأیید کنید که عملکرد محاسبات حفظ حریم خصوصی از طریق دسته‌بندی، کشینگ و شتاب‌دهی سخت‌افزاری بهینه شده است در حالی که تضمین‌های امنیت رمزنگاری حفظ می‌شوند.

---

### امنیت ادغام ابری چارچوب عامل C4.15 و استقرار هیبریدی

کنترل‌های امنیتی برای چارچوب‌های عامل یکپارچه با ابر با معماری‌های هیبریدی محلی/ابر.

 #4.15.1    سطح: 1    نقش: D/V
 تأیید کنید که یکپارچه‌سازی ذخیره‌سازی ابری از رمزگذاری انتها به انتها با مدیریت کلید کنترل‌شده توسط عامل استفاده می‌کند.
 #4.15.2    سطح: 2    نقش: D/V
 تأیید کنید که مرزهای امنیتی استقرار ترکیبی به وضوح تعریف شده‌اند و کانال‌های ارتباطی رمزنگاری شده هستند.
 #4.15.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که دسترسی به منابع ابری شامل تأیید هویت صفر–اعتماد با احراز هویت مداوم باشد.
 #4.15.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که الزامات اقامت داده‌ها توسط گواهی رمزنگاری شده مکان‌های ذخیره‌سازی اعمال می‌شوند.
 #4.15.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که ارزیابی‌های امنیتی ارائه‌دهنده خدمات ابری شامل مدل‌سازی تهدیدات خاص عامل و ارزیابی ریسک می‌باشند.

---

### مراجع

NIST Cybersecurity Framework 2.0
CIS Controls v8
OWASP Container Security Verification Standard
Kubernetes Security Best Practices
SLSA Supply Chain Security Framework
NIST SP 800-190: Application Container Security Guide
Cloud Security Alliance: Cloud Controls Matrix
ENISA: Secure Infrastructure Design
NIST SP 800-53: Security Controls for Federal Information Systems
ISO 27001:2022 Information Security Management
NIST AI Risk Management Framework
CIS Kubernetes Benchmark
FIPS 140-2 Security Requirements
NIST SP 800-207: Zero Trust Architecture
IEEE 2857: Privacy Engineering for AI Systems
NIST SP 800-161: Cybersecurity Supply Chain Risk Management
NIST Post-Quantum Cryptography Standards
Intel SGX Developer Guide
AMD SEV-SNP White Paper
ARM TrustZone Technology
ZK-SNARKs: A Gentle Introduction
NIST SP 800-57: Cryptographic Key Management
Side-Channel Attack Countermeasures
Neuromorphic Computing Security Challenges
FPGA Security: Fundamentals, Evaluation, and Countermeasures
Microsoft SEAL: Homomorphic Encryption Library
HElib: Homomorphic Encryption Library
PALISADE Lattice Cryptography Library
Differential Privacy: A Survey of Results
Secure Aggregation for Federated Learning
Private Information Retrieval: Concepts and Constructions

## کنترل دسترسی C5 و هویت برای اجزای هوش مصنوعی و کاربران

### هدف کنترل

کنترل دسترسی موثر برای سیستم‌های هوش مصنوعی نیازمند مدیریت هویت قوی، احراز هویت مبتنی بر زمینه و اجرای زمان اجرا مطابق با اصول اعتماد صفر است. این کنترل‌ها تضمین می‌کنند که انسان‌ها، سرویس‌ها و عوامل خودکار تنها در محدوده‌های صریحاً مجاز شده به مدل‌ها، داده‌ها و منابع محاسباتی دسترسی داشته باشند و با قابلیت‌های تأیید و ممیزی مستمر همراه باشند.

---

### C5.1 مدیریت هویت و احراز هویت

شناسایی‌های مبتنی بر رمزنگاری را برای تمامی موجودیت‌ها با احراز هویت چندعاملی برای عملیات دارای امتیاز برقرار کنید.

 #5.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام کاربران انسانی و اصول‌های سرویس از طریق یک ارائه‌دهنده هویت سازمانی متمرکز (IdP) با استفاده از پروتکل‌های OIDC/SAML احراز هویت می‌شوند، با نگاشت‌های یکتا بین هویت و توکن (بدون حساب‌ها یا اعتبارنامه‌های مشترک).
 #5.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که عملیات پرریسک (استقرار مدل، صادرات وزن، دسترسی به داده‌های آموزشی، تغییرات پیکربندی تولید) نیاز به احراز هویت چندمرحله‌ای یا احراز هویت مرحله‌ای با بازتأیید جلسه دارند.
 #5.1.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که مدیران جدید قبل از دریافت دسترسی به سیستم تولید، فرآیند اثبات هویت را مطابق با استانداردهای NIST 800-63-3 IAL-2 یا استانداردهای معادل آن انجام می‌دهند.
 #5.1.4    سطح: 2    نقش: V
 تأیید کنید که بازبینی‌های دسترسی به صورت فصلی انجام می‌شوند همراه با شناسایی خودکار حساب‌های غیرفعال، اجرای گردش کار چرخش اعتبارنامه، و فرآیندهای حذف دسترسی.
 #5.1.5    سطح: 3    نقش: D/V
 تأیید کنید که عوامل هوش مصنوعی فدرال شده از طریق ادعاهای JWT امضا شده که حداکثر عمر 24 ساعت دارند و شامل اثبات رمزنگاری شده از مبدأ هستند، احراز هویت می‌شوند.

---

### C5.2 مجوز دسترسی منابع و کمترین سطح دسترسی

کنترل‌های دسترسی دقیق برای تمامی منابع هوش مصنوعی با مدل‌های مجوز صریح و سوابق حسابرسی اجرا کنید.

 #5.2.1    سطح: 1    نقش: D/V
 تأیید کنید که هر منبع هوش مصنوعی (مجموعه داده‌ها، مدل‌ها، نقاط انتهایی، مجموعه‌های برداری، شاخص‌های جاسازی، نمونه‌های محاسباتی) کنترل‌های دسترسی مبتنی بر نقش را با فهرست‌های اجازه صریح و سیاست‌های پیش‌فرض انکار اعمال می‌کند.
 #5.2.2    سطح: 1    نقش: D/V
 تأیید کنید که اصول حداقل دسترسی به صورت پیش‌فرض با حساب‌های سرویس اعمال شده‌اند، به‌طوری‌که دسترسی‌ها از سطح فقط خواندنی شروع شده و برای دسترسی نوشتن توجیه کسب‌وکاری مستند شده مورد نیاز باشد.
 #5.2.3    سطح: 1    نقش: V
 اطمینان حاصل کنید که همه تغییرات کنترل دسترسی به درخواست‌های تغییر تایید شده مرتبط هستند و به صورت غیرقابل تغییر با زمان‌سنجی، هویت بازیگران، شناسه‌های منابع و تغییرات مجوز ثبت شده‌اند.
 #5.2.4    سطح: 2    نقش: D
 تأیید کنید که برچسب‌های دسته‌بندی داده‌ها (PII، PHI، کنترل‌ شده برای صادرات، مالکیتی) به طور خودکار به منابع مشتق‌شده (برداشت‌ها، کش‌های درخواست، خروجی‌های مدل) با اعمال سیاست‌های سازگار منتقل می‌شوند.
 #5.2.5    سطح: 2    نقش: D/V
 تأیید کنید که تلاش‌های دسترسی غیرمجاز و رویدادهای بالا بردن امتیازات، هشدارهای زنده با متادیتای متنی به سیستم‌های SIEM ظرف 5 دقیقه ارسال می‌کنند.

---

### C5.3 ارزیابی پویا سیاست

پیاده‌سازی موتورهای کنترل دسترسی مبتنی بر ویژگی (ABAC) برای تصمیم‌گیری‌های مجازسازی آگاه به زمینه با قابلیت‌های حسابرسی.

 #5.3.1    سطح: 1    نقش: D/V
 تأیید کنید که تصمیمات مجوزدهی به یک موتور سیاست مستقل (OPA، Cedar یا معادل آن) واگذار شده است که از طریق APIهای احراز هویت شده با محافظت از صحت رمزنگاری شده قابل دسترسی باشد.
 #5.3.2    سطح: 1    نقش: D/V
 بررسی کنید که سیاست‌ها ویژگی‌های پویا را در زمان اجرا ارزیابی می‌کنند، از جمله سطح تصفیه کاربر، طبقه‌بندی حساسیت منبع، زمینه درخواست، جداسازی مستأجر و محدودیت‌های زمانی.
 #5.3.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که تعریف‌های سیاست‌ها تحت کنترل نسخه قرار دارند، توسط هم‌رده‌ها بازبینی شده‌اند، و از طریق تست‌های خودکار در خطوط لوله CI/CD قبل از استقرار در محیط تولید تایید شده‌اند.
 #5.3.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که نتایج ارزیابی سیاست شامل دلایل ساخت‌یافته تصمیم‌گیری هستند و به سیستم‌های SIEM برای تحلیل همبستگی و گزارش‌دهی تطبیق منتقل می‌شوند.
 #5.3.5    سطح: 3    نقش: D/V
 تأیید کنید که مقادیر زمان زندگی (TTL) حافظه نهان سیاست برای منابع با حساسیت بالا بیش از ۵ دقیقه و برای منابع استاندارد با قابلیت باطل‌سازی حافظه نهان بیش از ۱ ساعت نباشد.

---

### اجرای امنیت در زمان پرس‌وجو C5.4

کنترل‌های امنیتی لایه پایگاه داده را با فیلترینگ اجباری و سیاست‌های امنیتی در سطح ردیف پیاده‌سازی کنید.

 #5.4.1    سطح: 1    نقش: D/V
 تأیید کنید که تمامی پرس‌وجوهای پایگاه داده برداری و SQL شامل فیلترهای امنیتی اجباری (شناسه مستاجر، برچسب‌های حساسیت، دامنه کاربر) باشند که در سطح موتور پایگاه داده اعمال می‌شوند، نه در کد برنامه.
 #5.4.2    سطح: 1    نقش: D/V
 تأیید کنید که سیاست‌های امنیت در سطح ردیف (RLS) و ماسکینگ در سطح فیلد با ارث‌بری سیاست برای تمام پایگاه‌های داده برداری، شاخص‌های جستجو و مجموعه داده‌های آموزش فعال شده‌اند.
 #5.4.3    سطح: 2    نقش: D
 تأیید کنید که ارزیابی‌های ناموفق مجوز، از حملات "معاون گیج‌شده" جلوگیری می‌کنند، با این کار که بلافاصله پرس‌وجوها را متوقف کرده و کدهای خطای مجوز صریح را برمی‌گردانند به جای اینکه مجموعه نتایج خالی برگردانند.
 #5.4.4    سطح: 2    نقش: V
 تأیید کنید که تأخیر ارزیابی سیاست به طور مداوم با هشدارهای خودکار برای شرایط زمان‌بندی معیوب که می‌تواند باعث دور زدن مجوزها شود، نظارت می‌شود.
 #5.4.5    سطح: 3    نقش: D/V
 تأیید کنید که مکانیزم‌های تلاش مجدد پرس و جو، سیاست‌های مجوزدهی را بازنگری می‌کنند تا تغییرات پویا در سطح دسترسی‌ها در جلسات فعال کاربر لحاظ شوند.

---

### فیلتر خروجی C5.5 و جلوگیری از نشت داده‌ها

اجرای کنترل‌های پس‌پردازش به منظور جلوگیری از افشای غیرمجاز داده‌ها در محتوای تولید شده توسط هوش مصنوعی.

 #5.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های فیلترینگ پس از استنتاج، اطلاعات شناسایی شخصی غیرمجاز (PII)، اطلاعات طبقه‌بندی شده و داده‌های اختصاصی را قبل از ارائه محتوا به درخواست‌ کنندگان، اسکن و پاک‌سازی می‌کنند.
 #5.5.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که استنادها، مراجع و نسبت‌دهی منابع در خروجی‌های مدل بر اساس مجوزهای تماس‌گیرنده اعتبارسنجی شده و در صورت شناسایی دسترسی غیرمجاز حذف شوند.
 #5.5.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که محدودیت‌های قالب خروجی (PDFهای پاک‌سازی‌شده، تصاویر بدون متادیتا، انواع فایل‌های تأییدشده) بر اساس سطح دسترسی کاربران و طبقه‌بندی داده‌ها اعمال می‌شود.
 #5.5.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که الگوریتم‌های حذف اطلاعات به صورت تعیین‌پذیر، کنترل نسخه شده و دارای ثبت گزارش‌های حسابرسی برای پشتیبانی از تحقیقات تطبیقی و تحلیل‌های جنایی هستند.
 #5.5.5    سطح: 3    نقش: V
 تأیید کنید که رویدادهای تحریر با ریسک بالا، لاگ‌های تطبیقی تولید می‌کنند که شامل هش‌های رمزنگاری شده از محتوای اصلی برای بازیابی قضایی بدون افشای داده‌ها هستند.

---

### C5.6 ایزولاسیون چند مستاجری

اطمینان از جداسازی رمزنگاری و منطقی بین مستاجران در زیرساخت مشترک هوش مصنوعی.

 #5.6.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که فضای حافظه، فروشگاه‌های تعبیه، ورودی‌های کش، و فایل‌های موقت به صورت جداشده بر اساس فضای نام هر مستاجر نگهداری می‌شوند و هنگام حذف مستاجر یا اتمام جلسه، پاک‌سازی امن انجام می‌شود.
 #5.6.2    سطح: 1    نقش: D/V
 تأیید کنید که هر درخواست API شامل یک شناسه مستأجر احراز هویت شده باشد که به صورت رمزنگاری شده بر اساس زمینه جلسه و مجوزهای کاربر اعتبارسنجی شود.
 #5.6.3    سطح: 2    نقش: D
 بررسی کنید که سیاست‌های شبکه قوانین پیش‌فرض-رد را برای ارتباط بین مستأجرها در داخل شبکه‌های خدمت و پلتفرم‌های ارکستراسیون کانتینر اعمال می‌کنند.
 #5.6.4    سطح: 3    نقش: D
 تأیید کنید که کلیدهای رمزگذاری برای هر مستأجر منحصر به فرد هستند با پشتیبانی از کلید مدیریت شده توسط مشتری (CMK) و جداسازی رمزنگاری شده بین مخازن داده‌های مستأجر.

---

### C5.7 مجوز عامل خودمختار

کنترل دسترسی‌ها برای عوامل هوش مصنوعی و سیستم‌های خودمختار از طریق نشانه‌های قابلیت محدوده‌دار و مجوزدهی مداوم.

 #5.7.1    سطح: 1    نقش: D/V
 تأیید کنید که عوامل خودکار توکن‌های قابلیت محدوده‌دار دریافت می‌کنند که به‌طور صریح اقدامات مجاز، منابع قابل دسترسی، محدودیت‌های زمانی و محدودیت‌های عملیاتی را فهرست می‌کنند.
 #5.7.2    سطح: 1    نقش: D/V
 تأیید کنید که قابلیت‌های پرخطر (دسترسی به سیستم فایل، اجرای کد، تماس‌های API خارجی، تراکنش‌های مالی) به‌طور پیش‌فرض غیرفعال هستند و برای فعال‌سازی نیاز به مجوزهای صریح همراه با توجیهات کسب‌وکاری دارند.
 #5.7.3    سطح: 2    نقش: D
 تأیید کنید که توکن‌های قابلیت به جلسات کاربری متصل شده‌اند، حفاظت از یکپارچگی رمزنگاری شده را شامل می‌شوند، و اطمینان حاصل شود که نمی‌توانند در سناریوهای آفلاین ذخیره یا دوباره استفاده شوند.
 #5.7.4    سطح: 2    نقش: V
 تأیید کنید که اقدامات آغاز شده توسط عامل، از طریق موتور سیاست ABAC با ارزیابی کامل زمینه و ثبت گزارش حسابرسی، مورد مجوز ثانویه قرار می‌گیرند.
 #5.7.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که شرایط خطاهای عامل و بررسی استثناها شامل اطلاعات دامنه قابلیت برای پشتیبانی از تجزیه و تحلیل حادثه و تحقیق قضایی باشد.

---

### مراجع

#### استانداردها و چارچوب‌ها

NIST SP 800-63-3: Digital Identity Guidelines
Zero Trust Architecture – NIST SP 800-207
OWASP Application Security Verification Standard (AISVS)
​
#### راهنمای پیاده‌سازی

Identity and Access Management in the AI Era: 2025 Guide – IDSA
Attribute-Based Access Control with OPA – Permify
How We Designed Cedar to Be Intuitive, Fast, and Safe – AWS
​
#### امنیت خاص هوش مصنوعی

Row Level Security in Vector DBs for RAG – Bluetuple.ai
Tenant Isolation in Multi-Tenant Systems – WorkOS
Handling AI Agent Permissions – Stytch
OWASP Top 10 for Large Language Model Applications

## امنیت زنجیره تأمین C6 برای مدل‌ها، چارچوب‌ها و داده‌ها

### هدف کنترل

حملات زنجیره تامین هوش مصنوعی از مدل‌ها، چارچوب‌ها یا مجموعه‌داده‌های شخص ثالث بهره می‌برند تا درب‌های پشتی، تعصب یا کدهای قابل سوءاستفاده را جاسازی کنند. این کنترل‌ها مدیریت تمام‌عیار منشاء، مدیریت آسیب‌پذیری و نظارت را برای محافظت از کل چرخه عمر مدل فراهم می‌کنند.

---

### C6.1 بررسی مدل پیش‌آموزش‌دیده و پیشینه

قبل از هرگونه تنظیم دقیق یا استقرار، منشأ، مجوزها و رفتارهای مخفی مدل‌های شخص ثالث را ارزیابی و تأیید کنید.

 #6.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر اثر مدل شخص ثالث شامل یک رکورد منشأ امضا شده باشد که مخزن منبع و هش کامیت را شناسایی می‌کند.
 #6.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مدل‌ها قبل از وارد کردن، با استفاده از ابزارهای خودکار برای بررسی لایه‌های مخرب یا تریگرهای تروجان اسکن شده باشند.
 #6.1.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که تنظیم دقیق با استفاده از یادگیری انتقالی، ارزیابی مقابله‌ای را برای شناسایی رفتارهای پنهان پشت سر می‌گذارد.
 #6.1.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که مجوزهای مدل، برچسب‌های کنترل صادرات و بیانیه‌های منشاء داده در یک ورودی ML-BOM ثبت شده باشند.
 #6.1.5    سطح: 3    نقش: D/V
 تأیید کنید که مدل‌های پرخطر (وزن‌های آپلود شده عمومی، سازندگان تأیید نشده) تا زمان بررسی و تأیید انسانی تحت قرنطینه باقی بمانند.

---

### C6.2 اسکن فریمورک و کتابخانه

به طور مداوم چارچوب‌ها و کتابخانه‌های یادگیری ماشین را برای CVEها و کد مخرب اسکن کنید تا پشته زمان اجرا امن باقی بماند.

 #6.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که خطوط لوله CI اسکنرهای وابستگی را روی چارچوب‌های هوش مصنوعی و کتابخانه‌های حیاتی اجرا می‌کنند.
 #6.2.2    سطح: 1    نقش: D/V
 تأیید کنید که آسیب‌پذیری‌های حیاتی (CVSS ≥ 7.0) از ارتقاء به تصاویر تولیدی جلوگیری می‌کنند.
 #6.2.3    سطح: 2    نقش: D
 تأیید کنید که تحلیل ایستا کد بر روی کتابخانه‌های ML منشعب شده یا وارد شده اجرا می‌شود.
 #6.2.4    سطح: 2    نقش: V
 تأیید کنید که پیشنهادهای ارتقاء چارچوب شامل ارزیابی تأثیر امنیتی با ارجاع به منابع عمومی CVE باشد.
 #6.2.5    سطح: 3    نقش: V
 تأیید کنید که حسگرهای زمان اجرا در مورد بارگذاری‌های غیرمنتظره کتابخانه‌های دینامیک که از SBOM امضا شده انحراف دارند، هشدار دهند.

---

### C6.3 پین‌کردن و تأیید وابستگی‌ها

همه وابستگی‌ها را به هش‌های غیرقابل تغییر قفل کنید و ساخت‌ها را بازتولید کنید تا تضمین شود که آثار به‌دست‌آمده یکسان و بدون دستکاری هستند.

 #6.3.1    سطح: 1    نقش: D/V
 بررسی کنید که آیا تمام مدیران بسته اعمال قفل نسخه را از طریق فایل‌های قفل تضمین می‌کنند.
 #6.3.2    سطح: 1    نقش: D/V
 تأیید کنید که در ارجاعات کانتینر به جای برچسب‌های متغیر از هش‌های تغییرناپذیر استفاده شده است.
 #6.3.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که بررسی‌های ساخت مجدد، هش‌ها را در طول اجرای CI مقایسه می‌کنند تا خروجی‌های یکسان تضمین شود.
 #6.3.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که تصدیق‌های ساخت برای 18 ماه جهت ردیابی حسابرسی ذخیره می‌شوند.
 #6.3.5    سطح: 3    نقش: D
 اطمینان حاصل کنید که وابستگی‌های منقضی شده باعث ایجاد درخواست‌های خودکار اصلاح (PR) برای به‌روزرسانی یا فورک نسخه‌های پین‌شده می‌شوند.

---

### C6.4 اجرای منبع مورد اعتماد

امکان دانلود مصنوعات فقط از منابع تأیید شده رمزنگاری شده و مورد تایید سازمان را فراهم کنید و سایر موارد را مسدود کنید.

 #6.4.1    سطح: 1    نقش: D/V
 تأیید کنید که وزن‌های مدل، مجموعه‌داده‌ها و کانتینرها تنها از دامنه‌های تأیید شده یا رجیستری‌های داخلی دانلود شوند.
 #6.4.2    سطح: 1    نقش: D/V
 تأیید کنید که امضاهای Sigstore/Cosign هویت ناشر را قبل از ذخیره محلی آثار اعتبارسنجی می‌کنند.
 #6.4.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که پراکسی‌های خروجی دانلودهای غیرمجاز آثار را مسدود می‌کنند تا سیاست منبع مورد اعتماد اعمال شود.
 #6.4.4    سطح: 2    نقش: V
 تأیید کنید که فهرست‌های مجاز مخزن به صورت فصلی بازبینی می‌شوند و برای هر ورودی دلیل تجاری به‌عنوان مدرک وجود دارد.
 #6.4.5    سطح: 3    نقش: V
 تأیید کنید که نقض‌های سیاست منجر به قرنطینه شدن مصنوعات و بازگشت اجرای خطوط لوله وابسته می‌شود.

---

### C6.5 ارزیابی ریسک مجموعه داده‌های شخص ثالث

داده‌های خارجی را از نظر مسمومیت، تعصب و تطابق قانونی ارزیابی کرده و در طول چرخه عمر آنها را پایش کنید.

 #6.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مجموعه داده‌های خارجی تحت ارزیابی ریسک مسمومیت قرار می‌گیرند (مثلاً اثر انگشت داده، شناسایی داده‌های پرت).
 #6.5.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که معیارهای تعصب (توازن جمعیتی، فرصت برابر) قبل از تایید مجموعه داده محاسبه شده‌اند.
 #6.5.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که اصالت و شرایط مجوز برای مجموعه داده‌ها در ورودی‌های ML-BOM ثبت شده باشد.
 #6.5.4    سطح: 2    نقش: V
 تأیید کنید که پایش دوره‌ای تغییر یا فساد در مجموعه داده‌های میزبانی شده را تشخیص دهد.
 #6.5.5    سطح: 3    نقش: D
 تأیید کنید که محتوای غیرمجاز (حق نشر، اطلاعات شناسایی شخصی) پیش از آموزش از طریق پاک‌سازی خودکار حذف شده باشد.

---

### C6.6 نظارت بر حملات زنجیره تأمین

تهدیدهای زنجیره تأمین را از طریق فیدهای CVE، تحلیل‌های لاگ حسابرسی و شبیه‌سازی‌های تیم قرمز به‌موقع تشخیص دهید.

 #6.6.1    سطح: 1    نقش: V
 تأیید کنید که گزارش‌های حسابرسی CI/CD به جریان تشخیص‌های SIEM برای کشیدن‌های غیرعادی بسته یا مراحل ساخت دستکاری‌شده ارسال می‌شوند.
 #6.6.2    سطح: 2    نقش: D
 تأیید کنید که کتابچه‌های پاسخ به حادثه شامل روش‌های بازگشت برای مدل‌ها یا کتابخانه‌های آسیب‌دیده باشد.
 #6.6.3    سطح: 3    نقش: V
 تایید کنید که برچسب‌های غنی‌سازی اطلاعات تهدید، شاخص‌های خاص یادگیری ماشین (مانند نشانگرهای IoC مربوط به مسموم‌سازی مدل) را در مرحله سه‌گانه هشدار علامت‌گذاری می‌کنند.

---

### C6.7 ML‑BOM برای مصنوعات مدل

تولید و امضای SBOMهای دقیق خاص یادگیری ماشین (ML‑BOMها) به طوری که مصرف‌کنندگان در مراحل بعدی بتوانند صحت اجزاء را در زمان استقرار بررسی کنند.

 #6.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر اثر مدل یک ML-BOM منتشر می‌کند که شامل مجموعه داده‌ها، وزن‌ها، هایپرپارامترها و مجوزها است.
 #6.7.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تولید ML‑BOM و امضای Cosign به صورت خودکار در CI انجام شده و برای ادغام ضروری هستند.
 #6.7.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که بررسی‌های کامل بودن ML‑BOM در صورت فقدان هر گونه متادیتای مؤلفه (هش، مجوز) ساخت را ناموفق اعلام می‌کنند.
 #6.7.4    سطح: 2    نقش: V
 بررسی کنید که مصرف‌کنندگان پایین‌دستی قادر باشند از طریق API به ML-BOMها query کنند تا مدل‌های وارد شده را در زمان استقرار اعتبارسنجی کنند.
 #6.7.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که ML-BOMها نسخه‌بندی شده و مقایسه می‌شوند تا تغییرات غیرمجاز شناسایی شوند.

---

### مراجع

ML Supply Chain Compromise – MITRE ATLAS
Supply‑chain Levels for Software Artifacts (SLSA)
CycloneDX – Machine Learning Bill of Materials
What is Data Poisoning? – SentinelOne
Transfer Learning Attack – OWASP ML Security Top 10
AI Data Security Best Practices – CISA
Secure CI/CD Supply Chain – Sumo Logic
AI & Transparency: Protect ML Models – ReversingLabs
SBOM Overview – CISA
Training Data Poisoning Guide – Lakera.ai
Dependency Pinning for Reproducible Python – Medium

## رفتار مدل C7، کنترل خروجی و تضمین ایمنی

### هدف کنترل

خروجی‌های مدل باید ساختارمند، قابل اعتماد، ایمن، قابل توضیح و به طور مداوم در محیط تولید نظارت شده باشند. انجام این کار باعث کاهش توهمات، نشت‌های حریم خصوصی، محتوای مضر و اقدامات خارج از کنترل شده و در عین حال افزایش اعتماد کاربران و رعایت مقررات می‌شود.

---

### C7.1 اجرای قالب خروجی

اسکیماهای سختگیرانه، کدگذاری محدود شده، و اعتبارسنجی در مراحل بعدی از انتشار محتوای نادرست یا مخرب جلوگیری می‌کنند.

 #7.1.1    سطح: 1    نقش: D/V
 تأیید کنید که طرح‌های پاسخ (مثلاً JSON Schema) در پیام سیستم ارائه شده‌اند و هر خروجی به‌طور خودکار اعتبارسنجی می‌شود؛ خروجی‌های نامطابق باعث فعال شدن فرآیند تعمیر یا رد می‌شوند.
 #7.1.2    سطح: 1    نقش: D/V
 تأیید کنید که رمزگشایی محدود شده (توکن‌های توقف، عبارات منظم، حداکثر تعداد توکن‌ها) فعال است تا از سرریز یا کانال‌های کناری نفوذ در پرسش‌نامه جلوگیری شود.
 #7.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اجزای پایین‌دستی خروجی‌ها را به عنوان داده‌های غیر قابل اعتماد در نظر می‌گیرند و آن‌ها را بر اساس طرح‌واره‌ها یا دِسریالایزرهای ایمن در برابر تزریق اعتبارسنجی می‌کنند.
 #7.1.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که رویدادهای خروجی نامناسب ثبت، محدود به نرخ و به سیستم مانیتورینگ ارسال می‌شوند.

---

### C7.2 شناسایی و کاهش هلوکینیشن

برآورد عدم قطعیت و استراتژی‌های جایگزین پاسخ‌های ساختگی را محدود می‌کنند.

 #7.2.1    سطح: 1    نقش: D/V
 تأیید کنید که احتمال‌های لوگ‌ترازوی سطح توکن، انسجام خودی مجموعه‌ای، یا آشکارسازهای هذیان تنظیم شده دقیق، به هر پاسخ یک نمره اعتماد اختصاص می‌دهند.
 #7.2.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که پاسخ‌هایی که پایین‌تر از آستانه اطمینان قابل تنظیم هستند، جریان‌های کاری جایگزین (مانند تولید افزوده با بازیابی، مدل ثانویه، یا بازبینی انسانی) را فعال می‌کنند.
 #7.2.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که حوادث هذیان با متاداده علت ریشه‌ای برچسب‌گذاری شده و به خطوط لوله پست‌مورتوم و تنظیم دقیق ارسال می‌شوند.
 #7.2.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که آستانه‌ها و آشکارسازها پس از به‌روزرسانی‌های عمده مدل یا پایگاه دانش دوباره کالیبره شوند.
 #7.2.5    سطح: 3    نقش: V
 تأیید کنید که ویژوال‌سازی‌های داشبورد نرخ‌های هذیان‌گویی را دنبال می‌کنند.

---

### C7.3 فیلترینگ ایمنی و حریم خصوصی خروجی

فیلترهای سیاستی و پوشش تیم قرمز از کاربران و داده‌های محرمانه محافظت می‌کنند.

 #7.3.1    سطح: 1    نقش: D/V
 تأیید کنید که طبقه‌بندی‌کننده‌های قبل و بعد از تولید، محتوای نفرت‌انگیز، آزاردهنده، خودآسیب رسان، افراطی و جنسی صریح مطابق با سیاست را مسدود می‌کنند.
 #7.3.2    سطح: 1    نقش: D/V
 تأیید کنید که شناسایی PII/PCI و حذف خودکار در هر پاسخ اجرا شود؛ تخلفات باعث ایجاد حادثه حریم خصوصی می‌شود.
 #7.3.3    سطح: 2    نقش: D
 تأیید کنید که برچسب‌های محرمانگی (مانند اسرار تجاری) در سراسر حالت‌ها منتقل می‌شوند تا از نشت اطلاعات در متن، تصاویر یا کد جلوگیری شود.
 #7.3.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تلاش‌های عبور از فیلتر یا دسته‌بندی‌های با ریسک بالا نیاز به تأییدیه ثانویه یا احراز هویت مجدد کاربر دارند.
 #7.3.5    سطح: 3    نقش: D/V
 تأیید کنید که آستانه‌های فیلتر کردن منعکس‌کننده حوزه‌های قضایی قانونی و زمینه سن/نقش کاربر باشند.

---

### C7.4 محدودسازی خروجی و اقدامات

محدودیت‌های نرخ و دروازه‌های تأیید از سوءاستفاده و خودمختاری بیش از حد جلوگیری می‌کنند.

 #7.4.1    سطح: 1    نقش: D
 تأیید کنید که سهمیه‌های هر کاربر و هر کلید API، درخواست‌ها، توکن‌ها و هزینه‌ها را با استفاده از بازگشت نمایی (exponential back-off) در هنگام بروز خطاهای 429 محدود می‌کنند.
 #7.4.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که اقدامات دارای امتیاز ویژه (نوشتن فایل، اجرای کد، تماس‌های شبکه) نیازمند تأیید مبتنی بر سیاست یا دخالت انسان هستند.
 #7.4.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که بررسی‌های تطابق میان‌حسی تضمین می‌کنند تصاویر، کد، و متنی که برای یک درخواست مشابه تولید شده‌اند، نمی‌توانند برای قاچاق محتوای مخرب استفاده شوند.
 #7.4.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که عمق تفویض اختیار عامل، محدودیت‌های بازگشتی، و فهرست ابزارهای مجاز به‌طور صریح پیکربندی شده‌اند.
 #7.4.5    سطح: 3    نقش: V
 تأیید کنید که نقض محدودیت‌ها رویدادهای امنیتی ساختاریافته‌ای را برای جذب در سیستم SIEM ارسال می‌کند.

---

### C7.5 قابلیت توضیح خروجی

سیگنال‌های شفاف اعتماد کاربر و اشکال‌زدایی داخلی را بهبود می‌بخشند.

 #7.5.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که امتیازهای اطمینان قابل مشاهده برای کاربر یا خلاصه‌های مختصر استدلال زمانی که ارزیابی ریسک مناسب تشخیص می‌دهد، نمایش داده شوند.
 #7.5.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که توضیحات تولید شده از افشای دستورات حساس سیستم یا داده‌های مالکیتی جلوگیری می‌کنند.
 #7.5.3    سطح: 3    نقش: D
 تأیید کنید که سیستم احتمال‌های لاگ در سطح توکن یا نقشه‌های توجه را ثبت می‌کند و آن‌ها را برای بازرسی مجاز ذخیره می‌کند.
 #7.5.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که آثار قابلیت توضیح‌دهی همراه با نسخه‌های مدل برای قابلیت حسابرسی، تحت کنترل نسخه قرار دارند.

---

### C7.6 ادغام پایش

قابلیت مشاهده در زمان واقعی حلقه بین توسعه و تولید را بسته می‌کند.

 #7.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که معیارها (نقض‌های طرحواره، نرخ توهم‌زایی، سمی بودن، نشت اطلاعات شناسایی شخصی، تأخیر، هزینه) به یک پلتفرم نظارتی مرکزی ارسال می‌شوند.
 #7.6.2    سطح: 1    نقش: V
 تأیید کنید که آستانه‌های هشدار برای هر معیار ایمنی تعریف شده باشند، همراه با مسیرهای ارتقاء در زمان تماس اضطراری.
 #7.6.3    سطح: 2    نقش: V
 بررسی کنید که داشبوردها ناهنجاری‌های خروجی را با مدل/نسخه، علامت ویژگی و تغییرات داده‌های بالادستی مرتبط می‌کنند.
 #7.6.4    سطح: 2    نقش: D/V
 تأیید کنید که داده‌های پایش به‌عنوان ورودی به بازآموزی، تنظیم دقیق، یا به‌روزرسانی قوانین در یک روند کاری مستند MLOps بازخورد داده می‌شوند.
 #7.6.5    سطح: 3    نقش: V
 تأیید کنید که خطوط لوله نظارتی از نظر نفوذ تست شده و کنترل دسترسی شده‌اند تا از لو رفتن لاگ‌های حساس جلوگیری شود.

---

### 7.7 تدابیر حفاظتی رسانه‌های مولد

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی محتوای رسانه‌ای غیرقانونی، مضر یا غیرمجاز تولید نکنند از طریق اعمال محدودیت‌های سیاستی، اعتبارسنجی خروجی و قابلیت رصد.

 #7.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که دستورات سیستم و راهنمایی‌های کاربر به‌طور صریح تولید رسانه‌های دیپ‌فیک غیرقانونی، مضر یا بدون رضایت (مانند تصویر، ویدئو، صدا) را ممنوع می‌کنند.
 #7.7.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که درخواست‌ها برای تلاش‌های تولید جعل هویت، دیپ‌فیک‌های جنسی صریح، یا رسانه‌هایی که افراد واقعی را بدون رضایت نشان می‌دهند، فیلتر می‌شوند.
 #7.7.3    سطح: 2    نقش: V
 تأیید کنید که سیستم از هش درک‌شناختی، تشخیص واترمارک، یا اثرانگشت‌نگاری برای جلوگیری از تکثیر بدون اجازه رسانه‌های دارای حق انتشار استفاده می‌کند.
 #7.7.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تمام رسانه‌های تولید شده به‌صورت رمزنگاری‌شده امضا شده، دارای واترمارک هستند یا با متاداده‌های اثبات منشأ مقاوم در برابر تغییر برای ردیابی در مراحل بعدی، تعبیه شده‌اند.
 #7.7.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که تلاش‌های دور زدن (مانند پیچیده‌سازی درخواست، زبان عامیانه، عبارت‌بندی خصمانه) شناسایی، ثبت، و نرخ محدود می‌شوند؛ سوء استفاده مکرر به سیستم‌های نظارت گزارش داده شود.

### مراجع

NIST AI Risk Management Framework
ISO/IEC 42001:2023 – AI Management System
OWASP Top-10 for Large Language Model Applications (2025)
Improper Output Handling – OWASP LLM05:2025
Practical Techniques to Constrain LLM Output
Dataiku – Structured Text Generation Guide
VL-Uncertainty: Detecting Hallucinations
HaDeMiF: Hallucination Detection & Mitigation
Building Confidence in LLM Outputs
Explainable AI & LLMs
LLM Red-Teaming Guide
Sensitive Information Disclosure in LLMs
LangChain – Chat Model Rate Limiting
OpenAI Rate-Limit & Exponential Back-off
Arize AI – LLM Observability Platform

## امنیت حافظه C8، امبدینگ‌ها و پایگاه داده‌های برداری

### هدف کنترل

امبدینگ‌ها و فروشگاه‌های برداری مانند «حافظه زنده» سیستم‌های معاصر هوش مصنوعی عمل می‌کنند و به‌طور مداوم داده‌های ارائه‌شده توسط کاربر را می‌پذیرند و از طریق تولید تقویت‌شده با بازیابی (RAG) آن را به زمینه‌های مدل بازمی‌گردانند. اگر این حافظه بدون کنترل رها شود، ممکن است اطلاعات شناسایی شخصی (PII) نشت کند، رضایت نقض شود یا به گونه‌ای معکوس شود که متن اصلی بازسازی شود. هدف این خانواده کنترل، سخت کردن مسیرهای حافظه و پایگاه‌های داده برداری است به طوری که دسترسی کمترین امتیاز لازم باشد، امبدینگ‌ها حفظ حریم خصوصی کنند، بردارهای ذخیره‌شده منقضی شوند یا در صورت نیاز قابل ابطال باشند، و حافظه هر کاربر هرگز باعث آلودگی درخواست‌ها یا تکمیل‌های کاربران دیگر نشود.

---

### C8.1 کنترل‌های دسترسی بر حافظه و شاخص‌های RAG

اجرای کنترل‌های دسترسی دقیق بر روی هر مجموعه برداری.

 #8.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که قوانین کنترل دسترسی در سطح ردیف/فضای نام، عملیات درج، حذف و جستجو را به ازای هر مستأجر، مجموعه یا برچسب سند محدود می‌کنند.
 #8.1.2    سطح: 1    نقش: D/V
 تأیید کنید که کلیدهای API یا JWT شامل ادعاهای محدوده دار (مثلاً شناسه‌های مجموعه، افعال عملیاتی) باشند و حداقل هر سه ماه یکبار تعویض شوند.
 #8.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تلاش‌های افزایش دسترسی (مانند پرس‌وجوهای مشابهت بین فضای نام‌ها) در عرض ۵ دقیقه شناسایی و به یک سامانه مدیریت اطلاعات و رویدادهای امنیتی (SIEM) گزارش می‌شوند.
 #8.1.4    سطح: 2    نقش: D/V
 تأیید کنید که پایگاه داده برداری گزارش‌های حسابرسی شامل شناسه موضوع، عملیات، شناسه بردار/فضای نام، آستانه شباهت و تعداد نتایج باشد.
 #8.1.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که تصمیمات دسترسی هر زمان که موتور‌ها به‌روزرسانی می‌شوند یا قوانین تقسیم‌بندی شاخص تغییر می‌کنند، از نظر نقص‌های دور زدن تست می‌شوند.

---

### C8.2 پاکسازی و اعتبارسنجی جاسازی

متن را برای اطلاعات شخصی قابل شناسایی (PII) پیش‌غربالگری کنید، قبل از تبدیل به بردار، آن را حذف یا شبه‌نام‌گذاری کنید، و به طور اختیاری پس‌پردازش تعبیه‌ها را برای حذف سیگنال‌های باقی‌مانده انجام دهید.

 #8.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که داده‌های شناسایی‌شدنی شخصی (PII) و داده‌های تنظیم شده از طریق طبقه‌بندهای خودکار شناسایی شده و پیش از جاسازی، ماسک شده، توکنیزه شده یا حذف می‌شوند.
 #8.2.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که خطوط لوله تعبیه شده ورودی‌هایی که شامل کد اجرایی یا آثار غیر UTF-8 هستند که ممکن است نمایه را آلوده کنند، رد یا قرنطینه می‌کنند.
 #8.2.3    سطح: 2    نقش: D/V
 تأیید کنید که ضدعفونی‌سازی با حریم خصوصی تفاضلی محلی یا متریک بر روی تعبیه‌های جمله اعمال شده است که فاصله آنها تا هر توکن شناخته‌شده PII کمتر از یک آستانه قابل تنظیم است.
 #8.2.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که اثربخشی پالایش (مثلاً بازیابی حذف اطلاعات شناسایی شخصی، انحراف معنایی) حداقل به صورت نیم‌سالانه در برابر مجموعه‌های معیار ارزیابی می‌شود.
 #8.2.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که پیکربندی‌های پاکسازی تحت کنترل نسخه هستند و تغییرات زیر نظر بازبینی همکاران قرار می‌گیرند.

---

### C8.3 انقضای حافظه، لغو و حذف

قانون GDPR "حق فراموش شدن" و قوانین مشابه نیازمند پاک‌سازی به‌موقع هستند؛ بنابراین، فروشگاه‌های وکتور باید از TTLها، حذف‌های سخت، و تامب‌استونینگ پشتیبانی کنند تا وکتورهای لغو شده قابل بازیابی یا بازنمایه‌سازی نباشند.

 #8.3.1    سطح: 1    نقش: D/V
 بررسی کنید که هر رکورد بردار و فراداده دارای یک TTL یا برچسب نگهداری صریح باشد که توسط وظایف پاکسازی خودکار رعایت می‌شود.
 #8.3.2    سطح: 1    نقش: D/V
 تأیید کنید که درخواست‌های حذف آغاز شده توسط کاربر، بردارها، فراداده‌ها، نسخه‌های کش و نمایه‌های مشتق شده را در طی ۳۰ روز پاک می‌کنند.
 #8.3.3    سطح: 2    نقش: D
 تأیید کنید که حذف‌های منطقی پس از آن با ردیابی رمزنگاری‌شده بلوک‌های ذخیره‌سازی در صورتی که سخت‌افزار پشتیبانی کند، یا با تخریب کلیدهای ذخیره‌شده در کیف کلید دنبال شوند.
 #8.3.4    سطح: 3    نقش: D/V
 تأیید کنید که بردارهای منقضی شده ظرف کمتر از 500 میلی‌ثانیه پس از انقضا از نتایج جستجوی نزدیک‌ترین همسایه حذف می‌شوند.

---

### C8.4 جلوگیری از وارونگی و نشت جاسازی

دفاع‌های اخیر—افزودن نویز، شبکه‌های پروجکشن، اختلال نورون حریم خصوصی، و رمزنگاری لایه برنامه—می‌توانند نرخ بازگشت معکوس در سطح توکن را به زیر 5% کاهش دهند.

 #8.4.1    سطح: 1    نقش: V
 اطمینان حاصل شود که یک مدل تهدید رسمی که شامل حملات وارونگی، عضویت و استنتاج ویژگی‌ها است وجود داشته و سالیانه مورد بازبینی قرار می‌گیرد.
 #8.4.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که رمزگذاری لایه برنامه یا رمزگذاری جستجوپذیر، بردارها را از خوانش مستقیم توسط مدیران زیرساخت یا کارکنان ابر محافظت می‌کند.
 #8.4.3    سطح: 3    نقش: V
 اطمینان حاصل کنید که پارامترهای دفاعی (ε برای حفظ حریم خصوصی تفاضلی، نویز σ، رتبه پروجکشن k) تعادل مناسبی بین حفاظت از حریم خصوصی ≥ 99٪ توکن و کاربردی بودن ≤ 3٪ کاهش دقت برقرار می‌کنند.
 #8.4.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که معیارهای مقاومت در برابر وارونگی بخشی از دروازه‌های انتشار برای به‌روزرسانی‌های مدل هستند، با تعریف بودجه‌های رگرسیون.

---

### C8.5 اجرای حوزه برای حافظه خاص کاربر

نشتی بین مستاجران همچنان یکی از بزرگ‌ترین ریسک‌های RAG است: پرس‌وجوهای تشابه به‌طور نادرست فیلتر شده می‌توانند اسناد خصوصی مشتری دیگر را آشکار کنند.

 #8.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر پرس‌وجوی بازیابی قبل از ارسال به پرسش LLM، بر اساس شناسه مستاجر/کاربر پس‌پردازش شده باشد.
 #8.5.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که نام‌های مجموعه یا شناسه‌های نام‌گذاری شده برای هر کاربر یا مستاجر به صورت نمک‌گذاری شده باشند تا بردارها در بین حوزه‌ها تداخل نداشته باشند.
 #8.5.3    سطح: 2    نقش: D/V
 تأیید کنید که نتایج شباهت بالاتر از آستانه فاصله قابل تنظیم اما خارج از حوزه تماس‌گیرنده دور ریخته شده و هشدارهای امنیتی را فعال می‌کنند.
 #8.5.4    سطح: 2    نقش: V
 تأیید کنید که تست‌های فشار چند مستاجری، شبیه‌سازی پرسش‌های خصمانه‌ای هستند که تلاش می‌کنند اسناد خارج از حوزه را بازیابی کنند و نشان دهند که هیچ نشت اطلاعاتی رخ نمی‌دهد.
 #8.5.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که کلیدهای رمزگذاری به ازای هر مستأجر جدا شده‌اند و جداسازی رمزنگاری حتی در صورت اشتراک‌گذاری فضای ذخیره‌سازی فیزیکی حفظ می‌شود.

---

### C8.6 امنیت پیشرفته سیستم حافظه

کنترل‌های امنیتی برای معماری‌های پیچیده حافظه شامل حافظه اپیزودیک، معنایی و کاری با الزامات خاص ایزولاسیون و اعتبارسنجی.

 #8.6.1    سطح: 1    نقش: D/V
 تأیید کنید که انواع مختلف حافظه (اپیزودیک، معنادار، کاری) دارای زمینه‌های امنیتی جداگانه با کنترل‌های دسترسی مبتنی بر نقش، کلیدهای رمزنگاری جداگانه و الگوهای دسترسی مستند برای هر نوع حافظه باشند.
 #8.6.2    سطح: 2    نقش: D/V
 تأیید کنید که فرآیندهای تحکیم حافظه شامل اعتبارسنجی امنیتی برای جلوگیری از وارد کردن خاطرات مخرب از طریق پاک‌سازی محتوا، تأیید منبع، و بررسی‌های صحت قبل از ذخیره‌سازی باشند.
 #8.6.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که پرس‌وجوهای بازیابی حافظه بررسی و پاک‌سازی می‌شوند تا از استخراج اطلاعات غیرمجاز از طریق تحلیل الگوی پرس‌وجو، اعمال کنترل دسترسی و فیلتر کردن نتایج جلوگیری شود.
 #8.6.4    سطح: 3    نقش: D/V
 تأیید کنید که مکانیزم‌های فراموشی حافظه با تضمین‌های پاک‌سازی رمزنگاری شده، اطلاعات حساس را به صورت ایمن حذف می‌کنند، از جمله حذف کلید، بازنویسی چندباره، یا حذف ایمن مبتنی بر سخت‌افزار همراه با گواهی‌های تأیید.
 #8.6.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که یکپارچگی سیستم حافظه به طور مداوم از طریق چکسام‌ها، لاگ‌های حسابرسی و هشدارهای خودکار هنگام تغییر محتوای حافظه خارج از عملیات عادی برای اصلاحات غیرمجاز یا خرابی‌ها نظارت می‌شود.

---

### مراجع

Vector database security: Pinecone – IronCore Labs
Securing the Backbone of AI: Safeguarding Vector Databases and Embeddings – Privacera
Enhancing Data Security with RBAC of Qdrant Vector Database – AI Advances
Mitigating Privacy Risks in LLM Embeddings from Embedding Inversion – arXiv
DPPN: Detecting and Perturbing Privacy-Sensitive Neurons – OpenReview
Art. 17 GDPR – Right to Erasure
Sensitive Data in Text Embeddings Is Recoverable – Tonic.ai
PII Identification and Removal – NVIDIA NeMo Docs
De-identifying Sensitive Data – Google Cloud DLP
Remove PII from Conversations Using Sensitive Information Filters – AWS Bedrock Guardrails
Think Your RAG Is Secure? Think Again – Medium
Design a Secure Multitenant RAG Inferencing Solution – Microsoft Learn
Best Practices for Multi-Tenancy RAG with Milvus – Milvus Blog

## 9 امنیت ارکستراسیون خودران و اقدام عاملیت‌مند

### هدف کنترل

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی خودمختار یا چند عامله تنها قادر به اجرای اقداماتی هستند که به طور صریح مورد نظر، تایید شده، قابل حسابرسی و در محدوده هزینه و آستانه‌های ریسک تعریف شده باشند. این اقدام از تهدیداتی مانند نفوذ به سیستم خودمختار، استفاده نادرست از ابزار، شناسایی حلقه عامل، ربایش ارتباطات، جعل هویت، دستکاری گروهی و دستکاری قصد جلوگیری می‌کند.

---

### 9.1 بودجه‌های برنامه‌ریزی وظایف عامل و بازگشت‌دهی

طرح‌های بازگشتی را محدود کنید و برای اقدامات دارای امتیاز، نقاط توقف انسانی را اجباری کنید.

 #9.1.1    سطح: 1    نقش: D/V
 تأیید کنید که عمق حداکثر بازگشت، عرض، زمان ساعت دیواری، توکن‌ها و هزینه مالی هر اجرای عامل به صورت مرکزی پیکربندی شده و تحت کنترل نسخه قرار دارند.
 #9.1.2    سطح: 1    نقش: D/V
 تأیید کنید که اقدامات ویژه یا غیرقابل بازگشت (مثلاً کامیت‌های کد، انتقالات مالی) قبل از اجرا نیازمند تأیید صریح انسانی از طریق کانالی قابل حسابرسی باشند.
 #9.1.3    سطح: 2    نقش: D
 تأیید کنید که مانیتورهای منابع زمان واقعی هنگام عبور از هر آستانه بودجه، باعث وقفه مدار شکن شده و توسعه بیشتر وظیفه را متوقف می‌کنند.
 #9.1.4    سطح: 2    نقش: D/V
 تأیید کنید که رویدادهای قطع‌کننده مدار به همراه شناسه عامل، شرایط تحریک‌کننده و وضعیت طرح گرفته‌شده برای بررسی قانونی ثبت می‌شوند.
 #9.1.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که تست‌های امنیتی، سناریوهای تمام شدن بودجه و طرح‌های خارج از کنترل را پوشش می‌دهند و توقف ایمن بدون از دست دادن داده را تأیید می‌کنند.
 #9.1.6    سطح: 3    نقش: D
 اطمینان حاصل کنید که سیاست‌های بودجه به صورت سیاست-به-کد بیان شده‌اند و در CI/CD اجرا می‌شوند تا از انحراف پیکربندی جلوگیری شود.

---

### 9.2 ایزولاسیون افزونه ابزار (Tool Plugin Sandboxing)

تعاملات ابزار را جدا کنید تا از دسترسی غیرمجاز به سیستم یا اجرای کد جلوگیری شود.

 #9.2.1    سطح: 1    نقش: D/V
 تأیید کنید که هر ابزار/افزونه در داخل یک سیستم‌عامل، کانتینر، یا سندباکس سطح WASM اجرا شود که دارای سیاست‌های کمترین امتیاز بر روی فایل‌سیستم، شبکه و فراخوانی‌های سیستمی باشد.
 #9.2.2    سطح: 1    نقش: D/V
 تأیید کنید که محدودیت‌های منابع سندباکس (CPU، حافظه، دیسک، خروجی شبکه) و زمان‌های پایان اجرای برنامه اجرا و ثبت می‌شوند.
 #9.2.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که باینری‌ها یا توصیف‌گرهای ابزار به صورت دیجیتال امضا شده‌اند؛ امضاها قبل از بارگذاری اعتبارسنجی می‌شوند.
 #9.2.4    سطح: 2    نقش: V
 اطمینان حاصل کنید که داده‌های تله‌متری سندباکس به سامانه مدیریت اطلاعات و رویدادهای امنیتی (SIEM) ارسال می‌شود؛ ناهنجاری‌ها (مانند تلاش برای اتصال خروجی) هشدار ایجاد می‌کنند.
 #9.2.5    سطح: 3    نقش: V
 تأیید کنید که افزونه‌های پرخطر قبل از استقرار در محیط تولید، مورد بازبینی امنیتی و تست نفوذ قرار گیرند.
 #9.2.6    سطح: 3    نقش: D/V
 تأیید کنید که تلاش‌های فرار از سندباکس به‌طور خودکار مسدود شده و پلاگین متخلف تا زمان بررسی در قرنطینه قرار می‌گیرد.

---

### 9.3 حلقه خودگردان و محدودسازی هزینه

شناسایی و جلوگیری از بازگشت‌های بازگشتی کنترل‌نشده بین عامل‌ها و انفجارهای هزینه‌ای.

 #9.3.1    سطح: 1    نقش: D/V
 تأیید کنید که تماس‌های بین عامل‌ها شامل محدودیت پرش یا TTL باشد که زمان اجرا آن را کاهش داده و اعمال می‌کند.
 #9.3.2    سطح: 2    نقش: D
 تأیید کنید که عامل‌ها یک شناسه منحصربه‌فرد برای نمودار فراخوانی حفظ کنند تا فراخوانی به خود یا الگوهای چرخه‌ای را تشخیص دهند.
 #9.3.3    سطح: 2    نقش: D/V
 تأیید کنید که شمارنده‌های تجمعی واحد محاسباتی و هزینه برای هر زنجیره درخواست پیگیری می‌شوند؛ عبور از حد تعیین‌شده باعث قطع زنجیره می‌گردد.
 #9.3.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که تحلیل رسمی یا مدل‌چکینگ عدم وجود بازگشت نامحدود در پروتکل‌های عامل را نشان می‌دهد.
 #9.3.5    سطح: 3    نقش: D
 اطمینان حاصل کنید که رویدادهای خاتمه حلقه، هشدارها را تولید می‌کنند و معیارهای بهبود مستمر را تغذیه می‌کنند.

---

### 9.4 حفاظت در برابر سوءاستفاده در سطح پروتکل

کانال‌های ارتباطی امن بین نمایندگان و سیستم‌های خارجی برای جلوگیری از ربوده شدن یا دستکاری.

 #9.4.1    سطح: 1    نقش: D/V
 تأیید کنید که تمامی پیام‌های بین عامل و ابزار و همچنین بین عوامل، احراز هویت شده‌اند (مثلاً با استفاده از TLS متقابل یا JWT) و به صورت پایان به پایان رمزگذاری شده‌اند.
 #9.4.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که اسکیم‌ها به‌طور دقیق اعتبارسنجی می‌شوند؛ فیلدهای ناشناخته یا پیام‌های نادرست رد می‌شوند.
 #9.4.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که بررسی‌های یکپارچگی (MAC ها یا امضاهای دیجیتال) کل بار پیام از جمله پارامترهای ابزار را پوشش می‌دهند.
 #9.4.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که محافظت در برابر بازپخش (nonceها یا پنجره‌های زمان‌بندی) در لایه پروتکل اعمال می‌شود.
 #9.4.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که پیاده‌سازی‌های پروتکل تحت فرآیند فازینگ و تحلیل ایستا برای یافتن نقص‌های تزریق یا سریال‌زدایی قرار می‌گیرند.

---

### 9.5 هویت عامل و شواهد عدم دستکاری

اطمینان حاصل کنید که اقدامات قابل انتساب و تغییرات قابل تشخیص باشند.

 #9.5.1    سطح: 1    نقش: D/V
 تأیید کنید که هر نمونه عامل دارای یک هویت رمزنگاری منحصر به فرد (جفت کلید یا مدارک ریشه‌ای مبتنی بر سخت‌افزار) است.
 #9.5.2    سطح: 2    نقش: D/V
 تأیید کنید که تمام اقدامات عامل امضا و زمان‌گذاری شده باشند؛ گزارش‌ها شامل امضا برای عدم انکار هستند.
 #9.5.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که لاگ‌های قابل تشخیص دستکاری در یک رسانه افزودنی فقط یا یک بار نوشتنی ذخیره می‌شوند.
 #9.5.4    سطح: 3    نقش: D
 اطمینان حاصل کنید که کلیدهای هویتی بر اساس یک برنامه تعریف شده و در صورت وجود شاخص‌های نفوذ، چرخش می‌کنند.
 #9.5.5    سطح: 3    نقش: D/V
 تأیید کنید که تلاش‌های جعل هویت یا تعارض کلید منجر به قرنطینه فوری عامل متاثر شده شود.

---

### 9.6 کاهش ریسک گروهی چندعاملی

کاهش مخاطرات رفتار جمعی از طریق جداسازی و مدل‌سازی رسمی ایمنی.

 #9.6.1    سطح: 1    نقش: D/V
 تأیید کنید که عامل‌هایی که در حوزه‌های امنیتی مختلف فعالیت می‌کنند، در محیط‌های اجرای ایزوله شده مانند ساندباکس‌های زمانی یا بخش‌های شبکه جداگانه اجرا شوند.
 #9.6.2    سطح: 3    نقش: V
 تأیید کنید که رفتارهای گروهی مدل‌سازی شده و به طور رسمی برای زنده‌مانی و ایمنی قبل از استقرار تأیید شده باشند.
 #9.6.3    سطح: 3    نقش: D
 تأیید کنید که مانیتورهای زمان اجرا الگوهای ناایمن نوظهور (مانند نوسانات، بن‌بست‌ها) را شناسایی کرده و اقدامات اصلاحی را آغاز می‌کنند.

---

### 9.7 احراز هویت / مجوز کاربران و ابزارها

کنترل‌های دسترسی قوی را برای هر عملی که توسط عامل انجام می‌شود، پیاده‌سازی کنید.

 #9.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که عوامل به عنوان اصلی‌ترین اشخاص به سیستم‌های پایین‌دستی احراز هویت می‌کنند و هرگز از اعتبارنامه‌های کاربران نهایی مجدداً استفاده نمی‌کنند.
 #9.7.2    سطح: 2    نقش: D
 تأیید کنید که سیاست‌های مجوزدهی با دقت بالا محدود می‌کنند که کدام ابزارها توسط یک عامل فراخوانی شوند و کدام پارامترها می‌توانند ارائه شوند.
 #9.7.3    سطح: 2    نقش: V
 تأیید کنید که بررسی‌های اختیارات در هر فراخوانی دوباره ارزیابی شوند (مجوزدهی پیوسته)، نه فقط در شروع جلسه.
 #9.7.4    سطح: 3    نقش: D
 تأیید کنید که اختیارات واگذار شده به طور خودکار منقضی می‌شوند و پس از اتمام زمان مجاز یا تغییر دامنه، نیاز به رضایت مجدد دارند.

---

### 9.8 امنیت ارتباط عامل با عامل

تمام پیام‌های بین عوامل را رمزنگاری کرده و از صحت آنها محافظت کنید تا از استراق سمع و دستکاری جلوگیری شود.

 #9.8.1    سطح: 1    نقش: D/V
 تأیید کنید که احراز هویت متقابل و رمزنگاری با امنیت کامل به جلو (مثلاً TLS 1.3) برای کانال‌های عامل اجباری هستند.
 #9.8.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که صحت و منبع پیام قبل از پردازش تأیید شده‌اند؛ در صورت بروز خطا، هشدار صادر شده و پیام حذف می‌شود.
 #9.8.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فراداده‌های ارتباطی (زمان‌سنجی‌ها، شماره‌های توالی) برای پشتیبانی از بازسازی قضایی ثبت می‌شوند.
 #9.8.4    سطح: 3    نقش: V
 تأیید کنید که بررسی رسمی یا مدل‌سازی اثبات می‌کند که ماشین‌های حالت پروتکل نمی‌توانند به حالت‌های ناامن وارد شوند.

---

### 9.9 تایید نیت و اجرای محدودیت‌ها

اعتبارسنجی کنید که اقدامات عامل با نیت بیان شده توسط کاربر و محدودیت‌های سیستم هماهنگ باشد.

 #9.9.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که حل‌کننده‌های محدودیت پیش‌اجرا، اقدامات پیشنهادی را در برابر قوانین ایمنی و سیاست‌های سخت‌کد شده بررسی می‌کنند.
 #9.9.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اقدامات با اثر بالا (مالی، مخرب، حساس به حریم خصوصی) نیاز به تأیید صریح نیت از سوی کاربر آغازکننده دارند.
 #9.9.3    سطح: 2    نقش: V
 تأیید کنید که بررسی‌های شرط پس از انجام، صحت اجرای اقدامات کامل شده را بدون اثرات جانبی ارزیابی می‌کنند؛ ناهنجاری‌ها باعث بازگردانی می‌شوند.
 #9.9.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که روش‌های رسمی (مانند مدل‌سازی بررسی، اثبات نظریه) یا آزمایش‌های مبتنی بر ویژگی نشان می‌دهند که برنامه‌های عامل تمام محدودیت‌های اعلام‌شده را برآورده می‌کنند.
 #9.9.5    سطح: 3    نقش: D
 تأیید کنید که حوادث عدم تطابق هدف یا نقض محدودیت، چرخه‌های بهبود مستمر و به اشتراک‌گذاری اطلاعات تهدید را تغذیه می‌کنند.

---

### 9.10 استراتژی استدلال عامل امنیتی

انتخاب و اجرای ایمن استراتژی‌های مختلف استدلال از جمله روش‌های ReAct، زنجیره‌ای-از-تفکر (Chain-of-Thought)، و درختی-از-تفکرات (Tree-of-Thoughts).

 #9.10.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که انتخاب استراتژی استدلال از معیارهای تعیین‌شده استفاده می‌کند (پیچیدگی ورودی، نوع وظیفه، زمینه امنیتی) و ورودی‌های یکسان در همان زمینه امنیتی انتخاب استراتژی یکسانی تولید می‌کنند.
 #9.10.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که هر استراتژی استدلال (ReAct، Chain-of-Thought، Tree-of-Thoughts) دارای اعتبارسنجی ورودی اختصاصی، پاکسازی خروجی، و محدودیت‌های زمان اجرای مشخص برای رویکرد شناختی مربوط به خود باشد.
 #9.10.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که انتقال‌های استراتژی استدلال با زمینه کامل شامل ویژگی‌های ورودی، مقادیر معیار انتخاب، و فراداده اجرای برای بازسازی مسیر بررسی ثبت می‌شوند.
 #9.10.4    سطح: 2    نقش: D/V
 تأیید کنید که استدلال درخت-افکار شامل مکانیزم‌های هرس شاخه است که هنگام شناسایی نقض سیاست‌ها، محدودیت‌های منابع، یا مرزهای ایمنی، کاوش را متوقف می‌کنند.
 #9.10.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که چرخه‌های ReAct (استدلال-عمل-مشاهده) شامل نقاط بازرسی اعتبارسنجی در هر مرحله هستند: تأیید گام استدلال، مجوز انجام عمل و پاک‌سازی مشاهده قبل از ادامه.
 #9.10.6    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که معیارهای عملکرد استراتژی استدلال (زمان اجرا، استفاده از منابع، کیفیت خروجی) با هشدارهای خودکار زمانی که معیارها از حدود تعیین شده فراتر می‌روند، پایش می‌شوند.
 #9.10.7    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که روش‌های استدلال ترکیبی که چندین استراتژی را با هم ترکیب می‌کنند، اعتبارسنجی ورودی و محدودیت‌های خروجی همه استراتژی‌های تشکیل‌دهنده را حفظ می‌کنند بدون اینکه هیچ‌یک از کنترل‌های امنیتی را دور بزنند.
 #9.10.8    سطح: 3    نقش: D/V
 تأیید کنید که آزمایش امنیتی استراتژی استدلال شامل فازینگ با ورودی‌های معیوب، پرامپت‌های خصمانه طراحی شده برای اجبار به تغییر استراتژی، و آزمایش شرایط مرزی برای هر رویکرد شناختی باشد.

---

### 9.11 مدیریت وضعیت چرخه عمر عامل و امنیت

راه‌اندازی امن عامل، انتقال‌های حالت و خاتمه با مسیرهای حسابرسی رمزنگاری شده و رویه‌های بازیابی تعریف‌شده.

 #9.11.1    سطح: 1    نقش: D/V
 تأیید کنید که راه‌اندازی عامل شامل برقراری هویت رمزنگاری شده با مدارک پشتیبانی‌شده توسط سخت‌افزار و ثبت‌های حسابرسی غیرقابل تغییر در زمان راه‌اندازی است که شامل شناسه عامل، نشان زمان، هش پیکربندی و پارامترهای راه‌اندازی می‌باشد.
 #9.11.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که انتقال‌های وضعیت عامل به‌صورت رمزنگاری شده امضا شده، دارای مهرزمان هستند و با کامل‌ترین زمینه شامل رویدادهای محرک، هش وضعیت قبلی، هش وضعیت جدید و اعتبارسنجی‌های امنیتی انجام شده، ثبت می‌شوند.
 #9.11.3    سطح: 2    نقش: D/V
 تأیید کنید که رویه‌های خاموش کردن عامل شامل پاک‌سازی ایمن حافظه با استفاده از حذف رمزنگاری‌شده یا بازنویسی چندباره، لغو اعتبار اطلاعات ورود با اطلاع‌رسانی به مرجع صدور گواهی، و تولید گواهی‌های خاتمه با قابلیت تشخیص دستکاری باشد.
 #9.11.4    سطح: 3    نقش: D/V
 تأیید کنید که مکانیزم‌های بازیابی عامل صحت یکپارچگی وضعیت را با استفاده از چک‌سام‌های رمزنگاری شده (حداقل SHA-256) بررسی می‌کنند و در صورت تشخیص فساد، به وضعیت‌های معتبر شناخته شده بازمی‌گردند، همراه با هشدارهای خودکار و نیاز به تأیید دستی.
 #9.11.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های پایداری عامل داده‌های حالت حساس را با کلیدهای AES-256 اختصاصی برای هر عامل رمزگذاری می‌کنند و چرخش امن کلید را با برنامه‌های قابل تنظیم (حداکثر 90 روز) با استقرار بدون قطعی اجرا می‌کنند.

---

### چارچوب امنیتی ادغام ابزار 9.12

کنترل‌های امنیتی برای بارگذاری دینامیک ابزار، اجرای آن و اعتبارسنجی نتایج با فرآیندهای ارزیابی ریسک و تأیید مشخص شده.

 #9.12.1    سطح: 1    نقش: D/V
 تأیید کنید که توصیف‌کننده‌های ابزار شامل فراداده‌های امنیتی باشند که مجوزهای لازم (خواندن/نوشتن/اجرا)، سطوح ریسک (کم/متوسط/بالا)، محدودیت‌های منابع (CPU، حافظه، شبکه) و الزامات اعتبارسنجی که در مانیفست‌های ابزار مستند شده‌اند را مشخص می‌کنند.
 #9.12.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که نتایج اجرای ابزار پیش از ادغام با محدودیت‌های زمان اجرا و رویه‌های مدیریت خطا، بر اساس اسکیمای مورد انتظار (JSON Schema، XML Schema) و سیاست‌های امنیتی (پاک‌سازی خروجی، طبقه‌بندی داده‌ها) اعتبارسنجی می‌شوند.
 #9.12.3    سطح: 2    نقش: D/V
 تأیید کنید که لاگ‌های تعامل ابزار شامل زمینه‌ی امنیتی دقیق باشد که استفاده از مجوزها، الگوهای دسترسی به داده‌ها، زمان اجرا، مصرف منابع و کدهای بازگشتی را با لاگ‌گذاری ساختاریافته برای یکپارچه‌سازی با SIEM شامل می‌شود.
 #9.12.4    سطح: 2    نقش: D/V
 تأیید کنید که مکانیزم‌های بارگذاری ابزار پویا امضاهای دیجیتال را با استفاده از زیرساخت کلید عمومی (PKI) اعتبارسنجی می‌کنند و پروتکل‌های بارگذاری امن را با جداسازی محیطی (sandbox) و تأیید مجوزها قبل از اجرا پیاده‌سازی می‌نمایند.
 #9.12.5    سطح: 3    نقش: D/V
 تأیید کنید که ارزیابی‌های امنیتی ابزار به‌طور خودکار برای نسخه‌های جدید با دروازه‌های تصویب اجباری شامل تحلیل ایستا، آزمایش پویا و بازبینی تیم امنیتی با معیارهای تصویب مستند و الزامات SLA فعال می‌شوند.

---

#### مراجع

MITRE ATLAS tactics ML09
Circuit-breaker research for AI agents — Zou et al., 2024
Trend Micro analysis of sandbox escapes in AI agents — Park, 2025
Auth0 guidance on human-in-the-loop authorization for agents — Martinez, 2025
Medium deep-dive on MCP & A2A protocol hijacking — ForAISec, 2025
Rapid7 fundamentals on spoofing attack prevention — 2024
Imperial College verification of swarm systems — Lomuscio et al.
NIST AI Risk Management Framework 1.0, 2023
WIRED security briefing on encryption best practices, 2024
OWASP Top 10 for LLM Applications, 2025
Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS
[How Is LLM Reasoning Distracted by Irrelevant Context?
An Analysis Using a Controlled Benchmark](https://www.arxiv.org/pdf/2505.18761)
Large Language Model Sentinel: LLM Agent for Adversarial Purification
Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents

## 10 مقاومت در برابر حملات مخرب و دفاع از حریم خصوصی

### هدف کنترل

اطمینان حاصل کنید که مدل‌های هوش مصنوعی هنگام مواجهه با حملات دور زدن، استنتاج، استخراج یا مسموم‌سازی، قابل اطمینان، محافظت‌کننده از حریم خصوصی و مقاوم در برابر سوء استفاده باقی بمانند.

---

### 10.1 تطابق و ایمنی مدل

در برابر خروجی‌های مضر یا نقض‌کننده‌ی سیاست‌ها محافظت کنید.

 #10.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که یک مجموعه تست هماهنگی (پرامپت‌های تیم قرمز، پروب‌های فرار، محتوای ممنوعه) تحت کنترل نسخه است و در هر نسخه مدل اجرا می‌شود.
 #10.1.2    سطح: 1    نقش: D
 تأیید کنید که محافظ‌های رد کردن و اتمام ایمن اجرا شده‌اند.
 #10.1.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که یک ارزیاب خودکار نرخ محتوای مضر را اندازه‌گیری می‌کند و بازگشت‌های منفی فراتر از آستانه تعیین‌شده را علامت‌گذاری می‌کند.
 #10.1.4    سطح: 2    نقش: D
 اطمینان حاصل کنید که آموزش ضد دورزدن سیستم مستند و قابل بازتولید است.
 #10.1.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که اثبات‌های رسمی رعایت سیاست یا پایش معتبر، حوزه‌های حیاتی را پوشش می‌دهند.

---

### 10.2 مقاوم‌سازی در برابر نمونه‌های مخرب

افزایش مقاومت در برابر ورودی‌های دستکاری شده. آموزش مقاومتی قوی و امتیازدهی بنچمارک در حال حاضر بهترین روش‌های مورد استفاده هستند.

 #10.2.1    سطح: 1    نقش: D
 بررسی کنید که مخازن پروژه شامل تنظیمات آموزش تقابلی با دانه‌های قابل بازتولید باشند.
 #10.2.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تشخیص مثال‌های متخاصم در خطوط تولید باعث ایجاد هشدارهای مسدودکننده می‌شود.
 #10.2.4    سطح: 3    نقش: V
 تأیید کنید که اثبات‌های مقاومت تاییدشده یا گواهی‌های بازه‌ای حداقل شامل مهم‌ترین کلاس‌های بحرانی باشند.
 #10.2.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که تست‌های رگرسیون از حملات تطبیقی استفاده می‌کنند تا عدم کاهش قابل سنجش در مقاومت را تأیید کنند.

---

### 10.3 کاهش استنباط عضویت

محدود کردن امکان تصمیم‌گیری درباره اینکه آیا یک رکورد در داده‌های آموزشی بوده است یا خیر. حفظ حریم خصوصی تفاضلی و ماسک کردن نمره اطمینان همچنان مؤثرترین روش‌های دفاعی شناخته شده هستند.

 #10.3.1    سطح: 1    نقش: D
 تأیید کنید که تنظیم منظم‌سازی آنتروپی به ازای هر پرسش یا مقیاس‌بندی دما باعث کاهش پیش‌بینی‌های بیش از حد مطمئن می‌شود.
 #10.3.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که آموزش از بهینه‌سازی گرادیان خصوصی متفاوت با کران ε برای مجموعه داده‌های حساس استفاده می‌کند.
 #10.3.3    سطح: 2    نقش: V
 تأیید کنید که شبیه‌سازی‌های حمله (مدل سایه یا جعبه سیاه) میزان AUC حمله ≤ 0.60 را روی داده‌های نگه‌داشته‌شده نشان دهند.

---

### 10.4 مقاومت در برابر وارونگی مدل

جلوگیری از بازسازی ویژگی‌های خصوصی. بررسی‌های اخیر بر کوتاه‌سازی خروجی و تضمین‌های DP به‌عنوان دفاع‌های عملی تأکید دارند.

 #10.4.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که ویژگی‌های حساس هرگز به صورت مستقیم خروجی داده نشوند؛ در صورت لزوم، از دسته‌بندی‌ها یا تبدیلات یک‌طرفه استفاده کنید.
 #10.4.2    سطح: 1    نقش: D/V
 تأیید کنید که محدودیت‌های نرخ پرس‌وجو، پرس‌وجوهای تطبیقی تکراری از همان اصل را محدود می‌کنند.
 #10.4.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که مدل با نویز حفظ حریم خصوصی آموزش داده شده است.

---

### 10.5 دفاع در برابر استخراج مدل

کپی‌برداری غیرمجاز را شناسایی و جلوگیری کنید. استفاده از نشان‌گذاری آبی و تحلیل الگوی پرس‌وجو توصیه می‌شود.

 #10.5.1    سطح: 1    نقش: D
 تأیید کنید که دروازه‌های استنتاج محدودیت‌های نرخ کلی و محدودیت‌های نرخ به ازای هر کلید API را که متناسب با آستانه حفظ مدل تنظیم شده‌اند، اعمال می‌کنند.
 #10.5.2    سطح: 2    نقش: D/V
 تأیید کنید که آمارهای آنتروپی پرس‌وجو و چندگانگی ورودی، یک آشکارساز استخراج خودکار را تغذیه می‌کنند.
 #10.5.3    سطح: 2    نقش: V
 تأیید کنید که واترمارک‌های شکننده یا احتمالاتی می‌توانند با p < 0.01 در ≤ 1 000 پرس‌و‌جو علیه یک نسخه مشکوک اثبات شوند.
 #10.5.4    سطح: 3    نقش: D
 اطمینان حاصل کنید که کلیدهای واترمارک و مجموعه‌های تریگر در یک ماژول امنیت سخت‌افزاری ذخیره شده و سالانه چرخش می‌یابند.
 #10.5.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که رویدادهای هشدار استخراج شامل کوئری‌های مخرب بوده و با کتابچه‌های راهنمای پاسخ به حادثه یکپارچه شده‌اند.

---

### 10.6 تشخیص داده‌های آلوده در زمان استنتاج

شناسایی و خنثی‌سازی ورودی‌های دارای درب‌پشتی یا مسموم شده.

 #10.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که ورودی‌ها قبل از استنتاج مدل از طریق یک آشکارساز ناهنجاری (مانند STRIP، امتیازدهی ثبات) عبور می‌کنند.
 #10.6.2    سطح: 1    نقش: V
 اطمینان حاصل کنید که آستانه‌های آشکارساز بر روی مجموعه‌های اعتبارسنجی تمیز/مسموم تنظیم شده‌اند تا کمتر از ۵٪ خطاهای مثبت کاذب به دست آید.
 #10.6.3    سطح: 2    نقش: D
 بررسی کنید که ورودی‌هایی که به‌عنوان آلوده علامت‌گذاری شده‌اند، موجب فعال شدن جریان‌های کاری مسدودسازی نرم و بازبینی انسانی شوند.
 #10.6.4    سطح: 2    نقش: V
 تأیید کنید که آشکارسازها تحت آزمایش استرس با حملات درب‌پشتی تطبیقی و بدون محرک قرار گرفته‌اند.
 #10.6.5    سطح: 3    نقش: D
 اطمینان حاصل کنید که معیارهای اثربخشی تشخیص ثبت شده و به طور دوره‌ای با اطلاعات تهدید جدید بازبینی می‌شوند.

---

### 10.7 انطباق پویا سیاست امنیتی

به‌روزرسانی‌های سیاست امنیتی در زمان واقعی بر اساس اطلاعات تهدید و تحلیل رفتاری.

 #10.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیاست‌های امنیتی می‌توانند به‌طور پویا بدون راه‌اندازی مجدد عامل به‌روزرسانی شوند در حالی که صحت نسخه سیاست حفظ می‌شود.
 #10.7.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که به‌روزرسانی‌های سیاست به‌صورت رمزنگاری‌شده توسط کارکنان امنیتی مجاز امضا شده و قبل از اجرا اعتبارسنجی می‌شوند.
 #10.7.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تغییرات سیاست پویا با سوابق کامل حسابرسی شامل توجیه، زنجیره‌های تصویب و روش‌های بازگردانی ثبت می‌شوند.
 #10.7.4    سطح: 3    نقش: D/V
 تأیید کنید که مکانیزم‌های امنیت تطبیقی حساسیت شناسایی تهدید را بر اساس زمینه ریسک و الگوهای رفتاری تنظیم می‌کنند.
 #10.7.5    سطح: 3    نقش: D/V
 تأیید کنید که تصمیمات تطبیق سیاست قابل توضیح باشند و شامل شواهد و مدارک برای بازبینی تیم امنیتی باشند.

---

### 10.8 تحلیل امنیت مبتنی بر انعکاس

اعتبارسنجی امنیت از طریق خودبازتابی عامل و تحلیل فرامعلوماتی.

 #10.8.1    سطح: 1    نقش: D/V
 تأیید کنید که مکانیزم‌های بازتاب عامل شامل ارزیابی خود متمرکز بر امنیت تصمیمات و اقدامات باشد.
 #10.8.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که خروجی‌های بازتابی برای جلوگیری از دستکاری مکانیزم‌های خودارزیابی توسط ورودی‌های مخرب، اعتبارسنجی می‌شوند.
 #10.8.3    سطح: 2    نقش: D/V
 تأیید کنید که تحلیل امنیت فراشناختی، سوگیری، دستکاری یا به خطر افتادن احتمالی در فرآیندهای استدلال عامل را شناسایی می‌کند.
 #10.8.4    سطح: 3    نقش: D/V
 تأیید کنید که هشدارهای امنیتی مبتنی بر بازتاب، رصد پیشرفته و جریان‌های کاری احتمالی دخالت انسانی را فعال می‌کنند.
 #10.8.5    سطح: 3    نقش: D/V
 تأیید کنید که یادگیری مستمر از بازتاب‌های امنیتی، تشخیص تهدید را بهبود می‌بخشد بدون اینکه عملکرد مشروع را کاهش دهد.

---

### 10.9 امنیت تکامل و خود بهبودی

کنترل‌های امنیتی برای سیستم‌های عاملی که توانایی خودتغییری و تکامل دارند.

 #10.9.1    سطح: 1    نقش: D/V
 تأیید کنید که قابلیت‌های خود-تغییریابی محدود به نواحی امن مشخص شده با مرزهای تأیید رسمی باشند.
 #10.9.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که پیشنهادهای توسعه قبل از اجرا تحت ارزیابی تأثیر امنیتی قرار گیرند.
 #10.9.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مکانیزم‌های خودبهبودی شامل قابلیت بازگردانی همراه با بررسی صحت هستند.
 #10.9.4    سطح: 3    نقش: D/V
 تأیید کنید که امنیت متا-یادگیری از دستکاری مخرب الگوریتم‌های بهبود جلوگیری می‌کند.
 #10.9.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که خودبه‌سازی بازگشتی توسط محدودیت‌های رسمی ایمنی با اثبات‌های ریاضی همگرایی محدود شده است.

---

#### مراجع

MITRE ATLAS adversary tactics for ML
NIST AI Risk Management Framework 1.0, 2023
OWASP Top 10 for LLM Applications, 2025
Adversarial Training: A Survey — Zhao et al., 2024
RobustBench adversarial-robustness benchmark
Membership-Inference & Model-Inversion Risk Survey, 2025
PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023
Model-Inversion Attacks & Defenses Survey — AI Review, 2025
Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024
Fragile Model Watermarking Survey — 2025
Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025
BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024

## 11 حفاظت از حریم خصوصی و مدیریت داده‌های شخصی

### هدف کنترل

نگهداری تضمین‌های سختگیرانه حفظ حریم خصوصی در سراسر چرخه عمر هوش مصنوعی—جمع‌آوری، آموزش، استنتاج، و پاسخ به حادثه—به‌طوری که داده‌های شخصی تنها با رضایت صریح، دامنه حداقلی لازم، حذف قابل اثبات، و تضمین‌های رسمی حریم خصوصی پردازش شوند.

---

### 11.1 ناشناس‌سازی و کمینه‌سازی داده‌ها

 #11.1.1    سطح: 1    نقش: D/V
 تأیید کنید که شناسه‌های مستقیم و شبه‌ شناسه‌ها حذف یا هش شده باشند.
 #11.1.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که حسابرسی‌های خودکار معیارهای k-ناشناس‌سازی/l-تنوع را اندازه‌گیری کرده و هنگامی که آستانه‌ها زیر سیاست تنظیم شده کاهش می‌یابند، هشدار می‌دهند.
 #11.1.3    سطح: 2    نقش: V
 تأیید کنید که گزارش‌های اهمیت ویژگی مدل نشان می‌دهند که هیچ نشت شناسه‌ای فراتر از ε = 0.01 اطلاعات متقابل وجود ندارد.
 #11.1.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که اثبات‌های رسمی یا گواهی‌خطی داده‌های مصنوعی نشان می‌دهند که ریسک بازشناسایی حتی در حملات لینک‌دهی کمتر یا مساوی 0.05 است.

---

### 11.2 حق به فراموش شدن و اجرای حذف

 #11.2.1    سطح: 1    نقش: D/V
 تأیید کنید که درخواست‌های حذف داده‌های موضوعی به مجموعه‌های داده خام، نقاط چک‌پوینت، جاسازی‌ها، گزارش‌ها و نسخه‌های پشتیبان در قالب توافق‌نامه‌های سطح خدمت با مدت کمتر از ۳۰ روز منتقل شوند.
 #11.2.2    سطح: 2    نقش: D
 تأیید کنید که روش‌های "یادگیری معکوس ماشین" به‌صورت فیزیکی بازآموزی یا حذف تقریبی را با استفاده از الگوریتم‌های تایید شده یادگیری معکوس انجام می‌دهند.
 #11.2.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که ارزیابی مدل سایه نشان می‌دهد رکوردهای فراموش شده کمتر از 1٪ از خروجی‌ها را پس از فرآیند فراموشی تحت تأثیر قرار می‌دهند.
 #11.2.4    سطح: 3    نقش: V
 تأیید کنید که رویدادهای حذف به طور غیرقابل تغییر ثبت شده و برای ناظران قابل ممیزی باشند.

---

### 11.3 تدابیر حفظ حریم خصوصی تفاضلی

 #11.3.1    سطح: 2    نقش: D/V
 تأیید کنید که داشبوردهای حسابداری از دست دادن حریم خصوصی هنگامی که مجموع ε از آستانه‌های سیاست فراتر رود، هشدار می‌دهند.
 #11.3.2    سطح: 2    نقش: V
 تأیید کنید که ممیزی‌های حفظ حریم خصوصی جعبه سیاه، ε̂ را در حدود ۱۰٪ از مقدار اعلام شده تخمین می‌زنند.
 #11.3.3    سطح: 3    نقش: V
 اطمینان حاصل کنید که اثبات‌های رسمی تمامی تنظیم‌های دقیق پس از آموزش و تعبیه‌ها را پوشش می‌دهند.

---

### 11.4 محدودیت هدف و حفاظت در برابر افزایش دامنه

 #11.4.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که هر مجموعه داده و نقطه بررسی مدل دارای برچسب هدف قابل خواندن توسط ماشین است که با رضایت اصلی هم‌راستا باشد.
 #11.4.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مانیتورهای زمان اجرا پرس‌وجوهای ناسازگار با هدف اعلام‌شده را شناسایی کرده و انکار نرم را فعال می‌کنند.
 #11.4.3    سطح: 3    نقش: D
 تأیید کنید که دروازه‌های سیاست به عنوان کد، از استقرار مجدد مدل‌ها در دامنه‌های جدید بدون بازبینی DPIA جلوگیری می‌کنند.
 #11.4.4    سطح: 3    نقش: V
 تأیید کنید که مدارک رسمی ردیابی نشان می‌دهد هر مرحله از چرخه زندگی داده‌های شخصی در چارچوب رضایت داده‌شده باقی می‌ماند.

---

### 11.5 مدیریت رضایت و ردیابی بر اساس مبنای قانونی

 #11.5.1    سطح: 1    نقش: D/V
 تأیید کنید که یک پلتفرم مدیریت رضایت (CMP) وضعیت رضایت، هدف و دوره نگهداری را برای هر موضوع داده ثبت می‌کند.
 #11.5.2    سطح: 2    نقش: D
 تأیید کنید که APIها توکن‌های رضایت را ارائه می‌دهند؛ مدل‌ها باید پیش از اجرای استنتاج، محدوده توکن را اعتبارسنجی کنند.
 #11.5.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که عدم موافقت یا پس گرفتن رضایت، پردازش خطوط لوله را ظرف 24 ساعت متوقف می‌کند.

---

### 11.6 یادگیری فدرال با کنترل‌های حریم خصوصی

 #11.6.1    سطح: 1    نقش: D
 تایید کنید که به‌روزرسانی‌های مشتری از افزودن نویز حریم خصوصی تفاضلی محلی قبل از تجمیع استفاده می‌کنند.
 #11.6.2    سطح: 2    نقش: D/V
 تأیید کنید که معیارهای آموزش به صورت خصوصی تفاضلی هستند و هرگز ضرر تک-مشتری را فاش نمی‌کنند.
 #11.6.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که تجمیع مقاوم در برابر مسمومیت (مانند Krum/Trimmed-Mean) فعال است.
 #11.6.4    سطح: 3    نقش: V
 تأیید کنید که اثبات‌های رسمی بودجه کلی ε را با کمتر از ۵ واحد کاهش کاربردی نشان می‌دهند.

---

#### مراجع

GDPR & AI Compliance Best Practices
EU Parliament Study on GDPR & AI, 2020
ISO 31700-1:2023 — Privacy by Design for Consumer Products
NIST Privacy Framework 1.1 (2025 Draft)
Machine Unlearning: Right-to-Be-Forgotten Techniques
A Survey of Machine Unlearning, 2024
Auditing DP-SGD — ArXiv 2024
DP-SGD Explained — PyTorch Blog
Purpose-Limitation for AI — IJLIT 2025
Data-Protection Considerations for AI — URM Consulting
Top Consent-Management Platforms, 2025
Secure Aggregation in DP Federated Learning — ArXiv 2024

## C12 نظارت، ثبت وقایع و شناسایی ناهنجاری

### هدف کنترل

این بخش نیازمندی‌هایی را برای ارائه دیدگاه بلادرنگ و جرم‌شناسی نسبت به آنچه مدل و سایر اجزای هوش مصنوعی مشاهده، انجام و بازمی‌گردانند، فراهم می‌کند تا تهدیدها شناسایی، اولویت‌بندی و از آنها درس گرفته شود.

### C12.1 ثبت درخواست و پاسخ

 #12.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام درخواست‌های کاربر و پاسخ‌های مدل با فراداده‌های مناسب (مانند زمان‌سنجی، شناسه کاربر، شناسه جلسه، نسخه مدل) ثبت شده باشند.
 #12.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که لاگ‌ها در مخازن امن و کنترل‌شده بر اساس دسترسی با سیاست‌های نگهداری مناسب و رویه‌های پشتیبان‌گیری ذخیره می‌شوند.
 #12.1.3    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم‌های ذخیره‌سازی لاگ، رمزگذاری در حالت استراحت و در انتقال را برای حفاظت از اطلاعات حساس موجود در لاگ‌ها اجرا می‌کنند.
 #12.1.4    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که داده‌های حساس در درخواست‌ها و خروجی‌ها به‌طور خودکار قبل از ثبت لاگ، حذف یا مخفی می‌شوند، با قوانین قابل تنظیم برای حذف اطلاعات شناسایی شخصی (PII)، اطلاعات ورود و اطلاعات اختصاصی.
 #12.1.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تصمیمات سیاستی و اقدامات فیلترینگ ایمنی با جزئیات کافی ثبت می‌شوند تا امکان حسابرسی و اشکال‌زدایی سیستم‌های مدیریت محتوا فراهم شود.
 #12.1.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که صحت لاگ از طریق امضاهای رمزنگاری شده یا ذخیره‌سازی فقط-نوشتنی محافظت می‌شود.

---

### C12.2 شناسایی سوء استفاده و هشدار دهی

 #12.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم الگوهای شناخته شده فرار از محدودیت، تلاش‌های تزریق درخواست و ورودی‌های خصمانه را با استفاده از شناسایی مبتنی بر امضاء شناسایی و هشدار می‌دهد.
 #12.2.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم با استفاده از فرمت‌ها و پروتکل‌های استاندارد لاگ، با پلتفرم‌های موجود مدیریت اطلاعات و رویدادهای امنیتی (SIEM) یکپارچه می‌شود.
 #12.2.3    سطح: 2    نقش: D/V
 تأیید کنید که رویدادهای امنیتی غنی شده شامل زمینه‌های خاص هوش مصنوعی مانند شناسه‌های مدل، امتیازهای اطمینان و تصمیمات فیلتر ایمنی باشند.
 #12.2.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تشخیص ناهنجاری رفتاری الگوهای غیرمعمول گفتگو، تلاش‌های مکرر بیش از حد، یا رفتارهای سیستماتیک بررسی را شناسایی می‌کند.
 #12.2.5    سطح: 2    نقش: D/V
 تأیید کنید که مکانیزم‌های هشداردهی در زمان واقعی، تیم‌های امنیتی را هنگام شناسایی تخلفات احتمالی سیاست یا تلاش‌های حمله مطلع می‌کنند.
 #12.2.6    سطح: 2    نقش: D/V
 تأیید کنید که قوانین سفارشی برای شناسایی الگوهای تهدید خاص هوش مصنوعی شامل تلاش‌های هماهنگ شده برای دورزدن محدودیت‌ها (jailbreak)، کمپین‌های تزریق فرمان (prompt injection) و حملات استخراج مدل گنجانده شده‌اند.
 #12.2.7    سطح: 3    نقش: D/V
 تأیید کنید که جریان‌های کاری پاسخ خودکار به حادثه می‌توانند مدل‌های به‌خطر افتاده را ایزوله کنند، کاربران مخرب را مسدود کنند و رویدادهای امنیتی بحرانی را ارتقاء دهند.

---

### C12.3 تشخیص انحراف مدل

 #12.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیستم معیارهای عملکرد پایه مانند دقت، امتیازهای اطمینان، تأخیر و نرخ خطا را در نسخه‌های مدل و بازه‌های زمانی مختلف رصد می‌کند.
 #12.3.2    سطح: 2    نقش: D/V
 تأیید کنید که هشدار خودکار زمانی فعال می‌شود که شاخص‌های عملکرد از آستانه‌های تخریب از پیش تعریف شده فراتر روند یا به طور قابل توجهی از مبناها منحرف شوند.
 #12.3.3    سطح: 2    نقش: D/V
 تأیید کنید که مانیتورهای تشخیص هالوسیناسیون مواردی را که خروجی‌های مدل شامل اطلاعات نادرست، ناسازگار یا ساختگی است، شناسایی و علامت‌گذاری می‌کنند.

---

### C12.4 عملکرد و تله‌متری رفتار

 #12.4.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که معیارهای عملیاتی شامل تأخیر درخواست، مصرف توکن، استفاده از حافظه و توان عملیاتی به صورت مداوم جمع‌آوری و نظارت می‌شوند.
 #12.4.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که نرخ‌های موفقیت و شکست همراه با دسته‌بندی انواع خطاها و علل اصلی آن‌ها پیگیری می‌شوند.
 #12.4.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مانیتورینگ استفاده از منابع شامل استفاده از GPU/CPU، مصرف حافظه و نیازهای ذخیره‌سازی باشد و در صورت عبور از آستانه‌های تعیین شده هشدار دهد.

---

### C12.5 برنامه ریزی و اجرای واکنش به حادثه هوش مصنوعی

 #12.5.1    سطح: 1    نقش: D/V
 بررسی کنید که برنامه‌های پاسخ به حادثه به‌طور خاص به رویدادهای امنیتی مرتبط با هوش مصنوعی از جمله به خطر افتادن مدل، مسموم‌سازی داده‌ها و حملات دشمنی پرداخته باشند.
 #12.5.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تیم‌های پاسخ به حوادث دسترسی به ابزارهای تخصصی جرم‌شناسی مرتبط با هوش مصنوعی و تخصص لازم برای بررسی رفتار مدل و بردارهای حمله را دارند.
 #12.5.3    سطح: 3    نقش: D/V
 تأیید کنید که تحلیل پس از حادثه شامل ملاحظاتی برای بازآموزی مدل، به‌روزرسانی فیلترهای ایمنی، و ادغام درس‌های آموخته شده در کنترل‌های امنیتی باشد.

---

### C12.5 تشخیص افت عملکرد هوش مصنوعی

نظارت و شناسایی کاهش عملکرد و کیفیت مدل هوش مصنوعی در طول زمان.

 #12.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که دقت مدل، دقت مثبت، بازیابی و نمرات F1 به طور مداوم پایش شده و با آستانه‌های پایه مقایسه می‌شوند.
 #12.5.2    سطح: 1    نقش: D/V
 تأیید کنید که تشخیص تغییر داده‌ها، تغییرات توزیع ورودی را که ممکن است بر عملکرد مدل تأثیر بگذارد، پایش کند.
 #12.5.3    سطح: 2    نقش: D/V
 تأیید کنید که تشخیص تغییر مفهوم، تغییرات در رابطه بین ورودی‌ها و خروجی‌های مورد انتظار را شناسایی می‌کند.
 #12.5.4    سطح: 2    نقش: D/V
 تأیید کنید که کاهش عملکرد، هشدارهای خودکار را فعال می‌کند و فرایندهای بازآموزی یا جایگزینی مدل را شروع می‌کند.
 #12.5.5    سطح: 3    نقش: V
 اطمینان حاصل کنید که تحلیل علت اصلی کاهش کیفیت، افت عملکرد را با تغییرات داده‌ها، مشکلات زیرساختی یا عوامل خارجی هم‌بستگی می‌دهد.

---

### C12.6 تجسم DAG و امنیت گردش‌کار

سیستم‌های تصویری گردش کار را در برابر نشت اطلاعات و حملات دستکاری محافظت کنید.

 #12.6.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که داده‌های تصویری DAG برای حذف اطلاعات حساس قبل از ذخیره‌سازی یا انتقال پاک‌سازی شده‌اند.
 #12.6.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که کنترل‌های دسترسی به تجسم گردش کار فقط به کاربران مجاز اجازه می‌دهد مسیرهای تصمیم‌گیری عامل و ردگیری‌های استدلال را مشاهده کنند.
 #12.6.3    سطح: 2    نقش: D/V
 تأیید کنید که یکپارچگی داده‌های DAG از طریق امضاهای رمزنگاری شده و مکانیزم‌های ذخیره‌سازی ضد دستکاری محافظت می‌شود.
 #12.6.4    سطح: 2    نقش: D/V
 تأیید کنید که سیستم‌های تصویری‌سازی جریان‌های کاری اعتبارسنجی ورودی را پیاده‌سازی می‌کنند تا از حملات تزریق از طریق داده‌های ساختگی گره یا یال جلوگیری شود.
 #12.6.5    سطح: 3    نقش: D/V
 بررسی کنید که به‌روزرسانی‌های DAG در زمان واقعی محدود به نرخ شده و اعتبارسنجی می‌شوند تا از حملات انکار سرویس بر سیستم‌های تجسم جلوگیری شود.

---

### C12.7 نظارت بر رفتار پیشگیرانه امنیت

شناسایی و پیشگیری از تهدیدات امنیتی از طریق تحلیل رفتار پیشگیرانه عامل.

 #12.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که رفتارهای پیش‌دستانه عامل قبل از اجرا با ادغام ارزیابی ریسک از نظر امنیتی تایید شده‌اند.
 #12.7.2    سطح: 2    نقش: D/V
 تأیید کنید که محرک‌های ابتکار خودمختار شامل ارزیابی زمینه امنیتی و ارزیابی چشم‌انداز تهدید هستند.
 #12.7.3    سطح: 2    نقش: D/V
 تأیید کنید که الگوهای رفتار پیشگیرانه برای پیامدهای احتمالی امنیتی و عواقب ناخواسته تحلیل می‌شوند.
 #12.7.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که اقدامات پیشگیرانه حیاتی برای امنیت نیاز به زنجیره‌های تایید صریح همراه با سوابق حسابرسی دارند.
 #12.7.5    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که شناسایی ناهنجاری رفتاری انحرافات در الگوهای عامل پیشگیرانه را که ممکن است نشان‌دهنده نفوذ باشند، تشخیص می‌دهد.

---

### مراجع

NIST AI Risk Management Framework 1.0 - Manage 4.1 and 4.3
ISO/IEC 42001:2023 — AI Management Systems Requirements - Annex B 6.2.6
EU AI Act — Article 12, 13, 16 and 19 on Logging and Record-keeping

## C13 نظارت انسانی، پاسخگویی و حاکمیت

### هدف کنترل

این فصل الزامات حفظ نظارت انسانی و زنجیره‌های مسئولیت شفاف در سیستم‌های هوش مصنوعی را فراهم می‌کند، و اطمینان از قابلیت توضیح، شفافیت و مدیریت اخلاقی در سراسر چرخه عمر هوش مصنوعی را تضمین می‌کند.

---

### C13.1 مکانیزم‌های قطع‌کننده اضطراری و جایگزین

ارائه مسیرهای خاموش کردن یا بازگشت زمانی که رفتار ناایمن سیستم هوش مصنوعی مشاهده می‌شود.

 #13.1.1    سطح: 1    نقش: D/V
 تأیید کنید که مکانیزم دستی قطع‌کننده (kill-switch) برای توقف فوری استنتاج و خروجی‌های مدل هوش مصنوعی وجود دارد.
 #13.1.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که کنترل‌های جایگزین فقط برای افراد مجاز قابل دسترسی هستند.
 #13.1.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که رویه‌های بازگردانی قادر به بازگشت به نسخه‌های قبلی مدل یا عملیات حالت امن هستند.
 #13.1.4    سطح: 3    نقش: V
 اطمینان حاصل کنید که مکانیسم‌های بازنویسی به طور منظم آزمایش می‌شوند.

---

### C13.2 نقاط بازبینی تصمیم‌گیری با دخالت انسان

در صورت عبور سطح ریسک از آستانه‌های تعریف‌شده، نیاز به تأییدهای انسانی است.

 #13.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تصمیمات هوش مصنوعی با ریسک بالا قبل از اجرا نیاز به تأیید صریح انسانی دارند.
 #13.2.2    سطح: 1    نقش: D
 اطمینان حاصل کنید که آستانه‌های ریسک به‌وضوح تعریف شده‌اند و به‌طور خودکار فرایندهای بازبینی انسانی را فعال می‌کنند.
 #13.2.3    سطح: 2    نقش: D
 بررسی کنید که تصمیمات حساس به زمان دارای روش‌های جایگزین باشند زمانی که تأیید انسانی در بازه‌های زمانی مورد نیاز قابل دریافت نباشد.
 #13.2.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که رویه‌های ارتقا سطوح، سطوح صلاحیت واضحی برای انواع مختلف تصمیم‌گیری‌ها یا دسته‌بندی‌های ریسک تعریف می‌کنند، در صورت لزوم.

---

### C13.3 زنجیره مسئولیت و قابلیت حسابرسی

اقدامات اپراتور و تصمیمات مدل را ثبت کنید.

 #13.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تمام تصمیمات سیستم هوش مصنوعی و مداخلات انسانی با مهرهای زمانی، هویت کاربران و دلایل تصمیم ثبت می‌شوند.
 #13.3.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که لاگ‌های حسابرسی قابل دستکاری نباشند و مکانیزم‌های تایید صحت را شامل شوند.

---

### C13.4 تکنیک‌های هوش مصنوعی تبیینی (Explainable-AI)

اهمیت ویژگی سطحی، نمونه‌های ضدواقعیت و توضیحات محلی.

 #13.4.1    سطح: 1    نقش: D/V
 تأیید کنید که سیستم‌های هوش مصنوعی توضیحات پایه‌ای درباره تصمیمات خود به صورت قابل فهم برای انسان ارائه می‌دهند.
 #13.4.2    سطح: 2    نقش: V
 اطمینان حاصل کنید که کیفیت توضیح از طریق مطالعات و معیارهای ارزیابی انسانی مورد اعتبارسنجی قرار گرفته است.
 #13.4.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که نمرات اهمیت ویژگی یا روش‌های تخصیص (مانند SHAP، LIME و غیره) برای تصمیمات بحرانی در دسترس باشند.
 #13.4.4    سطح: 3    نقش: V
 تأیید کنید که توضیحات متضاد نشان می‌دهند چگونه ورودی‌ها می‌توانند برای تغییر نتایج تغییر داده شوند، اگر برای مورد استفاده و حوزه مربوطه قابل اعمال باشد.

---

### کارت‌های مدل C13.5 و افشای استفاده

نگهداری کارت‌های مدل برای استفاده مورد نظر، معیارهای عملکرد و ملاحظات اخلاقی.

 #13.5.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که کارت‌های مدل موارد استفاده مدنظر، محدودیت‌ها، و حالت‌های شکست شناخته‌شده را مستند کرده‌اند.
 #13.5.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که معیارهای عملکرد در موارد استفاده مختلف قابل اعمال افشا شده‌اند.
 #13.5.3    سطح: 2    نقش: D
 اطمینان حاصل کنید که ملاحظات اخلاقی، ارزیابی‌های تعصب، ارزیابی‌های انصاف، ویژگی‌های داده‌های آموزشی و محدودیت‌های شناخته‌شده داده‌های آموزشی مستندسازی شده و به‌طور منظم به‌روزرسانی می‌شوند.
 #13.5.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که کارت‌های مدل تحت کنترل نسخه بوده و در طول چرخه عمر مدل با ردیابی تغییرات نگهداری می‌شوند.

---

### C13.6 کمی‌سازی عدم قطعیت

انتشار نمرات اطمینان یا معیارهای آنتروپی در پاسخ‌ها.

 #13.6.1    سطح: 1    نقش: D
 اطمینان حاصل کنید که سیستم‌های هوش مصنوعی با خروجی‌های خود، امتیازهای اطمینان یا معیارهای عدم قطعیت را ارائه می‌دهند.
 #13.6.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که آستانه‌های عدم قطعیت موجب بررسی بیشتر توسط انسان یا مسیرهای تصمیم‌گیری جایگزین می‌شوند.
 #13.6.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که روش‌های کمیت‌سنجی عدم قطعیت کالیبره شده و در برابر داده‌های حقیقت زمینه‌ای اعتبارسنجی شده‌اند.
 #13.6.4    سطح: 3    نقش: D/V
 تضمین کنید که انتشار عدم قطعیت در جریان‌های کاری چند مرحله‌ای هوش مصنوعی حفظ می‌شود.

---

### C13.7 گزارش‌های شفافیت برای کاربران

افشای دوره‌ای در مورد حوادث، انحراف و استفاده از داده‌ها ارائه دهید.

 #13.7.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیاست‌های استفاده از داده‌ها و روش‌های مدیریت رضایت کاربران به وضوح به ذینفعان اطلاع داده شده باشد.
 #13.7.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که ارزیابی‌های تأثیر هوش مصنوعی انجام شده و نتایج آن در گزارش‌دهی گنجانده شده‌اند.
 #13.7.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که گزارش‌های شفافیت منتشر شده به طور منظم، حوادث هوش مصنوعی و معیارهای عملیاتی را با جزئیات منطقی افشا می‌کنند.

#### مراجع

EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
ISO/IEC 42001:2023 — AI Management Systems Requirements
NIST AI Risk Management Framework 1.0
NIST SP 800-53 Revision 5 — Security and Privacy Controls
A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)
Model Cards for Model Reporting (Mitchell et al., 2018)
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)
ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods
IEEE 7001-2021 — Transparency of Autonomous Systems
GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)
Human Oversight under Article 14 of the EU AI Act (Fink, 2025)

## ضمیمه A: فرهنگ واژگان

این فرهنگ جامع تعاریف اصطلاحات کلیدی هوش مصنوعی، یادگیری ماشین و امنیت را که در سراسر AISVS استفاده شده‌اند، به منظور اطمینان از وضوح و درک مشترک ارائه می‌دهد.

مثال خصمانه: ورودیی که به طور عمدی طراحی شده است تا مدل هوش مصنوعی را به اشتباه اندازد، اغلب با افزودن تغییرات ظریف که برای انسان‌ها قابل درک نیستند.
​
استحکام مقابله‌ای – استحکام مقابله‌ای در هوش مصنوعی به توانایی یک مدل برای حفظ عملکرد خود و مقاومت در برابر فریب خوردن یا دستکاری توسط ورودی‌های عمدی و مخرب طراحی شده برای ایجاد خطا اشاره دارد.
​
عامل – عامل‌های هوش مصنوعی سیستم‌های نرم‌افزاری هستند که از هوش مصنوعی برای دنبال کردن اهداف و انجام وظایف به نمایندگی از کاربران استفاده می‌کنند. آن‌ها توانایی استدلال، برنامه‌ریزی و حافظه را نشان می‌دهند و دارای سطحی از خودمختاری برای اتخاذ تصمیم، یادگیری و سازگاری هستند.
​
هوش مصنوعی عاملیت‌دار: سیستم‌های هوش مصنوعی که می‌توانند با درجه‌ای از خودمختاری عمل کنند تا اهدافی را محقق سازند، که اغلب تصمیم‌گیری و اقدام بدون دخالت مستقیم انسان را شامل می‌شوند.
​
کنترل دسترسی مبتنی بر ویژگی (ABAC): یک الگوی کنترل دسترسی که تصمیمات مجوزدهی بر اساس ویژگی‌های کاربر، منابع، عمل و محیط، که در زمان پرس‌وجو ارزیابی می‌شوند، اتخاذ می‌شود.
​
حمله درب‌پشتی: نوعی حمله مسموم‌سازی داده که در آن مدل طوری آموزش داده می‌شود که به طور خاص به محرک‌های مشخصی پاسخ دهد در حالی که در سایر موارد رفتار عادی دارد.
​
سوگیری: خطاهای سیستماتیکی در خروجی‌های مدل هوش مصنوعی که می‌تواند منجر به نتایج ناعادلانه یا تبعیض‌آمیز برای گروه‌های خاص یا در زمینه‌های مشخص شود.
​
استثمار تعصب: یک تکنیک حمله که از تعصبات شناخته شده در مدل‌های هوش مصنوعی برای دستکاری خروجی‌ها یا نتایج استفاده می‌کند.
​
Cedar: زبان سیاست آمازون و موتور آن برای مجوزهای دقیق که در پیاده‌سازی ABAC برای سیستم‌های هوش مصنوعی استفاده می‌شود.
​
زنجیره تفکر: تکنیکی برای بهبود استدلال در مدل‌های زبانی با تولید گام‌های میانی استدلال قبل از ارائه پاسخ نهایی.
​
قطع‌کننده‌های مدار: مکانیزم‌هایی که به‌طور خودکار عملیات سیستم هوش مصنوعی را زمانی که آستانه‌های خطر مشخصی فراتر رود، متوقف می‌کنند.
​
نشت داده: افشای ناخواسته اطلاعات حساس از طریق خروجی‌ها یا رفتار مدل هوش مصنوعی.
​
سرریز داده: فساد عمدی داده‌های آموزشی به منظور به خطر انداختن یکپارچگی مدل، که اغلب برای نصب درهای پشتی یا کاهش کارایی انجام می‌شود.
​
حریم خصوصی تفاضلی – حریم خصوصی تفاضلی چارچوبی ریاضیاتی دقیق برای ارائه اطلاعات آماری درباره داده‌ها است در حالی که حریم خصوصی افراد داده‌شده را محافظت می‌کند. این امکان را به دارنده داده می‌دهد تا الگوهای تجمیعی گروه را به اشتراک بگذارد و در عین حال اطلاعات منتشر شده درباره افراد خاص را محدود کند.
​
تعبیه‌ها: نمایش‌های برداری متراکم از داده‌ها (متن، تصاویر و غیره) که معنای مفهومی را در یک فضای با ابعاد بالا در بر می‌گیرند.
​
قابلیت توضیح‌پذیری – قابلیت توضیح‌پذیری در هوش مصنوعی به معنای توانایی یک سیستم هوش مصنوعی در ارائه دلایل قابل فهم برای انسان‌ها درباره تصمیمات و پیش‌بینی‌های خود است، که بینش‌هایی در مورد عملکرد داخلی آن ارائه می‌دهد.
​
هوش مصنوعی قابل توضیح (XAI): سیستم‌های هوش مصنوعی طراحی شده برای ارائه توضیحات قابل فهم برای انسان درباره تصمیمات و رفتارهای خود از طریق تکنیک‌ها و چارچوب‌های مختلف.
​
یادگیری مشارکتی: رویکردی در یادگیری ماشین که در آن مدل‌ها بر روی چندین دستگاه غیرمتمرکز که نمونه‌های داده محلی را نگه می‌دارند، آموزش داده می‌شوند، بدون اینکه داده‌ها به خودی خود تبادل شوند.
​
گاردریل‌ها: محدودیت‌هایی که برای جلوگیری از تولید خروجی‌های مضر، دارای تعصب یا به هر شکل نامطلوب توسط سیستم‌های هوش مصنوعی اعمال می‌شوند.
​
هذیان – هذیان هوش مصنوعی به پدیده‌ای اشاره دارد که در آن یک مدل هوش مصنوعی اطلاعات نادرست یا گمراه‌کننده‌ای تولید می‌کند که بر اساس داده‌های آموزشی یا واقعیت‌های عینی نیست.
​
انسان در حلقه (HITL): سیستم‌هایی که طراحی شده‌اند تا نظارت، تایید، یا مداخله انسانی در نقاط تصمیم‌گیری حیاتی را نیاز داشته باشند.
​
زیرساخت به‌عنوان کد (IaC): مدیریت و ارائه زیرساخت از طریق کد به جای فرآیندهای دستی، که امکان اسکن امنیتی و استقرارهای یکنواخت را فراهم می‌کند.
​
Jailbreak: تکنیک‌هایی که برای دور زدن حفاظ‌های ایمنی در سیستم‌های هوش مصنوعی، به‌ویژه در مدل‌های زبان بزرگ، برای تولید محتوای ممنوعه استفاده می‌شوند.
​
کمترین سطح دسترسی: اصل امنیتی که تنها حداقل حقوق دسترسی لازم را برای کاربران و فرآیندها اعطا می‌کند.
​
LIME (توضیحات قابل تفسیر محلی مستقل از مدل): روشی برای توضیح پیش‌بینی‌های هر دسته‌بندی‌کننده یادگیری ماشین از طریق تقریب محلی آن با یک مدل قابل تفسیر.
​
حمله استنتاج عضویت: حمله‌ای که هدف آن تعیین این است که آیا یک نقطه داده خاص برای آموزش یک مدل یادگیری ماشین استفاده شده است یا خیر.
​
MITRE ATLAS: چشم‌انداز تهدیدات مهاجمان برای سیستم‌های هوش مصنوعی؛ یک پایگاه دانش از تاکتیک‌ها و تکنیک‌های مهاجمان علیه سیستم‌های هوش مصنوعی.
​
کارت مدل – کارت مدل یک سند است که اطلاعات استاندارد شده‌ای در مورد عملکرد، محدودیت‌ها، کاربردهای مورد نظر و ملاحظات اخلاقی یک مدل هوش مصنوعی ارائه می‌دهد تا شفافیت و توسعه مسئولانه هوش مصنوعی را ترویج کند.
​
استخراج مدل: حمله‌ای که در آن یک مهاجم به طور مکرر مدل هدف را پرس‌وجو می‌کند تا نسخه‌ای با عملکرد مشابه بدون مجوز ایجاد کند.
​
وارون‌سازی مدل: حمله‌ای که با تحلیل خروجی‌های مدل سعی در بازسازی داده‌های آموزشی دارد.
​
مدیریت چرخه عمر مدل – مدیریت چرخه عمر مدل هوش مصنوعی فرآیند نظارت بر تمام مراحل وجود یک مدل هوش مصنوعی است، از جمله طراحی، توسعه، استقرار، پایش، نگهداری و نهایتاً بازنشستگی آن، به منظور اطمینان از اینکه مدل موثر باقی می‌ماند و با اهداف همسو است.
​
آلوده‌سازی مدل: وارد کردن آسیب‌پذیری‌ها یا درهای پشتی به‌طور مستقیم در مدل در فرآیند آموزش.
​
دزدیدن/سرقت مدل: استخراج نسخه یا تقریب یک مدل اختصاصی از طریق پرسش‌های تکراری.
​
سیستم چندعاملی: سیستمی متشکل از چند عامل هوش مصنوعی که هر یک ممکن است دارای قابلیت‌ها و اهداف متفاوتی باشند.
​
OPA (عامل سیاست‌باز): یک موتور سیاست متن‌باز است که امکان اجرای یکپارچه سیاست‌ها را در سراسر پشته فراهم می‌کند.
​
یادگیری ماشین حفظ حریم خصوصی (PPML): تکنیک‌ها و روش‌هایی برای آموزش و پیاده‌سازی مدل‌های یادگیری ماشین در حالی که حریم خصوصی داده‌های آموزشی حفظ می‌شود.
​
تزریق فرمان: حمله‌ای که در آن دستورهای مخرب در ورودی‌ها جاسازی می‌شوند تا رفتار مورد نظر مدل را بازنویسی کنند.
​
RAG (تولید افزوده‌شده با بازیابی): تکنیکی که مدل‌های زبان بزرگ را با بازیابی اطلاعات مرتبط از منابع دانش خارجی قبل از تولید پاسخ، بهبود می‌بخشد.
​
تیم قرمز: عملی است که در آن سیستم‌های هوش مصنوعی به طور فعال با شبیه‌سازی حملات دشمنانه آزمایش می‌شوند تا آسیب‌پذیری‌ها شناسایی شوند.
​
SBOM (فهرست مواد نرم‌افزاری): یک رکورد رسمی حاوی جزئیات و روابط زنجیره تأمین اجزای مختلف مورد استفاده در ساخت نرم‌افزار یا مدل‌های هوش مصنوعی است.
​
SHAP (توضیحات جمعی شاپلی): یک رویکرد نظریه بازی‌ها برای توضیح خروجی هر مدل یادگیری ماشین با محاسبه سهم هر ویژگی در پیش‌بینی.
​
حمله زنجیره تامین: به خطر انداختن یک سیستم با هدف قرار دادن عناصر کم‌امنیت‌تر در زنجیره تامین آن، مانند کتابخانه‌های شخص ثالث، مجموعه‌های داده یا مدل‌های پیش‌آموزش‌دیده.
​
یادگیری انتقالی: تکنیکی که در آن مدل توسعه یافته برای یک کار به عنوان نقطه شروع برای مدلی در کار دوم استفاده مجدد می‌شود.
​
پایگاه داده برداری: یک پایگاه داده تخصصی طراحی شده برای ذخیره بردارهای با ابعاد بالا (تعبیه‌ها) و انجام جستجوهای کارآمد بر اساس شباهت.
​
اسکن آسیب‌پذیری: ابزارهای خودکاری که آسیب‌پذیری‌های امنیتی شناخته‌شده در اجزای نرم‌افزاری، از جمله چارچوب‌ها و وابستگی‌های هوش مصنوعی را شناسایی می‌کنند.
​
واترمارکینگ: تکنیک‌هایی برای جاسازی نشانگرهای غیرقابل تشخیص در محتوای تولید شده توسط هوش مصنوعی به منظور ردیابی منبع آن یا تشخیص تولید توسط هوش مصنوعی.
​
آسیب‌پذیری صفر روزه: یک آسیب‌پذیری ناشناخته قبلی است که مهاجمان می‌توانند قبل از اینکه توسعه‌دهندگان وصله‌ای ایجاد و منتشر کنند، از آن سوءاستفاده کنند.

## پیوست ب: منابع

### TODO

## پیوست ج: حاکمیت و مستندسازی امنیت هوش مصنوعی

### هدف

این پیوست الزامات پایه‌ای برای ایجاد ساختارهای سازمانی، سیاست‌ها و فرآیندها جهت حاکمیت امنیت هوش مصنوعی در سراسر چرخه عمر سیستم را فراهم می‌کند.

---

### تصمیم‌گیری درباره پذیرش چارچوب مدیریت ریسک هوش مصنوعی AC.1

یک چارچوب رسمی برای شناسایی، ارزیابی و کاهش ریسک‌های خاص هوش مصنوعی در طول چرخه عمر سیستم ارائه دهید.

 #AC.1.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که یک روش ارزیابی ریسک خاص هوش مصنوعی مستند و اجرا شده است.
 #AC.1.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که ارزیابی‌های ریسک در نقاط کلیدی چرخه عمر هوش مصنوعی و پیش از تغییرات قابل توجه انجام می‌شوند.
 #AC.1.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که چارچوب مدیریت ریسک با استانداردهای معتبر (به‌عنوان مثال، چارچوب مدیریت ریسک هوش مصنوعی NIST) هم‌راستا باشد.

---

### AC.2 سیاست‌ها و رویه‌های امنیت هوش مصنوعی

تعریف و اجرای استانداردهای سازمانی برای توسعه، استقرار و کارکرد امن هوش مصنوعی.

 #AC.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که سیاست‌های امنیتی مستند شده در زمینه هوش مصنوعی وجود دارد.
 #AC.2.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که سیاست‌ها حداقل سالی یک بار و پس از تغییرات قابل توجه در چشم‌انداز تهدیدات بازبینی و به‌روزرسانی می‌شوند.
 #AC.2.3    سطح: 3    نقش: D/V
 تأیید کنید که سیاست‌ها تمام دسته‌های AISVS و الزامات قانونی قابل اجرا را پوشش می‌دهند.

---

### AC.3 نقش‌ها و مسئولیت‌ها برای امنیت هوش مصنوعی

مسئولیت‌پذیری واضح برای امنیت هوش مصنوعی در سراسر سازمان برقرار کنید.

 #AC.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که نقش‌ها و مسئولیت‌های امنیتی هوش مصنوعی مستند شده‌اند.
 #AC.3.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که افراد مسئول دارای تخصص مناسب در زمینه امنیت باشند.
 #AC.3.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که کمیته اخلاق هوش مصنوعی یا هیئت حاکمیتی برای سیستم‌های هوش مصنوعی پرخطر برقرار شده است.

---

### اجرای دستورالعمل‌های اخلاقی هوش مصنوعی AC.4

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی مطابق با اصول اخلاقی تعیین شده عمل می‌کنند.

 #AC.4.1    سطح: 1    نقش: D/V
 تأیید کنید که دستورالعمل‌های اخلاقی برای توسعه و استقرار هوش مصنوعی وجود دارد.
 #AC.4.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که مکانیزم‌هایی برای شناسایی و گزارش تخلفات اخلاقی وجود دارد.
 #AC.4.3    سطح: 3    نقش: D/V
 تأیید کنید که بازبینی‌های اخلاقی منظم سیستم‌های هوش مصنوعی مستقر شده انجام می‌شود.

---

### AC.5 نظارت بر تطابق با مقررات هوش مصنوعی

آگاهی از مقررات در حال تکامل هوش مصنوعی و رعایت آنها را حفظ کنید.

 #AC.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که فرایندهایی برای شناسایی مقررات کاربردی هوش مصنوعی وجود دارد.
 #AC.5.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که رعایت تمامی الزامات مقرراتی ارزیابی شده است.
 #AC.5.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تغییرات قانونی در زمان مناسب باعث بررسی‌ها و به‌روزرسانی‌های سیستم‌های هوش مصنوعی می‌شوند.

### AC.6 حاکمیت داده‌های آموزشی، مستندسازی و فرایند

 #1.1.2    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که تنها مجموعه داده‌هایی که از نظر کیفیت، نمایندگی، تأمین اخلاقی و رعایت مجوز بررسی شده‌اند، اجازه استفاده دارند، که این کار خطرات مسمومیت داده‌ها، تعصب نهفته و نقض مالکیت فکری را کاهش می‌دهد.
 #1.1.5    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که کیفیت برچسب‌گذاری/حاشیه‌نویسی از طریق بازبینی متقابل یا توافق جمعی بررسی می‌شود.
 #1.1.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که "کارت‌های داده" یا "ورق‌های اطلاعاتی برای مجموعه‌داده‌ها" برای مجموعه‌داده‌های آموزش مهم نگهداری می‌شوند، که شامل جزئیاتی درباره ویژگی‌ها، انگیزه‌ها، ترکیب، فرآیندهای جمع‌آوری، پیش‌پردازش، و کاربردهای توصیه‌شده/غیرمجاز هستند.
 #1.3.2    سطح: 2    نقش: D/V
 تأیید کنید که سوگیری‌های شناسایی‌شده از طریق استراتژی‌های مستندسازی شده مانند توازن مجدد، افزایش داده‌های هدفمند، تنظیمات الگوریتمی (مثلاً تکنیک‌های پیش‌پردازش، درون‌پردازش، پس‌پردازش) یا وزن‌دهی مجدد کاهش یافته‌اند و تأثیر کاهش سوگیری بر هر دو معیار عدالت و عملکرد کلی مدل مورد ارزیابی قرار گرفته است.
 #1.3.3    سطح: 2    نقش: D/V
 اطمینان حاصل شود که معیارهای عدالت پس از آموزش ارزیابی و مستندسازی شده‌اند.
 #1.3.4    سطح: 3    نقش: D/V
 تأیید کنید که سیاست مدیریت تعصبات چرخه عمر، مالک‌ها و دوره بازبینی را تعیین می‌کند.
 #1.4.1    سطح: 2    نقش: D/V
 تضمین کنید که کیفیت برچسب‌گذاری/حاشیه‌نویسی از طریق دستورالعمل‌های واضح، بررسی متقابل توسط بازبین‌ها، مکانیزم‌های اجماع (برای مثال، پایش توافق بین حاشیه‌نویسان)، و فرآیندهای مشخص برای رفع اختلاف‌ها تضمین شده است.
 #1.4.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که برچسب‌هایی که برای ایمنی، امنیت یا انصاف حیاتی هستند (مانند شناسایی محتوای سمی، یافته‌های پزشکی حیاتی) تحت بازبینی دوگانه مستقل اجباری یا تأیید معادل قوی قرار بگیرند.
 #1.4.6    سطح: 2    نقش: D/V
 تأیید کنید که راهنمای برچسب‌گذاری و دستورالعمل‌ها جامع، تحت کنترل نسخه و بازبینی شده توسط همتایان باشند.
 #1.4.6    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که طرح‌های داده برای برچسب‌ها به وضوح تعریف شده و تحت کنترل نسخه هستند.
 #1.3.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مجموعه داده‌ها برای عدم تعادل نمایشی و تعصبات احتمالی در میان ویژگی‌های محافظت‌شده قانونی (مانند نژاد، جنسیت، سن) و سایر ویژگی‌های حساس اخلاقی مرتبط با حوزه کاربرد مدل (مانند وضعیت اقتصادی-اجتماعی، موقعیت جغرافیایی) تحلیل شده باشند.
 #1.5.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که بررسی‌های دستی نمونه‌ای توسط کارشناسان حوزه شامل یک نمونه آماری معنادار باشد (به‌عنوان مثال، ≥1٪ یا 1,000 نمونه، هر کدام که بیشتر باشد، یا طبق ارزیابی ریسک تعیین شده است) تا مسائل ظریف کیفیت که توسط خودکارسازی شناسایی نشده‌اند را شناسایی کند.
 #1.8.4    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که جریان‌های کاری برچسب‌گذاری برون‌سپاری شده یا جمع‌سپاری شده شامل محافظت‌های فنی/اجرایی برای تضمین محرمانگی داده‌ها، صحت داده‌ها، کیفیت برچسب‌ها و جلوگیری از نشت داده‌ها باشند.
 #1.5.4    سطح: 2    نقش: D/V
 تأیید کنید که مراحل اصلاح به سوابق منبع اضافه شده‌اند.
 #1.6.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که نمونه‌های علامت‌گذاری شده پیش از آموزش باعث بررسی دستی می‌شوند.
 #1.6.3    سطح: 2    نقش: V
 اطمینان حاصل کنید که نتایج، پرونده امنیتی مدل را تغذیه کرده و اطلاعات تهدید جاری را مطلع می‌سازند.
 #1.6.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که منطق تشخیص با اطلاعات جدید تهدید به‌روزرسانی شده است.
 #1.6.5    سطح: 3    نقش: D/V
 تأیید کنید که خطوط لوله یادگیری آنلاین تغییر توزیع را پایش می‌کنند.
 #1.7.1    سطح: 1    نقش: D/V
 تأیید کنید که جریان‌های کاری حذف داده‌های آموزشی داده‌های اولیه و مشتق شده را پاک می‌کنند و تأثیر آن بر مدل را ارزیابی کرده و در صورت لزوم این تأثیر مورد بررسی و رفع قرار می‌گیرد (مثلاً از طریق آموزش مجدد یا بازتنظیم کالیبراسیون).
 #1.7.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که مکانیزم‌هایی برای دنبال کردن و احترام به دامنه و وضعیت رضایت کاربر (و لغو آن) برای داده‌های مورد استفاده در آموزش وجود دارد و رضایت قبل از وارد کردن داده‌ها به فرآیندهای آموزش جدید یا به‌روزرسانی‌های مهم مدل تأیید می‌شود.
 #1.7.3    سطح: 2    نقش: V
 تأیید کنید که گردش‌های کاری سالانه آزمایش شده و ثبت می‌شوند.
 #1.8.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تامین‌کنندگان داده‌های ثالث، از جمله ارائه‌دهندگان مدل‌های پیش‌آموزش‌دیده و مجموعه داده‌های خارجی، قبل از ادغام داده‌ها یا مدل‌های‌شان، بررسی‌های لازم در زمینه امنیت، حریم خصوصی، منبع‌گیری اخلاقی و کیفیت داده را انجام داده باشند.
 #1.8.2    سطح: 1    نقش: D
 بررسی کنید که انتقال‌های خارجی از TLS/احراز هویت و بررسی‌های صحت داده استفاده می‌کنند.
 #1.8.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که منابع داده با ریسک بالا (مثلاً مجموعه داده‌های متن‌باز با منشأ نامشخص، تامین‌کنندگان تاییدنشده) قبل از استفاده در برنامه‌های حساس، تحت بررسی دقیق‌تر قرار گیرند، مانند تحلیل در محیط ایزوله (sandboxed)، بررسی‌های گسترده کیفیت/اروایی و تشخیص هدفمند مسمومیت داده‌ها.
 #1.8.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که مدل‌های پیش‌آموزش‌دیده‌شده که از طرف‌های ثالث به‌دست آمده‌اند، قبل از تنظیم دقیق یا استقرار، از نظر تعصبات نهفته، پشتی‌های احتمالی، صحت معماری آن‌ها و منشأ داده‌های آموزش اصلی‌شان ارزیابی شده‌اند.
 #1.5.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اگر آموزش تهاجمی (adversarial training) استفاده می‌شود، تولید، مدیریت و نسخه‌بندی داده‌های تهاجمی مستندسازی شده و کنترل می‌شوند.
 #1.5.3    سطح: 3    نقش: D/V
 تأیید کنید که تأثیر آموزش مقاومت در برابر حملات دشمنانه بر عملکرد مدل (در برابر ورودی‌های تمیز و دشمنانه) و معیارهای عدالت ارزیابی، مستندسازی و نظارت شده است.
 #1.5.4    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که استراتژی‌های آموزش خصمانه و مقاومت به طور دوره‌ای بازبینی و به‌روزرسانی می‌شوند تا در مقابل تکنیک‌های حمله خصمانه در حال تحول مقابله کنند.
 #1.4.2    سطح: 2    نقش: D/V
 تأیید کنید که مجموعه داده‌های ناموفق با مسیرهای ممیزی قرنطینه شده‌اند.
 #1.4.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که دروازه‌های کیفیت، مجموعه داده‌های زیر استاندارد را مسدود می‌کنند مگر اینکه استثناها تأیید شده باشند.
 #1.11.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فرآیند تولید، پارامترها و استفاده مورد نظر از داده‌های مصنوعی مستند شده‌اند.
 #1.11.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که داده‌های مصنوعی پیش از استفاده در آموزش از نظر ریسک‌های تعصب، نشت حریم خصوصی و مشکلات نمایشی ارزیابی شده باشند.
 #1.12.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که هشدارها برای رویدادهای دسترسی مشکوک ایجاد شده و به‌سرعت بررسی می‌شوند.
 #1.13.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که دوره‌های نگهداری صریح برای تمامی مجموعه‌داده‌های آموزشی تعریف شده‌اند.
 #1.13.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که مجموعه‌داده‌ها به‌طور خودکار در پایان دوره عمرشان منقضی، حذف یا برای حذف بازبینی می‌شوند.
 #1.13.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که اقدامات نگهداری و حذف ثبت شده و قابل حسابرسی هستند.
 #1.14.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که الزامات محل اقامت داده‌ها و انتقال فرامرزی برای همه مجموعه داده‌ها شناسایی و اجرا شده‌اند.
 #1.14.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که قوانین خاص هر بخش (مانند بهداشت و درمان، مالی) در مدیریت داده‌ها شناسایی و مورد بررسی قرار گرفته‌اند.
 #1.14.3    سطح: 2    نقش: D/V
 تأیید کنید که رعایت قوانین مربوط به حفظ حریم خصوصی (مانند GDPR، CCPA) مستندسازی شده و به‌طور منظم بازبینی می‌شود.
 #1.16.1    سطح: 2    نقش: D/V
 تأیید کنید که مکانیزم‌هایی برای پاسخگویی به درخواست‌های شخص داده برای دسترسی، اصلاح، محدودیت یا اعتراض وجود دارد.
 #1.16.2    سطح: 2    نقش: D/V
 تأیید کنید که درخواست‌ها در بازه‌های زمانی تعیین‌شده توسط قانون ثبت، پیگیری و انجام می‌شوند.
 #1.16.3    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که فرایندهای حقوق موضوع داده به طور منظم برای اثربخشی آزمایش و بازبینی می‌شوند.
 #1.17.1    سطح: 2    نقش: D/V
 تأیید کنید که یک تحلیل تأثیر پیش از به‌روزرسانی یا جایگزینی نسخه داده‌ها انجام شود، که شامل عملکرد مدل، انصاف و انطباق باشد.
 #1.17.2    سطح: 2    نقش: D/V
 تأیید کنید که نتایج تحلیل تأثیر مستندسازی شده و توسط ذینفعان مربوطه بازبینی شده است.
 #1.17.3    سطح: 2    نقش: D/V
 تأیید کنید که برنامه‌های بازگشت در صورت معرفی نسخه‌های جدید که ریسک‌ها یا افت‌های غیرقابل قبول ایجاد می‌کنند، وجود داشته باشد.
 #1.18.1    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تمام کارکنان دخیل در برچسب‌گذاری داده‌ها، پیش‌زمینه‌ی امنیتی بررسی شده و آموزش‌های لازم در زمینه امنیت داده‌ها و حفظ حریم خصوصی را دیده باشند.
 #1.18.2    سطح: 2    نقش: D/V
 اطمینان حاصل کنید که تمام کارکنان مربوط به حاشیه‌نویسی قراردادهای محرمانگی و عدم افشای اطلاعات را امضا کرده‌اند.
 #1.18.3    سطح: 2    نقش: D/V
 تأیید کنید که پلتفرم‌های نشانه‌گذاری کنترل‌های دسترسی را اعمال می‌کنند و تهدیدات داخلی را نظارت می‌کنند.

#### مراجع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
EU Artificial Intelligence Act — Regulation (EU) 2024/1689
ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods

## پیوست D: حاکمیت و تأیید کدگذاری ایمن با کمک هوش مصنوعی

### هدف

این فصل کنترل‌های سازمانی پایه را برای استفاده ایمن و مؤثر از ابزارهای کدنویسی کمکی هوش مصنوعی در طول توسعه نرم‌افزار تعریف می‌کند، به‌گونه‌ای که امنیت و قابلیت ردیابی در سراسر چرخه عمر توسعه نرم‌افزار (SDLC) تضمین شود.

---

### AD.1 جریان کاری کدنویسی امن با کمک هوش مصنوعی

ابزارهای هوش مصنوعی را در چرخه عمر توسعه نرم‌افزار امن سازمان (SSDLC) ادغام کنید بدون اینکه دفاع‌های امنیتی موجود تضعیف شوند.

 #AD.1.1    سطح: 1    نقش: D/V
 تأیید کنید که یک گردش کار مستند شده زمانی و نحوه استفاده از ابزارهای هوش مصنوعی برای تولید، بازسازی یا مرور کد را شرح می‌دهد.
 #AD.1.2    سطح: 2    نقش: D
 تأیید کنید که جریان کاری به هر مرحله از SSDLC (طراحی، پیاده‌سازی، بازبینی کد، آزمون، استقرار) نگاشت شود.
 #AD.1.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که معیارها (برای مثال، چگالی آسیب‌پذیری، میانگین زمان شناسایی) بر روی کد تولید شده توسط هوش مصنوعی جمع‌آوری شده و با معیارهای پایه‌ای فقط انسانی مقایسه می‌شوند.

---

### AD.2 صلاحیت ابزار هوش مصنوعی و مدل‌سازی تهدید

اطمینان حاصل شود که ابزارهای کدنویسی هوش مصنوعی قبل از پذیرش، از نظر قابلیت‌های امنیتی، ریسک و تاثیر زنجیره تامین ارزیابی شوند.

 #AD.2.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که مدل تهدید برای هر ابزار هوش مصنوعی، سوءاستفاده، وارونگی مدل، نشت داده و خطرات زنجیره وابستگی را شناسایی می‌کند.
 #AD.2.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که ارزیابی‌های ابزار شامل تحلیل ایستا/پویا از هر جزء محلی و ارزیابی نقاط انتهایی SaaS (TLS، تأیید هویت/مجوزدهی، ثبت لاگ) باشد.
 #AD.2.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که ارزیابی‌ها بر اساس یک چارچوب شناخته شده انجام شده‌اند و پس از تغییرات عمده نسخه مجدداً انجام می‌شوند.

---

### AD.3 مدیریت امن درخواست و زمینه

جلوگیری از نشت اسرار، کد اختصاصی و داده‌های شخصی هنگام ساختن پرامپت‌ها یا زمینه‌ها برای مدل‌های هوش مصنوعی.

 #AD.3.1    سطح: 1    نقش: D/V
 بررسی کنید که راهنمایی‌های مکتوب ارسال اسرار، مدارک احراز هویت یا داده‌های طبقه‌بندی شده در دستورات را ممنوع کرده باشد.
 #AD.3.2    سطح: 2    نقش: D
 تأیید کنید که کنترل‌های فنی (حذف اطلاعات حساس در سمت کلاینت، فیلترهای متن تایید شده) به‌صورت خودکار اشیاء حساس را حذف می‌کنند.
 #AD.3.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که درخواست‌ها و پاسخ‌ها توکنیزه شده، در حین انتقال و در حالت استراحت رمزگذاری شده‌اند و دوره‌های نگهداری با سیاست طبقه‌بندی داده‌ها مطابقت دارند.

---

### AD.4 اعتبارسنجی کد تولید شده توسط هوش مصنوعی

شناسایی و رفع آسیب‌پذیری‌های ایجاد شده توسط خروجی هوش مصنوعی قبل از ادغام یا استقرار کد.

 #AD.4.1    سطح: 1    نقش: D/V
 تأیید کنید که کد تولید شده توسط هوش مصنوعی همیشه تحت بازبینی کد انسانی قرار می‌گیرد.
 #AD.4.2    سطح: 2    نقش: D
 اطمینان حاصل کنید که اسکنرهای خودکار (SAST/IAST/DAST) روی هر درخواست Pull که شامل کد تولید شده توسط هوش مصنوعی است اجرا می‌شوند و ادغام‌ها را در صورت وجود یافته‌های حیاتی مسدود می‌کنند.
 #AD.4.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که تست‌های فراگیر تفاضلی یا تست‌های مبتنی بر ویژگی، رفتارهای حیاتی امنیتی (مانند اعتبارسنجی ورودی، منطق مجوزدهی) را اثبات می‌کنند.

---

### AD.5 قابلیت توضیح‌پذیری و ردیابی پیشنهادات کد

برای حسابرسان و توسعه‌دهندگان بینش ارائه دهید که چرا یک پیشنهاد ارائه شده است و چگونه تکامل یافته است.

 #AD.5.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که جفت‌های پرسش/پاسخ با شناسه‌های تعهد (commit IDs) ثبت می‌شوند.
 #AD.5.2    سطح: 2    نقش: D
 تأیید کنید که توسعه‌دهندگان قادر به ارائه استنادهای مدل (قطعات آموزشی، مستندات) که پیشنهاد را پشتیبانی می‌کند، باشند.
 #AD.5.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که گزارش‌های قابلیت توضیح با مصنوعات طراحی ذخیره شده و در بازبینی‌های امنیتی به آن‌ها ارجاع داده شده‌اند، به‌طوری که اصول ردیابی ISO/IEC 42001 را برآورده کنند.

---

### AD.6 بازخورد مداوم و تنظیم دقیق مدل

عملکرد امنیت مدل را در طول زمان بهبود بخشید و در عین حال از بروز روند منفی جلوگیری کنید.

 #AD.6.1    سطح: 1    نقش: D/V
 اطمینان حاصل کنید که توسعه‌دهندگان می‌توانند پیشنهادات ناامن یا غیرمطابق را علامت‌گذاری کنند و اینکه این علامت‌ها پیگیری می‌شوند.
 #AD.6.2    سطح: 2    نقش: D
 تأیید کنید که بازخورد تجمیع‌شده برای تنظیم دقیق دوره‌ای یا تولید تقویت‌شده با بازیابی با مجموعه‌های کدگذاری امن تأیید شده (به عنوان مثال، دفترچه‌های تقلب OWASP) مورد استفاده قرار می‌گیرد.
 #AD.6.3    سطح: 3    نقش: D/V
 اطمینان حاصل کنید که یک هارنس ارزیابی حلقه بسته پس از هر تنظیم دقیق، آزمایش‌های رگرسیون را اجرا می‌کند؛ معیارهای امنیتی باید قبل از استقرار برابر یا بهتر از خطوط پایه قبلی باشند.

---

#### مراجع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
OWASP Secure Coding Practices — Quick Reference Guide

## ضمیمه E: نمونه ابزارها و چارچوب‌ها

### هدف

این فصل نمونه‌هایی از ابزارها و چارچوب‌هایی را ارائه می‌دهد که می‌توانند از پیاده‌سازی یا تحقق یک نیازمندی مشخص AISVS پشتیبانی کنند. این موارد به عنوان توصیه یا تأییدیه از طرف تیم AISVS یا پروژه امنیتی OWASP GenAI تلقی نمی‌شوند.

---

### AE.1 حاکمیت داده‌های آموزشی و مدیریت تعصب

ابزارهای مورد استفاده برای تجزیه و تحلیل داده‌ها، حکمرانی، و مدیریت تعصب.

 #AE.1.1    بخش: 1.1
 ابزار مدیریت موجودی داده: ابزارهای مدیریت موجودی داده مانند...
 #AE.1.2    بخش: 1.2
 رمزنگاری در حین انتقال از TLS برای برنامه‌های مبتنی بر HTTPS استفاده کنید، با ابزارهایی مانند openSSL و پایتون`ssl`کتابخانه.

---

### AE.2 اعتبارسنجی ورودی کاربر

ابزارهایی برای مدیریت و اعتبارسنجی ورودی‌های کاربر.

 #AE.2.1    بخش: 2.1
 ابزارهای دفاع در برابر تزریق فرمان: از ابزارهای گاردریل مانند NeMo شرکت NVIDIA یا Guardrails AI استفاده کنید.

---

