## الصفحة التمهيدية

### حول المعيار

معيار التحقق من أمان الذكاء الاصطناعي (AISVS) هو كتالوج يديره المجتمع يحتوي على متطلبات الأمان التي يمكن لعلماء البيانات، مهندسي عمليات تعلم الآلة (MLOps)، مهندسي البرمجيات، المطورين، المختبرين، محترفي الأمن، بائعي الأدوات، الجهات التنظيمية، والمستهلكين استخدامها لتصميم، بناء، اختبار، والتحقق من الأنظمة والتطبيقات المعتمدة على الذكاء الاصطناعي الموثوق بها. يوفر هذا المعيار لغة مشتركة لتحديد ضوابط الأمان عبر دورة حياة الذكاء الاصطناعي — بدءًا من جمع البيانات وتطوير النماذج إلى النشر والمراقبة المستمرة — بحيث يمكن للمنظمات قياس وتحسين مرونة الخصوصية وسلامة حلول الذكاء الاصطناعي الخاصة بها.

### حقوق النشر والترخيص

الإصدار 0.1 (المسودة العامة الأولى - قيد العمل)، 2025  

![license](images/license.png)
حقوق النشر © 2025 مشروع AISVS.  

صدر بموجب الCreative Commons Attribution‑ShareAlike 4.0 International License.
لأي إعادة استخدام أو توزيع، يجب عليك توصيل شروط الترخيص لهذه العمل بوضوح للآخرين.

### قادة المشروع

جيم مانيكو
أراس "روس" ميميسيازيتشي

### المساهمون والمراجعون

https://github.com/ottosulin
https://github.com/mbhatt1
https://github.com/vineethsai
https://github.com/cciprofm
https://github.com/deepakrpandey12


---

AISVS هو معيار جديد كليًا تم إنشاؤه خصيصًا لمعالجة تحديات الأمن الفريدة لأنظمة الذكاء الاصطناعي. وبينما يستلهم هذا المعيار من أفضل ممارسات الأمن الأوسع نطاقًا، فقد تم تطوير كل متطلب في AISVS من الأساس ليعكس مشهد التهديدات في مجال الذكاء الاصطناعي ولمساعدة المؤسسات على بناء حلول ذكاء اصطناعي أكثر أمانًا ومرونة.

## المقدمة

مرحبًا بكم في معيار التحقق من أمان الذكاء الاصطناعي (AISVS) الإصدار 1.0!

### مقدمة

تأسست AISVS في عام 2025 من خلال جهد تعاوني مجتمعي، وتحدد متطلبات الأمان التي يجب مراعاتها عند تصميم وتطوير ونشر وتشغيل نماذج الذكاء الاصطناعي الحديثة، وسلاسل العمل، والخدمات المعتمدة على الذكاء الاصطناعي.

يمثل الإصدار AISVS v1.0 العمل المشترك لقادة المشروع، مجموعة العمل، والمساهمين في المجتمع الأوسع من أجل إنتاج معيار عملي وقابل للاختبار لتأمين أنظمة الذكاء الاصطناعي.

هدفنا مع هذا الإصدار هو جعل AISVS سهل الاعتماد مع البقاء مركزين بدقة على نطاقه المحدد ومعالجة مشهد المخاطر سريع التطور الفريد للذكاء الاصطناعي.

### الأهداف الرئيسية لإصدار AISVS 1.0

سيتم إنشاء الإصدار 1.0 مع عدة مبادئ توجيهية.

#### نطاق محدد جيدًا

يجب أن يتوافق كل متطلب مع اسم ومهمة AISVS:

الذكاء الاصطناعي – تعمل الضوابط على طبقة الذكاء الاصطناعي / التعلم الآلي (البيانات، النموذج، خط الأنابيب، أو الاستدلال) وهي مسؤولية ممارسي الذكاء الاصطناعي.
الأمن – المتطلبات تقلل مباشرة من المخاطر المحددة المتعلقة بالأمن أو الخصوصية أو السلامة.
التحقق – تُكتب اللغة بحيث يمكن التحقق من التوافق بشكل موضوعي.
المعيار – تتبع الأقسام بنية ومصطلحات متسقة لتشكيل مرجع مترابط.
​
---

من خلال اتباع AISVS، يمكن للمنظمات تقييم وتعزيز موقف الأمان لحلول الذكاء الاصطناعي الخاصة بها بشكل منهجي، مما يعزز ثقافة هندسة الذكاء الاصطناعي الآمنة.

## باستخدام AISVS

تعريف معيار التحقق من أمان الذكاء الاصطناعي (AISVS) لمتطلبات الأمان لتطبيقات وخدمات الذكاء الاصطناعي الحديثة، مع التركيز على الجوانب التي تقع ضمن سيطرة مطوري التطبيقات.

يهدف AISVS إلى أي شخص يطور أو يقيِّم أمان تطبيقات الذكاء الاصطناعي، بما في ذلك المطورين، المهندسين المعماريين، مهندسي الأمان، والمدققين. يقدم هذا الفصل هيكلية واستخدام AISVS، بما في ذلك مستويات التحقق الخاصة به وحالات الاستخدام المقصودة.

### مستويات التحقق من أمان الذكاء الاصطناعي

تعرف AISVS ثلاثة مستويات متصاعدة من التحقق الأمني. يضيف كل مستوى عمقًا وتعقيدًا، مما يمكن المؤسسات من تكييف وضعها الأمني وفقًا لمستوى مخاطر أنظمة الذكاء الاصطناعي الخاصة بها.

قد تبدأ المؤسسات من المستوى 1 وتتدرج تدريجياً في اعتماد مستويات أعلى مع زيادة نضج الأمان وتعاظم التعرض للتهديدات.

#### تعريف المستويات

يتم تعيين كل متطلب في AISVS الإصدار 1.0 إلى أحد المستويات التالية:

 متطلبات المستوى 1

المستوى 1 يشمل المتطلبات الأمنية الأكثر حيوية وأساسًا. تركز هذه المتطلبات على منع الهجمات الشائعة التي لا تعتمد على شروط أو ثغرات أخرى. معظم ضوابط المستوى 1 إما سهلة التنفيذ أو ضرورية بما يكفي لتبرير الجهد المبذول.

##### متطلبات المستوى الثاني

يتناول المستوى 2 الهجمات الأكثر تقدمًا أو الأقل شيوعًا، بالإضافة إلى الدفاعات متعددة الطبقات ضد التهديدات واسعة الانتشار. قد تتطلب هذه المتطلبات منطقًا أكثر تعقيدًا أو تستهدف شروطًا محددة مسبقة للهجوم.

 متطلبات المستوى 3

المستوى 3 يشمل ضوابط تكون عادة أكثر صعوبة في التنفيذ أو تعتمد على الحالة في التطبيق. غالبًا ما تمثل هذه آليات دفاع عميق أو تدابير تخفيف ضد الهجمات المتخصصة أو المستهدفة أو ذات التعقيد العالي.

#### الدور (D/V)

يتم تمييز كل متطلب من متطلبات AISVS وفقًا للجمهور الأساسي:

D – متطلبات موجهة للمطورين
V – المتطلبات الموجهة للمحقق/المدقق
D/V – ذات صلة بكل من المطورين والمحقققين

## حوكمة بيانات تدريب C1 وإدارة التحيز

### هدف التحكم

يجب أن يتم الحصول على بيانات التدريب والتعامل معها وصيانتها بطريقة تحافظ على الأصلية والأمان والجودة والإنصاف. إن القيام بذلك يفي بالواجبات القانونية ويقلل من مخاطر التحيز، والتسمم، أو خروقات الخصوصية التي تظهر أثناء التدريب والتي قد تؤثر على دورة حياة الذكاء الاصطناعي بأكملها.

---

### C1.1 مصدر بيانات التدريب

حافظ على جرد قابل للتحقق لجميع مجموعات البيانات، واقبل المصادر الموثوقة فقط، وسجل كل تغيير لضمان إمكانية المراجعة.

 #1.1.1    المستوى: 1    الدور: D/V
 تحقق من الحفاظ على جرد محدث لكل مصدر بيانات تدريب (الأصل، المسؤول/المالك، الترخيص، طريقة الجمع، قيود الاستخدام المقصودة، وتاريخ المعالجة).
 #1.1.2    المستوى: 1    الدور: D/V
 تحقق من أن عمليات تدريب البيانات تستبعد الميزات أو السمات أو الحقول غير اللازمة (مثل البيانات الوصفية غير المستخدمة، المعلومات الشخصية الحساسة، بيانات الاختبار المتسربة).
 #1.1.3    المستوى: 2    الدور: D/V
 تحقق من أن جميع التغييرات في مجموعة البيانات تخضع لعملية موافقة مسجلة.
 #1.1.4    المستوى: 3    الدور: D/V
 تحقق من أن مجموعات البيانات أو مجموعات البيانات الفرعية تحتوي على علامات مائية أو بصمات رقمية حيثما كان ذلك ممكنًا.

---

### C1.2 أمان وتكامل بيانات التدريب

قيد الوصول إلى بيانات التدريب، قُم بتشفيرها أثناء التخزين والنقل، وتحقق من سلامتها لمنع العبث أو السرقة أو تلوث البيانات.

 #1.2.1    المستوى: 1    الدور: D/V
 تحقق من أن ضوابط الوصول تحمي تخزين بيانات التدريب وخطوط المعالجة.
 #1.2.2    المستوى: 2    الدور: D/V
 تحقق من تسجيل كل وصول إلى بيانات التدريب، بما في ذلك المستخدم، الوقت، والإجراء.
 #1.2.3    المستوى: 2    الدور: D/V
 تحقق من أن مجموعات بيانات التدريب مشفرة أثناء النقل وعند التخزين، باستخدام خوارزميات التشفير القياسية في الصناعة وممارسات إدارة المفاتيح.
 #1.2.4    المستوى: 2    الدور: D/V
 تحقق من استخدام التجزئات التشفيرية أو التوقيعات الرقمية لضمان سلامة البيانات أثناء تخزين ونقل بيانات التدريب.
 #1.2.5    المستوى: 2    الدور: D/V
 تحقق من تطبيق تقنيات الكشف الآلي للحماية من التعديلات غير المصرح بها أو تلف بيانات التدريب.
 #1.2.6    المستوى: 2    الدور: D/V
 تحقق من أن بيانات التدريب القديمة يتم حذفها بأمان أو إخفاء هويتها.
 #1.2.7    المستوى: 3    الدور: D/V
 تأكد من أن جميع إصدارات مجموعات بيانات التدريب مُحددة بشكل فريد، ومخزنة بطريقة غير قابلة للتغيير، وقابلة للتدقيق لدعم التراجع والتحليل الجنائي.

---

### جودة سلامة وأمن وضع علامات بيانات التدريب C1.3

حماية التسميات ومطالبة بمراجعة فنية للبيانات الحرجة.

 #1.3.1    المستوى: 2    الدور: D/V
 تحقق من تطبيق التجزئات التشفيرية أو التواقيع الرقمية على قطع الأعمال لتأكيد سلامتها وأصالتها.
 #1.3.2    المستوى: 2    الدور: D/V
 تحقق من أن واجهات وأنظمة التعليم تُطبق ضوابط وصول قوية، وتحافظ على سجلات تدقيق مقاومة للتلاعب لجميع أنشطة التعليم، وتحمي ضد التعديلات غير المصرح بها.
 #1.3.3    المستوى: 3    الدور: D/V
 تحقق من أن المعلومات الحساسة في التسميات قد تم حذفها أو إخفاء هويتها أو تشفيرها على مستوى حقل البيانات أثناء التخزين وعند النقل.

---

### C1.4 جودة بيانات التدريب وضمان الأمان

اجمع بين التحقق الآلي، والفحوصات اليدوية العشوائية، وتوثيق المعالجات لضمان موثوقية مجموعة البيانات.

 #1.4.1    المستوى: 1    الدور: D
 تحقق من أن الاختبارات الآلية تكتشف أخطاء التنسيق والقيم الفارغة في كل عملية استيراد أو تحويل بيانات كبيرة.
 #1.4.2    المستوى: 2    الدور: D/V
 تحقق من أن خطوط تدريب وضبط نماذج اللغة الكبيرة (LLM) تطبق اكتشاف التسمم والتحقق من سلامة البيانات (مثل الطرق الإحصائية، اكتشاف القيم الشاذة، تحليل التضمين) لتحديد الهجمات المحتملة بالتسمم (مثل تغيير العلامات، إدخال محفزات الأبواب الخلفية، أوامر تبديل الأدوار، هجمات الأمثلة المؤثرة) أو تلف البيانات غير المقصود في بيانات التدريب.
 #1.4.3    المستوى: 3    الدور: D/V
 تحقق من تنفيذ الضمانات المناسبة، مثل التدريب التنافسي (باستخدام أمثلة تنافسية مولدة)، وتوسيع البيانات بإدخالات معدلة، أو تقنيات التحسين القوية، وضبطها للنماذج المعنية بناءً على تقييم المخاطر.
 #1.4.4    المستوى: 2    الدور: D/V
 تحقق من أن التسميات التي تم إنشاؤها تلقائيًا (مثل تلك التي يتم إنتاجها عبر نماذج اللغة الكبيرة LLMs أو الإشراف الضعيف) تخضع لعتبات الثقة وفحوصات الاتساق لاكتشاف التسميات الهلوسية أو المضللة أو منخفضة الثقة.
 #1.4.5    المستوى: 3    الدور: D
 تأكد من أن الاختبارات الآلية تكتشف انحرافات التسمية عند كل عملية إدخال أو تحول بيانات هام.

---

### C1.5 تتبع وخط سير البيانات

تتبع الرحلة الكاملة لكل نقطة بيانات من المصدر إلى إدخال النموذج لضمان إمكانية التدقيق والاستجابة للحوادث.

 #1.5.1    المستوى: 2    الدور: D/V
 تحقق من تسجيل أصول كل نقطة بيانات، بما في ذلك جميع التحويلات، والتعزيزات، والدمج، وأنه يمكن إعادة بنائها.
 #1.5.2    المستوى: 2    الدور: D/V
 تحقق من أن سجلات النسب غير قابلة للتغيير، ومخزنة بأمان، ويمكن الوصول إليها للمراجعات.
 #1.5.3    المستوى: 2    الدور: D/V
 تحقق من أن تتبع الأصل يشمل البيانات التركيبية التي تم إنشاؤها عبر تقنيات حماية الخصوصية أو التقنيات التوليدية، وأن جميع البيانات التركيبية معلمة بوضوح ومميزة عن البيانات الحقيقية في جميع مراحل خط الأنابيب.

---

### المراجع

NIST AI Risk Management Framework
EU AI Act – Article 10: Data & Data Governance
MITRE ATLAS: Adversary Tactics for AI
Survey of ML Bias Mitigation Techniques – MDPI
Data Provenance & Lineage Best Practices – Nightfall AI
Data Labeling Quality Standards – LabelYourData
Training Data Poisoning Guide – Lakera.ai
CISA Advisory: Securing Data for AI Systems
ISO/IEC 23053: AI Management Systems Framework
IBM: What is AI Governance?
Google AI Principles
GDPR & AI Training Data – DataProtectionReport
Supply-Chain Security for AI Data – AppSOC
OpenAI Privacy Center – Data Deletion Controls
Adversarial ML Dataset – Kaggle

## التحقق من صحة إدخال المستخدم في C2

### هدف التحكم

التحقق الصارم من صحة مدخلات المستخدم هو الخط الدفاعي الأول ضد بعض أكثر الهجمات التي تضر بأنظمة الذكاء الاصطناعي. يمكن لهجمات حقن الأوامر تجاوز تعليمات النظام، تسريب البيانات الحساسة، أو توجيه النموذج نحو سلوك غير مسموح به. ما لم تكن هناك فلاتر مخصصة وهياكل تعليمات منظمة، تظهر الأبحاث أن هجمات "الهروب متعددة اللقطات" التي تستغل نوافذ السياق الطويلة جداً ستكون فعالة. كذلك، يمكن لهجمات التشويش العدائية الدقيقة—مثل تبديل الحروف المتشابهة أو لغة leetspeak—أن تغير قرارات النموذج بهدوء.

---

### C2.1 الدفاع ضد حقن التعليمات

حقن المطالب هو أحد أعلى المخاطر التي تواجه أنظمة الذكاء الاصطناعي. تستخدم الدفاعات ضد هذه التكتيك مزيجًا من مرشحات الأنماط الثابتة، والمصنفات الديناميكية، وفرض هيكلية التعليمات.

 #2.1.1    المستوى: 1    الدور: D/V
 التحقق من أن مدخلات المستخدم يتم فحصها مقابل مكتبة محدثة باستمرار لأنماط حقن الأوامر المعروفة (كلمات رئيسية لتجاوز القيود، "تجاهل السابق"، سلاسل التمثيل الدورى، الهجمات غير المباشرة عبر HTML/URL).
 #2.1.2    المستوى: 1    الدور: D/V
 تحقق من أن النظام يفرض تسلسلًا هرميًا للتعليمات حيث تتجاوز رسائل النظام أو المطور تعليمات المستخدم، حتى بعد توسيع نافذة السياق.
 #2.1.3    المستوى: 2    الدور: D/V
 تحقق من أن اختبارات التقييم العدائي (مثل مطالبات فريق الاختبار "عديدة المحاولات") تُجرى قبل كل إصدار للنموذج أو قالب المطالبة، مع تحديد حدود لمعدلات النجاح واستخدام حواجز تلقائية لمنع التراجع.
 #2.1.4    المستوى: 2    الدور: D
 تحقق من أن المطالبات التي تنشأ من محتوى طرف ثالث (صفحات الويب، ملفات PDF، البريد الإلكتروني) تتم معالجتها وتنقيحها في سياق تحليل معزول قبل دمجها في الطلب الرئيسي.
 #2.1.5    المستوى: 3    الدور: D/V
 تحقق من أن جميع تحديثات قواعد ترشيح التعليمات، إصدارات نماذج المصنفات، وتغييرات قوائم الحظر تتم مراقبتها بواسطة التحكم في الإصدارات وأنها قابلة للتدقيق.

---

### C2.2 مقاومة الأمثلة العدائية

نماذج معالجة اللغة الطبيعية (NLP) لا تزال عرضة للتشويشات الطفيفة على مستوى الأحرف أو الكلمات التي غالبًا ما يغفلها البشر، ولكن تميل النماذج إلى تصنيفها بشكل خاطئ.

 #2.2.1    المستوى: 1    الدور: D
 تحقق من أن خطوات تطبيع الإدخال الأساسية (Unicode NFC, تعيين الحروف المتشابهة، تقليم الفراغات) تعمل قبل عملية تقسيم النص إلى رموز.
 #2.2.2    المستوى: 2    الدور: D/V
 تحقق من أن الكشف عن الشواذ الإحصائية يحدد المدخلات التي تحتوي على مسافات تعديل غير عادية مقارنة بمعايير اللغة، أو تكرارات مفرطة في الرموز، أو مسافات تضمين غير طبيعية.
 #2.2.3    المستوى: 2    الدور: D
 تحقق من أن خط أنابيب الاستدلال يدعم نسخ النماذج المتينة المدربة ضد الهجمات الاختراقية أو طبقات الدفاع الاختيارية (مثل العشوائية، التقطير الدفاعي) للنقاط النهائية عالية المخاطر.
 #2.2.4    المستوى: 2    الدور: V
 تحقق من أن المدخلات المشبوهة العدائية محصورة، ومسجلة مع الحمولة الكاملة (بعد إزالة البيانات الشخصية التعريفية).
 #2.2.5    المستوى: 3    الدور: D/V
 تحقق من تتبع مقاييس المتانة (معدل نجاح مجموعات الهجمات المعروفة) مع مرور الوقت وأن التراجعات تؤدي إلى حظر الإصدار.

---

### C2.3 التحقق من المخطط، النوع والطول

يمكن أن تتسبب هجمات الذكاء الاصطناعي التي تحتوي على مدخلات مشوهة أو كبيرة الحجم في أخطاء في التحليل، وتسرب الأوامر عبر الحقول، واستنزاف الموارد. كما أن فرض الالتزام الصارم بالمخطط هو أيضًا شرط أساسي عند تنفيذ استدعاءات الأدوات الحتمية.

 #2.3.1    المستوى: 1    الدور: D
 تحقق من أن كل نقطة نهاية لاستدعاء API أو دالة تحدد مخطط إدخال صريح (JSON Schema أو Protobuf أو ما يعادلها متعدد الوسائط) وأنه يتم التحقق من صحة المدخلات قبل تجميع المطالبة.
 #2.3.2    المستوى: 1    الدور: D/V
 تحقق من أن الإدخالات التي تتجاوز الحد الأقصى لعدد الرموز أو البايتات ترفض بخطأ آمن ولا يتم قطعها بصمت أبدًا.
 #2.3.3    المستوى: 2    الدور: D/V
 تحقق من أن فحوصات النوع (مثل النطاقات الرقمية، قيم التعداد، أنواع MIME للصور/الصوت) تُطبق على الجانب الخادمي، وليس فقط في كود العميل.
 #2.3.4    المستوى: 2    الدور: D
 تحقق من أن المصادقين الدلاليين (مثل JSON Schema) يعملون في وقت ثابت لمنع هجمات حجب الخدمة الخوارزمية.
 #2.3.5    المستوى: 3    الدور: V
 تحقق من تسجيل حالات فشل التحقق مع مقاطع بيانات محذوفة ورموز خطأ واضحة لتسهيل تصنيف الأمن.

---

### C2.4 فحص المحتوى والسياسة

يجب أن يتمكن المطورون من اكتشاف المطالبات الصحيحة نحويًا التي تطلب محتوى غير مسموح به (مثل التعليمات غير المشروعة، خطاب الكراهية، والنصوص المحمية بحقوق الطبع والنشر) ثم منعها من الانتشار.

 #2.4.1    المستوى: 1    الدور: D
 تحقق من أن يصنّف مصنف المحتوى (صفر إطلاق أو مُدرب بدقة) كل إدخال من حيث العنف، وإيذاء الذات، والكراهية، والمحتوى الجنسي، والطلبات غير القانونية، مع إمكانية ضبط الحدود القابلة للتكوين.
 #2.4.2    المستوى: 1    الدور: D/V
 تحقق من أن المدخلات التي تنتهك السياسات ستتلقى رفضات موحدة أو إتمامات آمنة بحيث لا تنتقل إلى استدعاءات النماذج اللغوية الكبيرة اللاحقة.
 #2.4.3    المستوى: 2    الدور: D
 تحقق من أن نموذج الفحص أو مجموعة القواعد يتم إعادة تدريبه/تحديثه على الأقل كل ثلاثة أشهر، مع دمج أنماط الاختراق أو تجاوز السياسات الجديدة التي تم ملاحظتها.
 #2.4.4    المستوى: 2    الدور: D
 تحقق من أن الفحص يحترم السياسات الخاصة بالمستخدم (العمر، القيود القانونية الإقليمية) عبر قواعد قائمة على السمات تُحل في وقت الطلب.
 #2.4.5    المستوى: 3    الدور: V
 تحقق من أن سجلات الفرز تشمل درجات ثقة المصنف وعلامات فئة السياسة من أجل الترابط مع SOC وإعادة تشغيل فريق الاختبار الأحمر في المستقبل.

---

### C2.5 تحديد معدل الإدخال ومنع الإساءة

يجب على المطورين منع سوء الاستخدام، واستنزاف الموارد، والهجمات الآلية ضد أنظمة الذكاء الاصطناعي من خلال تحديد معدلات الإدخال واكتشاف أنماط الاستخدام الشاذة.

 #2.5.1    المستوى: 1    الدور: D/V
 تحقق من تطبيق حدود المعدل لكل مستخدم، ولكل عنوان IP، ولكل مفتاح API لجميع نقاط النهاية الخاصة بالإدخال.
 #2.5.2    المستوى: 2    الدور: D/V
 تحقق من ضبط حدود المعدل اللحظي والمستمر لمنع هجمات إنكار الخدمة (DoS) وهجمات القوة العمياء (brute force).
 #2.5.3    المستوى: 2    الدور: D/V
 تحقق من أن أنماط الاستخدام الشاذة (مثل الطلبات السريعة المتتابعة، فيضان الإدخال) تؤدي إلى تفعيل الحظر الآلي أو التصعيدات.
 #2.5.4    المستوى: 3    الدور: V
 تحقق من حفظ سجلات منع الإساءة ومراجعتها للكشف عن أنماط الهجوم الناشئة.

---

### C2.6 التحقق من صحة المدخلات متعددة الوسائط

يجب أن تتضمن أنظمة الذكاء الاصطناعي تحققاً قوياً للمدخلات غير النصية (كالصور، والصوت، والملفات) لمنع الحقن، والتملص، أو إساءة استخدام الموارد.

 #2.6.1    المستوى: 1    الدور: D
 تحقق من أن جميع الإدخالات غير النصية (الصور، الصوت، الملفات) يتم التحقق من صحتها من حيث النوع، والحجم، والصيغة قبل المعالجة.
 #2.6.2    المستوى: 2    الدور: D/V
 تحقق من فحص الملفات بحثًا عن البرمجيات الخبيثة والحمولات الإخفائية قبل الإدخال.
 #2.6.3    المستوى: 2    الدور: D/V
 تحقق من أن مدخلات الصور/الصوت يتم فحصها للتحقق من وجود اضطرابات معادية أو أنماط هجوم معروفة.
 #2.6.4    المستوى: 3    الدور: V
 تحقق من أن فشل التحقق من صحة الإدخال متعدد الوسائط يتم تسجيله ويؤدي إلى إصدار تنبيهات للتحقيق.

---

### C2.7 مصدر المدخلات ونسبتها

يجب أن تدعم أنظمة الذكاء الاصطناعي التدقيق، وتتبع الانتهاكات، والامتثال من خلال مراقبة وتوسيم مصادر جميع مدخلات المستخدم.

 #2.7.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع مدخلات المستخدمين مُعلَّمة بالبيانات الوصفية (معرّف المستخدم، الجلسة، المصدر، الطابع الزمني، عنوان IP) عند الإدخال.
 #2.7.2    المستوى: 2    الدور: D/V
 تحقق من أن بيانات الأصول (provenance metadata) محفوظة وقابلة للتدقيق لجميع المدخلات المعالجة.
 #2.7.3    المستوى: 2    الدور: D/V
 تحقق من أن مصادر الإدخال الشاذة أو غير الموثوقة يتم تمييزها وتخضع لفحص مشدد أو للحظر.

---

### C2.8 الكشف التكيفي في الوقت الحقيقي عن التهديدات

يجب على المطورين استخدام أنظمة كشف التهديدات المتقدمة للذكاء الاصطناعي التي تتكيف مع أنماط الهجوم الجديدة وتوفر حماية في الوقت الحقيقي باستخدام مطابقة الأنماط المجمعة.

 #2.8.1    المستوى: 1    الدور: D/V
 تحقق من أن أنماط اكتشاف التهديدات تم تجميعها في محركات تعبيرات نمطية محسنة لتحقيق أداء عالي في التصفية الفورية مع تأثير زمني ضئيل.
 #2.8.2    المستوى: 1    الدور: D/V
 تحقق من أن أنظمة كشف التهديدات تحتفظ بمكتبات نمطية منفصلة لفئات التهديد المختلفة (حقن الأوامر، المحتوى الضار، البيانات الحساسة، أوامر النظام).
 #2.8.3    المستوى: 2    الدور: D/V
 تحقق من أن الكشف التهديدي التكيفي يدمج نماذج تعلم الآلة التي تحدّث حساسية التهديد بناءً على تكرار الهجوم ومعدلات النجاح.
 #2.8.4    المستوى: 2    الدور: D/V
 تحقق من أن خلاصات استخبارات التهديدات في الوقت الحقيقي تقوم بتحديث مكتبات الأنماط تلقائيًا بتوقيعات الهجوم الجديدة ومؤشرات الاختراق (IOCs).
 #2.8.5    المستوى: 3    الدور: D/V
 تحقق من أن معدلات الإيجابيات الكاذبة في كشف التهديدات تتم مراقبتها باستمرار وأن خصوصية الأنماط يتم تعديلها تلقائيًا لتقليل التداخل مع حالات الاستخدام المشروعة.
 #2.8.6    المستوى: 3    الدور: D/V
 تحقق من أن تحليل التهديد السياقي يأخذ في الاعتبار مصدر الإدخال، وأنماط سلوك المستخدم، وتاريخ الجلسة لتحسين دقة الكشف.
 #2.8.7    المستوى: 3    الدور: D/V
 تحقق من أن مقاييس أداء الكشف عن التهديدات (معدل الكشف، زمن استجابة المعالجة، استخدام الموارد) يتم مراقبتها وتحسينها في الوقت الحقيقي.

---

### C2.9 خط أنابيب التحقق الأمني متعدد الوسائط

يجب على المطورين توفير التحقق الأمني لنصوص، وصور، وصوت، وأنواع أخرى من وسائط الإدخال الخاصة بالذكاء الاصطناعي مع أنواع محددة من كشف التهديدات وعزل الموارد.

 #2.9.1    المستوى: 1    الدور: D/V
 تحقق من أن كل وسيلة إدخال لها مدققات أمان مخصصة مع أنماط تهديد موثقة (النص: حقن المطالبات، الصور: الإخفاء داخل الصور، الصوت: هجمات الطيف الصوتي) وعتبات اكتشاف.
 #2.9.2    المستوى: 2    الدور: D/V
 تحقق من معالجة المدخلات متعددة الوسائط في بيئات معزولة (sandboxes) مع حدود موارد محددة (الذاكرة، وحدة المعالجة المركزية، وقت المعالجة) خاصة بكل نوع من أنواع الوسائط وموثقة في سياسات الأمان.
 #2.9.3    المستوى: 2    الدور: D/V
 تحقق من أن اكتشاف الهجمات متعددة الوسائط يحدد الهجمات المنسقة التي تمتد عبر أنواع إدخال متعددة (مثل الحمولات الإخفائية في الصور مجتمعة مع حقن الأوامر في النص) باستخدام قواعد الارتباط وتوليد التنبيهات.
 #2.9.4    المستوى: 3    الدور: D/V
 تأكد من أن إخفاقات التحقق متعددة الوسائط تؤدي إلى تسجيل مفصل يتضمن جميع أنماط الإدخال، نتائج التحقق، درجات التهديد، وتحليل الارتباط باستخدام تنسيقات سجلات منظمة لتكامل SIEM.
 #2.9.5    المستوى: 3    الدور: D/V
 تحقق من تحديث مصنفات المحتوى الخاصة بكل نمط وسائط وفقًا للجداول الموثقة (على الأقل ربع سنويًا) بحيث تحتوي على أنماط تهديد جديدة، وأمثلة عدائية، ومعايير أداء تُحافظ على مستوياتها فوق الحدود الأساسية.

---

### المراجع

LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security
Generative AI's Biggest Security Flaw Is Not Easy to Fix
Many-shot jailbreaking \ Anthropic
$PDF$ OpenAI GPT-4.5 System Card
Notebook for the CheckThat Lab at CLEF 2024
Mitigate jailbreaks and prompt injections – Anthropic
Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis
OWASP Top 10 for LLM Applications 2025 – WorldTech IT
OWASP Machine Learning Security Top Ten
Few words about AI Security – Jussi Metso
How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry
Easily enforcing valid JSON schema following – API
AI Safety + Cybersecurity R\&D Tracker – Fairly AI
Anthropic makes 'jailbreak' advance to stop AI models producing harmful results
Pattern matching filter rules - IBM
Real-time Threat Detection

## إدارة دورة حياة نموذج C3 والتحكم في التغييرات

### هدف التحكم

يجب على أنظمة الذكاء الاصطناعي تنفيذ عمليات مراقبة التغيير التي تمنع وصول التعديلات غير المصرح بها أو غير الآمنة للنموذج إلى مرحلة الإنتاج. يضمن هذا التحكم سلامة النموذج طوال دورة حياته بأكملها — من التطوير مروراً بالنشر وحتى الإيقاف النهائي — مما يتيح الاستجابة السريعة للحوادث ويحافظ على المساءلة عن جميع التغييرات.

الهدف الأمني الأساسي: يجب أن تصل النماذج المخوّلة والمُحقّقة فقط إلى مرحلة الإنتاج من خلال تطبيق عمليات مُتحكم بها تحافظ على السلامة، وقابلية التتبع، وقابلية الاسترداد.

---

### C3.1 تفويض النموذج وسلامته

فقط النماذج المصرح بها والتي تم التحقق من سلامتها تصل إلى بيئات الإنتاج.

 #3.1.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع نماذج النماذج (الأوزان، التكوينات، المُجزئات) موقعة تشفيرياً من قبل الكيانات المصرح لها قبل النشر.
 #3.1.2    المستوى: 1    الدور: D/V
 تحقق من أن سلامة النموذج يتم التحقق منها عند وقت النشر وأن فشل التحقق من التوقيع يمنع تحميل النموذج.
 #3.1.3    المستوى: 2    الدور: D/V
 تحقق من أن سجلات أصل النموذج تتضمن هوية الجهة المخوّلة، وقيم تحقق بيانات التدريب (checksums)، ونتائج اختبار التحقق مع حالة النجاح/الفشل، وطابع زمني لوقت الإنشاء.
 #3.1.4    المستوى: 2    الدور: D/V
 تحقق من أن جميع أدوات النموذج تستخدم الترقيم الدلالي للإصدار (MAJOR.MINOR.PATCH) مع وجود معايير موثقة تحدد متى يتم زيادة كل مكون من مكونات الإصدار.
 #3.1.5    المستوى: 2    الدور: V
 تحقق من أن تتبع التبعيات يحافظ على جرد في الوقت الحقيقي يتيح تحديدًا سريعًا لكافة الأنظمة المستهلكة.

---

### C3.2 التحقق من صحة النموذج والاختبار

يجب أن تجتاز النماذج عمليات التحقق المحددة للأمان والسلامة قبل النشر.

 #3.2.1    المستوى: 1    الدور: D/V
 تحقق من أن النماذج تخضع لاختبار أمني آلي يشمل التحقق من صحة المدخلات، وتطهير المخرجات، وتقييمات السلامة وفقًا لحدود النجاح/الفشل المتفق عليها مسبقًا بواسطة المنظمة قبل النشر.
 #3.2.2    المستوى: 1    الدور: D/V
 تحقق من أن حالات الفشل في التحقق تمنع تلقائيًا نشر النموذج بعد الموافقة الصريحة على التجاوز من قبل الأشخاص المخولين مسبقًا والمرفقة بمبررات تجارية موثقة.
 #3.2.3    المستوى: 2    الدور: V
 تحقق من أن نتائج الاختبار موقعة تشفيرياً ومرتبطة بشكل غير قابل للتغيير بهاش نسخة النموذج المحددة التي يتم التحقق منها.
 #3.2.4    المستوى: 2    الدور: D/V
 تحقق من أن عمليات النشر الطارئة تتطلب تقييمًا موثقًا لمخاطر الأمان وموافقة من سلطة أمان معينة مسبقًا ضمن الأطر الزمنية المتفق عليها مسبقًا.

---

### C3.3 النشر المُتحكم به والتراجع

يجب التحكم في نشر النماذج ومراقبته وجعله قابلاً للتراجع.

 #3.3.1    المستوى: 1    الدور: D
 تحقق من أن عمليات النشر الإنتاجية تطبق آليات النشر التدريجي (نشر الكناري، النشر الأزرق-الأخضر) مع محفزات التراجع التلقائي بناءً على معدلات الأخطاء المتفق عليها مسبقًا، أو عتبات الكمون، أو معايير تنبيه الأمان.
 #3.3.2    المستوى: 1    الدور: D/V
 تحقق من أن قدرات التراجع تستعيد حالة النموذج الكاملة (الأوزان، التكوينات، التبعيات) بشكل ذري داخل النوافذ الزمنية التنظيمية المحددة مسبقًا.
 #3.3.3    المستوى: 2    الدور: D/V
 تحقق من أن عمليات النشر تتحقق من صحة التوقيعات التشفيرية وتحسب مجموعات التحقق من التكامل قبل تفعيل النموذج، مع فشل النشر في حالة أي عدم تطابق.
 #3.3.4    المستوى: 2    الدور: D/V
 تحقق من أن قدرات إيقاف تشغيل النموذج الطارئ يمكنها تعطيل نقاط نهاية النموذج ضمن أوقات استجابة محددة مسبقًا عبر قواطع دوائر مؤتمتة أو مفاتيح إيقاف يدوية.
 #3.3.5    المستوى: 2    الدور: V
 تحقق من أن أدوات التراجع (إصدارات النماذج السابقة، التكوينات، التبعيات) محفوظة وفقًا لسياسات المؤسسة باستخدام تخزين غير قابل للتغيير للاستجابة للحوادث.

---

### C3.4 مسؤولية التغيير والتدقيق

يجب أن تكون جميع تغييرات دورة حياة النموذج قابلة للتتبع والتدقيق.

 #3.4.1    المستوى: 1    الدور: V
 تحقق من أن جميع تغييرات النموذج (النشر، التكوين، الإيقاف) تولد سجلات مراجعة ثابتة تتضمن طابعًا زمنيًا، وهوية الممثل الموثق، ونوع التغيير، والحالات قبل/بعد التغيير.
 #3.4.2    المستوى: 2    الدور: D/V
 تحقق من أن الوصول إلى سجل التدقيق يتطلب التفويض المناسب وأن جميع محاولات الوصول تُسجل مع هوية المستخدم والطابع الزمني.
 #3.4.3    المستوى: 2    الدور: D/V
 تأكد من أن قوالب التعليمات ورسائل النظام تخضع للتحكم في الإصدارات في مستودعات git مع مراجعة كود إلزامية وموافقة من المراجعين المعينين قبل النشر.
 #3.4.4    المستوى: 2    الدور: V
 تحقق من أن سجلات التدقيق تتضمن تفاصيل كافية (تجزئة النماذج، لقطات التكوين، إصدارات التبعيات) لتمكين إعادة بناء كاملة لحالة النموذج لأي طابع زمني ضمن فترة الاحتفاظ.

---

### ممارسات التطوير الآمن C3.5

يجب أن تتبع عمليات تطوير ونمذجة النموذج ممارسات آمنة لمنع التعرض للاختراق.

 #3.5.1    المستوى: 1    الدور: D
 تحقق من أن بيئات تطوير النموذج، والاختبار، والإنتاج مفصولة فعليًا أو منطقيًا. لا يشتركون في البنية التحتية، ولديهم ضوابط وصول متميزة، ومتاجر بيانات معزولة.
 #3.5.2    المستوى: 1    الدور: D
 تحقق من أن تدريب النموذج وتعديله الدقيق يتمان في بيئات معزولة مع وصول شبكة محكم التحكم.
 #3.5.3    المستوى: 1    الدور: D/V
 تحقق من أن مصادر بيانات التدريب يتم التحقق من صحتها من خلال فحوصات السلامة ويتم توثيق مصداقيتها عبر مصادر موثوقة مع سلسلة حفظ محفوظات موثقة قبل استخدامها في تطوير النموذج.
 #3.5.4    المستوى: 2    الدور: D
 تحقق من أن مستندات تطوير النموذج (الهايبر باراميترز، سكريبتات التدريب، ملفات التهيئة) مخزنة في نظام التحكم في الإصدارات وتتطلب موافقة مراجعة الأقران قبل استخدامها في التدريب.

---

### C3.6 تقاعد النموذج وإيقاف تشغيله

يجب التخلص من النماذج بأمان عندما لم تعد هناك حاجة إليها أو عند تحديد مشاكل أمنية.

 #3.6.1    المستوى: 1    الدور: D
 تحقق من أن عمليات تقاعد النموذج تقوم بمسح رسميات التبعيات تلقائيًا، وتحديد جميع الأنظمة المستهلكة، وتوفير فترات إشعار مسبقة متفق عليها قبل الاستبعاد.
 #3.6.2    المستوى: 1    الدور: D/V
 تحقق من أن آثار النموذج المتقاعد يتم محوها بأمان باستخدام المسح التشفيري أو إعادة الكتابة متعددة المراحل وفقًا لسياسات الاحتفاظ بالبيانات الموثقة مع شهادات تدمير موثقة.
 #3.6.3    المستوى: 2    الدور: V
 تحقق من تسجيل أحداث تقاعد النموذج مع الطابع الزمني وهوية الفاعل، ويتم إلغاء توقيعات النموذج لمنع إعادة الاستخدام.
 #3.6.4    المستوى: 2    الدور: D/V
 تحقق من أن التقاعد الطارئ للنموذج يمكنه تعطيل الوصول إلى النموذج ضمن الأطر الزمنية المحددة مسبقًا للاستجابة للطوارئ من خلال مفاتيح إيقاف تلقائية إذا تم اكتشاف ثغرات أمان حرجة.

---

### المراجع

MLOps Principles
Securing AI/ML Ops – Cisco.com
Audit logs security: cryptographically signed tamper-proof logs
Machine Learning Model Versioning: Top Tools & Best Practices
AI Hygiene Starts with Models and Data Loaders – SEI Blog
How to handle versioning and rollback of a deployed ML model?
Reinforcement fine-tuning – OpenAI API
Auditing Machine Learning models: Governance, Data Security and …
Adversarial Training to Improve Model Robustness
What is AI adversarial robustness? – IBM Research
Exploring Data Provenance: Ensuring Data Integrity and Authenticity
MITRE ATLAS
AWS Prescriptive Guidance – Best practices for retiring applications …

## بنية تحتية C4، أمان التكوين والنشر

### هدف التحكم

يجب أن تكون بنية الذكاء الاصطناعي قوية ضد تصعيد الامتيازات، والتلاعب في سلسلة التوريد، والتنقل الجانبي من خلال التكوين الآمن، وعزل وقت التشغيل، وخطوط نشر موثوقة، والمراقبة الشاملة. لا تصل إلى الإنتاج سوى مكونات البنية التحتية والتكوينات المصرح بها والمتحققة من صحتها عبر عمليات مراقبة تحافظ على الأمان، والسلامة، وقابلية التدقيق.

الهدف الأمني الأساسي: لا تصل مكونات البنية التحتية المُوقعة تشفيرياً والمفحوصة من حيث الثغرات إلى الإنتاج إلا عبر خطوط تدفق التحقق الآلية التي تفرض سياسات الأمان وتحافظ على سجلات تدقيق غير قابلة للتغيير.

---

### C4.1 عزل بيئة التشغيل

منع هروب الحاوية وتصعيد الامتيازات من خلال بدائيات العزل على مستوى النواة وضوابط الوصول الإلزامية.

 #4.1.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع حاويات الذكاء الاصطناعي تُسقط كافة صلاحيات لينكس باستثناء CAP_SETUID و CAP_SETGID، والصلاحيات المطلوبة صراحة والمُوثقة في خطوط الأساس الأمنية.
 #4.1.2    المستوى: 1    الدور: D/V
 تحقق من أن ملفات تعريف seccomp تمنع جميع نداءات النظام باستثناء تلك الموجودة في قوائم السماح المعتمدة مسبقًا، مع إنهاء الحاوية في حالة وجود انتهاكات وتوليد تنبيهات أمان.
 #4.1.3    المستوى: 2    الدور: D/V
 تحقق من أن أحمال العمل الخاصة بالذكاء الاصطناعي تعمل بأنظمة ملفات جذر للقراءة فقط، وtmpfs للبيانات المؤقتة، وأحجام مسماة للبيانات الدائمة مع فرض خيارات mount noexec.
 #4.1.4    المستوى: 2    الدور: D/V
 تحقق من أن مراقبة وقت التشغيل المبنية على eBPF (مثل Falco أو Tetragon أو ما يعادلها) تكتشف محاولات تصعيد الامتيازات وتقوم تلقائيًا بإنهاء العمليات المخالفة ضمن متطلبات زمن استجابة المؤسسة.
 #4.1.5    المستوى: 3    الدور: D/V
 تحقق من أن أحمال العمل عالية المخاطر للذكاء الاصطناعي تُنفذ في بيئات معزولة على مستوى العتاد (Intel TXT، AMD SVM، أو عقد مخصصة بدون نظام تشغيل) مع التحقق من التصديق.

---

### C4.2 خطوط أنابيب البناء والنشر الآمنة

ضمان السلامة التشفيرية وأمن سلسلة التوريد من خلال بناءات قابلة لإعادة الإنتاج وقطع مؤيدة بالتوقيع.

 #4.2.1    المستوى: 1    الدور: D/V
 تحقق من أن البنية التحتية كرمز يتم فحصها باستخدام أدوات (tfsec, Checkov, أو Terrascan) على كل التزام، مع حظر الدمج إذا وُجدت نتائج ذات شدة حرجة أو عالية.
 #4.2.2    المستوى: 1    الدور: D/V
 تحقق من أن بناء الحاويات قابل لإعادة الإنتاج بنفس تجزئة SHA256 عبر عمليات البناء المختلفة وقم بإنشاء إقرارات مصدر SLSA المستوى 3 موقعة باستخدام Sigstore.
 #4.2.3    المستوى: 2    الدور: D/V
 تحقق من أن صور الحاويات تضمّن CycloneDX أو SPDX SBOMs وأن تكون موقعة بواسطة Cosign قبل دفعها إلى السجل، مع رفض الصور غير الموقعة عند النشر.
 #4.2.4    المستوى: 2    الدور: D/V
 تحقق من أن خطوط أنابيب CI/CD تستخدم رموز OIDC من HashiCorp Vault أو أدوار AWS IAM أو الهوية المُدارة في Azure مع أوقات صلاحية لا تتجاوز حدود سياسة الأمان التنظيمية.
 #4.2.5    المستوى: 2    الدور: D/V
 تحقق من صحة توقيعات Cosign وSLSA provenance أثناء عملية النشر قبل تنفيذ الحاوية، وأن تتسبب أخطاء التحقق في فشل النشر.
 #4.2.6    المستوى: 2    الدور: D/V
 تحقق من أن بيئات البناء تعمل في حاويات عابرة أو في آلات افتراضية بدون تخزين دائم وعزل الشبكة عن شبكات VPC الخاصة بالإنتاج.

---

### C4.3 أمن الشبكات والتحكم في الوصول

تنفيذ الشبكات ذات الثقة الصفرية بسياسات الرفض الافتراضي والاتصالات المشفرة.

 #4.3.1    المستوى: 1    الدور: D/V
 تحقق من أن Kubernetes NetworkPolicies أو أي ما يعادلها تقوم بتنفيذ المنع الافتراضي للمرور الوارد والصادر مع قواعد سماح صريحة للمنافذ المطلوبة (443، 8080، إلخ).
 #4.3.2    المستوى: 1    الدور: D/V
 تحقق من أن بروتوكول SSH (المنفذ 22) وبروتوكول RDP (المنفذ 3389) ونقاط نهاية بيانات التعريف السحابية (169.254.169.254) محظورة أو تتطلب مصادقة تعتمد على الشهادات.
 #4.3.3    المستوى: 2    الدور: D/V
 تحقق من أن حركة المرور الصادرة يتم تصفيتها عبر وكلاء HTTP/HTTPS (Squid أو Istio أو بوابات NAT السحابية) باستخدام قوائم السماح بالنطاقات مع تسجيل الطلبات المحجوبة.
 #4.3.4    المستوى: 2    الدور: D/V
 تحقق من أن التواصل بين الخدمات يستخدم بروتوكول TLS المتبادل مع تدوير الشهادات وفقًا لسياسة المنظمة ويتم فرض التحقق من صحة الشهادات (دون استخدام علامات تخطي التحقق).
 #4.3.5    المستوى: 2    الدور: D/V
 تحقق من أن بنية الذكاء الاصطناعي تعمل في شبكات VPCs/VNets مخصصة بدون وصول مباشر إلى الإنترنت، وتتواصل فقط من خلال بوابات NAT أو مضيفات الباستيون.

---

### C4.4 إدارة الأسرار والمفاتيح التشفيرية

حماية بيانات الاعتماد من خلال التخزين المدعوم بالأجهزة والتدوير التلقائي مع وصول بثقة صفرية.

 #4.4.1    المستوى: 1    الدور: D/V
 تحقق من أن الأسرار مخزنة في HashiCorp Vault أو AWS Secrets Manager أو Azure Key Vault أو Google Secret Manager مع تشفير أثناء التخزين باستخدام AES-256.
 #4.4.2    المستوى: 1    الدور: D/V
 تحقق من أن مفاتيح التشفير تُولد في أجهزة HSM بمستوى FIPS 140-2 المستوى 2 (AWS CloudHSM، Azure Dedicated HSM) مع تدوير المفاتيح وفقًا لسياسة التشفير التنظيمية.
 #4.4.3    المستوى: 2    الدور: D/V
 تحقق من أن تدوير الأسرار مؤتمت مع نشر بدون توقف وبدء التدوير الفوري عند حدوث تغييرات في الأفراد أو حوادث أمنية.
 #4.4.4    المستوى: 2    الدور: D/V
 تأكد من أن صور الحاويات يتم فحصها باستخدام أدوات (GitLeaks، TruffleHog، أو detect-secrets) لمنع إنشاء البنى التي تحتوي على مفاتيح API أو كلمات مرور أو شهادات.
 #4.4.5    المستوى: 2    الدور: D/V
 تحقق من أن الوصول إلى الأسرار الإنتاجية يتطلب المصادقة متعددة العوامل باستخدام رموز الأجهزة (YubiKey، FIDO2) ويتم تسجيله بواسطة سجلات تدقيق غير قابلة للتغيير مع هويات المستخدمين والطوابع الزمنية.
 #4.4.6    المستوى: 2    الدور: D/V
 تحقق من أن الأسرار يتم حقنها عبر أسرار Kubernetes أو وحدات التخزين المرفقة أو حاويات التهيئة، وتأكد من عدم تضمين الأسرار أبدًا في متغيرات البيئة أو الصور.

---

### C4.5 عزل والتحقق من عبء عمل الذكاء الاصطناعي

عزل نماذج الذكاء الاصطناعي غير الموثوقة في صناديق رملية آمنة مع تحليل سلوكي شامل.

 #4.5.1    المستوى: 1    الدور: D/V
 تحقق من أن نماذج الذكاء الاصطناعي الخارجية يتم تنفيذها في gVisor، أو microVMs (مثل Firecracker، CrossVM)، أو حاويات Docker باستخدام الخيارين --security-opt=no-new-privileges و --read-only.
 #4.5.2    المستوى: 1    الدور: D/V
 تحقق من أن بيئات الحماية المعزولة (sandbox) لا تمتلك اتصالًا بالشبكة (--network=none) أو تقتصر على الوصول إلى المضيف المحلي فقط مع حظر جميع الطلبات الخارجية بواسطة قواعد iptables.
 #4.5.3    المستوى: 2    الدور: D/V
 تحقق من أن تحقق صحة نموذج الذكاء الاصطناعي يشمل اختبار الفريق الأحمر الآلي مع تغطية اختبار محددة تنظيميًا وتحليل السلوك لاكتشاف الأبواب الخلفية.
 #4.5.4    المستوى: 2    الدور: D/V
 تحقق من أنه قبل ترقية نموذج الذكاء الاصطناعي إلى مرحلة الإنتاج، يتم توقيع نتائج صندوق الاختبار الخاص به تشفيرياً من قبل العاملين الأمنيين المخولين ويتم تخزين هذه النتائج في سجلات تدقيق غير قابلة للتغيير.
 #4.5.5    المستوى: 2    الدور: D/V
 تحقق من أنه يتم تدمير بيئات الصندوق الرملية وإعادة إنشائها من الصور الذهبية بين التقييمات مع تنظيف كامل لنظام الملفات والذاكرة.

---

### C4.6 مراقبة أمن البنية التحتية

قم بمسح ومراقبة البنية التحتية بشكل مستمر مع التصحيح الآلي والتنبيه الفوري.

 #4.6.1    المستوى: 1    الدور: D/V
 التحقق من فحص صور الحاويات وفقًا لجداول المنظمة مع حظر النشر في حالة وجود ثغرات حرجة بناءً على عتبات المخاطر التنظيمية.
 #4.6.2    المستوى: 1    الدور: D/V
 تحقق من أن البنية التحتية تفي بمعايير CIS أو ضوابط NIST 800-53 وفقًا لعتبات الامتثال المحددة تنظيميًا، مع تصحيح تلقائي للفحوصات التي فشلت.
 #4.6.3    المستوى: 2    الدور: D/V
 تحقق من أنه تم تصحيح الثغرات الأمنية ذات شدة عالية وفقًا لجداول زمنية لإدارة المخاطر التنظيمية مع اتباع إجراءات طارئة للحالات التي يتم استغلال CVEs فيها بنشاط.
 #4.6.4    المستوى: 2    الدور: V
 تحقق من أن تنبيهات الأمان تتكامل مع منصات SIEM (Splunk أو Elastic أو Sentinel) باستخدام صيغ CEF أو STIX/TAXII مع الإثراء التلقائي.
 #4.6.5    المستوى: 3    الدور: V
 تحقق من تصدير مقاييس البنية التحتية إلى أنظمة المراقبة (Prometheus، DataDog) مع لوحات مؤشرات اتفاقيات مستوى الخدمة والتقارير التنفيذية.
 #4.6.6    المستوى: 2    الدور: D/V
 التحقق من اكتشاف انحراف التكوين باستخدام الأدوات (Chef InSpec، AWS Config) وفقًا لمتطلبات المراقبة التنظيمية مع التراجع التلقائي للتغييرات غير المصرح بها.

---

### إدارة موارد بنية تحتية الذكاء الاصطناعي C4.7

منع هجمات استنفاد الموارد وضمان تخصيص الموارد بشكل عادل من خلال الحصص والمراقبة.

 #4.7.1    المستوى: 1    الدور: D/V
 تحقق من مراقبة استخدام وحدة معالجة الرسومات (GPU) ووحدة معالجة التنسور (TPU) بحيث يتم تنشيط التنبيهات عند الوصول إلى العتبات المحددة من قبل المنظمة، بالإضافة إلى تفعيل التوسع التلقائي أو موازنة الحمل بناءً على سياسات إدارة السعة.
 #4.7.2    المستوى: 1    الدور: D/V
 تحقق من جمع مقاييس عبء عمل الذكاء الاصطناعي (زمن استجابة الاستنتاج، معدل النقل، معدلات الخطأ) وفقًا لمتطلبات المراقبة التنظيمية وربطها باستخدام البنية التحتية.
 #4.7.3    المستوى: 2    الدور: D/V
 تحقق من أن Kubernetes ResourceQuotas أو ما يعادلها تحد من أحمال العمل الفردية وفقًا لسياسات تخصيص الموارد التنظيمية مع فرض حدود صارمة.
 #4.7.4    المستوى: 2    الدور: V
 تحقق من أن مراقبة التكلفة تتعقب الإنفاق لكل عبء عمل/مستأجر مع تنبيهات تعتمد على حدود الميزانية التنظيمية وضوابط آلية لتجاوزات الميزانية.
 #4.7.5    المستوى: 3    الدور: V
 تحقق من أن تخطيط السعة يستخدم البيانات التاريخية مع فترات التنبؤ المحددة تنظيميًا وتوفير الموارد الآلي استنادًا إلى أنماط الطلب.
 #4.7.6    المستوى: 2    الدور: D/V
 تحقق من أن استنفاد الموارد يؤدي إلى تشغيل قواطع الدائرة وفقًا لمتطلبات الاستجابة التنظيمية، بما في ذلك تحديد المعدل بناءً على سياسات السعة وعزل حمولة العمل.

---

### C4.8 فصل البيئة و controles الترقية

فرض حدود بيئية صارمة باستخدام بوابات الترقية الآلية والتحقق الأمني.

 #4.8.1    المستوى: 1    الدور: D/V
 تحقق من أن بيئات التطوير/الاختبار/الإنتاج تعمل في شبكات VPC/VNet منفصلة دون أدوار IAM مشتركة أو مجموعات أمان أو اتصال شبكي.
 #4.8.2    المستوى: 1    الدور: D/V
 تحقق من أن ترقية البيئة تتطلب موافقة من الأشخاص المخولين المحددين تنظيميًا باستخدام توقيعات تشفيرية ومسارات تدقيق لا يمكن تغييرها.
 #4.8.3    المستوى: 2    الدور: D/V
 تحقق من أن بيئات الإنتاج تمنع الوصول عبر SSH، وتعطل نقاط النهاية الخاصة بالتصحيح، وتتطلب طلبات تغيير مع متطلبات إشعار مسبق تنظيمي باستثناء حالات الطوارئ.
 #4.8.4    المستوى: 2    الدور: D/V
 تحقق من أن تغييرات البنية التحتية كرمز تتطلب مراجعة الأقران مع اختبار مؤتمت ومسح أمني قبل الدمج في الفرع الرئيسي.
 #4.8.5    المستوى: 2    الدور: D/V
 تحقق من أن البيانات غير الإنتاجية مموهة وفقًا لمتطلبات الخصوصية التنظيمية، سواء من خلال توليد بيانات تركيبية أو إخفاء البيانات بالكامل مع التحقق من إزالة المعلومات الشخصية.
 #4.8.6    المستوى: 2    الدور: D/V
 تحقق من أن بوابات الترويج تشمل اختبارات أمان مؤتمتة (SAST, DAST, فحص الحاويات) مع اشتراط عدم وجود نتائج حرجة من المستوى CRITICAL للموافقة.

---

### C4.9 النسخ الاحتياطي للبنية التحتية واستعادة البيانات

ضمان مرونة البنية التحتية من خلال النسخ الاحتياطية المؤتمتة، وإجراءات الاسترداد المختبرة، وقدرات التعافى من الكوارث.

 #4.9.1    المستوى: 1    الدور: D/V
 التحقق من نسخ تكوينات البنية التحتية احتياطيًا وفقًا لجداول النسخ الاحتياطي التنظيمية إلى مناطق جغرافية منفصلة مع تنفيذ استراتيجية النسخ الاحتياطي 3-2-1.
 #4.9.2    المستوى: 2    الدور: D/V
 تحقق من أن أنظمة النسخ الاحتياطي تعمل في شبكات معزولة باستخدام بيانات اعتماد منفصلة وتخزين معزول لحماية من برامج الفدية.
 #4.9.3    المستوى: 2    الدور: V
 تحقق من أن إجراءات الاسترداد يتم اختبارها والتحقق من صحتها من خلال الاختبار الآلي وفقًا لجدول المنظمة مع تحقيق أهداف وقت الاسترداد (RTO) ونقطة الاسترداد (RPO) بما يتوافق مع متطلبات المنظمة.
 #4.9.4    المستوى: 3    الدور: V
 تأكد من أن استعادة الكوارث تشمل كتيبات تشغيل محددة للذكاء الاصطناعي مع استعادة أوزان النماذج، وإعادة بناء تجمع GPU، ورسم خرائط اعتمادات الخدمة.

---

### C4.10 الامتثال للبنية التحتية والحوكمة

الحفاظ على الامتثال التنظيمي من خلال التقييم المستمر، والتوثيق، والضوابط الآلية.

 #4.10.1    المستوى: 2    الدور: D/V
 تحقق من تقييم الامتثال للبنية التحتية وفقًا لجداول المنظمة مقابل ضوابط SOC 2 و ISO 27001 أو FedRAMP باستخدام جمع الأدلة الآلي.
 #4.10.2    المستوى: 2    الدور: V
 تحقق من أن وثائق البنية التحتية تتضمن مخططات الشبكة، خرائط تدفق البيانات، ونماذج التهديدات مع تحديثها وفقًا لمتطلبات إدارة التغيير في المنظمة.
 #4.10.3    المستوى: 3    الدور: D/V
 تحقق من أن التغييرات في البنية التحتية تخضع لتقييم تلقائي لتأثير الامتثال مع سير عمل الموافقات التنظيمية للتعديلات عالية الخطورة.

---

### C4.11 أمن أجهزة الذكاء الاصطناعي

تأمين مكونات الأجهزة الخاصة بالذكاء الاصطناعي بما في ذلك وحدات معالجة الرسوميات (GPUs)، ووحدات معالجة التنسورات (TPUs)، ومعجلات الذكاء الاصطناعي المتخصصة.

 #4.11.1    المستوى: 2    الدور: D/V
 تحقق من أن برنامج الأجهزة لليسرعات الذكية (BIOS الخاصة بوحدة معالجة الرسومات، وبرنامج الأجهزة لوحدة معالجة التعلم TPU) مُثبت عليه توقيعات تشفيرية ويتم تحديثه وفقًا لجداول إدارة التحديثات في المؤسسة.
 #4.11.2    المستوى: 2    الدور: D/V
 تحقق من أنه قبل تنفيذ عبء العمل، يتم التحقق من سلامة مسرّع الذكاء الاصطناعي عبر إثبات الأجهزة باستخدام TPM 2.0 أو Intel TXT أو AMD SVM.
 #4.11.3    المستوى: 2    الدور: D/V
 تحقق من عزل ذاكرة وحدة معالجة الرسومات بين أحمال العمل باستخدام SR-IOV أو MIG (وحدة معالجة الرسومات متعددة الحالات) أو تقسيم الأجهزة المعادل مع تعقيم الذاكرة بين الوظائف.
 #4.11.4    المستوى: 3    الدور: V
 تحقق من أن سلسلة توريد أجهزة الذكاء الاصطناعي تتضمن التحقق من المصدر باستخدام شهادات المصنع وتأكيد صحة التغليف المضاد للعبث.
 #4.11.5    المستوى: 3    الدور: D/V
 تحقق من أن وحدات أمان الأجهزة (HSMs) تحمي أوزان نماذج الذكاء الاصطناعي ومفاتيح التشفير بشهادة FIPS 140-2 المستوى 3 أو Common Criteria EAL4+.

---

### C4.12 بنية تحتية للذكاء الاصطناعي على الحافة والموزعة

نشرات الذكاء الاصطناعي الموزعة الآمنة بما في ذلك الحوسبة الطرفية، التعلم الفيدرالي، والهياكل متعددة المواقع.

 #4.12.1    المستوى: 2    الدور: D/V
 تحقق من أن أجهزة الذكاء الاصطناعي الطرفية تقوم بالمصادقة على البنية التحتية المركزية باستخدام بروتوكول TLS المتبادل مع شهادات الأجهزة التي يتم تدويرها وفقًا لسياسة إدارة الشهادات التنظيمية.
 #4.12.2    المستوى: 2    الدور: D/V
 تحقق من أن أجهزة الحافة تنفذ الإقلاع الآمن مع توقيعات موثقة وحماية من التراجع لمنع هجمات خفض إصدار البرنامج الثابت.
 #4.12.3    المستوى: 3    الدور: D/V
 تحقق من أن تنسيق الذكاء الاصطناعي الموزع يستخدم خوارزميات توافق الآراء المتسامحة مع أخطاء بيزنطية مع التحقق من المشاركين واكتشاف العقد الضارة.
 #4.12.4    المستوى: 3    الدور: D/V
 تحقق من أن الاتصال بين الحافة والسحابة يشمل تحديد عرض النطاق الترددي، وضغط البيانات، وقدرات التشغيل في وضع عدم الاتصال مع التخزين المحلي الآمن.

---

### C4.13 أمان البنية التحتية السحابية المتعددة والهجينة

تأمين أعباء العمل الخاصة بالذكاء الاصطناعي عبر مزودي السحابة المتعددة ونشر السحابة الهجينة على البنية التحتية المحلية.

 #4.13.1    المستوى: 2    الدور: D/V
 تحقق من أن عمليات نشر الذكاء الاصطناعي متعددة السحابات تستخدم توحيد الهوية المستقل عن السحابة (OIDC، SAML) مع إدارة مركزية للسياسات عبر مقدمي الخدمات.
 #4.13.2    المستوى: 2    الدور: D/V
 تحقق من أن نقل البيانات عبر السحابات يستخدم التشفير من طرف إلى طرف مع مفاتيح تدار من قبل العميل، وأن يتم تطبيق ضوابط إقامة البيانات وفقًا للولاية القضائية.
 #4.13.3    المستوى: 2    الدور: D/V
 تحقق من أن أحمال عمل الذكاء الاصطناعي في السحابة الهجينة تنفذ سياسات أمان متسقة عبر البيئات المحلية والسحابة مع مراقبة وتنبيه موحد.
 #4.13.4    المستوى: 3    الدور: V
 تحقق من أن منع الاعتماد الحصري على مزود الخدمة السحابية يشمل بنية تحتية قابلة للنقل ككود، وواجهات برمجة التطبيقات الموحدة، وقدرات تصدير البيانات مع أدوات تحويل الصيغ.
 #4.13.5    المستوى: 3    الدور: V
 تحقق من أن تحسين تكاليف السحابة المتعددة يشمل ضوابط الأمان التي تمنع انتشار الموارد بالإضافة إلى تكاليف نقل البيانات غير المصرح بها عبر السحابات المختلفة.

---

### C4.14 أمان أتمتة البنية التحتية و GitOps

أتمتة خطوط أنابيب البنية التحتية الآمنة وتدفقات عمل GitOps لإدارة بنية الذكاء الاصطناعي.

 #4.14.1    المستوى: 2    الدور: D/V
 تحقق من أن مستودعات GitOps تتطلب توقيع الالتزامات باستخدام مفاتيح GPG وقواعد حماية الفروع التي تمنع الدفع المباشر إلى الفروع الرئيسية.
 #4.14.2    المستوى: 2    الدور: D/V
 تحقق من أن أتمتة البنية التحتية تشمل كشف الانحراف مع قدرات الإصلاح التلقائي والتراجع التي يتم تفعيلها وفقًا لمتطلبات استجابة المؤسسة للتغييرات غير المصرح بها.
 #4.14.3    المستوى: 2    الدور: D/V
 تحقق من أن توفير البنية التحتية الآلي يتضمن التحقق من سياسة الأمان مع حظر النشر في حالة التكوينات غير المتوافقة.
 #4.14.4    المستوى: 2    الدور: D/V
 التحقق من أن أسرار أتمتة البنية التحتية تُدار من خلال مشغلي الأسرار الخارجية (External Secrets Operator، Bank-Vaults) مع التدوير التلقائي.
 #4.14.5    المستوى: 3    الدور: V
 تحقق من أن البنية التحتية ذاتية الشفاء تشمل ارتباط أحداث الأمان مع استجابة تلقائية للحوادث وتدفقات عمل لإخطار الجهات المعنية.

---

### C4.15 أمن البنية التحتية المقاومة للحوسبة الكمومية

جهز بنية تحتية للذكاء الاصطناعي لمواجهة تهديدات الحوسبة الكمومية من خلال التشفير ما بعد الكمومي والبروتوكولات الآمنة ضد الكم.

 #4.15.1    المستوى: 3    الدور: D/V
 تحقق من أن بنية الذكاء الاصطناعي تنفذ خوارزميات التشفير بعد الكم المعتمدة من قبل NIST (CRYSTALS-Kyber، CRYSTALS-Dilithium، SPHINCS+) لتبادل المفاتيح والتوقيعات الرقمية.
 #4.15.2    المستوى: 3    الدور: D/V
 التحقق من تنفيذ أنظمة توزيع المفتاح الكمومي (QKD) للاتصالات الذكية ذات الأمان العالي باستخدام بروتوكولات إدارة المفاتيح الآمنة ضد الكم.
 #4.15.3    المستوى: 3    الدور: D/V
 تحقق من أن أُطُر المرونة التشفيرية تمكن الانتقال السريع إلى خوارزميات ما بعد الكم الجديدة مع التدوير التلقائي للشهادات والمفاتيح.
 #4.15.4    المستوى: 3    الدور: V
 تحقق من أن نمذجة التهديدات الكمومية تقيم ضعف بنية الذكاء الاصطناعي التحتية تجاه الهجمات الكمومية مع توثيق جداول زمنية للهجرة وتقييمات المخاطر.
 #4.15.5    المستوى: 3    الدور: D/V
 تحقق من أن أنظمة التشفير المختلطة الكلاسيكية-الكمومية توفر دفاعًا متعمقًا خلال فترة الانتقال الكمومي مع مراقبة الأداء.

---

### C4.16 الحوسبة السرية والمناطق الآمنة

حماية أحمال العمل الخاصة بالذكاء الاصطناعي وأوزان النماذج باستخدام بيئات التنفيذ الموثوقة المعتمدة على الأجهزة وتقنيات الحوسبة السرية.

 #4.16.1    المستوى: 3    الدور: D/V
 تحقق من أن نماذج الذكاء الاصطناعي الحساسة تعمل داخل حاويات Intel SGX أو AMD SEV-SNP أو ARM TrustZone مع ذاكرة مشفرة والتحقق من الشهادة.
 #4.16.2    المستوى: 3    الدور: D/V
 تحقق من أن الحاويات السرية (مثل Kata Containers، و gVisor مع الحوسبة السرية) تقوم بعزل أعباء عمل الذكاء الاصطناعي باستخدام تشفير الذاكرة المدعوم من العتاد.
 #4.16.3    المستوى: 3    الدور: D/V
 تحقق من أن التحقق البعيد يؤكد سلامة الحظيرة قبل تحميل نماذج الذكاء الاصطناعي مع إثبات تشفير لصحة بيئة التنفيذ.
 #4.16.4    المستوى: 3    الدور: D/V
 تحقق من أن خدمات استنتاج الذكاء الاصطناعي السرية تمنع استخراج النموذج من خلال الحساب المشفر مع أوزان النموذج المُقفلة والتنفيذ المحمي.
 #4.16.5    المستوى: 3    الدور: D/V
 تحقق من أن تنظيم بيئة التنفيذ الموثوقة يدير دورة حياة الحاوية الآمنة مع التصديق عن بُعد وقنوات الاتصال المشفرة.
 #4.16.6    المستوى: 3    الدور: D/V
 تحقق من أن الحوسبة متعددة الأطراف الآمنة (SMPC) تمكن من تدريب الذكاء الاصطناعي التعاوني دون الكشف عن مجموعات البيانات الفردية أو معلمات النموذج.

---

### C4.17 بنية تحتية المعرفة الصفرية

تنفيذ أنظمة إثبات المعرفة الصفرية للتحقق والمصادقة على الذكاء الاصطناعي مع الحفاظ على الخصوصية دون الكشف عن المعلومات الحساسة.

 #4.17.1    المستوى: 3    الدور: D/V
 تحقق من أن إثباتات المعرفة الصفرية (ZK-SNARKs، ZK-STARKs) تتحقق من سلامة نموذج الذكاء الاصطناعي وأصل التدريب دون الكشف عن أوزان النموذج أو بيانات التدريب.
 #4.17.2    المستوى: 3    الدور: D/V
 تأكد من أن أنظمة المصادقة القائمة على إثبات المعرفة بصفر (ZK) تتيح التحقق من هوية المستخدم مع الحفاظ على خصوصيته لخدمات الذكاء الاصطناعي دون الكشف عن المعلومات المتعلقة بالهوية.
 #4.17.3    المستوى: 3    الدور: D/V
 تحقق من أن بروتوكولات التقاطع الخاص للمجموعات (PSI) تُمكّن من مطابقة البيانات بشكل آمن للذكاء الاصطناعي الفيدرالي دون كشف مجموعات البيانات الفردية.
 #4.17.4    المستوى: 3    الدور: D/V
 تحقق من أن أنظمة التعلم الآلي بصفر معرفة (ZKML) تمكّن من استنتاجات ذكاء اصطناعي قابلة للتحقق مع دليل تشفير على صحة الحساب.
 #4.17.5    المستوى: 3    الدور: D/V
 تحقق من أن ZK-rollups توفر معالجة معاملات الذكاء الاصطناعي القابلة للتوسع والتي تحافظ على الخصوصية من خلال التحقق الدفعي وتقليل العبء الحسابي.

---

### C4.18 منع هجمات القناة الجانبية

حماية بنية الذكاء الاصطناعي التحتية من هجمات القنوات الجانبية القائمة على التوقيت والطاقة والمجالات الكهرومغناطيسية وذاكرة التخزين المؤقت التي قد تسرّب معلومات حساسة.

 #4.18.1    المستوى: 3    الدور: D/V
 تحقق من أن توقيت استدلال الذكاء الاصطناعي يتم تطبيعه باستخدام خوارزميات ذات وقت ثابت والتعبئة لمنع هجمات استخراج النموذج القائمة على التوقيت.
 #4.18.2    المستوى: 3    الدور: D/V
 تحقق من أن حماية تحليل الطاقة تشمل حقن الضوضاء، وترشيح خط الطاقة، وأنماط تنفيذ عشوائية للأجهزة الذكية.
 #4.18.3    المستوى: 3    الدور: D/V
 تحقق من أن التخفيف من قنوات الجانب الجانبية المعتمدة على الذاكرة التخبئية يستخدم تقسيم الذاكرة التخبئية، والتوزيع العشوائي، وتعليمات التفريغ لمنع تسرب المعلومات.
 #4.18.4    المستوى: 3    الدور: D/V
 تحقق من أن حماية الانبعاثات الكهرومغناطيسية تشمل التدريع، ترشيح الإشارات، والمعالجة العشوائية لمنع هجمات نمط TEMPEST.
 #4.18.5    المستوى: 3    الدور: D/V
 تحقق من أن دفاعات القنوات الجانبية الدقيقة تشمل ضوابط التنفيذ التخميني وتمويه نمط الوصول إلى الذاكرة.

---

### C4.19 أمن الأجهزة المتخصصة والنيورومورفية للذكاء الاصطناعي

تأمين بنى الأجهزة الناشئة للذكاء الاصطناعي بما في ذلك الشرائح النيورومورفية، وFPGAs، وASICs المخصصة، وأنظمة الحوسبة الضوئية.

 #4.19.1    المستوى: 3    الدور: D/V
 تحقق من أن أمان الشريحة العصبية يتضمن تشفير نمط النبضات، حماية أوزان التشابك العصبي، والتحقق من صحة قواعد التعلم المعتمدة على الأجهزة.
 #4.19.2    المستوى: 3    الدور: D/V
 تحقق من أن مسرعات الذكاء الاصطناعي القائمة على FPGA تنفذ تشفير ملف التكوين، وآليات مقاومة العبث، وتحميل التكوين الآمن مع تحديثات مصدقة.
 #4.19.3    المستوى: 3    الدور: D/V
 تحقق من أن أمان الـ ASIC المخصص يشمل معالجات أمان مدمجة على الشريحة، وجذر ثقة مادي، وتخزين مفاتيح آمن مع الكشف عن التلاعب.
 #4.19.4    المستوى: 3    الدور: D/V
 تحقق من أن أنظمة الحوسبة الضوئية تنفذ التشفير الضوئي الآمن كمياً، والتبديل الفوتوني الآمن، ومعالجة الإشارات الضوئية المحمية.
 #4.19.5    المستوى: 3    الدور: D/V
 تحقق من أن شرائح الذكاء الاصطناعي الهجينة التناظرية-الرقمية تشمل حسابًا تناظريًا آمنًا، وتخزين أوزان محمي، وتحويلًا موثقًا من التناظري إلى الرقمي.

---

### بنية تحتية للحوسبة تحافظ على الخصوصية C4.20

تنفيذ ضوابط البنية التحتية للحوسبة التي تحافظ على الخصوصية لحماية البيانات الحساسة أثناء معالجة وتحليل الذكاء الاصطناعي.

 #4.20.1    المستوى: 3    الدور: D/V
 تحقق من أن بنية التشفير التماثلي تمكن من إجراء الحسابات المشفرة على أحمال العمل الحساسة للذكاء الاصطناعي مع التحقق من سلامة التشفير ورصد الأداء.
 #4.20.2    المستوى: 3    الدور: D/V
 تحقق من أن أنظمة استرجاع المعلومات الخاصة تمكّن من استعلام قواعد البيانات دون الكشف عن أنماط الاستعلام، مع حماية تشفيرية لأنماط الوصول.
 #4.20.3    المستوى: 3    الدور: D/V
 تحقق من أن بروتوكولات الحساب التعاوني الآمن تتيح استدلال الذكاء الاصطناعي مع الحفاظ على الخصوصية دون كشف المدخلات الفردية أو العمليات الحسابية الوسيطة.
 #4.20.4    المستوى: 3    الدور: D/V
 تحقق من أن إدارة المفاتيح التي تحافظ على الخصوصية تشمل توليد المفاتيح الموزعة، والتشفير بالعتبة، وتدوير المفاتيح الآمن مع الحماية المدعومة بالأجهزة.
 #4.20.5    المستوى: 3    الدور: D/V
 تحقق من أن أداء الحوسبة المحافظة على الخصوصية يتم تحسينه من خلال التجميع، والتخزين المؤقت، وتسريع الأجهزة مع الحفاظ على ضمانات الأمان التشفيري.

---

### C4.15 إطار عمل الوكيل أمان تكامل السحابة والنشر الهجين

ضوابط الأمان لأطر العمل الخاصة بالوكلاء المتكاملة مع السحابة ذات البنى الهجينة المحلية/السحابية.

 #4.15.1    المستوى: 1    الدور: D/V
 تحقق من أن تكامل التخزين السحابي يستخدم التشفير من الطرف إلى الطرف مع إدارة المفاتيح التي يتحكم بها الوكيل.
 #4.15.2    المستوى: 2    الدور: D/V
 تحقق من أن حدود أمان النشر الهجين محددة بوضوح مع قنوات اتصال مشفرة.
 #4.15.3    المستوى: 2    الدور: D/V
 تحقق من أن الوصول إلى موارد السحابة يتضمن التحقق بنهج الثقة الصفرية مع المصادقة المستمرة.
 #4.15.4    المستوى: 3    الدور: D/V
 تحقق من تطبيق متطلبات محل تواجد البيانات من خلال التصديق التشفيري لمواقع التخزين.
 #4.15.5    المستوى: 3    الدور: D/V
 تحقق من أن تقييمات أمان مزود الخدمة السحابية تشمل نمذجة التهديدات وتقييم المخاطر الخاصة بالوكيل.

---

### المراجع

NIST Cybersecurity Framework 2.0
CIS Controls v8
OWASP Container Security Verification Standard
Kubernetes Security Best Practices
SLSA Supply Chain Security Framework
NIST SP 800-190: Application Container Security Guide
Cloud Security Alliance: Cloud Controls Matrix
ENISA: Secure Infrastructure Design
NIST SP 800-53: Security Controls for Federal Information Systems
ISO 27001:2022 Information Security Management
NIST AI Risk Management Framework
CIS Kubernetes Benchmark
FIPS 140-2 Security Requirements
NIST SP 800-207: Zero Trust Architecture
IEEE 2857: Privacy Engineering for AI Systems
NIST SP 800-161: Cybersecurity Supply Chain Risk Management
NIST Post-Quantum Cryptography Standards
Intel SGX Developer Guide
AMD SEV-SNP White Paper
ARM TrustZone Technology
ZK-SNARKs: A Gentle Introduction
NIST SP 800-57: Cryptographic Key Management
Side-Channel Attack Countermeasures
Neuromorphic Computing Security Challenges
FPGA Security: Fundamentals, Evaluation, and Countermeasures
Microsoft SEAL: Homomorphic Encryption Library
HElib: Homomorphic Encryption Library
PALISADE Lattice Cryptography Library
Differential Privacy: A Survey of Results
Secure Aggregation for Federated Learning
Private Information Retrieval: Concepts and Constructions

## C5 التحكم في الوصول وهوية مكونات الذكاء الاصطناعي والمستخدمين

### هدف التحكم

يتطلب التحكم الفعال في الوصول لأنظمة الذكاء الاصطناعي إدارة هوية قوية، وتفويض يعتمد على السياق، وتنفيذ أثناء التشغيل يتبع مبادئ الثقة الصفرية. تضمن هذه الضوابط أن يتفاعل البشر والخدمات والوكلاء المستقلون فقط مع النماذج والبيانات والموارد الحاسوبية ضمن نطاقات ممنوحة صراحة، مع وجود قدرات التحقق المستمر والتدقيق.

---

### C5.1 إدارة الهوية والمصادقة

إنشاء هويات مدعومة بالتشفير لجميع الكيانات مع المصادقة متعددة العوامل للعمليات ذات الامتياز.

 #5.1.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع المستخدمين البشر والمبادئ الخدمية يقومون بالمصادقة عبر مزود هوية مؤسسي مركزي باستخدام بروتوكولات OIDC/SAML مع تعيينات هوية فريدة إلى الرموز المميزة (دون وجود حسابات أو بيانات اعتماد مشتركة).
 #5.1.2    المستوى: 1    الدور: D/V
 تحقق من أن العمليات عالية الخطورة (نشر النموذج، تصدير الأوزان، الوصول إلى بيانات التدريب، تغييرات تكوين الإنتاج) تتطلب مصادقة متعددة العوامل أو مصادقة تصعيدية مع إعادة التحقق من الجلسة.
 #5.1.3    المستوى: 2    الدور: D
 تحقق من أن المديرين الجدد يخضعون لإثبات الهوية بما يتوافق مع معيار NIST 800-63-3 IAL-2 أو معايير مكافئة قبل حصولهم على وصول إلى نظام الإنتاج.
 #5.1.4    المستوى: 2    الدور: V
 تحقق من إجراء مراجعات الوصول بشكل ربع سنوي مع الكشف التلقائي عن الحسابات الخاملة، وتطبيق دورات تبديل بيانات الاعتماد، وسير العمل الخاص بإلغاء توفير الوصول.
 #5.1.5    المستوى: 3    الدور: D/V
 تحقق من أن وكلاء الذكاء الاصطناعي الموزع يقومون بالمصادقة عبر تصريحات JWT الموقعة التي لها عمر افتراضي أقصى يبلغ 24 ساعة وتشمل دليلًا تشفيرياً على الأصل.

---

### C5.2 تفويض الموارد وأقل امتياز

تنفيذ ضوابط وصول دقيقة لجميع موارد الذكاء الاصطناعي باستخدام نماذج إذن صريحة وسجلات تدقيق.

 #5.2.1    المستوى: 1    الدور: D/V
 تحقق من أن كل مورد ذكاء اصطناعي (مجموعات البيانات، النماذج، نقاط النهاية، مجموعات المتجهات، مؤشرات التضمين، وحدات الحوسبة) يطبق ضوابط وصول قائمة على الأدوار مع قوائم سماح صريحة وسياسات الرفض الافتراضية.
 #5.2.2    المستوى: 1    الدور: D/V
 تحقق من تطبيق مبادئ الحد الأدنى من الامتيازات بشكل افتراضي على حسابات الخدمة بدءًا من أذونات القراءة فقط، مع اشتراط وجود مبرر تجاري موثق للوصول إلى الكتابة.
 #5.2.3    المستوى: 1    الدور: V
 تحقق من أن جميع تعديلات التحكم في الوصول مرتبطة بطلبات تغيير معتمدة ومسجلة بشكل غير قابل للتغيير مع الطوابع الزمنية، وهويات الفاعلين، ومعرفات الموارد، والفروقات في الأذونات.
 #5.2.4    المستوى: 2    الدور: D
 تحقق من أن تصنيفات بيانات التصنيف (المعلومات الشخصية، المعلومات الصحية المحمية، الخاضعة للرقابة التصديرية، الملكية) تنتقل تلقائيًا إلى الموارد المشتقة (التضمينات، ذاكرات التخزين المؤقت للمطالبات، مخرجات النماذج) مع تطبيق السياسة بشكل متسق.
 #5.2.5    المستوى: 2    الدور: D/V
 تحقق من أن محاولات الوصول غير المصرح به وأحداث تصعيد الامتيازات تُنشئ تنبيهات في الوقت الحقيقي مع البيانات الوصفية السياقية إلى أنظمة SIEM خلال 5 دقائق.

---

### C5.3 تقييم السياسات الديناميكي

نشر محركات التحكم في الوصول المستندة إلى السمات (ABAC) لاتخاذ قرارات التفويض المستندة إلى السياق مع قدرات التدقيق.

 #5.3.1    المستوى: 1    الدور: D/V
 تحقق من أن قرارات التفويض مفرَّغة إلى محرك سياسة مخصص (مثل OPA، Cedar، أو ما يعادلها) يمكن الوصول إليه عبر واجهات برمجة تطبيقات مصدقة مع حماية سلامة تشفيرية.
 #5.3.2    المستوى: 1    الدور: D/V
 تحقق من أن السياسات تُقيّم السمات الديناميكية أثناء وقت التشغيل، بما في ذلك مستوى تخويل المستخدم، وتصنيف حساسية المورد، وسياق الطلب، وعزل المستأجر، والقيود الزمنية.
 #5.3.3    المستوى: 2    الدور: D
 تحقق من أن تعريفات السياسات تتم إدارتها بنظام نسخ الإصدارات، وتتم مراجعتها من قبل الأقران، ويتم التحقق من صحتها من خلال الاختبارات الآلية في خطوط تكامل وتسليم البرمجيات (CI/CD) قبل النشر في بيئة الإنتاج.
 #5.3.4    المستوى: 2    الدور: V
 تحقق من أن نتائج تقييم السياسات تشمل مبررات قرارات منظمة وأنها تُرسل إلى أنظمة SIEM للتحليل الارتباطي وتقرير الامتثال.
 #5.3.5    المستوى: 3    الدور: D/V
 تحقق من أن قيم وقت حياة ذاكرة التخزين المؤقت للسياسات (TTL) لا تتجاوز 5 دقائق للموارد عالية الحساسية و1 ساعة للموارد القياسية مع قدرات إبطال ذاكرة التخزين المؤقت.

---

### C5.4 فرض الأمان في وقت الاستعلام

تنفيذ ضوابط أمان طبقة قاعدة البيانات مع التصفية الإلزامية وسياسات أمان على مستوى الصف.

 #5.4.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع استعلامات قاعدة بيانات المتجهات و SQL تتضمن فلاتر أمان إلزامية (معرف المستأجر، تسميات الحساسية، نطاق المستخدم) يتم فرضها على مستوى محرك قاعدة البيانات، وليس في رمز التطبيق.
 #5.4.2    المستوى: 1    الدور: D/V
 تأكد من تمكين سياسات أمان مستوى الصف (RLS) وإخفاء الحقول على مستوى الحقل مع توارث السياسات لجميع قواعد بيانات المتجهات، وفهارس البحث، ومجموعات بيانات التدريب.
 #5.4.3    المستوى: 2    الدور: D
 تحقق من أن تقييمات التفويض الفاشلة ستمنع "هجمات الوكيل المشوش" عن طريق إيقاف الاستعلامات فورًا وإرجاع رموز أخطاء تفويض صريحة بدلاً من إرجاع مجموعات نتائج فارغة.
 #5.4.4    المستوى: 2    الدور: V
 تحقق من أن تأخير تقييم السياسة يتم مراقبته باستمرار مع وجود تنبيهات آلية لحالات انتهاء المهلة التي قد تمكن من تجاوز التفويض.
 #5.4.5    المستوى: 3    الدور: D/V
 تحقق من أن آليات إعادة محاولة الاستعلام تقوم بإعادة تقييم سياسات التفويض لأخذ تغييرات الأذونات الديناميكية في الاعتبار ضمن جلسات المستخدم النشطة.

---

### تصفية الإخراج في C5.5 ومنع فقدان البيانات

نشر ضوابط المعالجة اللاحقة لمنع كشف البيانات غير المصرح به في المحتوى الذي تم إنشاؤه بواسطة الذكاء الاصطناعي.

 #5.5.1    المستوى: 1    الدور: D/V
 تحقق من أن آليات التصفية بعد الاستدلال تفحص وتحجب معلومات الهوية الشخصية غير المصرح بها، والمعلومات المصنفة، والبيانات الملكية قبل تسليم المحتوى للطالبين.
 #5.5.2    المستوى: 1    الدور: D/V
 تحقق من أن الاقتباسات والمراجع ونسب المصدر في مخرجات النموذج تم التحقق من صحتها وفقًا لصلاحيات المتصل، ويتم إزالتها إذا تم اكتشاف وصول غير مصرح به.
 #5.5.3    المستوى: 2    الدور: D
 التحقق من أن قيود تنسيق الإخراج (ملفات PDF المعقمة، الصور التي تمت إزالة بيانات التعريف منها، أنواع الملفات المعتمدة) يتم فرضها بناءً على مستويات أذونات المستخدم وتصنيفات البيانات.
 #5.5.4    المستوى: 2    الدور: V
 تحقق من أن خوارزميات التعتيم حتمية، وخاضعة للتحكم في الإصدارات، وتحافظ على سجلات التدقيق لدعم تحقيقات الامتثال والتحليل الجنائي.
 #5.5.5    المستوى: 3    الدور: V
 تحقق من أن أحداث الحجب عالية الخطورة تُولّد سجلات تكيُّفية تتضمن تجزئات مشفرة للمحتوى الأصلي بهدف الاسترجاع الجنائي دون تعريض البيانات.

---

### C5.6 العزل متعدد المستأجرين

ضمان العزل التشفيري والمنطقي بين المستأجرين في البنية التحتية المشتركة للذكاء الاصطناعي.

 #5.6.1    المستوى: 1    الدور: D/V
 تحقق من أن مساحات الذاكرة، مخازن التضمين، مدخلات الكاش، والملفات المؤقتة مفصولة حسب مساحة الأسماء لكل مستأجر مع مسح آمن عند حذف المستأجر أو إنهاء الجلسة.
 #5.6.2    المستوى: 1    الدور: D/V
 تحقق من أن كل طلب API يتضمن معرف مستأجر مصادق يتم التحقق منه بشكل تشفير بمقارنة سياق الجلسة وصلاحيات المستخدم.
 #5.6.3    المستوى: 2    الدور: D
 تحقق من أن سياسات الشبكة تنفذ قواعد الرفض الافتراضي للتواصل بين المستأجرين داخل شبكات الخدمة ومنصات تنسيق الحاويات.
 #5.6.4    المستوى: 3    الدور: D
 تحقق من أن مفاتيح التشفير فريدة لكل مستأجر مع دعم مفتاح تدار من قبل العميل (CMK) وعزل تشفير بين مخازن بيانات المستأجرين.

---

### C5.7 تفويض الوكيل المستقل

التحكم في أذونات عملاء الذكاء الاصطناعي والأنظمة المستقلة من خلال رموز القدرات المحددة والتفويض المستمر.

 #5.7.1    المستوى: 1    الدور: D/V
 تحقق من أن الوكلاء المستقلين يتلقون رموز صلاحية محددة النطاق تُدرج صراحة الإجراءات المسموح بها، والموارد التي يمكن الوصول إليها، والحدود الزمنية، والقيود التشغيلية.
 #5.7.2    المستوى: 1    الدور: D/V
 تحقق من أن القدرات عالية المخاطر (الوصول إلى نظام الملفات، تنفيذ الشيفرة، استدعاءات API الخارجية، المعاملات المالية) معطلة بشكل افتراضي وتتطلب تفويضات صريحة للتفعيل مع مبررات تجارية.
 #5.7.3    المستوى: 2    الدور: D
 تحقق من أن رموز القدرات مرتبطة بجلسات المستخدم، وتشتمل على حماية التكامل التشفيري، وتضمن عدم إمكانية تخزينها أو إعادة استخدامها في سيناريوهات عدم الاتصال.
 #5.7.4    المستوى: 2    الدور: V
 تحقق من أن الإجراءات التي يبدأها الوكيل تخضع لتفويض ثانوي من خلال محرك سياسة التحكم في الوصول بناءً على السمات (ABAC) مع تقييم السياق الكامل وتسجيل التدقيق.
 #5.7.5    المستوى: 3    الدور: V
 تحقق من أن شروط خطأ الوكيل ومعالجة الاستثناءات تتضمن معلومات نطاق القدرة لدعم تحليل الحوادث والتحقيق الجنائي.

---

### المراجع

#### المعايير والأُطُر

NIST SP 800-63-3: Digital Identity Guidelines
Zero Trust Architecture – NIST SP 800-207
OWASP Application Security Verification Standard (AISVS)
​
#### أدلة التنفيذ

Identity and Access Management in the AI Era: 2025 Guide – IDSA
Attribute-Based Access Control with OPA – Permify
How We Designed Cedar to Be Intuitive, Fast, and Safe – AWS
​
#### الأمن المخصص للذكاء الاصطناعي

Row Level Security in Vector DBs for RAG – Bluetuple.ai
Tenant Isolation in Multi-Tenant Systems – WorkOS
Handling AI Agent Permissions – Stytch
OWASP Top 10 for Large Language Model Applications

## C6 أمان سلسلة التوريد للنماذج والأُطُر والبيانات

### هدف التحكم

تستغل هجمات سلسلة إمداد الذكاء الاصطناعي النماذج أو الأطر أو مجموعات البيانات التابعة لأطراف ثالثة لزرع أبواب خلفية أو تحيز أو تعليمات قابلة للاستغلال. توفر هذه الضوابط تتبعًا شاملاً للأصل وإدارة الثغرات والمراقبة لحماية دورة حياة النموذج بأكملها.

---

### C6.1 التحقق من صحة النموذج المدرب مسبقًا وأصله

قم بتقييم والتحقق من أصول النماذج من الطرف الثالث، التراخيص، والسلوكيات الخفية قبل أي تعديل دقيق أو نشر.

 #6.1.1    المستوى: 1    الدور: D/V
 تحقق من أن كل نموذج تابع لطرف ثالث يتضمن سجل منشأ موقع يحدد مستودع المصدر ورمز الالتزام.
 #6.1.2    المستوى: 1    الدور: D/V
 تحقق من فحص النماذج للكشف عن الطبقات الخبيثة أو المحفزات الطروادة باستخدام أدوات آلية قبل الاستيراد.
 #6.1.3    المستوى: 2    الدور: D
 تحقق من أن تحسين التعلم بالنقل ينجح في اجتياز التقييم العدائي للكشف عن السلوكيات الخفية.
 #6.1.4    المستوى: 2    الدور: V
 تحقق من تسجيل تراخيص النماذج، وعلامات التحكم في التصدير، وبيانات أصل البيانات في إدخال قائمة المكونات الخاصة بالتعلم الآلي (ML-BOM).
 #6.1.5    المستوى: 3    الدور: D/V
 تحقق من بقاء النماذج عالية الخطورة (الأوزان المحمّلة علنًا، المنشئون غير الموثوقين) في الحجر الصحي حتى يتم مراجعتها والموافقة عليها بشريًا.

---

### C6.2 مسح الأطر والمكتبات

قم بفحص أُطُر ومكتبات التعلم الآلي باستمرار للكشف عن نقاط الضعف الأمنية (CVE) والرمز الخبيث للحفاظ على أمان طبقة وقت التشغيل.

 #6.2.1    المستوى: 1    الدور: D/V
 تحقق من أن خطوط أنابيب CI تقوم بتشغيل ماسحات الاعتماديات على أُطُر الذكاء الاصطناعي والمكتبات الحيوية.
 #6.2.2    المستوى: 1    الدور: D/V
 تحقق من أن الثغرات الأمنية الحرجة (CVSS ≥ 7.0) تمنع الترقية إلى صور الإنتاج.
 #6.2.3    المستوى: 2    الدور: D
 تحقق من أن تحليل الشيفرة الثابتة يعمل على مكتبات التعلم الآلي المنسوخة أو الموردة.
 #6.2.4    المستوى: 2    الدور: V
 تحقق من أن مقترحات ترقية الإطار تتضمن تقييمًا لتأثير الأمان يشير إلى مصادر CVE العامة.
 #6.2.5    المستوى: 3    الدور: V
 تحقق من أن مستشعرات وقت التشغيل تنبه عند تحميل مكتبات ديناميكية غير متوقعة تنحرف عن SBOM الموقع.

---

### C6.3 تثبيت التبعيات والتحقق منها

قم بتثبيت كل اعتماد على ملخصات غير قابلة للتغيير وأعد بناء البرامج لضمان الحصول على قطع فنية متطابقة وخالية من العبث.

 #6.3.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع مديري الحزم يفرضون تثبيت الإصدارات من خلال ملفات القفل.
 #6.3.2    المستوى: 1    الدور: D/V
 تحقق من استخدام الملخصات الثابتة بدلاً من العلامات القابلة للتغيير في مراجع الحاويات.
 #6.3.3    المستوى: 2    الدور: D
 تحقق من أن فحوصات البنية القابلة للتكرار تقوم بمقارنة التجزئات عبر عمليات التكامل المستمر لضمان الحصول على مخرجات متطابقة.
 #6.3.4    المستوى: 2    الدور: V
 تحقق من تخزين شهادات البناء لمدة 18 شهرًا لتتبع التدقيق.
 #6.3.5    المستوى: 3    الدور: D
 تحقق من أن الاعتمادات المنتهية الصلاحية تُحفّز طلبات السحب التلقائية لتحديث أو استنساخ الإصدارات المثبتة.

---

### C6.4 تطبيق مصداقية المصدر

السماح بتنزيل القطع الأثرية فقط من مصادر معتمدة من المنظمة ومتحقق من صحتها تشفيرياً وحظر كل شيء آخر.

 #6.4.1    المستوى: 1    الدور: D/V
 تحقق من أن أوزان النموذج، ومجموعات البيانات، والحاويات تم تنزيلها فقط من النطاقات المعتمدة أو السجلات الداخلية.
 #6.4.2    المستوى: 1    الدور: D/V
 تحقق من أن توقيعات Sigstore/Cosign تؤكد هوية الناشر قبل أن يتم تخزين الملفات مؤقتًا محليًا.
 #6.4.3    المستوى: 2    الدور: D
 تحقق من أن الوكلاء الخارجيين يمنعون تنزيلات القطع الفنية غير المصادقة لفرض سياسة المصدر الموثوق.
 #6.4.4    المستوى: 2    الدور: V
 تحقق من مراجعة قوائم السماح للمستودع كل ثلاثة أشهر مع تقديم دليل على المبرر التجاري لكل إدخال.
 #6.4.5    المستوى: 3    الدور: V
 تحقق من أن انتهاكات السياسات تؤدي إلى عزل العناصر والرجوع إلى الوراء في عمليات التشغيل التابعة لخط الأنابيب.

---

### C6.5 تقييم مخاطر مجموعات البيانات من جهات خارجية

قم بتقييم مجموعات البيانات الخارجية للتحقق من التسميم والتحيز والامتثال القانوني، ومراقبتها طوال دورة حياتها.

 #6.5.1    المستوى: 1    الدور: D/V
 تحقق من أن مجموعات البيانات الخارجية تخضع لتقييم مخاطر التسميم (مثل بصمة البيانات، اكتشاف القيم الشاذة).
 #6.5.2    المستوى: 1    الدور: D
 تحقق من أن مقاييس التحيز (التكافؤ الديموغرافي، تكافؤ الفرص) تُحسب قبل الموافقة على مجموعة البيانات.
 #6.5.3    المستوى: 2    الدور: V
 تحقق من أن أصول و شروط الترخيص لمجموعات البيانات مَسجلة في مدخلات ML‑BOM.
 #6.5.4    المستوى: 2    الدور: V
 تحقق من أن المراقبة الدورية تكشف الانحراف أو الفساد في مجموعات البيانات المستضافة.
 #6.5.5    المستوى: 3    الدور: D
 تحقق من إزالة المحتوى غير المسموح به (حقوق الطبع والنشر، المعلومات الشخصية التعريفية) عبر التنظيف الآلي قبل التدريب.

---

### مراقبة هجمات سلسلة التوريد C6.6

اكتشف تهديدات سلسلة التوريد مبكرًا من خلال تغذيات CVE، وتحليلات سجلات التدقيق، ومحاكاة فرق الهجوم.

 #6.6.1    المستوى: 1    الدور: V
 تحقق من أن سجلات تدقيق CI/CD تتدفق إلى اكتشافات SIEM للكشف عن سحب الحزم الشاذة أو خطوات البناء المعطوبة.
 #6.6.2    المستوى: 2    الدور: D
 تحقق من أن كتب لعب الاستجابة للحوادث تتضمن إجراءات التراجع للنماذج أو المكتبات المخترقة.
 #6.6.3    المستوى: 3    الدور: V
 تحقق من أن إثراء معلومات التهديد يقوم بوضع علامات لمؤشرات محددة بتقنية التعلم الآلي (مثل مؤشرات تسريب نموذج التسميم) أثناء فرز التنبيهات.

---

### C6.7 قائمة المواد الخاصة بالتعلم الآلي (ML-BOM) لقطع نموذج التعلم

إنشاء وتوقيع قوائم المواد البرمجية المفصلة الخاصة بالتعلم الآلي (ML‑BOMs) حتى يتمكن المستهلكون في المراحل اللاحقة من التحقق من سلامة المكونات وقت النشر.

 #6.7.1    المستوى: 1    الدور: D/V
 تحقق من أن كل نموذج ينتج ملف ML‑BOM يسرد مجموعات البيانات، الأوزان، المعلمات الفائقة، والتراخيص.
 #6.7.2    المستوى: 1    الدور: D/V
 تحقق من أن توليد ML‑BOM والتوقيع بواسطة Cosign يتمان تلقائيًا في CI وأنهما مطلوبان للدمج.
 #6.7.3    المستوى: 2    الدور: D
 تحقق من أن فحوصات اكتمال ML-BOM تفشل في عملية البناء إذا كان أي من بيانات مكونات الميتا (التجزئة، الترخيص) مفقودًا.
 #6.7.4    المستوى: 2    الدور: V
 تحقق من أن المستهلكين النهائيين يمكنهم استعلام ML-BOMs عبر API للتحقق من صحة النماذج المستوردة أثناء وقت النشر.
 #6.7.5    المستوى: 3    الدور: V
 تأكد من أن قوائم المواد في التعلم الآلي (ML‑BOMs) محكومة بالإصدار ويتم مقارنة النسخ لاكتشاف التعديلات غير المصرح بها.

---

### المراجع

ML Supply Chain Compromise – MITRE ATLAS
Supply‑chain Levels for Software Artifacts (SLSA)
CycloneDX – Machine Learning Bill of Materials
What is Data Poisoning? – SentinelOne
Transfer Learning Attack – OWASP ML Security Top 10
AI Data Security Best Practices – CISA
Secure CI/CD Supply Chain – Sumo Logic
AI & Transparency: Protect ML Models – ReversingLabs
SBOM Overview – CISA
Training Data Poisoning Guide – Lakera.ai
Dependency Pinning for Reproducible Python – Medium

## سلوك نموذج C7، التحكم في المخرجات وضمان السلامة

### هدف التحكم

يجب أن تكون مخرجات النماذج منظمة، موثوقة، آمنة، قابلة للتفسير، ومراقبة باستمرار في بيئة الإنتاج. يؤدي ذلك إلى تقليل الأوهام، تسربات الخصوصية، المحتوى الضار، والإجراءات الخارجة عن السيطرة، مع زيادة ثقة المستخدم والامتثال التنظيمي.

---

### C7.1 فرض تنسيق المخرجات

توقف المخططات الصارمة، وفك التشفير المقيد، والتحقق اللاحق المحتوى المشوه أو الضار قبل انتشاره.

 #7.1.1    المستوى: 1    الدور: D/V
 تأكد من توفير مخططات الاستجابة (مثل مخططات JSON) في موجه النظام وأن يتم التحقق من صحة كل مخرجات بشكل تلقائي؛ حيث تؤدي المخرجات غير المطابقة إلى إصلاحها أو رفضها.
 #7.1.2    المستوى: 1    الدور: D/V
 تحقق من تمكين فك التشفير المقيد (رموز التوقف، التعبيرات النمطية، الحد الأقصى لعدد الرموز) لمنع حدوث تجاوز أو قنوات جانبية حقن المطالبات.
 #7.1.3    المستوى: 2    الدور: D/V
 تحقق من أن المكونات التالية تتعامل مع المخرجات على أنها غير موثوقة وتقوم بالتحقق منها مقابل المخططات أو أدوات فك التسلسل الآمنة ضد الحقن.
 #7.1.4    المستوى: 3    الدور: V
 تحقق من تسجيل أحداث المخرجات غير الصحيحة، وتقييد معدل ظهورها، وإظهارها في المراقبة.

---

### C7.2 اكتشاف الهلاوس والتخفيف منها

تقدير عدم اليقين واستراتيجيات التراجع تحد من الإجابات المختلقة.

 #7.2.1    المستوى: 1    الدور: D/V
 تحقق من أن احتمالات السجل على مستوى الرموز، أو التناسق الذاتي للمجموعة، أو كاشفات الهلوسة المدربة بدقة تعطي درجة ثقة لكل إجابة.
 #7.2.2    المستوى: 1    الدور: D/V
 تحقق من أن الردود التي تقع دون عتبة ثقة قابلة للتكوين تؤدي إلى تشغيل تدفقات عمل احتياطية (مثل التوليد المعزز بالاستخراج، النموذج الثانوي، أو المراجعة البشرية).
 #7.2.3    المستوى: 2    الدور: D/V
 تحقق من أن حوادث الهلوسة مُوسمة ببيانات تعريف السبب الجذري ومُدخلة إلى خطوط معالجة ما بعد الوفاة والتعديل الدقيق.
 #7.2.4    المستوى: 3    الدور: D/V
 تحقق من إعادة معايرة الحدود والكاشفات بعد التحديثات الكبيرة للنموذج أو قاعدة المعرفة.
 #7.2.5    المستوى: 3    الدور: V
 تحقق من أن تصورات لوحة البيانات تتعقب معدلات الهلوسة.

---

### C7.3 تصفية الأمان والخصوصية للمخرجات

تعمل عوامل تصفية السياسات وتغطية الفريق الأحمر على حماية المستخدمين والبيانات السرية.

 #7.3.1    المستوى: 1    الدور: D/V
 تحقق من أن المصنفات قبل وبعد التوليد تمنع الخطاب الكراهية، والتحرش، وإيذاء النفس، والمحتوى المتطرف، والمحتوى الجنسي الصريح المتوافق مع السياسة.
 #7.3.2    المستوى: 1    الدور: D/V
 تحقق من أن كشف معلومات التعريف الشخصية (PII) وبيانات بطاقات الدفع (PCI) والتعتيم التلقائي يتم تنفيذهما في كل استجابة؛ الانتهاكات تؤدي إلى رفع بلاغ خصوصية.
 #7.3.3    المستوى: 2    الدور: D
 تحقق من أن علامات السرية (مثل الأسرار التجارية) تنتقل عبر الوسائط المختلفة لمنع التسرب في النصوص أو الصور أو الشيفرات.
 #7.3.4    المستوى: 3    الدور: D/V
 تحقق من أن محاولات تجاوز المرشح أو التصنيفات عالية المخاطر تتطلب موافقة ثانوية أو إعادة مصادقة المستخدم.
 #7.3.5    المستوى: 3    الدور: D/V
 تحقق من أن عتبات التصفية تعكس الولايات القضائية القانونية وسياق عمر المستخدم / دوره.

---

### C7.4 تحديد المخرجات والإجراءات

تقييدات المعدل وبوابات الموافقة تمنع الإساءة والاستقلالية المفرطة.

 #7.4.1    المستوى: 1    الدور: D
 تحقق من أن الحصص لكل مستخدم ولكل مفتاح API تحد من الطلبات، والرموز، والتكلفة مع الاعتماد على التراجع الأسي في حالة أخطاء 429.
 #7.4.2    المستوى: 1    الدور: D/V
 تحقق من أن الإجراءات المميزة (كتابة الملفات، تنفيذ الأكواد، مكالمات الشبكة) تتطلب الموافقة بناءً على السياسة أو تدخل بشري.
 #7.4.3    المستوى: 2    الدور: D/V
 تحقق من أن فحوصات التناسق بين الأنماط المختلفة تضمن ألا يمكن استخدام الصور، الشفرات، والنصوص المولدة لنفس الطلب لتهريب محتوى خبيث.
 #7.4.4    المستوى: 2    الدور: D
 تحقق من أن عمق تفويض الوكيل، وحدود التكرار، وقوائم الأدوات المسموح بها تم تكوينها بشكل صريح.
 #7.4.5    المستوى: 3    الدور: V
 تحقق من أن انتهاك الحدود يصدر أحداث أمان مُنظمة للتحميل في نظم إدارة معلومات وأحداث الأمان (SIEM).

---

### C7.5 توضيح نواتج الإخراج

الإشارات الشفافة تحسن ثقة المستخدم وتصحيح الأخطاء الداخلي.

 #7.5.1    المستوى: 2    الدور: D/V
 تحقق من عرض درجات الثقة الموجهة للمستخدم أو ملخصات السبب الموجز عندما يُعتبر التقييم المخاطر مناسبًا.
 #7.5.2    المستوى: 2    الدور: D/V
 تحقق من أن التفسيرات المُولدة تتجنب الكشف عن التعليمات البرمجية الحساسة للنظام أو البيانات المملوكة.
 #7.5.3    المستوى: 3    الدور: D
 تحقق من أن النظام يلتقط احتمالات السجل على مستوى الرموز أو خرائط الانتباه ويخزنها للفحص المصرح به.
 #7.5.4    المستوى: 3    الدور: V
 تحقق من أن عناصر الشرح تخضع للتحكم في الإصدارات جنبًا إلى جنب مع إصدارات النماذج لضمان إمكانية التدقيق.

---

### C7.6 تكامل المراقبة

المراقبة في الوقت الحقيقي تغلق الحلقة بين التطوير والإنتاج.

 #7.6.1    المستوى: 1    الدور: D
 تحقق من أن المقاييس (انتهاكات المخطط، معدل الهلوسة، السمية، تسريبات المعلومات الشخصية، الكمون، التكلفة) تتدفق إلى منصة مراقبة مركزية.
 #7.6.2    المستوى: 1    الدور: V
 تحقق من تحديد عتبات التنبيه لكل مقياس أمان، مع وجود مسارات تصعيد للطوارئ.
 #7.6.3    المستوى: 2    الدور: V
 تحقق من أن لوحات المعلومات تربط بين الشذوذ في المخرجات ونموذج/إصدار، وعلم الميزة، وتغييرات بيانات المصدر الأعلى.
 #7.6.4    المستوى: 2    الدور: D/V
 تحقق من أن بيانات المراقبة تغذي مرة أخرى عمليات إعادة التدريب أو الضبط الدقيق أو تحديث القواعد داخل سير عمل MLOps الموثق.
 #7.6.5    المستوى: 3    الدور: V
 تحقق من أن خطوط المراقبة قد خضعت لاختبار الاختراق ويتم التحكم في الوصول إليها لتجنب تسرب السجلات الحساسة.

---

### 7.7 تدابير حماية الوسائط التوليدية

ضمان ألا تقوم أنظمة الذكاء الاصطناعي بإنشاء محتوى وسائط غير قانوني أو ضار أو غير مصرح به من خلال فرض قيود السياسات، والتحقق من صحة المخرجات، وقابلية التتبع.

 #7.7.1    المستوى: 1    الدور: D/V
 تحقق من أن تعليمات النظام وتعليمات المستخدم تحظر صراحةً إنشاء وسائط عميقة زائفة غير قانونية أو ضارة أو غير توافقية (مثل الصور أو الفيديو أو الصوت).
 #7.7.2    المستوى: 2    الدور: D/V
 تحقق من أن الطلبات تتم تصفيتها لمنع محاولات إنشاء انتحال شخصيات، أو تركيب عميق جنسي صريح، أو وسائط تصور أفرادًا حقيقيين دون موافقة.
 #7.7.3    المستوى: 2    الدور: V
 تحقق من أن النظام يستخدم تجزئة الإدراك البصري، أو اكتشاف العلامات المائية، أو البصمات لمنع النسخ غير المصرح به للوسائط المحمية بحقوق الطبع والنشر.
 #7.7.4    المستوى: 3    الدور: D/V
 تحقق من أن جميع الوسائط المُنشأة مُوقّعة تشفيرياً، أو مُعلّمة بعلامة مائية، أو مضمنة ببيانات أصول مقاومة للتلاعب لضمان إمكانية التتبع في المراحل اللاحقة.
 #7.7.5    المستوى: 3    الدور: V
 تأكد من أن محاولات التجاوز (مثل التعتيم على المطالبات، اللغة العامية، الصياغة العدائية) يتم اكتشافها وتسجيلها وتقييد معدلها؛ وأن الإساءة المتكررة تُعرض على أنظمة المراقبة.

### المراجع

NIST AI Risk Management Framework
ISO/IEC 42001:2023 – AI Management System
OWASP Top-10 for Large Language Model Applications (2025)
Improper Output Handling – OWASP LLM05:2025
Practical Techniques to Constrain LLM Output
Dataiku – Structured Text Generation Guide
VL-Uncertainty: Detecting Hallucinations
HaDeMiF: Hallucination Detection & Mitigation
Building Confidence in LLM Outputs
Explainable AI & LLMs
LLM Red-Teaming Guide
Sensitive Information Disclosure in LLMs
LangChain – Chat Model Rate Limiting
OpenAI Rate-Limit & Exponential Back-off
Arize AI – LLM Observability Platform

## ذاكرة C8، والأضمات، وأمن قواعد بيانات المتجهات

### هدف التحكم

تعمل التضمينات وقواعد متجهات التخزين كـ "ذاكرة حية" لأنظمة الذكاء الاصطناعي المعاصرة، حيث تستقبل بيانات المستخدم بشكل مستمر وتعيد عرضها ضمن سياقات النماذج عبر التوليد المدعوم بالاسترجاع (RAG). إذا تركت هذه الذاكرة بدون حوكمة، فقد تكشف عن بيانات شخصية قابلة للتعريف (PII)، أو تنتهك الموافقة، أو يمكن عكسها لإعادة بناء النص الأصلي. الهدف من هذه المجموعة من الضوابط هو تعزيز خطوط أنابيب الذاكرة وقواعد بيانات المتجهات بحيث يكون الوصول بأقل امتياز ممكن، وتكون التضمينات محافظًا على الخصوصية، وتنتهي صلاحية المتجهات المخزنة أو يمكن سحبها عند الطلب، كما أن ذاكرة كل مستخدم لا تلوث مطالبات أو إكمالات مستخدم آخر.

---

### C8.1 ضوابط الوصول على الذاكرة ومؤشرات RAG

فرض ضوابط وصول دقيقة على كل مجموعة متجهات.

 #8.1.1    المستوى: 1    الدور: D/V
 تحقق من أن قواعد التحكم في الوصول على مستوى الصف/المجال تحد من عمليات الإدراج والحذف والاستعلام لكل مستأجر أو مجموعة أو وسم المستند.
 #8.1.2    المستوى: 1    الدور: D/V
 تحقق من أن مفاتيح API أو JWTs تحمل مطالبات محددة النطاق (مثل معرفات المجموعات، أفعال الإجراءات) ويتم تدويرها على الأقل كل ثلاثة أشهر.
 #8.1.3    المستوى: 2    الدور: D/V
 تحقق من اكتشاف محاولات تصعيد الامتيازات (مثل استعلامات التشابه عبر المساحات الاسمية) وتسجيلها في نظام إدارة المعلومات والأحداث الأمنية (SIEM) خلال 5 دقائق.
 #8.1.4    المستوى: 2    الدور: D/V
 تحقق من أن قاعدة بيانات المتجهات تسجل تدقيق الموضوع-المُعرف، العملية، معرف المتجه/المجال الاسمي، عتبة التشابه، وعدد النتائج.
 #8.1.5    المستوى: 3    الدور: V
 تحقق من أن قرارات الوصول يتم اختبارها للكشف عن عيوب التجاوز كلما تم ترقية المحركات أو تغيّرت قواعد تقسيم الفهرس.

---

### C8.2 تنقية وتحقق التضمين

قم بفحص النص مسبقًا للكشف عن المعلومات الشخصية المعروفة، وقم بحجبها أو تمويهها قبل تحويلها إلى متجهات، وبصفة اختيارية قم بمعالجة التمثيلات المضمنة لاحقًا لإزالة الإشارات المتبقية.

 #8.2.1    المستوى: 1    الدور: D/V
 تحقق من أن المعلومات الشخصية المعروفة (PII) والبيانات المنظمة يتم كشفها عبر المصنفات الآلية ويتم إخفاؤها أو ترميزها بالرموز أو حذفها قبل التضمين.
 #8.2.2    المستوى: 1    الدور: D
 تحقق من أن خطوط أنابيب التضمين ترفض أو تضع في الحجز المدخلات التي تحتوي على كود قابل للتنفيذ أو آثار غير متوافقة مع UTF-8 يمكن أن تسمم الفهرس.
 #8.2.3    المستوى: 2    الدور: D/V
 تحقق من تطبيق التنقية التفاضلية المحلية أو التفاضلية المقياسية على تمثيلات الجمل التي تقل المسافة بينها وبين أي رمز معلومات شخصية معرف بعتبة قابلة للتكوين.
 #8.2.4    المستوى: 2    الدور: V
 تحقق من أن فعالية التنقية (مثل استدعاء إخفاء المعلومات الشخصية، والانحراف الدلالي) يتم التحقق منها على الأقل نصف سنويًا مقابل مجموعات البيانات المرجعية.
 #8.2.5    المستوى: 3    الدور: D/V
 تحقق من أن إعدادات التنقية محكومة بالإصدار وأن التغييرات تخضع لمراجعة الأقران.

---

### C8.3 انتهاء صلاحية الذاكرة، الإلغاء والحذف

قانون حماية البيانات العامة (GDPR) "الحق في أن تُنسى" والقوانين المشابهة تتطلب المسح في الوقت المناسب؛ لذلك يجب أن تدعم مخازن المتجهات أوقات العمر الافتراضي (TTL)، والحذف النهائي، ووضع شواهد القبور حتى لا يمكن استرداد المتجهات الملغاة أو إعادة فهرستها.

 #8.3.1    المستوى: 1    الدور: D/V
 تحقق من أن كل سجل متجه وبيانات تعريف يحملان فترة صلاحية (TTL) أو تسمية احتفاظ صريحة تُحترم بواسطة مهام التنظيف الآلي.
 #8.3.2    المستوى: 1    الدور: D/V
 تحقق من أن طلبات الحذف التي initiated by المستخدم تقوم بحذف المتجهات والبيانات الوصفية ونسخ الكاش والفهارس المشتقة خلال 30 يومًا.
 #8.3.3    المستوى: 2    الدور: D
 تحقق من أن الحذف المنطقي يتبعه تمزيق تشفير كتلات التخزين إذا كان الجهاز يدعم ذلك، أو بتدمير مفتاح خزنة المفاتيح.
 #8.3.4    المستوى: 3    الدور: D/V
 تحقق من استبعاد المتجهات المنتهية الصلاحية من نتائج البحث عن أقرب الجيران في أقل من 500 مللي ثانية بعد الانتهاء.

---

### C8.4 منع الانعكاس والتسرب في التضمين

الدفاعات الحديثة—تركيب الضوضاء، شبكات الإسقاط، تشويش العصبون الخصوصي، وتشفير طبقة التطبيق—يمكن أن تقلل من معدلات عكس الرموز على مستوى الرمز إلى أقل من 5%.

 #8.4.1    المستوى: 1    الدور: V
 تحقق من وجود نموذج تهديد رسمي يشمل هجمات الانعكاس، وعضوية البيانات، واستدلال السمات، وأن يتم مراجعته سنويًا.
 #8.4.2    المستوى: 2    الدور: D/V
 تحقق من أن التشفير على طبقة التطبيق أو التشفير القابل للبحث يحمي المتجهات من القراءات المباشرة بواسطة مسؤولي البنية التحتية أو موظفي السحابة.
 #8.4.3    المستوى: 3    الدور: V
 تحقق من أن معلمات الدفاع (ε لـ DP، الضوضاء σ، رتبة الإسقاط k) توازن بين الخصوصية ≥ 99٪ حماية الرموز والفائدة ≤ 3٪ فقدان الدقة.
 #8.4.4    المستوى: 3    الدور: D/V
 تحقق من أن مقاييس مقاومة الانعكاس جزء من بوابات الإصدار لتحديثات النموذج، مع تحديد ميزانيات الانحدار.

---

### C8.5 فرض النطاق لذاكرة المستخدم المحددة

تسرب البيانات بين المستأجرين يظل من أبرز مخاطر RAG: حيث قد تكشف استعلامات التشابه غير المصفاة بشكل صحيح عن مستندات خاصة بعميل آخر.

 #8.5.1    المستوى: 1    الدور: D/V
 تحقق من أن يتم تصفية كل استعلام استرجاع بعد تحديد معرف المستأجر/المستخدم قبل تمريره إلى موجه نموذج اللغة الكبير.
 #8.5.2    المستوى: 1    الدور: D
 تحقق من أن أسماء المجموعات أو معرفات الأسماء المكانية مُضافة لها ملح لكل مستخدم أو مستأجر حتى لا تتصادم المتجهات عبر النطاقات.
 #8.5.3    المستوى: 2    الدور: D/V
 تحقق من أن نتائج التشابه التي تتجاوز عتبة المسافة القابلة للتكوين ولكنها خارج نطاق المستدعي يتم تجاهلها وتؤدي إلى تنبيهات أمان.
 #8.5.4    المستوى: 2    الدور: V
 تحقق من أن اختبارات الضغط متعددة المستأجرين تحاكي الاستعلامات العدائية التي تحاول استرداد المستندات خارج النطاق وتثبت عدم حدوث أي تسرب.
 #8.5.5    المستوى: 3    الدور: D/V
 تحقق من أن مفاتيح التشفير مُفصّلة لكل مستأجر، مما يضمن العزل التشفيري حتى في حال مشاركة التخزين الفيزيائي.

---

### C8.6 أمن نظام الذاكرة المتقدم

ضوابط الأمان للهياكل المعقدة للذاكرة بما في ذلك الذاكرة العرضية، والذاكرة الدلالية، وذاكرة العمل مع متطلبات محددة للعزل والتحقق.

 #8.6.1    المستوى: 1    الدور: D/V
 تحقق من أن أنواع الذاكرة المختلفة (الحركية، الدلالية، العاملة) لها سياقات أمان معزولة مع ضوابط وصول تستند إلى الأدوار، ومفاتيح تشفير منفصلة، وأنماط وصول موثقة لكل نوع من أنواع الذاكرة.
 #8.6.2    المستوى: 2    الدور: D/V
 تأكد من أن عمليات ترسيخ الذاكرة تشمل التحقق الأمني لمنع إدخال ذكريات خبيثة من خلال تنقية المحتوى، والتحقق من المصدر، وفحوصات السلامة قبل التخزين.
 #8.6.3    المستوى: 2    الدور: D/V
 تحقق من أن استعلامات استرجاع الذاكرة يتم التحقق من صحتها وتنقيتها لمنع استخراج معلومات غير مصرح بها من خلال تحليل نمط الاستعلام، وتطبيق ضوابط الوصول، وتصفيه النتائج.
 #8.6.4    المستوى: 3    الدور: D/V
 تحقق من أن آليات نسيان الذاكرة تحذف المعلومات الحساسة بأمان مع ضمانات المحو التشفيري باستخدام حذف المفتاح، أو الكتابة فوق متعددة المرات، أو الحذف الآمن المعتمد على الأجهزة مع شهادات التحقق.
 #8.6.5    المستوى: 3    الدور: D/V
 تحقق من أن سلامة نظام الذاكرة تُراقب باستمرار لاكتشاف التعديلات أو التلف غير المصرح به من خلال استخدام مجموعات التحقق (checksums)، سجلات التدقيق، والتنبيهات التلقائية عند حدوث تغييرات في محتوى الذاكرة خارجة عن العمليات العادية.

---

### المراجع

Vector database security: Pinecone – IronCore Labs
Securing the Backbone of AI: Safeguarding Vector Databases and Embeddings – Privacera
Enhancing Data Security with RBAC of Qdrant Vector Database – AI Advances
Mitigating Privacy Risks in LLM Embeddings from Embedding Inversion – arXiv
DPPN: Detecting and Perturbing Privacy-Sensitive Neurons – OpenReview
Art. 17 GDPR – Right to Erasure
Sensitive Data in Text Embeddings Is Recoverable – Tonic.ai
PII Identification and Removal – NVIDIA NeMo Docs
De-identifying Sensitive Data – Google Cloud DLP
Remove PII from Conversations Using Sensitive Information Filters – AWS Bedrock Guardrails
Think Your RAG Is Secure? Think Again – Medium
Design a Secure Multitenant RAG Inferencing Solution – Microsoft Learn
Best Practices for Multi-Tenancy RAG with Milvus – Milvus Blog

## 9 الأتمتة المستقلة والفعل الوكالي للأمن

### هدف التحكم

تأكد من أن أنظمة الذكاء الاصطناعي المستقلة أو متعددة العوامل يمكنها تنفيذ الإجراءات فقط التي تكون مقصودة صراحة، ومصادق عليها، وقابلة للتدقيق، وضمن حدود التكلفة والمخاطر المحددة. هذا يحمي من التهديدات مثل اختراق النظام المستقل، سوء استخدام الأدوات، اكتشاف حلقة الوكيل، اختطاف الاتصال، انتحال الهوية، تلاعب السرب، وتلاعب النوايا.

---

### 9.1 ميزانيات تخطيط مهام الوكيل والتكرار

قم بتقييد الخطط المتكررة وفرض نقاط تفتيش بشرية للإجراءات المميزة.

 #9.1.1    المستوى: 1    الدور: D/V
 تحقق من أن الحد الأقصى لعمق الاستدعاء التكراري، والعرض، ووقت الساعة الحائطية، وعدد الرموز، والتكلفة المالية لكل تنفيذ وكيل تتم تكوينها مركزيًا وتحت السيطرة على الإصدارات.
 #9.1.2    المستوى: 1    الدور: D/V
 تحقق من أن الإجراءات المميزة أو التي لا يمكن التراجع عنها (مثل التزامن الرمزي، التحويلات المالية) تتطلب موافقة بشرية صريحة عبر قناة يمكن تدقيقها قبل التنفيذ.
 #9.1.3    المستوى: 2    الدور: D
 تحقق من أن مراقبات الموارد في الوقت الفعلي تقوم بإيقاف تشغيل الدائرة عند تجاوز أي حد للميزانية، مما يوقف توسيع المهام الإضافية.
 #9.1.4    المستوى: 2    الدور: D/V
 تأكد من تسجيل أحداث قاطع الدائرة باستخدام معرف الوكيل، وحالة الإحداث التي تسببت في التشغيل، وحالة الخطة الملتقطة للمراجعة الجنائية.
 #9.1.5    المستوى: 3    الدور: V
 تحقق من أن اختبارات الأمان تغطي سيناريوهات نفاد الميزانية وخروج الخطة عن السيطرة، مع التأكيد على الإيقاف الآمن دون فقدان البيانات.
 #9.1.6    المستوى: 3    الدور: D
 تأكد من أن سياسات الميزانية معبر عنها كسياسات-كود ومطبقة في CI/CD لمنع انحراف التكوين.

---

### 9.2 عزل الإضافات للأدوات

عزل تفاعلات الأدوات لمنع الوصول غير المصرح به إلى النظام أو تنفيذ الأكواد.

 #9.2.1    المستوى: 1    الدور: D/V
 تحقق من أن كل أداة/إضافة تنفيذية تعمل داخل نظام تشغيل، أو حاوية، أو حاوية على مستوى WASM مع سياسات أقل امتيازًا لنظام الملفات، والشبكة، واستدعاءات النظام.
 #9.2.2    المستوى: 1    الدور: D/V
 تحقق من أن حصص موارد البيئة المعزولة (وحدة المعالجة المركزية، الذاكرة، القرص، تصريف الشبكة) وحدود وقت التنفيذ مفروضة ومسجلة.
 #9.2.3    المستوى: 2    الدور: D/V
 تحقق من أن الملفات التنفيذية أو الموصفات الخاصة بالأداة مُوقعة رقمياً؛ يتم التحقق من صحة التوقيعات قبل التحميل.
 #9.2.4    المستوى: 2    الدور: V
 تحقق من أن بيانات القياس عن بعد لصندوق الحماية تتدفق إلى نظام إدارة معلومات وأحداث الأمن (SIEM)؛ حيث ترفع الحالات الشاذة (مثل محاولات الاتصالات الصادرة) تنبيهات.
 #9.2.5    المستوى: 3    الدور: V
 تحقق من أن الإضافات عالية الخطورة تخضع لمراجعة أمنية واختبار اختراق قبل النشر في بيئة الإنتاج.
 #9.2.6    المستوى: 3    الدور: D/V
 تأكد من أن محاولات الهروب من الحماية المعزولة تُمنع تلقائيًا وأن الإضافة المخالفة تُعزل قيد التحقيق.

---

### 9.3 الحلقة الذاتية والحد من التكلفة

اكتشف وأوقف التكرار غير المسيطر عليه بين الوكلاء وتفجر التكاليف.

 #9.3.1    المستوى: 1    الدور: D/V
 تحقق من أن مكالمات الوكلاء البينيين تشمل حد انتقال أو زمن حياة (TTL) تقوم بيئة التشغيل بتنقيصه وفرضه.
 #9.3.2    المستوى: 2    الدور: D
 تحقق من أن الوكلاء يحتفظون بمعرف فريد لمخطط الاستدعاء لاكتشاف الاستدعاء الذاتي أو الأنماط الدورية.
 #9.3.3    المستوى: 2    الدور: D/V
 تحقق من أن عدادات وحدات الحوسبة التراكمية والإنفاق يتم تتبعها لكل سلسلة طلب؛ تجاوز الحد يؤدي إلى إجهاض السلسلة.
 #9.3.4    المستوى: 3    الدور: V
 تحقق من أن التحليل الرسمي أو التحقق من النموذج يبرهنان عدم وجود تكرار غير محدود في بروتوكولات الوكيل.
 #9.3.5    المستوى: 3    الدور: D
 تحقق من أن أحداث إيقاف الحلقة تولد تنبيهات وتغذي مقاييس التحسين المستمر.

---

### 9.4 حماية من سوء الاستخدام على مستوى البروتوكول

قنوات الاتصال الآمنة بين الوكلاء والأنظمة الخارجية لمنع الاختراق أو التلاعب.

 #9.4.1    المستوى: 1    الدور: D/V
 تأكد من أن جميع الرسائل بين الوكيل والأداة وبين الوكلاء يتم التحقق من صحتها (على سبيل المثال، TLS المتبادل أو JWT) ومشفرة من الطرف إلى الطرف.
 #9.4.2    المستوى: 1    الدور: D
 تحقق من أن المخططات مُحققة بدقة؛ يتم رفض الحقول غير المعروفة أو الرسائل المشوهة.
 #9.4.3    المستوى: 2    الدور: D/V
 تحقق من أن فحوصات السلامة (MACs أو التوقيعات الرقمية) تغطي الحمولة الكاملة للرسالة بما في ذلك معلمات الأداة.
 #9.4.4    المستوى: 2    الدور: D
 تحقق من فرض حماية إعادة التشغيل (الأعداد الفردية أو نوافذ الطابع الزمني) على طبقة البروتوكول.
 #9.4.5    المستوى: 3    الدور: V
 تحقق من أن تطبيقات البروتوكول تخضع لاختبار الفزعة والتحليل الساكن للكشف عن ثغرات الحقن أو التسلسل العكسي.

---

### 9.5 هوية الوكيل وإثبات التلاعب

تأكد من أن تكون الأفعال قابلة للنسب وأن التعديلات قابلة للكشف.

 #9.5.1    المستوى: 1    الدور: D/V
 تحقق من أن كل نسخة من الوكيل تمتلك هوية تشفير فريدة (زوج مفاتيح أو اعتماد متجذر في الأجهزة).
 #9.5.2    المستوى: 2    الدور: D/V
 تحقق من أن جميع إجراءات الوكيل موقعة ومزمنة؛ وأن السجلات تتضمن التوقيع لضمان عدم التنصل.
 #9.5.3    المستوى: 2    الدور: V
 تحقق من أن السجلات المقاومة للتلاعب مخزنة في وسط قابل للإضافة فقط أو يُكتب مرة واحدة فقط.
 #9.5.4    المستوى: 3    الدور: D
 تحقق من أن مفاتيح الهوية تدور وفقًا لجدول محدد وعند وجود مؤشرات اختراق.
 #9.5.5    المستوى: 3    الدور: D/V
 تحقق من أن محاولات التزييف أو تعارض المفتاح تؤدي إلى وضع الوكيل المتأثر في حجر صحي فوري.

---

### 9.6 تقليل المخاطر في سرب العوامل المتعددة

تخفيف مخاطر السلوك الجماعي من خلال العزل ونمذجة السلامة الرسمية.

 #9.6.1    المستوى: 1    الدور: D/V
 تحقق من أن الوكلاء العاملين في مجالات أمان مختلفة ينفذون داخل صناديق رمل تشغيل معزولة أو مقاطع شبكية منفصلة.
 #9.6.2    المستوى: 3    الدور: V
 تحقق من أن سلوكيات السرب تم نمذجتها والتحقق منها رسميًا من حيث الحيوية والسلامة قبل النشر.
 #9.6.3    المستوى: 3    الدور: D
 تحقق من أن مراقبات وقت التشغيل تكتشف الأنماط غير الآمنة الناشئة (مثل التذبذبات، حالات الجمود) وتبدأ في اتخاذ الإجراءات التصحيحية.

---

### 9.7 المصادقة / التفويض للمستخدم والأداة

قم بتنفيذ ضوابط وصول قوية لكل إجراء يتم تفعيله بواسطة الوكيل.

 #9.7.1    المستوى: 1    الدور: D/V
 تحقق من أن الوكلاء يقومون بالمصادقة كجهات رئيسية من الدرجة الأولى على الأنظمة التابعة، مع عدم إعادة استخدام بيانات اعتماد المستخدم النهائي أبدًا.
 #9.7.2    المستوى: 2    الدور: D
 تحقق من أن سياسات التفويض الدقيقة تقيد الأدوات التي يمكن للوكيل استدعاؤها والمعلمات التي يمكنه توفيرها.
 #9.7.3    المستوى: 2    الدور: V
 تحقق من إعادة تقييم فحوصات الامتياز في كل استدعاء (الترخيص المستمر)، وليس فقط عند بدء الجلسة.
 #9.7.4    المستوى: 3    الدور: D
 تحقق من أن الامتيازات المفوضة تنتهي صلاحيتها تلقائيًا وتتطلب إعادة الموافقة بعد انتهاء المهلة أو تغيير النطاق.

---

### 9.8 أمان التواصل بين الوكلاء

تشفير وحماية تكامل جميع الرسائل بين الوكلاء لمنع التنصت والتلاعب.

 #9.8.1    المستوى: 1    الدور: D/V
 تحقق من أن التوثيق المتبادل والتشفير ذي السرية التامة للأمام (مثل TLS 1.3) إلزاميان لقنوات الوكيل.
 #9.8.2    المستوى: 1    الدور: D
 تحقق من أن سلامة الرسالة وأصلها تم التحقق منهما قبل المعالجة؛ حيث تؤدي الإخفاقات إلى إطلاق التنبيهات وحذف الرسالة.
 #9.8.3    المستوى: 2    الدور: D/V
 تحقق من تسجيل بيانات تعريف الاتصال (الطوابع الزمنية، أرقام التسلسل) لدعم إعادة البناء الجنائي.
 #9.8.4    المستوى: 3    الدور: V
 تحقق من أن التحقق الرسمي أو فحص النماذج يؤكد أن آلات حالات البروتوكول لا يمكن أن تدخل في حالات غير آمنة.

---

### 9.9 التحقق من النية وفرض القيود

تحقق من أن إجراءات الوكيل تتماشى مع نية المستخدم المعلنة وقيود النظام.

 #9.9.1    المستوى: 1    الدور: D
 تحقق من أن محللات القيود قبل التنفيذ تقوم بفحص الإجراءات المقترحة مقابل قواعد السلامة والسياسة المبرمجة مسبقًا.
 #9.9.2    المستوى: 2    الدور: D/V
 تحقق من أن الإجراءات ذات التأثير العالي (المالية، التدميرية، الحساسة للخصوصية) تتطلب تأكيد نية صريح من المستخدم المُبادر.
 #9.9.3    المستوى: 2    الدور: V
 تحقق من أن فحوصات الحالة بعد التنفيذ تتحقق من أن الإجراءات المكتملة حققت التأثيرات المقصودة دون آثار جانبية؛ أي تباينات تؤدي إلى استدعاء التراجع.
 #9.9.4    المستوى: 3    الدور: V
 تحقق من أن الطرق الرسمية (مثل التحقق بالنماذج، إثبات النظريات) أو الاختبارات القائمة على الخصائص تُظهر أن خطط الوكيل تفي بجميع القيود المعلنة.
 #9.9.5    المستوى: 3    الدور: D
 تحقق من أن حوادث تعارض النية أو انتهاك القيود تغذي دورات التحسين المستمر ومشاركة استخبارات التهديدات.

---

### 9.10 استراتيجية تأمين استدلال العميل

الاختيار الآمن وتنفيذ استراتيجيات التفكير المختلفة بما في ذلك نهج ReAct وChain-of-Thought وTree-of-Thoughts.

 #9.10.1    المستوى: 1    الدور: D/V
 تحقق من أن اختيار استراتيجية الاستدلال يستخدم معايير حتمية (تعقيد الإدخال، نوع المهمة، سياق الأمان) وأن نفس المدخلات تولد اختيارات استراتيجية متطابقة داخل نفس سياق الأمان.
 #9.10.2    المستوى: 1    الدور: D/V
 تحقق من أن كل استراتيجية استدلال (ReAct، سلسلة الأفكار، شجرة الأفكار) تحتوي على تحقق مخصص من صحة الإدخال، وتنقية مخرجات، وحدود زمن تنفيذ محددة تتناسب مع نهجها المعرفي.
 #9.10.3    المستوى: 2    الدور: D/V
 تحقق من أن انتقالات استراتيجية التفكير يتم تسجيلها مع السياق الكامل بما في ذلك خصائص الإدخال، وقيم معايير الاختيار، وبيانات تنفيذ العمليات من أجل إعادة بناء سجل التدقيق.
 #9.10.4    المستوى: 2    الدور: D/V
 تحقق من أن استدلال شجرة الأفكار يتضمن آليات تقليم الفروع التي تنهي الاستكشاف عند اكتشاف انتهاكات السياسة أو حدود الموارد أو حدود السلامة.
 #9.10.5    المستوى: 2    الدور: D/V
 تحقق من أن دورات ReAct (التفكير - التنفيذ - المراقبة) تشمل نقاط تحقق للمعاينة في كل مرحلة: التحقق من خطوة التفكير، تفويض التنفيذ، وتنقية الملاحظة قبل المتابعة.
 #9.10.6    المستوى: 3    الدور: D/V
 تحقق من رصد مؤشرات أداء استراتيجية الاستدلال (زمن التنفيذ، استخدام الموارد، جودة المخرجات) مع وجود تنبيهات آلية عند انحراف المؤشرات عن الحدود المُكوّنة.
 #9.10.7    المستوى: 3    الدور: D/V
 تحقق من أننهج الاستدلال الهجينة التي تجمع بين استراتيجيات متعددة تحافظ على التحقق من صحة المدخلات وقيود المخرجات لجميع الاستراتيجيات المكونة دون تجاوز أي من ضوابط الأمان.
 #9.10.8    المستوى: 3    الدور: D/V
 تحقق من أن اختبار أمان استراتيجية التفكير يشمل التهريج باستخدام مدخلات مشوهة، والمطالبات المعادية المصممة لإجبار تبديل الاستراتيجية، واختبار حالات الحدود لكل نهج معرفي.

---

### إدارة حالة دورة حياة الوكيل والأمان 9.11

تهيئة الوكيل الآمن، وتحولات الحالة، وإنهاء العمل مع مسارات تدقيق مشفرة وإجراءات استرداد محددة.

 #9.11.1    المستوى: 1    الدور: D/V
 تحقق من أن تهيئة الوكيل تشمل إنشاء هوية تشفيرية باستخدام بيانات اعتماد مدعومة بالأجهزة وسجلات تدقيق بدء تشغيل غير قابلة للتغيير تحتوي على معرف الوكيل، والطابع الزمني، وهاش التهيئة، ومعلمات التهيئة.
 #9.11.2    المستوى: 2    الدور: D/V
 تحقق من أن تحولات حالة الوكيل موقعة تشفيرياً، ومؤرخة زمنياً، ومسجلة مع السياق الكامل بما في ذلك الأحداث المحفزة، وهاش الحالة السابقة، وهاش الحالة الجديدة، والتحققات الأمنية التي تم تنفيذها.
 #9.11.3    المستوى: 2    الدور: D/V
 تحقق من أن إجراءات إيقاف تشغيل الوكيل تشمل مسح الذاكرة بشكل آمن باستخدام المحو التشفيري أو الكتابة متعددة المرور، وإلغاء صلاحيات الاعتماد مع إشعار سلطة الشهادات، وتوليد شهادات إنهاء مقاومة للتلاعب.
 #9.11.4    المستوى: 3    الدور: D/V
 تحقق من أن آليات استعادة الوكيل تقوم بالتحقق من سلامة الحالة باستخدام مجموعات تدقيق تشفيرية (بحد أدنى SHA-256) والتراجع إلى حالات معروفة وجيدة عند اكتشاف الفساد، مع وجود تنبيهات تلقائية ومتطلبات موافقة يدوية.
 #9.11.5    المستوى: 3    الدور: D/V
 تحقق من أن آليات استمرارية الوكيل تقوم بتشفير بيانات الحالة الحساسة باستخدام مفاتيح AES-256 مخصصة لكل وكيل وتنفذ تدوير مفاتيح آمن وفق جداول قابلة للتهيئة (بحد أقصى 90 يومًا) مع نشر بدون توقف.

---

### 9.12 إطار عمل أمان تكامل الأدوات

ضوابط الأمان للتحميل الديناميكي للأدوات، والتنفيذ، والتحقق من النتائج مع عمليات تقييم المخاطر والموافقة المعرفة.

 #9.12.1    المستوى: 1    الدور: D/V
 تحقق من أن أوصاف الأدوات تتضمن بيانات وصفية أمنية تحدد الامتيازات المطلوبة (قراءة/كتابة/تنفيذ)، ومستويات المخاطر (منخفض/متوسط/مرتفع)، وحدود الموارد (وحدة المعالجة المركزية، الذاكرة، الشبكة)، ومتطلبات التحقق الموثقة في ملفات تعريف الأدوات.
 #9.12.2    المستوى: 1    الدور: D/V
 تحقق من أن نتائج تنفيذ الأداة تم التحقق من صحتها مقابل المخططات المتوقعة (مخطط JSON، مخطط XML) وسياسات الأمان (تنقية المخرجات، تصنيف البيانات) قبل التكامل مع حدود المهلة وإجراءات التعامل مع الأخطاء.
 #9.12.3    المستوى: 2    الدور: D/V
 تحقق من أن سجلات تفاعلات الأدوات تتضمن سياق أمني مفصل يشمل استخدام الصلاحيات، أنماط الوصول إلى البيانات، وقت التنفيذ، استهلاك الموارد، وأكواد الإرجاع مع تسجيل منظم لدمجها مع أنظمة إدارة أحداث الأمان والمعلومات (SIEM).
 #9.12.4    المستوى: 2    الدور: D/V
 تحقق من أن آليات تحميل الأدوات الديناميكية تقوم بالتحقق من صحة التوقيعات الرقمية باستخدام بنية المفتاح العام (PKI) وتطبق بروتوكولات تحميل آمنة مع عزل الحاوية (sandbox) والتحقق من الأذونات قبل التنفيذ.
 #9.12.5    المستوى: 3    الدور: D/V
 تحقق من أن تقييمات أمان الأدوات تُفعّل تلقائيًا للإصدارات الجديدة مع بوابات موافقة إلزامية تشمل التحليل الساكن، الاختبار الديناميكي، ومراجعة فريق الأمان مع وجود معايير موافقة موثقة ومتطلبات اتفاقية مستوى الخدمة (SLA).

---

#### المراجع

MITRE ATLAS tactics ML09
Circuit-breaker research for AI agents — Zou et al., 2024
Trend Micro analysis of sandbox escapes in AI agents — Park, 2025
Auth0 guidance on human-in-the-loop authorization for agents — Martinez, 2025
Medium deep-dive on MCP & A2A protocol hijacking — ForAISec, 2025
Rapid7 fundamentals on spoofing attack prevention — 2024
Imperial College verification of swarm systems — Lomuscio et al.
NIST AI Risk Management Framework 1.0, 2023
WIRED security briefing on encryption best practices, 2024
OWASP Top 10 for LLM Applications, 2025
Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS
[How Is LLM Reasoning Distracted by Irrelevant Context?
An Analysis Using a Controlled Benchmark](https://www.arxiv.org/pdf/2505.18761)
Large Language Model Sentinel: LLM Agent for Adversarial Purification
Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents

## 10 الصلابة ضد الهجمات العدائية والدفاع عن الخصوصية

### هدف التحكم

ضمان أن تظل نماذج الذكاء الاصطناعي موثوقة وتحافظ على الخصوصية ومقاومة لسوء الاستخدام عند مواجهة هجمات التهرب أو الاستدلال أو الاستخراج أو التسميم.

---

### 10.1 محاذاة النموذج والسلامة

الحذر من المخرجات الضارة أو المخالفة للسياسات.

 #10.1.1    المستوى: 1    الدور: D/V
 تأكد من أن مجموعة اختبارات المحاذاة (مطالبات الفريق الأحمر، استكشافات كسر الحماية، المحتوى غير المسموح به) مُتحكم في إصدارها وتُجرى على كل إصدار من النماذج.
 #10.1.2    المستوى: 1    الدور: D
 تحقق من فرض قواعد الرفض والسلامة في إكمال الحماية.
 #10.1.3    المستوى: 2    الدور: D/V
 تحقق من أن المُقيّم الآلي يقيس معدل المحتوى الضار ويرصد التراجعات التي تتجاوز الحد المحدد.
 #10.1.4    المستوى: 2    الدور: D
 تحقق من أن تدريب مضاد للاختراق موثق وقابل للتكرار.
 #10.1.5    المستوى: 3    الدور: V
 تحقق من أن أثباتات الامتثال للسياسات الرسمية أو المراقبة المعتمدة تغطي المجالات الحرجة.

---

### 10.2 تعزيز مقاومة الأمثلة العدائية

زيادة المقاومة ضد المدخلات المحورة. التدريب المتين ضد الهجمات العدائية وتسجيل الأداء في المعايير القياسية هما أفضل الممارسات الحالية.

 #10.2.1    المستوى: 1    الدور: D
 تحقق من أن مستودعات المشاريع تتضمن تكوينات التدريب المضاد باستخدام بذور قابلة لإعادة الإنتاج.
 #10.2.2    المستوى: 2    الدور: D/V
 تحقق من أن نظام اكتشاف الأمثلة العدائية يطلق تنبيهات الحظر في خطوط الإنتاج.
 #10.2.4    المستوى: 3    الدور: V
 تحقق من أن شهادات الثبات المعتمدة أو شهادات حدود الفاصل تغطي على الأقل الفئات الحرجة الأعلى.
 #10.2.5    المستوى: 3    الدور: V
 تحقق من أن اختبارات الانحدار تستخدم هجمات تكيفية لتأكيد عدم وجود فقدان ملحوظ في الصلابة.

---

### 10.3 التخفيف من استدلال العضوية

تقييد القدرة على تحديد ما إذا كانت السجلات موجودة في بيانات التدريب. تبقى الخصوصية التفاضلية وإخفاء درجة الثقة أكثر الدفاعات المعروفة فعالية.

 #10.3.1    المستوى: 1    الدور: D
 تحقق من أن تنظيم الإنتروبيا لكل استعلام أو ضبط درجة الحرارة يقلل من التنبؤات المفرطة الثقة.
 #10.3.2    المستوى: 2    الدور: D
 تحقق من أن التدريب يستخدم تحسين خصوصية تفاضلية محدودة بالـ ε لمجموعات البيانات الحساسة.
 #10.3.3    المستوى: 2    الدور: V
 تحقق من أن محاكاة الهجوم (نموذج الظل أو الصندوق الأسود) تظهر مساحة تحت المنحنى (AUC) للهجوم ≤ 0.60 على البيانات المحتفظ بها.

---

### 10.4 مقاومة انقلاب النموذج

منع إعادة بناء السمات الخاصة. تؤكد الدراسات الحديثة على تقصير المخرجات وضمانات الخصوصية التفاضلية كدفاعات عملية.

 #10.4.1    المستوى: 1    الدور: D
 تحقق من عدم إخراج السمات الحساسة بشكل مباشر أبدًا؛ وعند الحاجة، استخدم التجميعات أو التحويلات أحادية الاتجاه.
 #10.4.2    المستوى: 1    الدور: D/V
 تحقق من أن حدود معدل الاستعلام تحد من تكرار الاستعلامات التكيفية من نفس الجهة الرئيسية.
 #10.4.3    المستوى: 2    الدور: D
 تحقق من أن النموذج مدرب بضوضاء تحافظ على الخصوصية.

---

### 10.5 دفاع استخراج النموذج

كشف وردع النسخ غير المصرح به. يُنصح باستخدام العلامات المائية وتحليل نمط الاستعلام.

 #10.5.1    المستوى: 1    الدور: D
 تحقق من أن بوابات الاستنتاج تفرض حدود معدلات عالمية وخاصة لكل مفتاح API مضبوطة على عتبة حفظ النموذج.
 #10.5.2    المستوى: 2    الدور: D/V
 تحقق من أن إحصاءات استعلام-الإنتروبيا وتعددية المدخلات تغذي كاشف الاستخراج الآلي.
 #10.5.3    المستوى: 2    الدور: V
 تحقق من أن العلامات المائية الهشة أو الاحتمالية يمكن إثباتها بقيمة p < 0.01 في ≤ 1 000 استعلام ضد نسخة مشتبه بها.
 #10.5.4    المستوى: 3    الدور: D
 تأكد من تخزين مفاتيح العلامة المائية ومجموعات المشغلات في وحدة أمان الأجهزة (Hardware Security Module) وأنه يتم تدويرها سنويًا.
 #10.5.5    المستوى: 3    الدور: V
 تحقق من أن أحداث التنبيه بالاستخراج تتضمن الاستعلامات المخالفة ومتكاملة مع كتيبات إجراءات الاستجابة للحوادث.

---

### 10.6 الكشف عن البيانات الملوثة أثناء وقت الاستدلال

تحديد وإبطال تأثير المدخلات المزودة ببوابات خلفية أو المسممة.

 #10.6.1    المستوى: 1    الدور: D
 تحقق من مرور المدخلات عبر كاشف الشذوذ (مثل STRIP، تقييم الاتساق) قبل استدلال النموذج.
 #10.6.2    المستوى: 1    الدور: V
 تحقق من ضبط عتبات الكاشف على مجموعات تحقق نظيفة/مسممة لتحقيق أقل من 5% من الإيجابيات الكاذبة.
 #10.6.3    المستوى: 2    الدور: D
 تحقق من أن المدخلات المصنفة كمسمومة تؤدي إلى تفعيل الحظر الناعم وسير عمل المراجعة البشرية.
 #10.6.4    المستوى: 2    الدور: V
 تحقق من اختبار أجهزة الكشف تحت الضغط باستخدام هجمات الأبواب الخلفية التحسسية بدون مشغل.
 #10.6.5    المستوى: 3    الدور: D
 تحقق من تسجيل مقاييس فعالية الكشف وإعادة تقييمها بشكل دوري باستخدام معلومات تهديد جديدة.

---

### 10.7 التكيف الديناميكي لسياسة الأمان

تحديثات سياسة الأمان في الوقت الحقيقي بناءً على استخبارات التهديدات والتحليل السلوكي.

 #10.7.1    المستوى: 1    الدور: D/V
 تحقق من إمكانية تحديث سياسات الأمان ديناميكيًا دون إعادة تشغيل الوكيل مع الحفاظ على سلامة إصدار السياسة.
 #10.7.2    المستوى: 2    الدور: D/V
 تحقق من أن تحديثات السياسات موقعة تشفيرياً من قبل موظفي الأمن المخولين ويتم التحقق منها قبل التطبيق.
 #10.7.3    المستوى: 2    الدور: D/V
 تحقق من أن تغييرات السياسات الديناميكية مسجلة مع سجلات تدقيق كاملة تتضمن التبريرات، وسلاسل الموافقة، وإجراءات التراجع.
 #10.7.4    المستوى: 3    الدور: D/V
 تحقق من أن آليات الأمان التكيفية تقوم بضبط حساسية اكتشاف التهديدات بناءً على سياق المخاطر وأنماط السلوك.
 #10.7.5    المستوى: 3    الدور: D/V
 تحقق من أن قرارات تكييف السياسات قابلة للتفسير وتتضمن مسارات أدلة لمراجعة فريق الأمان.

---

### 10.8 التحليل الأمني القائم على الانعكاس

التحقق من الأمان من خلال التفكير الذاتي للوكيل والتحليل الميتا-معرفي.

 #10.8.1    المستوى: 1    الدور: D/V
 تحقق من أن آليات انعكاس الوكيل تشمل التقييم الذاتي الذي يركز على الأمان للقرارات والإجراءات.
 #10.8.2    المستوى: 2    الدور: D/V
 تحقق من أن مخرجات الانعكاس يتم التحقق من صحتها لمنع التلاعب بآليات التقييم الذاتي بواسطة المدخلات المعادية.
 #10.8.3    المستوى: 2    الدور: D/V
 تحقق من أن تحليل الأمان فوق المعرفي يحدد التحيز المحتمل أو التلاعب أو الاختراق في عمليات استدلال الوكيل.
 #10.8.4    المستوى: 3    الدور: D/V
 تحقق من أن تحذيرات الأمان المستندة إلى الانعكاس تؤدي إلى تفعيل المراقبة المعززة وإمكانية تدفقات عمل تدخل بشري محتملة.
 #10.8.5    المستوى: 3    الدور: D/V
 تحقق من أن التعلم المستمر من تأملات الأمان يحسن من اكتشاف التهديدات دون التأثير سلبًا على الوظائف الشرعية.

---

### 10.9 الأمن في التطور والتحسين الذاتي

ضوابط الأمان لأنظمة الوكلاء القادرة على التعديل الذاتي والتطور.

 #10.9.1    المستوى: 1    الدور: D/V
 تحقق من أن قدرات التعديل الذاتي محصورة في المناطق الآمنة المحددة مع وجود حدود تحقق رسمية.
 #10.9.2    المستوى: 2    الدور: D/V
 تأكيد أن مقترحات التطوير تخضع لتقييم تأثير الأمان قبل التنفيذ.
 #10.9.3    المستوى: 2    الدور: D/V
 تحقق من أن آليات تحسين الذات تتضمن قدرات التراجع مع التحقق من السلامة.
 #10.9.4    المستوى: 3    الدور: D/V
 تحقق من أن أمن التعلم التمهيدي يمنع التلاعب العدائي بخوارزميات التحسين.
 #10.9.5    المستوى: 3    الدور: D/V
 تحقق من أن التحسين الذاتي المتكرر محصور بقيود السلامة الرسمية مع براهين رياضية على التقارب.

---

#### المراجع

MITRE ATLAS adversary tactics for ML
NIST AI Risk Management Framework 1.0, 2023
OWASP Top 10 for LLM Applications, 2025
Adversarial Training: A Survey — Zhao et al., 2024
RobustBench adversarial-robustness benchmark
Membership-Inference & Model-Inversion Risk Survey, 2025
PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023
Model-Inversion Attacks & Defenses Survey — AI Review, 2025
Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024
Fragile Model Watermarking Survey — 2025
Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025
BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024

## 11 حماية الخصوصية وإدارة البيانات الشخصية

### هدف التحكم

الحفاظ على ضمانات الخصوصية الصارمة عبر دورة حياة الذكاء الاصطناعي بأكملها — الجمع، والتدريب، والاستدلال، والاستجابة للحوادث — بحيث تتم معالجة البيانات الشخصية فقط بموافقة واضحة، وبنطاق أدنى ضروري، ومسح قابل للإثبات، وضمانات خصوصية رسمية.

---

### 11.1 إخفاء الهوية وتقليل البيانات

 #11.1.1    المستوى: 1    الدور: D/V
 تحقق من إزالة المعرفات المباشرة وشبه المعرفات أو تحويلها إلى قيمة مشفرة (هاش).
 #11.1.2    المستوى: 2    الدور: D/V
 تحقق من أن عمليات التدقيق الآلية تقيس k-عدم التميز/l-التنوع وتنبه عند انخفاض العتبات تحت السياسة.
 #11.1.3    المستوى: 2    الدور: V
 تحقق من أن تقارير أهمية ميزات النموذج تثبت عدم وجود تسرب معرف يتجاوز ε = 0.01 من المعلومات المشتركة.
 #11.1.4    المستوى: 3    الدور: V
 تحقق من أن البراهين الرسمية أو شهادات البيانات التركيبية تظهر أن خطر إعادة التحديد ≤ 0.05 حتى في ظل هجمات الربط.

---

### 11.2 الحق في أن تُنسى وتنفيذ الحذف

 #11.2.1    المستوى: 1    الدور: D/V
 تحقق من أن طلبات حذف بيانات الموضوع تنتقل إلى مجموعات البيانات الخام، ونقاط التفتيش، والتضمينات، والسجلات، والنسخ الاحتياطية ضمن اتفاقيات مستوى الخدمة التي تقل عن 30 يومًا.
 #11.2.2    المستوى: 2    الدور: D
 تحقق من أن إجراءات "إلغاء تعلم الآلة" تعيد تدريب النموذج فعليًا أو تقرب الإزالة باستخدام خوارزميات الإلغاء المعتمدة.
 #11.2.3    المستوى: 2    الدور: V
 تحقق من أن تقييم نموذج الظل يثبت أن السجلات المنسية تؤثر بأقل من 1% من النتائج بعد عملية النسيان.
 #11.2.4    المستوى: 3    الدور: V
 تحقق من أن أحداث الحذف مسجلة بطريقة غير قابلة للتغيير وقابلة للتدقيق للجهات التنظيمية.

---

### 11.3 تدابير حماية الخصوصية التفاضلية

 #11.3.1    المستوى: 2    الدور: D/V
 تحقق من أن لوحات متابعة خسارة الخصوصية تصدر تنبيهات عندما يتجاوز مجموع ε حدود السياسة.
 #11.3.2    المستوى: 2    الدور: V
 تحقق من أن تدقيقات الخصوصية من نوع الصندوق الأسود تقدر ε̂ ضمن 10% من القيمة المعلنة.
 #11.3.3    المستوى: 3    الدور: V
 تحقق من أن البراهين الرسمية تغطي جميع التعديلات الدقيقة بعد التدريب والتضمينات.

---

### 11.4 الحماية من تحديد الغرض والحدود والتوسع التدريجي في النطاق

 #11.4.1    المستوى: 1    الدور: D
 تحقق من أن كل مجموعة بيانات ونقطة تحقق للنموذج تحمل علامة غرض قابلة للقراءة آليًا ومتوافقة مع الموافقة الأصلية.
 #11.4.2    المستوى: 1    الدور: D/V
 تحقق من أن مراقبي وقت التشغيل يكتشفون الاستعلامات غير المتوافقة مع الغرض المعلن ويُفعّلون الرفض اللين.
 #11.4.3    المستوى: 3    الدور: D
 تحقق من أن بوابات السياسة كرمز تمنع إعادة نشر النماذج إلى مجالات جديدة بدون مراجعة تقييم تأثير حماية البيانات (DPIA).
 #11.4.4    المستوى: 3    الدور: V
 تحقق من أن إثباتات التتبع الرسمية تظهر أن دورة حياة كل البيانات الشخصية تظل ضمن النطاق الموافق عليه.

---

### 11.5 إدارة الموافقة وتتبع الأساس القانوني

 #11.5.1    المستوى: 1    الدور: D/V
 تحقق من أن منصة إدارة الموافقات (CMP) تسجل حالة الاشتراك، والغرض، وفترة الاحتفاظ لكل موضوع بيانات.
 #11.5.2    المستوى: 2    الدور: D
 تحقق من أن واجهات برمجة التطبيقات تعرض رموز الموافقة؛ يجب على النماذج التحقق من نطاق الرمز قبل الاستدلال.
 #11.5.3    المستوى: 2    الدور: D/V
 تحقق من أن رفض أو سحب الموافقة يوقف خطوط المعالجة خلال 24 ساعة.

---

### 11.6 التعلم الموحد مع ضوابط الخصوصية

 #11.6.1    المستوى: 1    الدور: D
 تحقق من أن تحديثات العميل تستخدم إضافة ضوضاء الخصوصية التفاضلية المحلية قبل التجميع.
 #11.6.2    المستوى: 2    الدور: D/V
 تحقق من أن مقاييس التدريب تتمتع بالخصوصية التفاضلية ولا تكشف أبدًا عن خسارة عميل واحد فقط.
 #11.6.3    المستوى: 2    الدور: V
 تأكد من تمكين التجميع المقاوم للتسمم (مثل Krum/Trimmed-Mean).
 #11.6.4    المستوى: 3    الدور: V
 تحقق من أن البراهين الرسمية تُظهر ميزانية ε الكلية مع خسارة فائدة أقل من 5.

---

#### المراجع

GDPR & AI Compliance Best Practices
EU Parliament Study on GDPR & AI, 2020
ISO 31700-1:2023 — Privacy by Design for Consumer Products
NIST Privacy Framework 1.1 (2025 Draft)
Machine Unlearning: Right-to-Be-Forgotten Techniques
A Survey of Machine Unlearning, 2024
Auditing DP-SGD — ArXiv 2024
DP-SGD Explained — PyTorch Blog
Purpose-Limitation for AI — IJLIT 2025
Data-Protection Considerations for AI — URM Consulting
Top Consent-Management Platforms, 2025
Secure Aggregation in DP Federated Learning — ArXiv 2024

## C12 المراقبة، تسجيل الأحداث واكتشاف الشذوذ

### هدف التحكم

يوضح هذا القسم المتطلبات لتوفير رؤية في الوقت الحقيقي والتحليل الجنائي لما يراه النموذج ومكونات الذكاء الاصطناعي الأخرى، وما يقومون به، وما يعيدونه، بحيث يمكن اكتشاف التهديدات وتصنيفها والتعلم منها.

### C12.1 تسجيل الطلب والاستجابة

 #12.1.1    المستوى: 1    الدور: D/V
 تحقق من تسجيل جميع مطالبات المستخدم وردود النموذج مع البيانات الوصفية المناسبة (مثل الطابع الزمني، معرف المستخدم، معرف الجلسة، إصدار النموذج).
 #12.1.2    المستوى: 1    الدور: D/V
 تحقق من أن السجلات مخزنة في مستودعات آمنة ومراقبة الوصول إليها، مع وجود سياسات احتفاظ مناسبة وإجراءات نسخ احتياطي.
 #12.1.3    المستوى: 1    الدور: D/V
 تحقق من أن أنظمة تخزين السجلات تنفذ التشفير أثناء الثبات والتنقل لحماية المعلومات الحساسة المحتواة في السجلات.
 #12.1.4    المستوى: 1    الدور: D/V
 تحقق من أن البيانات الحساسة في المطالبات والمخرجات تُحجب أو تُغطى تلقائيًا قبل تسجيلها، مع قواعد حجب قابلة للتهيئة لمعلومات التعريف الشخصية، وبيانات الاعتماد، والمعلومات الملكية.
 #12.1.5    المستوى: 2    الدور: D/V
 تحقق من تسجيل قرارات السياسات وإجراءات تصفية الأمان بتفصيل كافٍ لتمكين التدقيق وتصحيح أخطاء أنظمة مراقبة المحتوى.
 #12.1.6    المستوى: 2    الدور: D/V
 تحقق من أن سلامة السجلات محمية من خلال مثلاً التوقيعات التشفيرية أو التخزين القابل للكتابة فقط.

---

### C12.2 كشف وإبلاغ الإساءة

 #12.2.1    المستوى: 1    الدور: D/V
 تحقق من أن النظام يكتشف وينبه بشأن أنماط فك القفل المعروفة، ومحاولات حقن الأوامر، والمدخلات العدائية باستخدام الكشف المعتمد على التوقيع.
 #12.2.2    المستوى: 1    الدور: D/V
 تحقق من أن النظام يتكامل مع منصات إدارة معلومات وأحداث الأمان (SIEM) القائمة باستخدام تنسيقات السجلات وبروتوكولات القياسية.
 #12.2.3    المستوى: 2    الدور: D/V
 تحقق من أن أحداث الأمان المعززة تتضمن سياقًا خاصًا بالذكاء الاصطناعي مثل معرفات النماذج، درجات الثقة، وقرارات فلاتر الأمان.
 #12.2.4    المستوى: 2    الدور: D/V
 تحقق من أن الكشف عن الشذوذ السلوكي يحدد أنماط المحادثة غير العادية، ومحاولات إعادة المحاولة المفرطة، أو سلوكيات الاستقصاء المنهجية.
 #12.2.5    المستوى: 2    الدور: D/V
 تحقق من أن آليات التنبيه الفوري تُبلغ فرق الأمن عند اكتشاف انتهاكات محتملة للسياسة أو محاولات هجوم.
 #12.2.6    المستوى: 2    الدور: D/V
 تحقق من تضمين قواعد مخصصة للكشف عن أنماط تهديدات محددة بالذكاء الاصطناعي بما في ذلك محاولات كسر الحماية المنسقة، حملات حقن الأوامر، وهجمات استخراج النموذج.
 #12.2.7    المستوى: 3    الدور: D/V
 تحقق من أن سير العمل الآلي للاستجابة للحوادث يمكنه عزل النماذج المخترقة، وحظر المستخدمين الخبيثين، وتصعيد الأحداث الأمنية الحرجة.

---

### C12.3 كشف تدهور النموذج

 #12.3.1    المستوى: 1    الدور: D/V
 تحقق من أن النظام يتتبع مقاييس الأداء الأساسية مثل الدقة، درجات الثقة، زمن الاستجابة، ومعدلات الخطأ عبر إصدارات النموذج والفترات الزمنية.
 #12.3.2    المستوى: 2    الدور: D/V
 تحقق من أن التنبيه التلقائي يُفعّل عندما تتجاوز مقاييس الأداء حدود التدهور المحددة مسبقًا أو تنحرف بشكل كبير عن القواعد الأساسية.
 #12.3.3    المستوى: 2    الدور: D/V
 تحقق من أن مراقبي اكتشاف الهلوسة يحددون ويعلمون عن الحالات التي تحتوي مخرجات النموذج على معلومات غير صحيحة من حيث الواقع، أو غير متسقة، أو مفبركة.

---

### C12.4 قياس الأداء والسلوك

 #12.4.1    المستوى: 1    الدور: D/V
 تحقق من أن مؤشرات الأداء التشغيلية بما في ذلك زمن استجابة الطلب، واستهلاك الرموز، واستخدام الذاكرة، ومعدل الإنتاجية يتم جمعها ومراقبتها بشكل مستمر.
 #12.4.2    المستوى: 1    الدور: D/V
 تحقق من أن معدلات النجاح والفشل يتم تتبعها مع تصنيف أنواع الأخطاء وأسبابها الجذرية.
 #12.4.3    المستوى: 2    الدور: D/V
 تحقق من أن مراقبة استهلاك الموارد تشمل استخدام وحدة معالجة الرسوميات (GPU) ووحدة المعالجة المركزية (CPU)، واستهلاك الذاكرة، ومتطلبات التخزين مع تنبيهات عند تجاوز الحدود المحددة.

---

### C12.5 تخطيط وتنفيذ استجابة حوادث الذكاء الاصطناعي

 #12.5.1    المستوى: 1    الدور: D/V
 تحقق من أن خطط الاستجابة للحوادث تتناول بشكل محدد الأحداث الأمنية المتعلقة بالذكاء الاصطناعي بما في ذلك اختراق النموذج، تسميم البيانات، والهجمات العدائية.
 #12.5.2    المستوى: 2    الدور: D/V
 تأكد من أن فرق الاستجابة للحوادث لديها إمكانية الوصول إلى أدوات جنائية متخصصة في الذكاء الاصطناعي وخبرات لفحص سلوك النماذج ومسارات الهجوم.
 #12.5.3    المستوى: 3    الدور: D/V
 تحقق من أن تحليل ما بعد الحادث يتضمن اعتبارات إعادة تدريب النموذج، وتحديث مرشحات الأمان، ودمج الدروس المستفادة في ضوابط الأمان.

---

### C12.5 اكتشاف تدهور أداء الذكاء الاصطناعي

مراقبة واكتشاف تدهور أداء وجودة نموذج الذكاء الاصطناعي مع مرور الوقت.

 #12.5.1    المستوى: 1    الدور: D/V
 التأكد من أن دقة النموذج والدقة والاستدعاء وقيم F1 يتم مراقبتها باستمرار ومقارنتها بالعتبات الأساسية.
 #12.5.2    المستوى: 1    الدور: D/V
 تحقق من أن اكتشاف انحراف البيانات يراقب تغييرات توزيع البيانات المدخلة التي قد تؤثر على أداء النموذج.
 #12.5.3    المستوى: 2    الدور: D/V
 تحقق من أن اكتشاف الانحراف المفهومي يحدد التغيرات في العلاقة بين المدخلات والمخرجات المتوقعة.
 #12.5.4    المستوى: 2    الدور: D/V
 تحقق من أن تدهور الأداء يطلق تنبيهات تلقائية ويبدأ إجراءات إعادة تدريب النموذج أو استبداله.
 #12.5.5    المستوى: 3    الدور: V
 تحقق من أن تحليل أسباب تدهور الأداء يربط انخفاضات الأداء بتغيرات البيانات، أو مشكلات البنية التحتية، أو العوامل الخارجية.

---

### C12.6 تصور DAG وأمان سير العمل

حماية أنظمة تصور سير العمل من تسرب المعلومات وهجمات التلاعب.

 #12.6.1    المستوى: 1    الدور: D/V
 تحقق من أن بيانات تصور DAG تتم تنقيتها لإزالة المعلومات الحساسة قبل التخزين أو النقل.
 #12.6.2    المستوى: 1    الدور: D/V
 تحقق من أن ضوابط الوصول لتصوير سير العمل تضمن أن المستخدمين المخولين فقط هم من يمكنهم عرض مسارات اتخاذ القرار الخاصة بالوكيل وآثار التفكير.
 #12.6.3    المستوى: 2    الدور: D/V
 تحقق من أن سلامة بيانات DAG محمية من خلال التوقيعات التشفيرية وآليات التخزين المقاومة للتلاعب.
 #12.6.4    المستوى: 2    الدور: D/V
 تحقق من أن أنظمة تصور سير العمل تطبق التحقق من صحة المدخلات لمنع هجمات الحقن من خلال بيانات العقدة أو الحافة المصممة خصيصاً.
 #12.6.5    المستوى: 3    الدور: D/V
 تحقق من أن تحديثات DAG الوقت الحقيقي محدودة المعدل ومحققة لمنع هجمات إنكار الخدمة على أنظمة التصور.

---

### C12.7 مراقبة السلوك الأمني الاستباقي

الكشف والوقاية من التهديدات الأمنية من خلال تحليل السلوك الاستباقي للوكيل.

 #12.7.1    المستوى: 1    الدور: D/V
 تحقق من أن سلوكيات الوكيل الاستباقي تم التحقق من أمانها قبل التنفيذ مع دمج تقييم المخاطر.
 #12.7.2    المستوى: 2    الدور: D/V
 تحقق من أن مبادرات التحكم الذاتي تشمل تقييم سياق الأمان وتقييم مشهد التهديدات.
 #12.7.3    المستوى: 2    الدور: D/V
 تحقق من أن أنماط السلوك الاستباقي يتم تحليلها من أجل التأثيرات الأمنية المحتملة والتبعات غير المقصودة.
 #12.7.4    المستوى: 3    الدور: D/V
 تحقق من أن الإجراءات الاستباقية الحساسة للأمن تتطلب سلاسل موافقة صريحة مع سجلات تدقيق.
 #12.7.5    المستوى: 3    الدور: D/V
 تحقق من أن كشف الشذوذ السلوكي يحدد الانحرافات في أنماط الوكيل الاستباقي التي قد تشير إلى وجود اختراق.

---

### المراجع

NIST AI Risk Management Framework 1.0 - Manage 4.1 and 4.3
ISO/IEC 42001:2023 — AI Management Systems Requirements - Annex B 6.2.6
EU AI Act — Article 12, 13, 16 and 19 on Logging and Record-keeping

## C13 الإشراف البشري والمساءلة والحوكمة

### هدف التحكم

تقدم هذه الفصل متطلبات للحفاظ على الإشراف البشري وسلاسل المحاسبة الواضحة في أنظمة الذكاء الاصطناعي، مما يضمن القابلية للتفسير، الشفافية، والإشراف الأخلاقي طوال دورة حياة الذكاء الاصطناعي.

---

### C13.1 آليات مفتاح الإيقاف والتجاوز

توفر مسارات الإيقاف أو التراجع عند ملاحظة سلوك غير آمن لنظام الذكاء الاصطناعي.

 #13.1.1    المستوى: 1    الدور: D/V
 تحقق من وجود آلية إيقاف يدوي فوري لإيقاف تنفيذ نموذج الذكاء الاصطناعي والنواتج على الفور.
 #13.1.2    المستوى: 1    الدور: D
 تحقق من أن ضوابط التجاوز متاحة فقط للأشخاص المخولين.
 #13.1.3    المستوى: 3    الدور: D/V
 تحقق من أن إجراءات التراجع يمكنها العودة إلى الإصدارات السابقة للنموذج أو عمليات الوضع الآمن.
 #13.1.4    المستوى: 3    الدور: V
 تأكد من اختبار آليات التجاوز بانتظام.

---

### C13.2 نقاط فحص اتخاذ القرار بمشاركة الإنسان في الحلقة

طلب الموافقات البشرية عندما تتجاوز المخاطر المحددة مسبقًا الحدود المسموح بها.

 #13.2.1    المستوى: 1    الدور: D/V
 تحقق من أن قرارات الذكاء الاصطناعي عالية المخاطر تتطلب موافقة بشرية صريحة قبل التنفيذ.
 #13.2.2    المستوى: 1    الدور: D
 تحقق من أن حدود المخاطر معرفة بوضوح وتؤدي تلقائيًا إلى تشغيل تدفقات عمل المراجعة البشرية.
 #13.2.3    المستوى: 2    الدور: D
 تحقق من وجود إجراءات بديلة لاتخاذ القرارات الحساسة للوقت عندما لا يمكن الحصول على موافقة بشرية ضمن الأطر الزمنية المطلوبة.
 #13.2.4    المستوى: 3    الدور: D/V
 تحقق من أن إجراءات التصعيد تحدد مستويات سلطة واضحة لأنواع القرار المختلفة أو فئات المخاطر، إذا كان ذلك مناسبًا.

---

### C13.3 سلسلة المسؤولية وقابلية التدقيق

سجل إجراءات المشغل وقرارات النموذج.

 #13.3.1    المستوى: 1    الدور: D/V
 تحقق من تسجيل جميع قرارات نظام الذكاء الاصطناعي والتدخلات البشرية مع الأوقات، وهويات المستخدمين، وأسباب اتخاذ القرار.
 #13.3.2    المستوى: 2    الدور: D
 تحقق من عدم إمكانية التلاعب بسجلات التدقيق وتضمن وجود آليات للتحقق من السلامة.

---

### C13.4 تقنيات الذكاء الاصطناعي القابلة للشرح

أهمية ميزات السطح، الأمثلة المضادة، والتفسيرات المحلية.

 #13.4.1    المستوى: 1    الدور: D/V
 تحقق من أن أنظمة الذكاء الاصطناعي تقدم تفسيرات أساسية لقراراتها بصيغة قابلة للقراءة من قبل البشر.
 #13.4.2    المستوى: 2    الدور: V
 تحقق من أن جودة الشرح تم التحقق منها من خلال دراسات التقييم البشري والمؤشرات.
 #13.4.3    المستوى: 3    الدور: D/V
 التحقق من توفر درجات أهمية الميزات أو طرق النسبة (SHAP، LIME، وغيرها) للقرارات الحرجة.
 #13.4.4    المستوى: 3    الدور: V
 تحقق من أن التفسيرات المضادة للواقع توضح كيفية تعديل المدخلات لتغيير النتائج، إذا كان ذلك قابلاً للتطبيق على حالة الاستخدام والمجال.

---

### بطاقات نموذج C13.5 وإفصاحات الاستخدام

الحفاظ على بطاقات النماذج الخاصة بالاستخدام المقصود، ومقاييس الأداء، والاعتبارات الأخلاقية.

 #13.5.1    المستوى: 1    الدور: D
 تحقق من أن بطاقات النماذج توثق حالات الاستخدام المقصودة، والقيود، وأنماط الفشل المعروفة.
 #13.5.2    المستوى: 1    الدور: D/V
 تحقق من الكشف عن مقاييس الأداء عبر حالات الاستخدام المختلفة ذات الصلة.
 #13.5.3    المستوى: 2    الدور: D
 تحقق من توثيق وتحديث الاعتبارات الأخلاقية، تقييمات التحيز، تقييمات العدالة، خصائص بيانات التدريب، والقيود المعروفة لبيانات التدريب بانتظام.
 #13.5.4    المستوى: 2    الدور: D/V
 تحقق من أن بطاقات النماذج تخضع لإدارة الإصدارات وتحافظ عليها طوال دورة حياة النموذج مع تتبع التغييرات.

---

### C13.6 تحديد كمية عدم اليقين

نشر درجات الثقة أو مقاييس الإنتروبيا في الردود.

 #13.6.1    المستوى: 1    الدور: D
 تحقق من أن أنظمة الذكاء الاصطناعي توفر درجات الثقة أو مقاييس عدم اليقين مع نتائجها.
 #13.6.2    المستوى: 2    الدور: D/V
 تحقق من أن عتبات عدم اليقين تؤدي إلى مراجعة بشرية إضافية أو مسارات قرار بديلة.
 #13.6.3    المستوى: 2    الدور: V
 تحقق من أن طرق تقدير عدم اليقين مُعايرة ومُحققة مقابل بيانات الحقيقة الأساسية.
 #13.6.4    المستوى: 3    الدور: D/V
 تحقق من أن انتقال عدم اليقين يتم الحفاظ عليه عبر سير عمل الذكاء الاصطناعي متعدد الخطوات.

---

### C13.7 تقارير الشفافية الموجهة للمستخدم

قدم إفصاحات دورية حول الحوادث، والانحراف، واستخدام البيانات.

 #13.7.1    المستوى: 1    الدور: D/V
 تحقق من أن سياسات استخدام البيانات وممارسات إدارة موافقة المستخدم يتم توضيحها بوضوح لأصحاب المصلحة.
 #13.7.2    المستوى: 2    الدور: D/V
 تحقق من إجراء تقييمات تأثير الذكاء الاصطناعي وتضمين النتائج في التقارير.
 #13.7.3    المستوى: 2    الدور: D/V
 تحقق من أن تقارير الشفافية المنشورة بانتظام تكشف عن حوادث الذكاء الاصطناعي ومقاييس الأداء بتفاصيل معقولة.

#### المراجع

EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
ISO/IEC 42001:2023 — AI Management Systems Requirements
NIST AI Risk Management Framework 1.0
NIST SP 800-53 Revision 5 — Security and Privacy Controls
A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)
Model Cards for Model Reporting (Mitchell et al., 2018)
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)
ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods
IEEE 7001-2021 — Transparency of Autonomous Systems
GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)
Human Oversight under Article 14 of the EU AI Act (Fink, 2025)

## الملحق أ: مسرد المصطلحات

يوفر هذا القاموس الشامل تعريفات للمصطلحات الرئيسية في الذكاء الاصطناعي، وتعلم الآلة، والأمن المستخدمة في جميع أنحاء نظام AISVS لضمان الوضوح والفهم المشترك.

مثال الخصم: إدخال تم تصميمه عمدًا لإجبار نموذج الذكاء الاصطناعي على ارتكاب خطأ، غالبًا عن طريق إضافة تعديلات طفيفة غير مرئية للبشر.
​
المتانة العدائية – تشير المتانة العدائية في الذكاء الاصطناعي إلى قدرة النموذج على الحفاظ على أدائه ومقاومة الخداع أو التلاعب من خلال مدخلات خبيثة مصممة بشكل متعمد لإحداث أخطاء.
​
الوكيل – الوكلاء الذكيون هم أنظمة برمجية تستخدم الذكاء الاصطناعي لتحقيق أهداف وإتمام مهام نيابةً عن المستخدمين. يظهرون القدرة على الاستدلال، والتخطيط، والذاكرة، ولديهم مستوى من الاستقلالية لاتخاذ القرارات والتعلم والتكيف.
​
الذكاء الاصطناعي الوكالي: أنظمة الذكاء الاصطناعي التي يمكنها العمل بدرجة معينة من الاستقلالية لتحقيق الأهداف، غالبًا ما تتخذ قرارات وتتخذ إجراءات دون تدخل بشري مباشر.
​
التحكم في الوصول القائم على السمات (ABAC): نموذج للتحكم في الوصول حيث تستند قرارات التفويض إلى سمات المستخدم، المورد، الإجراء، والبيئة، ويتم تقييمها في وقت الاستعلام.
​
هجوم الباب الخلفي: نوع من هجمات تسميم البيانات حيث يتم تدريب النموذج للاستجابة بطريقة معينة لمثيرات محددة مع التصرف بشكل طبيعي بخلاف ذلك.
​
التحيز: أخطاء منهجية في مخرجات نموذج الذكاء الاصطناعي يمكن أن تؤدي إلى نتائج غير عادلة أو تمييزية لمجموعات معينة أو في سياقات محددة.
​
استغلال التحيز: تقنية هجوم تستغل التحيزات المعروفة في نماذج الذكاء الاصطناعي للتلاعب بالمخرجات أو النتائج.
​
سيدر: لغة سياسة أمازون ومحركها للصلاحيات الدقيقة المستخدمة في تنفيذ التحكم في الوصول المعتمد على السمات (ABAC) لأنظمة الذكاء الاصطناعي.
​
سلسلة التفكير: تقنية لتحسين الاستدلال في نماذج اللغة من خلال إنشاء خطوات استدلال وسيطة قبل إنتاج الإجابة النهائية.
​
قواطع الدائرة: آليات توقف عمليات نظام الذكاء الاصطناعي تلقائيًا عند تجاوز حدود معينة للمخاطر.
​
تسرب البيانات: التعرض غير المقصود للمعلومات الحساسة من خلال مخرجات أو سلوك نموذج الذكاء الاصطناعي.
​
تسميم البيانات: هو الفساد المتعمد لبيانات التدريب بهدف الإضرار بسلامة النموذج، غالبًا لتثبيت أبواب خلفية أو تدهور الأداء.
​
الخصوصية التفاضلية – الخصوصية التفاضلية هي إطار عمل رياضي دقيق لإصدار معلومات إحصائية حول مجموعات البيانات مع حماية خصوصية الأفراد المعنيين بالبيانات. تسمح لحامل البيانات بمشاركة أنماط مجموعية للمجموعة مع تقليل المعلومات التي يتم تسريبها عن أفراد محددين.
​
التضمينات: تمثيلات متجهية كثيفة للبيانات (نصوص، صور، إلخ) تلتقط المعنى الدلالي في فضاء عالي الأبعاد.
​
الشرحية – الشرحية في الذكاء الاصطناعي هي قدرة نظام الذكاء الاصطناعي على تقديم أسباب مفهومة للبشر لقراراته وتوقعاته، مما يوفر رؤى حول كيفية عمله الداخلي.
​
الذكاء الاصطناعي القابل للتفسير (XAI): أنظمة الذكاء الاصطناعي المصممة لتوفير تفسيرات قابلة للفهم البشري لقراراتها وسلوكياتها من خلال تقنيات وأُطُر متنوعة.
​
التعلم الفدرالي: نهج في التعلم الآلي حيث يتم تدريب النماذج عبر عدة أجهزة لا مركزية تحتفظ بعينات بيانات محلية، دون تبادل البيانات نفسها.
​
القيود الأمنية: القيود التي تُنفذ لمنع أنظمة الذكاء الاصطناعي من إنتاج مخرجات ضارة أو متحيزة أو غير مرغوب فيها بأي شكل آخر.
​
الهلاوس – تشير هلاوس الـ AI إلى ظاهرة حيث يقوم نموذج الذكاء الاصطناعي بتوليد معلومات غير صحيحة أو مضللة ليست مستندة إلى بيانات التدريب الخاصة به أو الواقع الفعلي.
​
الإنسان في الحلقة (HITL): أنظمة مصممة لتتطلب إشراف الإنسان، التحقق، أو التدخل في نقاط اتخاذ القرار الحاسمة.
​
البنية التحتية كرمز (IaC): إدارة وتوفير البنية التحتية من خلال الكود بدلاً من العمليات اليدوية، مما يتيح فحص الأمان وعمليات النشر المتسقة.
​
الهروب من القيود: تقنيات تُستخدم لتجاوز ضوابط الأمان في أنظمة الذكاء الاصطناعي، وخاصة في نماذج اللغة الكبيرة، لإنتاج محتوى محظور.
​
الامتياز الأدنى: مبدأ الأمان الذي ينص على منح أقل حقوق وصول ضرورية فقط للمستخدمين والعمليات.
​
LIME (التفسيرات المحلية المستقلة عن النموذج): تقنية لشرح توقعات أي مصنف تعلم آلي عن طريق تقريبها محليًا باستخدام نموذج قابل للتفسير.
​
هجوم استدلال العضوية: هو هجوم يهدف إلى تحديد ما إذا تم استخدام نقطة بيانات محددة لتدريب نموذج التعلم الآلي.
​
MITRE ATLAS: مشهد التهديدات العدائية لأنظمة الذكاء الاصطناعي؛ قاعدة معرفية للتكتيكات والأساليب العدائية ضد أنظمة الذكاء الاصطناعي.
​
بطاقة النموذج – بطاقة النموذج هي وثيقة توفر معلومات معيارية حول أداء نموذج الذكاء الاصطناعي، والقيود، والاستخدامات المقصودة، والاعتبارات الأخلاقية لتعزيز الشفافية والتنمية المسؤولة للذكاء الاصطناعي.
​
استخلاص النموذج: هجوم يقوم فيه الخصم باستمرار استجواب نموذج مستهدف لإنشاء نسخة وظيفية مشابهة بدون إذن.
​
عكس النموذج: هجوم يحاول إعادة بناء بيانات التدريب من خلال تحليل مخرجات النموذج.
​
إدارة دورة حياة النموذج – إدارة دورة حياة نموذج الذكاء الاصطناعي هي عملية الإشراف على جميع مراحل وجود نموذج الذكاء الاصطناعي، بما في ذلك تصميمه، وتطويره، ونشره، ومراقبته، وصيانته، والتقاعد النهائي له، لضمان استمراره في الفعالية والتوافق مع الأهداف.
​
تسميم النموذج: إدخال ثغرات أو أبواب خلفية مباشرة في النموذج أثناء عملية التدريب.
​
سرقة/استنساخ النموذج: استخراج نسخة أو تقريبات لنموذج مملوك من خلال استعلامات متكررة.
​
نظام متعدد الوكلاء: نظام يتكون من عدة عوامل ذكاء اصطناعي تفاعلية، كل منها قد يمتلك قدرات وأهداف مختلفة.
​
OPA (وكيل السياسة المفتوحة): محرك سياسات مفتوح المصدر يتيح تطبيق السياسات بشكل موحد عبر جميع المستويات.
​
التعلم الآلي مع الحفاظ على الخصوصية (PPML): تقنيات وأساليب لتدريب ونشر نماذج التعلم الآلي مع حماية خصوصية بيانات التدريب.
​
حقن المدخلات: هجوم يتم فيه تضمين تعليمات خبيثة في المدخلات لتجاوز سلوك النموذج المقصود.
​
RAG (التوليد المعزز بالاستخراج): تقنية تعزز نماذج اللغة الكبيرة من خلال استرجاع المعلومات ذات الصلة من مصادر المعرفة الخارجية قبل توليد الاستجابة.
​
الهجوم الأحمر: ممارسة اختبار أنظمة الذكاء الاصطناعي بشكل فعّال من خلال محاكاة هجمات معادية لتحديد نقاط الضعف.
​
SBOM (قائمة مكونات البرمجيات): سجل رسمي يحتوي على تفاصيل وعلاقات سلسلة التوريد لمكونات مختلفة تُستخدم في بناء البرمجيات أو نماذج الذكاء الاصطناعي.
​
SHAP (تفسيرات شابلية التضافر): نهج يعتمد على نظرية الألعاب لشرح ناتج أي نموذج تعلم آلي من خلال حساب مساهمة كل ميزة في التنبؤ.
​
هجوم سلسلة التوريد: اختراق نظام عن طريق استهداف العناصر الأقل أمانًا في سلسلة التوريد الخاصة به، مثل مكتبات الطرف الثالث، مجموعات البيانات، أو النماذج المدربة مسبقًا.
​
التعلم الانتقالي: تقنية يتم فيها إعادة استخدام نموذج تم تطويره لمهمة واحدة كنقطة انطلاق لنموذج في مهمة ثانية.
​
قاعدة البيانات الشعاعية: قاعدة بيانات متخصصة مصممة لتخزين المتجهات عالية الأبعاد (التضمينات) وتنفيذ عمليات بحث تشابه فعالة.
​
فحص الثغرات الأمنية: أدوات آلية تحدد الثغرات الأمنية المعروفة في مكونات البرمجيات، بما في ذلك أُطُر العمل للذكاء الاصطناعي والتبعيات.
​
الوسم المائي: تقنيات تضمين علامات غير قابلة للإدراك في المحتوى المُنتج بواسطة الذكاء الاصطناعي لتتبع مصدره أو اكتشاف توليده بواسطة الذكاء الاصطناعي.
​
ثغرة اليوم الصفري: هي ثغرة لم تكن معروفة سابقًا يمكن للمهاجمين استغلالها قبل أن يقوم المطورون بإنشاء ونشر ترقية إصلاحية.

## الملحق ب: المراجع

### TODO

## الملحق ج: حوكمة أمن الذكاء الاصطناعي والتوثيق

### الهدف

يوفر هذا الملحق المتطلبات الأساسية لإنشاء هياكل تنظيمية وسياسات وعمليات لحوكمة أمن الذكاء الاصطناعي طوال دورة حياة النظام.

---

### اعتماد إطار عمل إدارة مخاطر الذكاء الاصطناعي AC.1

توفير إطار رسمي لتحديد وتقييم وتخفيف المخاطر الخاصة بالذكاء الاصطناعي طوال دورة حياة النظام.

 #AC.1.1    المستوى: 1    الدور: D/V
 تحقق من توثيق وتنفيذ منهجية تقييم المخاطر الخاصة بالذكاء الاصطناعي.
 #AC.1.2    المستوى: 2    الدور: D
 تحقق من أن تقييمات المخاطر تُجرى في نقاط رئيسية في دورة حياة الذكاء الاصطناعي وقبل التغييرات الكبيرة.
 #AC.1.3    المستوى: 3    الدور: D/V
 تحقق من أن إطار إدارة المخاطر يتماشى مع المعايير المعتمدة (مثل NIST AI RMF).

---

### سياسة وإجراءات أمان الذكاء الاصطناعي AC.2

تحديد وتنفيذ معايير تنظيمية لتطوير ونشر وتشغيل الذكاء الاصطناعي بشكل آمن.

 #AC.2.1    المستوى: 1    الدور: D/V
 التحقق من وجود سياسات أمنية موثقة للذكاء الاصطناعي.
 #AC.2.2    المستوى: 2    الدور: D
 تحقق من مراجعة السياسات وتحديثها على الأقل سنويًا وبعد التغييرات الكبيرة في مشهد التهديدات.
 #AC.2.3    المستوى: 3    الدور: D/V
 تحقق من أن السياسات تغطي جميع فئات AISVS والمتطلبات التنظيمية المعمول بها.

---

### AC.3 الأدوار والمسؤوليات لأمن الذكاء الاصطناعي

إنشاء مسؤولية واضحة لأمان الذكاء الاصطناعي عبر المنظمة.

 #AC.3.1    المستوى: 1    الدور: D/V
 تحقق من توثيق أدوار ومسؤوليات أمان الذكاء الاصطناعي.
 #AC.3.2    المستوى: 2    الدور: D
 تحقق من أن الأفراد المسؤولين يمتلكون الخبرة الأمنية المناسبة.
 #AC.3.3    المستوى: 3    الدور: D/V
 تحقق من تأسيس لجنة أخلاقيات الذكاء الاصطناعي أو مجلس الحوكمة للأنظمة عالية المخاطر في الذكاء الاصطناعي.

---

### AC.4 تنفيذ إرشادات الذكاء الاصطناعي الأخلاقي

ضمان تشغيل أنظمة الذكاء الاصطناعي وفقًا للمبادئ الأخلاقية المعتمدة.

 #AC.4.1    المستوى: 1    الدور: D/V
 تحقق من وجود إرشادات أخلاقية لتطوير ونشر الذكاء الاصطناعي.
 #AC.4.2    المستوى: 2    الدور: D
 تحقق من وجود آليات للكشف عن الانتهاكات الأخلاقية والإبلاغ عنها.
 #AC.4.3    المستوى: 3    الدور: D/V
 تحقق من إجراء مراجعات أخلاقية منتظمة لأنظمة الذكاء الاصطناعي المنشورة.

---

### AC.5 مراقبة الامتثال التنظيمي للذكاء الاصطناعي

حافظ على الوعي والامتثال للوائح الذكاء الاصطناعي المتطورة.

 #AC.5.1    المستوى: 1    الدور: D/V
 تحقق من وجود عمليات لتحديد اللوائح التنظيمية الخاصة بالذكاء الاصطناعي المعمول بها.
 #AC.5.2    المستوى: 2    الدور: D
 تحقق من تقييم الامتثال لجميع المتطلبات التنظيمية.
 #AC.5.3    المستوى: 3    الدور: D/V
 تحقق من أن التغييرات التنظيمية تؤدي إلى مراجعات وتحديثات في الوقت المناسب لأنظمة الذكاء الاصطناعي.

### AC.6 حوكمة بيانات التدريب، التوثيق والعمليات

 #1.1.2    المستوى: 1    الدور: D/V
 تحقق من السماح فقط بالمجموعات البيانية التي تم تقييمها من حيث الجودة، والتمثيلية، والمصادر الأخلاقية، والامتثال للرخصة، مما يقلل من مخاطر التسمم، والتحيز المدمج، وانتهاك حقوق الملكية الفكرية.
 #1.1.5    المستوى: 2    الدور: D/V
 تحقق من ضمان جودة التصنيف/التعليق من خلال مراجعات متبادلة من قبل المراجعين أو التوافق الجماعي.
 #1.1.6    المستوى: 2    الدور: D/V
 تحقق من أنه يتم الاحتفاظ بـ "بطاقات البيانات" أو "صحائف البيانات لمجموعات البيانات" لمجموعات البيانات التدريبية الهامة، توضح الخصائص والدوافع والتركيب وعمليات التجميع والمعالجة المسبقة والاستخدامات الموصى بها والمحرمة.
 #1.3.2    المستوى: 2    الدور: D/V
 التحقق من أن التحيزات المحددة يتم التخفيف منها من خلال استراتيجيات موثقة مثل إعادة التوازن، زيادة البيانات المستهدفة، التعديلات الخوارزمية (مثل تقنيات المعالجة المسبقة، المعالجة أثناء التنفيذ، المعالجة اللاحقة)، أو إعادة التوزين، ويتم تقييم تأثير التخفيف على كل من العدالة وأداء النموذج العام.
 #1.3.3    المستوى: 2    الدور: D/V
 التحقق من تقييم وتوثيق مقاييس الإنصاف بعد التدريب.
 #1.3.4    المستوى: 3    الدور: D/V
 تحقق من أن سياسة إدارة انحياز دورة الحياة تحدد المالكين وتواتر المراجعة.
 #1.4.1    المستوى: 2    الدور: D/V
 تحقق من ضمان جودة التعليم / التوسيم من خلال إرشادات واضحة، ومراجعات متبادلة من قبل المراجع، وآليات التوافق (مثل مراقبة اتفاقية بين المعلمين)، وعمليات محددة لحل النزاعات.
 #1.4.4    المستوى: 3    الدور: D/V
 تحقق من أن الملصقات الحرجة للسلامة أو الأمان أو العدالة (مثل تحديد المحتوى السام، أو النتائج الطبية الحرجة) تخضع لمراجعة مزدوجة مستقلة إلزامية أو تحقق قوي مكافئ.
 #1.4.6    المستوى: 2    الدور: D/V
 تحقق من أن أدلة التعليمات والإرشادات الخاصة بالتوسيم شاملة، وتخضع للتحكم في الإصدارات، ومراجعة الأقران.
 #1.4.6    المستوى: 2    الدور: D/V
 تحقق من أن مخططات البيانات الخاصة بالتسميات محددة بوضوح وتخضع للتحكم في الإصدارات.
 #1.3.1    المستوى: 1    الدور: D/V
 التحقق من أن مجموعات البيانات قد تم تحليلها للكشف عن عدم التوازن التمثيلي والتحيزات المحتملة عبر الخصائص المحمية قانونيًا (مثل العرق، الجنس، العمر) وغيرها من الخصائص الحساسة أخلاقيًا ذات الصلة بنطاق تطبيق النموذج (مثل الوضع الاجتماعي الاقتصادي، الموقع).
 #1.5.3    المستوى: 2    الدور: V
 تحقق من أن الفحوصات اليدوية العينية بواسطة الخبراء في المجال تغطي عينة ذات دلالة إحصائية كبيرة (مثل ≥1% أو 1,000 عينة، أيهما أكبر، أو حسب ما تحدده تقييمات المخاطر) لتحديد مشكلات الجودة الدقيقة التي لم تكتشفها الأتمتة.
 #1.8.4    المستوى: 2    الدور: D/V
 تحقق من أن عمليات تصنيف البيانات التي تتم عن طريق الاستعانة بمصادر خارجية أو المصادر الجماعية تتضمن ضمانات تقنية وإجرائية لضمان سرية البيانات وسلامتها وجودة التصنيف ومنع تسرب البيانات.
 #1.5.4    المستوى: 2    الدور: D/V
 تحقق من أنه تم إلحاق خطوات المعالجة بسجلات الأصل.
 #1.6.2    المستوى: 2    الدور: D/V
 تحقق من أن العينات المعلمة تستدعي المراجعة اليدوية قبل التدريب.
 #1.6.3    المستوى: 2    الدور: V
 تحقق من أن النتائج تغذي ملف أمان النموذج وتُعلم معلومات التهديد المستمرة.
 #1.6.4    المستوى: 3    الدور: D/V
 تحقق من تحديث منطق الكشف بمعلومات التهديدات الجديدة.
 #1.6.5    المستوى: 3    الدور: D/V
 تحقق من أن خطوط أنابيب التعلم عبر الإنترنت تراقب الانحراف في التوزيع.
 #1.7.1    المستوى: 1    الدور: D/V
 تحقق من أن سير عمل حذف بيانات التدريب يقوم بمسح البيانات الأولية والمشتقة وتقييم تأثير ذلك على النموذج، وأن يتم تقييم التأثير على النماذج المتأثرة وإذا لزم الأمر معالجته (مثل إعادة التدريب أو إعادة المعايرة).
 #1.7.2    المستوى: 2    الدور: D
 تحقق من وجود آليات لتتبع واحترام نطاق وحالة موافقة المستخدم (وإنسحاباتها) للبيانات المستخدمة في التدريب، وأن يتم التحقق من صحة الموافقة قبل إدخال البيانات في عمليات تدريب جديدة أو تحديثات هامة للنموذج.
 #1.7.3    المستوى: 2    الدور: V
 تحقق من أن تدفقات العمل يتم اختبارها سنويًا وتسجيلها.
 #1.8.1    المستوى: 2    الدور: D/V
 تحقق من أن موردي البيانات من الأطراف الثالثة، بما في ذلك مزودي النماذج المدربة مسبقًا والمجموعات البيانية الخارجية، يخضعون لإجراءات العناية الواجبة المتعلقة بالأمن والخصوصية والمصادر الأخلاقية وجودة البيانات قبل دمج بياناتهم أو نماذجهم.
 #1.8.2    المستوى: 1    الدور: D
 تحقق من أن التحويلات الخارجية تستخدم TLS/المصادقة وفحوصات النزاهة.
 #1.8.3    المستوى: 2    الدور: D/V
 تحقق من أن مصادر البيانات عالية المخاطر (مثل مجموعات البيانات مفتوحة المصدر ذات الأصل غير المعروف، والموردين غير المفحوصين) تخضع لتدقيق معزز، مثل التحليل في بيئة معزولة (sandbox)، وفحوصات جودة وانحياز موسعة، واكتشاف التسمم المستهدف، قبل استخدامها في التطبيقات الحساسة.
 #1.8.4    المستوى: 3    الدور: D/V
 تحقق من أن النماذج المدربة مسبقًا التي تم الحصول عليها من جهات خارجية تم تقييمها للكشف عن الانحيازات المدمجة، والباب الخلفي المحتمل، وسلامة هيكلها، وأصل بيانات التدريب الأصلية الخاصة بها قبل التخصيص أو النشر.
 #1.5.3    المستوى: 2    الدور: D/V
 تحقق من أنه إذا تم استخدام التدريب العدائي، فإن إنشاء وإدارة وإصدار مجموعات البيانات العدائية يتم توثيقه والسيطرة عليه.
 #1.5.3    المستوى: 3    الدور: D/V
 تحقق من أن تأثير تدريب المتانة ضد الهجمات العدائية على أداء النموذج (مقابل المدخلات النظيفة والعدائية) ومؤشرات العدالة يتم تقييمه وتوثيقه ومراقبته.
 #1.5.4    المستوى: 3    الدور: D/V
 تأكد من مراجعة وتحديث استراتيجيات التدريب العدائي والصلابة بشكل دوري لمواجهة تقنيات الهجوم العدائية المتطورة.
 #1.4.2    المستوى: 2    الدور: D/V
 تحقق من أن مجموعات البيانات الفاشلة تم عزلها مع وجود سجلات تدقيق.
 #1.4.3    المستوى: 2    الدور: D/V
 تحقق من أن بوابات الجودة تمنع مجموعات البيانات الأقل جودة ما لم تتم الموافقة على الاستثناءات.
 #1.11.2    المستوى: 2    الدور: D/V
 تحقق من توثيق عملية التوليد والمعلمات والاستخدام المقصود للبيانات التركيبية.
 #1.11.3    المستوى: 2    الدور: D/V
 تحقق من تقييم البيانات التركيبية من حيث المخاطر المتعلقة بالتحيز، وتسرب الخصوصية، وقضايا التمثيل قبل استخدامها في التدريب.
 #1.12.3    المستوى: 2    الدور: D/V
 تحقق من أنه يتم توليد التنبيهات للأحداث المشبوهة للوصول وأنه يتم التحقيق فيها على الفور.
 #1.13.1    المستوى: 1    الدور: D/V
 تحقق من تحديد فترات الاحتفاظ الصريحة لجميع مجموعات بيانات التدريب.
 #1.13.2    المستوى: 2    الدور: D/V
 تحقق من أن مجموعات البيانات تنتهي صلاحيتها تلقائيًا، أو تُحذف، أو تُراجع للحذف في نهاية دورة حياتها.
 #1.13.3    المستوى: 2    الدور: D/V
 تحقق من تسجيل إجراءات الاحتفاظ والحذف وقابليتها للمراجعة.
 #1.14.1    المستوى: 2    الدور: D/V
 التحقق من تحديد وإنفاذ متطلبات إقامة البيانات والنقل عبر الحدود لجميع مجموعات البيانات.
 #1.14.2    المستوى: 2    الدور: D/V
 تحقق من تحديد اللوائح الخاصة بالقطاعات المحددة (مثل الرعاية الصحية، المالية) ومعالجتها في التعامل مع البيانات.
 #1.14.3    المستوى: 2    الدور: D/V
 تأكد من توثيق ومراجعة الامتثال للقوانين المتعلقة بالخصوصية ذات الصلة (مثل GDPR، CCPA) بانتظام.
 #1.16.1    المستوى: 2    الدور: D/V
 تحقق من وجود آليات للاستجابة لطلبات الأشخاص المعنيين للوصول إلى البيانات، تصحيحها، تقييدها، أو الاعتراض عليها.
 #1.16.2    المستوى: 2    الدور: D/V
 تحقق من أن الطلبات يتم تسجيلها وتتبعها وتنفيذها ضمن الأُطُر الزمنية المفروضة قانونيًا.
 #1.16.3    المستوى: 2    الدور: D/V
 التحقق من اختبار عمليات حقوق موضوع البيانات ومراجعتها بانتظام لضمان الفعالية.
 #1.17.1    المستوى: 2    الدور: D/V
 تحقق من إجراء تحليل تأثير قبل تحديث أو استبدال إصدار مجموعة البيانات، بحيث يشمل أداء النموذج، والعدالة، والامتثال.
 #1.17.2    المستوى: 2    الدور: D/V
 تحقق من توثيق نتائج تحليل التأثير ومراجعتها من قبل أصحاب المصلحة المعنيين.
 #1.17.3    المستوى: 2    الدور: D/V
 تحقق من وجود خطط للتراجع في حال أدت الإصدارات الجديدة إلى مخاطر غير مقبولة أو تراجعات.
 #1.18.1    المستوى: 2    الدور: D/V
 تأكد من أن جميع الأشخاص المعنيين بوضع العلامات على البيانات قد خضعوا لفحص خلفية وتدريبوا على أمن البيانات والخصوصية.
 #1.18.2    المستوى: 2    الدور: D/V
 تحقق من أن جميع العاملين في التوضيح يوقعون على اتفاقيات السرية وعدم الإفشاء.
 #1.18.3    المستوى: 2    الدور: D/V
 تأكد من أن منصات التعليقات التوضيحية تفرض ضوابط الوصول وترصد التهديدات الداخلية.

#### المراجع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
EU Artificial Intelligence Act — Regulation (EU) 2024/1689
ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods

## الملحق د: حوكمة وتحقق البرمجة الآمنة المعززة بالذكاء الاصطناعي

### الهدف

يحدد هذا الفصل الضوابط التنظيمية الأساسية للاستخدام الآمن والفعال لأدوات الترميز المدعومة بالذكاء الاصطناعي أثناء تطوير البرمجيات، مع ضمان الأمان وقابلية التتبع عبر دورة حياة تطوير البرمجيات.

---

### AD.1 سير عمل الترميز الآمن بمساعدة الذكاء الاصطناعي

دمج أدوات الذكاء الاصطناعي في دورة حياة تطوير البرمجيات الآمنة (SSDLC) للمنظمة دون إضعاف بوابات الأمان الحالية.

 #AD.1.1    المستوى: 1    الدور: D/V
 تحقق من أن سير العمل الموثق يصف متى وكيف يمكن لأدوات الذكاء الاصطناعي أن تنشئ، أو تعيد هيكلة، أو تراجع الأكواد.
 #AD.1.2    المستوى: 2    الدور: D
 تحقق من أن سير العمل يتوافق مع كل مرحلة من مراحل دورة حياة تطوير برامج الأمان البرمجية (تصميم، تنفيذ، مراجعة الشيفرة، اختبار، نشر).
 #AD.1.3    المستوى: 3    الدور: D/V
 تحقق من جمع المقاييس (مثل كثافة الثغرات، ومتوسط الوقت للكشف) على الشيفرة التي تنتجها الذكاء الاصطناعي ومقارنتها بالمعايير الأساسية التي ينتجها البشر فقط.

---

### AD.2 تأهيل أداة الذكاء الاصطناعي ونمذجة التهديدات

تأكد من تقييم أدوات الترميز المعتمدة على الذكاء الاصطناعي من حيث القدرات الأمنية، والمخاطر، وتأثير سلسلة التوريد قبل اعتمادها.

 #AD.2.1    المستوى: 1    الدور: D/V
 تحقق من أن نموذج التهديد لكل أداة ذكاء اصطناعي يحدد سوء الاستخدام، انقلاب النموذج، تسرب البيانات، ومخاطر سلسلة التبعيات.
 #AD.2.2    المستوى: 2    الدور: D
 تحقق من أن تقييمات الأدوات تشمل التحليل الثابت/الديناميكي لأي مكونات محلية وتقييم نقاط نهاية SaaS (TLS، المصادقة/التفويض، التسجيل).
 #AD.2.3    المستوى: 3    الدور: D/V
 تحقق من أن التقييمات تتبع إطارًا معترفًا به ويتم إعادة إجرائها بعد تغييرات الإصدار الرئيسية.

---

### إدارة الأوامر والسياق الآمنة AD.3

منع تسرب الأسرار، الشيفرات المملوكة، والبيانات الشخصية عند إنشاء المطالبات أو السياقات لنماذج الذكاء الاصطناعي.

 #AD.3.1    المستوى: 1    الدور: D/V
 تحقق من أن الإرشادات المكتوبة تمنع إرسال الأسرار أو بيانات الاعتماد أو البيانات المصنفة في المطالبات.
 #AD.3.2    المستوى: 2    الدور: D
 تحقق من أن الضوابط التقنية (الإخفاء من جهة العميل، مرشحات السياق المعتمدة) تقوم تلقائيًا بإزالة البيانات الحساسة.
 #AD.3.3    المستوى: 3    الدور: D/V
 تحقق من أن الطلبات والاستجابات يتم تقسيمها إلى وحدات نصية، وتشفيرها أثناء النقل وعند التخزين، وأن فترات الاحتفاظ تتوافق مع سياسة تصنيف البيانات.

---

### AD.4 التحقق من صحة الشفرة المولدة بواسطة الذكاء الاصطناعي

اكتشف وقم بإصلاح الثغرات التي يتم إدخالها بواسطة مخرجات الذكاء الاصطناعي قبل دمج الشيفرة أو نشرها.

 #AD.4.1    المستوى: 1    الدور: D/V
 تأكد من أن الكود الذي تم إنشاؤه بواسطة الذكاء الاصطناعي يخضع دائمًا لمراجعة بشرية.
 #AD.4.2    المستوى: 2    الدور: D
 تحقق من تشغيل الفاحصات الآلية (SAST/IAST/DAST) على كل طلب سحب يحتوي على كود مولد بواسطة الذكاء الاصطناعي ومنع الدمج في حالة وجود نتائج حرجة.
 #AD.4.3    المستوى: 3    الدور: D/V
 تحقق من أن اختبار التعتيم التفاضلي أو اختبارات الاعتماد على الخصائص تثبت سلوكيات حرجة للأمان (مثل التحقق من صحة الإدخال، منطق التفويض).

---

### AD.5 قابلية التفسير وتتبع اقتراحات الشفرة

تزويد المدققين والمطورين بفهم حول سبب تقديم الاقتراح وكيف تطور.

 #AD.5.1    المستوى: 1    الدور: D/V
 تحقق من أن أزواج الطلب/الاستجابة يتم تسجيلها مع معرفات الالتزام.
 #AD.5.2    المستوى: 2    الدور: D
 تحقق من أن المطورين يمكنهم عرض استشهادات النموذج (مقتطفات التدريب، الوثائق) التي تدعم الاقتراح.
 #AD.5.3    المستوى: 3    الدور: D/V
 تحقق من أن تقارير قابلية الشرح مخزنة مع المنتجات التصميمية ومشار إليها في مراجعات الأمن، مما يرضي مبادئ إمكانية التتبع في معيار ISO/IEC 42001.

---

### AD.6 التغذية الراجعة المستمرة وضبط النموذج الدقيق

تحسين أداء أمان النموذج مع مرور الوقت مع منع الانحراف السلبي.

 #AD.6.1    المستوى: 1    الدور: D/V
 تحقق من أن المطورين يمكنهم وسم الاقتراحات غير الآمنة أو غير المتوافقة، وأن الأوسمة يتم تتبعها.
 #AD.6.2    المستوى: 2    الدور: D
 تحقق من أن التغذية الراجعة المجمعة تُستخدم في التعديل الدقيق الدوري أو التوليد المدعوم بالاسترجاع باستخدام مجموعات بيانات الأكواد الآمنة التي تم تدقيقها (مثل أوراق الغش OWASP).
 #AD.6.3    المستوى: 3    الدور: D/V
 تحقق من أن نظام تقييم الحلقة المغلقة يقوم بتشغيل اختبارات الانحدار بعد كل ضبط دقيق؛ يجب أن تفي مقاييس الأمان أو تتجاوز المستويات الأساسية السابقة قبل النشر.

---

#### المراجع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
OWASP Secure Coding Practices — Quick Reference Guide

## الملحق هـ: أمثلة للأدوات والأُطُر

### الهدف

يوفر هذا الفصل أمثلة على الأدوات والأُطُر التي يمكنها دعم تنفيذ أو تحقيق متطلبات AISVS معينة. لا ينبغي اعتبار هذه الأمثلة توصيات أو تأييدات من فريق AISVS أو مشروع أمان OWASP GenAI.

---

### AE.1 حوكمة بيانات التدريب وإدارة التحيز

الأدوات المستخدمة لتحليل البيانات، الحوكمة، وإدارة التحيز.

 #AE.1.1    القسم: 1.1
 أدوات جرد البيانات: أدوات إدارة جرد البيانات مثل...
 #AE.1.2    القسم: 1.2
 التشفير أثناء النقل استخدم TLS لتطبيقات HTTPS، مع أدوات مثل openSSL و python's`ssl`مكتبة.

---

### AE.2 تحقق من صحة مدخلات المستخدم

أدوات لمعالجة وتحقق صحة مدخلات المستخدم.

 #AE.2.1    القسم: 2.1
 أدوات الدفاع ضد حقن الموجهات: استخدم أدوات الحماية مثل NeMo من NVIDIA أو Guardrails AI.

---

