## لوحة أمامية

### حول المعيار

معيار أمان التحقق من الذكاء الاصطناعي (AISVS) هو فهرس مدفوع بالمجتمع لمتطلبات الأمان يمكن لعلماء البيانات، ومهندسي MLOps، ومعماريي البرمجيات، والمطورين، والمختبرين، والمتخصصين في الأمن، وبائعي الأدوات، والجهات التنظيمية، والمستهلكين استخدامه لتصميم وبناء واختبار والتحقق من أنظمة وتطبيقات مدعومة بالذكاء الاصطناعي موثوقة. إنه يوفر لغة مشتركة لتحديد ضوابط الأمان عبر دورة حياة الذكاء الاصطناعي—from data collection and model development to deployment and ongoing monitoring—حتى تتمكن المؤسسات من قياس وتحسين المتانة والخصوصية والسلامة لحلولها في مجال الذكاء الاصطناعي.

### حقوق النشر والترخيص

الإصدار 0.1 (المسودة العامة الأولى - قيد التطوير)، 2025  

![license](images/license.png)
حقوق النشر © 2025 مشروع AISVS  

صدر بموجبCreative Commons Attribution‑ShareAlike 4.0 International License.
لأي إعادة استخدام أو توزيع، يجب عليك توضيح شروط الترخيص الخاصة بهذا العمل للآخرين بوضوح.

### قادة المشروع

جيم مانيكو
Aras “Russ” Memisyazici

### المساهمون والمراجعون

https://github.com/ottosulin
https://github.com/mbhatt1
https://github.com/vineethsai
https://github.com/cciprofm
https://github.com/deepakrpandey12


---

AISVS هو معيار جديد كلياً صُمم خصيصاً لمعالجة التحديات الأمنية الفريدة لأنظمة الذكاء الاصطناعي. بينما يستلهم من أفضل ممارسات الأمن على نطاق أوسع، فقد تم تطوير كل متطلب في AISVS من الأساس ليعكس مشهد التهديدات المرتبطة بالذكاء الاصطناعي ولمساعدة المؤسسات في بناء حلول ذكاء اصطناعي أكثر أماناً ومرونة.

## المقدمة

مرحبًا بكم في معيار التحقق من أمان الذكاء الاصطناعي (AISVS) الإصدار 1.0!

### مقدمة

تأسست AISVS في عام 2025 من خلال جهدٍ مجتمعي تعاوني، وتحدد المتطلبات الأمنية التي يجب أخذها بعين الاعتبار عند تصميم وتطوير ونشر وتشغيل نماذج الذكاء الاصطناعي الحديثة، وخطوط أنابيب تعلم الآلة، والخدمات AI‑enabled.

AISVS v1.0 يمثل العمل المجمّع لقادة المشروع، ومجموعة العمل، ومساهمي المجتمع الأوسع لإنتاج خط أساس عملي وقابل للاختبار لضمان أمان أنظمة الذكاء الاصطناعي.

هدفنا من هذا الإصدار هو جعل AISVS سهل التبنّي مع الحفاظ على تركيز حاد على النطاق المحدد له ومعالجة مشهد المخاطر الذي يتطور بسرعة والذي يخص الذكاء الاصطناعي.

### الأهداف الرئيسية لـ AISVS الإصدار 1.0

سيتم إنشاء الإصدار 1.0 مع عدة مبادئ توجيهية.

#### نطاق محدد بشكل واضح

يجب أن تتماشى كل متطلب مع اسم AISVS ومهمته:

الذكاء الاصطناعي – تعمل الضوابط على طبقة AI/ML (البيانات، النموذج، خط الأنابيب، أو الاستدلال)، وهي مسؤولية ممارسي الذكاء الاصطناعي.
الأمن – المتطلبات تقلل مباشرة من المخاطر المحددة المرتبطة بالأمن والخصوصية أو السلامة.
التحقق – اللغة مكتوبة بحيث يمكن التحقق من المطابقة بشكل موضوعي.
المعيار – تتبع الأقسام بنيةً موحّدة ومصطلحاتٍ متسقة لتشكّل مرجعًا متماسكًا.
​
---

باتباع AISVS، يمكن للمؤسسات تقييم الوضع الأمني لحلولها في الذكاء الاصطناعي بشكل منهجي وتعزيزه، مما يعزز ثقافة الهندسة الآمنة للذكاء الاصطناعي.

## باستخدام AISVS

المعيار الأمني للتحقق من الذكاء الاصطناعي (AISVS) يحدّد متطلبات الأمن للتطبيقات والخدمات الحديثة للذكاء الاصطناعي، مع التركيز على الجوانب الواقعة ضمن نطاق سيطرة مطوري التطبيقات.

يهدف AISVS إلى أي شخص يعمل على تطوير أو تقييم أمان تطبيقات الذكاء الاصطناعي، بما في ذلك المطورين والمهندسين المعماريين ومهندسي الأمن والمدققين. يقدم هذا الفصل هيكل AISVS واستخدامه، بما في ذلك مستويات التحقق وحالات الاستخدام المقصودة.

### مستويات التحقق الأمني للذكاء الاصطناعي

يُعَرِّف AISVS ثلاث مستويات تصاعدية من التحقق الأمني. كل مستوى يضيف عمقًا وتعقيدًا، مما يمكّن المؤسسات من ضبط وضعها الأمني وفق مستوى مخاطر أنظمة الذكاء الاصطناعي لديها.

قد تبدأ المؤسسات من المستوى 1 وتتبنى تدريجياً مستويات أعلى مع زيادة نضج الأمن وتزايد تعرضها للتهديد.

#### تعريف المستويات

يُعَيَّن كل متطلب في AISVS v1.0 إلى أحد المستويات التالية:

 متطلبات المستوى 1

المستوى 1 يشمل أكثر المتطلبات الأمنية أهمية وأساساً. تركز هذه المتطلبات على منع الهجمات الشائعة التي لا تعتمد على شروط مسبقة أو ثغرات أخرى. ومعظم ضوابط المستوى 1 إما أن تكون سهلة التنفيذ أو أساسية بما يكفي لتبرير الجهد المبذول.

 متطلبات المستوى 2

المستوى 2 يعالج هجمات أكثر تقدمًا أو أقل شيوعًا، وكذلك الدفاعات متعددة الطبقات ضد التهديدات واسعة الانتشار. قد تتضمن هذه المتطلبات منطقًا أكثر تعقيدًا أو استهداف متطلبات مسبقة محددة للهجوم.

 متطلبات المستوى 3

المستوى 3 يشمل ضوابط عادةً ما تكون صعبة التنفيذ أو تطبيقها ظرفيًا. غالبًا ما تمثل هذه آليات الدفاع في العمق أو تدابير تخفيف ضد هجمات متخصصة أو مستهدفة أو عالية التعقيد.

#### دور (D/V)

يُشار إلى كل متطلب من AISVS وفق الجمهور الأساسي المستهدف:

D – المتطلبات الموجهة للمطور
V – المتطلبات التي يركّز عليها المُدقق/المراجِع
D/V – ذات صلة بكل من المطورين والمدققين

## C1 حوكمة بيانات التدريب وإدارة التحيز

### هدف الرقابة

يجب أن تكون بيانات التدريب مستمدة من مصادر موثوقة، ومُعالجة، ومُحفوظة بطريقة تحافظ على الأصل، والأمان، والجودة، والإنصاف. وبهذه الطريقة، يُلبي ذلك الالتزامات القانونية ويقلل من مخاطر التحيز والتسميم وانتهاكات الخصوصية التي قد تظهر أثناء التدريب والتي قد تؤثر على دورة حياة الذكاء الاصطناعي ككل.

---

### C1.1 أصل بيانات التدريب

احفظ جرداً قابلاً للتحقق من جميع مجموعات البيانات، واقبل فقط المصادر الموثوقة، وسجّل كل تغيير لأغراض التدقيق.

 #1.1.1    المستوى: 1    الدور: D/V
 تحقق من أن يتم الحفاظ على جرد محدث لكل مصدر بيانات التدريب (الأصل، المسؤول/المالك، الترخيص، طريقة جمع البيانات، قيود الاستخدام المقصودة، وتاريخ المعالجة).
 #1.1.2    المستوى: 1    الدور: D/V
 تحقق من أن عمليات معالجة بيانات التدريب تستبعد الميزات غير الضرورية أو السمات أو الحقول (على سبيل المثال، البيانات الوصفية غير المستخدمة، المعلومات الشخصية القابلة للتحديد الحساسة (PII)، بيانات الاختبار المسربة).
 #1.1.3    المستوى: 2    الدور: D/V
 تحقق من أن جميع تغييرات مجموعة البيانات خاضعة لسير عمل موافقات مُسجّل.
 #1.1.4    المستوى: 3    الدور: D/V
 تحقق من أن مجموعات البيانات أو أجزائها تحمل علامة مائية أو بصمة عند الإمكان.

---

### C1.2 أمان ونزاهة بيانات التدريب

فرض قيود على الوصول إلى بيانات التدريب، وتشفيرها عند التخزين وفي أثناء النقل، والتحقق من سلامة البيانات لمنع التلاعب والسرقة وتسميم البيانات.

 #1.2.1    المستوى: 1    الدور: D/V
 تحقق من أن ضوابط الوصول تحمي تخزين بيانات التدريب وخطوط أنابيب بيانات التدريب.
 #1.2.2    المستوى: 2    الدور: D/V
 تحقق من أن جميع عمليات الوصول إلى بيانات التدريب مسجّلة، بما في ذلك المستخدم والوقت والإجراء.
 #1.2.3    المستوى: 2    الدور: D/V
 تحقق من أن مجموعات بيانات التدريب مشفرة أثناء النقل وعند التخزين، باستخدام خوارزميات تشفير معيارية صناعيًا وممارسات إدارة المفاتيح.
 #1.2.4    المستوى: 2    الدور: D/V
 تحقق من استخدام التجزئات التشفيرية أو التوقيعات الرقمية لضمان تكامل البيانات أثناء تخزين بيانات التدريب ونقلها.
 #1.2.5    المستوى: 2    الدور: D/V
 تحقق من أن تقنيات الكشف الآلي مطبقة للحماية من التعديلات غير المصرح بها أو فساد بيانات التدريب.
 #1.2.6    المستوى: 2    الدور: D/V
 تحقق من أن بيانات التدريب القديمة قد تم محوها بشكل آمن أو تم إخفاؤها بشكل مجهول الهوية.
 #1.2.7    المستوى: 3    الدور: D/V
 تحقق من أن جميع إصدارات مجموعة بيانات التدريب مُعرَّفة بشكل فريد، ومخزَّنة بشكل غير قابل للتغيير، وقابلة للتدقيق لدعم التراجع والتحليل الجنائي الرقمي.

---

### C1.3 جودة تسمية بيانات التدريب، وتكاملها، وأمانها

احمِ التسميات وتشترط مراجعة تقنية للبيانات الحرجة.

 #1.3.1    المستوى: 2    الدور: D/V
 تحقق من تطبيق تجزئات تشفيرية أو توقيعات رقمية على عناصر التصنيف لضمان سلامتها ومصداقيتها.
 #1.3.2    المستوى: 2    الدور: D/V
 تحقق من أن واجهات الوسم والمنصات تفرض ضوابط وصول قوية، وتحتفظ بسجلات تدقيق تكشف أي عبث لجميع أنشطة الوسم، وتحمي من التعديلات غير المصرح بها.
 #1.3.3    المستوى: 3    الدور: D/V
 تحقق من أن المعلومات الحساسة في الملصقات يتم حجبها أو إخفاء الهوية أو تشفيرها على مستوى حقول البيانات، سواء عند التخزين أو أثناء النقل.

---

### C1.4 ضمان جودة بيانات التدريب وأمنها

اجمع بين التحقق الآلي، وفحوصات يدوية عشوائية، والإصلاحات المسجلة لضمان موثوقية مجموعة البيانات.

 #1.4.1    المستوى: 1    الدور: D
 تحقق من أن الاختبارات الآلية تلتقط أخطاء التنسيق والقيم الفارغة في كل إدخال للبيانات أو عند إجراء تحويلات كبيرة للبيانات.
 #1.4.2    المستوى: 2    الدور: D/V
 تحقق من أن خطوط أنابيب تدريب وتكييف نماذج اللغة الكبيرة (LLMs) تطبق كشف التسميم والتحقق من تكامل البيانات (مثلاً، طرق إحصائية، اكتشاف القيم الشاذة، تحليل التضمينات) بهدف التعرف على هجمات تسميم محتملة (مثلاً، قلب التسميات، إدراج محفز خلفي، أوامر تبديل الأدوار، هجمات أمثلة مؤثرة) أو تشوّش البيانات عن غير قصد في بيانات التدريب.
 #1.4.3    المستوى: 3    الدور: D/V
 تحقق من أن التدابير الدفاعية المناسبة، مثل التدريب المعادي (باستخدام أمثلة عدائية مولَّدة)، وتوسيع البيانات باستخدام مدخلات مُشوَّهة، أو تقنيات التحسين المتينة، قد تم تنفيذها وضبطها للنماذج ذات الصلة استناداً إلى تقييم المخاطر.
 #1.4.4    المستوى: 2    الدور: D/V
 تحقق من أن التسميات المولَّدة تلقائيًا (على سبيل المثال عبر نماذج اللغة الكبيرة (LLMs) أو الإشراف الضعيف) تخضع لعتبات الثقة واختبارات الاتساق للكشف عن التسميات الوهمية أو المضلة أو ذات الثقة المنخفضة.
 #1.4.5    المستوى: 3    الدور: D
 تحقق من أن الاختبارات الآلية تكشف عن انحرافات التسميات في كل استيعاب للبيانات أو عند كل تحويل كبير للبيانات.

---

### C1.5 سلسلة البيانات وتتبعها

تتبع المسار الكامل لكل نقطة بيانات من المصدر إلى مدخل النموذج لأغراض التدقيق والاستجابة للحوادث.

 #1.5.1    المستوى: 2    الدور: D/V
 تحقق من أن سلالة كل نقطة بيانات، بما في ذلك جميع التحويلات والتعزيزات والدمجات، مسجَّلة ويمكن إعادة بنائها.
 #1.5.2    المستوى: 2    الدور: D/V
 تحقق من أن سجلات تتبّع أصل البيانات غير قابلة للتغيير، مخزّنة بشكل آمن، ومتاحة لإجراء التدقيق.
 #1.5.3    المستوى: 2    الدور: D/V
 تأكد من أن تتبّع أصل البيانات يغطي البيانات الاصطناعية الناتجة عن تقنيات تحافظ على الخصوصية أو تقنيات توليد، وأن يتم وسم جميع البيانات الاصطناعية بوضوح وتمييزها عن البيانات الحقيقية طوال سلسلة المعالجة.

---

### المراجع

NIST AI Risk Management Framework
EU AI Act – Article 10: Data & Data Governance
MITRE ATLAS: Adversary Tactics for AI
Survey of ML Bias Mitigation Techniques – MDPI
Data Provenance & Lineage Best Practices – Nightfall AI
Data Labeling Quality Standards – LabelYourData
Training Data Poisoning Guide – Lakera.ai
CISA Advisory: Securing Data for AI Systems
ISO/IEC 23053: AI Management Systems Framework
IBM: What is AI Governance?
Google AI Principles
GDPR & AI Training Data – DataProtectionReport
Supply-Chain Security for AI Data – AppSOC
OpenAI Privacy Center – Data Deletion Controls
Adversarial ML Dataset – Kaggle

## C2 التحقق من إدخال المستخدم

### هدف الرقابة

التحقق القوي من مدخلات المستخدم هو خط الدفاع الأول ضد بعض أكثر الهجمات تدميراً على أنظمة الذكاء الاصطناعي.
هجمات حقن التعليمات يمكنها تجاوز تعليمات النظام، وتسريب بيانات حساسة، أو توجيه النموذج نحو سلوك غير مسموح.
ما لم تكن هناك فلاتر مخصصة وهرميات التعليمات في مكانها، تشير الأبحاث إلى أن هجمات كسر القيود "multi-shot" التي تستغل نوافذ السياق الطويلة جدًا ستكون فعالة.
أيضًا، يمكن لهجمات تشويش عدائية دقيقة--مثل تبديل الأحرف المتشابهة شكلاً (الهوموغليف) أو leetspeak—-يمكن أن تغيّر قرارات النموذج بشكل صامت.

---

### C2.1 الدفاع ضد حقن المطالب

حقن المحفز هو أحد أبرز المخاطر التي تواجه أنظمة الذكاء الاصطناعي. تعتمد الدفاعات ضد هذه الحيلة على مزيج من مرشحات الأنماط الثابتة، ومصنفات ديناميكية، وفرض هيكلية التعليمات.

 #2.1.1    المستوى: 1    الدور: D/V
 تحقق من أن مدخلات المستخدم تُفحص مقابل مكتبة محدثة باستمرار من أنماط حقن المطالب المعروفة (كلمات مفتاحية لكسر الحماية، "ignore previous"، سلاسل تمثيل الأدوار، هجمات HTML/URL غير المباشرة).
 #2.1.2    المستوى: 1    الدور: D/V
 تحقق من أن النظام يفرض هيكلًا هرميًا للتعليمات يجعل رسائل النظام أو المطور تتجاوز تعليمات المستخدم، حتى بعد توسيع نافذة السياق.
 #2.1.3    المستوى: 2    الدور: D/V
 تحقق من أن اختبارات التقييم العدائي (على سبيل المثال فريق الاختبار الأحمر مع مطالبات كثيرة-اللقطات) تُجرى قبل إصدار كل نموذج أو قالب استدعاء، مع عتبات معدل النجاح وحواجز آلية ضد التراجعات.
 #2.1.4    المستوى: 2    الدور: D
 تحقق من أن المطالبات التي تأتي من محتوى طرف ثالث (صفحات الويب، ملفات PDF، رسائل البريد الإلكتروني) يتم تطهيرها في سياق تحليل معزول قبل دمجها في الموجه الرئيسي.
 #2.1.5    المستوى: 3    الدور: D/V
 تحقق من أن جميع تحديثات قواعد فلترة المطالبات وإصدارات نماذج التصنيف وتغييرات قائمة الحظر محكومة بنظام التحكم بالإصدارات وقابلة للتدقيق.

---

### C2.2 مقاومة الأمثلة العدائية

نماذج معالجة اللغة الطبيعية (NLP) لا تزال عرضة لاضطرابات دقيقة على مستوى الأحرف أو الكلمات، والتي غالباً ما يغفل عنها البشر، لكنها تميل إلى التصنيف الخاطئ من قبل النماذج.

 #2.2.1    المستوى: 1    الدور: D
 تحقق من أن خطوات التطبيع الأساسية للمدخلات (Unicode NFC، تحويل أشكال متجانسة، تقليم الفراغات) تتم قبل عملية التوكننة.
 #2.2.2    المستوى: 2    الدور: D/V
 تحقق من أن الكشف عن الشذوذ الإحصائي يُشير إلى المدخلات التي تمتلك مسافة تحرير عالية بشكل غير عادي مقارنة بمعايير اللغة، وتكراراً مفرطاً للوحدات، أو مسافات تضمين غير طبيعية.
 #2.2.3    المستوى: 2    الدور: D
 تحقق من أن خط أنابيب الاستدلال يدعم نماذج بديلة مقواة بالتدريب العدائي–المحصّن أو طبقات دفاعية اختيارية للنقاط النهاية عالية المخاطر (على سبيل المثال، التعشوائية، التقطير الدفاعي).
 #2.2.4    المستوى: 2    الدور: V
 تحقق من أن المدخلات العدائية المشبوهة معزولة، ومسجلة بالحمولات الكاملة (بعد إخفاء البيانات الشخصية).
 #2.2.5    المستوى: 3    الدور: D/V
 تحقق من أن معايير المتانة (معدل نجاح مجموعات الهجمات المعروفة) يتم تتبّعها مع مرور الوقت، وأن التراجعات تؤدي إلى تفعيل مانع الإصدار.

---

### C2.3 التحقق من المخطط، النوع والطول

هجمات الذكاء الاصطناعي التي تتضمن مدخلات مشوهة أو كبيرة الحجم يمكن أن تتسبب في حدوث أخطاء في التحليل، وتسرب المدخلات عبر الحقول، واستهلاك الموارد.  كما أن فرض صارم للمخطط يعد شرطًا أساسيًا عند إجراء استدعاءات أدوات حتمية.

 #2.3.1    المستوى: 1    الدور: D
 تحقق من أن كل نقطة نهاية API أو استدعاء دالة تحدد مخطط إدخال صريح (مخطط JSON، Protobuf أو ما يعادله متعدد الوسائط) وأن يتم التحقق من صحة المدخلات قبل تجميع الموجه.
 #2.3.2    المستوى: 1    الدور: D/V
 تحقق من أن المدخلات التي تتجاوز الحد الأقصى لعدد التوكنات أو البايتات تُرفض بخطأ آمن ولا يتم اقتطاعها صمتاً.
 #2.3.3    المستوى: 2    الدور: D/V
 تحقق من أن فحوصات النوع تُطبق على جانب الخادم، وليس فقط في كود العميل (على سبيل المثال نطاقات رقمية، قيم التعداد (enum)، وأنواع MIME للصور/الصوت).
 #2.3.4    المستوى: 2    الدور: D
 تحقق من أن المدققين الدلاليين (مثل JSON Schema) يعملون في زمن ثابت لمنع هجوم رفض الخدمة الخوارزمي.
 #2.3.5    المستوى: 3    الدور: V
 تحقق من أن فشل التحقق يسجّل مع مقتطفات الحمولة المحجوبة ورموز خطأ غير غامضة للمساعدة في الفرز الأمني.

---

### C2.4 فحص المحتوى والسياسات

يجب أن يكون بإمكان المطورين اكتشاف المطالبات ذات البنية النحوية الصحيحة التي تطلب محتوى محظورًا، ثم منع انتشارها.

 #2.4.1    المستوى: 1    الدور: D
 تحقق من أن مصنف المحتوى (بدون أمثلة أو مُدرب بدقة) يُقيِّم كل إدخال وفق معايير العنف وإيذاء النفس والكراهية والمحتوى الجنسي والطلبات غير القانونية، مع عتبات قابلة للضبط.
 #2.4.2    المستوى: 1    الدور: D/V
 تحقق من أن المدخلات التي تنتهك السياسات ستحصل على رفض موحد أو إكمال آمن، حتى لا تنتشر إلى استدعاءات LLM اللاحقة.
 #2.4.3    المستوى: 2    الدور: D
 تحقق من أن نموذج الفحص أو مجموعة القواعد يتم إعادة تدريبه وتحديثه على الأقل ربع سنويًا، مع إدراج الأنماط الجديدة التي رُصدت لكسر القيود أو تجاوز السياسات.
 #2.4.4    المستوى: 2    الدور: D
 تحقق من أن الفحص يراعي السياسات المخصصة للمستخدم (العمر، القيود القانونية الإقليمية) عبر قواعد مبنية على السمات تُحل في وقت الطلب.
 #2.4.5    المستوى: 3    الدور: V
 تحقق من أن سجلات الفحص تتضمن درجات ثقة المصنف ووسوم فئة السياسة لارتباط مركز عمليات الأمن (SOC) وإعادة تشغيل فريق الاختبار الأحمر في المستقبل.

---

### C2.5 تقييد معدل الإدخال ومنع إساءة الاستخدام

يجب على المطورين منع سوء الاستخدام وإرهاق الموارد والهجمات الآلية ضد أنظمة الذكاء الاصطناعي من خلال تقليل معدلات الإدخال واكتشاف أنماط الاستخدام الشاذة.

 #2.5.1    المستوى: 1    الدور: D/V
 تحقق من أن حدود معدل الاستخدام لكل مستخدم، ولكل عنوان IP، ولكل مفتاح واجهة برمجة التطبيقات، تُفرض على جميع نقاط النهاية المدخلة.
 #2.5.2    المستوى: 2    الدور: D/V
 تحقق من أن حدود معدل الذروة والمعدل المستدام مُضبوطة لمنع هجمات رفض الخدمة (DoS) وهجمات القوة الغاشمة.
 #2.5.3    المستوى: 2    الدور: D/V
 تحقق من أن أنماط الاستخدام الشاذة (على سبيل المثال، الطلبات المتلاحقة بسرعة، وإغراق الإدخالات) تفعِّل الحظر الآلي أو التصعيدات.
 #2.5.4    المستوى: 3    الدور: V
 تحقق من أن سجلات منع إساءة الاستخدام يتم الاحتفاظ بها ومراجعتها لاكتشاف أنماط هجمات ناشئة.

---

### C2.6 التحقق من صحة المدخلات متعددة الوسائط

يجب أن تتضمن أنظمة الذكاء الاصطناعي تحققاً قوياً من المدخلات غير النصية (الصور، الصوت، الملفات) لمنع حقن تعليمات خبيثة، والتملّص، وإساءة استخدام الموارد.

 #2.6.1    المستوى: 1    الدور: D
 تأكد من أن جميع المدخلات غير النصية (الصور، الصوت، الملفات) يتم التحقق من نوعها وحجمها وتنسيقها قبل المعالجة.
 #2.6.2    المستوى: 2    الدور: D/V
 تأكد من أن الملفات تُفحص بحثًا عن البرمجيات الخبيثة والحمولات التخفيّة قبل الاستيعاب.
 #2.6.3    المستوى: 2    الدور: D/V
 تحقق من أن مدخلات الصور/الصوت تُفحص بحثاً عن تشويهات عدائية أو أنماط هجوم معروفة.
 #2.6.4    المستوى: 3    الدور: V
 تحقق من أن فشل التحقق من صحة المدخلات متعددة-الوسائط قد تم تسجيله وتُصدر تنبيهات للتحقيق.

---

### C2.7 أصل الإدخال والإسناد

يجب أن تدعم أنظمة الذكاء الاصطناعي التدقيق وتتبع إساءة الاستخدام والامتثال من خلال مراقبة ووضع علامات على أصول جميع مدخلات المستخدم.

 #2.7.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع مدخلات المستخدم موسومة ببيانات وصفية (معرّف المستخدم، الجلسة، المصدر، الطابع الزمني، عنوان IP) عند الاستيعاب.
 #2.7.2    المستوى: 2    الدور: D/V
 تحقق من أن بيانات النسب محفوظة وقابلة للتدقيق لجميع المدخلات المعالجة.
 #2.7.3    المستوى: 2    الدور: D/V
 تحقق من أن مصادر الإدخال الشاذة أو غير الموثوقة يتم وسمها وتخضع لرقابة معزَّزة أو للحظر.

---

### C2.8 اكتشاف التهديدات التكيفية في الوقت الحقيقي

ينبغي للمطورين استخدام أنظمة كشف التهديدات المتقدمة للذكاء الاصطناعي التي تتكيف مع أنماط الهجوم الجديدة وتوفر حماية في الوقت الحقيقي مع مطابقة الأنماط المجمّعة.

 #2.8.1    المستوى: 1    الدور: D/V
 تحقق من أن أنماط الكشف عن التهديدات جرى تجميعها في محركات تعبيرات نمطية مُحسّنة لأداء عالي في الترشيح في الوقت الفعلي مع تأثير تأخير منخفض.
 #2.8.2    المستوى: 1    الدور: D/V
 تحقق من أن أنظمة الكشف عن التهديدات تحافظ على مكتبات أنماط منفصلة لفئات التهديد المختلفة (حقن الطلبات، المحتوى الضار، البيانات الحساسة، أوامر النظام).
 #2.8.3    المستوى: 2    الدور: D/V
 تحقق من أن الكشف التهديدي التكيفي يتضمن نماذج التعلم الآلي التي تقوم بتحديث حساسية التهديد بناءً على معدل الهجمات ونسب النجاح.
 #2.8.4    المستوى: 2    الدور: D/V
 تحقق من أن مغذيات استخبارات التهديدات في الوقت الفعلي تقوم تلقائيًا بتحديث مكتبات الأنماط بتوقيعات هجوم جديدة و IOCs (Indicators of Compromise).
 #2.8.5    المستوى: 3    الدور: D/V
 تحقق من أن معدلات الإيجابيات الكاذبة في كشف التهديدات تُرصد باستمرار وأن دقة الأنماط تُضبط تلقائيًا لتقليل التداخل مع حالات الاستخدام المشروعة.
 #2.8.6    المستوى: 3    الدور: D/V
 تحقق من أن تحليل التهديد السياقي يأخذ في الاعتبار مصدر الإدخال وأنماط سلوك المستخدم وسجل الجلسة من أجل تحسين دقة الكشف.
 #2.8.7    المستوى: 3    الدور: D/V
 تحقق من أن مقاييس أداء كشف التهديدات (معدل الكشف، زمن الاستجابة، استهلاك الموارد) يتم مراقبتها وتحسينها في الوقت الفعلي.

---

### C2.9 خط أنابيب التحقق الأمني متعدد الوسائط

يجب على المطورين توفير التحقق الأمني لوسائط الإدخال مثل النص والصورة والصوت وغيرها من مدخلات الذكاء الاصطناعي، مع أنواع محددة من اكتشاف التهديدات وعزل الموارد.

 #2.9.1    المستوى: 1    الدور: D/V
 تحقق من أن كل نوع إدخال يمتلك مدققات أمان مخصصة مع أنماط التهديد الموثقة (نص: حقن المطالب، الصور: إخفاء البيانات، الصوت: هجمات مخطط طيفي) وعتبات الكشف.
 #2.9.2    المستوى: 2    الدور: D/V
 تحقق من أن المدخلات متعددة الوسائط تُعالج في بيئات sandbox معزولة بحدود موارد محددة (الذاكرة، وحدة المعالجة المركزية، ووقت المعالجة) مخصصة لكل نمط من الوسائط وموثقة في سياسات الأمن.
 #2.9.3    المستوى: 2    الدور: D/V
 تحقق من أن كشف الهجمات عبر الوسائط المتعددة يحدد هجمات منسقة تمتد عبر عدة أنواع إدخال (على سبيل المثال، حمولات ستيجانوجرافية في الصور مع حقن تعليمات في النص) باستخدام قواعد الترابط وتوليد الإنذارات.
 #2.9.4    المستوى: 3    الدور: D/V
 تحقق من أن فشل التحقق متعدد الوسائط يؤدي إلى تسجيل تفصيلي يشمل جميع وسائل الإدخال ونتائج التحقق ودرجات التهديد وتحليل الترابط مع صيغ سجلات مُهيكلة للتكامل مع SIEM.
 #2.9.5    المستوى: 3    الدور: D/V
 تحقق من تحديث مصنفات المحتوى الخاصة بكل نمط وفق جداول زمنية موثقة (على الأقل ربع سنويًا)، مع أنماط تهديد جديدة، وأمثلة عدائية، ومعايير أداء تحافظ على مستوى أعلى من العتبات الأساسية.

---

### المراجع

LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security
Generative AI's Biggest Security Flaw Is Not Easy to Fix
Many-shot jailbreaking \ Anthropic
$PDF$ OpenAI GPT-4.5 System Card
Notebook for the CheckThat Lab at CLEF 2024
Mitigate jailbreaks and prompt injections – Anthropic
Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis
OWASP Top 10 for LLM Applications 2025 – WorldTech IT
OWASP Machine Learning Security Top Ten
Few words about AI Security – Jussi Metso
How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry
Easily enforcing valid JSON schema following – API
AI Safety + Cybersecurity R\&D Tracker – Fairly AI
Anthropic makes 'jailbreak' advance to stop AI models producing harmful results
Pattern matching filter rules - IBM
Real-time Threat Detection

## إدارة دورة حياة نموذج C3 والتحكم في التغيير

### هدف الرقابة

يجب على أنظمة الذكاء الاصطناعي أن تنفّذ عمليات إدارة التغيير التي تمنع التعديلات غير المصرّح بها أو غير الآمنة للنموذج من الوصول إلى بيئة الإنتاج. يضمن هذا التحكم سلامة النموذج طوال دورة حياته الكاملة--من التطوير وحتى النشر وحتى التقاعد--ما يمكّن من الاستجابة السريعة للحوادث ويحافظ على المساءلة عن جميع التغييرات.

الهدف الأمني الأساسي: فقط النماذج المعتمدة والموثقة تصل إلى بيئة الإنتاج من خلال تطبيق عمليات محكومة تحافظ على التكامل، قابلية التتبع، وإمكانية الاسترداد.

---

### C3.1 تفويض النموذج ونزاهته

فقط النماذج المصرّح بها والتي تم التحقق من سلامتها تصل إلى بيئات الإنتاج.

 #3.1.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع مخرجات النموذج (الأوزان، التكوينات، أدوات تقسيم الرموز) موقّعة رقمياً من قبل جهات مخوَّلة قبل النشر.
 #3.1.2    المستوى: 1    الدور: D/V
 تأكد من أن تكامل النموذج يتم التحقق منه عند النشر وأن فشل التحقق من التوقيع يمنع تحميل النموذج.
 #3.1.3    المستوى: 2    الدور: D/V
 تحقق من أن سجلات أصل النموذج تتضمن هوية جهة التفويض، وقيم التحقق لبيانات التدريب، ونتائج اختبارات التحقق مع حالة النجاح/الفشل، وطابع زمني لوقت الإنشاء.
 #3.1.4    المستوى: 2    الدور: D/V
 تحقق من أن جميع مخرجات النماذج تستخدم الإصدار الدلالي (MAJOR.MINOR.PATCH) مع معايير موثقة تُبيّن متى يزداد كل جزء من أجزاء الإصدار.
 #3.1.5    المستوى: 2    الدور: V
 تحقق من أن تتبّع التبعيات يحافظ على جرد في الوقت الفعلي يمكّن من التعرف السريع على جميع الأنظمة المستهلكة.

---

### C3.2 تحقق من النموذج والاختبار

يجب أن تمر النماذج بالتحققات الأمنية والسلامة المحددة قبل النشر.

 #3.2.1    المستوى: 1    الدور: D/V
 تأكد من أن النماذج تخضع لاختبار أمني تلقائي يشمل التحقق من صحة المدخلات وتنقية المخرجات وتقييمات السلامة مع حدود النجاح والفشل المؤسسية المتفق عليها مسبقاً قبل النشر.
 #3.2.2    المستوى: 1    الدور: D/V
 تأكد من أن فشل التحقق من الصحة يمنع نشر النموذج تلقائيًا بعد الموافقة الصريحة على تجاوز من قبل أفراد مخولين محددين مسبقًا مع مبررات تجارية موثقة.
 #3.2.3    المستوى: 2    الدور: V
 تحقق من أن نتائج الاختبار موقّعة تشفيرياً ومربوطة بشكل لا يقبل التغيير بقيمة التجزئة الخاصة بإصدار النموذج المحدد قيد التحقق.
 #3.2.4    المستوى: 2    الدور: D/V
 تحقق من أن عمليات النشر الطارئة تتطلب تقييم مخاطر أمنية موثّق وموافقة من جهة أمنية محددة مسبقاً ضمن الإطارات الزمنية المتفق عليها.

---

### C3.3 النشر المُدار والتراجع

يجب أن يكون نشر النماذج محكومًا ومراقَبًا وقابلًا للعكس.

 #3.3.1    المستوى: 1    الدور: D
 تحقق من أن عمليات النشر في الإنتاج تنفذ آليات النشر التدريجي (نشر الكناري، النشر الأزرق-الأخضر) مع مُحفِّزات التراجع التلقائي المستندة إلى معدلات الخطأ المتفق عليها مسبقاً، أو حدود زمن الاستجابة، أو معايير الإنذار الأمني.
 #3.3.2    المستوى: 1    الدور: D/V
 تحقق من أن قدرات التراجع تستعيد حالة النموذج الكاملة (الأوزان، التكوينات، التبعيات) بشكل ذري ضمن فترات زمنية تنظيمية محددة مسبقاً.
 #3.3.3    المستوى: 2    الدور: D/V
 تحقق من أن عمليات النشر تتحقق من صحة التواقيع التشفيرية وتحسب قيم تحقق التكامل قبل تفعيل النموذج، وتفشل عملية النشر في حال وجود أي عدم مطابقة.
 #3.3.4    المستوى: 2    الدور: D/V
 تحقق من أن قدرات الإيقاف الطارئ للنموذج يمكنها تعطيل نقاط نهاية النموذج ضمن أوقات استجابة محددة مسبقاً عبر قواطع دارة آلية أو مفاتيح إيقاف يدوية.
 #3.3.5    المستوى: 2    الدور: V
 تحقق من أن مواد التراجع (إصدارات النماذج السابقة، والتكوينات، والتبعيات) محفوظة وفق سياسات المؤسسة مع التخزين غير القابل للتعديل لاستجابة الحوادث.

---

### C3.4 المساءلة والتدقيق بشأن التغيير

يجب أن تكون جميع تغييرات دورة حياة النموذج قابلة للتتبع والتدقيق.

 #3.4.1    المستوى: 1    الدور: V
 تحقق من أن جميع تغييرات النموذج (النشر، التكوين، التقاعد) تولّد سجلات تدقيق غير قابلة للتغيير، متضمنة طابعاً زمنياً، وهوية فاعل معتمدة، ونوع التغيير، والحالات قبل وبعد.
 #3.4.2    المستوى: 2    الدور: D/V
 تحقق من أن الوصول إلى سجل التدقيق يتطلب تفويضاً مناسباً، وأن جميع محاولات الوصول مسجلة بهوية المستخدم وطابع زمني.
 #3.4.3    المستوى: 2    الدور: D/V
 تحقق من أن قوالب المطالبات ورسائل النظام محكومة بإدارة الإصدارات في مستودعات Git مع مراجعة كود وإقرار إلزامي من المراجعين المعينين قبل النشر.
 #3.4.4    المستوى: 2    الدور: V
 تحقق من أن سجلات التدقيق تتضمن تفاصيل كافية (قيم التجزئة للنموذج، لقطات التكوين، إصدارات التبعيات) لتمكين إعادة بناء كاملة لحالة النموذج لأي طابع زمني ضمن فترة الاحتفاظ.

---

### C3.5 ممارسات التطوير الآمن

يجب أن تتبع عمليات تطوير وتدريب النموذج ممارسات آمنة لمنع حدوث اختراق.

 #3.5.1    المستوى: 1    الدور: D
 تحقق من أن بيئات تطوير النموذج والاختبار والإنتاج منفصلة ماديًا أو منطقيًا. وليس لديها بنية تحتية مشتركة وضوابط وصول مميزة ومخازن بيانات معزولة.
 #3.5.2    المستوى: 1    الدور: D
 تحقق من أن تدريب النموذج وضبطه يتمان في بيئات معزولة وبوصول شبكي مقيد.
 #3.5.3    المستوى: 1    الدور: D/V
 تحقق من أن مصادر بيانات التدريب قد تم التحقق من صحتها من خلال فحوصات التكامل وتوثيقها من مصادر موثوقة مع سلسلة حفظ موثقة قبل استخدامها في تطوير النموذج.
 #3.5.4    المستوى: 2    الدور: D
 تحقق من أن مخرجات تطوير النموذج (المعلمات الفائقة، سكريبتات التدريب، ملفات التهيئة) يتم تخزينها في نظام التحكم في الإصدارات وتتطلب موافقة مراجعة من الأقران قبل استخدامها في التدريب.

---

### C3.6 تقاعد النموذج وإيقاف تشغيله

يجب إيقاف النماذج بشكل آمن عندما لا تعود مطلوبة أو عندما تُعرَف قضايا أمنيّة.

 #3.6.1    المستوى: 1    الدور: D
 تحقق من أن عمليات تقاعد النماذج تقوم تلقائياً بمسح مخططات التبعية، وتحديد جميع الأنظمة التي تستهلكه، وتوفير فترات إشعار مسبقة متفق عليها قبل إيقاف تشغيلها.
 #3.6.2    المستوى: 1    الدور: D/V
 تحقق من أن مقتنيات النماذج المتقاعدة قد تم محوها بشكل آمن باستخدام المحو التشفيري أو الكتابة المتعددة المرور وفق سياسات الاحتفاظ بالبيانات الموثقة، مع شهادات تدمير موثقة.
 #3.6.3    المستوى: 2    الدور: V
 تحقق من أن أحداث تقاعد النماذج تُسجَّل مع الطابع الزمني وهوية الفاعل، وأن تُسحب توقيعات النموذج لمنع إعادة استخدامها.
 #3.6.4    المستوى: 2    الدور: D/V
 تحقق من أن سحب النموذج في حالات الطوارئ يمكنه تعطيل وصول النموذج ضمن فترات الاستجابة للطوارئ المحددة مسبقاً من خلال أزرار الإيقاف التلقائية إذا تم اكتشاف ثغرات أمنية حرجة.

---

### المراجع

MLOps Principles
Securing AI/ML Ops – Cisco.com
Audit logs security: cryptographically signed tamper-proof logs
Machine Learning Model Versioning: Top Tools & Best Practices
AI Hygiene Starts with Models and Data Loaders – SEI Blog
How to handle versioning and rollback of a deployed ML model?
Reinforcement fine-tuning – OpenAI API
Auditing Machine Learning models: Governance, Data Security and …
Adversarial Training to Improve Model Robustness
What is AI adversarial robustness? – IBM Research
Exploring Data Provenance: Ensuring Data Integrity and Authenticity
MITRE ATLAS
AWS Prescriptive Guidance – Best practices for retiring applications …

## C4: أمن البنية التحتية والتكوين والنشر

### هدف الرقابة

يجب تعزيز بنية الذكاء الاصطناعي التحتية ضد تصعيد الامتيازات والتلاعب بسلسلة الإمداد والتحرك الجانبي من خلال التكوين الآمن، والعزل أثناء التشغيل، وخطوط أنابيب النشر الموثوقة، والمراقبة الشاملة. فقط المكونات والتكوينات المعتمدة والمتحققة تصل إلى بيئة الإنتاج عبر عمليات محكومة تحافظ على الأمن والنزاهة وقابلية التدقيق.

الهدف الأمني الأساسي: فقط مكوّنات البنية التحتية الموقّعة تشفيرياً وخاضعة لفحص الثغرات تصل إلى بيئة الإنتاج من خلال خطوط تحقق آلية تفرض سياسات الأمن وتُحافظ على سجلات تدقيق غير قابلة للتغيير.

---

### C4.1 عزل بيئة وقت التشغيل

منع الإفلات من الحاويات وتصعيد الامتيازات من خلال أدوات العزل على مستوى النواة وأنظمة التحكم بالوصول الإلزامية.

 #4.1.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع حاويات الذكاء الاصطناعي تسقط جميع صلاحيات Linux باستثناء CAP_SETUID، CAP_SETGID، والقدرات المطلوبة صراحةً المذكورة في خطوط أساس الأمان.
 #4.1.2    المستوى: 1    الدور: D/V
 تحقق من أن ملفات seccomp تحظر جميع استدعاءات النظام باستثناء تلك الموجودة في قوائم السماح المعتمدة مسبقاً، مع وجود انتهاكات تؤدي إلى إنهاء الحاوية وتوليد تنبيهات أمنية.
 #4.1.3    المستوى: 2    الدور: D/V
 تحقق من أن أحمال الذكاء الاصطناعي تعمل باستخدام أنظمة ملفات جذرية للقراءة فقط، وtmpfs للبيانات المؤقتة، وبالأحجام المسماة للبيانات الدائمة مع فرض خيارات التثبيت noexec.
 #4.1.4    المستوى: 2    الدور: D/V
 تحقق من أن المراقبة في وقت التشغيل المعتمدة على eBPF (Falco، Tetragon، أو ما يعادلها) تكشف عن محاولات تصعيد الامتيازات وتقوم تلقائيًا بقتل العمليات المخالفة ضمن متطلبات زمن الاستجابة التنظيمية.
 #4.1.5    المستوى: 3    الدور: D/V
 تحقق من أن أعباء العمل في الذكاء الاصطناعي عالية المخاطر تُنفَّذ في بيئات معزولة على مستوى العتاد (Intel TXT، AMD SVM، أو عُقد bare-metal مخصصة) مع تحقق الإشهاد.

---

### C4.2 أنابيب البناء والنشر الآمنة

ضمان سلامة التشفير وأمان سلسلة التوريد من خلال عمليات البناء القابلة لإعادة البناء والنتاجات الموقّعة رقميًا.

 #4.2.1    المستوى: 1    الدور: D/V
 تحقق من أن البنية التحتية ككود تُفحص باستخدام الأدوات (tfsec، Checkov، أو Terrascan) في كل التزام، ويتم حظر الدمج عند وجود نتائج ذات شدة CRITICAL أو HIGH.
 #4.2.2    المستوى: 1    الدور: D/V
 تحقق من أن بناءات الحاويات قابلة لإعادة الإنتاج مع قيم SHA256 المتطابقة عبر عمليات البناء وتوليد شهادات إثبات الأصل من المستوى 3 لـ SLSA موقعة بواسطة Sigstore.
 #4.2.3    المستوى: 2    الدور: D/V
 تحقق من أن صور الحاويات تحتوي CycloneDX أو SPDX SBOMs وأنها موقَّعة بواسطة Cosign قبل رفعها إلى المستودع، ويتم رفض الصور غير الموقَّعة عند النشر.
 #4.2.4    المستوى: 2    الدور: D/V
 تحقق من أن خطوط أنابيب CI/CD تستخدم رموز OIDC من HashiCorp Vault، أو أدوار AWS IAM، أو الهوية المدارة من Azure مع مدد صلاحية لا تتجاوز حدود سياسة الأمان التنظيمية للمؤسسة.
 #4.2.5    المستوى: 2    الدور: D/V
 تحقق من أن توقيعات Cosign وإثبات أصل SLSA يتم التحقق منها أثناء عملية النشر قبل تشغيل الحاوية، وأن تؤدي أخطاء التحقق إلى فشل النشر.
 #4.2.6    المستوى: 2    الدور: D/V
 تحقق من أن بيئات البناء تعمل في حاويات مؤقتة أو أجهزة افتراضية بدون تخزين دائم، ومع عزل الشبكة عن شبكات افتراضية خاصة الإنتاجية (VPCs).

---

### C4.3 أمن الشبكات والتحكم في الوصول

طبق شبكات الثقة الصفرية مع سياسات الرفض الافتراضية والاتصالات المشفرة.

 #4.3.1    المستوى: 1    الدور: D/V
 تحقق من أن سياسات الشبكة في كوبرنيتس (NetworkPolicies) أو ما يعادلها تُنفّذ الرفض الافتراضي للوصول الوارد والصادر مع قواعد سماح صريحة للمنافذ المطلوبة (443، 8080، إلخ).
 #4.3.2    المستوى: 1    الدور: D/V
 تحقق من أن SSH (المنفذ 22)، وRDP (المنفذ 3389)، ونقاط نهاية بيانات تعريف السحابة (169.254.169.254) محجوبة أو تتطلب مصادقة قائمة على الشهادات.
 #4.3.3    المستوى: 2    الدور: D/V
 تحقق من أن حركة المرور الصادرة مُفلترة عبر وكلاء HTTP/HTTPS (Squid، Istio، أو بوابات NAT السحابية) مع قوائم السماح بالنطاقات وتسجيل الطلبات المحظورة.
 #4.3.4    المستوى: 2    الدور: D/V
 تحقق من أن التواصل بين الخدمات يستخدم TLS متبادل المصادقة مع تدوير الشهادات وفق سياسة المؤسسة ويتم فرض التحقق من الشهادات (بدون خيارات تخطي التحقق).
 #4.3.5    المستوى: 2    الدور: D/V
 تحقق من أن البنية التحتية للذكاء الاصطناعي تعمل في شبكات افتراضية خاصة مخصصة بدون وصول مباشر إلى الإنترنت وتتواصل فقط عبر بوابات NAT أو خوادم البوابة.

---

### C4.4 الأسرار وإدارة مفاتيح التشفير

احمِ بيانات الاعتماد من خلال التخزين المدعوم بالأجهزة والتدوير الآلي مع وصول وفق مبدأ عدم الثقة.

 #4.4.1    المستوى: 1    الدور: D/V
 تحقق من أن الأسرار مخزنة في HashiCorp Vault و AWS Secrets Manager و Azure Key Vault أو Google Secret Manager مع التشفير أثناء التخزين باستخدام AES-256.
 #4.4.2    المستوى: 1    الدور: D/V
 تحقق من أن مفاتيح التشفير تُولَّد في أجهزة HSM من المستوى 2 وفق معيار FIPS 140-2 (AWS CloudHSM، Azure Dedicated HSM) مع تدوير المفاتيح وفق سياسة التشفير المؤسسية.
 #4.4.3    المستوى: 2    الدور: D/V
 تحقق من أن تدوير الأسرار آلي مع نشر بلا توقف وتدوير فوري يُفعَّل عند تغيّرات في الأفراد أو الحوادث الأمنية.
 #4.4.4    المستوى: 2    الدور: D/V
 تحقق من أن صور الحاويات تُفحص باستخدام أدوات (GitLeaks، TruffleHog، أو detect-secrets) لمنع عمليات البناء التي تحتوي على مفاتيح API أو كلمات مرور أو شهادات.
 #4.4.5    المستوى: 2    الدور: D/V
 تحقق من أن الوصول إلى الأسرار الإنتاجية يتطلب المصادقة متعددة العوامل باستخدام مفاتيح أمان الأجهزة (YubiKey، FIDO2)، وأنه يُسجَّل في سجلات تدقيق غير قابلة للتعديل تحتوي على هويات المستخدمين والطوابع الزمنية.
 #4.4.6    المستوى: 2    الدور: D/V
 تحقق من أن الأسرار تُحقن عبر أسرار Kubernetes، أو عبر الأحجام المُثبتة، أو حاويات التهيئة، وتأكد من ألا تُضمَّن الأسرار في متغيرات البيئة أو في صور الحاويات.

---

### C4.5 عزل عبء عمل الذكاء الاصطناعي في صندوق الرمل والتحقق

عزل نماذج الذكاء الاصطناعي غير الموثوقة في صناديق الرمل الآمنة مع تحليل سلوكي شامل.

 #4.5.1    المستوى: 1    الدور: D/V
 تحقق من أن نماذج الذكاء الاصطناعي الخارجية تُنفَّذ في gVisor، أو microVMs (مثل Firecracker و CrossVM)، أو حاويات Docker مع الأعلام --security-opt=no-new-privileges و --read-only.
 #4.5.2    المستوى: 1    الدور: D/V
 تحقق من أن بيئات sandbox المعزلة لا تمتلك اتصالاً بالشبكة إطلاقاً (--network=none) أو أن يكون الوصول إليها محصوراً في localhost فقط مع حجب جميع الطلبات الخارجية بواسطة قواعد iptables.
 #4.5.3    المستوى: 2    الدور: D/V
 تأكد من أن عملية التحقق من صحة نموذج الذكاء الاصطناعي تتضمن اختبارات الفريق الأحمر الآلية مع تغطية اختبارات محددة تنظيميًا وتحليل سلوكي للكشف عن باب خلفي.
 #4.5.4    المستوى: 2    الدور: D/V
 تحقق من أنه قبل ترقية نموذج الذكاء الاصطناعي إلى الإنتاج، تُوقَّع نتائج صندوق الرمل رقمياً من قِبل موظفي الأمن المعتمدين وتُخزَّن في سجلات تدقيق غير قابلة للتغيير.
 #4.5.5    المستوى: 2    الدور: D/V
 تحقق من أن بيئات صندوق الرمل تُدمر وتُعاد إنشاؤها من صور ذهبية بين التقييمات مع تنظيف كامل لنظام الملفات والذاكرة.

---

### C4.6 مراقبة أمن البنية التحتية

المسح والمراقبة المستمرة للبنية التحتية مع الإصلاح التلقائي والتنبيهات في الوقت الحقيقي.

 #4.6.1    المستوى: 1    الدور: D/V
 تحقق من أن صور الحاويات يتم فحصها وفق جداول المؤسسة مع وجود ثغرات حرجة تعيق النشر استنادًا إلى عتبات المخاطر التنظيمية.
 #4.6.2    المستوى: 1    الدور: D/V
 تحقق من أن البنية التحتية تتوافق مع معايير CIS Benchmarks أو ضوابط NIST 800-53 مع عتبات امتثال محددة تنظيميًا وتصحيح تلقائي للفحوصات الفاشلة.
 #4.6.3    المستوى: 2    الدور: D/V
 تحقق من أن الثغرات الأمنية عالية الخطورة قد تم تصحيحها وفق الجداول الزمنية لإدارة المخاطر التنظيمية، مع إجراءات طارئة للثغرات CVEs التي يتم استغلالها بنشاط.
 #4.6.4    المستوى: 2    الدور: V
 تحقق من أن تنبيهات الأمان تتكامل مع منصات SIEM (Splunk، Elastic، أو Sentinel) باستخدام تنسيقات CEF أو STIX/TAXII مع الإثراء الآلي.
 #4.6.5    المستوى: 3    الدور: V
 تحقق من أن مقاييس البنية التحتية يتم تصديرها إلى أنظمة المراقبة (Prometheus، DataDog) مع لوحات SLA وتقارير تنفيذية.
 #4.6.6    المستوى: 2    الدور: D/V
 تحقق من اكتشاف انحراف التكوين باستخدام أدوات (Chef InSpec، AWS Config) وفق متطلبات المراقبة المؤسسية مع التراجع التلقائي عن التغييرات غير المصرح بها.

---

### C4.7 إدارة موارد البنية التحتية للذكاء الاصطناعي

منع هجمات استنزاف الموارد وضمان تخصيص الموارد بشكل عادل من خلال الحصص والمراقبة.

 #4.7.1    المستوى: 1    الدور: D/V
 تحقق من رصد استخدام GPU/TPU مع إطلاق تنبيهات عند العتبات التي تحددها المؤسسة وتفعيل التوسع التلقائي أو موازنة الحمل استنادًا إلى سياسات إدارة السعة.
 #4.7.2    المستوى: 1    الدور: D/V
 تحقق من أن مقاييس عبء العمل في الذكاء الاصطناعي (زمن الكمون للاستدلال، معدل المعالجة، معدلات الأخطاء) جمعت وفق متطلبات الرصد التنظيمية ومُرتبطة باستغلال البنية التحتية.
 #4.7.3    المستوى: 2    الدور: D/V
 تحقق من أن ResourceQuotas في Kubernetes أو ما يعادله يقيد أحمال العمل الفردية وفق سياسات تخصيص الموارد التنظيمية مع فرض حدود صلبة.
 #4.7.4    المستوى: 2    الدور: V
 تحقق من أن مراقبة التكاليف تتعقب الإنفاق لكل عبء عمل/مستأجر مع تنبيهات مبنية على حدود الميزانية المؤسسية وضوابط آلية لمواجهة تجاوزات الميزانية.
 #4.7.5    المستوى: 3    الدور: V
 تحقق من أن تخطيط السعة يستخدم بيانات تاريخية مع فترات التنبؤ التي تحددها المؤسسة وتوفير الموارد آلياً اعتماداً على أنماط الطلب.
 #4.7.6    المستوى: 2    الدور: D/V
 تحقق من أن استنفاد الموارد يفعّل قواطع الدائرة وفقًا لمتطلبات الاستجابة المؤسسية، بما في ذلك تقييد المعدل بناءً على سياسات السعة وعزل عبء العمل.

---

### C4.8 فصل البيئات وضوابط الترقية

فرض حدود صارمة على البيئة مع بوابات ترقية آلية والتحقق الأمني.

 #4.8.1    المستوى: 1    الدور: D/V
 تحقق من أن بيئات التطوير والاختبار والإنتاج تعمل في VPCs/VNets منفصلة بدون وجود أدوار IAM مشتركة، ومجموعات أمان مشتركة، أو اتصالات شبكية مشتركة.
 #4.8.2    المستوى: 1    الدور: D/V
 تحقق من أن ترقية البيئة تتطلب موافقة من موظفين مخوّلين محدّدين تنظيميًا مع توقيعات رقمية وسجلات تدقيق غير قابلة للتعديل.
 #4.8.3    المستوى: 2    الدور: D/V
 تحقق من أن بيئات الإنتاج تحجب وصول SSH، وتقوم بتعطيل نقاط النهاية الخاصة بالتصحيح، وتتطلب طلبات التغيير مع متطلبات إشعار مسبق تنظيمية باستثناء الحالات الطارئة.
 #4.8.4    المستوى: 2    الدور: D/V
 تحقق من أن تغييرات البنية التحتية ككود تتطلب مراجعة من الزملاء مع اختبارات آلية وفحص أمني قبل الدمج إلى الفرع الرئيسي.
 #4.8.5    المستوى: 2    الدور: D/V
 تحقق من أن البيانات غير الإنتاجية قد تم إخفاؤها وفقًا لمتطلبات الخصوصية التنظيمية، أو توليد بيانات اصطناعية، أو إخفاء البيانات بالكامل مع إزالة المعلومات القابلة للتعرّف الشخصية (PII) والتحقق من ذلك.
 #4.8.6    المستوى: 2    الدور: D/V
 تحقق من أن بوابات الترويج تتضمن اختبارات أمان آلية (SAST، DAST، فحص الحاويات) مع شرط ألا توجد أي نتائج حرجة للموافقة.

---

### C4.9 النسخ الاحتياطي للبنية التحتية والاسترداد

ضمان مرونة البنية التحتية من خلال النسخ الاحتياطية الآلية، وإجراءات الاستعادة التي تم اختبارها، وقدرات التعافي من الكوارث.

 #4.9.1    المستوى: 1    الدور: D/V
 تحقق من أن تكوينات البنية التحتية مُنسخ احتياطيًا وفق جداول النسخ الاحتياطي التنظيمية في مناطق جغرافية منفصلة مع تطبيق استراتيجية النسخ الاحتياطي 3-2-1.
 #4.9.2    المستوى: 2    الدور: D/V
 تحقق من أن أنظمة النسخ الاحتياطي تعمل في شبكات معزولة ببيانات اعتماد منفصلة وتخزين معزول عن الشبكة للحماية من برامج الفدية.
 #4.9.3    المستوى: 2    الدور: V
 تحقق من أن إجراءات الاسترداد مختبرة ومصدقة عبر اختبارات آلية وفق جداول المؤسسة، مع أهداف RTO و RPO التي تلبِّي متطلبات المؤسسة.
 #4.9.4    المستوى: 3    الدور: V
 تأكد من أن خطط التعافي من الكوارث تتضمن أدلة تشغيل خاصة بالذكاء الاصطناعي مع استعادة أوزان النماذج، وإعادة بناء عنقود وحدات معالجة الرسومات، وتحديد تبعيات الخدمات.

---

### C4.10 التوافق والحوكمة للبنية التحتية

ضمان الامتثال التنظيمي من خلال التقييم المستمر والتوثيق والضوابط الآلية.

 #4.10.1    المستوى: 2    الدور: D/V
 تحقق من أن امتثال البنية التحتية يتم تقييمه وفق الجداول التنظيمية للمؤسسة إزاء ضوابط SOC 2 و ISO 27001 أو FedRAMP مع جمع أدلة آلية.
 #4.10.2    المستوى: 2    الدور: V
 تحقق من أن وثائق البنية التحتية تشمل مخططات الشبكة وخرائط تدفق البيانات ونماذج التهديدات المحدثة وفقًا لمتطلبات إدارة التغيير التنظيمي.
 #4.10.3    المستوى: 3    الدور: D/V
 تحقق من أن تغييرات البنية التحتية تخضع لتقييم أثر الامتثال الآلي مع سير عمل الموافقات التنظيمية للتعديلات عالية الخطورة.

---

### C4.11 أمان أجهزة الذكاء الاصطناعي

حماية مكوّنات الأجهزة الخاصة بالذكاء الاصطناعي، بما في ذلك وحدات معالجة الرسومات (GPUs)، ووحدات TPU، ومسرّعات الذكاء الاصطناعي المتخصصة.

 #4.11.1    المستوى: 2    الدور: D/V
 تحقق من أن البرامج الثابتة لمسرعات الذكاء الاصطناعي (بيوس GPU، وبرمجيات TPU الثابتة) موقَّعة رقمياً ومحدَّثة وفق جداول إدارة التصحيحات المؤسسية.
 #4.11.2    المستوى: 2    الدور: D/V
 تأكد من أنه قبل تنفيذ عبء العمل، يتم التحقق من سلامة مسرّع الذكاء الاصطنيعي من خلال توثيق الأجهزة باستخدام TPM 2.0 و Intel TXT و AMD SVM.
 #4.11.3    المستوى: 2    الدور: D/V
 تحقق من عزل ذاكرة GPU بين أحمال العمل باستخدام SR-IOV، MIG (GPU متعدد المثيلات)، أو تقسيم الأجهزة المكافئة مع تطهير الذاكرة بين المهام.
 #4.11.4    المستوى: 3    الدور: V
 تحقق من أن سلسلة توريد أجهزة الذكاء الاصطناعي تتضمن التحقق من المنشأ مع شهادات المصنع والتحقق من عبوات مانعة للعبث.
 #4.11.5    المستوى: 3    الدور: D/V
 تحقق من أن وحدات أمان الأجهزة (HSMs) تحمي أوزان نماذج الذكاء الاصطناعي ومفاتيح التشفير بشهادة FIPS 140-2 المستوى 3 أو بشهادة المعايير المشتركة EAL4+.

---

### C4.12 البنية التحتية للذكاء الاصطناعي على الحافة والذكاء الاصطناعي الموزع

نشر آمن للذكاء الاصطناعي الموزع، بما في ذلك الحوسبة عند الحافة، والتعلم الاتحادي، والهندسة المعمارية متعددة المواقع.

 #4.12.1    المستوى: 2    الدور: D/V
 تحقق من أن أجهزة الذكاء الاصطناعي على الحافة تُثبت هويتها لدى البنية التحتية المركزية باستخدام TLS متبادل مع شهادات الأجهزة التي يتم تدويرها وفق سياسة إدارة الشهادات المؤسسية.
 #4.12.2    المستوى: 2    الدور: D/V
 تحقق من أن أجهزة الحافة تنفّذ الإقلاع الآمن بتوقيعات موثّقة وتوفر حماية من الرجوع إلى إصدار أقدم لمنع هجمات تخفيض البرنامج الثابت.
 #4.12.3    المستوى: 3    الدور: D/V
 تحقق من أن تنسيق الذكاء الاصطناعي الموزع يستخدم خوارزميات الإجماع المقاومة للأخطاء البيزنطية مع التحقق من صحة المشاركين واكتشاف العُقَد الخبيثة
 #4.12.4    المستوى: 3    الدور: D/V
 تحقق من أن الاتصالات من الحافة إلى السحابة تتضمن تقييد عرض النطاق الترددي، وضغط البيانات، وقدرات التشغيل دون اتصال مع التخزين المحلي الآمن.

---

### C4.13 أمن البنية التحتية متعددة السحب والهجينة

تأمين أعباء عمل الذكاء الاصطناعي عبر عدة مزودي خدمات سحابية ونُظُم نشر هجينة بين السحابة والبيئة المحلية.

 #4.13.1    المستوى: 2    الدور: D/V
 تحقق من أن النشر عبر عدة سُحُبات للذكاء الاصطناعي يستخدم اتحاد هوية محايد تجاه السحابة (OIDC، SAML) مع إدارة سياسات مركزيّة عبر مقدمي الخدمات.
 #4.13.2    المستوى: 2    الدور: D/V
 تحقق من أن نقل البيانات عبر السحابات المتعددة يستخدم التشفير من الطرف إلى الطرف مع مفاتيح مُدارة من قبل العميل وتُفرض ضوابط إقامة البيانات وفقاً للنطاق القضائي.
 #4.13.3    المستوى: 2    الدور: D/V
 تحقق من أن أعباء عمل الذكاء الاصطناعي في السحابة الهجينة تطبق سياسات أمنية متسقة عبر البيئات المحلية والسحابية مع رصد وتنبيه موحدين.
 #4.13.4    المستوى: 3    الدور: V
 تحقق من أن منع الاعتماد على موفري السحابة يشمل البنية التحتية ككود قابلة للنقل، وواجهات برمجة التطبيقات الموحدة، وإمكانيات تصدير البيانات مع أدوات تحويل التنسيقات.
 #4.13.5    المستوى: 3    الدور: V
 تحقق من أن تحسين تكاليف الحوسبة عبر السحابات المتعددة يتضمن ضوابط أمان تمنع انتشار الموارد، وكذلك رسوم نقل البيانات عبر السحابات المتعددة دون تفويض.

---

### C4.14 أتمتة البنية التحتية وأمن GitOps

تأمين خطوط أنابيب أتمتة البنية التحتية وتدفقات GitOps لإدارة البنية التحتية للذكاء الاصطناعي.

 #4.14.1    المستوى: 2    الدور: D/V
 تحقق من أن مستودعات GitOps تتطلب التزامات موقَّعة باستخدام مفاتيح GPG وقواعد حماية الفروع التي تمنع الرفع المباشر إلى الفروع الرئيسية.
 #4.14.2    المستوى: 2    الدور: D/V
 تحقق من أن أتمتة البنية التحتية تتضمن كشف الانحراف في التكوين مع الإصلاح التلقائي وقدرات الرجوع إلى الوضع السابق التي تُفَعَّل وفق متطلبات الاستجابة التنظيمية للتغييرات غير المصرح بها.
 #4.14.3    المستوى: 2    الدور: D/V
 تحقق من أن توفير البنية التحتية المؤتمتة يتضمن التحقق من سياسة الأمان مع حظر النشر للتكوينات غير المتوافقة.
 #4.14.4    المستوى: 2    الدور: D/V
 تحقق من أن أسرار أتمتة البنية التحتية تُدار من خلال مشغلي الأسرار الخارجية (External Secrets Operator، Bank-Vaults) مع التدوير التلقائي.
 #4.14.5    المستوى: 3    الدور: V
 تحقق من أن البنية التحتية ذاتية الإصلاح تتضمن ارتباط أحداث الأمان مع استجابة آلية للحوادث وتدفقات إخطار أصحاب المصلحة.

---

### C4.15 أمن البنية التحتية المقاومة- للحوسبة الكمية

جهز بنية تحتية للذكاء الاصطناعي لمواجهة تهديدات الحوسبة الكمومية من خلال التشفير ما بعد الكم وبروتوكولات آمنة كموميًا.

 #4.15.1    المستوى: 3    الدور: D/V
 تحقق من أن البنية التحتية للذكاء الاصطناعي تطبق خوارزميات التشفير ما بعد الكوانتوم المعتمدة من NIST لتبادل المفاتيح والتوقيعات الرقمية (CRYSTALS-Kyber, CRYSTALS-Dilithium, SPHINCS+).
 #4.15.2    المستوى: 3    الدور: D/V
 تحقق من تنفيذ أنظمة توزيع المفتاح الكمي (QKD) للاتصالات المعتمدة على الذكاء الاصطناعي عالية الأمان مع بروتوكولات إدارة المفاتيح الآمنة كمياً.
 #4.15.3    المستوى: 3    الدور: D/V
 تحقق من أن أطر المرونة التشفيرية تتيح الترحيل السريع إلى خوارزميات ما بعد الكوانتم الجديدة مع تدوير تلقائي للشهادات والمفاتيح.
 #4.15.4    المستوى: 3    الدور: V
 تأكد من أن نمذجة التهديدات الكمومية تقيّم هشاشة البنية التحتية للذكاء الاصطناعي أمام الهجمات الكمومية مع جداول ترحيل موثقة وتقييمات المخاطر.
 #4.15.5    المستوى: 3    الدور: D/V
 تحقق من أن أنظمة التشفير الهجينة الكلاسيكية-الكمومية توفر الدفاع متعدد الطبقات خلال فترة الانتقال الكمومي مع رصد الأداء.

---

### C4.16 الحوسبة السرية والوحدات الآمنة

حماية أحمال العمل في الذكاء الاصطناعي وأوزان النموذج باستخدام بيئات تنفيذ موثوقة مبنية على العتاد وتقنيات الحوسبة السرية.

 #4.16.1    المستوى: 3    الدور: D/V
 تحقق من أن نماذج الذكاء الاصطناعي الحساسة تعمل داخل حصون Intel SGX، وAMD SEV-SNP، أو ARM TrustZone مع ذاكرة مشفَّرة والتحقق من الشهادة.
 #4.16.2    المستوى: 3    الدور: D/V
 تحقق من أن الحاويات الآمنة (Kata Containers، gVisor مع الحوسبة الآمنة) تعزل أعباء عمل الذكاء الاصطناعي باستخدام تشفير الذاكرة المعتمد من الأجهزة.
 #4.16.3    المستوى: 3    الدور: D/V
 تحقق من أن التصديق عن بعد يضمن سلامة البيئة المحصنة قبل تحميل نماذج الذكاء الاصطناعي مع إثبات تشفيري على أصالة بيئة التنفيذ.
 #4.16.4    المستوى: 3    الدور: D/V
 تحقق من أن خدمات استدلال الذكاء الاصطناعي السرية تمنع استخراج النموذج من خلال الحوسبة المشفرة مع أوزان النموذج المختومة وتنفيذ محمي.
 #4.16.5    المستوى: 3    الدور: D/V
 تحقق من أن تنظيم بيئة التنفيذ الموثوقة يدير دورة حياة الحيز الآمن مع التوثيق عن بُعد وقنوات اتصال مشفرة.
 #4.16.6    المستوى: 3    الدور: D/V
 تحقق من أن الحوسبة الآمنة متعددة الأطراف (SMPC) تُمكّن تدريب الذكاء الاصطناعي التعاوني دون كشف مجموعات البيانات الفردية أو معاملات النموذج.

---

### C4.17 البنية التحتية للمعرفة الصفرية

تنفيذ أنظمة إثبات معرفة صفرية لضمان التحقق من الهوية والمصادقة في الذكاء الاصطناعي مع الحفاظ على الخصوصية ودون كشف معلومات حساسة.

 #4.17.1    المستوى: 3    الدور: D/V
 تحقق من أن إثباتات المعرفة الصفرية (ZK-SNARKs، ZK-STARKs) تؤكد سلامة نموذج الذكاء الاصطناعي وأصل التدريب دون كشف أوزان النموذج أو بيانات التدريب.
 #4.17.2    المستوى: 3    الدور: D/V
 تحقق من أن أنظمة المصادقة القائمة على إثبات المعرفة الصفري (ZKP) تُمكّن من التحقق من هوية المستخدم مع الحفاظ على الخصوصية لخدمات الذكاء الاصطناعي دون كشف معلومات تتعلق بالهوية.
 #4.17.3    المستوى: 3    الدور: D/V
 تحقق من أن بروتوكولات تقاطع المجموعات الخاص (PSI) تُمكّن مطابقة البيانات الآمنة للذكاء الاصطناعي الاتحادي دون كشف مجموعات البيانات الفردية.
 #4.17.4    المستوى: 3    الدور: D/V
 تحقق من أن أنظمة تعلم آلي بدون معرفة (ZKML) تُمكّن استدلالات الذكاء الاصطناعي القابلة للتحقق مع إثبات تشفري لصحة التنفيذ.
 #4.17.5    المستوى: 3    الدور: D/V
 تحقق من أن ZK-rollups توفر معالجة معاملات الذكاء الاصطناعي قابلة للتوسع وتحافظ على الخصوصية، مع التحقق على دفعات وانخفاض العبء الحاسوبي.

---

### C4.18 منع هجمات القنوات الجانبية

حماية البنية التحتية للذكاء الاصطناعي من هجمات القنوات الجانبية المعتمدة على التوقيت والطاقة والمجال الكهرومغناطيسي وذاكرة التخزين المؤقت التي قد تكشف عن معلومات حساسة.

 #4.18.1    المستوى: 3    الدور: D/V
 تحقق من أن توقيت استدلال الذكاء الاصطناعي موحّد باستخدام خوارزميات زمن ثابت وتعبئة لمنع هجمات استخراج النموذج القائمة على التوقيت.
 #4.18.2    المستوى: 3    الدور: D/V
 تحقق من أن حماية تحليل الطاقة تتضمن حقن الضوضاء، وتصفية خط الطاقة، وأنماط تنفيذ عشوائية لأجهزة الذكاء الاصطناعي.
 #4.18.3    المستوى: 3    الدور: D/V
 تحقق من أن التخفيف من القنوات الجانبية القائمة على ذاكرة التخزين المؤقت يستخدم تقسيم ذاكرة التخزين المؤقت، والتوليد العشوائي، وتعليمات الإفراغ لمنع تسرب المعلومات.
 #4.18.4    المستوى: 3    الدور: D/V
 تحقق من أن حماية الانبعاثات الكهرومغناطيسية تتضمن التدريع، وتصفية الإشارة، ومعالجة عشوائية لمنع هجمات من طراز TEMPEST.
 #4.18.5    المستوى: 3    الدور: D/V
 تأكد من أن دفاعات القنوات الجانبية الميكرومعمارية تشمل ضوابط التنفيذ التكهني وإخفاء نمط الوصول إلى الذاكرة.

---

### C4.19 نيورومورفيك & أمان أجهزة الذكاء الاصطناعي المتخصصة

تأمين هندسات أجهزة الذكاء الاصطناعي الناشئة بما في ذلك شرائح نيورومورف، وFPGAs، وASICs مخصصة، وأنظمة الحوسبة البصرية.

 #4.19.1    المستوى: 3    الدور: D/V
 تحقق من أن أمان شريحة نيورومورفية يشمل تشفير نمط النبض، وحماية أوزان التشابك، والتحقق من صحة قواعد التعلم المستندة إلى العتاد.
 #4.19.2    المستوى: 3    الدور: D/V
 تحقق من أن المعجِّلات المعتمدة على FPGA في الذكاء الاصطناعي تنفّذ تشفير تدفق البت، وآليات مضادة للعبث، وتحميل التكوين الآمن مع تحديثات موثقة.
 #4.19.3    المستوى: 3    الدور: D/V
 تحقق من أن أمان ASIC المخصص يشمل معالجات أمان مدمجة على الرقاقة، وجذر الثقة العتادي، وتخزين آمن للمفاتيح مع كشف التلاعب.
 #4.19.4    المستوى: 3    الدور: D/V
 تحقق من أن أنظمة الحوسبة البصرية تطبق التشفير البصري الآمن كمياً، والتبديل الفوتوني الآمن، ومعالجة الإشارة البصرية المحمية.
 #4.19.5    المستوى: 3    الدور: D/V
 تحقق من أن شرائح الذكاء الاصطناعي الهجينة التناظرية-الرقمية تتضمن حوسبة تناظرية آمنة، وتخزين أوزان محمي، وتحويل تناظري-رقمي موثوق به.

---

### C4.20 البنية التحتية للحوسبة مع الحفاظ على الخصوصية

نفّذ ضوابط البنية التحتية للحوسبة التي تحافظ على الخصوصية لحماية البيانات الحساسة أثناء معالجة وتحليل الذكاء الاصطناعي.

 #4.20.1    المستوى: 3    الدور: D/V
 تحقق من أن بنية التشفير التجانسي تتيح إجراء عمليات مشفّرة على أعباء العمل الحساسة في الذكاء الاصطناعي، مع التحقق من التكامل التشفيري ومراقبة الأداء.
 #4.20.2    المستوى: 3    الدور: D/V
 تحقق من أن أنظمة استرجاع المعلومات الخاصة تمكّن من إجراء استعلامات قاعدة البيانات دون الكشف عن أنماط الاستعلام مع حماية تشفيرية لأنماط الوصول.
 #4.20.3    المستوى: 3    الدور: D/V
 تحقق من أن بروتوكولات الحوسبة متعددة الأطراف الآمنة تتيح استدلال ذكاء اصطناعي يحافظ على الخصوصية دون كشف المدخلات الفردية أو الحسابات الوسيطة.
 #4.20.4    المستوى: 3    الدور: D/V
 تحقق من أن إدارة المفاتيح التي تُحافظ على الخصوصية تتضمن توليد المفاتيح الموزعة والتشفير بالعتبة وتدوير المفاتيح بشكل آمن مع حماية مدعومة من العتاد.
 #4.20.5    المستوى: 3    الدور: D/V
 تحقق من أن أداء الحوسبة مع الحفاظ على الخصوصية مُحسَّن من خلال التجميع والتخزين المؤقت وتسريع الأجهزة مع الحفاظ على ضمانات الأمن التشفري.

---

### C4.15 إطار عمل الوكيل تكامل السحابة والأمن والنشر الهجين

ضوابط الأمان لإطارات الوكلاء المتكاملة مع السحابة ضمن هياكل هجينة محلية/سحابية.

 #4.15.1    المستوى: 1    الدور: D/V
 تحقق من أن تكامل التخزين السحابي يستخدم التشفير من الطرف إلى الطرف مع إدارة المفاتيح التي يتحكم فيها الوكيل.
 #4.15.2    المستوى: 2    الدور: D/V
 تحقق من أن حدود أمان النشر الهجين محددة بوضوح باستخدام قنوات اتصال مشفرة.
 #4.15.3    المستوى: 2    الدور: D/V
 تحقق من أن وصول الموارد السحابية يتضمن التحقق وفق مبدأ الثقة الصفري مع المصادقة المستمرة.
 #4.15.4    المستوى: 3    الدور: D/V
 تحقق من أن متطلبات إقامة البيانات مفروضة من خلال التصديق التشفيري لمواقع التخزين.
 #4.15.5    المستوى: 3    الدور: D/V
 تحقق من أن تقييمات أمان مزود الخدمات السحابية تشمل نمذجة التهديدات الخاصة بالوكيل وتقييم المخاطر.

---

### المراجع

NIST Cybersecurity Framework 2.0
CIS Controls v8
OWASP Container Security Verification Standard
Kubernetes Security Best Practices
SLSA Supply Chain Security Framework
NIST SP 800-190: Application Container Security Guide
Cloud Security Alliance: Cloud Controls Matrix
ENISA: Secure Infrastructure Design
NIST SP 800-53: Security Controls for Federal Information Systems
ISO 27001:2022 Information Security Management
NIST AI Risk Management Framework
CIS Kubernetes Benchmark
FIPS 140-2 Security Requirements
NIST SP 800-207: Zero Trust Architecture
IEEE 2857: Privacy Engineering for AI Systems
NIST SP 800-161: Cybersecurity Supply Chain Risk Management
NIST Post-Quantum Cryptography Standards
Intel SGX Developer Guide
AMD SEV-SNP White Paper
ARM TrustZone Technology
ZK-SNARKs: A Gentle Introduction
NIST SP 800-57: Cryptographic Key Management
Side-Channel Attack Countermeasures
Neuromorphic Computing Security Challenges
FPGA Security: Fundamentals, Evaluation, and Countermeasures
Microsoft SEAL: Homomorphic Encryption Library
HElib: Homomorphic Encryption Library
PALISADE Lattice Cryptography Library
Differential Privacy: A Survey of Results
Secure Aggregation for Federated Learning
Private Information Retrieval: Concepts and Constructions

## C5 التحكّم في الوصول والهوية لمكوّنات الذكاء الاصطناعي والمستخدمين

### هدف الرقابة

يتطلب التحكم الفعّال في الوصول إلى أنظمة الذكاء الاصطناعي إدارة هوية قوية، وتفويضاً يعتمد على السياق، وإنفاذاً أثناء وقت التشغيل وفق مبادئ الثقة الصفرية. وتضمن هذه الضوابط أن يتفاعلون البشر والخدمات ووكلاء مستقلون فقط مع النماذج والبيانات والموارد الحاسوبية ضمن نطاقات مُمنوحة بشكل صريح، مع إمكانات تحقق مستمر وآليات تدقيق.

---

### C5.1 إدارة الهوية والمصادقة

تأسيس هويات مدعومة بتشفير لجميع الكيانات مع المصادقة متعددة العوامل للعمليات ذات الامتياز.

 #5.1.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع المستخدمين البشريين ومبادئ الخدمة يتم المصادقة عبر مزود الهوية المؤسسي المركزي (IdP) باستخدام بروتوكولات OIDC/SAML مع خرائط هوية-إلى-رمز فريدة (لا توجد حسابات أو بيانات اعتماد مشتركة).
 #5.1.2    المستوى: 1    الدور: D/V
 تحقق من أن العمليات عالية المخاطر (نشر النموذج، تصدير الأوزان، الوصول إلى بيانات التدريب، تغييرات تكوين الإنتاج) تتطلب المصادقة متعددة العوامل أو المصادقة التصعيدية مع إعادة التحقق من الجلسة.
 #5.1.3    المستوى: 2    الدور: D
 تحقق من أن المستخدمين الجدد يخضعون لإثبات الهوية بما يتوافق مع NIST 800-63-3 IAL-2 أو معايير مكافئة قبل حصولهم على وصول إلى النظام الإنتاجي.
 #5.1.4    المستوى: 2    الدور: V
 تحقق من أن مراجعات الوصول تُجرى ربع سنويًا مع الكشف التلقائي عن الحسابات غير النشطة، وفرض تدوير بيانات الاعتماد، وإجراءات إنهاء الوصول.
 #5.1.5    المستوى: 3    الدور: D/V
 تحقق من أن وكلاء الذكاء الاصطناعي الفيدراليين يصدقون عبر ادعاءات JWT الموقعة التي تكون مدة صلاحيتها القصوى 24 ساعة وتتضمن إثباتاً تشفيرياً للمصدر.

---

### C5.2 تفويض الموارد والحد الأدنى من الامتياز

تنفيذ ضوابط وصول دقيقة ومفصلة لجميع موارد الذكاء الاصطناعي مع نماذج أذونات صريحة وسجلات التدقيق

 #5.2.1    المستوى: 1    الدور: D/V
 تحقق من أن كل مورد من موارد الذكاء الاصطناعي (مجموعات البيانات، النماذج، النقاط النهائية، مجموعات المتجهات، فهارس التضمين، مثيلات الحوسبة) يطبق ضوابط وصول مستندة إلى الأدوار مع قوائم سماح صريحة وسياسات رفض افتراضية.
 #5.2.2    المستوى: 1    الدور: D/V
 تحقق من أن مبادئ الحد الأدنى من الامتيازات مطبقة افتراضيًا مع حسابات الخدمة التي تبدأ بامتيازات القراءة فقط، وأنه يُشترط وجود مبرر تجاري موثّق للوصول إلى صلاحيات الكتابة.
 #5.2.3    المستوى: 1    الدور: V
 تحقق من أن جميع تعديلات التحكم في الوصول مرتبطة بطلبات التغيير المعتمدة ومسجّلة بشكل لا يمكن تغييره مع طوابع زمنية وهويات الجهات الفاعلة ومعرفات الموارد وفروقات الإذن.
 #5.2.4    المستوى: 2    الدور: D
 تحقق من أن تسميات تصنيف البيانات (PII, PHI, export-controlled, proprietary) تنتشر تلقائياً إلى الموارد المشتقة (التضمينات، مخازن المطالب، مخرجات النموذج) مع تطبيق سياسات بشكل متسق.
 #5.2.5    المستوى: 2    الدور: D/V
 تحقق من أن محاولات الوصول غير المصرح بها وأحداث التصعيد في الامتيازات تُطلق تنبيهات في الوقت الفعلي مع بيانات وصفية سياقية إلى أنظمة SIEM خلال 5 دقائق.

---

### C5.3 تقييم السياسة الديناميكية

نشر محركات التحكم بالوصول المعتمَد على السمات (ABAC) من أجل قرارات تفويض مدعومة بالسياق مع قدرات التدقيق.

 #5.3.1    المستوى: 1    الدور: D/V
 تحقق من أن قرارات الإذن تُحوَّل إلى محرك سياسات مخصص (OPA، Cedar، أو ما يعادله) يمكن الوصول إليه عبر واجهات برمجة تطبيقات موثقة مع حماية تكامل تشفري.
 #5.3.2    المستوى: 1    الدور: D/V
 تحقق من أن السياسات تقيم السمات الديناميكية في وقت التشغيل، بما في ذلك مستوى صلاحية المستخدم، وتصنيف حساسية الموارد، وسياق الطلب، وعزل المستأجر، والقيود الزمنية.
 #5.3.3    المستوى: 2    الدور: D
 تحقق من أن تعريفات السياسات مُدارة بنظام التحكم في الإصدارات، ومراجعة من قِبل الأقران، ومحققة من خلال الاختبار الآلي في خطوط CI/CD قبل النشر إلى بيئة الإنتاج.
 #5.3.4    المستوى: 2    الدور: V
 تحقق من أن نتائج تقييم السياسات تتضمن مبررات القرار المهيكلة، وأنها تُنقل إلى أنظمة SIEM من أجل تحليل الارتباط وتقارير الامتثال.
 #5.3.5    المستوى: 3    الدور: D/V
 تحقق من أن قيم TTL لذاكرة التخزين المؤقت الخاصة بالسياسة لا تتجاوز 5 دقائق للموارد عالية الحساسية و1 ساعة للموارد القياسية التي لديها إمكانات إبطال التخزين المؤقت.

---

### C5.4 فرض الأمان أثناء الاستعلام

تنفيذ ضوابط أمان على مستوى طبقة قاعدة البيانات مع التصفية الإلزامية وسياسات أمان على مستوى الصفوف.

 #5.4.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع استعلامات قاعدة بيانات المتجهات وSQL تتضمن فلاتر أمان إلزامية (معرّف المستأجر، علامات الحساسية، نطاق المستخدم) تُفرض على مستوى محرك قاعدة البيانات، وليس في شفرة التطبيق.
 #5.4.2    المستوى: 1    الدور: D/V
 تحقق من تفعيل سياسات الأمان على مستوى الصفوف (RLS) والتعتيم على مستوى الحقول مع وراثة السياسات لجميع قواعد البيانات المتجهة وفهارس البحث ومجموعات البيانات التدريبية.
 #5.4.3    المستوى: 2    الدور: D
 تحقق من أن تقييمات التفويض الفاشلة ستمنع "confused deputy attacks" عبر إيقاف الاستعلامات فوراً وإرجاع رموز خطأ تفويض صريحة بدلاً من إرجاع مجموعات نتائج فارغة.
 #5.4.4    المستوى: 2    الدور: V
 تحقق من أن زمن تقييم السياسة يُراقَب باستمرار مع إشعارات آلية لحالات انتهاء المهلة التي قد تتيح تجاوز التفويض
 #5.4.5    المستوى: 3    الدور: D/V
 تحقق من أن آليات إعادة المحاولة للاستعلام تعيد تقييم سياسات التفويض لتأخذ تغيّرات الأذونات الديناميكية ضمن جلسات المستخدم النشطة.

---

### C5.5 تصفية الإخراج و منع فقدان البيانات

نشر ضوابط المعالجة اللاحقة لمنع كشف البيانات غير المصرح بها في المحتوى AI-generated.

 #5.5.1    المستوى: 1    الدور: D/V
 تحقق من أن آليات التصفية بعد الاستدلال تفحص وتطمس PII غير المصرح بها، والمعلومات المصنّفة، والبيانات المملوكة قبل تسليم المحتوى إلى مقدمي الطلب.
 #5.5.2    المستوى: 1    الدور: D/V
 تحقق من أن الاستشهادات والمراجع ونسب المصادر في مخرجات النموذج يتم التحقق منها مقابل صلاحيات المتصل، وتُحذف إذا تم اكتشاف وصول غير مصرح به.
 #5.5.3    المستوى: 2    الدور: D
 تحقق من أن قيود تنسيق الإخراج (ملفات PDF المعقمة، الصور بدون بيانات وصفية، أنواع الملفات المعتمدة) مطبقة وفقًا لمستويات أذونات المستخدم وتصنيفات البيانات.
 #5.5.4    المستوى: 2    الدور: V
 تحقق من أن خوارزميات الإخفاء حتمية، ومُدارة بواسطة الإصدارات، وتحتفظ بسجلات تدقيق لدعم تحقيقات الامتثال والتحليل الجنائي.
 #5.5.5    المستوى: 3    الدور: V
 تحقق من أن أحداث الإخفاء ذات مخاطر عالية تولِّد سجلات تكيفية تتضمن تجزئات تشفيرية للمحتوى الأصلي من أجل الاستخراج الجنائي دون كشف البيانات.

---

### C5.6 عزل المستأجرين المتعددين

ضمان العزل التشفري والمنطقي بين المستأجرين في البنية التحتية المشتركة للذكاء الاصطناعي.

 #5.6.1    المستوى: 1    الدور: D/V
 تحقق من أن مساحات الذاكرة، مخازن التضمين، إدخالات التخزين المؤقت، والملفات المؤقتة مفصولة حسب مساحة الاسم لكل مستأجر، مع المسح الآمن عند حذف المستأجر أو إنهاء الجلسة.
 #5.6.2    المستوى: 1    الدور: D/V
 تحقق من أن كل طلب API يتضمن معرّف المستأجر المصادق عليه الذي يتم التحقق من صحته تشفيرياً مقابل سياق الجلسة وامتيازات المستخدم.
 #5.6.3    المستوى: 2    الدور: D
 تحقق من أن سياسات الشبكة تنفذ قواعد الرفض الافتراضي للاتصال بين المستأجرين ضمن شبكات الخدمات ومنصات تنظيم الحاويات.
 #5.6.4    المستوى: 3    الدور: D
 تحقق من أن مفاتيح التشفير فريدة لكل مستأجر مع دعم مفتاح مُدار من قبل العميل (CMK) والعزل التشفيري بين مخازن بيانات المستأجرين.

---

### C5.7 تفويض الوكيل المستقل

التحكم في أذونات وكلاء الذكاء الاصطناعي والأنظمة المستقلة من خلال توكنات القدرة المحدودة والتفويض المستمر.

 #5.7.1    المستوى: 1    الدور: D/V
 تحقق من أن الوكلاء المستقلين يتلقون توكنات صلاحية مقيدة بالنطاق التي تسرد صراحة الإجراءات المسموح بها، والموارد التي يمكن الوصول إليها، والحدود الزمنية، والقيود التشغيلية.
 #5.7.2    المستوى: 1    الدور: D/V
 تحقق من أن القدرات عالية المخاطر (الوصول إلى نظام الملفات، تنفيذ الشيفرة، الاتصالات بواجهات برمجة التطبيقات الخارجية، المعاملات المالية) معطلة افتراضيًا وتتطلب تصاريح صريحة للتفعيل مع مبررات تجارية.
 #5.7.3    المستوى: 2    الدور: D
 تحقق من أن رموز القدرة مرتبطة بجلسات المستخدمين، وتحتوي على حماية تكامل تشفري، وأنها لا يمكن حفظها أو إعادة استخدامها في سيناريوهات عدم الاتصال.
 #5.7.4    المستوى: 2    الدور: V
 تحقق من أن الإجراءات التي يبدأها الوكيل تخضع لتفويض ثانٍ من خلال محرك سياسات ABAC مع تقييم سياق كامل وتسجيل تدقيق.
 #5.7.5    المستوى: 3    الدور: V
 تحقق من أن حالات خطأ الوكيل ومعالجة الاستثناءات تتضمن معلومات نطاق القدرات لدعم تحليل الحوادث والتحقيق الجنائي.

---

### المراجع

#### المعايير والأطر

NIST SP 800-63-3: Digital Identity Guidelines
Zero Trust Architecture – NIST SP 800-207
OWASP Application Security Verification Standard (AISVS)
​
#### أدلة التنفيذ

Identity and Access Management in the AI Era: 2025 Guide – IDSA
Attribute-Based Access Control with OPA – Permify
How We Designed Cedar to Be Intuitive, Fast, and Safe – AWS
​
#### أمن مخصص للذكاء الاصطناعي

Row Level Security in Vector DBs for RAG – Bluetuple.ai
Tenant Isolation in Multi-Tenant Systems – WorkOS
Handling AI Agent Permissions – Stytch
OWASP Top 10 for Large Language Model Applications

## C6 أمان سلسلة التوريد للنماذج والإطارات والبيانات

### هدف الرقابة

هجمات سلسلة توريد الذكاء الاصطناعي تستغل نماذج من طرف ثالث، أو أطر عمل، أو مجموعات بيانات لإدراج أبواب خلفية، وانحياز، أو رمز قابل للاستغلال. توفّر هذه الضوابط إثبات الأصل من البداية إلى النهاية، وإدارة الثغرات، والمراقبة لحماية دورة حياة النموذج بأكملها.

---

### C6.1 فحص النموذج المدرب مسبقاً وأصله

قم بتقييم وتوثيق أصول نماذج الأطراف الثالثة وتراخيصها وسلوكياتها الخفية قبل أي تخصيص دقيق أو نشر.

 #6.1.1    المستوى: 1    الدور: D/V
 تحقق من أن كل عنصر نموذج لطرف ثالث يتضمن سجل أصل موقّع يحدّد مستودع المصدر وهاش الالتزام.
 #6.1.2    المستوى: 1    الدور: D/V
 تأكد من أن النماذج تُفْحَص بحثًا عن طبقات خبيثة أو مشغّلات Trojan باستخدام أدوات آلية قبل الاستيراد.
 #6.1.3    المستوى: 2    الدور: D
 تحقق من أن عمليات الضبط الدقيق باستخدام التعلم بالنقل تجتاز التقييم العدائي للكشف عن السلوكيات الخفية.
 #6.1.4    المستوى: 2    الدور: V
 تحقق من أن تراخيص النموذج، وعلامات الرقابة على التصدير، وتصريحات منشأ البيانات مسجَّلة في إدخال ML‑BOM.
 #6.1.5    المستوى: 3    الدور: D/V
 تحقق من أن النماذج عالية‑المخاطر (الأوزان التي تم رفعها علناً، والمنشئين غير موثوقين) تظل في الحجر الصحي حتى تتم مراجعتها من قِبل البشر والحصول على الموافقة النهائية.

---

### C6.2 فحص أطر العمل والمكتبات

فحص مستمر لأطر تعلم الآلة ومكتباتها من ثغرات CVEs وشيفرات ضارة للحفاظ على أمان مكدس وقت التشغيل.

 #6.2.1    المستوى: 1    الدور: D/V
 تحقق من أن خطوط CI تقوم بتشغيل ماسحات الاعتماديات على أطر الذكاء الاصطناعي والمكتبات الحرجة.
 #6.2.2    المستوى: 1    الدور: D/V
 تحقق من أن وجود ثغرات حرجة (CVSS ≥ 7.0) يمنع الترويج إلى صور الإنتاج.
 #6.2.3    المستوى: 2    الدور: D
 تحقق من أن التحليل الثابت للكود يعمل على مكتبات تعلم الآلة المستنسخة (forked) أو المكتبات vendored المدرجة في المشروع.
 #6.2.4    المستوى: 2    الدور: V
 تحقق من أن مقترحات ترقية الإطار تتضمن تقييم أثر أمني يشير إلى تغذيات CVE العامة.
 #6.2.5    المستوى: 3    الدور: V
 تحقق من أن أجهزة الاستشعار أثناء التشغيل تصدر تنبيهًا عند تحميل مكتبات ديناميكية غير متوقعة تنحرف عن قائمة مكونات البرمجيات الموقَّعة.

---

### C6.3 تثبيت الاعتماديات والتحقق

ثبت كل تبعية على تجزئات غير قابلة للتغيير وأعد إنتاج عمليات البناء لضمان مخرجات مطابقة تماماً وخالية من التلاعب.

 #6.3.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع مديري الحزم يفرضون تقييد الإصدارات عبر ملفات القفل.
 #6.3.2    المستوى: 1    الدور: D/V
 تحقق من استخدام التجزئات غير القابلة للتغيير بدلاً من الوسوم القابلة للتغيير في مراجع الحاويات.
 #6.3.3    المستوى: 2    الدور: D
 تحقق من أن فحوصات reproducible‑build تقارن هاشات عبر تشغيلات CI لضمان مخرجات متطابقة.
 #6.3.4    المستوى: 2    الدور: V
 تحقق من حفظ شهادات البناء لمدة 18 شهرًا من أجل التتبّع التدقيقي.
 #6.3.5    المستوى: 3    الدور: D
 تحقق من أن التبعيات منتهية الصلاحية تؤدي إلى طلبات سحب تلقائية لتحديثها أو تفريع الإصدارات المثبتة.

---

### C6.4 إنفاذ المصادر الموثوقة

السماح بتنزيل المخرجات فقط من المصادر التي تم التحقق منها تشفيرياً والمعتمدة من المؤسسة، وحظر كل شيء آخر.

 #6.4.1    المستوى: 1    الدور: D/V
 تحقق من أن أوزان النموذج ومجموعات البيانات والحاويات يتم تنزيلها فقط من المجالات المعتمدة أو المستودعات الداخلية.
 #6.4.2    المستوى: 1    الدور: D/V
 تحقق من أن توقيعات Sigstore/Cosign تتحقق من هوية الناشر قبل أن يتم تخزين المخرجات محلياً.
 #6.4.3    المستوى: 2    الدور: D
 تحقق من أن بروكسيات الخروج تمنع تنزيلات المخرجات البرمجية غير المصادق عليها لتطبيق سياسة المصدر الموثوق.
 #6.4.4    المستوى: 2    الدور: V
 تحقق من أن قوائم السماح للمستودع يتم مراجعتها بشكل ربع سنوي مع وجود دليل يبرر السبب التجاري لكل إدخال.
 #6.4.5    المستوى: 3    الدور: V
 تحقق من أن انتهاكات السياسة تؤدي إلى الحجر الصحي للقطع الناتجة والتراجع عن تشغيلات خطوط الأنابيب التابعة.

---

### C6.5 تقييم مخاطر مجموعة بيانات الطرف الثالث

تقييم مجموعات البيانات الخارجية من حيث تلويث البيانات والتحيز والامتثال القانوني، ومراقبتها طوال دورة حياتها.

 #6.5.1    المستوى: 1    الدور: D/V
 تحقق من أن مجموعات البيانات الخارجية تخضع لتقييم مخاطر التسميم (مثلاً، بصمة البيانات، وكشف القيم الشاذة).
 #6.5.2    المستوى: 1    الدور: D
 تحقق من أن مقاييس التحيز (التكافؤ الديموغرافي، وتكافؤ الفرص) تُحسب قبل اعتماد مجموعة البيانات.
 #6.5.3    المستوى: 2    الدور: V
 تحقق من أن أصل البيانات وشروط الترخيص الخاصة بمجموعات البيانات موثقة في بنود ML‑BOM.
 #6.5.4    المستوى: 2    الدور: V
 تحقق من أن المراقبة الدورية تكشف انزياح البيانات أو تلفها في مجموعات البيانات المستضافة.
 #6.5.5    المستوى: 3    الدور: D
 تحقق من أن المحتوى غير المصرّح به (حقوق النشر، PII) يُزال عبر التنظيف الآلي قبل التدريب.

---

### C6.6 مراقبة هجمات سلسلة التوريد

اكتشاف تهديدات سلسلة‑التوريد مبكرًا من خلال تغذيات CVE، وتحليلات سجل‑التدقيق، ومحاكاة الفريق‑الأحمر.

 #6.6.1    المستوى: 1    الدور: V
 تحقق من أن سجلات تدقيق CI/CD تتدفق إلى SIEM لاكتشاف سحب الحزم بشكل غير عادي أو تعديلات في خطوات البناء.
 #6.6.2    المستوى: 2    الدور: D
 تحقق من أن خطط استجابة الحوادث تتضمن إجراءات التراجع للنماذج أو المكتبات المخترقة.
 #6.6.3    المستوى: 3    الدور: V
 تأكد من أن وسوم إثراء استخبارات التهديد تتضمن مؤشرات محددة للتعلم الآلي (على سبيل المثال، IoCs الخاصة بتلويث النموذج) في فرز الإنذارات.

---

### C6.7 ML‑BOM لمخرجات النموذج

أنشئ ووقّع قوائم مكوّنات البرمجيات المفصّلة الخاصة بـ ML‑SBOMs (ML‑BOMs) ليتمكّن المستهلكون في الطرف التالي من التحقق من سلامة المكوّنات عند النشر.

 #6.7.1    المستوى: 1    الدور: D/V
 تحقق من أن كل ناتج النموذج ينشر ML‑BOM ويضم مجموعات البيانات، الأوزان، المعلمات الفائقة، والتراخيص.
 #6.7.2    المستوى: 1    الدور: D/V
 تحقق من أن توليد ML‑BOM وتوقيع Cosign آليان في CI ومطلوبان للدمج.
 #6.7.3    المستوى: 2    الدور: D
 تحقق من أن فحوص اكتمال ML‑BOM تفشل عملية البناء إذا كانت هناك أي بيانات تعريف للمكوّن (الهاش، الرخصة) غير متوفرة.
 #6.7.4    المستوى: 2    الدور: V
 تحقق من أن المستهلكين اللاحقين يستطيعون الاستعلام عن ML-BOMs عبر واجهة برمجة التطبيقات للتحقق من صحة النماذج المستوردة عند وقت النشر.
 #6.7.5    المستوى: 3    الدور: V
 تحقق من أن ML‑BOMs خاضعة لإدارة الإصدارات وتُجرى فيها مقارنة الفروقات لاكتشاف التعديلات غير المصرّح بها.

---

### المراجع

ML Supply Chain Compromise – MITRE ATLAS
Supply‑chain Levels for Software Artifacts (SLSA)
CycloneDX – Machine Learning Bill of Materials
What is Data Poisoning? – SentinelOne
Transfer Learning Attack – OWASP ML Security Top 10
AI Data Security Best Practices – CISA
Secure CI/CD Supply Chain – Sumo Logic
AI & Transparency: Protect ML Models – ReversingLabs
SBOM Overview – CISA
Training Data Poisoning Guide – Lakera.ai
Dependency Pinning for Reproducible Python – Medium

## C7 سلوك النموذج، التحكم في الإخراج وضمان السلامة

### هدف الرقابة

مخرجات النموذج يجب أن تكون مُهيكلة وموثوقة وآمنة وقابلة للتفسير، وتخضع للمراقبة المستمرة في بيئة الإنتاج. القيام بذلك يقلل من الهلوسات وتسريبات الخصوصية والمحتوى الضار والسلوكيات الخارجة عن السيطرة، مع زيادة ثقة المستخدم والالتزام التنظيمي.

---

### C7.1 إنفاذ تنسيق الإخراج

المخططات الصارمة وفك الترميز المقيد والتحقق اللاحق توقف المحتوى المعيب أو الضار قبل أن ينتشر.

 #7.1.1    المستوى: 1    الدور: D/V
 تحقق من أن مخططات الاستجابة (مثل مخطط JSON) مُزوَّدة في موجه النظام، وأن يتم التحقق تلقائيًا من كل إخراج؛ الإخراجات غير المطابقة تؤدي إلى الإصلاح أو الرفض.
 #7.1.2    المستوى: 1    الدور: D/V
 تحقق من أن التوليد المقيد مفعل (رموز الإيقاف، التعبيرات النمطية، max-tokens) لمنع تجاوز السعة أو القنوات الجانبية المرتبطة بحقن المطالبات.
 #7.1.3    المستوى: 2    الدور: D/V
 تحقق من أن المكونات التابعة تتعامل مع المخرجات كمخرجات غير موثوقة وتتحقق منها مقابل المخططات أو أدوات فك التسلسل الآمنة ضد الحقن.
 #7.1.4    المستوى: 3    الدور: V
 تحقق من أن أحداث الإخراج غير الصحيح تُسجَّل وتُقيَّد بمعدل وتُعرض على أنظمة المراقبة.

---

### C7.2 الكشف عن الهلاوس والتخفيف منها

تقدير عدم اليقين واستراتيجيات الاحتياطي يحدّان من الإجابات المصطنعة.

 #7.2.1    المستوى: 1    الدور: D/V
 تحقق من أن احتمالات لوغاريتمية عند مستوى التوكن، والتوافق الذاتي للنظام التجميعي، وكاشفات الهلوسة المدربة بعناية تمنح درجة ثقة لكل إجابة.
 #7.2.2    المستوى: 1    الدور: D/V
 تحقق من أن الاستجابات التي تقع تحت عتبة الثقة القابلة للتكوين تُفعِّل مسارات العمل البديلة (على سبيل المثال، التوليد المعزز بالاسترجاع، أو نموذج ثانوي، أو مراجعة بشرية).
 #7.2.3    المستوى: 2    الدور: D/V
 تحقق من أن حوادث الهلوسة موسومة ببيانات السبب الجذري وتُغذّى إلى خطوط أنابيب تحليل ما بعد الحدث وخطوط أنابيب الضبط الدقيق.
 #7.2.4    المستوى: 3    الدور: D/V
 تحقق من إعادة معايرة العتبات والكاشفات بعد تحديثات كبيرة للنموذج أو قاعدة المعرفة.
 #7.2.5    المستوى: 3    الدور: V
 تأكد من أن المرئيات في لوحة البيانات تتبع معدلات الهلاوس.

---

### C7.3 تصفية السلامة والخصوصية للمخرجات

فلاتر السياسات وتغطية الفريق الأحمر تحمي المستخدمين والبيانات السرية.

 #7.3.1    المستوى: 1    الدور: D/V
 تحقق من أن مصنفات ما قبل التوليد وما بعد التوليد تحجب المحتوى الذي يتضمن خطاب الكراهية والمضايقة وإيذاء النفس والتطرف والمحتوى الجنسي الصريح بما يتماشى مع السياسة.
 #7.3.2    المستوى: 1    الدور: D/V
 تحقق من أن كشف PII/PCI والإخفاء التلقائي يتم في كل استجابة؛ المخالفات تثير حادثة خصوصية.
 #7.3.3    المستوى: 2    الدور: D
 تحقق من أن علامات السرية (على سبيل المثال، الأسرار التجارية) تنتشر عبر الوسائط المتعددة لمنع التسرب في النصوص والصور والشفرة.
 #7.3.4    المستوى: 3    الدور: D/V
 تأكد من أن محاولات تجاوز الفلتر أو التصنيفات عالية المخاطر تتطلب موافقة ثانوية أو إعادة المصادقة للمستخدم.
 #7.3.5    المستوى: 3    الدور: D/V
 تحقق من أن حدود التصفية تعكس الاختصاصات القانونية وسياق عمر المستخدم ودوره.

---

### C7.4 الإخراج وتقييد الإجراءات

قيود المعدل وبوابات الموافقة تمنع إساءة الاستخدام والاستقلالية المفرطة.

 #7.4.1    المستوى: 1    الدور: D
 تحقق من أن الحصص لكل مستخدم ولكل مفتاح API تقيد الطلبات والتوكنات والتكلفة مع التأخير الأسي عند أخطاء 429.
 #7.4.2    المستوى: 1    الدور: D/V
 تحقق من أن الإجراءات ذات الامتياز (كتابة الملفات، تنفيذ التعليمات البرمجية، استدعاءات الشبكة) تتطلب موافقة قائمة على السياسات أو التدخل البشري في الحلقة.
 #7.4.3    المستوى: 2    الدور: D/V
 تحقق من أن فحوصات الاتساق عبر الوسائط تضمن أن الصور والكود والنص الناتجون عن نفس الطلب لا يمكن استخدامها لتهريب محتوى ضار.
 #7.4.4    المستوى: 2    الدور: D
 تحقق من أن عمق تفويض الوكيل، وحدود الاستدعاء العودي، وقوائم الأدوات المسموح بها محددة بشكل صريح.
 #7.4.5    المستوى: 3    الدور: V
 تحقق من أن انتهاك الحدود يُصدر أحداث أمان مُهيكلة لاستيعابها في SIEM.

---

### C7.5 قابلية تفسير المخرجات

الإشارات الشفافة تعزز ثقة المستخدم وتسهّل التصحيح الداخلي.

 #7.5.1    المستوى: 2    الدور: D/V
 تحقق من أن درجات الثقة المعروضة للمستخدم أو ملخصات الاستدلال الموجزة تُعرض عندما يعتبر تقييم المخاطر مناسباً.
 #7.5.2    المستوى: 2    الدور: D/V
 تحقق من أن التفسيرات المُولَّدة لا تكشف عن موجهات النظام الحساسة أو البيانات الملكية.
 #7.5.3    المستوى: 3    الدور: D
 تأكد من أن النظام يلتقط احتمالات لوغاريتمية على مستوى الرموز أو خرائط الانتباه ويخزّنها للمراجعة المصرّح بها.
 #7.5.4    المستوى: 3    الدور: V
 تحقق من أن مخرجات التفسير مُدارَة بنسخ الإصدارات جنبًا إلى جنب مع إصدارات النماذج لأغراض التدقيق.

---

### C7.6 تكامل الرصد

المراقبة في الوقت الفعلي تغلق الحلقة بين التطوير والإنتاج.

 #7.6.1    المستوى: 1    الدور: D
 تحقق من أن المقاييس (انتهاكات المخطط، معدل الهلوسة، السمية، تسريبات PII، زمن الاستجابة، التكلفة) تتدفق إلى منصة مراقبة مركزية.
 #7.6.2    المستوى: 1    الدور: V
 تحقق من أن عتبات الإنذار محددة لكل مقياس سلامة، مع مسارات التصعيد أثناء المناوبة أيضًا.
 #7.6.3    المستوى: 2    الدور: V
 تحقق من أن لوحات المعلومات تُظهر ارتباط الشذوذات الناتجة بالنموذج/الإصدار، وعلم الميزة، وتغييرات البيانات المصدرية.
 #7.6.4    المستوى: 2    الدور: D/V
 تحقق من أن بيانات الرصد تغذّي عمليات إعادة التدريب أو الضبط الدقيق أو تحديثات القواعد ضمن سير عمل MLOps موثق.
 #7.6.5    المستوى: 3    الدور: V
 تحقق من أن خطوط الرصد قد خضعت لاختبار الاختراق وتخضع لضوابط وصول لتجنب تسرب السجلات الحساسة.

---

### 7.7 ضمانات الوسائط التوليدية

تأكد من أن أنظمة الذكاء الاصطناعي لا تولد محتوى إعلامي غير قانوني أو ضار أو غير مصرح به من خلال فرض قيود السياسة والتحقق من المخرجات والتتبع.

 #7.7.1    المستوى: 1    الدور: D/V
 تحقق من أن إشعارات النظام وتعليمات المستخدم تحظر صراحة توليد الوسائط المزيفة العميقة غير القانونية أو الضارة أو غير الموافق عليها (على سبيل المثال، صورة، فيديو، صوت).
 #7.7.2    المستوى: 2    الدور: D/V
 تأكد من أن المطالبات مُفلترة من محاولات توليد انتحال الهوية، أو ديب فايك جنسي صريح، أو وسائط تصور أشخاصًا حقيقيين بدون موافقتهم.
 #7.7.3    المستوى: 2    الدور: V
 تحقق من أن النظام يستخدم التجزئة الإدراكية أو كشف العلامة المائية أو بصمة رقمية لمنع إعادة إنتاج غير مصرح به لوسائط محمية بحقوق الطبع والنشر.
 #7.7.4    المستوى: 3    الدور: D/V
 تحقق من أن جميع الوسائط المُولَّدة مُوقَّعة رقمياً، أو مُختومة بختم مائي، أو مدمجة ببيانات أصل مقاومة للعبث لتتبّعها في المراحل التالية.
 #7.7.5    المستوى: 3    الدور: V
 تحقق من أن محاولات التحايل على المطالب (مثل إخفاء المطالب، العامية، الصياغة العدائية) يتم اكتشافها وتسجيلها وتقييدها بمعدل؛ وتُعرض الإساءات المتكررة على أنظمة المراقبة.

### المراجع

NIST AI Risk Management Framework
ISO/IEC 42001:2023 – AI Management System
OWASP Top-10 for Large Language Model Applications (2025)
Improper Output Handling – OWASP LLM05:2025
Practical Techniques to Constrain LLM Output
Dataiku – Structured Text Generation Guide
VL-Uncertainty: Detecting Hallucinations
HaDeMiF: Hallucination Detection & Mitigation
Building Confidence in LLM Outputs
Explainable AI & LLMs
LLM Red-Teaming Guide
Sensitive Information Disclosure in LLMs
LangChain – Chat Model Rate Limiting
OpenAI Rate-Limit & Exponential Back-off
Arize AI – LLM Observability Platform

## ذاكرة C8، التضمينات وأمان قاعدة بيانات المتجهات

### هدف الرقابة

التضمينات ومخازن المتجهات تعملان كذاكرة حية لأنظمة الذكاء الاصطناعي المعاصرة، حيث تقبلان باستمرار بيانات مقدمة من المستخدم وتعيدانها إلى سياقات النموذج عبر التوليد المعزز بالاسترجاع (RAG). إذا تُركتا دون حوكمة، يمكن أن تتسرب إلى الذاكرة معلومات شخصية قابلة للتمييز (PII)، وتُنتهك الموافقة، أو تُعكَّس لإعادة بناء النص الأصلي. الهدف من هذه المجموعة من الضوابط هو تدعيم صلابة مسارات الذاكرة وقواعد بيانات المتجهات بحيث يكون الوصول وفق مبدأ الحد الأدنى من الامتيازات، وتكون التضمينات محافظة على الخصوصية، وتنقضي صلاحية المتجهات المخزَّنة أو يمكن سحبها عند الطلب، وتبقى ذاكرة كل مستخدم بعيدة عن مطالبات وإكمالات مستخدم آخر.

---

### C8.1 ضوابط الوصول إلى الذاكرة ومؤشرات RAG

إنفاذ ضوابط وصول دقيقة على كل مجموعة من المتجهات.

 #8.1.1    المستوى: 1    الدور: D/V
 تحقق من أن قواعد التحكم في الوصول على مستوى الصف ومساحة الاسم تقيد عمليات الإدراج والحذف والاستعلام وفق المستأجر، أو المجموعة، أو وسم المستند.
 #8.1.2    المستوى: 1    الدور: D/V
 تحقق من أن مفاتيح API أو JWTs تحمل مطالبات مقيدة بالنطاق (على سبيل المثال معرفات المجموعات، أفعال الإجراء) وتُدوَّر على الأقل كل ثلاثة أشهر.
 #8.1.3    المستوى: 2    الدور: D/V
 تحقق من أن محاولات تصعيد الامتياز (على سبيل المثال، استعلامات تشابه عبر مساحات أسماء مختلفة) يتم اكتشافها وتسجيلها في SIEM خلال 5 دقائق.
 #8.1.4    المستوى: 2    الدور: D/V
 تحقق من أن سجلات تدقيق قاعدة بيانات المتجهات تسجل معرّف الجهة، العملية، معرّف المتجه/فضاء أسماء، عتبة التشابه، وعدد النتائج.
 #8.1.5    المستوى: 3    الدور: V
 تحقق من أن قرارات الوصول يتم اختبارها للكشف عن ثغرات التجاوز عندما تتم ترقية المحركات أو تتغير قواعد تقسيم الفهرسة.

---

### C8.2 تنقية التضمينات والتحقق منها

فحص مسبق للنص بحثاً عن معلومات تعريف شخصية (PII)، وإخفاء الهوية أو استخدام أسماء مستعارة قبل تحويله إلى متجهات، واختياريًا إجراء معالجة لاحقة للتضمينات لإزالة الإشارات المتبقية.

 #8.2.1    المستوى: 1    الدور: D/V
 تحقق من اكتشاف PII والبيانات الخاضعة للوائح عبر مصنفات آلية، مع إخفائها أو ترميزها إلى توكنات، أو إسقاطها قبل التضمين.
 #8.2.2    المستوى: 1    الدور: D
 تحقق من أن خطوط أنابيب التضمين ترفض أو تعزل المدخلات التي تحتوي على كود قابل للتنفيذ أو مكونات غير UTF-8 قد تفسد الفهرس.
 #8.2.3    المستوى: 2    الدور: D/V
 تحقق من تطبيق تنقيّة الخصوصية التفاضلية المحلية أو المبنية على المسافة على تمثيلات الجُمَل التي تقع مسافتها إلى أي رمز PII معروف تحت عتبة قابلة للضبط.
 #8.2.4    المستوى: 2    الدور: V
 تحقق من أن فعالية التنقية (على سبيل المثال معدل طمس PII والانجراف الدلالي) يتم التحقق منها كل ستة أشهر على الأقل مقابل مجموعات بيانات معيارية.
 #8.2.5    المستوى: 3    الدور: D/V
 تحقق من أن إعدادات التنقية خاضعة للتحكّم بالإصدارات وأن التغييرات تخضع للمراجعة من الأقران.

---

### C8.3 انتهاء صلاحية الذاكرة، الإلغاء والحذف

اللائحة العامة لحماية البيانات (GDPR) و"الحق في النسيان" وقوانين مماثلة تتطلب المحو في الوقت المناسب؛ لذا يجب أن تدعم قواعد بيانات المتجهات TTLs والحذف الدائم وتسجيلات القبور حتى لا يمكن استرداد المتجهات الملغاة أو إعادة فهرستها.

 #8.3.1    المستوى: 1    الدور: D/V
 تحقق من أن كل متجه وكل سجل بيانات وصفية يحمل TTL أو علامة احتفاظ صريحة يتم الالتزام بها من قبل مهام التنظيف الآلي.
 #8.3.2    المستوى: 1    الدور: D/V
 تحقق من أن طلبات الحذف التي يطلقها المستخدم تمحو المتجهات والبيانات الوصفية ونسخ التخزين المؤقت والفهارس المشتقة خلال 30 يوماً.
 #8.3.3    المستوى: 2    الدور: D
 تحقق من أن الحذف المنطقي يتبعه إتلاف تشفيري لكتل التخزين إذا كان العتاد يدعمه، أو بتدمير مفتاح خزنة المفاتيح.
 #8.3.4    المستوى: 3    الدور: D/V
 تحقق من استبعاد المتجهات المنتهية الصلاحية من نتائج البحث عن أقرب-جار في أقل من 500 ms بعد انتهاء صلاحيتها.

---

### C8.4 منع انعكاس التضمين وتسرب التضمين

الدفاعات الحديثة—تراكب الضوضاء، وشبكات الإسقاط، واضطراب عصبون الخصوصية، وتشفير طبقة التطبيق—يمكن أن تخفض معدلات استرجاع التوكن عند مستوى الرمز إلى أقل من 5%.

 #8.4.1    المستوى: 1    الدور: V
 تحقق من وجود نموذج تهديد رسمي يغطي هجمات الانعكاس والانتماء واستنتاج السمات، ويتم مراجعته سنوياً.
 #8.4.2    المستوى: 2    الدور: D/V
 تحقق من أن تشفير طبقة التطبيق أو التشفير القابل للبحث يحمي المتجهات من القراءات المباشرة من قبل مسؤولي البنية التحتية أو موظفي السحابة.
 #8.4.3    المستوى: 3    الدور: V
 تحقق من أن معلمات الدفاع (ε لـ DP، الضوضاء σ، رتبة الإسقاط k) توازن الخصوصية ≥ 99 % لحماية الرموز والفائدة ≤ 3 % من فقدان الدقة.
 #8.4.4    المستوى: 3    الدور: D/V
 تحقق من أن مقاييس مقاومة هجوم استرجاع النموذج هي جزء من بوابات الإصدار لتحديثات النماذج، مع تحديد ميزانيات الانحدار.

---

### C8.5 فرض النطاق على الذاكرة المخصصة للمستخدم

التسريب عبر المستأجرين لا يزال أحد أبرز مخاطر RAG: الاستعلامات التشابهية غير المُفلترة بشكل صحيح قد تكشف عن مستندات خاصة بعميل آخر.

 #8.5.1    المستوى: 1    الدور: D/V
 تحقق من أن كل استعلام استرجاع يتم فلترته لاحقاً بناءً على معرّف المستأجر/المستخدم قبل تمريره إلى موجه LLM.
 #8.5.2    المستوى: 1    الدور: D
 تحقق من أن أسماء المجموعات أو المعرفات ذات النطاق مُملَّحة لكل مستخدم أو مستأجر، بحيث لا تتصادم المتجهات عبر النطاقات.
 #8.5.3    المستوى: 2    الدور: D/V
 تحقق من أن نتائج التشابه التي تتجاوز عتبة مسافة قابلة للتكوين لكنها خارج نطاق المستدعي يتم تجاهلها وتُطلق تنبيهات أمنية.
 #8.5.4    المستوى: 2    الدور: V
 تحقق من أن اختبارات الإجهاد متعددة المستأجرين تحاكي استفسارات عدائية تحاول استرجاع وثائق خارج النطاق وتُظهر عدم وجود أي تسرب.
 #8.5.5    المستوى: 3    الدور: D/V
 تحقق من أن مفاتيح التشفير مفصولة حسب كل مستأجر، لضمان العزل التشفيري حتى إذا كان التخزين الفيزيائي مشتركا.

---

### C8.6 أمان نظام الذاكرة المتقدمة

ضوابط الأمان لهياكل ذاكرة متطورة تشمل الذاكرة الحدثية والدلالية والذاكرة العاملة، مع متطلبات عزل وتحقق محددة.

 #8.6.1    المستوى: 1    الدور: D/V
 تحقق من أن أنواع الذاكرة المختلفة (الذاكرة الحدثية، الذاكرة الدلالية، والذاكرة العاملة) تمتلك سياقات أمنيّة معزولة، وضوابط وصول قائمة على الأدوار، ومفاتيح تشفير منفصلة، وأنماط وصول موثقة لكل نوع من أنواع الذاكرة.
 #8.6.2    المستوى: 2    الدور: D/V
 تحقق من أن عمليات ترسيخ الذاكرة تتضمن التحقق الأمني لمنع حقن الذكريات الخبيثة من خلال تنقية المحتوى، والتحقق من المصدر، وفحص التكامل قبل التخزين.
 #8.6.3    المستوى: 2    الدور: D/V
 تحقق من صحة وتنقية استعلامات استرجاع الذاكرة لمنع استخراج معلومات غير مصرح بها من خلال تحليل أنماط الاستعلام، وتطبيق ضوابط الوصول، وتصفية النتائج.
 #8.6.4    المستوى: 3    الدور: D/V
 تحقق من أن آليات محو الذاكرة تزيل المعلومات الحساسة بشكل آمن مع ضمانات المحو التشفيري باستخدام حذف المفتاح، والكتابة عبر عدة تمريرات، أو الحذف الآمن القائم على الأجهزة مع شهادات تحقق.
 #8.6.5    المستوى: 3    الدور: D/V
 تحقق من أن تكامل ذاكرة النظام يُراقب باستمرار لأي تعديلات غير مصرح بها أو تلف من خلال قيم التحقق، سجلات التدقيق، والتنبيهات الآلية عند تغيّر محتوى الذاكرة خارج نطاق التشغيل العادي.

---

### المراجع

Vector database security: Pinecone – IronCore Labs
Securing the Backbone of AI: Safeguarding Vector Databases and Embeddings – Privacera
Enhancing Data Security with RBAC of Qdrant Vector Database – AI Advances
Mitigating Privacy Risks in LLM Embeddings from Embedding Inversion – arXiv
DPPN: Detecting and Perturbing Privacy-Sensitive Neurons – OpenReview
Art. 17 GDPR – Right to Erasure
Sensitive Data in Text Embeddings Is Recoverable – Tonic.ai
PII Identification and Removal – NVIDIA NeMo Docs
De-identifying Sensitive Data – Google Cloud DLP
Remove PII from Conversations Using Sensitive Information Filters – AWS Bedrock Guardrails
Think Your RAG Is Secure? Think Again – Medium
Design a Secure Multitenant RAG Inferencing Solution – Microsoft Learn
Best Practices for Multi-Tenancy RAG with Milvus – Milvus Blog

## 9 الأمن المتعلق بالتنسيق المستقل وتصرفات الوكيل

### هدف الرقابة

تأكد من أن أنظمة الذكاء الاصطناعي المستقلة أو متعددة الوكلاء يمكنها تنفيذ الإجراءات فقط إذا كانت مقصودة صراحة وموثقة وقابلة للمراجعة وتحت حدود التكلفة والمخاطر المحدودة. هذا يحمي من تهديدات مثل اختراق النظام المستقل، سوء استخدام الأدوات، كشف حلقة الوكلاء، اختطاف الاتصالات، انتحال الهوية، التلاعب بسرب الوكلاء، والتلاعب بالنوايا.

---

### 9.1 وكيل-تخطيط المهام وميزانيات الاستدعاء الذاتي

إبطاء التخطيط التكراري وفرض نقاط مراجعة بشرية للإجراءات ذات الامتياز.

 #9.1.1    المستوى: 1    الدور: D/V
 تحقق من أن أقصى عمق للتكرار، وعرض البحث، والزمن الحقيقي، والتوكنات، والتكلفة المالية لكل تنفيذ للوكيل، مهيأة مركزيًا وتخضع لإدارة الإصدارات.
 #9.1.2    المستوى: 1    الدور: D/V
 تحقق من أن الإجراءات ذات الامتياز أو غير القابلة للإلغاء تتطلب موافقة بشرية صريحة عبر قناة قابلة للتدقيق قبل التنفيذ، مثل الالتزامات البرمجية والتحويلات المالية.
 #9.1.3    المستوى: 2    الدور: D
 تحقق من أن مراقبات الموارد في الوقت الفعلي تفعّل انقطاع قاطع الدائرة عند تجاوز أي عتبة للميزانية، مما يوقف توسع المهام اللاحقة.
 #9.1.4    المستوى: 2    الدور: D/V
 تحقق من تسجيل أحداث قاطع الدائرة مع معرّف الوكيل، والشرط المحفّز، وحالة الخطة الملتقطة للمراجعة الجنائية.
 #9.1.5    المستوى: 3    الدور: V
 تحقق من أن اختبارات الأمان تغطي سيناريوهات استنزاف الميزانية وخطة خارج السيطرة، مع تأكيد الإيقاف الآمن دون فقدان البيانات.
 #9.1.6    المستوى: 3    الدور: D
 تحقق من أن سياسات الميزانية مُعبر عنها كسياسة-as-code ومطبقة في CI/CD لمنع انحراف التكوين.

---

### 9.2 عزل الإضافة البرمجية للأداة في صندوق الرمل

عزل تفاعلات الأدوات لمنع الوصول غير المصرح به إلى النظام أو تنفيذ الشفرة.

 #9.2.1    المستوى: 1    الدور: D/V
 تحقق من أن كل أداة أو إضافة تعمل داخل sandbox على مستوى OS أو حاوية أو WASM مع سياسات أقل امتيازاً لنظام الملفات والشبكة واستدعاءات النظام.
 #9.2.2    المستوى: 1    الدور: D/V
 تحقق من أن حصص موارد صندوق الرمل (CPU، الذاكرة، القرص، حركة مرور الشبكة الصادرة) ومهل انتهاء التنفيذ مطبقة ومسجلة.
 #9.2.3    المستوى: 2    الدور: D/V
 تحقق من أن ثنائيات الأدوات أو أوصافها الرقمية موقَّعة توقيعاً رقمياً؛ يتم التحقق من التوقيعات قبل التحميل.
 #9.2.4    المستوى: 2    الدور: V
 تحقق من أن تدفقات بيانات القياس عن بُعد من صندوق الرمل إلى SIEM؛ شذوذات (على سبيل المثال، محاولات اتصالات صادرة) تثير الإنذارات.
 #9.2.5    المستوى: 3    الدور: V
 تحقق من أن الإضافات عالية المخاطر تخضع لمراجعة أمنية واختبار اختراق قبل النشر في بيئة الإنتاج.
 #9.2.6    المستوى: 3    الدور: D/V
 تحقق من أن محاولات الهروب من صندوق الرمل تُحجب تلقائياً، وأن الإضافة المخالفة مُعزَلة في انتظار التحقيق.

---

### 9.3 حلقة مستقلة وحدود التكلفة

كشف وإيقاف التكرار غير المسيطر عليه بين الوكلاء وانفجارات التكاليف.

 #9.3.1    المستوى: 1    الدور: D/V
 تحقق من أن النداءات بين الوكلاء تتضمن حد قفز أو TTL يقوم وقت التشغيل بخفضه وتطبيقه.
 #9.3.2    المستوى: 2    الدور: D
 تحقق من أن الوكلاء يحافظون على معرف فريد لمخطط الاستدعاء لاكتشاف الاستدعاء الذاتي أو أنماط دورية.
 #9.3.3    المستوى: 2    الدور: D/V
 تحقق من أن وحدات الحوسبة المتراكمة وعدادات الإنفاق تُتبع لكل سلسلة من الطلبات؛ فـ تجاوز الحد يؤدي إلى إيقاف السلسلة.
 #9.3.4    المستوى: 3    الدور: V
 تحقق من أن التحليل الرسمي أو فحص النماذج يُظهر غياب التكرار غير المحدود في بروتوكولات الوكلاء.
 #9.3.5    المستوى: 3    الدور: D
 تحقق من أن أحداث إيقاف الحلقة تولّد تنبيهات وتغذي مقاييس التحسين المستمر.

---

### 9.4 الحماية من إساءة الاستخدام على مستوى البروتوكول

قنوات اتصال آمنة بين الوكلاء والأنظمة الخارجية لمنع الاختطاف أو التلاعب.

 #9.4.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع رسائل الوكيل-إلى-الأداة ورسائل الوكيل-إلى-الوكيل مُوثَّقة (مثلاً TLS المتبادل أو JWT) ومشفَّرة من الطرف إلى الطرف.
 #9.4.2    المستوى: 1    الدور: D
 تحقق من صحة المخططات بشكل صارم، وتُرفض الحقول غير المعروفة والرسائل ذات البنية الخاطئة.
 #9.4.3    المستوى: 2    الدور: D/V
 تحقق من أن فحوصات التكامل (MACs أو التوقيعات الرقمية) تغطي الحمولة الكلية للرسالة بما في ذلك معلمات الأداة.
 #9.4.4    المستوى: 2    الدور: D
 تحقق من تطبيق حماية ضد إعادة الإرسال في طبقة البروتوكول (أرقام عشوائية أحادية الاستخدام أو نوافذ الطابع الزمني).
 #9.4.5    المستوى: 3    الدور: V
 تحقق من أن تنفيذات البروتوكولات تخضع للاختبار العشوائي والتحليل الثابت للكشف عن ثغرات الحقن أو فك التسلسل.

---

### 9.5 هوية الوكيل وإثبات العبث

تأكد من أن الإجراءات منسوبة إلى فاعليها وأن التغييرات قابلة للكشف.

 #9.5.1    المستوى: 1    الدور: D/V
 تحقق من أن كل مثيل وكيل يمتلك هوية تشفيرية فريدة (زوج مفاتيح أو اعتماد عتادي).
 #9.5.2    المستوى: 2    الدور: D/V
 تحقق من أن جميع إجراءات الوكلاء موقّعة ومؤرّخة بطابع زمني؛ وتتضمن السجلات التوقيعات لضمان عدم الإنكار.
 #9.5.3    المستوى: 2    الدور: V
 تحقق من أن سجلات مقاومة العبث مُخزَّنة على وسيط قابل للإضافة فقط أو وسيط قابل للكتابة مرة واحدة.
 #9.5.4    المستوى: 3    الدور: D
 تحقق من أن مفاتيح الهوية تدور وفق جدول زمني محدد وعلى أساس مؤشرات الاختراق.
 #9.5.5    المستوى: 3    الدور: D/V
 تحقق من أن محاولات انتحال الهوية أو تصادم المفاتيح تؤدي إلى عزل فوري للوكيل المتأثر.

---

### 9.6 تقليل مخاطر سرب الوكلاء المتعددين

تقليل مخاطر السلوك الجماعي من خلال العزل والنمذجة الرسمية للسلامة.

 #9.6.1    المستوى: 1    الدور: D/V
 تحقق من أن الوكلاء الذين يعملون في مجالات أمان مختلفة ينفذون في بيئات صندوق الرمل المعزولة أثناء التشغيل أو في أقسام الشبكة.
 #9.6.2    المستوى: 3    الدور: V
 تحقق من أن سلوكيات القطيع مُنمذجة ومتحققة رسميًا للحيوية والسلامة قبل النشر.
 #9.6.3    المستوى: 3    الدور: D
 تحقق من أن مراقبات وقت التشغيل تكشف عن أنماط غير آمنة ناشئة (مثلاً التذبذبات، انسدادات التزامنية) وتباشر باتخاذ إجراء تصحيحي.

---

### 9.7 المصادقة للمستخدم والأداة / التفويض

طبق ضوابط وصول صارمة على كل إجراء يتم تشغيله بواسطة الوكيل.

 #9.7.1    المستوى: 1    الدور: D/V
 تحقق من أن الوكلاء يُصدّقون كجهات أصلية من المستوى الأول تجاه الأنظمة التابعة، ولا يعيدون استخدام بيانات اعتماد المستخدم النهائي.
 #9.7.2    المستوى: 2    الدور: D
 تحقق من أن سياسات التفويض الدقيقة تقيد الأدوات التي يجوز للوكيل استدعاؤها والمعلمات التي يجوز له تزويدها.
 #9.7.3    المستوى: 2    الدور: V
 تحقق من أن فحص الامتيازات يُعاد تقييمه في كل استدعاء (التفويض المستمر)، وليس فقط عند بدء الجلسة.
 #9.7.4    المستوى: 3    الدور: D
 تحقق من أن صلاحية الامتيازات المفوَّضة تنتهي تلقائيًا وتتطلب إعادة الموافقة بعد انتهاء المهلة أو عند تغيير النطاق.

---

### 9.8 أمن-التواصل بين الوكلاء

تشفير وحماية سلامة جميع رسائل الوكلاء المتبادلة لمنع التنصت والتلاعب.

 #9.8.1    المستوى: 1    الدور: D/V
 المصادقة المتبادلة والتشفير ذو خصوصية أمامية مثالية (مثلاً TLS 1.3) أمورٌ إِلزامية لقنوات الوكلاء.
 #9.8.2    المستوى: 1    الدور: D
 تحقق من تكامل الرسالة ومصدرها قبل المعالجة؛ في حال الفشل، يتم إصدار تنبيهات وإسقاط الرسالة.
 #9.8.3    المستوى: 2    الدور: D/V
 تحقق من أن بيانات تعريف الاتصالات (طوابع زمنية، أرقام تسلسلية) مُسجَّلة لدعم إعادة البناء الجنائي الرقمي.
 #9.8.4    المستوى: 3    الدور: V
 تحقق من أن التحقق الرسمي أو التحقق من النماذج يؤكد أن آلات حالة البروتوكول لا يمكن دفعها إلى حالات غير آمنة.

---

### 9.9 التحقق من النية وإنفاذ القيود

تحقق من توافق إجراءات الوكيل مع نية المستخدم المعلنة والقيود النظامية.

 #9.9.1    المستوى: 1    الدور: D
 تحقق من أن محللات القيود قبل التنفيذ تفحص الإجراءات المقترحة ضد قواعد السلامة والسياسة المبرمجة مسبقاً.
 #9.9.2    المستوى: 2    الدور: D/V
 تحقق من أن الإجراءات ذات التأثير العالي (مالية، تدميرية، حساسة للخصوصية) تتطلب تأكيد نية صريحة من المستخدم المبادر.
 #9.9.3    المستوى: 2    الدور: V
 تحقق من أن فحوص ما بعد الشرط تتحقق من أن الإجراءات المكتملة قد حققت التأثيرات المقصودة دون آثار جانبية؛ الاختلافات تؤدي إلى التراجع.
 #9.9.4    المستوى: 3    الدور: V
 تحقق من أن الأساليب الرسمية (على سبيل المثال فحص النماذج، إثبات النظريات) أو الاختبارات القائمة على الخصائص تثبت أن خطط الوكلاء تفي بجميع القيود المعلنة.
 #9.9.5    المستوى: 3    الدور: D
 تحقق من أن حالات عدم التطابق في النية أو انتهاك القيود تغذي دورات التحسين المستمر وتبادل معلومات استخبارات التهديد.

---

### 9.10 استراتيجية استدلال الوكيل والأمن

الاختيار والتنفيذ الآمن لاستراتيجيات التفكير المختلفة بما في ذلك ReAct و Chain-of-Thought و Tree-of-Thoughts.

 #9.10.1    المستوى: 1    الدور: D/V
 تحقق من أن اختيار استراتيجية الاستدلال يستخدم معايير حتمية (تعقيد الإدخال، نوع المهمة، سياق الأمان)، وأن الإدخالات المتطابقة تُنتج اختيارات استراتيجية متطابقة ضمن نفس سياق الأمان.
 #9.10.2    المستوى: 1    الدور: D/V
 تحقق من أن كل استراتيجية استدلال (ReAct، Chain-of-Thought، Tree-of-Thoughts) لديها تحقق صحة الإدخال المخصص، وتنقية المخرجات المخصصة، وحدود زمن التنفيذ المخصصة تتوافق مع نهجها المعرفي.
 #9.10.3    المستوى: 2    الدور: D/V
 تحقق من أن انتقالات استراتيجية الاستدلال مُسجَّلة مع سياق كامل بما في ذلك خصائص الإدخال وقيم معايير الاختيار وبيانات التنفيذ من أجل إعادة بناء سجل التدقيق.
 #9.10.4    المستوى: 2    الدور: D/V
 تحقق من أن Tree-of-Thoughts يتضمن آليات تقليم الفروع التي تؤدي إلى إنهاء الاستكشاف عند اكتشاف انتهاكات السياسات أو قيود الموارد أو حدود السلامة.
 #9.10.5    المستوى: 2    الدور: D/V
 تحقق من أن دورات ReAct (Reason-Act-Observe) تتضمن نقاط فحص عند كل مرحلة: التحقق من خطوة الاستدلال، تصريح الإجراء، وتنقية الملاحظات قبل المتابعة.
 #9.10.6    المستوى: 3    الدور: D/V
 تحقق من أن مقاييس أداء استراتيجية الاستدلال (زمن التنفيذ، استهلاك الموارد، جودة الناتج) تُرصد تلقائيًا مع وجود تنبيهات آلية عند انحراف المقاييس عن العتبات المعتمدة.
 #9.10.7    المستوى: 3    الدور: D/V
 تحقق من أن أساليب الاستدلال الهجينة التي تدمج عدة استراتيجيات تحافظ على التحقق من صحة المدخلات وقيود الإخراج لجميع الاستراتيجيات المكوّنة دون تجاوز أي ضوابط أمان.
 #9.10.8    المستوى: 3    الدور: D/V
 تحقق من أن اختبار أمان استراتيجيات الاستدلال يتضمن fuzzing باستخدام مدخلات مشوّهة، وأوامر عدائية مصممة لإجبار تحويل الاستراتيجية، واختبار شروط الحد لكل نهج إدراكي.

---

### 9.11 إدارة حالة دورة حياة الوكيل والأمن

تهيئة وكيل آمن، وانتقالات الحالة، والإنهاء مع سجلات تدقيق تشفيرية وإجراءات استرداد محددة.

 #9.11.1    المستوى: 1    الدور: D/V
 تحقق من أن تهيئة الوكيل تشمل إرساء الهوية التشفيرية باستخدام اعتمادات مدعومة من العتاد وسجلات تدقيق بدء التشغيل غير القابلة للتعديل التي تحتوي على معرّف الوكيل، والطابع الزمني، وهاش التكوين، ومعلمات التهيئة.
 #9.11.2    المستوى: 2    الدور: D/V
 تحقق من أن انتقالات حالة الوكيل موقّعة بتوقيع رقمي، ومؤرخة زمنياً، ومسجَّلة مع السياق الكامل بما في ذلك الأحداث المحفِّزة، وهاش الحالة السابقة، وهاش الحالة الجديدة، والتحققات الأمنية التي تم إجراؤها.
 #9.11.3    المستوى: 2    الدور: D/V
 تحقق من أن إجراءات إيقاف تشغيل الوكيل تتضمن محوًا آمنًا للذاكرة باستخدام الإمحاء التشفري أو الكتابة عبر مرورين متعددين، وإلغاء بيانات الاعتماد مع إشعار سلطة الشهادات، وتوليد شهادات إنهاء قابلة للكشف عن العبث
 #9.11.4    المستوى: 3    الدور: D/V
 تحقق من أن آليات استرداد الوكلاء تتحقق من تكامل الحالة باستخدام تجزئات تشفيرية (SHA-256 كحد أدنى) والعودة إلى حالات سليمة معروفة عند اكتشاف تلف مع إشعارات آلية ومتطلبات موافقة يدوية.
 #9.11.5    المستوى: 3    الدور: D/V
 تحقق من أن آليات حفظ حالة الوكيل تقوم بتشفير البيانات الحساسة للحالة باستخدام مفاتيح AES-256 خاصة بكل وكيل وتنفّذ تدوير مفاتيح آمن وفق جداول قابلة للتكوين (الحد الأقصى 90 يومًا) مع نشر بدون توقف.

---

### 9.12 إطار أمان لتكامل الأدوات

ضوابط أمان لتحميل الأدوات بشكل ديناميكي، وتنفيذها، والتحقق من النتائج مع تقييم مخاطر محدد وعمليات موافقة.

 #9.12.1    المستوى: 1    الدور: D/V
 تحقق من أن موصفات الأدوات تتضمن بيانات أمان تحدد الصلاحيات المطلوبة (قراءة/كتابة/تنفيذ)، ومستويات المخاطر (منخفض/متوسط/مرتفع)، وحدود الموارد (CPU، الذاكرة، الشبكة)، ومتطلبات التحقق الموثقة في ملفات تعريف الأدوات.
 #9.12.2    المستوى: 1    الدور: D/V
 تحقق من أن نتائج تشغيل الأداة مطابقة للمخططات المتوقعة (مخطط JSON، مخطط XML) وسياسات الأمان (تنقية الإخراج، تصنيف البيانات) قبل الدمج مع حدود المهلة الزمنية وإجراءات معالجة الأخطاء.
 #9.12.3    المستوى: 2    الدور: D/V
 تحقق من أن سجلات التفاعل مع الأدوات تتضمن سياقًا أمنيًا تفصيليًا بما في ذلك استخدام الامتيازات وأنماط الوصول إلى البيانات وزمن التنفيذ واستهلاك الموارد ورموز الإرجاع مع تسجيل منسّق لتكامل SIEM.
 #9.12.4    المستوى: 2    الدور: D/V
 تحقق من أن آليات تحميل الأدوات الديناميكية تتحقق من التواقيع الرقمية باستخدام بنية المفاتيح العامة (PKI)، وتطبق بروتوكولات تحميل آمنة مع عزل صندوق الرمل والتحقق من الأذونات قبل التنفيذ.
 #9.12.5    المستوى: 3    الدور: D/V
 تحقق من أن تقييمات أمان الأدوات تُشغَّل تلقائيًا للإصدارات الجديدة مع بوابات الموافقة الإلزامية التي تشمل التحليل الثابت، الاختبار الديناميكي، ومراجعة فريق الأمن مع معايير الموافقة الموثقة ومتطلبات SLA

---

#### المراجع

MITRE ATLAS tactics ML09
Circuit-breaker research for AI agents — Zou et al., 2024
Trend Micro analysis of sandbox escapes in AI agents — Park, 2025
Auth0 guidance on human-in-the-loop authorization for agents — Martinez, 2025
Medium deep-dive on MCP & A2A protocol hijacking — ForAISec, 2025
Rapid7 fundamentals on spoofing attack prevention — 2024
Imperial College verification of swarm systems — Lomuscio et al.
NIST AI Risk Management Framework 1.0, 2023
WIRED security briefing on encryption best practices, 2024
OWASP Top 10 for LLM Applications, 2025
Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS
[How Is LLM Reasoning Distracted by Irrelevant Context?
An Analysis Using a Controlled Benchmark](https://www.arxiv.org/pdf/2505.18761)
Large Language Model Sentinel: LLM Agent for Adversarial Purification
Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents

## 10 المتانة ضد الهجمات العدائية والدفاع عن الخصوصية

### هدف الرقابة

تأكد من أن نماذج الذكاء الاصطناعي تظل موثوقة مع الحفاظ على الخصوصية ومقاومة لسوء الاستخدام عند مواجهة هجمات التهرب والاستدلال والاستخراج والتسميم.

---

### 10.1 محاذاة النموذج والسلامة

احذر من المخرجات الضارة أو التي تخالف السياسات.

 #10.1.1    المستوى: 1    الدور: D/V
 تحقق من أن مجموعة اختبارات المحاذاة (موجهات فريق الاختبار الأحمر، استقصاءات فك القيود، المحتوى المحظور) مدارة بنظام التحكم بالإصدارات وتُشغّل مع كل إصدار للنموذج.
 #10.1.2    المستوى: 1    الدور: D
 تحقق من تطبيق قيود الرفض وحواجز الإكمال الآمن.
 #10.1.3    المستوى: 2    الدور: D/V
 تحقق من أن مُقيِّم آلي يقيس معدل المحتوى الضار ويُعلِم بالتراجعات التي تتجاوز عتبة محددة.
 #10.1.4    المستوى: 2    الدور: D
 تحقق من أن تدريب مضاد لكسر الحماية موثق وقابل لإعادة الإنتاج.
 #10.1.5    المستوى: 3    الدور: V
 تحقق من أن إثباتات الامتثال الرسمي للسياسات أو المراقبة المعتمدة تغطي المجالات الحرجة.

---

### 10.2 تحصين-الأمثلة العدائية

زيادة المرونة أمام المدخلات المعدلة بشكل عدائي. التدريب العدائي القوي وتقييم المعايير المرجعية هما أفضل الممارسات في الوقت الحالي.

 #10.2.1    المستوى: 1    الدور: D
 تحقق من أن مستودعات المشاريع تتضمن إعدادات التدريب ضد الهجمات مع بذور قابلة لإعادة الإنتاج.
 #10.2.2    المستوى: 2    الدور: D/V
 تحقق من أن كشف الأمثلة العدائية يثير تنبيهات الحظر في خطوط الإنتاج.
 #10.2.4    المستوى: 3    الدور: V
 تحقق من أن براهين المتانة المعتمدة أو شهادات الحدود النطاقية تغطي على الأقل أهم الفئات الحرجة.
 #10.2.5    المستوى: 3    الدور: V
 تحقق من أن اختبارات الانحدار تستخدم الهجمات التكيفية للتأكد من عدم وجود انخفاض قابل للقياس في المتانة.

---

### 10.3 التخفيف من استنتاج العضوية

تقليل القدرة على تحديد ما إذا كان سجل معين موجوداً في بيانات التدريب. تظل الخصوصية التفاضلية وإخفاء درجات الثقة من أكثر وسائل الدفاع فاعلية المعروفة.

 #10.3.1    المستوى: 1    الدور: D
 تحقق من أن تنظيم الإنتروبيا لكل استعلام أو ضبط درجة الحرارة يقلل من التنبؤات ذات الثقة المفرطة.
 #10.3.2    المستوى: 2    الدور: D
 تحقق من أن التدريب يستخدم تحسيناً ذا خصوصية تفاضلية مقيدة بـ ε للبيانات الحساسة.
 #10.3.3    المستوى: 2    الدور: V
 تحقق من أن محاكاة الهجوم (النموذج الظلي أو الصندوق الأسود) تُظهر AUC الهجوم ≤ 0.60 على البيانات المحجوزة.

---

### 10.4 مقاومة استرجاع النموذج

منع إعادة بناء السمات الخاصة. تشير الاستطلاعات الأخيرة إلى اقتطاع الإخراج وضمانات الخصوصية التفاضلية (DP) كإجراءات دفاعية عملية.

 #10.4.1    المستوى: 1    الدور: D
 تحقق من أن السمات الحساسة لا تخرج مباشرة مطلقاً؛ عند الحاجة، استخدم التقطيع إلى فئات أو التحويلات أحادية الاتجاه.
 #10.4.2    المستوى: 1    الدور: D/V
 تحقق من أن حدود معدل الاستعلامات تُبطئ الاستفسارات التكيفية المتكررة من نفس الجهة المفوَّضة.
 #10.4.3    المستوى: 2    الدور: D
 تحقق من أن النموذج مُدرَّب باستخدام ضوضاء تحافظ على الخصوصية.

---

### 10.5 الدفاع ضد استخراج النموذج

اكتشاف ومنع الاستنساخ غير المصرح به. يوصى بإضافة علامة مائية وتحليل نمط الاستعلام.

 #10.5.1    المستوى: 1    الدور: D
 تحقق من أن بوابات الاستدلال تفرض حدود المعدل العالمي وحدود المعدل لكل مفتاح API، مضبوطة وفق عتبة حفظ ذاكرة النموذج.
 #10.5.2    المستوى: 2    الدور: D/V
 تحقق من أن إحصاءات إنتروبيا-الاستعلام وتعددية-المدخلات تغذي كاشف استخراج تلقائي.
 #10.5.3    المستوى: 2    الدور: V
 تحقق من أن العلامات المائية الهشة أو الاحتمالية يمكن إثباتها بـ p < 0.01 في ≤ 1 000 استعلام ضد استنساخ مشتبه به
 #10.5.4    المستوى: 3    الدور: D
 تحقق من أن مفاتيح العلامة المائية ومجموعات المحفزات مخزنة في وحدة أمان الأجهزة ويتم تدويرها سنويًا.
 #10.5.5    المستوى: 3    الدور: V
 تحقق من أن أحداث التنبيه للاستخراج تتضمن الاستعلامات المسيئة وتتكامل مع خطط استجابة الحوادث.

---

### 10.6 كشف البيانات الملوثة أثناء الاستدلال

تحديد وتحييد المدخلات المحتوية على باب خلفي أو المدخلات الملوثة.

 #10.6.1    المستوى: 1    الدور: D
 تحقق من أن المدخلات تمر عبر كاشف الشذوذ (مثلاً STRIP، وتقييم الاتساق) قبل استدلال النموذج.
 #10.6.2    المستوى: 1    الدور: V
 تحقق من أن عتبات الكشف تم ضبطها على مجموعات التحقق النظيفة/المسمّمة لتحقيق أقل من 5% من الإيجابيات الكاذبة.
 #10.6.3    المستوى: 2    الدور: D
 تحقق من أن المدخلات المصنَّفة كمسمَّمة تؤدي إلى تفعيل الحظر الناعم وتدفقات العمل للمراجعة البشرية.
 #10.6.4    المستوى: 2    الدور: V
 تحقق من أن الكاشفات يتم إخضاعها لاختبارات الإجهاد باستخدام هجمات باب خلفي تكيفية بدون محفز.
 #10.6.5    المستوى: 3    الدور: D
 تحقق من أن مقاييس فعالية الكشف مُسجَّلة وتُعاد تقييمها بشكل دوري باستخدام معلومات استخبارية حديثة عن التهديدات.

---

### 10.7 التكيف الديناميكي لسياسة الأمن

تحديثات سياسة الأمن في الوقت الفعلي استنادًا إلى استخبارات التهديد والتحليل السلوكي.

 #10.7.1    المستوى: 1    الدور: D/V
 تحقق من أن سياسات الأمان يمكن تحديثها ديناميكياً دون إعادة تشغيل الوكيل مع الحفاظ على تكامل إصدار السياسة.
 #10.7.2    المستوى: 2    الدور: D/V
 تحقق من أن تحديثات السياسة موقَّعة رقمياً من قبل موظفين أمنيين مخولين ومُدَقَّقة قبل التطبيق.
 #10.7.3    المستوى: 2    الدور: D/V
 تحقق من أن تغييرات السياسة الديناميكية تُسجل مع سجلات تدقيق كاملة تشمل المبررات وسلاسل الموافقات وإجراءات التراجع.
 #10.7.4    المستوى: 3    الدور: D/V
 تحقق من أن آليات الأمن التكيفية تضبط حساسية اكتشاف التهديدات استنادًا إلى سياق المخاطر وأنماط السلوك.
 #10.7.5    المستوى: 3    الدور: D/V
 تحقق من أن قرارات تكييف السياسة قابلة للتفسير وتتضمن مسارات الأدلة لمراجعة فريق الأمن.

---

### 10.8 تحليل أمني قائم على الانعكاس

التحقق الأمني من خلال تفكّر الوكيل في ذاته والتحليل الميتا-معرفي.

 #10.8.1    المستوى: 1    الدور: D/V
 تحقق من أن آليات انعكاس الوكيل تتضمن تقييمًا ذاتيًا يركّز على الأمن لقراراته وإجراءاته.
 #10.8.2    المستوى: 2    الدور: D/V
 تحقق من صحة مخرجات الانعكاس لضمان عدم التلاعب بآليات التقييم الذاتي من خلال المدخلات العدائية.
 #10.8.3    المستوى: 2    الدور: D/V
 تحقق من أن تحليل أمان ميتا-معرفي يحدد التحيز المحتمل أو التلاعب أو التعرض للاختراق في عمليات الاستدلال لدى الوكيل.
 #10.8.4    المستوى: 3    الدور: D/V
 تحقق من أن التحذيرات الأمنية المستندة إلى الانعكاس تُؤدي إلى تفعيل مراقبة مُعزَّزة وتدفقات عمل تدخل بشري محتمل.
 #10.8.5    المستوى: 3    الدور: D/V
 تحقق من أن التعلم المستمر من الانعكاسات الأمنية يحسّن اكتشاف التهديدات دون الإضرار بالوظائف المشروعة.

---

### 10.9 أمان التطور والتحسين الذاتي

ضوابط الأمان لأنظمة الوكلاء القادرة على التعديل الذاتي والتطور.

 #10.9.1    المستوى: 1    الدور: D/V
 تحقق من أن قدرات التعديل الذاتي مقصورة على مناطق آمنة محددة مع حدود التحقق الرسمي.
 #10.9.2    المستوى: 2    الدور: D/V
 تحقق من أن مقترحات التطوير تخضع لتقييم أثر الأمن قبل التنفيذ.
 #10.9.3    المستوى: 2    الدور: D/V
 تحقق من أن آليات التحسين الذاتي تتضمن قدرات التراجع مع التحقق من التكامل.
 #10.9.4    المستوى: 3    الدور: D/V
 تحقق من أن أمان التعلم الميتا يمنع التلاعب العدائي في خوارزميات التحسين.
 #10.9.5    المستوى: 3    الدور: D/V
 تحقق من أن التحسن الذاتي التكراري محدود بقيود السلامة الشكلية مع براهين رياضية على التقارب.

---

#### المراجع

MITRE ATLAS adversary tactics for ML
NIST AI Risk Management Framework 1.0, 2023
OWASP Top 10 for LLM Applications, 2025
Adversarial Training: A Survey — Zhao et al., 2024
RobustBench adversarial-robustness benchmark
Membership-Inference & Model-Inversion Risk Survey, 2025
PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023
Model-Inversion Attacks & Defenses Survey — AI Review, 2025
Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024
Fragile Model Watermarking Survey — 2025
Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025
BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024

## 11 حماية الخصوصية وإدارة البيانات الشخصية

### هدف الرقابة

احرص على ضمانات الخصوصية الصارمة عبر دورة حياة الذكاء الاصطناعي الكاملة—جمع البيانات والتدريب والاستدلال والاستجابة للحوادث—بحيث تُعالج البيانات الشخصية فقط بموافقة واضحة، وبالحد الأدنى من النطاق اللازم، وبالمحو القابل لإثباته، وبضمانات خصوصية رسمية.

---

### 11.1 إخفاء الهوية وتقليل البيانات الشخصية

 #11.1.1    المستوى: 1    الدور: D/V
 تحقق من إزالة المعرفات المباشرة والمعرفات شبه القابلة للتعرّف، وتطبيق الهاش عليها.
 #11.1.2    المستوى: 2    الدور: D/V
 تحقق من أن التدقيقات الآلية تقيس k-anonymity و l-diversity وتنبه عندما تنخفض العتبات عن السياسة.
 #11.1.3    المستوى: 2    الدور: V
 تحقق من أن تقارير أهمية الميزات في النموذج تثبت عدم وجود تسرب معرف يتجاوز ε = 0.01 من المعلومات المتبادلة.
 #11.1.4    المستوى: 3    الدور: V
 تحقق من أن البرهانات الرسمية أو شهادة البيانات الاصطناعية تُظهر أن خطر إعادة التعريف ≤ 0.05 حتى في ظل هجمات الربط.

---

### 11.2 حق النسيان وإنفاذ الحذف

 #11.2.1    المستوى: 1    الدور: D/V
 تحقق من أن طلبات حذف بيانات صاحب البيانات تنتشر إلى مجموعات البيانات الخام، ونقاط حفظ النموذج، والتضمينات، والسجلات، والنسخ الاحتياطية ضمن اتفاقيات مستوى الخدمة التي تقل عن 30 يومًا.
 #11.2.2    المستوى: 2    الدور: D
 تحقق من أن إجراءات "إلغاء تعلم الآلة" تقوم بإعادة تدريبها فعلياً أو تقريب الإزالة باستخدام خوارزميات إلغاء تعلم معتمدة.
 #11.2.3    المستوى: 2    الدور: V
 تحقق من أن تقييم النموذج الظلي يثبت أن السجلات المنسية تؤثر على أقل من 1% من المخرجات بعد إلغاء التعلم.
 #11.2.4    المستوى: 3    الدور: V
 التحقق من أن أحداث الحذف مسجلة بشكل غير قابل للتغيير وقابلة للتدقيق من قبل الجهات التنظيمية.

---

### 11.3 تفاضلية-خصوصية إجراءات حماية

 #11.3.1    المستوى: 2    الدور: D/V
 تحقق من أن لوحات معلومات محاسبة فقدان الخصوصية تُصدر تنبيهات عندما يتجاوز ε التراكمي عتبات السياسة.
 #11.3.2    المستوى: 2    الدور: V
 تحقق من أن تقدير ε̂ من خلال التدقيقات الخصوصية بنظام صندوق أسود يقع ضمن 10% من القيمة المعلنة.
 #11.3.3    المستوى: 3    الدور: V
 تحقق من أن الإثباتات الشكلية تغطي جميع التعديلات الدقيقة بعد التدريب والتضمينات.

---

### 11.4 تقييد الغرض وحماية من توسع النطاق

 #11.4.1    المستوى: 1    الدور: D
 تحقق من أن كل مجموعة بيانات وكل نقطة حفظ للنموذج تحمل وسم غرض قابل للقراءة آلياً ومتوافقة مع الموافقة الأصلية.
 #11.4.2    المستوى: 1    الدور: D/V
 تحقق من أن مراقبات وقت التشغيل تكشف عن الاستفسارات غير المتوافقة مع الغرض المعلن وتولّد رفضاً ناعماً.
 #11.4.3    المستوى: 3    الدور: D
 تحقق من أن بوابات السياسة-كود تمنع إعادة نشر النماذج إلى مجالات جديدة دون مراجعة تقييم أثر حماية البيانات (DPIA).
 #11.4.4    المستوى: 3    الدور: V
 تحقق من أن إثباتات التتبع الرسمية تبين أن كل دورة حياة البيانات الشخصية تظل ضمن نطاق الموافقة الممنوح.

---

### 11.5 إدارة الموافقات & التتبع على الأساس-القانوني

 #11.5.1    المستوى: 1    الدور: D/V
 تحقق من أن منصة إدارة الموافقات (CMP) تسجل حالة الاشتراك والغرض وفترة الاحتفاظ لكل موضوع بيانات.
 #11.5.2    المستوى: 2    الدور: D
 تحقق من أن واجهات برمجة التطبيقات تكشف عن رموز الموافقة؛ يجب على النماذج التحقق من نطاق الرمز قبل الاستدلال.
 #11.5.3    المستوى: 2    الدور: D/V
 تحقق من أن الموافقة المرفوضة أو المسحوبة تتوقف خطوط المعالجة خلال 24 ساعة.

---

### 11.6 التعلم الفيدرالي مع ضوابط الخصوصية

 #11.6.1    المستوى: 1    الدور: D
 تحقق من أن تحديثات العميل تستخدم إضافة ضوضاء الخصوصية التفاضلية المحلية قبل التجميع.
 #11.6.2    المستوى: 2    الدور: D/V
 تحقق من أن مقاييس التدريب تتمتع بخصوصية تفاضلية ولا تكشف عن خسارة تخص عميلًا واحدًا.
 #11.6.3    المستوى: 2    الدور: V
 تحقق من أن التجميع المقاوم للتسميم (مثلاً Krum/Trimmed-Mean) مفعل.
 #11.6.4    المستوى: 3    الدور: V
 تحقق من أن البراهين الشكلية تُبيّن أن ميزانية ε الإجمالية مع خسارة المنفعة أقل من 5.

---

#### المراجع

GDPR & AI Compliance Best Practices
EU Parliament Study on GDPR & AI, 2020
ISO 31700-1:2023 — Privacy by Design for Consumer Products
NIST Privacy Framework 1.1 (2025 Draft)
Machine Unlearning: Right-to-Be-Forgotten Techniques
A Survey of Machine Unlearning, 2024
Auditing DP-SGD — ArXiv 2024
DP-SGD Explained — PyTorch Blog
Purpose-Limitation for AI — IJLIT 2025
Data-Protection Considerations for AI — URM Consulting
Top Consent-Management Platforms, 2025
Secure Aggregation in DP Federated Learning — ArXiv 2024

## C12 المراقبة والتسجيل واكتشاف الشذوذ

### هدف الرقابة

يقدّم هذا القسم المتطلبات اللازمة لتوفير رؤية في الوقت الفعلي والرؤية الجنائية الرقمية حول ما يراه النموذج ومكوّنات الذكاء الاصطناعي الأخرى، وما تفعله وما تعيده، حتى يمكن اكتشاف التهديدات وتحديد أولوياتها وتعلم الدروس منها.

### C12.1 تسجيل الطلبات والاستجابات

 #12.1.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع مدخلات المستخدم واستجابات النموذج مُسجَّلة مع بيانات تعريفية مناسبة (مثلاً الطابع الزمني، معرّف المستخدم، معرّف الجلسة، إصدار النموذج).
 #12.1.2    المستوى: 1    الدور: D/V
 تحقق من أن السجلات مخزَّنة في مستودعات آمنة ومتحكم فيها بالوصول، مع سياسات احتفاظ مناسبة وإجراءات نسخ احتياطي.
 #12.1.3    المستوى: 1    الدور: D/V
 تحقق من أن أنظمة تخزين السجلات تُطبق التشفير أثناء التخزين وأثناء النقل لحماية المعلومات الحساسة الموجودة في السجلات.
 #12.1.4    المستوى: 1    الدور: D/V
 تحقق من أن البيانات الحساسة في المطالبات والمخرجات تُحجب تلقائيًا أو تُموّه قبل التسجيل، مع قواعد حجب قابلة للتكوين لـ PII، وبيانات الاعتماد، والمعلومات المملوكة.
 #12.1.5    المستوى: 2    الدور: D/V
 تحقق من أن قرارات السياسة وإجراءات ترشيح السلامة مُسجَّلة بتفاصيل كافية لتمكين التدقيق وتصحيح الأخطاء في أنظمة تنظيم المحتوى.
 #12.1.6    المستوى: 2    الدور: D/V
 تحقق من أن تكامل السجل محمي من خلال، على سبيل المثال، التوقيعات الرقمية أو التخزين الذي يكتب فقط.

---

### C12.2 كشف إساءة الاستخدام والتنبيه

 #12.2.1    المستوى: 1    الدور: D/V
 تحقق من أن النظام يكتشف وينبه على أنماط كسر الحماية المعروفة، ومحاولات حقن المطالب، والمدخلات العدائية باستخدام الكشف القائم على التوقيعات.
 #12.2.2    المستوى: 1    الدور: D/V
 تحقق من أن النظام يتكامل مع منصات إدارة معلومات وأحداث الأمن (SIEM) القائمة باستخدام تنسيقات سجلات وبروتوكولات قياسية.
 #12.2.3    المستوى: 2    الدور: D/V
 تحقّق من أن أحداث الأمان المُعزَّزة تتضمن سياقاً خاصاً بالذكاء الاصطناعي مثل معرفات النماذج، ودرجات الثقة، وقرارات مرشحات السلامة.
 #12.2.4    المستوى: 2    الدور: D/V
 تأكد من أن اكتشاف الشذوذ السلوكي يحدد أنماط المحادثة غير العادية، أو محاولات إعادة المحاولة المفرطة، أو سلوكيات الاستقصاء المنهجية.
 #12.2.5    المستوى: 2    الدور: D/V
 تحقق من أن آليات الإنذار في الوقت الفعلي تبلغ فرق الأمن عندما يتم اكتشاف انتهاكات محتملة للسياسة أو محاولات هجوم.
 #12.2.6    المستوى: 2    الدور: D/V
 تحقق من أن القواعد المخصصة مُضمنة للكشف عن أنماط تهديد خاصة بالذكاء الاصطناعي، بما في ذلك محاولات فك القيود المنسقة، وحملات حقن التوجيه، وهجمات استخراج النموذج.
 #12.2.7    المستوى: 3    الدور: D/V
 تحقق من قدرة آليات الاستجابة للحوادث الآلية على عزل النماذج المصابة، وحظر المستخدمين الخبثاء، وتصعيد الأحداث الأمنية الحرجة.

---

### C12.3 كشف انحراف النموذج

 #12.3.1    المستوى: 1    الدور: D/V
 تحقق من أن النظام يتتبع مقاييس الأداء الأساسية مثل الدقة، ودرجات الثقة، وزمن الاستجابة، ومعدلات الخطأ عبر إصدارات النماذج وفترات زمنية.
 #12.3.2    المستوى: 2    الدور: D/V
 تحقق من تشغيل التنبيه الآلي عندما تتجاوز مقاييس الأداء حدود التدهور المحددة مسبقاً أو تنحرف بشكل كبير عن خط الأساس.
 #12.3.3    المستوى: 2    الدور: D/V
 تحقق من أن أنظمة مراقبة كشف الهلوسة تتعرّف على الحالات وتضع علامة عليها عندما تحتوي مخرجات النموذج على معلومات غير دقيقة من الناحية الواقعية، وغير متسقة، أو معلومات مختلقة.

---

### C12.4 قياس الأداء & السلوك

 #12.4.1    المستوى: 1    الدور: D/V
 تحقق من أن المقاييس التشغيلية بما في ذلك زمن استجابة الطلب، واستهلاك التوكنات، واستخدام الذاكرة، ومعدل المعالجة، يتم جمعها ومراقبتها باستمرار.
 #12.4.2    المستوى: 1    الدور: D/V
 تحقق من تتبّع معدلات النجاح والفشل مع تصنيف أنواع الأخطاء وأسبابها الجذرية.
 #12.4.3    المستوى: 2    الدور: D/V
 تحقق من أن رصد استخدام الموارد يتضمن استخدام GPU/CPU، واستهلاك الذاكرة، ومتطلبات التخزين مع تنبيه عند تجاوز العتبات.

---

### C12.5 التخطيط والتنفيذ لاستجابة الحوادث المرتبطة بالذكاء الاصطناعي

 #12.5.1    المستوى: 1    الدور: D/V
 تحقق من أن خطط الاستجابة للحوادث تعالج بشكل محدد الأحداث الأمنية المرتبطة بالذكاء الاصطناعي، بما في ذلك اختراق النماذج وتسميم البيانات والهجمات العدائية.
 #12.5.2    المستوى: 2    الدور: D/V
 تحقق من أن لدى فرق الاستجابة للحوادث إمكانية الوصول إلى أدوات التحري الجنائي الخاصة بالذكاء الاصطناعي وخبرة للتحقيق في سلوك النموذج ومسارات الهجوم.
 #12.5.3    المستوى: 3    الدور: D/V
 تحقق من أن تحليل ما بعد الحادث يتضمن اعتبارات إعادة تدريب النموذج، وتحديثات فلاتر الأمان، وتكامل الدروس المستفادة في ضوابط الأمن.

---

### C12.5 كشف تدهور أداء الذكاء الاصطناعي

مراقبة واكتشاف تدهور أداء وجودة نموذج الذكاء الاصطناعي مع مرور الوقت.

 #12.5.1    المستوى: 1    الدور: D/V
 تحقق من أن دقة النموذج، ودقة القياس (Precision)، والاسترجاع (Recall)، ومقاييس F1 يتم رصدها باستمرار ومقارنتها مع العتبات الأساسية.
 #12.5.2    المستوى: 1    الدور: D/V
 تحقق من أن رصد انزياح البيانات يراقب تغيرات توزيع المدخلات التي قد تؤثر على أداء النموذج.
 #12.5.3    المستوى: 2    الدور: D/V
 تحقق من أن كشف انزياح المفاهيم يحدد التغيّرات في العلاقة بين المدخلات والمخرجات المتوقعة.
 #12.5.4    المستوى: 2    الدور: D/V
 تحقق من أن تدهور الأداء يؤدي إلى تنبيهات تلقائية ويبدأ عمليات إعادة تدريب النموذج أو مسارات الاستبدال.
 #12.5.5    المستوى: 3    الدور: V
 تحقق من أن تحليل السبب الجذري للتدهور يربط انخفاض الأداء بتغيّرات البيانات، أو مشكلات البنية التحتية، أو العوامل الخارجية.

---

### C12.6 تصوّر DAG و أمن سير العمل

احمِ أنظمة تصور سير العمل من تسرب المعلومات وهجمات التلاعب.

 #12.6.1    المستوى: 1    الدور: D/V
 تحقق من أن بيانات تصور DAG قد تم تنظيفها لإزالة المعلومات الحساسة قبل التخزين أو الإرسال.
 #12.6.2    المستوى: 1    الدور: D/V
 تحقق من أن ضوابط وصول تصور سير العمل تضمن أن المستخدمين المصرح لهم فقط هم من يمكنهم عرض مسارات اتخاذ القرار الخاصة بالوكيل وآثار الاستدلال.
 #12.6.3    المستوى: 2    الدور: D/V
 تحقق من حماية سلامة بيانات DAG من خلال التوقيعات الكريبتوغرافية وآليات التخزين التي تكشف العبث.
 #12.6.4    المستوى: 2    الدور: D/V
 تحقق من أن أنظمة تصور سير العمل تنفذ التحقق من صحة الإدخال لمنع هجمات الحقن من خلال بيانات العقدة أو الحافة المصممة.
 #12.6.5    المستوى: 3    الدور: D/V
 تحقق من أن تحديثات DAG في الوقت الفعلي مقيدة بمعدل ومصادق عليها لمنع هجمات رفض الخدمة على أنظمة التصوّر.

---

### C12.7 مراقبة السلوك الأمني بشكل استباقي

الكشف والوقاية من التهديدات الأمنية من خلال تحليل سلوك الوكلاء بشكل استباقي.

 #12.7.1    المستوى: 1    الدور: D/V
 تحقق من أن سلوكيات الوكلاء الاستباقية متحققة أمنيًا قبل التنفيذ مع دمج تقييم المخاطر.
 #12.7.2    المستوى: 2    الدور: D/V
 تحقق من أن محفزات المبادرة المستقلة تشمل تقييم سياق الأمان وتقييم مشهد التهديدات.
 #12.7.3    المستوى: 2    الدور: D/V
 التأكد من أن أنماط السلوك الاستباقي يتم تحليلها من أجل الآثار الأمنية المحتملة والعواقب غير المقصودة.
 #12.7.4    المستوى: 3    الدور: D/V
 تحقق من أن الإجراءات الحساسة من الناحية الأمنية تتطلب سلاسل موافقات صريحة مع سجلات تدقيق.
 #12.7.5    المستوى: 3    الدور: D/V
 تحقق من أن كشف الشذوذ السلوكي يحدد الانحرافات في أنماط الوكلاء الاستباقيين التي قد تشير إلى وجود اختراق.

---

### المراجع

NIST AI Risk Management Framework 1.0 - Manage 4.1 and 4.3
ISO/IEC 42001:2023 — AI Management Systems Requirements - Annex B 6.2.6
EU AI Act — Article 12, 13, 16 and 19 on Logging and Record-keeping

## C13 الإشراف البشري، المساءلة والحوكمة

### هدف الرقابة

هذا الفصل يوفر متطلبات للحفاظ على إشراف بشري وسلاسل مساءلة واضحة في أنظمة الذكاء الاصطناعي، مع ضمان قابلية التفسير والشفافية والرعاية الأخلاقية طوال دورة حياة الذكاء الاصطناعي.

---

### C13.1 زر الإيقاف وآليات التجاوز

توفير مسارات للإيقاف أو الرجوع إلى الوضع السابق عند ملاحظة سلوك غير آمن لنظام الذكاء الاصطناعي.

 #13.1.1    المستوى: 1    الدور: D/V
 تحقق من وجود آلية إيقاف يدوي لإيقاف استدلال نموذج الذكاء الاصطناعي ومخرجاته على الفور.
 #13.1.2    المستوى: 1    الدور: D
 تحقق من أن ضوابط التجاوز متاحة فقط للأفراد المصرح لهم.
 #13.1.3    المستوى: 3    الدور: D/V
 تحقق من قدرة إجراءات التراجع على الرجوع إلى الإصدارات السابقة من النماذج أو عمليات الوضع الآمن.
 #13.1.4    المستوى: 3    الدور: V
 تحقق من أن آليات التجاوز تُختبر بانتظام.

---

### C13.2 الإنسان-في-الحلقة نقاط فحص القرار

يتطلب الحصول على موافقات بشرية عندما تتجاوز الرهانات عتبات المخاطر المحددة مسبقاً.

 #13.2.1    المستوى: 1    الدور: D/V
 تحقق من أن قرارات الذكاء الاصطناعي ذات مخاطر عالية تتطلب موافقة صريحة من الإنسان قبل التنفيذ.
 #13.2.2    المستوى: 1    الدور: D
 تحقق من أن حدود المخاطر محددة بوضوح وتُفعِّل تلقائيًا سير عمل المراجعة البشرية.
 #13.2.3    المستوى: 2    الدور: D
 تحقق من وجود إجراءات احتياطية للقرارات ذات الحساسية الزمنية عندما لا يمكن الحصول على موافقة بشرية ضمن المهلات الزمنية المطلوبة.
 #13.2.4    المستوى: 3    الدور: D/V
 تحقق من أن إجراءات التصعيد تحدد مستويات سلطة واضحة لأنواع القرارات المختلفة أو فئات المخاطر، إن كان ذلك قابلاً للتطبيق.

---

### C13.3 سلسلة المسؤولية وقابلية التدقيق

سجّل إجراءات المشغّل وقرارات النموذج.

 #13.3.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع قرارات نظام الذكاء الاصطناعي والتدخلات البشرية مُسجَّلة مع طوابع زمنية، وهويات المستخدمين، ومبررات القرار.
 #13.3.2    المستوى: 2    الدور: D
 تحقق من أن سجلات التدقيق لا يمكن التلاعب بها وتتضمن آليات تحقق من النزاهة.

---

### C13.4 تقنيات الذكاء الاصطناعي القابل للتفسير

أهمية السمات السطحية، والحالات المضادة، والتفسيرات المحلية.

 #13.4.1    المستوى: 1    الدور: D/V
 تحقق من أنظمة الذكاء الاصطناعي توفر تفسيرات أساسية لقراراتها بصيغة قابلة للقراءة البشرية.
 #13.4.2    المستوى: 2    الدور: V
 تأكد من أن جودة الشرح مُؤكدة من خلال دراسات التقييم البشري والمقاييس.
 #13.4.3    المستوى: 3    الدور: D/V
 تحقق من توفر درجات أهمية الميزات أو طرق الإسناد (SHAP، LIME، وما إلى ذلك) للاتخاذ قرارات حاسمة.
 #13.4.4    المستوى: 3    الدور: V
 تحقق من أن التفسيرات المضادّة للواقع تُظهر كيف يمكن تعديل المدخلات لتغيير النتائج، إذا كان ذلك قابلاً للتطبيق على حالة الاستخدام والمجال.

---

### C13.5 بطاقات النماذج وإفصاحات الاستخدام

الحفاظ على بطاقات النموذج للاستخدام المقصود، ومقاييس الأداء، والاعتبارات الأخلاقية.

 #13.5.1    المستوى: 1    الدور: D
 تحقق من أن بطاقات النماذج توثق حالات الاستخدام المقصودة والقيود وأنماط الفشل المعروفة.
 #13.5.2    المستوى: 1    الدور: D/V
 تحقق من أن مقاييس الأداء مُفصح عنها عبر حالات الاستخدام المختلفة القابلة للتطبيق.
 #13.5.3    المستوى: 2    الدور: D
 تحقق من أن الاعتبارات الأخلاقية وتقييمات التحيز وتقييمات العدالة وخصائص بيانات التدريب وقيود بيانات التدريب المعروفة موثقة ومحدَّثة بانتظام.
 #13.5.4    المستوى: 2    الدور: D/V
 تحقق من أن بطاقات النماذج خاضعة لإدارة الإصدارات ومُحافظة عليها طوال دورة حياة النموذج مع تتبّع التغييرات.

---

### C13.6 تقدير عدم اليقين

تمرير درجات الثقة أو مقاييس الإنتروبيا في الاستجابات.

 #13.6.1    المستوى: 1    الدور: D
 تحقق من أن أنظمة الذكاء الاصطناعي توفر درجات الثقة أو مقاييس عدم اليقين مع مخرجاتها.
 #13.6.2    المستوى: 2    الدور: D/V
 تحقق من أن عتبات عدم اليقين تؤدي إلى إجراء مراجعة بشرية إضافية أو مسارات اتخاذ قرار بديلة.
 #13.6.3    المستوى: 2    الدور: V
 تحقق من أن أساليب تقدير عدم اليقين مُعايرة ومُختبرة مقابل بيانات الحقيقة الأرضية.
 #13.6.4    المستوى: 3    الدور: D/V
 تحقق من أن انتشار عدم اليقين يظل قائماً عبر سير العمل في الذكاء الاصطناعي متعدد الخطوات.

---

### C13.7 تقارير الشفافية الموجهة للمستخدم

تقديم إفصاحات دورية عن الحوادث وانزياح المفاهيم واستخدام البيانات.

 #13.7.1    المستوى: 1    الدور: D/V
 تحقق من أن سياسات استخدام البيانات وممارسات إدارة موافقات المستخدم يتم توصيلها بوضوح إلى أصحاب المصلحة.
 #13.7.2    المستوى: 2    الدور: D/V
 تحقق من إجراء تقييمات أثر الذكاء الاصطناعي وتضمين النتائج في التقارير.
 #13.7.3    المستوى: 2    الدور: D/V
 تأكد من أن تقارير الشفافية التي تُنشر بانتظام تكشف عن حوادث الذكاء الاصطناعي والمقاييس التشغيلية بتفصيل معقول.

#### المراجع

EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
ISO/IEC 42001:2023 — AI Management Systems Requirements
NIST AI Risk Management Framework 1.0
NIST SP 800-53 Revision 5 — Security and Privacy Controls
A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)
Model Cards for Model Reporting (Mitchell et al., 2018)
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)
ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods
IEEE 7001-2021 — Transparency of Autonomous Systems
GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)
Human Oversight under Article 14 of the EU AI Act (Fink, 2025)

## الملحق أ: قائمة المصطلحات

This معجم شامل يقدم تعريفات للمصطلحات الرئيسية في الذكاء الاصطناعي والتعلم الآلي والأمن المستخدم عبر AISVS لضمان الوضوح والفهم المشترك.

مثال عدائي: مدخل مصمم عمدًا لإحداث خطأ في نموذج الذكاء الاصطناعي، غالبًا من خلال إضافة تشويهات دقيقة لا يمكن ملاحظتها للبشر.
​
المتانة ضد الهجمات العدائية – المتانة ضد الهجمات العدائية في الذكاء الاصطناعي تشير إلى قدرة النموذج على الحفاظ على أدائه ومقاومة أن يُخدع أو يُتلاعب به من قِبل مدخلات مُصمَّمة عمداً وخبيثة بهدف التسبب في أخطاء.
​
الوكيل – وكلاء الذكاء الاصطناعي هم أنظمة برمجية تستخدم الذكاء الاصطناعي لتحقيق الأهداف وإنجاز المهام نيابة عن المستخدمين. يظهرون الاستدلال والتخطيط والذاكرة ولهم مستوى من الاستقلالية لاتخاذ القرارات والتعلم والتكيف.
​
ذكاء اصطناعي ذو وكالة: أنظمة ذكاء اصطناعي يمكنها العمل بقدر من الاستقلال لتحقيق الأهداف، غالبًا ما تتخذ قرارات وتتصرف دون تدخل بشري مباشر.
​
التحكّم بالوصول القائم على السمات (ABAC): نمط تحكّم بالوصول يتم فيه اعتماد قرارات التفويض بناءً على سمات المستخدم والموارد والإجراء والبيئة، وتُقيَّم في وقت الاستعلام.
​
هجوم باب خلفي: نوع من هجمات تسميم البيانات حيث يتم تدريب النموذج على الاستجابة بطريقة محددة لمحفزات معينة، بينما يتصرف بشكل طبيعي في الحالات الأخرى.
​
التحيز: أخطاء منهجية في مخرجات نموذج الذكاء الاصطناعي يمكن أن تؤدي إلى نتائج غير عادلة أو تمييزية لفئات معينة أو في سياقات محددة.
​
استغلال الانحياز: تقنية هجوم تستغل الانحيازات المعروفة في نماذج الذكاء الاصطناعي للتلاعب بالمخرجات أو النتائج.
​
Cedar: لغة سياسات أمازون ومحركها للأذونات الدقيقة المفصّلة المستخدمة في تنفيذ ABAC لأنظمة الذكاء الاصطناعي.
​
سلسلة التفكير: تقنية لتحسين الاستدلال في نماذج اللغة من خلال توليد خطوات استدلال وسيطة قبل إنتاج الإجابة النهائية.
​
قواطع الدائرة: آليات توقف تشغيل أنظمة الذكاء الاصطناعي تلقائياً عندما تتجاوز عتبات المخاطر المحددة.
​
تسرب البيانات: الكشف غير المقصود عن معلومات حساسة من خلال مخرجات نموذج الذكاء الاصطناعي أو سلوكه.
​
تلويث البيانات: التلاعب المتعمد ببيانات التدريب من أجل المساس بسلامة النموذج، وغالبًا ما يكون ذلك بغرض تثبيت باب خلفي أو تدهور الأداء.
​
الخصوصية التفاضلية – الخصوصية التفاضلية إطار رياضي صارم لنشر معلومات إحصائية عن مجموعات البيانات مع حماية خصوصية الأفراد. إنها تتيح لمالك البيانات مشاركة أنماط مجمَّعة للمجموعة مع الحد من المعلومات التي يتم تسريبها عن أفراد بعينهم.
​
التضمينات: تمثيلات متجهية كثيفة للبيانات (النصوص، الصور، وغيرها) تلتقط المعنى الدلالي في فضاء عالي الأبعاد.
​
قابلية التفسير – قابلية التفسير في الذكاء الاصطناعي هي قدرة نظام ذكاء اصطناعي على تقديم أسباب يمكن فهمها للبشر لقراراته وتوقعاته، مع توفير رؤى حول آليات عمله الداخلية.
​
الذكاء الاصطناعي القابل للتفسير (XAI): أنظمة ذكاء اصطناعي مصممة لتوفير تفسيرات قابلة للفهم من قبل البشر لقراراتها وسلوكها من خلال تقنيات وأطر مختلفة.
​
التعلم الفيدرالي: نهج تعلم آلي يتم فيه تدريب النماذج عبر أجهزة لا مركزية متعددة تحمل عينات بيانات محلية، دون تبادل البيانات نفسها.
​
ضوابط: قيود منفذة لمنع أنظمة الذكاء الاصطناعي من إنتاج مخرجات ضارة أو متحيزة أو غير مرغوب فيها بأي شكل.
​
الهلوسة – تشير الهلوسة في الذكاء الاصطناعي إلى ظاهرة حيث يولّد نموذج الذكاء الاصطناعي معلومات غير صحيحة أو مضللة لا تستند إلى بيانات تدريبه أو إلى الواقع الفعلي.
​
الإنسان في الحلقة (HITL): أنظمة مصممة لتتطلب إشرافًا بشريًا، والتحقق، أو التدخل عند نقاط اتخاذ القرار الحاسمة.
​
البنية التحتية كرمز (IaC): إدارة وتوفير البنية التحتية من خلال الشفرة بدلاً من العمليات اليدوية، مما يمكّن من فحص الأمان وعمليات النشر المتسقة.
​
كسر الحماية: تقنيات تُستخدم لتجاوز حواجز السلامة في أنظمة الذكاء الاصطناعي، خاصة في نماذج اللغة الكبيرة، لإنتاج محتوى محظور.
​
مبدأ الأقل امتيازًا: المبدأ الأمني الذي يمنح فقط الحد الأدنى من حقوق الوصول اللازمة للمستخدمين والعمليات.
​
LIME (تفسيرات محلية قابلة للتفسير ومستقلة عن النموذج): تقنية لشرح توقعات أي مصنف تعلم آلي عن طريق تقريبه محلياً بنموذج قابل للتفسير.
​
هجوم استنتاج الانتماء: هجوم يهدف إلى تحديد ما إذا كانت نقطة بيانات محددة قد استخدمت في تدريب نموذج تعلم آلي.
​
MITRE ATLAS: مشهد التهديدات العدائية لأنظمة الذكاء الاصطناعي؛ قاعدة معرفة للأساليب والتقنيات العدائية ضد أنظمة الذكاء الاصطناعي.
​
بطاقة النموذج – هي وثيقة توفر معلومات موحدة عن أداء نموذج الذكاء الاصطناعي وحدوده، واستخداماته المقصودة، والاعتبارات الأخلاقية، من أجل تعزيز الشفافية وتطوير الذكاء الاصطناعي بشكل مسؤول.
​
استخراج النموذج: هجوم يقوم فيه خصم بطرح استفسارات متكررة على نموذج مستهدف بهدف إنشاء نسخة وظيفياً مشابهة دون إذن.
​
هجوم انعكاس النموذج: يحاول إعادة بناء بيانات التدريب من خلال تحليل مخرجات النموذج.
​
إدارة دورة حياة النموذج – إدارة دورة حياة نموذج الذكاء الاصطناعي هي العملية التي تتولى الإشراف على جميع مراحل وجود نموذج الذكاء الاصطناعي، بما في ذلك تصميمه وتطويره ونشره ومراقبته وصيانته والتقاعد النهائي، لضمان بقائه فعالاً ومتوافقاً مع الأهداف.
​
تلويث النموذج: إدخال ثغرات أو باب خلفي مباشرةً في النموذج أثناء عملية التدريب.
​
سرقة/انتهاك النموذج: استخراج نسخة أو تقريب من نموذج مملوك من خلال استفسارات متكررة.
​
نظام متعدد الوكلاء: نظام مكوّن من عدة وكلاء ذكاء اصطناعي يتفاعلون مع بعضهم البعض، كل واحد منهم قد يمتلك قدرات وأهداف مختلفة محتملة.
​
OPA (Open Policy Agent): محرك سياسات مفتوح المصدر يتيح تنفيذ سياسات موحدة عبر كامل المكدس.
​
التعلم الآلي المحافظ على الخصوصية (PPML): تقنيات وطرق لتدريب ونشر نماذج التعلم الآلي مع حماية خصوصية بيانات التدريب.
​
حقن الموجه: هجوم يتم فيه تضمين تعليمات خبيثة في المدخلات لتجاوز السلوك المقصود للنموذج.
​
RAG (التوليد المعزز بالاسترجاع): تقنية تعمل على تعزيز نماذج اللغة الكبيرة من خلال استرجاع معلومات ذات صلة من مصادر معرفة خارجية قبل توليد الاستجابة.
​
الاختبار-الأحمر: ممارسة اختبار أنظمة الذكاء الاصطناعي بنشاط من خلال محاكاة هجمات عدائية لتحديد الثغرات.
​
SBOM (قائمة المواد البرمجية): سجل رسمي يحتوي على التفاصيل وعلاقات سلسلة التوريد للمكونات المختلفة المستخدمة في بناء البرمجيات أو نماذج الذكاء الاصطناعي.
​
SHAP (SHapley Additive exPlanations): نهج مستند إلى نظرية الألعاب لشرح مخرجات أي نموذج تعلم آلي من خلال حساب مساهمة كل ميزة في التنبؤ.
​
هجوم سلسلة التوريد: اختراق النظام من خلال استهداف عناصر أقل أماناً في سلسلة التوريد الخاصة به، مثل مكتبات الطرف الثالث، ومجموعات البيانات، أو نماذج مدربة مسبقاً.
​
التعلم بالنقل: تقنية يتم فيها استخدام نموذج تم تطويره لمهمة واحدة كنقطة انطلاق لنموذج لمهمة ثانية.
​
قاعدة بيانات المتجهات: قاعدة بيانات متخصصة مصممة لتخزين المتجهات عالية الأبعاد (تمثيلات التضمين) وتنفيذ عمليات بحث تشابه فعالة.
​
مسح الثغرات الأمنية: أدوات آلية تحدد الثغرات الأمنية المعروفة في مكوّنات البرمجيات، بما في ذلك أطر العمل الخاصة بالذكاء الاصطناعي والتبعيات.
​
إضافة علامة مائية: تقنيات لإدراج علامات غير ملحوظة في المحتوى الناتج عن الذكاء الاصطناعي لتتبع مصدره أو الكشف عن توليده بواسطة الذكاء الاصطناعي.
​
ثغرة يوم الصفر: ثغرة غير معروفة سابقاً يمكن للمهاجمين استغلالها قبل أن يقوم المطورون بإنشاء ونشر التصحيح.

## الملحق B: المراجع

### TODO

## الملحق C: حوكمة الأمن والتوثيق في الذكاء الاصطناعي

### الهدف

يقدّم هذا الملحق متطلبات أساسية لإنشاء الهياكل التنظيمية والسياسات والعمليات بهدف حوكمة أمان الذكاء الاصطناعي طوال دورة حياة النظام.

---

### AC.1 اعتماد إطار إدارة مخاطر الذكاء الاصطناعي

وضع إطار عمل رسمي لتحديد المخاطر المرتبطة بالذكاء الاصطناعي وتقييمها والتخفيف من آثارها طوال دورة حياة النظام.

 #AC.1.1    المستوى: 1    الدور: D/V
 تحقق من توثيق وتنفيذ منهجية تقييم مخاطر خاصة بالذكاء الاصطناعي.
 #AC.1.2    المستوى: 2    الدور: D
 تحقق من إجراء تقييمات المخاطر في نقاط رئيسية في دورة حياة الذكاء الاصطناعي وقبل حدوث تغييرات كبيرة.
 #AC.1.3    المستوى: 3    الدور: D/V
 تحقق من أن إطار إدارة المخاطر يتماشى مع المعايير المعتمدة (على سبيل المثال NIST AI RMF).

---

### AC.2 سياسة وإجراءات أمان الذكاء الاصطناعي

حدد وطبق المعايير المؤسسية للأمان في تطوير الذكاء الاصطناعي ونشره وتشغيله.

 #AC.2.1    المستوى: 1    الدور: D/V
 تحقق من وجود سياسات أمان للذكاء الاصطناعي موثقة.
 #AC.2.2    المستوى: 2    الدور: D
 تحقق من أن السياسات تُراجع وتُحدَّث على الأقل سنويًا وبعد تغيّرات كبيرة في مشهد-التهديد.
 #AC.2.3    المستوى: 3    الدور: D/V
 تحقق من أن السياسات تغطي جميع فئات AISVS والمتطلبات التنظيمية المعمول بها.

---

### AC.3 الأدوار والمسؤوليات المتعلقة بأمن الذكاء الاصطناعي

إرساء مساءلة واضحة لأمان الذكاء الاصطناعي عبر المنظمة.

 #AC.3.1    المستوى: 1    الدور: D/V
 تحقق من توثيق أدوار ومسؤوليات الأمن المرتبط بالذكاء الاصطناعي.
 #AC.3.2    المستوى: 2    الدور: D
 تحقق من أن الأفراد المسؤولون يمتلكون خبرة أمنية مناسبة.
 #AC.3.3    المستوى: 3    الدور: D/V
 تحقق من إنشاء لجنة أخلاقيات الذكاء الاصطناعي أو مجلس الحوكمة للأنظمة عالية‑المخاطر في الذكاء الاصطناعي.

---

### AC.4 إنفاذ إرشادات الأخلاقيات في الذكاء الاصطناعي

تأكد من أن أنظمة الذكاء الاصطناعي تعمل وفق المبادئ الأخلاقية المعتمدة.

 #AC.4.1    المستوى: 1    الدور: D/V
 تحقق من وجود إرشادات أخلاقية لتطوير ونشر الذكاء الاصطناعي.
 #AC.4.2    المستوى: 2    الدور: D
 تحقق من وجود آليات للكشف عن الانتهاكات الأخلاقية والإبلاغ عنها.
 #AC.4.3    المستوى: 3    الدور: D/V
 تحقق من أن مراجعات أخلاقية منتظمة تُجرى لأنظمة الذكاء الاصطناعي المُنفَّذة.

---

### AC.5 مراقبة الامتثال التنظيمي للذكاء الاصطناعي

احرص على الوعي والامتثال للوائح الذكاء الاصطناعي المتغيرة.

 #AC.5.1    المستوى: 1    الدور: D/V
 تحقق من وجود عمليات لتحديد اللوائح الخاصة بالذكاء الاصطناعي القابلة للتطبيق.
 #AC.5.2    المستوى: 2    الدور: D
 تحقق من أن يتم تقييم الامتثال لجميع المتطلبات التنظيمية.
 #AC.5.3    المستوى: 3    الدور: D/V
 تحقق من أن تغييرات التنظيم تحفّز مراجعات وتحديثات في الوقت المناسب لأنظمة الذكاء الاصطناعي.

### AC.6 حوكمة بيانات التدريب والتوثيق والعمليات

 #1.1.2    المستوى: 1    الدور: D/V
 تحقق من أن تكون مجموعات البيانات المسموح بها فقط هي تلك الخاضعة للمراجعة لضمان الجودة والتمثيلية والمصادر الأخلاقية والامتثال للرخص، مما يقلل مخاطر تسميم البيانات والتحيز المضمن وانتهاك الملكية الفكرية.
 #1.1.5    المستوى: 2    الدور: D/V
 تحقق من ضمان جودة التوسيم/التعليقات التوضيحية عبر مراجعات متقاطعة من قِبل المراجعين أو عبر الإجماع.
 #1.1.6    المستوى: 2    الدور: D/V
 تحقق من أن "data cards" أو "datasheets for datasets" يتم الاحتفاظ بها لمجموعات البيانات التدريبية المهمة، مع تفصيل الخصائص والدوافع والتركيب وعمليات الجمع والمعالجة المسبقة، والاستخدامات الموصى بها أو غير الموصى بها.
 #1.3.2    المستوى: 2    الدور: D/V
 تحقق من أن الانحيازات المحددة قد تم تخفيفها من خلال استراتيجيات موثقة مثل إعادة-التوازن، تعزيز البيانات المستهدفة، تعديلات خوارزمية (مثل المعالجة-المسبقة، المعالجة-أثناء-التدريب، المعالجة-لاحقة)، أو إعادة-الوزن، ويتم تقييم أثر التخفيف على كل من الإنصاف والأداء العام للنموذج.
 #1.3.3    المستوى: 2    الدور: D/V
 تحقق من أن مقاييس الإنصاف بعد التدريب قد تم تقييمها وتوثيقها.
 #1.3.4    المستوى: 3    الدور: D/V
 تحقق من أن سياسة إدارة انحياز دورة الحياة تعيّن المالكين وتحدد وتيرة المراجعات.
 #1.4.1    المستوى: 2    الدور: D/V
 تحقق من أن جودة التسمية/التعليقات التوضيحية مضمونة من خلال إرشادات واضحة، ومراجعات متبادلة من قِبَل المراجعين، وآليات توافق (مثل رصد اتفاقية بين المُوسِّمين)، وعمليات محددة لحل الاختلافات.
 #1.4.4    المستوى: 3    الدور: D/V
 تحقق من أن التسميات التي تعتبر حرجة للسلامة والأمن أو الإنصاف (على سبيل المثال، تحديد المحتوى السام، النتائج الطبية الحرجة) تخضع لمراجعة مستقلة مزدوجة الإلزام أو تحقق قوي مكافئ.
 #1.4.6    المستوى: 2    الدور: D/V
 تحقق من أن إرشادات الوسم والتعليمات شاملة، وتخضع لإدارة الإصدارات، وتخضع لمراجعة من قبل الأقران.
 #1.4.6    المستوى: 2    الدور: D/V
 تحقق من أن مخططات البيانات الخاصة بالتسميات محددة بوضوح وتخضع للتحكم في الإصدار.
 #1.3.1    المستوى: 1    الدور: D/V
 تحقق من أن مجموعات البيانات فُحصت للكشف عن التفاوت التمثيلي والتحيزات المحتملة عبر السمات المحمية قانونياً (مثل العِرق، والجنس، والعمر) وأخرى حساسة أخلاقياً ذات صلة بمجال تطبيق النموذج (مثل الوضع الاجتماعي-الاقتصادي، الموقع).
 #1.5.3    المستوى: 2    الدور: V
 تحقق من أن فحوصات يدوية عشوائية يجريها خبراء المجال تغطي عينة ذات دلالة إحصائية (على سبيل المثال، ≥1% أو 1,000 عينات، أيهما أكبر، أو كما يحدده تقييم المخاطر) لتحديد قضايا جودة دقيقة لم تُلتقطها الأتمتة.
 #1.8.4    المستوى: 2    الدور: D/V
 تحقق من أن عمليات التسمية التي تتم عبر التعهيد الخارجي أو التعهيد الجماعي تتضمن إجراءات حماية تقنية/إجرائية لضمان سرية البيانات وسلامتها وجودة التسميات ومنع تسرب البيانات.
 #1.5.4    المستوى: 2    الدور: D/V
 تحقق من إضافة خطوات الإصلاح إلى سجلات الأصل.
 #1.6.2    المستوى: 2    الدور: D/V
 تحقق من أن العينات المصنفة تؤدي إلى مراجعة يدوية قبل التدريب.
 #1.6.3    المستوى: 2    الدور: V
 تحقق من أن النتائج تغذي الملف الأمني للنموذج وتزوّد معلومات استخبارات التهديد المستمرة.
 #1.6.4    المستوى: 3    الدور: D/V
 تحقق من أن منطق الكشف تم تحديثه بمعلومات التهديد الجديدة.
 #1.6.5    المستوى: 3    الدور: D/V
 تحقق من أن خطوط أنابيب التعلم عبر الإنترنت تراقب انزياح التوزيع.
 #1.7.1    المستوى: 1    الدور: D/V
 تحقق من أن إجراءات حذف بيانات التدريب تمحو البيانات الأولية والبيانات المشتقة، وأن يتم تقييم التأثير على النماذج المتأثرة، وإذا لزم الأمر، معالجته (على سبيل المثال، من خلال إعادة التدريب أو إعادة المعايرة).
 #1.7.2    المستوى: 2    الدور: D
 تحقق من وجود آليات لتتبع واحترام نطاق وحالة موافقة المستخدم (و سحبها) للبيانات المستخدمة في التدريب، وأن يتم التحقق من الموافقة قبل دمج البيانات في عمليات تدريب جديدة أو تحديثات كبيرة للنموذج.
 #1.7.3    المستوى: 2    الدور: V
 تحقق من أن سير العمل يُختبر سنوياً ويُسجَّل.
 #1.8.1    المستوى: 2    الدور: D/V
 تحقّق من أن مورّدي البيانات من الأطراف الثالثة، بمن فيهم مقدمو النماذج المدربة مسبقاً ومجموعات البيانات الخارجية، يخضعون للعناية الواجبة في الأمن والخصوصية والتوريد الأخلاقي وجودة البيانات قبل دمج بياناتهم أو نماذجهم.
 #1.8.2    المستوى: 1    الدور: D
 تحقق من أن التحويلات الخارجية تستخدم TLS/المصادقة وفحوصات التكامل.
 #1.8.3    المستوى: 2    الدور: D/V
 تحقق من أن مصادر البيانات عالية المخاطر (مثل مجموعات البيانات مفتوحة المصدر ذات المنشأ غير المعروف، وموردون غير مُراجَعين) تخضع لفحص أكثر صرامة، مثل تحليل في بيئة معزولة، وفحوصات جودة وانحياز موسّعة، وكشف تسميم مستهدف، قبل استخدامها في التطبيقات الحساسة.
 #1.8.4    المستوى: 3    الدور: D/V
 تحقق من أن النماذج المدربة مسبقًا، والتي تم الحصول عليها من أطراف ثالثة، تُقيَّم من أجل الانحيازات المدمجة، والبوابات الخلفية المحتملة، وسلامة بنية النموذج، ومصدر البيانات التدريبية الأصلية قبل إجراء الضبط الدقيق أو النشر.
 #1.5.3    المستوى: 2    الدور: D/V
 تحقق من أنه عند استخدام التدريب المعادي، يتم توثيق توليد مجموعات البيانات المعادية وإدارتها وإصداراتها والسيطرة عليها.
 #1.5.3    المستوى: 3    الدور: D/V
 تحقق من أن تأثير تدريب المتانة ضد الهجمات على أداء النموذج (ضد كل من الإدخالات النظيفة والإدخالات العدائية) ومقاييس الإنصاف يتم تقييمه وتوثيقه ومراقبته.
 #1.5.4    المستوى: 3    الدور: D/V
 تحقق من أن استراتيجيات التدريب ضد الهجمات العدائية والمتانة تُراجع وتُحدَّث بشكل دوري لمواجهة تقنيات الهجوم العدائي المتطورة.
 #1.4.2    المستوى: 2    الدور: D/V
 تحقق من أن مجموعات البيانات الفاشلة معزولة بسجلات التدقيق.
 #1.4.3    المستوى: 2    الدور: D/V
 تأكد من أن بوابات الجودة تمنع مجموعات البيانات منخفضة الجودة ما لم يتم الموافقة على الاستثناءات.
 #1.11.2    المستوى: 2    الدور: D/V
 تحقق من توثيق عملية التوليد والمعلمات والاستخدام المقصود للبيانات الاصطناعية.
 #1.11.3    المستوى: 2    الدور: D/V
 تأكد من أن البيانات الاصطناعية قد خضعت لتقييم المخاطر من حيث التحيز وتسريب الخصوصية ومشاكل التمثيل قبل استخدامها في التدريب.
 #1.12.3    المستوى: 2    الدور: D/V
 تحقق من أنه يتم إصدار الإنذارات لحوادث الوصول المشبوهة ويتم التحقيق فيها بسرعة.
 #1.13.1    المستوى: 1    الدور: D/V
 تحقق من أن فترات الاحتفاظ الصريحة محددة لجميع مجموعات بيانات التدريب.
 #1.13.2    المستوى: 2    الدور: D/V
 تحقق من أن مجموعات البيانات تنتهي صلاحيتها تلقائيًا، وتُحذف، أو تُراجع للحذف عند نهاية دورة حياتها.
 #1.13.3    المستوى: 2    الدور: D/V
 تحقق من أن إجراءات الاحتفاظ بالبيانات وإجراءات الحذف مسجلة وقابلة للتدقيق.
 #1.14.1    المستوى: 2    الدور: D/V
 تحقق من أن متطلبات إقامة البيانات ونقل البيانات عبر الحدود قد تم تحديدها وتطبيقها على جميع مجموعات البيانات.
 #1.14.2    المستوى: 2    الدور: D/V
 تحقق من أن اللوائح التنظيمية الخاصة بكل قطاع (مثل الرعاية الصحية والمالية) قد تم تحديدها ومعالجتها أثناء معالجة البيانات.
 #1.14.3    المستوى: 2    الدور: D/V
 تحقق من أن الامتثال لقوانين الخصوصية ذات الصلة موثّق ومراجَع بانتظام (على سبيل المثال، GDPR، CCPA).
 #1.16.1    المستوى: 2    الدور: D/V
 تحقق من وجود آليات للرد على طلبات أصحاب البيانات للوصول إلى بياناتهم، وتصحيحها، وتقييدها، أو الاعتراض عليها.
 #1.16.2    المستوى: 2    الدور: D/V
 تحقق من أن الطلبات مُسجَّلة، ومُتتبَّعة، ومُنفَّذة ضمن الإطارات الزمنية المفروضة قانوناً.
 #1.16.3    المستوى: 2    الدور: D/V
 تحقق من أن عمليات حقوق أصحاب البيانات يتم اختبارها ومراجعتها بانتظام من أجل الفعالية.
 #1.17.1    المستوى: 2    الدور: D/V
 تحقق من أن يتم إجراء تحليل الأثر قبل تحديث أو استبدال إصدار مجموعة البيانات، مع تغطية أداء النموذج والإنصاف والامتثال.
 #1.17.2    المستوى: 2    الدور: D/V
 تحقق من أن نتائج تحليل التأثير موثقة وتتم مراجعتها من قبل أصحاب المصلحة المعنيين.
 #1.17.3    المستوى: 2    الدور: D/V
 تحقق من وجود خطط التراجع في حال أدت الإصدارات الجديدة إلى مخاطر غير مقبولة أو تراجعات.
 #1.18.1    المستوى: 2    الدور: D/V
 تحقق من أن جميع العاملين المشاركين في توسيم البيانات قد خضعوا لفحص الخلفية وتلقوا تدريباً في أمن البيانات والخصوصية.
 #1.18.2    المستوى: 2    الدور: D/V
 تحقق من أن جميع موظفي التوسيم يوقعون على اتفاقيات السرية وعدم الإفشاء.
 #1.18.3    المستوى: 2    الدور: D/V
 تحقق من أن منصات وسم البيانات تفرض ضوابط الوصول وتراقب التهديدات من داخل المؤسسة.

#### المراجع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
EU Artificial Intelligence Act — Regulation (EU) 2024/1689
ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods

## الملحق D: حوكمة الترميز الآمن بمساعدة الذكاء الاصطناعي والتحقق

### الهدف

يحدد هذا الفصل الضوابط التنظيمية الأساسية لاستخدام آمن وفعال لأدوات البرمجة المدعومة بالذكاء الاصطناعي أثناء تطوير البرمجيات، مع ضمان الأمان وإمكانية التتبّع عبر دورة حياة تطوير البرمجيات (SDLC).

---

### AD.1 سير عمل الترميز الآمن بمساعدة الذكاء الاصطناعي

دمج أدوات الذكاء الاصطناعي في دورة‑حياة‑تطوير‑البرمجيات‑الآمنة للمنظمة (SSDLC) دون إضعاف بوابات الأمان الحالية.

 #AD.1.1    المستوى: 1    الدور: D/V
 تحقق من أن سير العمل الموثّق يصف متى وكيف يمكن لأدوات الذكاء الاصطناعي توليد الشيفرة، أو إعادة هيكلتها، أو مراجعتها.
 #AD.1.2    المستوى: 2    الدور: D
 تحقق من أن سير العمل يتطابق مع كل مرحلة من مراحل SSDLC (التصميم، التنفيذ، مراجعة الكود، الاختبار، النشر).
 #AD.1.3    المستوى: 3    الدور: D/V
 تحقق من أن المقاييس (على سبيل المثال، كثافة الثغرات الأمنية، متوسط-الزمن-للكشف) مجمّعة على الكود الناتج عن الذكاء الاصطناعي، وتُقارن مع خطوط الأساس التي تعتمد فقط على البشر.

---

### AD.2 تأهيل أداة الذكاء الاصطناعي ونمذجة التهديدات

تأكد من أن يتم تقييم أدوات برمجة الذكاء الاصطناعي من حيث القدرات الأمنية والمخاطر وتأثير سلسلة‑الإمداد قبل اعتمادها.

 #AD.2.1    المستوى: 1    الدور: D/V
 تحقق من أن نموذج التهديد لكل أداة ذكاء اصطناعي يحدد مخاطر إساءة الاستخدام، وهجمات عكس النموذج، وتسرّب البيانات، ومخاطر سلسلة الاعتماد.
 #AD.2.2    المستوى: 2    الدور: D
 تحقق من أن تقييمات الأدوات تتضمن تحليلًا ثابتًا/ديناميكيًا لأي مكونات محلية وتقييم نقاط نهاية SaaS (TLS، المصادقة/التفويض، التسجيل).
 #AD.2.3    المستوى: 3    الدور: D/V
 تحقق من أن التقييمات تتبع إطار عمل معترف به وتُعاد إجراؤها بعد تغييرات الإصدار الرئيسية.

---

### AD.3 إدارة الموجه والسياق الآمن

منع تسرب الأسرار والكود المملوك والبيانات الشخصية عند إنشاء المطالبات أو السياقات لنماذج الذكاء الاصطناعي.

 #AD.3.1    المستوى: 1    الدور: D/V
 تحقق من أن الإرشادات المكتوبة تحظر إرسال الأسرار، بيانات الاعتماد، أو البيانات المصنَّفة ضمن المطالبات.
 #AD.3.2    المستوى: 2    الدور: D
 تحقق من أن الضوابط الفنية (الإخفاء من جانب العميل، المرشحات السياقية المعتمدة) تقوم تلقائيًا بإزالة الآثار الحساسة.
 #AD.3.3    المستوى: 3    الدور: D/V
 تحقق من أن المحفزات والاستجابات مُجزأة إلى توكنات، ومشفَّرة أثناء النقل وخلال التخزين، وأن فترات الاحتفاظ تتوافق مع سياسة تصنيف البيانات.

---

### AD.4 التحقق من صحة الكود الناتج عن الذكاء الاصطناعي

اكتشف الثغرات التي تُسبّبها مخرجات الذكاء الاصطناعي وعالجها قبل دمج الشفرة أو نشرها.

 #AD.4.1    المستوى: 1    الدور: D/V
 تحقق من أن الكود الناتج عن الذكاء الاصطناعي يخضع دائماً لمراجعة الكود من قبل البشر.
 #AD.4.2    المستوى: 2    الدور: D
 تحقق من تشغيل فاحصات آلية (SAST/IAST/DAST) على كل طلب دمج يحتوي على كود مولّد بالذكاء الاصطناعي، وتمنع الدمج عند وجود نتائج حرجة.
 #AD.4.3    المستوى: 3    الدور: D/V
 تحقق من أن الاختبار التفاضلي أو الاختبارات المعتمدة على الخصائص تثبت السلوكيات الحرجة أمنياً (مثلاً، التحقق من صحة الإدخال، منطق التفويض).

---

### AD.5 قابلية التفسير وتتبع اقتراحات الكود

زوّد المراجعين والمطورين بفهمٍ لسبب تقديم الاقتراح وكيف تطوّر.

 #AD.5.1    المستوى: 1    الدور: D/V
 تحقق من أن أزواج المطالبات والردود مُسجَّلة بمعرّفات الالتزام.
 #AD.5.2    المستوى: 2    الدور: D
 تحقق من أن بإمكان المطورين عرض استشهادات النموذج (مقتطفات من بيانات التدريب والوثائق) التي تدعم اقتراحاً.
 #AD.5.3    المستوى: 3    الدور: D/V
 تحقق من أن تقارير قابلية التفسير مخزنة مع مخرجات التصميم ومذكورة في مراجعات الأمن، بما يتوافق مع مبادئ التتبّع ISO/IEC 42001.

---

### AD.6 التغذية الراجعة المستمرة وضبط النماذج الدقيقة

تحسين أداء أمان النموذج على مدار الوقت مع منع الانحراف السلبي.

 #AD.6.1    المستوى: 1    الدور: D/V
 تحقق من أن المطورين يمكنهم وسم الاقتراحات غير الآمنة أو غير المتوافقة، وأنه يتم تتبّع العلامات.
 #AD.6.2    المستوى: 2    الدور: D
 تحقق من أن التغذية الراجعة المجمّعة تُعلِم الضبط الدقيق الدوري أو التوليد المعزز بالاسترجاع باستخدام مجموعات نصوص موثوقة للبرمجة الآمنة (مثلاً OWASP Cheat Sheets).
 #AD.6.3    المستوى: 3    الدور: D/V
 تحقق من أن أداة تقييم ذات حلقة مغلقة تقوم بتشغيل اختبارات الانحدار بعد كل ضبط دقيق؛ يجب أن تستوفي مقاييس الأمان الحدود الأساسية السابقة أو تتجاوزها قبل النشر.

---

#### المراجع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
OWASP Secure Coding Practices — Quick Reference Guide

## الملحق E: أمثلة على الأدوات والأطر

### الهدف

هذا الفصل يقدّم أمثلة على الأدوات وأطر العمل التي يمكن أن تدعم تنفيذ أو تحقيق متطلب AISVS المعين. ولا يجب اعتبارها توصيات أو تأييدًا من فريق AISVS أو مشروع OWASP GenAI Security.

---

### AE.1 حوكمة بيانات التدريب وإدارة التحيز

الأدوات المستخدمة في تحليلات البيانات والحوكمة وإدارة التحيز.

 #AE.1.1    القسم: 1.1
 أدوات جرد البيانات: أدوات إدارة جرد البيانات مثل...
 #AE.1.2    القسم: 1.2
 التشفير-أثناء-النقل استخدم TLS للتطبيقات المعتمدة على HTTPS، مع أدوات مثل OpenSSL وبايثون`ssl` مكتبة.

---

### AE.2 التحقق من مدخلات المستخدم

أدوات لمعالجة مدخلات المستخدم والتحقق من صحتها.

 #AE.2.1    القسم: 2.1
 أدوات الدفاع ضد حقن المطالبات: استخدم أدوات Guardrail مثل NeMo من NVIDIA أو Guardrails AI.

---

