## الصفحة التقديمية

### عن المعيار

معيار التحقق من أمان الذكاء الاصطناعي (AISVS) هو دليل مجتمعي متكامل لمتطلبات الأمان يمكن لعلماء البيانات، ومهندسي عمليات تعلم الآلة (MLOps)، ومهندسي البرمجيات، والمطورين، والمختبرين، والمتخصصين في الأمان، وبائعي الأدوات، والمنظمين، والمستهلكين استخدامه لتصميم وبناء واختبار والتحقق من أنظمة وتطبيقات الذكاء الاصطناعي الموثوقة. ويوفر لغة مشتركة لتحديد ضوابط الأمان عبر دورة حياة الذكاء الاصطناعي — من جمع البيانات وتطوير النماذج إلى النشر والمراقبة المستمرة — حتى تتمكن المؤسسات من قياس وتحسين مقاومة وخصوصية وسلامة حلول الذكاء الاصطناعي الخاصة بها.

### حقوق النشر والترخيص

الإصدار 0.1 (المسودة العامة الأولى - قيد العمل)، 2025  

![license](images/license.png)
حقوق النشر © 2025 مشروع AISVS.  

تم الإصدار بموجب Creative Commons Attribution‑ShareAlike 4.0 International License.
لأي إعادة استخدام أو توزيع، يجب عليك توضيح شروط الترخيص لهذا العمل بوضوح للآخرين.

### قادة المشروع

جيم مانيكو
أراس "رس" ميميسيازيتشي

### المساهمون والمراجعون

https://github.com/ottosulin
https://github.com/mbhatt1
https://github.com/vineethsai
https://github.com/cciprofm
https://github.com/deepakrpandey12


---

AISVS هو معيار جديد تمامًا تم إنشاؤه خصيصًا لمعالجة تحديات الأمان الفريدة لأنظمة الذكاء الاصطناعي. وبينما يستوحي بعض المبادئ من أفضل ممارسات الأمان العامة، فقد تم تطوير كل متطلب في AISVS من الأساس ليعكس مشهد التهديدات المتعلقة بالذكاء الاصطناعي ولمساعدة المؤسسات في بناء حلول ذكاء اصطناعي أكثر أمانًا ومرونة.

## المقدمة

مرحبًا بكم في معيار التحقق من أمان الذكاء الاصطناعي (AISVS) الإصدار 1.0!

### مقدمة

تأسست AISVS في عام 2025 من خلال جهد مجتمعي تعاوني، وتحدد متطلبات الأمان التي يجب مراعاتها عند تصميم وتطوير ونشر وتشغيل نماذج الذكاء الاصطناعي الحديثة، وسير العمل، والخدمات المدعومة بالذكاء الاصطناعي.

تمثل AISVS v1.0 العمل المشترك لقادة المشروع، مجموعة العمل، والمساهمين من المجتمع الأوسع لإنتاج معيار عملي وقابل للاختبار لتأمين أنظمة الذكاء الاصطناعي.

هدفنا مع هذا الإصدار هو جعل AISVS سهل التبني مع الحفاظ على تركيز دقيق على نطاقه المحدد ومعالجة المشهد السريع التطور للمخاطر الفريدة من نوعها التي تخص الذكاء الاصطناعي.

### الأهداف الرئيسية لإصدار AISVS 1.0

سيتم إنشاء النسخة 1.0 مع عدة مبادئ توجيهية.

#### نطاق محدد جيدًا

يجب أن تتماشى كل متطلبات مع اسم ومهمة AISVS:

الذكاء الاصطناعي – تعمل الضوابط على طبقة الذكاء الاصطناعي/التعلم الآلي (البيانات، النموذج، خط الأنابيب، أو الاستدلال) وتكون مسؤولية ممارسي الذكاء الاصطناعي.
الأمان – المتطلبات تخفف بشكل مباشر المخاطر المحددة المتعلقة بالأمان أو الخصوصية أو السلامة.
التحقق – تُكتب اللغة بحيث يمكن التحقق من توافُقها بشكل موضوعي.
المعيار – تتبع الأقسام بنية ومصطلحات متسقة لتشكيل مرجع متماسك.
​
---

من خلال اتباع AISVS، يمكن للمنظمات تقييم وتعزيز وضع الأمان لحلول الذكاء الاصطناعي الخاصة بها بشكل منهجي، مما يعزز ثقافة هندسة الذكاء الاصطناعي الآمنة.

## باستخدام AISVS

تحدد معيار التحقق من أمان الذكاء الاصطناعي (AISVS) متطلبات الأمان لتطبيقات وخدمات الذكاء الاصطناعي الحديثة، مع التركيز على الجوانب التي تقع ضمن سيطرة مطوري التطبيقات.

يُقصد من AISVS أي شخص يقوم بتطوير أو تقييم أمان تطبيقات الذكاء الاصطناعي، بما في ذلك المطورين، والمصممين، ومهندسي الأمان، والمدققين. يقدم هذا الفصل هيكلية وطرق استخدام AISVS، بما في ذلك مستويات التحقق وحالات الاستخدام المقصودة.

### مستويات التحقق من أمان الذكاء الاصطناعي

تعرف AISVS ثلاثة مستويات تصاعدية للتحقق من الأمان. يضيف كل مستوى عمقًا وتعقيدًا، مما يمكّن المؤسسات من تكييف وضعها الأمني وفقًا لمستوى المخاطر في أنظمة الذكاء الاصطناعي الخاصة بها.

قد تبدأ المؤسسات من المستوى 1 وتتقدم تدريجيًا إلى المستويات الأعلى مع زيادة نضج الأمان وتعرضها للتهديدات.

#### تعريف المستويات

يتم تعيين كل متطلب في AISVS v1.0 إلى أحد المستويات التالية:

 متطلبات المستوى 1

المستوى 1 يشمل المتطلبات الأمنية الأكثر حيوية وأساساً. تركز هذه المتطلبات على منع الهجمات الشائعة التي لا تعتمد على شروط مسبقة أو ثغرات أخرى. معظم ضوابط المستوى 1 إما سهلة التنفيذ أو ضرورية بدرجة تبرر الجهد المبذول.

 متطلبات المستوى 2

المستوى 2 يعالج الهجمات الأكثر تقدمًا أو الأقل شيوعًا، بالإضافة إلى الدفاعات متعددة الطبقات ضد التهديدات واسعة الانتشار. قد تتطلب هذه المتطلبات منطقًا أكثر تعقيدًا أو تستهدف شروطًا محددة للهجوم.

 متطلبات المستوى 3

المستوى 3 يشمل ضوابط تكون عادةً أصعب في التطبيق أو ذات تطبيق يعتمد على الحالة. غالبًا ما تمثل هذه الآليات دفاعًا متعمقًا أو تدابير تخفيف ضد الهجمات المتخصصة، المستهدفة، أو ذات التعقيد العالي.

#### الدور (D/V)

يتم تصنيف كل متطلب من متطلبات AISVS وفقًا للجمهور الأساسي:

D – متطلبات مُركَزة على المطور
V – متطلبات تركز على المدقق/المدقق المستقل
D/V – ذات صلة بكل من المطورين والمحققين

## حوكمة بيانات التدريب C1 وإدارة التحيز

### هدف التحكم

يجب الحصول على بيانات التدريب والتعامل معها وصيانتها بطريقة تحافظ على الأصول، والأمان، والجودة، والعدالة. إن القيام بذلك يفي بالواجبات القانونية ويقلل من مخاطر التحيز، والتسمم، أو انتهاكات الخصوصية التي قد تظهر أثناء التدريب وتؤثر على دورة حياة الذكاء الاصطناعي بأكملها.

---

### C1.1 مصدر بيانات التدريب

حافظ على سجل قابل للتحقق لجميع مجموعات البيانات، واقبل المصادر الموثوقة فقط، وسجل كل تغيير لأغراض التدقيق.

 #1.1.1    المستوى: 1    الدور: D/V
 تحقق من أن يتم الحفاظ على جرد محدث لكل مصدر بيانات تدريب (الأصل، المسؤول/المالك، الترخيص، طريقة الجمع، قيود الاستخدام المقصودة، وتاريخ المعالجة).
 #1.1.2    المستوى: 1    الدور: D/V
 تحقق من أن عمليات تدريب البيانات تستبعد الميزات أو السمات أو الحقول غير الضرورية (مثل البيانات الوصفية غير المستخدمة، المعلومات الشخصية الحساسة، بيانات الاختبار المسربة).
 #1.1.3    المستوى: 2    الدور: D/V
 تحقق من أن جميع التغييرات في مجموعة البيانات تخضع لإجراء موافقة مسجلة.
 #1.1.4    المستوى: 3    الدور: D/V
 تحقق من أن مجموعات البيانات أو مجموعات البيانات الجزئية تحمل علامة مائية أو بصمة حيثما كان ذلك ممكنًا.

---

### C1.2 أمان وسلامة بيانات التدريب

تقييد الوصول إلى بيانات التدريب، تشفيرها أثناء السكون وأثناء النقل، والتحقق من سلامتها لمنع التلاعب أو السرقة أو تسميم البيانات.

 #1.2.1    المستوى: 1    الدور: D/V
 تحقق من أن ضوابط الوصول تحمي تخزين بيانات التدريب وخطوط الأنابيب الخاصة بها.
 #1.2.2    المستوى: 2    الدور: D/V
 تحقق من تسجيل جميع عمليات الوصول إلى بيانات التدريب، بما في ذلك المستخدم، الوقت، والإجراء.
 #1.2.3    المستوى: 2    الدور: D/V
 تحقق من تشفير مجموعات بيانات التدريب أثناء النقل وعندما تكون مخزنة، باستخدام خوارزميات التشفير القياسية في الصناعة وممارسات إدارة المفاتيح.
 #1.2.4    المستوى: 2    الدور: D/V
 تأكد من استخدام التجزئات التشفيرية أو التوقيعات الرقمية لضمان سلامة البيانات أثناء تخزين ونقل بيانات التدريب.
 #1.2.5    المستوى: 2    الدور: D/V
 تحقق من تطبيق تقنيات الكشف الآلي للحماية من التعديلات أو الفساد غير المصرح به لبيانات التدريب.
 #1.2.6    المستوى: 2    الدور: D/V
 تحقق من أن بيانات التدريب القديمة تم مسحها أو إخفاء هويتها بأمان.
 #1.2.7    المستوى: 3    الدور: D/V
 تحقق من أن جميع إصدارات مجموعة بيانات التدريب معرّفة بشكل فريد، ومخزنة بشكل غير قابل للتغيير، وقابلة للتدقيق لدعم التراجع والتحليل الجنائي.

---

### جودة وسلامة وأمن توصيف بيانات التدريب C1.3

حماية التسميات وفرض مراجعة تقنية للبيانات الحرجة.

 #1.3.1    المستوى: 2    الدور: D/V
 تحقق من تطبيق تجزئات التشفير أو التوقيعات الرقمية على عناصر العلامة لضمان سلامتها وأصالتها.
 #1.3.2    المستوى: 2    الدور: D/V
 قم بالتحقق من أن واجهات وأنظمة الوسم تفرض ضوابط وصول قوية، وتحافظ على سجلات تدقيق مقاومة للعبث لجميع أنشطة الوسم، وتحمي ضد التعديلات غير المصرح بها.
 #1.3.3    المستوى: 3    الدور: D/V
 تحقق من أن المعلومات الحساسة في الملصقات يتم إزالتها أو إخفاء هويتها أو تشفيرها على مستوى حقل البيانات أثناء التخزين وفي أثناء النقل.

---

### جودة بيانات التدريب وضمان الأمان C1.4

اجمع بين التحقق الآلي، والفحوصات اليدوية العشوائية، والتصحيح المسجل لضمان موثوقية مجموعة البيانات.

 #1.4.1    المستوى: 1    الدور: D
 تحقق من أن الاختبارات الآلية تكتشف أخطاء التنسيق والقيم الفارغة عند كل إدخال أو تحويل بيانات هام.
 #1.4.2    المستوى: 2    الدور: D/V
 تأكد من أن خطوط أنابيب تدريب وتحسين نماذج اللغة الكبيرة (LLM) تدمج آليات لاكتشاف التسميم والتحقق من سلامة البيانات (مثل الطرق الإحصائية، كشف القيم الشاذة، تحليل التضمين) لتحديد الهجمات المحتملة بالتسميم (مثل قلب التسمية، إدخال محفز الباب الخلفي، أوامر تبديل الأدوار، هجمات الحالات المؤثرة) أو تلف البيانات غير المقصود في بيانات التدريب.
 #1.4.3    المستوى: 3    الدور: D/V
 تحقق من تنفيذ وضبط الدفاعات المناسبة، مثل التدريب العدائي (باستخدام أمثلة عدائية مولدة)، وتوسيع البيانات باستخدام مدخلات مضطربة، أو تقنيات التحسين القوية، للنماذج ذات الصلة بناءً على تقييم المخاطر.
 #1.4.4    المستوى: 2    الدور: D/V
 تحقق من أن التسميات المولدة تلقائيًا (مثلًا عبر نماذج اللغة الكبيرة أو الإشراف الضعيف) تخضع لعتبات الثقة وفحوصات التناسق لاكتشاف التسميات المخادعة أو المضللة أو ذات الثقة المنخفضة.
 #1.4.5    المستوى: 3    الدور: D
 تحقق من أن الاختبارات الآلية تكتشف انحرافات التسميات في كل عملية استيعاب أو تحويل بيانات كبير.

---

### C1.5 تتبع الأصول وتتبع المصدر البيانات

تتبع الرحلة الكاملة لكل نقطة بيانات من المصدر حتى إدخال النموذج لضمان إمكانية التدقيق والاستجابة للحوادث.

 #1.5.1    المستوى: 2    الدور: D/V
 تحقق من أن تسلسل كل نقطة بيانات، بما في ذلك جميع التحويلات، والتعزيزات، والدمج، مسجل ويمكن إعادة بناؤه.
 #1.5.2    المستوى: 2    الدور: D/V
 تحقق من أن سجلات النسب ثابتة، ومخزنة بأمان، ومتاحة للمراجعات.
 #1.5.3    المستوى: 2    الدور: D/V
 تحقق من أن تتبع الأصول يشمل البيانات الصناعية التي تم إنشاؤها عبر تقنيات الحفاظ على الخصوصية أو التوليد، وأن جميع البيانات الصناعية معلمة بوضوح وقابلة للتمييز عن البيانات الحقيقية طوال مسار المعالجة.

---

### المراجع

NIST AI Risk Management Framework
EU AI Act – Article 10: Data & Data Governance
MITRE ATLAS: Adversary Tactics for AI
Survey of ML Bias Mitigation Techniques – MDPI
Data Provenance & Lineage Best Practices – Nightfall AI
Data Labeling Quality Standards – LabelYourData
Training Data Poisoning Guide – Lakera.ai
CISA Advisory: Securing Data for AI Systems
ISO/IEC 23053: AI Management Systems Framework
IBM: What is AI Governance?
Google AI Principles
GDPR & AI Training Data – DataProtectionReport
Supply-Chain Security for AI Data – AppSOC
OpenAI Privacy Center – Data Deletion Controls
Adversarial ML Dataset – Kaggle

## التحقق من صحة إدخال المستخدم في C2

### هدف التحكم

التحقق الدقيق من مدخلات المستخدم هو خط الدفاع الأول ضد بعض الهجمات الأكثر ضررًا على أنظمة الذكاء الاصطناعي. يمكن لهجمات حقن التعليمات تجاوز تعليمات النظام، وتسريب البيانات الحساسة، أو توجيه النموذج نحو سلوك غير مسموح به. ما لم تكن هناك فلاتر مخصصة وتسلسلات تعليمات منظمة، تُظهر الأبحاث أن عمليات كسر الحماية "متعددة اللقطات" التي تستغل نوافذ السياق الطويلة جدًا ستكون فعالة. كما أن الهجمات الطفيفة التميتية العدائية—مثل استبدال الحروف المتشابهة بصريًا أو الكتابة باستخدام رموز لييت—يمكن أن تغير قرارات النموذج بصمت.

---

### C2.1 الدفاع ضد حقن الأوامر

حقن التوجيه هو أحد أكبر المخاطر التي تواجه أنظمة الذكاء الاصطناعي. تستخدم الدفاعات ضد هذه التكتيك مزيجًا من مرشحات الأنماط الثابتة، والمصنفات الديناميكية، وإنفاذ تسلسل التعليمات.

 #2.1.1    المستوى: 1    الدور: D/V
 تأكد من أن مدخلات المستخدم تتم فحصها مقابل مكتبة محدثة باستمرار لأنماط حقن التعليمات المعروفة (الكلمات المفتاحية لكسر الحماية، "تجاهل السابق"، سلاسل تمثيل الأدوار، الهجمات غير المباشرة على HTML/URL).
 #2.1.2    المستوى: 1    الدور: D/V
 تحقق من أن النظام يفرض تسلسلًا هرميًا للتعليمات حيث تتجاوز رسائل النظام أو المطور تعليمات المستخدم، حتى بعد توسيع نافذة السياق.
 #2.1.3    المستوى: 2    الدور: D/V
 تحقق من أن اختبارات التقييم العدائية (مثل طلبات "العديد من المحاولات" لفريق الاختراق) تُجرى قبل إصدار كل نموذج أو قالب طلب، مع تحديد حدود لمعدلات النجاح ومنع تلقائي للتراجعات.
 #2.1.4    المستوى: 2    الدور: D
 تحقق من أن المطالبات التي تنشأ من محتوى جهات خارجية (صفحات الويب، ملفات PDF، البريد الإلكتروني) يتم تنقيتها في سياق تحليل معزول قبل دمجها في المطلب الرئيسي.
 #2.1.5    المستوى: 3    الدور: D/V
 تحقق من أن جميع تحديثات قواعد تصفية الطلبات، وإصدارات نماذج المصنف، وتغييرات قائمة الحظر تحت تحكم بالإصدارات وقابلة للتدقيق.

---

### C2.2 مقاومة الأمثلة العدائية

نماذج معالجة اللغة الطبيعية (NLP) لا تزال عرضة للتشويشات الدقيقة على مستوى الأحرف أو الكلمات التي يغفلها البشر غالبًا، ولكن تميل النماذج إلى تصنيفها بشكل خاطئ.

 #2.2.1    المستوى: 1    الدور: D
 تحقق من أن خطوات تطبيع الإدخال الأساسية (Unicode NFC، تخطيط الرموز المتشابهة بصريًا، تقليم الفراغات) تتم قبل عملية التجزئة.
 #2.2.2    المستوى: 2    الدور: D/V
 تحقق من أن الكشف عن الشذوذ الإحصائي يشير إلى المدخلات التي تحتوي على مسافة تحرير غير عادية عالية مقارنة بمعايير اللغة، أو تكرارات زائدة في الرموز، أو مسافات تضمين غير طبيعية.
 #2.2.3    المستوى: 2    الدور: D
 تحقق من أن خط استدلال النموذج يدعم نسخ النماذج المحصنة بالتدريب العدائي الاختياري أو طبقات الدفاع (مثل العشوائية، التقطير الدفاعي) للنقاط النهائية عالية الخطورة.
 #2.2.4    المستوى: 2    الدور: V
 تحقق من عزل المدخلات المشبوهة المعادية في الحجر الصحي، وتسجيلها مع الحمولة الكاملة (بعد إزالة المعلومات الشخصية الحساسة).
 #2.2.5    المستوى: 3    الدور: D/V
 تحقق من أن مقاييس المتانة (معدل نجاح مجموعات الهجمات المعروفة) تُتابع على مر الزمن وأن التراجعات تُسبب توقف الإصدار.

---

### C2.3 التحقق من المخطط والنوع والطول

يمكن لهجمات الذكاء الاصطناعي التي تتضمن مدخلات مشوهة أو ضخمة الحجم أن تسبب أخطاء في التحليل، وانسكاب الأوامر عبر الحقول، واستنفاد الموارد. كما أن تطبيق التحقق الصارم من المخطط ضروري عند إجراء استدعاءات الأدوات الحتمية.

 #2.3.1    المستوى: 1    الدور: D
 تحقق من أن كل نقطة نهاية لاستدعاء API أو دالة تحدد مخطط إدخال صريح (مخطط JSON، أو Protobuf، أو ما يعادله متعدد الوضعيات) وأنه يتم التحقق من صحة الإدخالات قبل تجميع الطلب.
 #2.3.2    المستوى: 1    الدور: D/V
 تأكد من رفض المدخلات التي تتجاوز الحد الأقصى لعدد الرموز أو البايتات برسالة خطأ آمنة وعدم اقتطاعها بصمت أبدًا.
 #2.3.3    المستوى: 2    الدور: D/V
 تحقق من أن عمليات التحقق من النوع (مثل النطاقات الرقمية، وقيم التعداد، وأنواع MIME للصور/الصوت) تُفرض على جانب الخادم، وليس فقط في شفرة العميل.
 #2.3.4    المستوى: 2    الدور: D
 تحقق من أن المدققات الدلالية (مثل JSON Schema) تعمل في وقت ثابت لمنع هجمات الحرمان من الخدمة القائمة على الخوارزميات.
 #2.3.5    المستوى: 3    الدور: V
 تحقق من تسجيل حالات فشل التحقق مع مقتطفات حمولة محجوبة ورموز أخطاء غير غامضة للمساعدة في تصنيف الأمان.

---

### C2.4 فحص المحتوى والسياسة

يجب أن يكون المطورون قادرين على اكتشاف التعليمات البرمجية الصحيحة نحويًا التي تطلب محتوى غير مسموح به (مثل التعليمات غير المشروعة، وخطاب الكراهية، والنصوص المحمية بحقوق الطبع والنشر) ثم منع انتشارها.

 #2.4.1    المستوى: 1    الدور: D
 تحقق من أن مصنف المحتوى (صفر تدريب أو مدرب بدقة) يقيم كل إدخال من حيث العنف، وإيذاء النفس، والكراهية، والمحتوى الجنسي، والطلبات غير القانونية، مع إمكانية ضبط العتبات.
 #2.4.2    المستوى: 1    الدور: D/V
 تحقق من أن المدخلات التي تنتهك السياسات ستتلقى رفضات موحدة أو إكمالات آمنة بحيث لا تنتقل إلى استدعاءات نموذج اللغة الكبير اللاحقة.
 #2.4.3    المستوى: 2    الدور: D
 تحقق من أن نموذج الفرز أو مجموعة القواعد يتم إعادة تدريبه/تحديثه على الأقل ربع سنويًا، مع دمج أنماط الهروب من الحماية أو تجاوز السياسات التي تم ملاحظتها حديثًا.
 #2.4.4    المستوى: 2    الدور: D
 التحقق من أن عملية الفحص تحترم السياسات الخاصة بالمستخدمين (العمر، القيود القانونية الإقليمية) من خلال قواعد تعتمد على السمات ويتم حلها في وقت الطلب.
 #2.4.5    المستوى: 3    الدور: V
 تحقق من أن سجلات الفحص تتضمن درجات ثقة المصنف وعلامات فئة السياسة لربط SOC وإعادة تشغيل الفريق الأحمر في المستقبل.

---

### C2.5 تحديد معدل الإدخال ومنع سوء الاستخدام

يجب على المطورين منع سوء الاستخدام، استنفاد الموارد، والهجمات الآلية على أنظمة الذكاء الاصطناعي من خلال تحديد معدلات الإدخال واكتشاف أنماط الاستخدام الشاذة.

 #2.5.1    المستوى: 1    الدور: D/V
 تحقق من تطبيق حدود المعدل لكل مستخدم، لكل عنوان IP، ولكل مفتاح API لجميع نقاط النهاية الخاصة بالإدخال.
 #2.5.2    المستوى: 2    الدور: D/V
 تحقق من ضبط حدود معدلات الانفجار والمستمرة لمنع هجمات الحرمان من الخدمة وهجمات القوة الغاشمة.
 #2.5.3    المستوى: 2    الدور: D/V
 تحقق من أن أنماط الاستخدام الشاذة (مثل الطلبات المتكررة بسرعة، فيضان الإدخال) تؤدي إلى حظر آلي أو تصعيد تلقائي.
 #2.5.4    المستوى: 3    الدور: V
 تحقق من احتفاظ سجلات منع الإساءة ومراجعتها لاكتشاف أنماط الهجوم الناشئة.

---

### C2.6 التحقق من صحة الإدخال متعدد الوسائط

يجب أن تتضمن أنظمة الذكاء الاصطناعي تحققًا قويًا للمدخلات غير النصية (الصور، الصوت، الملفات) لمنع الحقن، التهرب، أو إساءة استخدام الموارد.

 #2.6.1    المستوى: 1    الدور: D
 تحقق من أن جميع المدخلات غير النصية (الصور، الصوت، الملفات) يتم التحقق من صحتها من حيث النوع والحجم والتنسيق قبل المعالجة.
 #2.6.2    المستوى: 2    الدور: D/V
 تحقق من فحص الملفات بحثًا عن البرمجيات الخبيثة والحمولات التشفيرية قبل الاستيعاب.
 #2.6.3    المستوى: 2    الدور: D/V
 تحقق من أن مدخلات الصورة/الصوت يتم فحصها للكشف عن الاضطرابات العدائية أو أنماط الهجوم المعروفة.
 #2.6.4    المستوى: 3    الدور: V
 تحقق من تسجيل حالات فشل التحقق من صحة المدخلات متعددة الأنماط وإثارتها لتنبيهات من أجل التحقيق.

---

### C2.7 مصدر الإدخال والنسبة

يجب أن تدعم أنظمة الذكاء الاصطناعي التدقيق، وتتبع الانتهاكات، والامتثال من خلال مراقبة ووضع العلامات على مصادر جميع مدخلات المستخدم.

 #2.7.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع مدخلات المستخدم موسومة بالبيانات الوصفية (معرّف المستخدم، الجلسة، المصدر، الطابع الزمني، عنوان الـ IP) عند الإدخال.
 #2.7.2    المستوى: 2    الدور: D/V
 تحقق من أن بيانات أصل المعلومات (provenance metadata) محفوظة وقابلة للتدقيق لجميع المدخلات المعالجة.
 #2.7.3    المستوى: 2    الدور: D/V
 تحقق من أن مصادر الإدخال الشاذة أو غير الموثوق بها يتم تمييزها وتخضع لفحص معزز أو للحظر.

---

### C2.8 الكشف التهديدي التكيفي في الوقت الحقيقي

يجب على المطورين استخدام أنظمة كشف التهديدات المتقدمة للذكاء الاصطناعي التي تتكيف مع أنماط الهجوم الجديدة وتوفر حماية في الوقت الحقيقي باستخدام مطابقة الأنماط المجمعّة.

 #2.8.1    المستوى: 1    الدور: D/V
 تحقق من أن أنماط اكتشاف التهديدات مدمجة في محركات تعبيرات منتظمة مُحسّنة لأداء عالي في التصفية اللحظية مع تأثير تأخير ضئيل.
 #2.8.2    المستوى: 1    الدور: D/V
 تحقق من أن أنظمة كشف التهديدات تحافظ على مكتبات نماذج منفصلة لفئات التهديد المختلفة (حقن المطالبات، المحتوى الضار، البيانات الحساسة، أوامر النظام).
 #2.8.3    المستوى: 2    الدور: D/V
 تحقق من أن الكشف التهديدي التكيفي يدمج نماذج تعلم الآلة التي تقوم بتحديث حساسية التهديد بناءً على تكرار الهجوم ومعدلات النجاح.
 #2.8.4    المستوى: 2    الدور: D/V
 تأكد من أن تدفقات استخبارات التهديدات في الوقت الحقيقي تقوم بتحديث مكتبات الأنماط تلقائيًا بتوقيعات الهجمات الجديدة ومؤشرات الاختراق (IOCs).
 #2.8.5    المستوى: 3    الدور: D/V
 تحقق من أن معدلات الإيجابيات الكاذبة في كشف التهديدات تتم مراقبتها باستمرار وأن تخصيص نمط الكشف يتم ضبطه تلقائيًا لتقليل التدخل في حالات الاستخدام الشرعية.
 #2.8.6    المستوى: 3    الدور: D/V
 تحقق من أن تحليل التهديدات السياقي يأخذ في الاعتبار مصدر الإدخال، وأنماط سلوك المستخدم، وتاريخ الجلسة لتحسين دقة الكشف.
 #2.8.7    المستوى: 3    الدور: D/V
 تحقق من مراقبة وتحسين مقاييس أداء كشف التهديدات (معدل الكشف، زمن استجابة المعالجة، استغلال الموارد) في الوقت الحقيقي.

---

### C2.9 خط أنابيب التحقق الأمني متعدد الوضعيات

يجب على المطورين توفير تحقق أمني للمدخلات النصية والصورية والصوتية وغير ذلك من أنماط مدخلات الذكاء الاصطناعي باستخدام أنواع محددة من كشف التهديدات وعزل الموارد.

 #2.9.1    المستوى: 1    الدور: D/V
 تحقق من أن لكل نمط إدخال مدققات أمان مخصصة مع أنماط تهديد موثقة (النص: حقن الأوامر، الصور: الستيجانوغرافيا، الصوت: هجمات الطيف الترددي) وعوائد الكشف.
 #2.9.2    المستوى: 2    الدور: D/V
 تحقق من أن المدخلات متعددة الوسائط تتم معالجتها في صناديق رمل معزولة بحدود موارد محددة (الذاكرة، وحدة المعالجة المركزية، وقت المعالجة) خاصة بكل نوع من أنواع الوسائط وموثقة في سياسات الأمان.
 #2.9.3    المستوى: 2    الدور: D/V
 تحقق من أن نظام كشف الهجمات عبر الوسائط يقيم الهجمات المنسقة التي تمتد عبر أنواع إدخال متعددة (مثل الحمولة المخفية في الصور جنبًا إلى جنب مع حقن الموجه في النص) باستخدام قواعد الترابط وتوليد التنبيهات.
 #2.9.4    المستوى: 3    الدور: D/V
 تحقق من أن فشل التحقق متعدد الوسائط يُحرّض تسجيلًا تفصيليًا يشمل جميع الوسائط المدخلة، ونتائج التحقق، ودرجات التهديد، وتحليل الترابط بصيغ تسجيل مُهيكلة لدمجها مع أنظمة إدارة معلومات الأحداث الأمنية (SIEM).
 #2.9.5    المستوى: 3    الدور: D/V
 تحقق من تحديث مصنِّفات المحتوى الخاصة بالنمط modality-specific وفقًا للجدولات الموثقة (بحد أدنى ربع سنوي) بأنماط التهديد الجديدة، والأمثلة العدائية، والمعايير الأداء التي يتم الحفاظ عليها فوق حدود الأساس.

---

### المراجع

LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security
Generative AI's Biggest Security Flaw Is Not Easy to Fix
Many-shot jailbreaking \ Anthropic
$PDF$ OpenAI GPT-4.5 System Card
Notebook for the CheckThat Lab at CLEF 2024
Mitigate jailbreaks and prompt injections – Anthropic
Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis
OWASP Top 10 for LLM Applications 2025 – WorldTech IT
OWASP Machine Learning Security Top Ten
Few words about AI Security – Jussi Metso
How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry
Easily enforcing valid JSON schema following – API
AI Safety + Cybersecurity R\&D Tracker – Fairly AI
Anthropic makes 'jailbreak' advance to stop AI models producing harmful results
Pattern matching filter rules - IBM
Real-time Threat Detection

## إدارة دورة حياة نموذج C3 والتحكم في التغيير

### هدف التحكم

يجب على أنظمة الذكاء الاصطناعي تنفيذ عمليات التحكم في التغيير التي تمنع التعديلات غير المصرح بها أو غير الآمنة على النماذج من الوصول إلى مرحلة الإنتاج. يضمن هذا التحكم سلامة النموذج طوال دورة حياته بالكامل--من التطوير مروراً بالنشر حتى الإيقاف النهائي--مما يتيح الاستجابة السريعة للحوادث ويحافظ على المساءلة عن جميع التغييرات.

الهدف الأمني الأساسي: وصول النماذج المخوّلة والمُثبتة فقط إلى مرحلة الإنتاج من خلال توظيف عمليات محكومة تحافظ على السلامة والتتبع وقابلية الاسترداد.

---

### C3.1 تفويض النموذج وسلامته

فقط النماذج المصرح بها والتي تم التحقق من سلامتها تصل إلى بيئات الإنتاج.

 #3.1.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع مصنوعات النموذج (الأوزان، التكوينات، محولات الرموز) موقعة تشفيرياً من قبل الجهات المخولة قبل النشر.
 #3.1.2    المستوى: 1    الدور: D/V
 تحقق من أن سلامة النموذج يتم التحقق منها عند وقت النشر وأن فشل التحقق من التوقيع يمنع تحميل النموذج.
 #3.1.3    المستوى: 2    الدور: D/V
 تحقق من أن سجلات مصدر النموذج تتضمن هوية الجهة المصرحة، وملخصات بيانات التدريب، ونتائج اختبار التحقق مع حالة النجاح/الفشل، وطابع زمني للإنشاء.
 #3.1.4    المستوى: 2    الدور: D/V
 تحقق من أن جميع نماذج النماذج تستخدم الترقيم الدلالي للإصدار (MAJOR.MINOR.PATCH) مع معايير موثقة تحدد متى يتم زيادة كل مكون من مكونات الإصدار.
 #3.1.5    المستوى: 2    الدور: V
 تحقق من أن تتبع التبعيات يحافظ على جرد في الوقت الحقيقي يمكّن من التعرف السريع على جميع الأنظمة المستهلكة.

---

### C3.2 تحقق النموذج والاختبار

يجب أن تجتاز النماذج اختبارات الأمان والسلامة المحددة قبل النشر.

 #3.2.1    المستوى: 1    الدور: D/V
 تحقق من أن النماذج تخضع لاختبارات أمان آلية تشمل التحقق من صحة المدخلات، وتنقية المخرجات، وتقييمات الأمان مع حدود قبول/رفض متفق عليها مسبقًا على مستوى المنظمة قبل النشر.
 #3.2.2    المستوى: 1    الدور: D/V
 تحقق من أن حالات فشل التحقق تمنع تلقائيًا نشر النموذج بعد الموافقة الصريحة بالتحايل من أشخاص مخولين مسبقًا وموثقين بمبررات تجارية.
 #3.2.3    المستوى: 2    الدور: V
 تحقق من أن نتائج الاختبار موقعة تشفيرياً ومرتبطة بشكل لا يمكن تغييره بتجزئة إصدار النموذج المحدد الذي يتم التحقق منه.
 #3.2.4    المستوى: 2    الدور: D/V
 تحقق من أن عمليات النشر الطارئة تتطلب تقييمًا موثقًا لمخاطر الأمان وموافقة من سلطة أمان محددة مسبقًا ضمن الأطر الزمنية المتفق عليها مسبقًا.

---

### C3.3 النشر المراقب والتراجع

يجب أن تكون عمليات نشر النماذج خاضعة للرقابة، والمراقبة، وقابلة للعكس.

 #3.3.1    المستوى: 1    الدور: D
 تحقق من أن عمليات النشر في بيئة الإنتاج تنفذ آليات طرح تدريجية (نشر الكناري، النشر الأزرق-الأخضر) مع مشغلات التراجع التلقائي استنادًا إلى معدلات الخطأ المتفق عليها مسبقًا، أو عتبات الكمون، أو معايير التنبيه الأمني.
 #3.3.2    المستوى: 1    الدور: D/V
 تحقق من أن قدرات التراجع تستعيد حالة النموذج الكاملة (الأوزان، التهيئات، الاعتماديات) بشكل ذري ضمن نوافذ زمنية تنظيمية محددة مسبقًا.
 #3.3.3    المستوى: 2    الدور: D/V
 تحقق من أن عمليات النشر تتحقق من صحة التواقيع التشفيرية وتحسب مجموعات التحقق من السلامة قبل تفعيل النموذج، مع فشل النشر في حال وجود أي عدم تطابق.
 #3.3.4    المستوى: 2    الدور: D/V
 تحقق من أن قدرات إيقاف تشغيل النموذج الطارئ يمكنها تعطيل نقاط نهاية النموذج ضمن أوقات استجابة محددة مسبقًا عبر قواطع الدائرة الآلية أو مفاتيح الإيقاف اليدوية.
 #3.3.5    المستوى: 2    الدور: V
 تحقق من الاحتفاظ بآثار التراجع (إصدارات النماذج السابقة، التكوينات، التبعيات) وفقًا لسياسات المنظمة باستخدام تخزين غير قابل للتغيير للاستجابة للحوادث.

---

### C3.4 تغيير المساءلة والتدقيق

يجب أن تكون جميع تغييرات دورة حياة النموذج قابلة للتتبع والتدقيق.

 #3.4.1    المستوى: 1    الدور: V
 تحقق من أن جميع تغييرات النموذج (النشر، التكوين، التقاعد) تولد سجلات تدقيق غير قابلة للتغيير تشمل طابع زمني، هوية الممثل المصادق عليه، نوع التغيير، والحالات قبل/بعد التغيير.
 #3.4.2    المستوى: 2    الدور: D/V
 تحقق من أن الوصول إلى سجل التدقيق يتطلب التفويض المناسب وأن جميع محاولات الوصول تُسجَّل بهوية المستخدم والطابع الزمني.
 #3.4.3    المستوى: 2    الدور: D/V
 تحقق من أن قوالب الموجهات ورسائل النظام تخضع للتحكم في الإصدارات في مستودعات git مع مراجعة وإقرار الشفرة الإلزامية من المراجعين المعينين قبل النشر.
 #3.4.4    المستوى: 2    الدور: V
 تحقق من أن سجلات التدقيق تتضمن تفاصيل كافية (تجزئات النماذج، لقطات التكوين، إصدارات التبعيات) لتمكين إعادة بناء كاملة لحالة النموذج لأي طابع زمني ضمن فترة الاحتفاظ.

---

### ممارسات التطوير الآمن C3.5

يجب أن تتبع عمليات تطوير النموذج والتدريب ممارسات آمنة لمنع التعرض للاختراق.

 #3.5.1    المستوى: 1    الدور: D
 تحقق من أن بيئات تطوير النموذج، والاختبار، والإنتاج مفصولة فعليًا أو منطقيًا. يجب ألا يكون لديهم بنية تحتية مشتركة، مع ضوابط وصول مميزة، ومخازن بيانات معزولة.
 #3.5.2    المستوى: 1    الدور: D
 تأكد من أن تدريب النموذج والتعديل الدقيق يتمان في بيئات معزولة مع وصول محكم إلى الشبكة.
 #3.5.3    المستوى: 1    الدور: D/V
 تحقق من صحة مصادر بيانات التدريب من خلال فحوصات النزاهة وتوثيقها عبر مصادر موثوقة مع وجود سجل موثق لسلسلة الحيازة قبل استخدامها في تطوير النموذج.
 #3.5.4    المستوى: 2    الدور: D
 تحقق من أن مواد تطوير النموذج (مثل المعاملات الفائقة، نصوص التدريب، ملفات التكوين) مخزنة في نظام التحكم في الإصدارات وتتطلب موافقة مراجعة الأقران قبل استخدامها في التدريب.

---

### C3.6 تقاعد النموذج وإيقاف تشغيله

يجب تقاعد النماذج بأمان عندما لا تكون هناك حاجة إليها أو عند تحديد مشكلات أمنية.

 #3.6.1    المستوى: 1    الدور: D
 تحقق من أن عمليات إنهاء النموذج تفحص تلقائيًا مخططات التبعيات، وتحدد جميع الأنظمة المستهلكة، وتوفر فترات إخطار مسبقة متفق عليها قبل إيقاف التشغيل.
 #3.6.2    المستوى: 1    الدور: D/V
 تحقق من أن عناصر نموذج التقاعد يتم مسحها بأمان باستخدام المسح التشفيري أو الكتابة المتعددة المرات وفقًا لسياسات الاحتفاظ بالبيانات الموثقة مع شهادات تدمير موثقة.
 #3.6.3    المستوى: 2    الدور: V
 تحقق من تسجيل أحداث تقاعد النموذج مع طابع زمني وهوية الفاعل، ويتم إلغاء توقيعات النموذج لمنع إعادة الاستخدام.
 #3.6.4    المستوى: 2    الدور: D/V
 تحقق من أن تقاعد النموذج الطارئ يمكنه تعطيل الوصول إلى النموذج ضمن الأطر الزمنية المحددة مسبقًا للاستجابة الطارئة من خلال مفاتيح إيقاف تشغيل آلية في حال تم اكتشاف ثغرات أمنية حرجة.

---

### المراجع

MLOps Principles
Securing AI/ML Ops – Cisco.com
Audit logs security: cryptographically signed tamper-proof logs
Machine Learning Model Versioning: Top Tools & Best Practices
AI Hygiene Starts with Models and Data Loaders – SEI Blog
How to handle versioning and rollback of a deployed ML model?
Reinforcement fine-tuning – OpenAI API
Auditing Machine Learning models: Governance, Data Security and …
Adversarial Training to Improve Model Robustness
What is AI adversarial robustness? – IBM Research
Exploring Data Provenance: Ensuring Data Integrity and Authenticity
MITRE ATLAS
AWS Prescriptive Guidance – Best practices for retiring applications …

## بنية C4 التحتية، وتأمين التكوين والنشر

### هدف التحكم

يجب تعزيز بنية تحتية الذكاء الاصطناعي ضد تصعيد الامتيازات، والتلاعب بسلسلة التوريد، والحركة الجانبية من خلال التهيئة الآمنة، والعزل أثناء التشغيل، وخطوط نشر موثوقة، والمراقبة الشاملة. لا تصل إلى البيئة الإنتاجية سوى مكونات وبنى تحتية مُصرح بها، ومتحققة من صحتها، من خلال عمليات مراقبة تضمن الحفاظ على الأمان، والسلامة، وقابلية التدقيق.

الهدف الأمني الأساسي: لا تصل مكونات البنية التحتية إلا بعد توقيعها تشفيريا وفحصها من الثغرات الأمنية إلى بيئة الإنتاج من خلال خطوط تحقق مؤتمتة تفرض سياسات الأمان وتحافظ على سجلات تدقيق غير قابلة للتغيير.

---

### C4.1 عزل بيئة وقت التشغيل

منع هروب الحاوية وتصعيد الامتيازات من خلال بدائيات عزل على مستوى النواة وضوابط الوصول الإلزامية.

 #4.1.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع حاويات الذكاء الاصطناعي تزيل جميع صلاحيات لينكس باستثناء CAP_SETUID و CAP_SETGID، والصلاحيات المطلوبة صراحة والموثقة في قواعد الأمان الأساسية.
 #4.1.2    المستوى: 1    الدور: D/V
 تحقق من أن ملفات تعريف seccomp تحظر كافة مكالمات النظام باستثناء تلك الموجودة في قوائم السماح المعتمدة مسبقًا، مع إنهاء الحاوية في حالة وجود مخالفات وتوليد تنبيهات أمان.
 #4.1.3    المستوى: 2    الدور: D/V
 تحقق من أن أحمال العمل الخاصة بالذكاء الاصطناعي تعمل بأنظمة ملفات جذرية قابلة للقراءة فقط، و tmpfs للبيانات المؤقتة، وحجوم مسماة للبيانات المستمرة مع فرض خيارات التثبيت noexec.
 #4.1.4    المستوى: 2    الدور: D/V
 تحقق من أن المراقبة التشغيلية القائمة على eBPF (مثل Falco، Tetragon، أو ما يعادلها) تكشف محاولات تصعيد الامتيازات وتقوم تلقائيًا بإنهاء العمليات المخالفة ضمن متطلبات وقت الاستجابة للمنظمة.
 #4.1.5    المستوى: 3    الدور: D/V
 تحقق من أن أحمال العمل ذات المخاطر العالية للذكاء الاصطناعي تُنفذ في بيئات معزولة على مستوى الأجهزة (Intel TXT، AMD SVM، أو عقد مخصصة على مستوى العتاد الخالص) مع التحقق من المصادقة.

---

### C4.2 خطوط أنابيب البناء والنشر الآمنة

ضمان سلامة التشفير وأمن سلسلة التوريد من خلال عمليات بناء قابلة لإعادة الإنتاج والتحققات الموقعة.

 #4.2.1    المستوى: 1    الدور: D/V
 تحقق من أن البنية التحتية كرمز تُفحص باستخدام أدوات (tfsec، Checkov، أو Terrascan) في كل عملية التزام، مع منع الدمج في حال وجود نتائج ذات شدة حرجة أو عالية.
 #4.2.2    المستوى: 1    الدور: D/V
 تحقق من أن بناء الحاويات قابل للتكرار مع وجود تجزئات SHA256 متماثلة عبر عمليات البناء المختلفة وقم بإنشاء شهادات إثبات منشأ SLSA المستوى 3 موقعة بواسطة Sigstore.
 #4.2.3    المستوى: 2    الدور: D/V
 تحقق من أن صور الحاويات تحتوي على ملفات CycloneDX أو SPDX SBOMs وموقعة باستخدام Cosign قبل دفعها إلى السجل، مع رفض الصور غير الموقعة عند النشر.
 #4.2.4    المستوى: 2    الدور: D/V
 تأكد من أن خطوط أنابيب CI/CD تستخدم رموز OIDC من HashiCorp Vault أو أدوار AWS IAM أو الهوية المدارة من Azure بأعمار لا تتجاوز حدود سياسة الأمان التنظيمية.
 #4.2.5    المستوى: 2    الدور: D/V
 تحقق من أن توقيعات Cosign و SLSA provenance يتم التحقق منها أثناء عملية النشر قبل تنفيذ الحاوية وأن أخطاء التحقق تؤدي إلى فشل النشر.
 #4.2.6    المستوى: 2    الدور: D/V
 تحقق من أن بيئات البناء تعمل في حاويات أو آلات افتراضية مؤقتة بدون تخزين دائم وعزل الشبكة عن الشبكات الافتراضية الخاصة للإنتاج (VPCs).

---

### C4.3 أمن الشبكة والتحكم في الوصول

قم بتنفيذ شبكات الثقة الصفرية باستخدام سياسات الرفض الافتراضي والاتصالات المشفرة.

 #4.3.1    المستوى: 1    الدور: D/V
 تحقق من أن Kubernetes NetworkPolicies أو أي ما يعادلها تنفذ سياسة الحظر الافتراضي للدخول/الخروج مع قواعد سماح صريحة للمنافذ المطلوبة (443، 8080، إلخ).
 #4.3.2    المستوى: 1    الدور: D/V
 تحقق من أن بروتوكول SSH (المنفذ 22)، وRDP (المنفذ 3389)، ونقاط نهاية بيانات التعريف السحابية (169.254.169.254) محظورة أو تتطلب مصادقة تعتمد على الشهادات.
 #4.3.3    المستوى: 2    الدور: D/V
 تحقق من أن حركة المرور الصادرة يتم تصفيتها عبر وكلاء HTTP/HTTPS (Squid، Istio، أو بوابات NAT السحابية) مع قوائم السماح بالنطاقات وتسجيل الطلبات المحظورة.
 #4.3.4    المستوى: 2    الدور: D/V
 تحقق من أن التواصل بين الخدمات يستخدم بروتوكول TLS المتبادل مع تدوير الشهادات وفقًا لسياسة المنظمة وتطبيق التحقق من الشهادات (بدون استخدام علامات تخطي التحقق).
 #4.3.5    المستوى: 2    الدور: D/V
 تحقق من أن بنية الذكاء الاصطناعي تعمل في شبكات خاصة افتراضية مخصصة (VPCs/VNets) بدون وصول مباشر إلى الإنترنت وتتواصل فقط من خلال بوابات NAT أو مضيفي الباستيون.

---

### C4.4 إدارة الأسرار والمفاتيح التشفيرية

حماية بيانات الاعتماد من خلال التخزين المعتمد على الأجهزة وتدوير تلقائي بوصول قائم على الثقة الصفرية.

 #4.4.1    المستوى: 1    الدور: D/V
 تحقق من تخزين الأسرار في HashiCorp Vault أو AWS Secrets Manager أو Azure Key Vault أو Google Secret Manager مع التشفير أثناء التخزين باستخدام AES-256.
 #4.4.2    المستوى: 1    الدور: D/V
 تحقق من أن مفاتيح التشفير يتم توليدها في وحدات الأمان المادي (HSM) بمستوى FIPS 140-2 المستوى 2 (مثل AWS CloudHSM وAzure Dedicated HSM) مع تدوير المفاتيح وفقًا لسياسة التشفير التنظيمية.
 #4.4.3    المستوى: 2    الدور: D/V
 تحقق من أن تدوير أسرار النظام يتم تلقائيًا مع نشر بدون توقف وأن التدوير الفوري يتم تحفيزه بواسطة تغييرات في الأفراد أو حوادث أمان.
 #4.4.4    المستوى: 2    الدور: D/V
 تحقق من فحص صور الحاويات باستخدام أدوات (GitLeaks، TruffleHog، أو detect-secrets) لحظر عمليات البناء التي تحتوي على مفاتيح API أو كلمات مرور أو شهادات.
 #4.4.5    المستوى: 2    الدور: D/V
 تحقق من أن الوصول إلى أسرار الإنتاج يتطلب التحقق بخطوتين باستخدام رموز الأجهزة (YubiKey، FIDO2) وأنه يتم تسجيله بواسطة سجلات تدقيق غير قابلة للتغيير مع هويات المستخدم والطوابع الزمنية.
 #4.4.6    المستوى: 2    الدور: D/V
 تحقق من أن الأسرار مُحقنة عبر أسرار Kubernetes أو وحدات التخزين المُركبة أو حاويات التهيئة، وتأكد من عدم تضمين الأسرار أبدًا في متغيرات البيئة أو الصور.

---

### C4.5 تعقيم وتحقيق عبء عمل الذكاء الاصطناعي

عزل نماذج الذكاء الاصطناعي غير الموثوقة في بيئات معزولة آمنة مع تحليل سلوكي شامل.

 #4.5.1    المستوى: 1    الدور: D/V
 تحقق من أن نماذج الذكاء الاصطناعي الخارجية تُنفذ في gVisor أو microVMs (مثل Firecracker، CrossVM)، أو حاويات Docker مع خيارات --security-opt=no-new-privileges وعلم --read-only.
 #4.5.2    المستوى: 1    الدور: D/V
 تحقق من أن بيئات الصندوق الرملي لا تملك اتصالًا بالشبكة (--network=none) أو أنها تتيح فقط الوصول إلى المضيف المحلي مع حظر جميع الطلبات الخارجية بواسطة قواعد iptables.
 #4.5.3    المستوى: 2    الدور: D/V
 تحقق من أن التحقق من صحة نموذج الذكاء الاصطناعي يشمل اختبار الفريق الأحمر الآلي مع تغطية اختبار محددة تنظيميًا وتحليل السلوك لاكتشاف الأبواب الخلفية.
 #4.5.4    المستوى: 2    الدور: D/V
 تحقق من أنه قبل ترقية نموذج الذكاء الاصطناعي إلى بيئة الإنتاج، يتم توقيع نتائج البيئة المعزولة (sandbox) توقيعًا تشفيريًا من قبل موظفي الأمان المخولين ويتم تخزينها في سجلات تدقيق غير قابلة للتغيير.
 #4.5.5    المستوى: 2    الدور: D/V
 تحقق من أنه يتم تدمير بيئات الصندوق الرملي وإعادة إنشائها من الصور الذهبية بين التقييمات مع تنظيف كامل لنظام الملفات والذاكرة.

---

### C4.6 مراقبة أمان البنية التحتية

المسح المستمر والبقاء تحت المراقبة للبنية التحتية مع التصحيح التلقائي والتنبيه الفوري.

 #4.6.1    المستوى: 1    الدور: D/V
 تحقق من مسح صور الحاويات وفقًا للجداول التنظيمية، مع حظر النشر في حال وجود ثغرات حرجة بناءً على عتبات المخاطر التنظيمية.
 #4.6.2    المستوى: 1    الدور: D/V
 تحقق من أن البنية التحتية تلتزم بمعايير CIS أو ضوابط NIST 800-53 وفقًا لعتبات الامتثال المحددة تنظيميًا، مع تنفيذ الإصلاح التلقائي للفحوصات التي فشلت.
 #4.6.3    المستوى: 2    الدور: D/V
 تحقق من أنه تم تصحيح الثغرات الأمنية ذات الشدة العالية وفقًا لجداول إدارة المخاطر التنظيمية مع وجود إجراءات طارئة للثغرات الأمنية (CVEs) التي يتم استغلالها بنشاط.
 #4.6.4    المستوى: 2    الدور: V
 تحقق من أن تنبيهات الأمان تتكامل مع منصات SIEM (مثل Splunk أو Elastic أو Sentinel) باستخدام تنسيقات CEF أو STIX/TAXII مع الإثراء التلقائي.
 #4.6.5    المستوى: 3    الدور: V
 تحقق من تصدير مقاييس البنية التحتية إلى أنظمة المراقبة (Prometheus، DataDog) مع لوحات معلومات مستوى خدمة الاتفاقية (SLA) والتقارير التنفيذية.
 #4.6.6    المستوى: 2    الدور: D/V
 تحقق من اكتشاف انحراف التكوين باستخدام الأدوات (Chef InSpec, AWS Config) وفقًا لمتطلبات المراقبة الخاصة بالمنظمة مع التراجع التلقائي عن التغييرات غير المصرح بها.

---

### إدارة موارد بنية تحتية الذكاء الاصطناعي C4.7

منع هجمات استنفاد الموارد وضمان التوزيع العادل للموارد من خلال الحصص والمراقبة.

 #4.7.1    المستوى: 1    الدور: D/V
 تحقق من أن استخدام GPU/TPU يتم مراقبته مع تفعيل التنبيهات عند الوصول إلى العتبات التي تحددها المنظمة، وأن يتم تفعيل التحجيم التلقائي أو موازنة الحمل بناءً على سياسات إدارة السعة.
 #4.7.2    المستوى: 1    الدور: D/V
 تأكد من جمع مقاييس عبء العمل للذكاء الاصطناعي (زمن استجابة الاستدلال، معدل الإنتاجية، معدلات الخطأ) وفقًا لمتطلبات المراقبة التنظيمية وربطها باستخدام البنية التحتية.
 #4.7.3    المستوى: 2    الدور: D/V
 تحقق من أن Kubernetes ResourceQuotas أو ما يعادلها يحد من الأحمال الفردية وفقًا لسياسات تخصيص الموارد التنظيمية مع فرض الحدود الصارمة.
 #4.7.4    المستوى: 2    الدور: V
 تحقق من أن مراقبة التكلفة تتتبع الإنفاق لكل عبء عمل / مستأجر مع تنبيهات بناءً على حدود ميزانية المنظمة وضوابط آلية لتجاوز الميزانية.
 #4.7.5    المستوى: 3    الدور: V
 تحقق من أن تخطيط السعة يستخدم البيانات التاريخية مع فترات التنبؤ المحددة تنظيميًا وتوفير الموارد الآلي استنادًا إلى أنماط الطلب.
 #4.7.6    المستوى: 2    الدور: D/V
 تحقق من أن استنفاد الموارد يؤدي إلى تشغيل قواطع الدائرة وفقًا لمتطلبات الاستجابة التنظيمية، بما في ذلك تحديد المعدل بناءً على سياسات السعة وعزل حمل العمل.

---

### C4.8 فصل البيئة و ضوابط الترويج

فرض حدود بيئية صارمة من خلال بوابات ترقية آلية والتحقق الأمني.

 #4.8.1    المستوى: 1    الدور: D/V
 تحقق من أن بيئات التطوير/الاختبار/الإنتاج تعمل في شبكات VPC/VNet منفصلة بدون أدوار IAM مشتركة، أو مجموعات أمان، أو اتصال شبكي مشترك.
 #4.8.2    المستوى: 1    الدور: D/V
 تحقق من أن ترقية البيئة تتطلب موافقة من الأشخاص المخولين المحددين تنظيميًا باستخدام التوقيعات التشفيرية ومسارات التدقيق غير القابلة للتغيير.
 #4.8.3    المستوى: 2    الدور: D/V
 تحقق من أن بيئات الإنتاج تمنع الوصول عبر SSH، وتعطل نقاط النهاية الخاصة بالتصحيح، وتشترط طلبات التغيير مع متطلبات الإشعار المسبق التنظيمي باستثناء حالات الطوارئ.
 #4.8.4    المستوى: 2    الدور: D/V
 تحقق من أن تغييرات البنية التحتية ككود تتطلب مراجعة من قبل الزملاء مع اختبار آلي وفحص أمني قبل الدمج في الفرع الرئيسي.
 #4.8.5    المستوى: 2    الدور: D/V
 تحقق من أن بيانات غير الإنتاجية مُجهولة الهوية وفقًا لمتطلبات الخصوصية التنظيمية، أو توليد بيانات تركيبية، أو تغطية كاملة للبيانات مع التحقق من إزالة معلومات التعريف الشخصية (PII).
 #4.8.6    المستوى: 2    الدور: D/V
 تحقق من أن بوابات الترقية تشمل اختبارات الأمان الآلية (SAST، DAST، فحص الحاويات) مع ضرورة عدم وجود أية نتائج حرجة (CRITICAL) للموافقة.

---

### النسخ الاحتياطي والاستعادة لبنية C4.9 التحتية

ضمان مرونة البنية التحتية من خلال النسخ الاحتياطية الآلية، وإجراءات الاسترداد المختبرة، وقدرات استعادة البيانات بعد الكوارث.

 #4.9.1    المستوى: 1    الدور: D/V
 تحقق من أن تكوينات البنية التحتية يتم نسخها احتياطيًا وفقًا لجداول النسخ الاحتياطي التنظيمية إلى مناطق جغرافية منفصلة مع تنفيذ استراتيجية النسخ الاحتياطي 3-2-1.
 #4.9.2    المستوى: 2    الدور: D/V
 تحقق من أن أنظمة النسخ الاحتياطي تعمل في شبكات معزولة مع بيانات اعتماد منفصلة وتخزين مفصول جويًا لحماية من برامج الفدية.
 #4.9.3    المستوى: 2    الدور: V
 التحقق من اختبار وإثبات صحة إجراءات الاسترداد من خلال الاختبارات الآلية وفقًا لجدولات المنظمة مع تحقيق أهداف وقت استعادة التشغيل (RTO) ونقطة استعادة البيانات (RPO) لتلبية متطلبات المنظمة.
 #4.9.4    المستوى: 3    الدور: V
 تحقق من أن استعادة الكوارث تشمل كتيبات تشغيل مخصصة للذكاء الاصطناعي تحتوي على استعادة أوزان النماذج، وإعادة بناء عنقود GPU، ورسم خرائط الاعتماديات للخدمات.

---

### الامتثال والحوكمة للبنية التحتية C4.10

الحفاظ على الامتثال التنظيمي من خلال التقييم المستمر، والتوثيق، والضوابط الآلية.

 #4.10.1    المستوى: 2    الدور: D/V
 تحقق من أن امتثال البنية التحتية يتم تقييمه وفقًا للجداول الزمنية التنظيمية مقابل ضوابط SOC 2 أو ISO 27001 أو FedRAMP مع جمع الأدلة تلقائيًا.
 #4.10.2    المستوى: 2    الدور: V
 تحقق من أن وثائق البنية التحتية تتضمن مخططات الشبكة، وخرائط تدفق البيانات، ونماذج التهديدات المحدثة وفقًا لمتطلبات إدارة التغيير التنظيمي.
 #4.10.3    المستوى: 3    الدور: D/V
 تأكد من أن تغييرات البنية التحتية تخضع لتقييم تلقائي لتأثير الامتثال مع سير عمل الموافقات التنظيمية للتعديلات عالية المخاطر.

---

### C4.11 أمان أجهزة الذكاء الاصطناعي

تأمين مكونات الأجهزة الخاصة بالذكاء الاصطناعي بما في ذلك وحدات معالجة الرسوميات (GPUs)، ووحدات معالجة Tensor (TPUs)، والمسرعات المخصصة للذكاء الاصطناعي.

 #4.11.1    المستوى: 2    الدور: D/V
 تحقق من أن برنامج تشغيل معجلات الذكاء الاصطناعي (BIOS بطاقة الرسوميات، برنامج تشغيل TPU) يتم التحقق منه باستخدام توقيعات تشفيرية ويتم تحديثه وفقًا لجداول زمنية لإدارة تصحيح البرامج في المؤسسة.
 #4.11.2    المستوى: 2    الدور: D/V
 تحقق من أن سلامة مسرّع الذكاء الاصطناعي يتم التحقق منها بواسطة إثبات الأجهزة باستخدام TPM 2.0 أو Intel TXT أو AMD SVM قبل تنفيذ عبء العمل.
 #4.11.3    المستوى: 2    الدور: D/V
 تحقق من أن ذاكرة وحدة معالجة الرسومات (GPU) معزولة بين أعباء العمل باستخدام SR-IOV، MIG (GPU متعدد الحالات)، أو تقسيم الأجهزة المعادل مع تعقيم الذاكرة بين الوظائف.
 #4.11.4    المستوى: 3    الدور: V
 تحقق من أن سلسلة توريد أجهزة الذكاء الاصطناعي تشمل التحقق من المصدر باستخدام شهادات الشركة المصنعة والتحقق من صحة التغليف المقاومة للعبث.
 #4.11.5    المستوى: 3    الدور: D/V
 تحقق من أن وحدات أمان الأجهزة (HSMs) تحمي أوزان نماذج الذكاء الاصطناعي والمفاتيح التشفيرية بشهادة FIPS 140-2 المستوى 3 أو معيار Common Criteria EAL4+.

---

### C4.12 البنية التحتية للذكاء الاصطناعي الطرفي والموزع

نشرات الذكاء الاصطناعي الموزعة الآمنة بما في ذلك الحوسبة الطرفية، والتعلم الفيدرالي، والهياكل متعددة المواقع.

 #4.12.1    المستوى: 2    الدور: D/V
 تحقق من أن أجهزة الذكاء الاصطناعي الطرفية تقوم بالمصادقة على البنية التحتية المركزية باستخدام بروتوكول TLS المتبادل مع شهادات الأجهزة التي يتم تدويرها وفقًا لسياسة إدارة الشهادات التنظيمية.
 #4.12.2    المستوى: 2    الدور: D/V
 تحقق من أن أجهزة الطرفية تنفذ الإقلاع الآمن باستخدام توقيعات معتمدة وحماية من التراجع لمنع هجمات تخفيض إصدار البرنامج الثابت.
 #4.12.3    المستوى: 3    الدور: D/V
 تحقق من أن تنسيق الذكاء الاصطناعي الموزع يستخدم خوارزميات توافق آراء مقاومة للأخطاء البيزنطية مع التحقق من المشاركين والكشف عن العقد الخبيثة.
 #4.12.4    المستوى: 3    الدور: D/V
 تحقق من أن الاتصال بين الحافة والسحابة يشمل تحديد عرض النطاق الترددي، وضغط البيانات، وقدرات العمل في وضع عدم الاتصال مع تخزين محلي آمن.

---

### C4.13 أمان البنية التحتية متعددة السحب والهجينة

تأمين أحمال عمل الذكاء الاصطناعي عبر مزودات السحابة المتعددة ونشر السحابة الهجينة على المواقع المحلية.

 #4.13.1    المستوى: 2    الدور: D/V
 تحقق من أن عمليات نشر الذكاء الاصطناعي متعددة السحابات تستخدم اتحاد الهوية المستقل عن السحابة (OIDC، SAML) مع إدارة سياسة مركزية عبر المزودين.
 #4.13.2    المستوى: 2    الدور: D/V
 تأكد من أن نقل البيانات عبر السحابات يستخدم التشفير من الطرف إلى الطرف باستخدام مفاتيح يديرها العميل، مع فرض ضوابط إقامة البيانات حسب الولاية القضائية.
 #4.13.3    المستوى: 2    الدور: D/V
 تحقق من أن أحمال عمل الذكاء الاصطناعي في السحابة الهجينة تطبق سياسات أمان متسقة عبر البيئات المحلية والسحابية مع مراقبة موحدة وتنبيه.
 #4.13.4    المستوى: 3    الدور: V
 تحقق من أن منع التقييد بمزود السحابة يتضمن بنية تحتية قابلة للنقل ككود، وواجهات برمجة تطبيقات موحدة، وقدرات تصدير البيانات مع أدوات تحويل التنسيق.
 #4.13.5    المستوى: 3    الدور: V
 تحقق من أن تحسين التكلفة في البيئات متعددة السحابات يشمل ضوابط أمان تمنع انتشار الموارد غير المرغوب فيه وكذلك رسوم نقل البيانات غير المصرح بها بين السحابات.

---

### C4.14 أتمتة البنية التحتية وأمان GitOps

تأمين خطوط أنابيب الأتمتة للبنية التحتية وتدفقات العمل GitOps لإدارة بنية تحتية الذكاء الاصطناعي.

 #4.14.1    المستوى: 2    الدور: D/V
 تحقق من أن مستودعات GitOps تتطلب توقيع الالتزامات باستخدام مفاتيح GPG وقواعد حماية الفروع التي تمنع الدفع المباشر إلى الفروع الرئيسية.
 #4.14.2    المستوى: 2    الدور: D/V
 تحقق من أن أتمتة البنية التحتية تشمل الكشف عن الانحراف مع قدرات الإصلاح التلقائي والتراجع التي يتم تفعيلها وفقًا لمتطلبات استجابة المنظمة للتغييرات غير المصرح بها.
 #4.14.3    المستوى: 2    الدور: D/V
 تحقق من أن توفير البنية التحتية الآلي يتضمن التحقق من سياسات الأمان مع حظر النشر للتكوينات غير المتوافقة.
 #4.14.4    المستوى: 2    الدور: D/V
 تحقق من أن أسرار أتمتة البنية التحتية تُدار من خلال مشغلات الأسرار الخارجية (External Secrets Operator، Bank-Vaults) مع التدوير التلقائي.
 #4.14.5    المستوى: 3    الدور: V
 تحقق من أن البنية التحتية ذات القدرة على الشفاء الذاتي تتضمن ترابط أحداث الأمان مع استجابة الحوادث الآلية وسير عمل إشعارات أصحاب المصلحة.

---

### C4.15 أمن البنية التحتية المقاومة للحوسبة الكمومية

تحضير بنية تحتية للذكاء الاصطناعي لمواجهة تهديدات الحوسبة الكمومية من خلال التشفير ما بعد الكم والبروتوكولات الآمنة الكمومية.

 #4.15.1    المستوى: 3    الدور: D/V
 تحقق من أن بنية الذكاء الاصطناعي تنفذ خوارزميات التشفير ما بعد الكم المعتمدة من NIST (CRYSTALS-Kyber، CRYSTALS-Dilithium، SPHINCS+) لتبادل المفاتيح والتوقيعات الرقمية.
 #4.15.2    المستوى: 3    الدور: D/V
 تحقق من تنفيذ أنظمة توزيع المفاتيح الكمومية (QKD) لاتصالات الذكاء الاصطناعي عالية الأمان مع بروتوكولات إدارة المفاتيح الآمنة كموميًا.
 #4.15.3    المستوى: 3    الدور: D/V
 تحقق من أن أُطُر المرونة التشفيرية تمكّن من الترحيل السريع إلى خوارزميات ما بعد الكم الجديدة مع تدوير تلقائي للشهادات والمفاتيح.
 #4.15.4    المستوى: 3    الدور: V
 تحقق من أن نمذجة التهديدات الكمومية تقوم بتقييم ضعف بنية الذكاء الاصطناعي التحتية تجاه الهجمات الكمومية مع وجود جداول زمنية موثقة للترحيل وتقييمات للمخاطر.
 #4.15.5    المستوى: 3    الدور: D/V
 تحقق من أن أنظمة التشفير الهجينة الكلاسيكية-الكمومية توفر دفاعًا متعدد الطبقات خلال فترة الانتقال الكمومي مع مراقبة الأداء.

---

### C4.16 الحوسبة السرية والمناطق المحمية الآمنة

قم بحماية أعباء عمل الذكاء الاصطناعي وأوزان النماذج باستخدام بيئات التنفيذ الموثوقة المعتمدة على الأجهزة وتقنيات الحوسبة السرية.

 #4.16.1    المستوى: 3    الدور: D/V
 التحقق من أن نماذج الذكاء الاصطناعي الحساسة تعمل داخل مناطق Intel SGX الآمنة، أو AMD SEV-SNP، أو ARM TrustZone مع الذاكرة المشفرة والتحقق من الشهادة.
 #4.16.2    المستوى: 3    الدور: D/V
 تحقق من أن الحاويات السرية (Kata Containers، gVisor مع الحوسبة السرية) تعزل أحمال العمل الخاصة بالذكاء الاصطناعي باستخدام تشفير الذاكرة المعزز بالأجهزة.
 #4.16.3    المستوى: 3    الدور: D/V
 تحقق من أن التحقق البعيد يؤكد سلامة الحاوية قبل تحميل نماذج الذكاء الاصطناعي مع إثبات تشفير أصالة بيئة التنفيذ.
 #4.16.4    المستوى: 3    الدور: D/V
 تحقق من أن خدمات الاستدلال الخاصة بالذكاء الاصطناعي السرية تمنع استخراج النموذج من خلال الحوسبة المشفرة باستخدام أوزان نموذج مختومة والتنفيذ المحمي.
 #4.16.5    المستوى: 3    الدور: D/V
 تحقق من أن تنظيم بيئة التنفيذ الموثوقة يدير دورة حياة المنطقة الآمنة باستخدام التحقق عن بُعد وقنوات الاتصال المشفرة.
 #4.16.6    المستوى: 3    الدور: D/V
 تحقق من أن الحوسبة متعددة الأطراف الآمنة (SMPC) تتيح تدريب الذكاء الاصطناعي التعاوني دون الكشف عن مجموعات البيانات الفردية أو معلمات النموذج.

---

### C4.17 بنية تحتية لإثبات المعرفة الصفرية

تنفيذ أنظمة الإثبات بدون معرفة للتحقق والمصادقة على الذكاء الاصطناعي مع الحفاظ على الخصوصية دون الكشف عن المعلومات الحساسة.

 #4.17.1    المستوى: 3    الدور: D/V
 تحقق من أن إثباتات المعرفة الصفرية (ZK-SNARKs، ZK-STARKs) تقوم بالتحقق من سلامة نموذج الذكاء الاصطناعي وأصول التدريب دون الكشف عن أوزان النموذج أو بيانات التدريب.
 #4.17.2    المستوى: 3    الدور: D/V
 تحقق من أن أنظمة المصادقة القائمة على الإثباتات الصفرية المعرفة (ZK) تمكّن من التحقق من هوية المستخدم مع الحفاظ على الخصوصية لخدمات الذكاء الاصطناعي دون الكشف عن معلومات مرتبطة بالهوية.
 #4.17.3    المستوى: 3    الدور: D/V
 تحقق من أن بروتوكولات التقاطع الخاص للمجموعات (PSI) تتيح مطابقة بيانات آمنة للذكاء الاصطناعي الفيدرالي دون كشف مجموعات البيانات الفردية.
 #4.17.4    المستوى: 3    الدور: D/V
 تحقق من أن أنظمة تعلم الآلة ذات المعرفة الصفرية (ZKML) تمكن استنتاجات الذكاء الاصطناعي القابلة للتحقق مع إثبات تشفير للحساب الصحيح.
 #4.17.5    المستوى: 3    الدور: D/V
 تحقق من أن ZK-rollups توفر معالجة معاملات الذكاء الاصطناعي القابلة للتوسع والمحافظة على الخصوصية من خلال التحقق الدفعي وتقليل العبء الحسابي.

---

### C4.18 منع هجمات القنوات الجانبية

حماية بنية تحتية الذكاء الاصطناعي من هجمات القناة الجانبية القائمة على التوقيت والطاقة والكهرومغناطيسية والتخزين المؤقت والتي قد تسرب معلومات حساسة.

 #4.18.1    المستوى: 3    الدور: D/V
 تحقق من أن توقيت استدلال الذكاء الاصطناعي يتم تطبيعه باستخدام خوارزميات ذات زمن ثابت والتعبئة لمنع هجمات استخراج النموذج المعتمدة على التوقيت.
 #4.18.2    المستوى: 3    الدور: D/V
 تحقق من أن حماية تحليل القدرة تشمل حقن الضوضاء، تصفية خط الطاقة، وأنماط تنفيذ عشوائية لأجهزة الذكاء الاصطناعي.
 #4.18.3    المستوى: 3    الدور: D/V
 تحقق من أن التخفيف من قنوات التلاعب الجانبية المعتمدة على الذاكرة المخبأة يستخدم تقسيم الذاكرة المخبأة، والتعشوُب، وتعليمات التفريغ لمنع تسرب المعلومات.
 #4.18.4    المستوى: 3    الدور: D/V
 تحقق من أن حماية الانبعاثات الكهرومغناطيسية تشمل الحماية بالتظليل، وترشيح الإشارات، والمعالجة العشوائية لمنع الهجمات من نوع TEMPEST.
 #4.18.5    المستوى: 3    الدور: D/V
 تحقق من أن دفاعات القنوات الجانبية للميكروهندسة تشمل ضوابط التنفيذ التكهنية وتشويش نمط الوصول إلى الذاكرة.

---

### C4.19 أمان الأجهزة العصبية والتخصصية للذكاء الاصطناعي

تأمين معماريات أجهزة الذكاء الاصطناعي الناشئة بما في ذلك الرقاقات العصبية، وFPGAs، والدوائر المتكاملة المخصصة (ASICs)، وأنظمة الحوسبة البصرية.

 #4.19.1    المستوى: 3    الدور: D/V
 تحقق من أن أمان الشريحة العصبية يشمل تشفير نمط الشُظايا، حماية أوزان المشابك، والتحقق من قواعد التعلم المعتمدة على العتاد.
 #4.19.2    المستوى: 3    الدور: D/V
 تحقق من أن معجلات الذكاء الاصطناعي القائمة على FPGA تقوم بتنفيذ تشفير تدفقات البت، وآليات مضادة للتلاعب، وتحميل تكوين آمن مع تحديثات معتمدة.
 #4.19.3    المستوى: 3    الدور: D/V
 تحقق من أن أمان الـ ASIC المخصص يتضمن معالجات أمان مدمجة على الشريحة، وجذر ثقة مادي، وتخزين مفاتيح آمن مع اكتشاف التلاعب.
 #4.19.4    المستوى: 3    الدور: D/V
 تحقق من أن أنظمة الحوسبة البصرية تنفذ التشفير البصري الآمن ضد الكم، والتبديل الضوئي الآمن، ومعالجة الإشارات البصرية المحمية.
 #4.19.5    المستوى: 3    الدور: D/V
 تحقق من أن رقائق الذكاء الاصطناعي الهجينة التناظرية-الرقمية تتضمن حسابًا تماثليًا آمنًا، وتخزين أوزان محميًا، وتحويلًا تماثليًا إلى رقمي موثوقًا.

---

### البنية التحتية للحوسبة المحافِظة على الخصوصية C4.20

تنفيذ ضوابط البنية التحتية للحوسبة المحافظة على الخصوصية لحماية البيانات الحساسة أثناء معالجة الذكاء الاصطناعي والتحليل.

 #4.20.1    المستوى: 3    الدور: D/V
 تحقق من أن بنية التشفير التماثلي تمكّن الحساب المشفر على أحمال العمل الحساسة للذكاء الاصطناعي مع التحقق من سلامة التشفير ومراقبة الأداء.
 #4.20.2    المستوى: 3    الدور: D/V
 تحقق من أن أنظمة استرجاع المعلومات الخاصة تمكّن الاستعلامات في قواعد البيانات دون الكشف عن أنماط الاستعلام مع الحماية التشفيرية لأنماط الوصول.
 #4.20.3    المستوى: 3    الدور: D/V
 تحقق من أن بروتوكولات الحوسبة متعددة الأطراف الآمنة تمكّن الاستدلال في الذكاء الاصطناعي مع الحفاظ على الخصوصية دون الكشف عن المدخلات الفردية أو الحسابات الوسيطة.
 #4.20.4    المستوى: 3    الدور: D/V
 تحقق من أن إدارة المفاتيح التي تحافظ على الخصوصية تشمل التوليد الموزع للمفاتيح، التشفير بالعتبة، وتدوير المفاتيح الآمن مع حماية مدعومة بالأجهزة.
 #4.20.5    المستوى: 3    الدور: D/V
 تحقق من أن أداء الحوسبة المحافظة على الخصوصية مُحسَّن من خلال التجميع والتخزين المؤقت وتسريع الأجهزة مع الحفاظ على ضمانات الأمان التشفيرية.

---

### C4.15 إطار عمل الوكلاء لأمن التكامل السحابي والنشر الهجين

ضوابط الأمان لأطر الوكلاء المتكاملة مع السحابة في البنى المختلطة المحلية/السحابية.

 #4.15.1    المستوى: 1    الدور: D/V
 تحقق من أن تكامل التخزين السحابي يستخدم تشفيراً من النهاية إلى النهاية مع إدارة المفاتيح التي يتحكم بها الوكيل.
 #4.15.2    المستوى: 2    الدور: D/V
 تحقق من أن حدود أمان النشر الهجين محددة بوضوح مع قنوات اتصال مشفرة.
 #4.15.3    المستوى: 2    الدور: D/V
 تحقق من أن وصول موارد السحابة يتضمن التحقق بنموذج الثقة الصفرية مع المصادقة المستمرة.
 #4.15.4    المستوى: 3    الدور: D/V
 تحقق من تطبيق متطلبات إقامت البيانات من خلال التصديق التشفيري لمواقع التخزين.
 #4.15.5    المستوى: 3    الدور: D/V
 تحقق من أن تقييمات أمان مزود السحابة تتضمن نمذجة تهديدات خاصة بالوكيل وتقييم المخاطر.

---

### المراجع

NIST Cybersecurity Framework 2.0
CIS Controls v8
OWASP Container Security Verification Standard
Kubernetes Security Best Practices
SLSA Supply Chain Security Framework
NIST SP 800-190: Application Container Security Guide
Cloud Security Alliance: Cloud Controls Matrix
ENISA: Secure Infrastructure Design
NIST SP 800-53: Security Controls for Federal Information Systems
ISO 27001:2022 Information Security Management
NIST AI Risk Management Framework
CIS Kubernetes Benchmark
FIPS 140-2 Security Requirements
NIST SP 800-207: Zero Trust Architecture
IEEE 2857: Privacy Engineering for AI Systems
NIST SP 800-161: Cybersecurity Supply Chain Risk Management
NIST Post-Quantum Cryptography Standards
Intel SGX Developer Guide
AMD SEV-SNP White Paper
ARM TrustZone Technology
ZK-SNARKs: A Gentle Introduction
NIST SP 800-57: Cryptographic Key Management
Side-Channel Attack Countermeasures
Neuromorphic Computing Security Challenges
FPGA Security: Fundamentals, Evaluation, and Countermeasures
Microsoft SEAL: Homomorphic Encryption Library
HElib: Homomorphic Encryption Library
PALISADE Lattice Cryptography Library
Differential Privacy: A Survey of Results
Secure Aggregation for Federated Learning
Private Information Retrieval: Concepts and Constructions

## التحكم في الوصول والهوية لمكونات ومستخدمي الذكاء الاصطناعي C5

### هدف التحكم

يتطلب التحكم الفعّال في الوصول لأنظمة الذكاء الاصطناعي إدارة هوية متينة، وتفويضًا مدركًا للسياق، وتنفيذًا وقت التشغيل وفقًا لمبادئ الثقة الصفرية. تضمن هذه الضوابط أن يتفاعل البشر والخدمات والوكلاء المستقلون فقط مع النماذج والبيانات والموارد الحاسوبية ضمن النطاقات الممنوحة صراحةً، مع قدرات تحقق ومراجعة مستمرة.

---

### C5.1 إدارة الهوية والمصادقة

قم بإنشاء هويات مدعومة بالتشفير لجميع الكيانات مع المصادقة متعددة العوامل للعمليات ذات الامتيازات العالية.

 #5.1.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع المستخدمين البشر والمبادئ الخدمية يقومون بالمصادقة من خلال مزود هوية مؤسسي مركزي (IdP) باستخدام بروتوكولات OIDC/SAML مع تعيينات فريدة للهوية إلى الرموز المميزة (دون حسابات أو بيانات اعتماد مشتركة).
 #5.1.2    المستوى: 1    الدور: D/V
 تحقق من أن العمليات عالية الخطورة (نشر النموذج، تصدير الأوزان، الوصول إلى بيانات التدريب، تغييرات تكوين الإنتاج) تتطلب المصادقة متعددة العوامل أو المصادقة المتقدمة مع إعادة التحقق من الجلسة.
 #5.1.3    المستوى: 2    الدور: D
 تحقق من أن المديرين الجدد يخضعون لعملية التحقق من الهوية وفقًا لمعيار NIST 800-63-3 IAL-2 أو ما يعادله قبل منحهم حق الوصول إلى نظام الإنتاج.
 #5.1.4    المستوى: 2    الدور: V
 تحقق من إجراء مراجعات الوصول ربع سنويًا مع الكشف التلقائي عن الحسابات الخاملة، وفرض تدوير بيانات الاعتماد، وسير العمل لإلغاء التخصيص.
 #5.1.5    المستوى: 3    الدور: D/V
 تحقق من أن وكلاء الذكاء الاصطناعي الموزعين يقومون بالمصادقة عبر تصريحات JWT موقعة والتي لها عمر أقصى يصل إلى 24 ساعة وتشمل دليلاً تشفيرياً على الأصل.

---

### C5.2 تفويض الموارد وأدنى امتيازات

نفذ ضوابط وصول دقيقة لجميع موارد الذكاء الاصطناعي باستخدام نماذج إذن صريحة ومسارات تدقيق.

 #5.2.1    المستوى: 1    الدور: D/V
 تحقق من أن كل مورد من موارد الذكاء الاصطناعي (مجموعات البيانات، النماذج، نقاط النهاية، مجموعات المتجهات، مؤشرات التضمين، وحدات الحوسبة) يفرض ضوابط وصول تعتمد على الأدوار مع قوائم سماح صريحة وسياسات الرفض الافتراضي.
 #5.2.2    المستوى: 1    الدور: D/V
 تحقق من تطبيق مبادئ الحد الأدنى من الامتيازات بشكل افتراضي مع حسابات الخدمة بدءًا من أذونات القراءة فقط، ويجب وجود تبرير تجاري موثق للوصول للكتابة.
 #5.2.3    المستوى: 1    الدور: V
 تحقق من أن جميع تعديلات التحكم في الوصول مرتبطة بطلبات تغيير معتمدة ومسجلة بشكل غير قابل للتغيير مع الطوابع الزمنية، وهويات الجهات الفاعلة، ومعرفات الموارد، وفروقات الأذونات.
 #5.2.4    المستوى: 2    الدور: D
 تحقق من أن تسميات تصنيف البيانات (المعلومات الشخصية، المعلومات الصحية المحمية، الخاضعة للرقابة على التصدير، الملكية) تنتقل تلقائيًا إلى الموارد المستخلصة (التضمينات، مخابئ المطالبات، مخرجات النماذج) مع تطبيق سياسة متسقة.
 #5.2.5    المستوى: 2    الدور: D/V
 تحقق من أن محاولات الوصول غير المصرح بها وأحداث تصعيد الامتيازات تثير تنبيهات فورية مع البيانات الوصفية السياقية إلى أنظمة SIEM خلال 5 دقائق.

---

### C5.3 التقييم الديناميكي للسياسات

نشر محركات التحكم في الوصول القائمة على الخصائص (ABAC) لاتخاذ قرارات التفويض المستندة إلى السياق مع قدرات التدقيق.

 #5.3.1    المستوى: 1    الدور: D/V
 تحقق من أن قرارات التفويض تتم خارجيًا إلى محرك سياسة مخصص (مثل OPA، Cedar، أو ما يعادلها) يمكن الوصول إليه عبر واجهات برمجة تطبيقات موثقة مع حماية سلامة التشفير.
 #5.3.2    المستوى: 1    الدور: D/V
 تحقق من أن السياسات تقوم بتقييم السمات الديناميكية أثناء وقت التشغيل بما في ذلك مستوى تصفية المستخدم، وتصنيف حساسية المورد، وسياق الطلب، وعزل المستأجر، والقيود الزمنية.
 #5.3.3    المستوى: 2    الدور: D
 تحقق من أن تعريفات السياسات مُتحكّم فيها بالإصدار، ويتم مراجعتها من قبل الزملاء، ويتم التحقق من صحتها من خلال الاختبارات الآلية في خطوط أنابيب التكامل المستمر/النشر المستمر قبل النشر في بيئة الإنتاج.
 #5.3.4    المستوى: 2    الدور: V
 تحقق من أن نتائج تقييم السياسة تتضمن مبررات قرار منظمة ويتم نقلها إلى أنظمة SIEM لتحليل الترابط والتقارير الامتثالية.
 #5.3.5    المستوى: 3    الدور: D/V
 تحقق من أن قيم مدة بقاء ذاكرة التخزين المؤقت للسياسات (TTL) لا تتجاوز 5 دقائق للموارد عالية الحساسية و1 ساعة للموارد القياسية التي تمتلك قدرات إبطال ذاكرة التخزين المؤقت.

---

### C5.4 فرض أمان وقت الاستعلام

تنفيذ ضوابط الأمان على مستوى قاعدة البيانات باستخدام التصفية الإلزامية وسياسات الأمان على مستوى الصف.

 #5.4.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع استعلامات قاعدة بيانات المتجهات وSQL تشمل عوامل تصفية أمنية إلزامية (معرف المستأجر، تسميات الحساسية، نطاق المستخدم) يتم فرضها على مستوى محرك قاعدة البيانات، وليس على كود التطبيق.
 #5.4.2    المستوى: 1    الدور: D/V
 تحقق من تمكين سياسات أمان مستوى الصف (RLS) وقناع الحقول على مستوى الحقل مع وراثة السياسات لجميع قواعد بيانات المتجهات، وفهارس البحث، ومجموعات البيانات التدريبية.
 #5.4.3    المستوى: 2    الدور: D
 تحقق من أن تقييمات التفويض الفاشلة ستمنع "هجمات الوكيل المشوش" من خلال إيقاف الاستعلامات فورًا وإرجاع رموز خطأ تفويض صريحة بدلاً من إرجاع مجموعات نتائج فارغة.
 #5.4.4    المستوى: 2    الدور: V
 تحقق من أن زمن استجابة تقييم السياسات يتم مراقبته باستمرار مع تنبيهات آلية لحالات انتهاء المهلة التي قد تمكّن من تجاوز التفويض.
 #5.4.5    المستوى: 3    الدور: D/V
 تحقق من أن آليات إعادة محاولة الاستعلام تعيد تقييم سياسات التفويض لأخذ تغييرات الأذونات الديناميكية في الاعتبار داخل جلسات المستخدم النشطة.

---

### ترشيح مخرجات C5.5 ومنع فقدان البيانات

نشر ضوابط ما بعد المعالجة لمنع تعرض البيانات غير المصرح بها في المحتوى الذي تم إنشاؤه بواسطة الذكاء الاصطناعي.

 #5.5.1    المستوى: 1    الدور: D/V
 تحقق من أن آليات التصفية بعد الاستنتاج تقوم بمسح وحجب المعلومات الشخصية المصرح بها وغير المصرح بها، والمعلومات المصنفة، والبيانات الملكية قبل تسليم المحتوى إلى الطلبات.
 #5.5.2    المستوى: 1    الدور: D/V
 تحقق من أن الاقتباسات والمراجع ونسب المصادر في مخرجات النموذج قد تم التحقق من صحتها مقابل صلاحيات المستخدم وازلها إذا تم الكشف عن وصول غير مصرح به.
 #5.5.3    المستوى: 2    الدور: D
 التحقق من تطبيق قيود تنسيق المخرجات (ملفات PDF المعالجة، الصور التي تمت إزالة بياناتها الوصفية، أنواع الملفات المعتمدة) بناءً على مستويات أذونات المستخدم وتصنيفات البيانات.
 #5.5.4    المستوى: 2    الدور: V
 تحقق من أن خوارزميات الحجب حتمية، خاضعة للتحكم في الإصدار، وتحافظ على سجلات التدقيق لدعم تحقيقات الامتثال والتحليل الجنائي.
 #5.5.5    المستوى: 3    الدور: V
 تحقق من أن أحداث الحجب عالية الخطورة تُولّد سجلات تكيفية تتضمن تجزئات تشفيرية للمحتوى الأصلي لاسترجاع الأدلة الجنائية دون تعرض البيانات.

---

### C5.6 عزل متعدد المستأجرين

ضمان العزل التشفيري والمنطقي بين المستأجرين في البنية التحتية المشتركة للذكاء الاصطناعي.

 #5.6.1    المستوى: 1    الدور: D/V
 تحقق من أن مساحات الذاكرة، مخازن التضمين، مدخلات الكاش، والملفات المؤقتة مفصولة وفقًا لمساحات الأسماء لكل مستأجر مع تنفيذ عملية تنظيف آمنة عند حذف المستأجر أو إنهاء الجلسة.
 #5.6.2    المستوى: 1    الدور: D/V
 تحقق من أن كل طلب API يتضمن معرف مستأجر مصدق عليه يتم التحقق منه تشفيرياً مقابل سياق الجلسة وصلاحيات المستخدم.
 #5.6.3    المستوى: 2    الدور: D
 تحقق من أن سياسات الشبكة تنفذ قواعد الرفض الافتراضي للاتصالات عبر المستأجرين داخل شبكات الخدمات ومنصات تنظيم الحاويات.
 #5.6.4    المستوى: 3    الدور: D
 تحقق من أن مفاتيح التشفير فريدة لكل مستأجر مع دعم مفتاح يديره العميل (CMK) والعزل التشفيري بين مخازن بيانات المستأجر.

---

### C5.7 تفويض الوكيل المستقل

التحكم في أذونات وكلاء الذكاء الاصطناعي والأنظمة المستقلة من خلال رموز القدرات المجدولة والتفويض المستمر.

 #5.7.1    المستوى: 1    الدور: D/V
 تحقق من أن الوكلاء المستقلين يتلقون رموز قدرات محددة تنص صراحةً على الإجراءات المسموح بها، والموارد المتاحة، والحدود الزمنية، والقيود التشغيلية.
 #5.7.2    المستوى: 1    الدور: D/V
 تحقق من تعطيل القدرات عالية المخاطر (الوصول إلى نظام الملفات، تنفيذ الأكواد، استدعاءات واجهة برمجة التطبيقات الخارجية، المعاملات المالية) بشكل افتراضي وأنها تتطلب تفويضات صريحة للتفعيل مع تبريرات تجارية.
 #5.7.3    المستوى: 2    الدور: D
 تحقق من أن رموز القدرات مرتبطة بجلسات المستخدم، وتتضمن حماية سلامة تشفيرية، وتأكد من أنه لا يمكن الاحتفاظ بها أو إعادة استخدامها في السيناريوهات غير المتصلة بالإنترنت.
 #5.7.4    المستوى: 2    الدور: V
 تحقق من أن الإجراءات التي يبادر بها الوكيل تخضع لتصريح ثانوي من خلال محرك سياسة التحكم في الوصول القائم على السمات (ABAC) مع تقييم السياق الكامل وتسجيل التدقيق.
 #5.7.5    المستوى: 3    الدور: V
 تحقق من أن حالات خطأ الوكيل والتعامل مع الاستثناءات تتضمن معلومات نطاق القدرة لدعم تحليل الحوادث والتحقيق الجنائي.

---

### المراجع

#### المعايير والأُطُر

NIST SP 800-63-3: Digital Identity Guidelines
Zero Trust Architecture – NIST SP 800-207
OWASP Application Security Verification Standard (AISVS)
​
#### أدلة التنفيذ

Identity and Access Management in the AI Era: 2025 Guide – IDSA
Attribute-Based Access Control with OPA – Permify
How We Designed Cedar to Be Intuitive, Fast, and Safe – AWS
​
#### الأمن المخصص للذكاء الاصطناعي

Row Level Security in Vector DBs for RAG – Bluetuple.ai
Tenant Isolation in Multi-Tenant Systems – WorkOS
Handling AI Agent Permissions – Stytch
OWASP Top 10 for Large Language Model Applications

## أمن سلسلة الإمداد للنماذج والأطر والبيانات

### هدف التحكم

تستغل هجمات سلسلة إمداد الذكاء الاصطناعي النماذج أو الأطر أو مجموعات البيانات التابعة لأطراف ثالثة لزرع أبواب خلفية أو تحيز أو كود قابل للاستغلال. توفر هذه الضوابط تتبعاً شاملاً للأصل، وإدارة الثغرات، والمراقبة لحماية دورة حياة النموذج بأكملها.

---

### C6.1 التحقق من صحة النموذج المدرب مسبقًا وأصله

قم بتقييم والتحقق من أصول النماذج الطرف الثالث، والتراخيص، والسلوكيات المخفية قبل أي تعديل دقيق أو نشر.

 #6.1.1    المستوى: 1    الدور: D/V
 تحقق من أن كل نموذج تابع لجهة خارجية يتضمن سجل منشأ موقعًا يحدد مستودع المصدر ورمز الالتزام.
 #6.1.2    المستوى: 1    الدور: D/V
 تحقق من فحص النماذج بحثًا عن طبقات خبيثة أو مشغلات حصان طروادة باستخدام أدوات تلقائية قبل الاستيراد.
 #6.1.3    المستوى: 2    الدور: D
 تحقق من أن التخصيص الدقيق بالتعلم الانتقالي يجتاز التقييم المعادي للكشف عن السلوكيات المخفية.
 #6.1.4    المستوى: 2    الدور: V
 تحقق من تسجيل تراخيص النماذج، وعلامات التحكم في التصدير، وبيانات أصل البيانات في إدخال ML-BOM.
 #6.1.5    المستوى: 3    الدور: D/V
 تحقق من أن النماذج عالية الخطورة (الأوزان المرفوعة علنًا، المنشئون غير المعتمدين) تظل معزولة حتى يتم المراجعة البشرية والموافقة عليها.

---

### C6.2 فحص الأطر والمكتبات

قم بمسح أُطُر ومكتبات تعلم الآلة باستمرار للكشف عن نقاط الضعف الأمنية (CVEs) والشفرة الخبيثة للحفاظ على أمان بيئة التشغيل.

 #6.2.1    المستوى: 1    الدور: D/V
 تحقق من أن أنابيب CI تقوم بتشغيل فاحصي التبعيات على أُطُر العمل للذكاء الاصطناعي والمكتبات الحرجة.
 #6.2.2    المستوى: 1    الدور: D/V
 تحقق من أن الثغرات الحرجة (CVSS ≥ 7.0) تمنع الترقية إلى صور الإنتاج.
 #6.2.3    المستوى: 2    الدور: D
 تحقق من أن تحليل الشيفرة الثابتة يتم تشغيله على مكتبات تعلم الآلة المنقسمة أو المستعارة.
 #6.2.4    المستوى: 2    الدور: V
 تحقق من أن مقترحات ترقية الإطار تتضمن تقييم تأثير أمني يشير إلى مصادر CVE العامة.
 #6.2.5    المستوى: 3    الدور: V
 تحقق من أن مستشعرات وقت التشغيل تُنبه عند تحميل مكتبات ديناميكية غير متوقعة تختلف عن SBOM الموقع.

---

### C6.3 تثبيت الاعتمادية والتحقق منها

قم بتثبيت كل تبعية على هاشات غير قابلة للتغيير وأعد إنتاج البنايات لضمان قطعيات متطابقة وخالية من التلاعب.

 #6.3.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع مديري الحزم يفرضون تثبيت الإصدارات عبر ملفات القفل.
 #6.3.2    المستوى: 1    الدور: D/V
 تحقق من استخدام الملخصات غير القابلة للتغيير بدلاً من العلامات القابلة للتغيير في مراجع الحاويات.
 #6.3.3    المستوى: 2    الدور: D
 تحقق من أن عمليات التحقق من البناء القابل للتكرار تقوم بمقارنة القيم التجزئة عبر تشغيلات التكامل المستمر لضمان مطابقة المخرجات.
 #6.3.4    المستوى: 2    الدور: V
 تحقق من تخزين شهادات البناء لمدة 18 شهرًا لضمان إمكانية تتبع التدقيق.
 #6.3.5    المستوى: 3    الدور: D
 تحقق من أن الاعتمادات المنتهية الصلاحية تؤدي إلى إنشاء طلبات سحب آلية لتحديث أو تفرع الإصدارات المثبتة.

---

### C6.4 تنفيذ المصدر الموثوق

السماح بتنزيل القطع الأثرية فقط من مصادر معتمدة من المنظمة وموثقة تشفيرياً وحظر كل شيء آخر.

 #6.4.1    المستوى: 1    الدور: D/V
 تحقق من أن أوزان النماذج ومجموعات البيانات والحاويات يتم تنزيلها فقط من النطاقات المعتمدة أو السجلات الداخلية.
 #6.4.2    المستوى: 1    الدور: D/V
 تحقق من أن توقيعات Sigstore/Cosign تتحقق من هوية الناشر قبل تخزين القطع الفنية محليًا.
 #6.4.3    المستوى: 2    الدور: D
 تحقق من أن الوكلاء الخارجيين يمنعون تنزيلات القطع الغير مصدقة لفرض سياسة المصدر الموثوق.
 #6.4.4    المستوى: 2    الدور: V
 تحقق من مراجعة قوائم السماح الخاصة بالمستودع بشكل ربع سنوي مع تقديم دليل على مبرر تجاري لكل إدخال.
 #6.4.5    المستوى: 3    الدور: V
 تحقق من أن انتهاكات السياسة تؤدي إلى حجز القطع الفنية والتراجع عن تشغيلات الخطوط المتبعة المعتمدة.

---

### C6.5 تقييم مخاطر مجموعة بيانات الطرف الثالث

تقييم مجموعات البيانات الخارجية من حيث التسميم، والانحياز، والامتثال القانوني، ومراقبتها طوال دورة حياتها.

 #6.5.1    المستوى: 1    الدور: D/V
 تحقق من أن مجموعات البيانات الخارجية تخضع لتقييم مخاطر التسميم (مثل بصمة البيانات، واكتشاف القيم الشاذة).
 #6.5.2    المستوى: 1    الدور: D
 تحقق من أن مقاييس التحيز (التكافؤ الديموغرافي، تكافؤ الفرص) يتم حسابها قبل الموافقة على مجموعة البيانات.
 #6.5.3    المستوى: 2    الدور: V
 تحقق من أن معلومات المصدر وشروط الترخيص لمجموعات البيانات مُسجلة في سجلات ML‑BOM.
 #6.5.4    المستوى: 2    الدور: V
 تحقق من أن المراقبة الدورية تكتشف الانجراف أو التلف في مجموعات البيانات المستضافة.
 #6.5.5    المستوى: 3    الدور: D
 تحقق من إزالة المحتوى الممنوع (حقوق الطبع والنشر، المعلومات الشخصية التعريفية) من خلال التنقية الآلية قبل التدريب.

---

### مراقبة هجمات سلسلة التوريد C6.6

اكتشف تهديدات سلسلة التوريد مبكرًا من خلال خلاصات CVE، وتحليلات سجلات التدقيق، ومحاكاة الفريق الأحمر.

 #6.6.1    المستوى: 1    الدور: V
 تحقق من أن سجلات تدقيق CI/CD تُرسل إلى SIEM للكشف عن عمليات سحب الحزم الشاذة أو خطوات البناء التي تم التلاعب بها.
 #6.6.2    المستوى: 2    الدور: D
 تحقق من أن كتب إجراءات الاستجابة للحوادث تتضمن إجراءات التراجع للنماذج أو المكتبات المخترقة.
 #6.6.3    المستوى: 3    الدور: V
 تحقق من أن إثراء معلومات التهديد يوسم مؤشرات محددة بتقنيات التعلم الآلي (مثل مؤشرات اختراق تسميم النموذج) أثناء فرز التنبيهات.

---

### C6.7 قائمة مواد التعلم الآلي (ML‑BOM) لقطع نموذج الذكاء الاصطناعي

قم بإنشاء وتوقيع قوائم المواد البرمجية المفصلة الخاصة بالتعلم الآلي (ML‑BOMs) بحيث يمكن للمستهلكين في downstream التحقق من سلامة المكونات وقت النشر.

 #6.7.1    المستوى: 1    الدور: D/V
 تحقق من أن كل نموذج يُصدر ملف ML-BOM يسرد مجموعات البيانات والأوزان والمعاملات الفائقة والتراخيص.
 #6.7.2    المستوى: 1    الدور: D/V
 تحقق من أن توليد ML‑BOM والتوقيع بواسطة Cosign يتمان تلقائيًا في CI وأنهما مطلوبان للدمج.
 #6.7.3    المستوى: 2    الدور: D
 تحقق من أن فحوصات اكتمال ML‑BOM تفشل في البناء إذا كان أي من بيانات مكونات البرنامج (الهاش، الترخيص) مفقودًا.
 #6.7.4    المستوى: 2    الدور: V
 تحقق من أن المستهلكين في المستوى التالي يمكنهم استعلام قوائم مواد التعلم الآلي (ML-BOMs) عبر واجهة برمجة التطبيقات (API) للتحقق من صحة النماذج المستوردة أثناء وقت النشر.
 #6.7.5    المستوى: 3    الدور: V
 تحقق من أن قوائم المواد الخاصة بتعلم الآلة (ML-BOMs) يتم التحكم في إصداراتها ومقارنتها لاكتشاف التعديلات غير المصرح بها.

---

### المراجع

ML Supply Chain Compromise – MITRE ATLAS
Supply‑chain Levels for Software Artifacts (SLSA)
CycloneDX – Machine Learning Bill of Materials
What is Data Poisoning? – SentinelOne
Transfer Learning Attack – OWASP ML Security Top 10
AI Data Security Best Practices – CISA
Secure CI/CD Supply Chain – Sumo Logic
AI & Transparency: Protect ML Models – ReversingLabs
SBOM Overview – CISA
Training Data Poisoning Guide – Lakera.ai
Dependency Pinning for Reproducible Python – Medium

## سلوك نموذج C7، التحكم في المخرجات وضمان السلامة

### هدف التحكم

يجب أن تكون مخرجات النموذج منظمة، وموثوقة، وآمنة، وقابلة للتفسير، وتُراقب باستمرار أثناء الإنتاج. يؤدي ذلك إلى تقليل الهلوسات، وتسريبات الخصوصية، والمحتوى الضار، والإجراءات الخارجة عن السيطرة، مع زيادة ثقة المستخدم والامتثال التنظيمي.

---

### C7.1 فرض تنسيق المخرجات

توقف المخططات الصارمة، وفك الترميز المقيد، والتحقق اللاحق المحتوى المشوه أو الضار قبل انتشاره.

 #7.1.1    المستوى: 1    الدور: D/V
 تحقق من توفير مخططات الاستجابة (مثل JSON Schema) في موجه النظام وأن يتم التحقق من صحة كل مخرجات تلقائيًا؛ حيث تؤدي المخرجات غير المطابقة إلى إصلاحها أو رفضها.
 #7.1.2    المستوى: 1    الدور: D/V
 تحقق من تمكين فك التشفير المقيد (رموز التوقف، التعبيرات العادية، الحد الأقصى لعدد الرموز) لمنع الفائض أو قنوات الجانب الخاصة بحقن المطالبات.
 #7.1.3    المستوى: 2    الدور: D/V
 تأكد من أن المكونات التالية تتعامل مع المخرجات باعتبارها غير موثوق بها وتقوم بالتحقق من صحتها مقابل المخططات أو المحللات الآمنة من الحقن.
 #7.1.4    المستوى: 3    الدور: V
 تحقق من تسجيل أحداث الإخراج غير الصحيح، والحد من معدل حدوثها، وعرضها على أنظمة المراقبة.

---

### C7.2 الكشف عن الهلوسة والتخفيف منها

تقدير عدم اليقين واستراتيجيات التراجع تحد من الإجابات الملفقة.

 #7.2.1    المستوى: 1    الدور: D/V
 تحقق من أن احتمالات السجل على مستوى الرموز، أو التناسق الذاتي للتجمع، أو كواشف الهلوسة المُدعمة بالتدريب الدقيق تعيّن درجة ثقة لكل إجابة.
 #7.2.2    المستوى: 1    الدور: D/V
 تحقق من أن الردود التي تقل عن عتبة الثقة القابلة للتكوين تؤدي إلى تشغيل تدفقات العمل البديلة (مثل التوليد المدعوم بالاستخراج، النموذج الثانوي، أو المراجعة البشرية).
 #7.2.3    المستوى: 2    الدور: D/V
 تحقق من وسم حوادث الهلوسة ببيانات تعريف السبب الجذري وإدخالها في خطوط أنابيب التحليل بعد الوفاة والتعديل الدقيق.
 #7.2.4    المستوى: 3    الدور: D/V
 تحقق من إعادة معايرة العتبات والكواشف بعد التحديثات الكبرى للنموذج أو قاعدة المعرفة.
 #7.2.5    المستوى: 3    الدور: V
 تحقق من أن تصورات لوحة التحكم تتعقب معدلات التوهم.

---

### C7.3 تصفية السلامة والخصوصية للمخرجات

تعمل فلاتر السياسات وتغطية الفريق الأحمر على حماية المستخدمين والبيانات السرية.

 #7.3.1    المستوى: 1    الدور: D/V
 تحقق من أن المصنفات قبل وبعد التوليد تمنع المحتوى الكاره، والمضايقات، وإيذاء النفس، والمتطرف، والمحتوى الجنسي الصريح المتوافق مع السياسة.
 #7.3.2    المستوى: 1    الدور: D/V
 تأكد من أن الكشف عن المعلومات الشخصية الحساسة (PII) وبيانات بطاقة الدفع (PCI) بالإضافة إلى الحذف التلقائي يتم تنفيذهما على كل رد؛ حيث تؤدي الانتهاكات إلى رفع تقرير عن حادث خصوصية.
 #7.3.3    المستوى: 2    الدور: D
 تحقق من أن علامات السرية (مثل الأسرار التجارية) تنتقل عبر الوسائط المختلفة لمنع التسرب في النصوص أو الصور أو الشيفرة.
 #7.3.4    المستوى: 3    الدور: D/V
 تحقق من أن محاولات تجاوز الفلتر أو التصنيفات عالية المخاطر تتطلب موافقة ثانوية أو إعادة مصادقة المستخدم.
 #7.3.5    المستوى: 3    الدور: D/V
 تحقق من أن عتبات التصفية تعكس السلطات القانونية وسياق عمر/دور المستخدم.

---

### C7.4 تحديد الإخراج والإجراء

تحد من الحدود القصوى للطلبات وبوابات الموافقة سوء الاستخدام والاستقلالية المفرطة.

 #7.4.1    المستوى: 1    الدور: D
 تحقق من أن حصص الاستخدام لكل مستخدم ولكل مفتاح API تحد من الطلبات، والرموز، والتكلفة مع التراجع الأسّي عند حدوث أخطاء 429.
 #7.4.2    المستوى: 1    الدور: D/V
 تحقق من أن الإجراءات المميزة (كتابة الملفات، تنفيذ الأكواد، مكالمات الشبكة) تتطلب موافقة مستندة إلى سياسة أو تدخل بشري.
 #7.4.3    المستوى: 2    الدور: D/V
 تحقق من أن فحوصات التوافق متعددة الوسائط تضمن ألا يمكن استخدام الصور، الشيفرات، والنصوص التي يتم إنشاؤها لنفس الطلب لتهريب محتوى خبيث.
 #7.4.4    المستوى: 2    الدور: D
 تحقق من أن عمق تفويض الوكيل، وحدود العودية، وقوائم الأدوات المسموح بها تم تكوينها صراحةً.
 #7.4.5    المستوى: 3    الدور: V
 تحقق من أن انتهاك الحدود يصدر أحداث أمان منظمة لعملية استيعاب SIEM.

---

### C7.5 شرح قابلية تفسير المخرجات

الإشارات الشفافة تحسن ثقة المستخدم وتصحيح الأخطاء الداخلي.

 #7.5.1    المستوى: 2    الدور: D/V
 تأكد من عرض درجات الثقة الموجهة للمستخدم أو ملخصات التفكير الموجزة عندما يقر التقييم المخاطر بملاءمتها.
 #7.5.2    المستوى: 2    الدور: D/V
 تحقق من أن الشروحات المولدة تتجنب الكشف عن مطالبات النظام الحساسة أو البيانات الملكية.
 #7.5.3    المستوى: 3    الدور: D
 تحقق من أن النظام يلتقط احتمالات السجل على مستوى الرموز أو خرائط الانتباه ويخزنها للفحص المصرح به.
 #7.5.4    المستوى: 3    الدور: V
 تحقق من أن قطع الشرح تكون خاضعة للتحكم في الإصدارات جنبًا إلى جنب مع إصدارات النماذج لضمان إمكانية التدقيق.

---

### C7.6 دمج المراقبة

الرصد في الوقت الحقيقي يغلق الحلقة بين التطوير والإنتاج.

 #7.6.1    المستوى: 1    الدور: D
 تحقق من أن المقاييس (انتهاكات المخطط، معدل الهلوسة، السمية، تسريبات المعلومات الشخصية المميزة، الكمون، التكلفة) تتدفق إلى منصة مراقبة مركزية.
 #7.6.2    المستوى: 1    الدور: V
 تحقق من تحديد حدود التنبيه لكل مقياس أمان، مع وضع مسارات التصعيد للمكالمة عند الحاجة.
 #7.6.3    المستوى: 2    الدور: V
 تحقق من أن لوحات البيانات تربط بين الشذوذات في المخرجات مع النموذج/الإصدار، وعلامة الميزة، وتغييرات البيانات الصاعدة.
 #7.6.4    المستوى: 2    الدور: D/V
 تحقق من أن بيانات المراقبة تعود للتدريب من جديد، أو التعديل الدقيق، أو تحديث القواعد ضمن سير عمل MLOps موثق.
 #7.6.5    المستوى: 3    الدور: V
 تحقق من أن أنظمة مراقبة خطوط الأنابيب خضعت لاختبارات الاختراق وتم التحكم في الوصول إليها لتجنب تسرب السجلات الحساسة.

---

### 7.7 تدابير الأمان للوسائط التوليدية

ضمان أن أنظمة الذكاء الاصطناعي لا تولد محتوى وسائط غير قانوني أو ضار أو غير مصرح به من خلال تطبيق قيود السياسات، والتحقق من صحة المخرجات، وقابلية التتبع.

 #7.7.1    المستوى: 1    الدور: D/V
 تحقق من أن تعليمات النظام وتعليمات المستخدم تحظر صراحةً إنشاء وسائط المزيّفة العميقة غير القانونية أو الضارة أو التي تتم بدون موافقة (مثل الصورة، الفيديو، الصوت).
 #7.7.2    المستوى: 2    الدور: D/V
 تحقق من فلترة المطالبات لمنع المحاولات التي تهدف إلى توليد انتحال شخصيات، أو فيديوهات عميقة جنسية صريحة، أو وسائط تظهر أفراداً حقيقيين بدون موافقة.
 #7.7.3    المستوى: 2    الدور: V
 تحقق من أن النظام يستخدم التجزئة الإدراكية، أو الكشف عن العلامة المائية، أو بصمة الإصبع لمنع النسخ غير المصرح به للوسائط المحمية بحقوق الطبع والنشر.
 #7.7.4    المستوى: 3    الدور: D/V
 تحقق من أن جميع الوسائط المُولدة موقعة تشفيرياً، أو مرفقة بعلامة مائية، أو مضمنة ببيانات أصل مقاومة للتلاعب لضمان إمكانية تتبعها فيما بعد.
 #7.7.5    المستوى: 3    الدور: V
 تحقق من اكتشاف محاولات التجاوز (على سبيل المثال، إخفاء المطالبات، اللغة العامية، الصياغة العدائية)، وتسجيلها، وتقييد معدل حدوثها؛ ويتم عرض حالات الإساءة المتكررة على أنظمة المراقبة.

### المراجع

NIST AI Risk Management Framework
ISO/IEC 42001:2023 – AI Management System
OWASP Top-10 for Large Language Model Applications (2025)
Improper Output Handling – OWASP LLM05:2025
Practical Techniques to Constrain LLM Output
Dataiku – Structured Text Generation Guide
VL-Uncertainty: Detecting Hallucinations
HaDeMiF: Hallucination Detection & Mitigation
Building Confidence in LLM Outputs
Explainable AI & LLMs
LLM Red-Teaming Guide
Sensitive Information Disclosure in LLMs
LangChain – Chat Model Rate Limiting
OpenAI Rate-Limit & Exponential Back-off
Arize AI – LLM Observability Platform

## أمان ذاكرة C8، التضمينات وقاعدة بيانات المتجهات

### هدف التحكم

تعمل التضمينات ومخازن المتجهات كـ "ذاكرة حية" لأنظمة الذكاء الاصطناعي المعاصرة، إذ تستقبل باستمرار البيانات المقدمة من المستخدم وتعيد عرضها داخل سياقات النماذج عبر التوليد المعزز بالاسترجاع (RAG). إذا تُركت هذه الذاكرة بدون مراقبة، فقد تتسرب البيانات الشخصية المُحددة (PII)، أو تُنتهك الموافقات، أو يتم عكسها لإعادة إنشاء النص الأصلي. تهدف هذه المجموعة من الضوابط إلى تقوية مسارات الذاكرة وقواعد بيانات المتجهات بحيث يكون الوصول بأقل قدر من الامتيازات، وتكون التضمينات تحافظ على الخصوصية، وتنتهي صلاحية المتجهات المخزنة أو يمكن سحبها عند الطلب، وألا تلوث ذاكرة كل مستخدم مطالبات أو إكمالات مستخدم آخر.

---

### C8.1 ضوابط الوصول على الذاكرة ومؤشرات RAG

فرض ضوابط وصول دقيقة على كل مجموعة متجهات.

 #8.1.1    المستوى: 1    الدور: D/V
 تحقق من أن قواعد التحكم في الوصول على مستوى الصف/المجال تحد من عمليات الإدخال والحذف والاستعلام لكل مستأجر أو مجموعة أو وسم مستند.
 #8.1.2    المستوى: 1    الدور: D/V
 تحقق من أن مفاتيح API أو JWTs تحمل مطالبات محددة بالنطاق (مثل معرفات المجموعات، أفعال الإجراءات) وأنها تتم تدويرها على الأقل كل ثلاثة أشهر.
 #8.1.3    المستوى: 2    الدور: D/V
 تحقق من أن محاولات تصعيد الامتيازات (مثل استعلامات التشابه عبر المساحات الاسمية) يتم اكتشافها وتسجيلها في نظام إدارة معلومات وأحداث الأمن (SIEM) خلال 5 دقائق.
 #8.1.4    المستوى: 2    الدور: D/V
 تحقق من أن قاعدة بيانات المتجهات تسجل مراجعة المعرف الموضوعي، العملية، معرف المتجه/النطاق، عتبة التشابه، وعدد النتائج.
 #8.1.5    المستوى: 3    الدور: V
 تحقق من أن قرارات الوصول تُختبر للكشف عن ثغرات التجاوز كلما تم ترقية المحركات أو تغيرت قواعد تقسيم الفهرس.

---

### C8.2 تطهير وتحقق من صحة التضمين

قم بفحص النص مسبقًا بحثًا عن معلومات هوية شخصية، وقم بإخفائها أو تشفيرها قبل تحويلها إلى متجهات، وخياريًا قم بمعالجة التضمينات بعد ذلك لإزالة الإشارات المتبقية.

 #8.2.1    المستوى: 1    الدور: D/V
 تحقق من اكتشاف المعلومات الشخصية المعروفة (PII) والبيانات المنظمة عبر المصنفات الآلية وأن يتم إخفاؤها أو ترميزها أو حذفها قبل التضمين.
 #8.2.2    المستوى: 1    الدور: D
 تحقق من أن خطوط المعالجة الخاصة بالتضمين ترفض أو تعزل المدخلات التي تحتوي على تعليمات برمجية تنفيذية أو قطع غير قابلة للترميز بنظام UTF-8 والتي قد تلوث الفهرس.
 #8.2.3    المستوى: 2    الدور: D/V
 تحقق من تطبيق التقييد التفاضلي المحلي أو تقييد الخصوصية التفاضلية المترية على تمثيلات الجمل التي تقل المسافة بينها وبين أي رمز معلومات شخصية معرف (PII) عن حد قابل للتكوين.
 #8.2.4    المستوى: 2    الدور: V
 تحقق من أن فعالية التنقية (مثل استدعاء إزالة المعلومات الشخصية، والانحراف الدلالي) يتم التحقق منها على الأقل مرتين في السنة مقابل مجموعات البيانات المرجعية.
 #8.2.5    المستوى: 3    الدور: D/V
 تأكد من أن إعدادات التنقية تحت مراقبة الإصدارات وأن التغييرات تخضع لمراجعة الأقران.

---

### C8.3 انتهاء صلاحية الذاكرة، الإلغاء والحذف

يتطلب القانون العام لحماية البيانات (GDPR) "الحق في النسيان" والقوانين المشابهة الحذف في الوقت المناسب؛ لذلك يجب أن تدعم مخازن المتجهات أوقات الحياة المحددة (TTLs)، والحذف الصارم، ووضع الأوسمة (tomb-stoning) بحيث لا يمكن استعادة المتجهات الملغاة أو إعادة فهرستها.

 #8.3.1    المستوى: 1    الدور: D/V
 تحقق من أن كل متجه وسجل بيانات وصفية يحمل مدة صلاحية مؤقتة (TTL) أو تسمية احتفاظ صريحة تُحترم بواسطة مهام التنظيف الآلي.
 #8.3.2    المستوى: 1    الدور: D/V
 تحقق من أن طلبات الحذف التي يبادر بها المستخدم تقوم بمسح المتجهات والبيانات الوصفية ونسخ التخزين المؤقت والفهارس المشتقة خلال 30 يومًا.
 #8.3.3    المستوى: 2    الدور: D
 تحقق من أن عمليات الحذف المنطقي تليها تمزيق تشفير كتلات التخزين إذا كان الجهاز يدعم ذلك، أو عن طريق تدمير مفتاح خزنة المفاتيح.
 #8.3.4    المستوى: 3    الدور: D/V
 تحقق من استبعاد المتجهات منتهية الصلاحية من نتائج البحث عن أقرب الجيران في أقل من 500 مللي ثانية بعد انتهاء صلاحيتها.

---

### C8.4 منع انقلاب التضمين والتسرب

يمكن للدفاعات الحديثة—إضافة الضوضاء، شبكات الإسقاط، اضطراب الخلايا العصبية الخاصة بالخصوصية، وتشفير طبقة التطبيق—أن تخفض معدلات الانعكاس على مستوى الرموز إلى أقل من 5%.

 #8.4.1    المستوى: 1    الدور: V
 التحقق من وجود نموذج تهديد رسمي يشمل هجمات الانعكاس والهجمات على العضوية والهجمات على استنتاج الخصائص، وأن يتم مراجعته سنويًا.
 #8.4.2    المستوى: 2    الدور: D/V
 تحقق من أن التشفير على مستوى طبقة التطبيق أو التشفير القابل للبحث يحمي المتجهات من القراءة المباشرة بواسطة مسؤولي البنية التحتية أو موظفي السحابة.
 #8.4.3    المستوى: 3    الدور: V
 تحقق من أن معلمات الدفاع (ε لـ DP، الضوضاء σ، رتبة الإسقاط k) توازن بين الخصوصية ≥ 99٪ حماية الرموز والفائدة ≤ 3٪ خسارة الدقة.
 #8.4.4    المستوى: 3    الدور: D/V
 تحقق من أن مقاييس مقاومة الانعكاس هي جزء من بوابات الإطلاق لتحديثات النماذج، مع تحديد ميزانيات الانحدار.

---

### C8.5 تطبيق نطاق الذاكرة المخصص للمستخدم

تسرب البيانات بين المستأجرين ما زال يشكل أعلى مخاطر RAG: يمكن لاستعلامات التشابه التي لم تُصفّى بشكل صحيح أن تكشف عن مستندات خاصة بعملاء آخرين.

 #8.5.1    المستوى: 1    الدور: D/V
 تحقق من أن كل استعلام استرجاع يتم تصفيته بعد المعالجة بواسطة معرف المستأجر/المستخدم قبل تمريره إلى موجه نموذج اللغة الكبيرة (LLM).
 #8.5.2    المستوى: 1    الدور: D
 تحقق من أن أسماء المجموعات أو معرفات النطاقات تحتوي على ملح خاص بكل مستخدم أو مستأجر حتى لا تتصادم المتجهات عبر النطاقات.
 #8.5.3    المستوى: 2    الدور: D/V
 تأكد من أن نتائج التشابه التي تتجاوز عتبة المسافة القابلة للتكوين ولكنها خارج نطاق المتصل يتم تجاهلها وتؤدي إلى تفعيل تنبيهات الأمان.
 #8.5.4    المستوى: 2    الدور: V
 تحقق من أن اختبارات الضغط متعددة المستأجرين تحاكي الاستعلامات العدائية التي تحاول استرجاع مستندات خارج النطاق وتثبت عدم حدوث أي تسرب.
 #8.5.5    المستوى: 3    الدور: D/V
 تحقق من فصل مفاتيح التشفير لكل مستأجر، مما يضمن العزل التشفيري حتى في حالة مشاركة التخزين الفعلي.

---

### C8.6 أمان نظام الذاكرة المتقدم

ضوابط الأمان لهياكل الذاكرة المتقدمة بما في ذلك الذاكرة العرضية، والذاكرة الدلالية، والذاكرة العاملة مع متطلبات محددة للعزل والتحقق.

 #8.6.1    المستوى: 1    الدور: D/V
 تحقق من أن أنواع الذاكرة المختلفة (الذاكرة العرضية، الذاكرة الدلالية، الذاكرة العاملة) تمتلك سياقات أمان معزولة مع ضوابط وصول مبنية على الأدوار، ومفاتيح تشفير منفصلة، وأنماط وصول موثقة لكل نوع من أنواع الذاكرة.
 #8.6.2    المستوى: 2    الدور: D/V
 تحقق من أن عمليات دمج الذاكرة تشمل التحقق الأمني لمنع إدخال ذكريات خبيثة من خلال تطهير المحتوى، والتحقق من المصدر، وفحوصات السلامة قبل التخزين.
 #8.6.3    المستوى: 2    الدور: D/V
 تحقق من أن استعلامات استرجاع الذاكرة يتم التحقق من صحتها وتنقيتها لمنع استخراج المعلومات غير المصرح بها من خلال تحليل نمط الاستعلام، تنفيذ الرقابة على الوصول، وتصنيف النتائج.
 #8.6.4    المستوى: 3    الدور: D/V
 تحقق من أن آليات نسيان الذاكرة تقوم بحذف المعلومات الحساسة بشكل آمن مع ضمانات المحو التشفيري باستخدام حذف المفاتيح، أو الكتابة المتعددة المرات، أو الحذف الآمن المعتمد على العتاد مع شهادات التحقق.
 #8.6.5    المستوى: 3    الدور: D/V
 تحقق من أن سلامة نظام الذاكرة تتم مراقبتها باستمرار للكشف عن أي تعديلات أو تلف غير مصرح به من خلال استخدام التجزئات، وسجلات التدقيق، والتنبيهات الآلية عند حدوث تغييرات في محتوى الذاكرة خارج العمليات العادية.

---

### المراجع

Vector database security: Pinecone – IronCore Labs
Securing the Backbone of AI: Safeguarding Vector Databases and Embeddings – Privacera
Enhancing Data Security with RBAC of Qdrant Vector Database – AI Advances
Mitigating Privacy Risks in LLM Embeddings from Embedding Inversion – arXiv
DPPN: Detecting and Perturbing Privacy-Sensitive Neurons – OpenReview
Art. 17 GDPR – Right to Erasure
Sensitive Data in Text Embeddings Is Recoverable – Tonic.ai
PII Identification and Removal – NVIDIA NeMo Docs
De-identifying Sensitive Data – Google Cloud DLP
Remove PII from Conversations Using Sensitive Information Filters – AWS Bedrock Guardrails
Think Your RAG Is Secure? Think Again – Medium
Design a Secure Multitenant RAG Inferencing Solution – Microsoft Learn
Best Practices for Multi-Tenancy RAG with Milvus – Milvus Blog

## 9 التنسيق الذاتي والعمل الوكالي الأمني

### هدف التحكم

تأكد من أن أنظمة الذكاء الاصطناعي الذاتية أو متعددة الوكلاء يمكنها تنفيذ الإجراءات فقط التي تكون مقصودة صراحةً، ومصادق عليها، وقابلة للتدقيق، وضمن حدود التكلفة والمخاطر المسموح بها. هذا يحمي من التهديدات مثل اختراق النظام الذاتي، وسوء استخدام الأدوات، وكشف الحلقة الوكيلية، واختطاف الاتصالات، وانتحال الهوية، والتلاعب بالسرب، والتلاعب بالنية.

---

### 9.1 ميزانيات تخطيط مهام الوكيل والتكرار

تقييد الخطط العودية وفرض نقاط تفتيش بشرية للإجراءات المميزة.

 #9.1.1    المستوى: 1    الدور: D/V
 تحقق من أن أقصى عمق للتكرار، العرض، وقت الساعة الحائطية، الرموز، والتكلفة المالية لكل تنفيذ وكيل مُعدة مركزيًا وتخضع للتحكم بالإصدار.
 #9.1.2    المستوى: 1    الدور: D/V
 تحقق من أن الإجراءات ذات الامتياز أو التي لا يمكن التراجع عنها (مثل التزامات الشيفرة، والتحويلات المالية) تتطلب موافقة صريحة من الإنسان عبر قناة قابلة للتدقيق قبل التنفيذ.
 #9.1.3    المستوى: 2    الدور: D
 تحقق من أن مراقبي الموارد في الوقت الحقيقي يقومون بتحفيز انقطاع قاطع الدائرة عند تجاوز أي من حدود الميزانية، مما يوقف توسع المهام بشكل إضافي.
 #9.1.4    المستوى: 2    الدور: D/V
 تحقق من تسجيل أحداث قاطع الدائرة بمعرف الوكيل، وحالة التنشيط، وحالة الخطة الملتقطة للمراجعة الجنائية.
 #9.1.5    المستوى: 3    الدور: V
 تحقق من أن اختبارات الأمان تغطي سيناريوهات نفاد الميزانية وهروب الخطة، مع التأكيد على التوقف الآمن دون فقدان البيانات.
 #9.1.6    المستوى: 3    الدور: D
 تحقق من أن سياسات الميزانية معبر عنها كسياسة-كود ويتم فرضها في CI/CD لمنع انحراف التهيئة.

---

### 9.2 حجز أدوات الإضافة (Plugin Sandboxing)

عزل تفاعلات الأدوات لمنع الوصول غير المصرح به إلى النظام أو تنفيذ الأكواد.

 #9.2.1    المستوى: 1    الدور: D/V
 تحقق من أن كل أداة/مكون إضافي يتم تشغيله داخل نظام تشغيل، أو حاوية، أو بيئة رملية على مستوى WASM مع سياسات أقل امتيازًا لنظام الملفات، والشبكة، ونظام الاستدعاء.
 #9.2.2    المستوى: 1    الدور: D/V
 تحقق من أن حصص موارد البيئة المعزولة (CPU، الذاكرة، القرص، تصدير الشبكة) وحدود زمن التنفيذ مفروضة ومسجلة.
 #9.2.3    المستوى: 2    الدور: D/V
 تحقق من أن الملفات التنفيذية للأدوات أو أوصافها موقعة رقميًا؛ ويتم التحقق من التوقيعات قبل التحميل.
 #9.2.4    المستوى: 2    الدور: V
 تحقق من أن بيانات القياس عن بعد لـ sandbox تتدفق إلى نظام إدارة معلومات وأحداث الأمان (SIEM)؛ حيث تثير الشذوذات (مثل محاولات الاتصالات الصادرة) التنبيهات.
 #9.2.5    المستوى: 3    الدور: V
 تحقق من أن الإضافات عالية الخطورة تخضع لمراجعة أمنية واختبار اختراق قبل نشرها في بيئة الإنتاج.
 #9.2.6    المستوى: 3    الدور: D/V
 تأكد من أن محاولات الهروب من صندوق الحماية يتم حظرها تلقائيًا وأن الإضافة المخالفة توضع في الحجز المؤقت بانتظار التحقيق.

---

### 9.3 الحلقة الذاتية والحد من التكاليف

كشف وإيقاف التكرار غير المنضبط بين الوكلاء والانفجارات التكلفة.

 #9.3.1    المستوى: 1    الدور: D/V
 تحقق من أن المكالمات بين الوكلاء تتضمن حد انتقال أو TTL يقوم وقت التشغيل بتقليله وفرضه.
 #9.3.2    المستوى: 2    الدور: D
 تحقق من أن الوكلاء يحتفظون بمعرف فريد لمخطط الاستدعاء لرصد الاستدعاء الذاتي أو الأنماط الدورية.
 #9.3.3    المستوى: 2    الدور: D/V
 تحقق من أن عدادات وحدة الحوسبة التراكمية والإنفاق يتم تتبعها لكل سلسلة طلب؛ تجاوز الحد يؤدي إلى إلغاء السلسلة.
 #9.3.4    المستوى: 3    الدور: V
 تحقق من أن التحليل الرسمي أو التحقق من النموذج يثبت غياب التكرار غير المحدود في بروتوكولات الوكيل.
 #9.3.5    المستوى: 3    الدور: D
 تحقق من أن أحداث إيقاف الحلقة تولد تنبيهات وتغذي مقاييس التحسين المستمر.

---

### 9.4 حماية من سوء الاستخدام على مستوى البروتوكول

قنوات اتصال آمنة بين الوكلاء والأنظمة الخارجية لمنع الاختطاف أو التلاعب.

 #9.4.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع الرسائل بين الوكيل والأداة وبين الوكلاء مصدقة (مثل TLS المتبادل أو JWT) ومشفرة من طرف إلى طرف.
 #9.4.2    المستوى: 1    الدور: D
 تحقق من أن المخططات يتم التحقق منها بدقة؛ يتم رفض الحقول غير المعروفة أو الرسائل ذات التنسيق الخاطئ.
 #9.4.3    المستوى: 2    الدور: D/V
 تحقق من أن فحوصات السلامة (MACs أو التوقيعات الرقمية) تغطي كامل حمولة الرسالة بما في ذلك معلمات الأداة.
 #9.4.4    المستوى: 2    الدور: D
 تحقق من أن الحماية من إعادة التشغيل (الـ nonces أو نوافذ الطوابع الزمنية) مُطبقة على طبقة البروتوكول.
 #9.4.5    المستوى: 3    الدور: V
 تحقق من أن تطبيقات البروتوكول تخضع لاختبار الفازينج والتحليل الساكن للكشف عن عيوب الحقن أو التسلسل العكسي.

---

### 9.5 هوية الوكيل ودليل العبث

ضمان إمكانية عزو الأفعال واكتشاف التعديلات.

 #9.5.1    المستوى: 1    الدور: D/V
 تحقق من أن كل نسخة من الوكيل تمتلك هوية تشفير فريدة (زوج مفاتيح أو اعتماد مرتبط بالأجهزة).
 #9.5.2    المستوى: 2    الدور: D/V
 تحقق من توقيع جميع إجراءات العميل وتوقيتها؛ يجب أن تتضمن السجلات التوقيع لمنع التنصل.
 #9.5.3    المستوى: 2    الدور: V
 تحقق من أن السجلات المقاومة للتلاعب مخزنة في وسط يقتصر على الإضافة فقط أو الكتابة مرة واحدة.
 #9.5.4    المستوى: 3    الدور: D
 تأكد من أن مفاتيح الهوية تتغير وفق جدول زمني محدد وعند وجود مؤشرات على الاختراق.
 #9.5.5    المستوى: 3    الدور: D/V
 تحقق من أن محاولات الانتحال أو تعارض المفاتيح تؤدي إلى حجر صحي فوري للوكيل المتأثر.

---

### 9.6 تقليل مخاطر السرب متعدد الوكلاء

التخفيف من مخاطر السلوك الجماعي من خلال العزل والنمذجة الرسمية للسلامة.

 #9.6.1    المستوى: 1    الدور: D/V
 تحقق من أن الوكلاء الذين يعملون في مجالات أمنية مختلفة يتم تشغيلهم في صناديق أمان تنفيذ معزولة أو في قطاعات شبكية منفصلة.
 #9.6.2    المستوى: 3    الدور: V
 تحقق من أن سلوكيات السرب قد تم نمذجتها والتحقق منها رسميًا من حيث الحيوية والسلامة قبل النشر.
 #9.6.3    المستوى: 3    الدور: D
 تحقق من أن مراقبي وقت التشغيل يكتشفون الأنماط غير الآمنة الناشئة (مثل التذبذبات، والجمود) ويبدؤون بالإجراءات التصحيحية.

---

### 9.7 المصادقة / التفويض للمستخدم والأداة

نفذ ضوابط وصول قوية لكل إجراء يتم تفعيله بواسطة الوكيل.

 #9.7.1    المستوى: 1    الدور: D/V
 تحقق من أن الوكلاء يقومون بالمصادقة كجهات فاعلة من الدرجة الأولى للنظم التابعة، دون إعادة استخدام بيانات اعتماد المستخدم النهائي.
 #9.7.2    المستوى: 2    الدور: D
 تحقق من أن سياسات التفويض الدقيقة تحد من الأدوات التي يمكن للعميل استدعاؤها والمعلمات التي يمكنه تقديمها.
 #9.7.3    المستوى: 2    الدور: V
 تحقق من إعادة تقييم فحوصات الامتيازات عند كل استدعاء (الترخيص المستمر)، وليس فقط عند بدء الجلسة.
 #9.7.4    المستوى: 3    الدور: D
 تحقق من أن الامتيازات المفوضة تنتهي تلقائيًا وتتطلب إعادة الموافقة بعد انتهاء المهلة أو تغيير النطاق.

---

### 9.8 أمان التواصل بين الوكلاء

تشفير جميع الرسائل بين الوكلاء وحمايتها من العبث لضمان الحماية من التنصت والتلاعب.

 #9.8.1    المستوى: 1    الدور: D/V
 تحقق من أن المصادقة المتبادلة والتشفير بسريّة تامة للأمام (مثل TLS 1.3) إلزاميان لقنوات الوكيل.
 #9.8.2    المستوى: 1    الدور: D
 تحقق من صحة سلامة الرسالة وأصلها قبل المعالجة؛ في حال حدوث فشل، يتم رفع تنبيهات وإسقاط الرسالة.
 #9.8.3    المستوى: 2    الدور: D/V
 تحقق من تسجيل بيانات تعريف الاتصال (الطوابع الزمنية، أرقام التسلسل) لدعم إعادة البناء الجنائي.
 #9.8.4    المستوى: 3    الدور: V
 تحقق من أن التحقق الرسمي أو فحص النموذج يؤكد أن آلات حالة البروتوكول لا يمكن دفعها إلى حالات غير آمنة.

---

### 9.9 التحقق من النية وفرض القيود

تحقق من أن إجراءات الوكيل تتماشى مع نية المستخدم المعلنة وقيود النظام.

 #9.9.1    المستوى: 1    الدور: D
 تحقق من أن محركات حل القيود قبل التنفيذ تتحقق من الإجراءات المقترحة مقابل قواعد السلامة والسياسة المبرمجة مسبقًا.
 #9.9.2    المستوى: 2    الدور: D/V
 تحقق من أن الإجراءات ذات التأثير العالي (المالية، التدميرية، الحساسة للخصوصية) تتطلب تأكيد نية صريحة من المستخدم الذي بدأها.
 #9.9.3    المستوى: 2    الدور: V
 تحقق من أن فحوصات الشروط اللاحقة تؤكد أن الإجراءات المكتملة حققت التأثيرات المرجوة دون آثار جانبية؛ وأي تناقضات تؤدي إلى التراجع.
 #9.9.4    المستوى: 3    الدور: V
 تحقق من أن الطرق الرسمية (مثل التحقق من النماذج، إثبات النظريات) أو الاختبارات القائمة على الخصائص تثبت أن خطط الوكيل تفي بجميع القيود المعلنة.
 #9.9.5    المستوى: 3    الدور: D
 تحقق من أن الحوادث المتعلقة بعدم تطابق النية أو انتهاك القيود تغذي دورات التحسين المستمر ومشاركة معلومات التهديدات.

---

### 9.10 أمان استراتيجية استدلال الوكيل

الاختيار والتنفيذ الآمن لاستراتيجيات التفكير المختلفة بما في ذلك طرق ReAct، وسلسلة الأفكار، وشجرة الأفكار.

 #9.10.1    المستوى: 1    الدور: D/V
 تحقق من أن اختيار استراتيجية التفكير يستخدم معايير حتمية (تعقيد الإدخال، نوع المهمة، سياق الأمان) وأن المدخلات المتطابقة تُنتج اختيارات استراتيجية متطابقة ضمن نفس سياق الأمان.
 #9.10.2    المستوى: 1    الدور: D/V
 تحقق من أن كل استراتيجية استدلال (ReAct، سلسلة الأفكار، شجرة الأفكار) تحتوي على تحقق مخصص من صحة الإدخال، وتنقية مخرجات، وحدود زمن تنفيذ محددة خاصة بنهجها الإدراكي.
 #9.10.3    المستوى: 2    الدور: D/V
 تحقق من أن انتقالات استراتيجية التفكير يتم تسجيلها مع السياق الكامل بما في ذلك خصائص الإدخال وقيم معايير الاختيار وبيانات تنفيذ العمليات لاستعادة سجل التدقيق.
 #9.10.4    المستوى: 2    الدور: D/V
 تحقق من أن تفكير شجرة الأفكار يتضمن آليات تقليم الفروع التي تنهي الاستكشاف عند اكتشاف انتهاكات السياسة، أو حدود الموارد، أو حدود السلامة.
 #9.10.5    المستوى: 2    الدور: D/V
 تحقق من أن دورات ReAct (التفكير-التصرف-الملاحظة) تتضمن نقاط تحقق للتحقق في كل مرحلة: التحقق من خطوة التفكير، تفويض الفعل، وتنقية الملاحظة قبل المتابعة.
 #9.10.6    المستوى: 3    الدور: D/V
 تحقق من أن مؤشرات أداء استراتيجية الاستدلال (وقت التنفيذ، استخدام الموارد، جودة المخرجات) تتم مراقبتها بواسطة تنبيهات آلية عند انحراف المؤشرات عن الحدود المعتمدة.
 #9.10.7    المستوى: 3    الدور: D/V
 تحقق من أن النهج الهجين للاستدلال الذي يجمع بين استراتيجيات متعددة يحافظ على التحقق من صحة الإدخال وقيود الإخراج لجميع الاستراتيجيات المكونة دون تجاوز أي ضوابط أمان.
 #9.10.8    المستوى: 3    الدور: D/V
 تحقق من أن اختبار أمان استراتيجية الاستدلال يشمل التغطية بمدخلات مشوهة، والمطالبات العدائية المصممة لإجبار التبديل بين الاستراتيجيات، واختبار شروط الحدود لكل نهج معرفي.

---

### 9.11 إدارة حالة دورة حياة الوكيل والأمان

تهيئة الوكيل الآمن، والتحولات الحلقية، وإنهاء العمل مع سجلات تدقيق تشفيرية وإجراءات استرداد محددة.

 #9.11.1    المستوى: 1    الدور: D/V
 تحقق من أن تهيئة الوكيل تتضمن إنشاء هوية تشفيرية باستخدام بيانات اعتماد مدعومة بالأجهزة وسجلات تدقيق بدء تشغيل غير قابلة للتغيير تحتوي على معرف الوكيل والطابع الزمني وتجميع التكوين ومعلمات التهيئة.
 #9.11.2    المستوى: 2    الدور: D/V
 تحقق من أن الانتقالات في حالة الوكيل موقعة تشفيرياً، وموّقتة زمنياً، ومسجلة بسجل يحتوي على السياق الكامل بما في ذلك الأحداث المحفزة، وتجزئة الحالة السابقة، وتجزئة الحالة الجديدة، والتحققات الأمنية التي تم تنفيذها.
 #9.11.3    المستوى: 2    الدور: D/V
 تحقق من أن إجراءات إيقاف تشغيل الوكيل تتضمن مسحًا آمنًا للذاكرة باستخدام المحو التشفيري أو الكتابة المتعددة المرور، وإلغاء صلاحيات الاعتماد مع إشعار سلطة الشهادات، وإنشاء شهادات إنهاء مقاومة للتلاعب.
 #9.11.4    المستوى: 3    الدور: D/V
 تحقق من أن آليات استرداد الوكيل تقوم بالتحقق من سلامة الحالة باستخدام مجموعات تدقيق تشفيرية (SHA-256 كحد أدنى) وتعيد الحالة إلى حالات معروفة وصحيحة عند اكتشاف الفساد مع تنبيهات آلية ومتطلبات الموافقة اليدوية.
 #9.11.5    المستوى: 3    الدور: D/V
 تحقق من أن آليات استمرارية الوكيل تقوم بتشفير بيانات الحالة الحساسة باستخدام مفاتيح AES-256 لكل وكيل وتنفذ تدوير المفاتيح الآمن وفق جداول قابلة للتكوين (بحد أقصى 90 يومًا) مع نشر بدون توقف.

---

### 9.12 إطار أمان دمج الأدوات

ضوابط الأمان لتحميل الأدوات الديناميكي وتنفيذها والتحقق من النتائج مع عمليات تقييم المخاطر والموافقة المحددة.

 #9.12.1    المستوى: 1    الدور: D/V
 تحقق من أن أوصاف الأدوات تتضمن بيانات أمان وصفية تحدد الامتيازات المطلوبة (قراءة/كتابة/تنفيذ)، مستويات المخاطر (منخفض/متوسط/عالٍ)، حدود الموارد (وحدة المعالجة المركزية، الذاكرة، الشبكة)، ومتطلبات التحقق الموثقة في مَنشورات الأدوات.
 #9.12.2    المستوى: 1    الدور: D/V
 تحقق من أن نتائج تنفيذ الأداة يتم التحقق من صحتها مقابل المخططات المتوقعة (مخطط JSON، مخطط XML) وسياسات الأمان (تنقية المخرجات، تصنيف البيانات) قبل التكامل مع حدود المهلة وإجراءات التعامل مع الأخطاء.
 #9.12.3    المستوى: 2    الدور: D/V
 تحقق من أن سجلات تفاعل الأدوات تتضمن سياق أمني مفصل يشمل استخدام الامتيازات، أنماط الوصول إلى البيانات، وقت التنفيذ، استهلاك الموارد، وأكواد العودة مع تسجيل منظم لتكامل نظم إدارة الأحداث الأمنية (SIEM).
 #9.12.4    المستوى: 2    الدور: D/V
 تحقق من أن آليات تحميل الأدوات الديناميكية تقوم بالتحقق من صحة التوقيعات الرقمية باستخدام بنية المفتاح العام (PKI) وتنفذ بروتوكولات تحميل آمنة مع عزل في بيئة معزولة (sandbox) والتحقق من الأذونات قبل التنفيذ.
 #9.12.5    المستوى: 3    الدور: D/V
 تحقق من أن تقييمات أمان الأدوات يتم تشغيلها تلقائيًا للإصدارات الجديدة مع وجود بوابات الموافقة الإلزامية والتي تشمل التحليل الثابت، الاختبار الديناميكي، ومراجعة فريق الأمان مع وجود معايير موافقة موثقة ومتطلبات اتفاقية مستوى الخدمة (SLA).

---

#### المراجع

MITRE ATLAS tactics ML09
Circuit-breaker research for AI agents — Zou et al., 2024
Trend Micro analysis of sandbox escapes in AI agents — Park, 2025
Auth0 guidance on human-in-the-loop authorization for agents — Martinez, 2025
Medium deep-dive on MCP & A2A protocol hijacking — ForAISec, 2025
Rapid7 fundamentals on spoofing attack prevention — 2024
Imperial College verification of swarm systems — Lomuscio et al.
NIST AI Risk Management Framework 1.0, 2023
WIRED security briefing on encryption best practices, 2024
OWASP Top 10 for LLM Applications, 2025
Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS
[How Is LLM Reasoning Distracted by Irrelevant Context?
An Analysis Using a Controlled Benchmark](https://www.arxiv.org/pdf/2505.18761)
Large Language Model Sentinel: LLM Agent for Adversarial Purification
Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents

## 10 الصلابة ضد الهجمات العدائية والدفاع عن الخصوصية

### هدف التحكم

تأكد من بقاء نماذج الذكاء الاصطناعي موثوقة، تحافظ على الخصوصية، ومقاومة لسوء الاستخدام عند مواجهة هجمات التهرب، الاستنتاج، الاستخراج، أو التسميم.

---

### 10.1 محاذاة النموذج والسلامة

الحذر من المخرجات الضارة أو المخالفة للسياسات.

 #10.1.1    المستوى: 1    الدور: D/V
 تحقق من أن مجموعة اختبار المحاذاة (موجهات الفريق الأحمر، استقصاءات اختراق السجن، المحتوى الممنوع) تتم إدارتها بنظام التحكم في الإصدارات ويتم تشغيلها على كل إصدار من النموذج.
 #10.1.2    المستوى: 1    الدور: D
 تحقق من تطبيق قواعد الرفض وحماية إكمال المهام بأمان.
 #10.1.3    المستوى: 2    الدور: D/V
 تحقق من أن المقيم الآلي يقيس معدل المحتوى الضار ويشير إلى التراجع الذي يتجاوز الحد المحدد.
 #10.1.4    المستوى: 2    الدور: D
 تحقق من أن تدريب مكافحة الكسر محمي بشكل موثق وقابل لإعادة الإنتاج.
 #10.1.5    المستوى: 3    الدور: V
 تحقق من أن إثباتات الامتثال للسياسات الرسمية أو المراقبة المعتمدة تغطي المجالات الحرجة.

---

### 10.2 تعزيز مقاومة الأمثلة المعادية

زيادة الصلابة ضد المدخلات المُعدّلة. التدريب العدائي القوي وتقييم المعايير هما أفضل الممارسات الحالية.

 #10.2.1    المستوى: 1    الدور: D
 تحقق من أن مستودعات المشروع تتضمن إعدادات تدريب معاكسة مع بذور قابلة لإعادة الإنتاج.
 #10.2.2    المستوى: 2    الدور: D/V
 تحقق من أن الكشف عن الأمثلة العدائية يثير تنبيهات الحجب في خطوط الإنتاج.
 #10.2.4    المستوى: 3    الدور: V
 تحقق من أن إثباتات المتانة المعتمدة أو شهادات حدود الفترات تغطي على الأقل الفئات الحرجة العليا.
 #10.2.5    المستوى: 3    الدور: V
 تحقق من أن اختبارات الانحدار تستخدم الهجمات التكيفية لتأكيد عدم وجود فقدان ملحوظ في المتانة.

---

### 10.3 التخفيف من استنتاج العضوية

تقييد القدرة على تحديد ما إذا كانت السجلات موجودة في بيانات التدريب. تظل الخصوصية التفاضلية وإخفاء درجة الثقة أكثر وسائل الدفاع فعالية المعروفة.

 #10.3.1    المستوى: 1    الدور: D
 تحقق من أن تنظيم الانتروبيا لكل استعلام أو تعديل درجة الحرارة يقلل من التنبؤات المفرطة الثقة.
 #10.3.2    المستوى: 2    الدور: D
 تحقق من أن التدريب يستخدم تحسين الخصوصية التفاضلية المحصور بـ ε لمجموعات البيانات الحساسة.
 #10.3.3    المستوى: 2    الدور: V
 تحقق من أن محاكاة الهجوم (نموذج الظل أو الصندوق الأسود) تظهر أن مساحة تحت منحنى الهجوم (AUC) ≤ 0.60 على البيانات المحتجزة للاختبار.

---

### 10.4 مقاومة انقلاب النموذج

منع إعادة بناء السمات الخاصة. تؤكد الدراسات الاستقصائية الحديثة على تقطيع المخرجات وضمانات حماية الخصوصية التفاضلية كدفاعات عملية.

 #10.4.1    المستوى: 1    الدور: D
 تحقق من أن السمات الحساسة لا تُخرج مباشرة أبدًا؛ وعند الحاجة، استخدم التجميعات أو التحويلات أحادية الاتجاه.
 #10.4.2    المستوى: 1    الدور: D/V
 تحقق من أن حدود معدل الاستعلام تحد من تكرار الاستعلامات التكيفية من نفس المستخدم.
 #10.4.3    المستوى: 2    الدور: D
 تحقق من أن النموذج تم تدريبه باستخدام ضوضاء تحافظ على الخصوصية.

---

### 10.5 الدفاع ضد استخراج النماذج

كشف وردع النسخ غير المصرح به. يُوصى باستخدام تقنية العلامات المائية وتحليل أنماط الاستعلام.

 #10.5.1    المستوى: 1    الدور: D
 تحقق من أن بوابات الاستدلال تفرض حدود معدلات عامة وخاصة بكل مفتاح API مصممة وفقًا لعتبة الحفظ الخاصة بالنموذج.
 #10.5.2    المستوى: 2    الدور: D/V
 تحقق من أن إحصائيات إنتروبيا الاستعلام وتعددية الإدخال تغذي كاشف الاستخراج الآلي.
 #10.5.3    المستوى: 2    الدور: V
 تحقق من أن العلامات المائية الهشة أو الاحتمالية يمكن إثباتها بقيمة p < 0.01 في ≤ 1 000 استعلام ضد نسخة مشتبه بها.
 #10.5.4    المستوى: 3    الدور: D
 تحقق من أن مفاتيح العلامة المائية ومجموعات التشغيل مخزنة في وحدة أمان الأجهزة ويتم تدويرها سنويًا.
 #10.5.5    المستوى: 3    الدور: V
 تحقق من أن أحداث التنبيه الخاصة بالاستخراج تتضمن الاستعلامات المخالفة وأنها مدمجة مع كتيبات استجابة الحوادث.

---

### 10.6 كشف البيانات المسمومة في وقت الاستنتاج

تحديد المدخلات المزودة بأبواب خلفية أو المسمومة وتحيدها.

 #10.6.1    المستوى: 1    الدور: D
 تحقق من أن المدخلات تمر عبر كاشف الشذوذ (مثل STRIP، تقييم الاتساق) قبل استدلال النموذج.
 #10.6.2    المستوى: 1    الدور: V
 تأكد من ضبط عتبات الكاشف على مجموعات تحقق نظيفة/مسمومة لتحقيق أقل من 5% من الإيجابيات الكاذبة.
 #10.6.3    المستوى: 2    الدور: D
 تحقق من أن المدخلات التي تم تعليمها على أنها ملوثة تُفعّل حظرًا ناعماً وتدفقات عمل للمراجعة البشرية.
 #10.6.4    المستوى: 2    الدور: V
 تحقق من أن أجهزة الكشف قد خضعت لاختبارات إجهاد باستخدام هجمات خلفية تكيفية دون محرض.
 #10.6.5    المستوى: 3    الدور: D
 تحقق من تسجيل مقاييس فاعلية الكشف وإعادة تقييمها بشكل دوري باستخدام معلومات تهديد حديثة.

---

### 10.7 التكيف الديناميكي لسياسة الأمان

تحديثات سياسة الأمان في الوقت الحقيقي بناءً على استخبارات التهديدات وتحليل السلوك.

 #10.7.1    المستوى: 1    الدور: D/V
 تحقق من إمكانية تحديث سياسات الأمان ديناميكيًا دون إعادة تشغيل الوكيل مع الحفاظ على سلامة إصدار السياسة.
 #10.7.2    المستوى: 2    الدور: D/V
 تحقق من أن تحديثات السياسة موقعة تشفيرياً من قبل موظفي الأمن المخولين وتم التحقق منها قبل التطبيق.
 #10.7.3    المستوى: 2    الدور: D/V
 تحقق من أن تغييرات السياسة الديناميكية مسجلة بسجلات تدقيق كاملة تشمل التبرير، وسلاسل الموافقة، وإجراءات التراجع.
 #10.7.4    المستوى: 3    الدور: D/V
 تحقق من أن آليات الأمان التكيفية تضبط حساسية كشف التهديدات بناءً على سياق المخاطر وأنماط السلوك.
 #10.7.5    المستوى: 3    الدور: D/V
 تحقق من أن قرارات تكييف السياسات قابلة للتفسير وتتضمن مسارات أدلة لمراجعة فريق الأمان.

---

### 10.8 التحليل الأمني القائم على الانعكاس

التحقق الأمني من خلال التأمل الذاتي للوكيل والتحليل الميتا-معرفي.

 #10.8.1    المستوى: 1    الدور: D/V
 تحقق من أن آليات انعكاس الوكيل تتضمن التقييم الذاتي المركّز على الأمان للقرارات والإجراءات.
 #10.8.2    المستوى: 2    الدور: D/V
 تحقق من أن مخرجات الانعكاس تم التحقق منها لمنع التلاعب بآليات التقييم الذاتي بواسطة المدخلات العدائية.
 #10.8.3    المستوى: 2    الدور: D/V
 تحقق من أن التحليل الأمني فوق المعرفي يحدد التحيز المحتمل أو التلاعب أو الخطر في عمليات استدلال الوكيل.
 #10.8.4    المستوى: 3    الدور: D/V
 تحقق من أن تحذيرات الأمان القائمة على الانعكاس تؤدي إلى تفعيل المراقبة المعززة وإمكانيات التدخل البشري المحتملة في سير العمل.
 #10.8.5    المستوى: 3    الدور: D/V
 تحقق من أن التعلم المستمر من الانعكاسات الأمنية يحسن من اكتشاف التهديدات دون التأثير سلباً على الوظائف الشرعية.

---

### 10.9 الأمن والتحسين الذاتي

ضوابط الأمان لأنظمة العملاء القادرة على التعديل الذاتي والتطور.

 #10.9.1    المستوى: 1    الدور: D/V
 تحقق من أن قدرات التعديل الذاتي مقيدة بالمناطق الآمنة المحددة التي تحتوي على حدود تحقق رسمية.
 #10.9.2    المستوى: 2    الدور: D/V
 تأكد من خضوع مقترحات التطوير لتقييم تأثير الأمان قبل التنفيذ.
 #10.9.3    المستوى: 2    الدور: D/V
 تحقق من أن آليات تحسين الذات تتضمن قدرات التراجع مع التحقق من سلامة البيانات.
 #10.9.4    المستوى: 3    الدور: D/V
 تحقق من أن أمان التعلم التعزيزي يمنع التلاعب العدائي بخوارزميات التحسين.
 #10.9.5    المستوى: 3    الدور: D/V
 تحقق من أن التحسن الذاتي التكراري محدود بقيود السلامة الرسمية مع إثباتات رياضية للتقارب.

---

#### المراجع

MITRE ATLAS adversary tactics for ML
NIST AI Risk Management Framework 1.0, 2023
OWASP Top 10 for LLM Applications, 2025
Adversarial Training: A Survey — Zhao et al., 2024
RobustBench adversarial-robustness benchmark
Membership-Inference & Model-Inversion Risk Survey, 2025
PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023
Model-Inversion Attacks & Defenses Survey — AI Review, 2025
Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024
Fragile Model Watermarking Survey — 2025
Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025
BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024

## 11 حماية الخصوصية وإدارة البيانات الشخصية

### هدف التحكم

الحفاظ على ضمانات الخصوصية الصارمة عبر دورة حياة الذكاء الاصطناعي بأكملها — الجمع، والتدريب، والاستدلال، والاستجابة للحوادث — بحيث يتم معالجة البيانات الشخصية فقط بموافقة واضحة، وبنطاق الحد الأدنى اللازم، ومسح قابل للإثبات، وضمانات خصوصية رسمية.

---

### 11.1 إخفاء الهوية وتقليل البيانات

 #11.1.1    المستوى: 1    الدور: D/V
 تحقق من إزالة المعرفات المباشرة وشبه المعرفات أو تحويلها إلى قيمة هاش.
 #11.1.2    المستوى: 2    الدور: D/V
 تحقق من أن التدقيقات الآلية تقيس مقياس k-التمويه / l-التنوع وتنبه عندما تنخفض القيم تحت حدود السياسة.
 #11.1.3    المستوى: 2    الدور: V
 تحقق من أن تقارير أهمية ميزات النموذج تثبت عدم وجود تسرب معرف يتجاوز ε = 0.01 من المعلومات المشتركة.
 #11.1.4    المستوى: 3    الدور: V
 تحقق من أن البراهين الرسمية أو شهادة البيانات التركيبية تظهر أن خطر إعادة التعريف ≤ 0.05 حتى في ظل هجمات الربط.

---

### 11.2 الحق في النسيان وتنفيذ الحذف

 #11.2.1    المستوى: 1    الدور: D/V
 تأكد من أن طلبات حذف بيانات الموضوع تنتقل إلى مجموعات البيانات الخام، ونقاط التحقق، والتضمينات، والسجلات، والنسخ الاحتياطية ضمن اتفاقيات مستوى الخدمة التي تقل عن 30 يومًا.
 #11.2.2    المستوى: 2    الدور: D
 تحقق من أن روتينات "إلغاء التعلم الآلي" تعيد التدريب فعليًا أو تقترب من الإزالة باستخدام خوارزميات الإلغاء المعتمدة.
 #11.2.3    المستوى: 2    الدور: V
 تحقق من أن تقييم نموذج الظل يثبت أن السجلات المنسية تؤثر على أقل من 1% من المخرجات بعد عملية النسيان.
 #11.2.4    المستوى: 3    الدور: V
 تحقق من أن أحداث الحذف مسجلة بشكل لا يمكن تغييره وقابلة للتدقيق للمنظمين.

---

### 11.3 ضوابط الخصوصية التفاضلية

 #11.3.1    المستوى: 2    الدور: D/V
 تحقق من أن لوحات مراقبة حساب خسارة الخصوصية تُنبه عندما يتجاوز قيمة ε التراكمية حدود السياسات.
 #11.3.2    المستوى: 2    الدور: V
 تحقق من أن تدقيقات الخصوصية للصندوق الأسود تقدر ε̂ ضمن 10% من القيمة المعلنة.
 #11.3.3    المستوى: 3    الدور: V
 تحقق من أن البراهين الرسمية تغطي جميع التعديلات الدقيقة والتضمينات التي تلي التدريب.

---

### 11.4 حماية تحديد الغاية و تقييد النطاق و الحماية من توسع النطاق

 #11.4.1    المستوى: 1    الدور: D
 تحقق من أن كل مجموعة بيانات ونقطة تحقق للنموذج تحمل علامة غرض قابلة للقراءة آليًا ومتوافقة مع الموافقة الأصلية.
 #11.4.2    المستوى: 1    الدور: D/V
 التحقق من أن مراقبات وقت التشغيل تكتشف الاستعلامات غير المتوافقة مع الغرض المعلن وتُفعل الرفض اللطيف.
 #11.4.3    المستوى: 3    الدور: D
 تحقق من أن بوابات السياسة كرمز تمنع إعادة نشر النماذج في مجالات جديدة بدون مراجعة تقييم تأثير حماية البيانات (DPIA).
 #11.4.4    المستوى: 3    الدور: V
 تحقق من أن براهين التتبع الرسمية تظهر أن دورة حياة كل البيانات الشخصية تظل ضمن النطاق الموافق عليه.

---

### 11.5 إدارة الموافقة وتتبع الأساس القانوني

 #11.5.1    المستوى: 1    الدور: D/V
 تحقق من أن منصة إدارة الموافقات (CMP) تسجل حالة الموافقة، والهدف، وفترة الاحتفاظ لكل موضوع بيانات.
 #11.5.2    المستوى: 2    الدور: D
 تحقق من أن واجهات برمجة التطبيقات تعرض رموز الموافقة؛ يجب على النماذج التحقق من نطاق الرمز قبل الاستدلال.
 #11.5.3    المستوى: 2    الدور: D/V
 تحقق من أن رفض أو سحب الموافقة يوقف خطوط معالجة البيانات خلال 24 ساعة.

---

### 11.6 التعلم الموحد مع ضوابط الخصوصية

 #11.6.1    المستوى: 1    الدور: D
 تحقق من أن تحديثات العميل تستخدم إضافة ضوضاء الخصوصية التفاضلية المحلية قبل التجميع.
 #11.6.2    المستوى: 2    الدور: D/V
 تحقق من أن مقاييس التدريب محمية بالخصوصية التفاضلية ولا تكشف أبدًا عن خسارة عميل واحد فقط.
 #11.6.3    المستوى: 2    الدور: V
 تحقق من تمكين التجميع المقاوم للتسميم (مثل Krum/Trimmed-Mean).
 #11.6.4    المستوى: 3    الدور: V
 تحقق من أن البراهين الرسمية تظهر ميزانية ε الكلية مع خسارة منفعة أقل من 5.

---

#### المراجع

GDPR & AI Compliance Best Practices
EU Parliament Study on GDPR & AI, 2020
ISO 31700-1:2023 — Privacy by Design for Consumer Products
NIST Privacy Framework 1.1 (2025 Draft)
Machine Unlearning: Right-to-Be-Forgotten Techniques
A Survey of Machine Unlearning, 2024
Auditing DP-SGD — ArXiv 2024
DP-SGD Explained — PyTorch Blog
Purpose-Limitation for AI — IJLIT 2025
Data-Protection Considerations for AI — URM Consulting
Top Consent-Management Platforms, 2025
Secure Aggregation in DP Federated Learning — ArXiv 2024

## المراقبة والتسجيل واكتشاف الشذوذ في C12

### هدف التحكم

تقدم هذه القسم متطلبات لتوفير رؤية في الوقت الحقيقي والتحقيق الجنائي لما يراه النموذج ومكونات الذكاء الاصطناعي الأخرى، وما يقومون به، وما يعيدونه، بحيث يمكن اكتشاف التهديدات وتصنيفها والتعلم منها.

### تسجيل الطلب والاستجابة C12.1

 #12.1.1    المستوى: 1    الدور: D/V
 تحقق من تسجيل جميع مطالبات المستخدم واستجابات النموذج مع البيانات الوصفية المناسبة (مثل الطابع الزمني، معرف المستخدم، معرف الجلسة، نسخة النموذج).
 #12.1.2    المستوى: 1    الدور: D/V
 تحقق من أن السجلات مخزنة في مستودعات آمنة يتم التحكم في الوصول إليها مع سياسات احتفاظ مناسبة وإجراءات نسخ احتياطي.
 #12.1.3    المستوى: 1    الدور: D/V
 تحقق من أن أنظمة تخزين السجلات تنفذ التشفير عند الاستراحة وأثناء النقل لحماية المعلومات الحساسة المحتواة في السجلات.
 #12.1.4    المستوى: 1    الدور: D/V
 تحقق من أن البيانات الحساسة في المطالبات والمخرجات يتم حذفها أو إخفاؤها تلقائيًا قبل تسجيلها، مع قواعد حذف قابلة للتكوين للمعلومات الشخصية المعروفة (PII)، بيانات الاعتماد، والمعلومات الملكية.
 #12.1.5    المستوى: 2    الدور: D/V
 تحقق من أن قرارات السياسات وإجراءات تصفية الأمان يتم تسجيلها بتفاصيل كافية لتمكين التدقيق وتصحيح أخطاء أنظمة مراقبة المحتوى.
 #12.1.6    المستوى: 2    الدور: D/V
 تحقق من حماية سلامة السجل من خلال على سبيل المثال التوقيعات التشفيرية أو التخزين القابل للكتابة فقط.

---

### C12.2 الكشف عن الإساءة والتنبيه

 #12.2.1    المستوى: 1    الدور: D/V
 تحقق من أن النظام يكتشف وينبه على أنماط الاختراق المعروفة، ومحاولات حقن التعليمات، والمدخلات العدائية باستخدام الكشف القائم على التوقيع.
 #12.2.2    المستوى: 1    الدور: D/V
 تحقق من أن النظام يتكامل مع منصات إدارة معلومات وأحداث الأمان (SIEM) الموجودة باستخدام تنسيقات سجلات وبروتوكولات قياسية.
 #12.2.3    المستوى: 2    الدور: D/V
 تحقق من أن أحداث الأمان المعززة تتضمن سياقًا خاصًا بالذكاء الاصطناعي مثل معرفات النماذج، درجات الثقة، وقرارات فلتر الأمان.
 #12.2.4    المستوى: 2    الدور: D/V
 تحقق من أن الكشف عن الشذوذ السلوكي يحدد أنماط المحادثة غير العادية، ومحاولات المحاولة المتكررة المفرطة، أو سلوكيات الاستكشاف المنهجية.
 #12.2.5    المستوى: 2    الدور: D/V
 تحقق من أن آليات التنبيه في الوقت الحقيقي تُخطِر فرق الأمن عند اكتشاف انتهاكات محتملة للسياسات أو محاولات هجوم.
 #12.2.6    المستوى: 2    الدور: D/V
 تحقق من تضمين قواعد مخصصة للكشف عن أنماط التهديد الخاصة بالذكاء الاصطناعي بما في ذلك محاولات الاختراق المنسقة وحملات حقن المحفزات وهجمات استخراج النموذج.
 #12.2.7    المستوى: 3    الدور: D/V
 تحقق من أن سير العمل الآلي للاستجابة للحوادث يمكنه عزل النماذج المُخترقة، حظر المستخدمين الخبيثين، وتصعيد الأحداث الأمنية الحرجة.

---

### C12.3 كشف انحراف النموذج

 #12.3.1    المستوى: 1    الدور: D/V
 تحقق من أن النظام يتتبع مقاييس الأداء الأساسية مثل الدقة، درجات الثقة، الكمون، ومعدلات الأخطاء عبر نسخ النماذج والفترات الزمنية.
 #12.3.2    المستوى: 2    الدور: D/V
 تحقق من أن التنبيهات الآلية تعمل عندما تتجاوز مقاييس الأداء حدود التدهور المحددة مسبقًا أو تنحرف بشكل كبير عن الخطوط الأساسية.
 #12.3.3    المستوى: 2    الدور: D/V
 تحقق من أن مراقبي الكشف عن الهلوسة يحددون ويعلمون عند وجود حالات تحتوي مخرجات النموذج على معلومات غير دقيقة من الناحية الواقعية، أو متناقضة، أو مختلقة.

---

### C12.4 قياس الأداء والسلوك

 #12.4.1    المستوى: 1    الدور: D/V
 تحقق من أن المقاييس التشغيلية بما في ذلك زمن استجابة الطلب، استهلاك الرموز، استخدام الذاكرة، ومعدل الإنتاج يتم جمعها ومراقبتها بشكل مستمر.
 #12.4.2    المستوى: 1    الدور: D/V
 تحقق من تتبع نسب النجاح والفشل مع تصنيف أنواع الأخطاء وأسبابها الجذرية.
 #12.4.3    المستوى: 2    الدور: D/V
 تحقق من أن مراقبة استخدام الموارد تشمل استخدام GPU/CPU، واستهلاك الذاكرة، ومتطلبات التخزين مع التنبيه عند تجاوز العتبات.

---

### C12.5 تخطيط وتنفيذ الاستجابة لحوادث الذكاء الاصطناعي

 #12.5.1    المستوى: 1    الدور: D/V
 تحقق من أن خطط الاستجابة للحوادث تعالج بشكل خاص الأحداث الأمنية المتعلقة بالذكاء الاصطناعي بما في ذلك اختراق النموذج، وتسمم البيانات، والهجمات العدائية.
 #12.5.2    المستوى: 2    الدور: D/V
 تحقق من أن فرق الاستجابة للحوادث تمتلك إمكانية الوصول إلى أدوات الطب الشرعي الخاصة بالذكاء الاصطناعي والخبرة اللازمة للتحقيق في سلوك النماذج ومسارات الهجوم.
 #12.5.3    المستوى: 3    الدور: D/V
 تحقق من أن تحليل ما بعد الحادث يشمل اعتبارات إعادة تدريب النموذج، وتحديثات مرشحات السلامة، ودمج الدروس المستفادة في ضوابط الأمان.

---

### C12.5 اكتشاف تدهور أداء الذكاء الاصطناعي

مراقبة واكتشاف تدهور أداء وجودة نموذج الذكاء الاصطناعي مع مرور الوقت.

 #12.5.1    المستوى: 1    الدور: D/V
 تحقق من أن دقة النموذج، والدقة، والاسترجاع، ودرجات F1 تتم مراقبتها باستمرار ومقارنتها بمعايير الخط الأساس.
 #12.5.2    المستوى: 1    الدور: D/V
 تحقق من أن كشف انحراف البيانات يراقب تغييرات توزيع المدخلات التي قد تؤثر على أداء النموذج.
 #12.5.3    المستوى: 2    الدور: D/V
 تحقق من أن اكتشاف انحراف المفهوم يحدد التغيرات في العلاقة بين المدخلات والمخرجات المتوقعة.
 #12.5.4    المستوى: 2    الدور: D/V
 تحقق من أن تدهور الأداء يؤدي إلى تشغيل التنبيهات الآلية وبدء سير عمل إعادة تدريب النموذج أو استبداله.
 #12.5.5    المستوى: 3    الدور: V
 تحقق من أن تحليل سبب الجذر للتدهور يربط بين انخفاض الأداء وتغيرات البيانات أو مشاكل البنية التحتية أو العوامل الخارجية.

---

### C12.6 تصور الرسم البياني الموجه بدون دورات وأمان سير العمل

حماية أنظمة تصور سير العمل من تسرب المعلومات وهجمات التلاعب.

 #12.6.1    المستوى: 1    الدور: D/V
 تحقق من أن بيانات تصور DAG يتم تنقيتها لإزالة المعلومات الحساسة قبل التخزين أو النقل.
 #12.6.2    المستوى: 1    الدور: D/V
 تحقق من أن ضوابط الوصول لتصور سير العمل تضمن أن المستخدمين المصرح لهم فقط يمكنهم عرض مسارات قرارات الوكلاء وتتبع الأسباب.
 #12.6.3    المستوى: 2    الدور: D/V
 تحقق من أن سلامة بيانات DAG محمية من خلال التوقيعات التشفيرية وآليات التخزين المقاومة للتلاعب.
 #12.6.4    المستوى: 2    الدور: D/V
 تحقق من أن أنظمة تصور سير العمل تقوم بتنفيذ التحقق من صحة المدخلات لمنع هجمات الحقن من خلال بيانات العقد أو الحواف المُصممة.
 #12.6.5    المستوى: 3    الدور: D/V
 تحقق من أن تحديثات DAG في الوقت الحقيقي محدودة المعدل ومحققة لمنع هجمات حرمان الخدمة على أنظمة التصور.

---

### C12.7 المراقبة الاستباقية لسلوك الأمان

الكشف والوقاية من التهديدات الأمنية من خلال تحليل سلوك الوكلاء الاستباقي.

 #12.7.1    المستوى: 1    الدور: D/V
 تحقق من أن سلوكيات الوكيل الاستباقي تم التحقق من أمانها قبل التنفيذ مع دمج تقييم المخاطر.
 #12.7.2    المستوى: 2    الدور: D/V
 تحقق من أن المحفزات للمبادرة الذاتية تشمل تقييم سياق الأمان وتقييم مشهد التهديدات.
 #12.7.3    المستوى: 2    الدور: D/V
 تحقق من تحليل أنماط السلوك الاستباقي من حيث الآثار الأمنية المحتملة والتبعات غير المقصودة.
 #12.7.4    المستوى: 3    الدور: D/V
 تحقق من أن الإجراءات الاستباقية الحساسة للأمان تتطلب سلاسل موافقة صريحة مع سجلات تدقيق.
 #12.7.5    المستوى: 3    الدور: D/V
 تحقق من أن اكتشاف الشذوذ السلوكي يحدد الانحرافات في أنماط الوكيل الاستباقي التي قد تشير إلى تعرض للاختراق.

---

### المراجع

NIST AI Risk Management Framework 1.0 - Manage 4.1 and 4.3
ISO/IEC 42001:2023 — AI Management Systems Requirements - Annex B 6.2.6
EU AI Act — Article 12, 13, 16 and 19 on Logging and Record-keeping

## C13 الإشراف البشري والمساءلة والحوكمة

### هدف التحكم

يوفر هذا الفصل متطلبات للحفاظ على الإشراف البشري وسلاسل المحاسبة الواضحة في أنظمة الذكاء الاصطناعي، مع ضمان القابلية للتفسير والشفافية والإشراف الأخلاقي طوال دورة حياة الذكاء الاصطناعي.

---

### C13.1 آليات مفتاح الإيقاف والتجاوز

توفير مسارات للإغلاق أو التراجع عند ملاحظة سلوك غير آمن لنظام الذكاء الاصطناعي.

 #13.1.1    المستوى: 1    الدور: D/V
 تحقق من وجود آلية قتل يدوي توقف فوراً استنتاجات ونواتج نموذج الذكاء الاصطناعي.
 #13.1.2    المستوى: 1    الدور: D
 تحقق من أن عناصر التحكم في التجاوز متاحة فقط للأشخاص المصرح لهم.
 #13.1.3    المستوى: 3    الدور: D/V
 تحقق من أن إجراءات التراجع يمكنها العودة إلى إصدارات النماذج السابقة أو عمليات الوضع الآمن.
 #13.1.4    المستوى: 3    الدور: V
 تحقق من أن آليات التجاوز تُختبر بانتظام.

---

### C13.2 نقاط التحقق من القرار بمشاركة الإنسان في الحلقة

تتطلب الموافقات البشرية عندما تتجاوز المخاطر مستويات المخاطر المحددة مسبقاً.

 #13.2.1    المستوى: 1    الدور: D/V
 تحقق من أن قرارات الذكاء الاصطناعي عالية المخاطر تتطلب موافقة بشرية صريحة قبل التنفيذ.
 #13.2.2    المستوى: 1    الدور: D
 تحقق من أن حدود المخاطر محددة بوضوح وتؤدي تلقائيًا إلى تفعيل إجراءات مراجعة بشرية.
 #13.2.3    المستوى: 2    الدور: D
 تحقق من أن القرارات الحساسة للوقت تحتوي على إجراءات بديلة في حال عدم إمكانية الحصول على موافقة بشرية ضمن الأطر الزمنية المطلوبة.
 #13.2.4    المستوى: 3    الدور: D/V
 تحقق من أن إجراءات التصعيد تحدد مستويات سلطة واضحة لأنواع القرارات المختلفة أو فئات المخاطر، إذا كان ذلك ممكنًا.

---

### السلسلة 13.3: سلسلة المسؤولية وقابلية التدقيق

سجل إجراءات المشغل وقرارات النموذج.

 #13.3.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع قرارات نظام الذكاء الاصطناعي والتدخلات البشرية مسجلة مع علامات زمنية، وهويات المستخدمين، ومنطق القرار.
 #13.3.2    المستوى: 2    الدور: D
 تأكد من أن سجلات التدقيق لا يمكن العبث بها وأنها تتضمن آليات للتحقق من السلامة.

---

### C13.4 تقنيات الذكاء الاصطناعي القابل للتفسير

أهمية ميزات السطح، العكسيات، والتفسيرات المحلية.

 #13.4.1    المستوى: 1    الدور: D/V
 تحقق من أن أنظمة الذكاء الاصطناعي تقدم تفسيرات أساسية لقراراتها بصيغة قابلة للقراءة من قبل البشر.
 #13.4.2    المستوى: 2    الدور: V
 التحقق من جودة الشرح يتم من خلال دراسات التقييم البشري والمقاييس.
 #13.4.3    المستوى: 3    الدور: D/V
 تحقق من توفر درجات أهمية الميزات أو طرق النسبة (SHAP، LIME، إلخ) للقرارات الحرجة.
 #13.4.4    المستوى: 3    الدور: V
 تحقق من أن التفسيرات المضادة (counterfactual explanations) توضح كيف يمكن تعديل المدخلات لتغيير النتائج، إذا كان ذلك ينطبق على حالة الاستخدام والمجال.

---

### بطاقات نموذج C13.5 والإفصاحات الخاصة بالاستخدام

الحفاظ على بطاقات النماذج للاستخدام المقصود، مؤشرات الأداء، والاعتبارات الأخلاقية.

 #13.5.1    المستوى: 1    الدور: D
 تحقق من أن بطاقات النماذج توثق حالات الاستخدام المقصودة، والقيود، وأنماط الفشل المعروفة.
 #13.5.2    المستوى: 1    الدور: D/V
 تحقق من الإفصاح عن مقاييس الأداء عبر مختلف حالات الاستخدام المناسبة.
 #13.5.3    المستوى: 2    الدور: D
 تحقق من توثيق ومراجعة الاعتبارات الأخلاقية، وتقييمات التحيز، وتقييمات العدالة، وخصائص بيانات التدريب، والقيود المعروفة لبيانات التدريب بشكل منتظم ومحدث.
 #13.5.4    المستوى: 2    الدور: D/V
 تحقق من أن بطاقات النماذج تخضع للتحكم في الإصدارات ويتم صيانتها طوال دورة حياة النموذج مع تتبع التغييرات.

---

### C13.6 التحقق من عدم اليقين

نشر درجات الثقة أو مقاييس الانتروبيا في الاستجابات.

 #13.6.1    المستوى: 1    الدور: D
 تحقق من أن أنظمة الذكاء الاصطناعي تقدم درجات الثقة أو مقاييس عدم اليقين مع مخرجاتها.
 #13.6.2    المستوى: 2    الدور: D/V
 تحقق من أن عتبات عدم اليقين تؤدي إلى مراجعة بشرية إضافية أو مسارات قرار بديلة.
 #13.6.3    المستوى: 2    الدور: V
 تحقق من أن طرق قياس عدم اليقين معايرة ومحققة مقابل بيانات الحقيقة الأساسية.
 #13.6.4    المستوى: 3    الدور: D/V
 تحقق من أن انتقال عدم اليقين يتم الحفاظ عليه عبر سير العمل متعدد الخطوات للذكاء الاصطناعي.

---

### تقارير الشفافية الموجهة للمستخدمين C13.7

تقديم إفصاحات دورية حول الحوادث، والانحراف، واستخدام البيانات.

 #13.7.1    المستوى: 1    الدور: D/V
 تحقق من أن سياسات استخدام البيانات وممارسات إدارة موافقة المستخدم يتم توصيلها بوضوح إلى أصحاب المصلحة.
 #13.7.2    المستوى: 2    الدور: D/V
 تحقق من إجراء تقييمات تأثير الذكاء الاصطناعي وتضمين النتائج في التقارير.
 #13.7.3    المستوى: 2    الدور: D/V
 تحقق من أن تقارير الشفافية المنشورة بانتظام تكشف عن حوادث الذكاء الاصطناعي ومقاييس التشغيل بتفاصيل معقولة.

#### المراجع

EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
ISO/IEC 42001:2023 — AI Management Systems Requirements
NIST AI Risk Management Framework 1.0
NIST SP 800-53 Revision 5 — Security and Privacy Controls
A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)
Model Cards for Model Reporting (Mitchell et al., 2018)
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)
ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods
IEEE 7001-2021 — Transparency of Autonomous Systems
GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)
Human Oversight under Article 14 of the EU AI Act (Fink, 2025)

## الملحق أ: مسرد المصطلحات

يقدم هذا المسرد الشامل تعريفات للمصطلحات الرئيسية في الذكاء الاصطناعي، وتعلم الآلة، والأمان المستخدمة في جميع أنحاء AISVS لضمان الوضوح والفهم المشترك.

مثال عدائي: إدخال مصمم عمدًا لجعل نموذج الذكاء الاصطناعي يرتكب خطأً، غالبًا من خلال إضافة اضطرابات دقيقة غير ملحوظة للبشر.
​
الصلابة ضد الهجمات العدائية – تشير الصلابة ضد الهجمات العدائية في الذكاء الاصطناعي إلى قدرة النموذج على الحفاظ على أدائه ومقاومة أن يُخدع أو يُتلاعب به من خلال مدخلات خبيثة مصممة عمدًا لإحداث أخطاء.
​
الوكيل – الوكلاء الذكيون هم أنظمة برمجية تستخدم الذكاء الاصطناعي لتحقيق الأهداف وإتمام المهام نيابةً عن المستخدمين. يظهرون القدرة على التفكير، والتخطيط، والذاكرة، ولديهم درجة من الاستقلالية لاتخاذ القرارات، والتعلم، والتكيف.
​
الذكاء الاصطناعي الوكلي: أنظمة الذكاء الاصطناعي التي يمكنها العمل بدرجة من الاستقلالية لتحقيق الأهداف، وغالبًا ما تتخذ قرارات وتتخذ إجراءات دون تدخل بشري مباشر.
​
التحكم في الوصول بناءً على السمات (ABAC): هو نموذج تحكم في الوصول حيث تعتمد قرارات التفويض على سمات المستخدم، والموارد، والإجراء، والبيئة، ويتم تقييمها في وقت الاستعلام.
​
هجوم الباب الخلفي: نوع من هجمات تسميم البيانات يتم فيه تدريب النموذج على الاستجابة بطريقة محددة لمؤثرات معينة مع التصرف بشكل طبيعي في الحالات الأخرى.
​
التحيز: أخطاء منهجية في مخرجات نموذج الذكاء الاصطناعي يمكن أن تؤدي إلى نتائج غير عادلة أو تمييزية لفئات معينة أو في سياقات محددة.
​
استغلال التحيز: تقنية هجوم تستغل التحيزات المعروفة في نماذج الذكاء الاصطناعي للتلاعب بالمخرجات أو النتائج.
​
Cedar: لغة السياسات ومحركها من أمازون للأذونات الدقيقة المستخدمة في تنفيذ التحكم بالوصول القائم على السمات (ABAC) لأنظمة الذكاء الاصطناعي.
​
سلسلة التفكير: تقنية لتحسين الاستدلال في نماذج اللغة من خلال توليد خطوات استدلالية وسيطة قبل إنتاج الإجابة النهائية.
​
قواطع الدوائر: آليات تقوم بإيقاف عمليات نظام الذكاء الاصطناعي تلقائيًا عند تجاوز حدود معينة للمخاطر.
​
تسرب البيانات: التعرض غير المقصود للمعلومات الحساسة من خلال مخرجات أو سلوك نموذج الذكاء الاصطناعي.
​
تسميم البيانات: الفساد المتعمد لبيانات التدريب لتقويض سلامة النموذج، غالبًا لتثبيت أبواب خلفية أو تقليل الأداء.
​
الخصوصية التفاضلية – الخصوصية التفاضلية هي إطار صارم رياضيًا لإصدار معلومات إحصائية حول مجموعات البيانات مع حماية خصوصية الأفراد. تمكن حامل البيانات من مشاركة الأنماط الإجمالية للمجموعة مع الحد من تسرب المعلومات المتعلقة بأفراد معينين.
​
التضمينات: تمثيلات متجهة كثيفة للبيانات (النصوص، الصور، إلخ) تلتقط المعنى الدلالي في فضاء عالي الأبعاد.
​
القابلية للتفسير – القابلية للتفسير في الذكاء الاصطناعي هي قدرة نظام الذكاء الاصطناعي على تقديم أسباب مفهومة للبشر لقراراته وتنبؤاته، مما يوفر رؤى حول آلياته الداخلية.
​
الذكاء الاصطناعي القابل للتفسير (XAI): أنظمة الذكاء الاصطناعي المصممة لتقديم تفسيرات يمكن للبشر فهمها لقراراتها وسلوكياتها من خلال تقنيات وأُطُر مختلفة.
​
التعلم الموزع: هو نهج في التعلم الآلي حيث يتم تدريب النماذج عبر عدة أجهزة لا مركزية تحتفظ بعينات بيانات محلية، دون تبادل البيانات نفسها.
​
خطوط الحماية: قيود تُطبق لمنع أنظمة الذكاء الاصطناعي من إنتاج مخرجات ضارة أو متحيزة أو غير مرغوب فيها بأي شكل آخر.
​
الهلاوس – تشير هلاوس الذكاء الاصطناعي إلى ظاهرة يقوم فيها نموذج الذكاء الاصطناعي بتوليد معلومات غير صحيحة أو مضللة لا تستند إلى بيانات التدريب الخاصة به أو الواقع الفعلي.
​
الإنسان في الحلقة (HITL): أنظمة مصممة لتتطلب إشراف الإنسان أو التحقق منه أو تدخله في نقاط اتخاذ القرار الحاسمة.
​
البنية التحتية كرمز (IaC): إدارة وتوفير البنية التحتية من خلال الكود بدلاً من العمليات اليدوية، مما يتيح فحص الأمان ونشرًا متسقًا.
​
الهروب من القيود: تقنيات تُستخدم لتجاوز الحواجز الأمنية في أنظمة الذكاء الاصطناعي، خصوصاً في نماذج اللغة الكبيرة، لإنتاج محتوى محظور.
​
الحد الأدنى من الامتيازات: مبدأ الأمان الذي ينص على منح حد الوصول الأدنى الضروري فقط للمستخدمين والعمليات.
​
LIME (التفسيرات القابلة للتفسير محليًا والخالية من الاعتماد على النموذج): تقنية لشرح توقعات أي مصنف تعلم آلي من خلال تقريبها محليًا باستخدام نموذج يمكن تفسيره.
​
هجوم استنتاج العضوية: هو هجوم يهدف إلى تحديد ما إذا تم استخدام نقطة بيانات معينة في تدريب نموذج تعلُّم الآلة.
​
MITRE ATLAS: مشهد التهديدات العدائية لأنظمة الذكاء الاصطناعي؛ قاعدة معرفة بالتكتيكات والتقنيات العدائية ضد أنظمة الذكاء الاصطناعي.
​
بطاقة النموذج – بطاقة النموذج هي وثيقة توفر معلومات موحدة حول أداء نموذج الذكاء الاصطناعي، وقيوده، والاستخدامات المقصودة، والاعتبارات الأخلاقية لتعزيز الشفافية والتنمية المسؤولة للذكاء الاصطناعي.
​
استخلاص النموذج: هجوم يقوم فيه الخصم باستمرار باستجواب نموذج مستهدف لإنشاء نسخة مشابهة وظيفيًا دون إذن.
​
انعكاس النموذج: هجوم يحاول إعادة بناء بيانات التدريب من خلال تحليل مخرجات النموذج.
​
إدارة دورة حياة النموذج – إدارة دورة حياة نموذج الذكاء الاصطناعي هي عملية الإشراف على جميع مراحل وجود نموذج الذكاء الاصطناعي، بما في ذلك تصميمه، تطويره، نشره، مراقبته، صيانته، والتقاعد النهائي له، لضمان استمراره في الفعالية والتوافق مع الأهداف.
​
تسميم النموذج: إدخال ثغرات أو أبواب خلفية مباشرة في النموذج أثناء عملية التدريب.
​
سرقة/استنساخ النموذج: استخراج نسخة أو تقريبي من نموذج ملكية من خلال الاستفسارات المتكررة.
​
نظام متعدد الوكلاء: نظام يتكون من عدة وكلاء ذكاء اصطناعي متفاعلين، كل منهم يمتلك قدرات وأهداف قد تكون مختلفة.
​
OPA (وكيل السياسة المفتوحة): هو محرك سياسات مفتوح المصدر يتيح تنفيذ السياسات الموحدة عبر النظام.
​
تعلم الآلة مع الحفاظ على الخصوصية (PPML): تقنيات وأساليب لتدريب ونشر نماذج تعلم الآلة مع حماية خصوصية بيانات التدريب.
​
حقن الإرشادات: هجوم يتم فيه تضمين تعليمات خبيثة في المدخلات لتجاوز سلوك النموذج المقصود.
​
RAG (التوليد المعزز بالاسترجاع): تقنية تعزز نماذج اللغة الكبيرة من خلال استرجاع المعلومات ذات الصلة من مصادر المعرفة الخارجية قبل توليد الاستجابة.
​
الهجوم الأحمر: ممارسة اختبار أنظمة الذكاء الاصطناعي بنشاط من خلال محاكاة الهجمات العدائية لتحديد نقاط الضعف.
​
SBOM (قائمة مكونات البرمجيات): سجل رسمي يحتوي على تفاصيل وعلاقات سلسلة التوريد لمكونات مختلفة تُستخدم في بناء البرمجيات أو نماذج الذكاء الاصطناعي.
​
SHAP (تفسيرات شابلي الإضافية): نهج يعتمد على نظرية الألعاب لشرح مخرجات أي نموذج تعلم آلي من خلال حساب مساهمة كل ميزة في التنبؤ.
​
هجوم سلسلة التوريد: اختراق نظام عن طريق استهداف العناصر الأقل أمانًا في سلسلة التوريد الخاصة به، مثل المكتبات الخارجية، مجموعات البيانات، أو النماذج المدربة مسبقًا.
​
التعلم بالنقل: تقنية يُعاد فيها استخدام نموذج تم تطويره لمهمة واحدة كنقطة انطلاق لنموذج في مهمة ثانية.
​
قاعدة بيانات المتجهات: قاعدة بيانات متخصصة مصممة لتخزين المتجهات عالية الأبعاد (التضمينات) وأداء عمليات بحث تشابه فعالة.
​
فحص الثغرات الأمنية: أدوات آلية تحدد الثغرات الأمنية المعروفة في مكونات البرمجيات، بما في ذلك أُطُر الذكاء الاصطناعي والاعتمادات التابعة لها.
​
وضع العلامات المائية: تقنيات لدمج علامات غير مرئية في المحتوى المُنشأ بواسطة الذكاء الاصطناعي لتتبع أصله أو الكشف عن التوليد بواسطة الذكاء الاصطناعي.
​
ثغرة اليوم الصفري: هي ثغرة غير معروفة سابقًا يمكن للمهاجمين استغلالها قبل أن يقوم المطورون بإنشاء ونشر تصحيح.

## الملحق ب: المراجع

### TODO

## الملحق ج: حوكمة أمان الذكاء الاصطناعي والتوثيق

### الهدف

يوفر هذا الملحق المتطلبات الأساسية لإنشاء هياكل تنظيمية وسياسات وعمليات لإدارة أمان الذكاء الاصطناعي طوال دورة حياة النظام.

---

### اعتماد إطار إدارة مخاطر الذكاء الاصطناعي AC.1

توفير إطار عمل رسمي لتحديد وتقييم وتخفيف المخاطر الخاصة بالذكاء الاصطناعي في جميع مراحل دورة حياة النظام.

 #AC.1.1    المستوى: 1    الدور: D/V
 تحقق من توثيق وتنفيذ منهجية تقييم المخاطر المخصصة للذكاء الاصطناعي.
 #AC.1.2    المستوى: 2    الدور: D
 تحقق من إجراء تقييمات المخاطر في النقاط الرئيسية في دورة حياة الذكاء الاصطناعي وقبل التغييرات الكبيرة.
 #AC.1.3    المستوى: 3    الدور: D/V
 تحقق من أن إطار إدارة المخاطر يتماشى مع المعايير المعتمدة (مثل NIST AI RMF).

---

### سياسة وإجراءات أمان الذكاء الاصطناعي AC.2

تعريف وفرض معايير تنظيمية لتطوير ونشر وتشغيل الذكاء الاصطناعي بأمان.

 #AC.2.1    المستوى: 1    الدور: D/V
 تحقق من وجود سياسات أمان ذكاء اصطناعي موثقة.
 #AC.2.2    المستوى: 2    الدور: D
 التحقق من مراجعة السياسات وتحديثها على الأقل سنويًا وبعد حدوث تغييرات كبيرة في مشهد التهديدات.
 #AC.2.3    المستوى: 3    الدور: D/V
 تحقق من أن السياسات تغطي جميع فئات AISVS والمتطلبات التنظيمية المعمول بها.

---

### AC.3 الأدوار والمسؤوليات لأمن الذكاء الاصطناعي

إرساء مسؤولية واضحة لأمن الذكاء الاصطناعي عبر المؤسسة.

 #AC.3.1    المستوى: 1    الدور: D/V
 تحقق من توثيق أدوار ومسؤوليات أمن الذكاء الاصطناعي.
 #AC.3.2    المستوى: 2    الدور: D
 التحقق من أن الأفراد المسؤولين يمتلكون الخبرة الأمنية المناسبة.
 #AC.3.3    المستوى: 3    الدور: D/V
 تحقق من تأسيس لجنة أخلاقيات الذكاء الاصطناعي أو مجلس حوكمة لأنظمة الذكاء الاصطناعي عالية المخاطر.

---

### AC.4 تنفيذ إرشادات الذكاء الاصطناعي الأخلاقي

ضمان عمل أنظمة الذكاء الاصطناعي وفقًا للمبادئ الأخلاقية المعمول بها.

 #AC.4.1    المستوى: 1    الدور: D/V
 تحقق من وجود إرشادات أخلاقية لتطوير ونشر الذكاء الاصطناعي.
 #AC.4.2    المستوى: 2    الدور: D
 تحقق من وجود آليات للكشف عن انتهاكات الأخلاقيات والإبلاغ عنها.
 #AC.4.3    المستوى: 3    الدور: D/V
 تحقق من إجراء مراجعات أخلاقية منتظمة لأنظمة الذكاء الاصطناعي المنشورة.

---

### AC.5 مراقبة الامتثال التنظيمي للذكاء الاصطناعي

الحفاظ على الوعي والامتثال للوائح الذكاء الاصطناعي المتطورة.

 #AC.5.1    المستوى: 1    الدور: D/V
 تحقق من وجود عمليات لتحديد اللوائح التنظيمية للذكاء الاصطناعي ذات الصلة.
 #AC.5.2    المستوى: 2    الدور: D
 تحقق من تقييم الامتثال لجميع المتطلبات التنظيمية.
 #AC.5.3    المستوى: 3    الدور: D/V
 تحقق من أن التغييرات التنظيمية تؤدي إلى مراجعات وتحديثات في الوقت المناسب لأنظمة الذكاء الاصطناعي.

### AC.6 حوكمة بيانات التدريب، التوثيق والعمليات

 #1.1.2    المستوى: 1    الدور: D/V
 تحقق من أنه يسمح فقط بمجموعات البيانات التي تم التحقق من جودتها، وتمثيلها، ومصادرها الأخلاقية، والامتثال للترخيص، مما يقلل من مخاطر التسمم، والانحياز المدمج، وانتهاك حقوق الملكية الفكرية.
 #1.1.5    المستوى: 2    الدور: D/V
 تحقق من ضمان جودة التسمية/التعليق من خلال عمليات التحقق المتبادلة للمراجعين أو التوافق الجماعي.
 #1.1.6    المستوى: 2    الدور: D/V
 تحقق من أن "بطاقات البيانات" أو "صحائف البيانات لمجموعات البيانات" يتم الحفاظ عليها لمجموعات البيانات التدريبية الهامة، مع تفصيل الخصائص، الدوافع، التكوين، عمليات الجمع، المعالجة المسبقة، والاستخدامات الموصى بها/المحرَّضة.
 #1.3.2    المستوى: 2    الدور: D/V
 تحقق من أن التحيزات المحددة قد تم التخفيف منها عبر استراتيجيات موثقة مثل إعادة التوازن، وتعزيز البيانات المستهدفة، والتعديلات الخوارزمية (مثل تقنيات المعالجة المسبقة، والمعالجة أثناء التنفيذ، والمعالجة اللاحقة)، أو إعادة التوزين، ويتم تقييم تأثير التخفيف على كل من الإنصاف والأداء العام للنموذج.
 #1.3.3    المستوى: 2    الدور: D/V
 تحقق من تقييم وتوثيق مقاييس العدالة بعد التدريب.
 #1.3.4    المستوى: 3    الدور: D/V
 تحقق من أن سياسة إدارة تحيّز دورة الحياة تحدد المالكين وتيرة المراجعة.
 #1.4.1    المستوى: 2    الدور: D/V
 تأكد من ضمان جودة الوسم/التعليق من خلال إرشادات واضحة، والتدقيق المتبادل بين المراجعين، وآليات التوافق (مثل مراقبة اتفاق المثمنين)، والعمليات المحددة لحل التباينات.
 #1.4.4    المستوى: 3    الدور: D/V
 تحقق من أن العلامات الحرجة للسلامة أو الأمان أو العدالة (مثل تحديد المحتوى السام، النتائج الطبية الحرجة) تخضع لمراجعة مزدوجة مستقلة إلزامية أو تحقق قوي مكافئ.
 #1.4.6    المستوى: 2    الدور: D/V
 تحقق من أن أدلة التعليمات والتعليمات شاملة، وتخضع للتحكم بالإصدارات، ومراجعة من قبل الأقران.
 #1.4.6    المستوى: 2    الدور: D/V
 تحقق من أن مخططات البيانات للتسميات محددة بوضوح وتخضع للتحكم في الإصدارات.
 #1.3.1    المستوى: 1    الدور: D/V
 تحقق من أن مجموعات البيانات قد تم تحليلها للكشف عن عدم التوازن التمثيلي والانحيازات المحتملة عبر السمات المحمية قانونيًا (مثل العرق، الجنس، العمر) والخصائص الحساسة أخلاقيًا الأخرى ذات الصلة بمجال تطبيق النموذج (مثل الحالة الاجتماعية والاقتصادية، الموقع).
 #1.5.3    المستوى: 2    الدور: V
 تحقق من أن الفحوصات اليدوية العشوائية التي يقوم بها خبراء المجال تغطي عينة ذات دلالة إحصائية (مثل ≥1% أو 1,000 عينة، أيهما أكبر، أو كما يحددها تقييم المخاطر) لاكتشاف مشاكل جودة دقيقة لا يتم اكتشافها بواسطة الأتمتة.
 #1.8.4    المستوى: 2    الدور: D/V
 تحقق من أن تدفقات العمل الخاصة بالتصنيف التي يتم استيرادها أو الاستعانة بها تشمل ضمانات تقنية وإجرائية لضمان سرية البيانات وسلامتها وجودة العلامات ومنع تسرب البيانات.
 #1.5.4    المستوى: 2    الدور: D/V
 تحقق من أنه قد تم إرفاق خطوات التصحيح بسجلات الأصول.
 #1.6.2    المستوى: 2    الدور: D/V
 تأكد من أن العينات المعلمة تؤدي إلى مراجعة يدوية قبل التدريب.
 #1.6.3    المستوى: 2    الدور: V
 تحقق من أن النتائج تغذي ملف أمان النموذج وتُعلم استخبارات التهديدات المستمرة.
 #1.6.4    المستوى: 3    الدور: D/V
 تحقق من تحديث منطق الكشف بمعلومات تهديد جديدة.
 #1.6.5    المستوى: 3    الدور: D/V
 تحقق من أن خطوط أنظمة التعلم عبر الإنترنت تراقب انحراف التوزيع.
 #1.7.1    المستوى: 1    الدور: D/V
 التحقق من أن سير عمل حذف بيانات التدريب يقضي على البيانات الأساسية والمشتقة ويقيّم تأثيره على النموذج، وأن يتم تقييم التأثير على النماذج المتأثرة وإذا لزم الأمر معالجته (على سبيل المثال، من خلال إعادة التدريب أو إعادة المعايرة).
 #1.7.2    المستوى: 2    الدور: D
 تحقق من وجود آليات لتتبع واحترام نطاق وحالة موافقة المستخدم (وسحبها) للبيانات المستخدمة في التدريب، وأن يتم التحقق من صحة الموافقة قبل دمج البيانات في عمليات التدريب الجديدة أو التحديثات الهامة للنموذج.
 #1.7.3    المستوى: 2    الدور: V
 تحقق من أن التدفقات التشغيلية تُختبر سنويًا وتُسجل.
 #1.8.1    المستوى: 2    الدور: D/V
 تحقق من أن موردين البيانات من الأطراف الخارجية، بما في ذلك مزودي النماذج المدربة مسبقًا ومجموعات البيانات الخارجية، يمرون بإجراءات العناية الواجبة المتعلقة بالأمان والخصوصية والمصادر الأخلاقية وجودة البيانات قبل دمج بياناتهم أو نماذجهم.
 #1.8.2    المستوى: 1    الدور: D
 تحقق من أن التحويلات الخارجية تستخدم TLS/المصادقة وفحوصات السلامة.
 #1.8.3    المستوى: 2    الدور: D/V
 تحقق من أن مصادر البيانات عالية المخاطر (مثل مجموعات البيانات مفتوحة المصدر ذات الأصل غير المعروف، والموردين غير المعتمدين) تخضع لتدقيق متزايد، مثل التحليل في بيئة معزولة (sandbox)، وفحوصات جودة/تحيز شاملة، والكشف المستهدف عن التسمم، قبل استخدامها في التطبيقات الحساسة.
 #1.8.4    المستوى: 3    الدور: D/V
 تحقق من أن النماذج المدربة مسبقًا التي تم الحصول عليها من أطراف ثالثة قد تم تقييمها للكشف عن التحيزات المضمنة، والبوابات الخلفية المحتملة، وسلامة هيكلها، ومنشأ بيانات التدريب الأصلية قبل إجراء التخصيص الدقيق أو النشر.
 #1.5.3    المستوى: 2    الدور: D/V
 تحقق من أنه إذا تم استخدام التدريب العدائي، فإن توليد مجموعات البيانات العدائية وإدارتها وإصدار نسخ منها موثقة وتخضع للرقابة.
 #1.5.3    المستوى: 3    الدور: D/V
 تحقق من تقييم وتوثيق ورصد تأثير تدريب الصلابة ضد الهجمات العدائية على أداء النموذج (ضد كل من المدخلات النظيفة والعدائية) ومقاييس العدالة.
 #1.5.4    المستوى: 3    الدور: D/V
 التحقق من مراجعة وتحديث استراتيجيات التدريب العدائي والصلابة بشكل دوري لمواجهة تقنيات الهجوم العدائي المتطورة.
 #1.4.2    المستوى: 2    الدور: D/V
 تحقق من أن مجموعات البيانات الفاشلة معزولة مع وجود سجلات تدقيق.
 #1.4.3    المستوى: 2    الدور: D/V
 تحقق من أن بوابات الجودة تمنع مجموعات البيانات الرديئة إلا إذا تم الموافقة على الاستثناءات.
 #1.11.2    المستوى: 2    الدور: D/V
 تحقق من توثيق عملية التوليد، والمعاملات، والاستخدام المقصود للبيانات الاصطناعية.
 #1.11.3    المستوى: 2    الدور: D/V
 تحقق من تقييم مخاطر البيانات الاصطناعية من حيث التحيز وتسرب الخصوصية وقضايا التمثيل قبل استخدامها في التدريب.
 #1.12.3    المستوى: 2    الدور: D/V
 تحقق من إنشاء التنبيهات للأحداث المشبوهة للوصول والتحقيق فيها على الفور.
 #1.13.1    المستوى: 1    الدور: D/V
 تحقق من تحديد فترات الاحتفاظ الصريحة لجميع مجموعات بيانات التدريب.
 #1.13.2    المستوى: 2    الدور: D/V
 تحقق من أن مجموعات البيانات تنتهي صلاحيتها تلقائيًا أو تُحذف أو تُراجع للحذف في نهاية دورة حياتها.
 #1.13.3    المستوى: 2    الدور: D/V
 تحقق من أن إجراءات الاحتفاظ والحذف مسجلة وقابلة للتدقيق.
 #1.14.1    المستوى: 2    الدور: D/V
 تأكد من تحديد ومتطلبات إقامة البيانات ونقلها عبر الحدود وتطبيقها على جميع مجموعات البيانات.
 #1.14.2    المستوى: 2    الدور: D/V
 تحقق من تحديد اللوائح الخاصة بكل قطاع (مثل الرعاية الصحية، المالية) ومعالجتها في معالجة البيانات.
 #1.14.3    المستوى: 2    الدور: D/V
 تحقق من توثيق والاطلاع بانتظام على الامتثال للقوانين الخصوصية ذات الصلة (مثل GDPR، CCPA).
 #1.16.1    المستوى: 2    الدور: D/V
 تحقق من وجود آليات للرد على طلبات موضوع البيانات بالوصول أو التصحيح أو التقييد أو الاعتراض.
 #1.16.2    المستوى: 2    الدور: D/V
 تحقق من تسجيل الطلبات وتتبعها وتنفيذها ضمن الأطر الزمنية التي تفرضها القوانين.
 #1.16.3    المستوى: 2    الدور: D/V
 تأكد من اختبار ومراجعة عمليات حقوق موضوع البيانات بانتظام لضمان فعاليتها.
 #1.17.1    المستوى: 2    الدور: D/V
 تحقق من إجراء تحليل الأثر قبل تحديث أو استبدال إصدار مجموعة البيانات، مع تغطية أداء النموذج، والعدالة، والامتثال.
 #1.17.2    المستوى: 2    الدور: D/V
 تحقق من توثيق نتائج تحليل التأثير ومراجعتها من قبل أصحاب المصلحة المعنيين.
 #1.17.3    المستوى: 2    الدور: D/V
 تحقق من وجود خطط للتراجع في حال أدت الإصدارات الجديدة إلى مخاطر أو تراجعات غير مقبولة.
 #1.18.1    المستوى: 2    الدور: D/V
 تحقق من أن جميع الأفراد المشاركين في توضيح البيانات قد خضعوا لفحص الخلفية وتلقوا تدريبًا في أمان البيانات والخصوصية.
 #1.18.2    المستوى: 2    الدور: D/V
 تحقق من توقيع جميع موظفي التعليقات على اتفاقيات السرية وعدم الإفشاء.
 #1.18.3    المستوى: 2    الدور: D/V
 تحقق من أن منصات التعليقات التوضيحية تفرض ضوابط الوصول وترصد التهديدات الداخلية.

#### المراجع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
EU Artificial Intelligence Act — Regulation (EU) 2024/1689
ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods

## الملحق د: الحوكمة والتحقق من الترميز الآمن بمساعدة الذكاء الاصطناعي

### الهدف

يعرف هذا الفصل الضوابط التنظيمية الأساسية للاستخدام الآمن والفعال لأدوات الترميز المدعومة بالذكاء الاصطناعي خلال تطوير البرمجيات، مع ضمان الأمان وقابلية التتبع عبر دورة حياة تطوير البرمجيات (SDLC).

---

### AD.1 سير عمل التكويد الآمن المدعوم بالذكاء الاصطناعي

دمج أدوات الذكاء الاصطناعي في دورة حياة تطوير البرمجيات الآمنة (SSDLC) للمنظمة دون إضعاف حواجز الأمان الموجودة.

 #AD.1.1    المستوى: 1    الدور: D/V
 تحقق من أن سير العمل الموثق يصف متى وكيف يمكن لأدوات الذكاء الاصطناعي توليد أو إعادة هيكلة أو مراجعة الشيفرة.
 #AD.1.2    المستوى: 2    الدور: D
 تحقق من أن سير العمل يتطابق مع كل مرحلة من مراحل دورة حياة تطوير البرمجيات الآمنة ( SSDLC ) (التصميم، التنفيذ، مراجعة الشفرة، الاختبار، النشر).
 #AD.1.3    المستوى: 3    الدور: D/V
 تحقق من جمع المقاييس (مثل كثافة الثغرات، متوسط الوقت للكشف) على الشفرة الناتجة عن الذكاء الاصطناعي ومقارنتها بالمعايير الأساسية الخاصة بالبشر فقط.

---

### AD.2 تأهيل أداة الذكاء الاصطناعي ونمذجة التهديدات

تأكد من تقييم أدوات ترميز الذكاء الاصطناعي من حيث القدرات الأمنية والمخاطر وتأثير سلسلة التوريد قبل اعتمادها.

 #AD.2.1    المستوى: 1    الدور: D/V
 تحقق من أن نموذج التهديد لكل أداة ذكاء اصطناعي يحدد سوء الاستخدام، والانقلاب النموذجي، وتسرب البيانات، ومخاطر سلسلة الاعتماد.
 #AD.2.2    المستوى: 2    الدور: D
 تحقق من أن تقييمات الأدوات تشمل التحليل الثابت/الديناميكي لأي مكونات محلية وتقييم نقاط نهاية SaaS (TLS، المصادقة/التفويض، التسجيل).
 #AD.2.3    المستوى: 3    الدور: D/V
 تحقق من أن التقييمات تتبع إطارًا معترفًا به وأنه يتم إعادة إجرائها بعد تغييرات الإصدار الرئيسية.

---

### إدارة الأوامر الآمنة والسياق AD.3

منع تسرب الأسرار، الكود الخاص، والبيانات الشخصية عند بناء التعليمات أو السياقات لنماذج الذكاء الاصطناعي.

 #AD.3.1    المستوى: 1    الدور: D/V
 تحقق من أن التوجيهات المكتوبة تمنع إرسال الأسرار أو بيانات الاعتماد أو البيانات المصنفة في المطالبات.
 #AD.3.2    المستوى: 2    الدور: D
 تحقق من أن الضوابط التقنية (إزالة النصوص على جانب العميل، وفلاتر السياق المعتمدة) تقوم تلقائيًا بإزالة العناصر الحساسة.
 #AD.3.3    المستوى: 3    الدور: D/V
 التحقق من أن الطلبات والاستجابات تتم تجزئتها إلى رموز، وتشفيرها أثناء النقل وعند التخزين، وأن فترات الاحتفاظ تتوافق مع سياسة تصنيف البيانات.

---

### AD.4 التحقق من صحة الكود المولد بواسطة الذكاء الاصطناعي

كشف ومعالجة الثغرات التي قد تُنتج عن مخرجات الذكاء الاصطناعي قبل دمج الشيفرة أو نشرها.

 #AD.4.1    المستوى: 1    الدور: D/V
 تأكد من أن الشيفرة التي يولدها الذكاء الاصطناعي تخضع دائمًا لمراجعة الشيفرة البشرية.
 #AD.4.2    المستوى: 2    الدور: D
 تحقق من أن الماسحات الآلية (SAST/IAST/DAST) تعمل على كل طلب سحب يحتوي على كود تم إنشاؤه بواسطة الذكاء الاصطناعي وتمنع الدمج في حالة وجود نتائج حرجة.
 #AD.4.3    المستوى: 3    الدور: D/V
 تحقق من أن اختبار الصدأ التفريقي أو اختبارات القواعد الخصائصية تثبت سلوكيات حرجة للأمان (مثل، التحقق من صحة المدخلات، منطق التفويض).

---

### AD.5 قابلية التفسير وتتبع اقتراحات الكود

تزويد المدققين والمطورين بفهم حول سبب تقديم الاقتراح وكيف تطور.

 #AD.5.1    المستوى: 1    الدور: D/V
 تحقق من أن أزواج المطالبات/الاستجابات مسجلة مع معرفات الالتزام.
 #AD.5.2    المستوى: 2    الدور: D
 التحقق من أن المطورين يمكنهم عرض استشهادات النموذج (مقتطفات التدريب، الوثائق) التي تدعم الاقتراح.
 #AD.5.3    المستوى: 3    الدور: D/V
 تحقق من أن تقارير القابلية للفهم مخزنة مع مستندات التصميم وموثقة في مراجعات الأمان، مما يفي بمبادئ قابلية التتبع في معيار ISO/IEC 42001.

---

### AD.6 التغذية الراجعة المستمرة وضبط نموذج التعلم الدقيق

تحسين أداء أمان النموذج بمرور الوقت مع منع الانحراف السلبي.

 #AD.6.1    المستوى: 1    الدور: D/V
 تحقق من أن المطورين يمكنهم الإشارة إلى الاقتراحات غير الآمنة أو غير المتوافقة، وأنه يتم تتبع هذه الإشارات.
 #AD.6.2    المستوى: 2    الدور: D
 تحقق من أن التغذية الراجعة المجمعة تُستخدم في تحسين النماذج دورياً أو في التوليد المعزز بالاسترجاع باستخدام مجموعات بيانات الترميز الآمن الموثوقة (مثل أوراق الغش OWASP).
 #AD.6.3    المستوى: 3    الدور: D/V
 تحقق من أن إطار التقييم في الحلقة المغلقة يقوم بتشغيل اختبارات الانحدار بعد كل ضبط دقيق؛ يجب أن تفي مقاييس الأمان بالمعايير الأساسية السابقة أو تتجاوزها قبل النشر.

---

#### المراجع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
OWASP Secure Coding Practices — Quick Reference Guide

## الملحق هـ: أمثلة على الأدوات والأُطُر

### الهدف

يوفر هذا الفصل أمثلة على الأدوات والأُطُر التي يمكن أن تدعم تنفيذ أو تحقيق متطلبات AISVS معينة. ولا يجب اعتبار هذه الأمثلة توصيات أو تأييدًا من فريق AISVS أو مشروع أمان GenAI التابع لـ OWASP.

---

### AE.1 حوكمة بيانات التدريب وإدارة التحيز

الأدوات المستخدمة في تحليلات البيانات، والإدارة، وإدارة التحيز.

 #AE.1.1    قسم: 1.1
 أدوات جرد البيانات: أدوات إدارة جرد البيانات مثل...
 #AE.1.2    قسم: 1.2
 التشفير أثناء النقل استخدم TLS لتطبيقات HTTPS، مع أدوات مثل openSSL و python's`ssl`مكتبة.

---

### AE.2 التحقق من صحة إدخال المستخدم

أدوات للتعامل مع مدخلات المستخدم والتحقق من صحتها.

 #AE.2.1    قسم: 2.1
 أدوات الدفاع ضد حقن التعليمات البرمجية: استخدم أدوات الحماية مثل NeMo من NVIDIA أو Guardrails AI.

---

