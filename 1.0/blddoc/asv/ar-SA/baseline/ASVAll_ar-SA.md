## الصفحة التمهيدية

### حول المعيار

معيار التحقق من أمان الذكاء الاصطناعي (AISVS) هو كتالوج يقوده المجتمع يحتوي على متطلبات الأمان التي يمكن لعلماء البيانات، ومهندسي MLOps، والمهندسين المعماريين للبرمجيات، والمطورين، والمختبرين، وخبراء الأمان، وبائعي الأدوات، والمنظمين، والمستهلكين استخدامها لتصميم وبناء واختبار والتحقق من أنظمة وتطبيقات الذكاء الاصطناعي الموثوقة. يوفر معيار AISVS لغة مشتركة لتحديد ضوابط الأمان عبر دورة حياة الذكاء الاصطناعي—من جمع البيانات وتطوير النماذج إلى النشر والمراقبة المستمرة—حتى تتمكن المؤسسات من قياس وتحسين مرونة وخصوصية وسلامة حلول الذكاء الاصطناعي لديها.

### حقوق النشر والترخيص

الإصدار 0.1 (المسودة العامة الأولى - العمل جار)، 2025  

![license](images/license.png)
حقوق الطبع والنشر © 2025 مشروع AISVS.  

تم إصداره تحتCreative Commons Attribution‑ShareAlike 4.0 International License.
لأي إعادة استخدام أو توزيع، يجب عليك توضيح شروط الترخيص لهذا العمل للآخرين بوضوح.

### قادة المشروع

جيم مانيكو
أراس "روس" ميميسيازيتشي

### المساهمون والمراجعون

https://github.com/ottosulin
https://github.com/mbhatt1
https://github.com/vineethsai
https://github.com/cciprofm
https://github.com/deepakrpandey12


---

AISVS هو معيار جديد تمامًا تم إنشاؤه خصيصًا لمعالجة التحديات الأمنية الفريدة لأنظمة الذكاء الاصطناعي. وبينما يستلهم منه الممارسات الأمنية العامة الأفضل، تم تطوير كل متطلب في AISVS من الصفر ليعكس مشهد التهديدات في الذكاء الاصطناعي ولمساعدة المؤسسات على بناء حلول ذكاء اصطناعي أكثر أمانًا ومرونة.

## المقدمة

مرحبًا بكم في معيار التحقق من أمان الذكاء الاصطناعي (AISVS) الإصدار 1.0!

### مقدمة

تأسست AISVS في عام 2025 من خلال جهد مجتمعي تعاوني، وهي تحدد متطلبات الأمان التي يجب مراعاتها عند تصميم وتطوير ونشر وتشغيل نماذج الذكاء الاصطناعي الحديثة، وسلاسل العمليات، والخدمات المدعومة بالذكاء الاصطناعي.

تمثل AISVS v1.0 العمل المشترك لقادة المشروع، ومجموعة العمل، والمساهمين من المجتمع الأوسع لإنتاج معيار عملي وقابل للاختبار لتأمين أنظمة الذكاء الاصطناعي.

هدفنا في هذا الإصدار هو جعل AISVS سهل التبني مع الحفاظ على التركيز الدقيق على نطاقه المحدد ومعالجة المشهد السريع التطور للمخاطر الفريدة المرتبطة بالذكاء الاصطناعي.

### الأهداف الرئيسية لإصدار AISVS 1.0

سيتم إنشاء الإصدار 1.0 مع عدة مبادئ توجيهية.

#### نطاق محدد جيدًا

يجب أن يتماشى كل متطلب مع اسم وأهداف AISVS:

الذكاء الاصطناعي – تعمل الضوابط على طبقة الذكاء الاصطناعي/التعلم الآلي (البيانات، النموذج، خط الأنابيب، أو الاستدلال) وتكون مسؤولية ممارسي الذكاء الاصطناعي.
الأمن – المتطلبات تقلل مباشرة من المخاطر المحددة المتعلقة بالأمن أو الخصوصية أو السلامة.
التحقق – اللغة مكتوبة بحيث يمكن التحقق من الامتثال بشكل موضوعي.
المعيار – تتبع الأقسام هيكلًا ومصطلحات متسقة لتشكيل مرجع متماسك.
​
---

من خلال اتباع AISVS، يمكن للمنظمات تقييم وتقوية وضع الأمان لحلول الذكاء الاصطناعي الخاصة بها بشكل منهجي، مما يعزز ثقافة هندسة الذكاء الاصطناعي الآمنة.

## باستخدام AISVS

يحدد معيار التحقق من أمان الذكاء الاصطناعي (AISVS) متطلبات الأمان لتطبيقات وخدمات الذكاء الاصطناعي الحديثة، مع التركيز على الجوانب التي تقع تحت سيطرة مطوري التطبيقات.

يستهدف AISVS أي شخص يقوم بتطوير أو تقييم أمان تطبيقات الذكاء الاصطناعي، بما في ذلك المطورين، والمصممين، ومهندسي الأمان، والمدققين. تقدم هذه الفصل هيكل واستخدام AISVS، بما في ذلك مستويات التحقق الخاصة به وحالات الاستخدام المقصودة.

### مستويات تحقق أمان الذكاء الاصطناعي

تعرف AISVS ثلاث مستويات متصاعدة من التحقق الأمني. يضيف كل مستوى المزيد من العمق والتعقيد، مما يمكن المؤسسات من تكييف موقفها الأمني مع مستوى المخاطر في أنظمة الذكاء الاصطناعي الخاصة بها.

قد تبدأ المنظمات بالمستوى 1 وتتقدم تدريجيًا لاعتماد مستويات أعلى مع زيادة نضج الأمان وتعاظم التعرض للتهديدات.

#### تعريف المستويات

يتم تخصيص كل متطلب في AISVS الإصدار 1.0 إلى أحد المستويات التالية:

 متطلبات المستوى 1

المستوى 1 يشمل متطلبات الأمان الأكثر أهمية وأساسًا. تتركز هذه المتطلبات على منع الهجمات الشائعة التي لا تعتمد على شروط مسبقة أو ثغرات أخرى. معظم ضوابط المستوى 1 إما سهلة التنفيذ أو ضرورية بما يكفي لتبرير الجهد المبذول.

 متطلبات المستوى 2

يتناول المستوى 2 الهجمات الأكثر تقدمًا أو الأقل شيوعًا، بالإضافة إلى الدفاعات متعددة الطبقات ضد التهديدات واسعة الانتشار. قد تتطلب هذه المتطلبات منطقًا أكثر تعقيدًا أو تركز على شروط مسبقة محددة للهجوم.

 متطلبات المستوى 3

المستوى 3 يشمل ضوابط تكون عادة أصعب في التنفيذ أو ذات تطبيق موقفي. تمثل هذه غالبًا آليات دفاع في العمق أو تدابير تخفيف ضد هجمات متخصصة، موجهة، أو ذات تعقيد عالي.

#### الدور (الخضوع/الرفض)

يتم تصنيف كل متطلب من متطلبات AISVS وفقًا للجمهور الأساسي:

D – متطلبات موجهة للمطورين
V – المتطلبات الموجهة للمحقق/المراجع
D/V – ذات صلة بكل من المطورين والمتحققين

## حوكمة بيانات التدريب وإدارة التحيز في C1

### هدف التحكم

يجب أن يتم الحصول على بيانات التدريب والتعامل معها وصيانتها بطريقة تحافظ على الأصول والأمان والجودة والإنصاف. إن القيام بذلك يفي بالواجبات القانونية ويقلل من مخاطر التحيز أو التسمم أو انتهاكات الخصوصية التي تظهر أثناء التدريب والتي قد تؤثر على دورة حياة الذكاء الاصطناعي بأكملها.

---

### C1.1 مصدر بيانات التدريب

احتفظ بجرد يمكن التحقق منه لجميع مجموعات البيانات، واقبل المصادر الموثوقة فقط، وسجل كل تغيير لضمان إمكانية التدقيق.

 #1.1.1    المستوى: 1    الدور: D/V
 تحقق من تحديث جرد محدث لكل مصدر بيانات تدريب (الأصل، المشرف/المالك، الترخيص، طريقة الجمع، قيود الاستخدام المقصودة، وتاريخ المعالجة).
 #1.1.2    المستوى: 1    الدور: D/V
 تحقق من أن عمليات بيانات التدريب تستبعد الميزات أو السمات أو الحقول غير الضرورية (مثل البيانات الوصفية غير المستخدمة، أو معلومات التعريف الشخصية الحساسة، أو بيانات الاختبار المسربة).
 #1.1.3    المستوى: 2    الدور: D/V
 تحقق من أن جميع تغييرات مجموعة البيانات تخضع إلى سير عمل موافقة مسجل.
 #1.1.4    المستوى: 3    الدور: D/V
 تحقق من أن مجموعات البيانات أو أجزاء منها تحمل علامات مائية أو بصمات رقمية حيثما كان ذلك ممكنًا.

---

### C1.2 أمان وسلامة بيانات التدريب

تقييد الوصول إلى بيانات التدريب، وتشفيرها أثناء التخزين وفي أثناء النقل، والتحقق من سلامتها لمنع التلاعب أو السرقة أو تلوث البيانات.

 #1.2.1    المستوى: 1    الدور: D/V
 تحقق من أن ضوابط الوصول تحمي تخزين بيانات التدريب وأنابيب المعالجة.
 #1.2.2    المستوى: 2    الدور: D/V
 تحقق من تسجيل جميع عمليات الوصول إلى بيانات التدريب، بما في ذلك المستخدم، الوقت، والإجراء.
 #1.2.3    المستوى: 2    الدور: D/V
 تحقق من أن مجموعات بيانات التدريب مشفرة أثناء النقل وفي حالة السكون، باستخدام خوارزميات التشفير والمعايير الصناعية لإدارة المفاتيح.
 #1.2.4    المستوى: 2    الدور: D/V
 تحقق من استخدام التجزئات التشفيرية أو التواقيع الرقمية لضمان سلامة البيانات أثناء تخزين بيانات التدريب ونقلها.
 #1.2.5    المستوى: 2    الدور: D/V
 تحقق من تطبيق تقنيات الكشف الآلي للحماية من التعديلات أو التلف غير المصرح به في بيانات التدريب.
 #1.2.6    المستوى: 2    الدور: D/V
 تحقق من أن بيانات التدريب القديمة يتم حذفها بأمان أو إخفاء هويتها.
 #1.2.7    المستوى: 3    الدور: D/V
 تحقق من أن جميع إصدارات مجموعة بيانات التدريب معرّفة بشكل فريد، مخزنة بشكل غير قابل للتغيير، وقابلة للتدقيق لدعم التراجع والتحليل الجنائي.

---

### جودة تسميات بيانات التدريب، سلامتها، وأمانها

حماية التسميات وطلب مراجعة فنية للبيانات الحرجة.

 #1.3.1    المستوى: 2    الدور: D/V
 تحقق من أن يتم تطبيق التجزئات التشفيرية أو التواقيع الرقمية على عناصر التسمية لضمان سلامتها وأصالتها.
 #1.3.2    المستوى: 2    الدور: D/V
 تحقق من أن واجهات و منصات التصنيف تفرض ضوابط وصول قوية، وتحافظ على سجلات تدقيق مقاومة للتلاعب لجميع أنشطة التصنيف، وتحمي من التعديلات غير المصرح بها.
 #1.3.3    المستوى: 3    الدور: D/V
 تحقق من أن المعلومات الحساسة في التسميات تم تحريرها أو إخفاؤها أو تشفيرها على مستوى حقل البيانات أثناء التخزين وأثناء النقل.

---

### C1.4 جودة بيانات التدريب وضمان الأمان

ادمج التحقق التلقائي، والفحص اليدوي العشوائي، والتصحيح المسجل لضمان موثوقية مجموعة البيانات.

 #1.4.1    المستوى: 1    الدور: D
 تحقق من أن الاختبارات الآلية تكشف عن أخطاء التنسيق والقيم الفارغة في كل مرة يتم فيها الإدخال أو التحول الكبير للبيانات.
 #1.4.2    المستوى: 2    الدور: D/V
 تحقق من أن خطوط أنابيب تدريب وتحسين نماذج اللغة الكبيرة (LLM) تنفذ الكشف عن التسمم والتحقق من سلامة البيانات (مثل الأساليب الإحصائية، واكتشاف القيم الشاذة، وتحليل التضمين) لتحديد الهجمات المحتملة للتسمم (مثل تغيير التصنيفات، وإدخال محفز الباب الخلفي، وأوامر تبديل الأدوار، وهجمات الحالات المؤثرة) أو تلف البيانات غير المقصود في بيانات التدريب.
 #1.4.3    المستوى: 3    الدور: D/V
 تحقق من تنفيذ الضُعُون المناسبة، مثل التدريب العدائي (باستخدام أمثلة عدائية مُولدة)، وتوسيع البيانات بإدخالات مُزعزعة، أو تقنيات التحسين القوية، وضبطها للنماذج ذات الصلة بناءً على تقييم المخاطر.
 #1.4.4    المستوى: 2    الدور: D/V
 تحقق من أن التسميات التي تم إنشاؤها تلقائيًا (مثل تلك الناتجة عن نماذج اللغة الكبيرة أو الإشراف الضعيف) تخضع لعتبات الثقة وفحوصات الاتساق لاكتشاف التسميات الوهمية أو المضللة أو ذات الثقة المنخفضة.
 #1.4.5    المستوى: 3    الدور: D
 تحقق من أن الاختبارات الآلية تكتشف انحرافات الوسوم في كل عملية استيراد أو تحويل بيانات كبيرة.

---

### C1.5 تسلسل البيانات وقابلية تتبعها

تعقب الرحلة الكاملة لكل نقطة بيانات من المصدر إلى إدخال النموذج لضمان القابلية للتدقيق والاستجابة للحوادث.

 #1.5.1    المستوى: 2    الدور: D/V
 تحقق من أن أصل كل نقطة بيانات، بما في ذلك جميع التحولات، والتحسينات، والدمج، مسجل ويمكن إعادة بناءه.
 #1.5.2    المستوى: 2    الدور: D/V
 تحقق من أن سجلات النسب غير قابلة للتغيير، ومخزنة بأمان، ومتاحة للتدقيق.
 #1.5.3    المستوى: 2    الدور: D/V
 تحقق من أن تتبع النسب يشمل البيانات الاصطناعية التي تم إنشاؤها عبر تقنيات الحفاظ على الخصوصية أو التقنيات التوليدية، وأن جميع البيانات الاصطناعية مُعلمة بوضوح ويمكن تمييزها عن البيانات الحقيقية طوال مسار العمل.

---

### المراجع

NIST AI Risk Management Framework
EU AI Act – Article 10: Data & Data Governance
MITRE ATLAS: Adversary Tactics for AI
Survey of ML Bias Mitigation Techniques – MDPI
Data Provenance & Lineage Best Practices – Nightfall AI
Data Labeling Quality Standards – LabelYourData
Training Data Poisoning Guide – Lakera.ai
CISA Advisory: Securing Data for AI Systems
ISO/IEC 23053: AI Management Systems Framework
IBM: What is AI Governance?
Google AI Principles
GDPR & AI Training Data – DataProtectionReport
Supply-Chain Security for AI Data – AppSOC
OpenAI Privacy Center – Data Deletion Controls
Adversarial ML Dataset – Kaggle

## التحقق من صحة إدخال المستخدم في C2

### هدف التحكم

التحقق القوي من مدخلات المستخدم هو خط الدفاع الأول ضد بعض أكثر الهجمات إلحاقًا بالضرر على أنظمة الذكاء الاصطناعي. يمكن لهجمات حقن الطلبات تجاوز تعليمات النظام، وتسريب البيانات الحساسة، أو توجيه النموذج نحو سلوك غير مسموح به. ما لم تكن هناك فلاتر مخصصة وتسلسلات تعليمات منظمة، تظهر الأبحاث أن "الاختراقات متعددة الطلقات" التي تستغل نوافذ السياق الطويلة جدًا ستكون فعالة. أيضًا، يمكن لهجمات التشويش العدائية الدقيقة—مثل تبديل الحروف المتشابهة أو لغة الرموز—تغيير قرارات النموذج بهدوء.

---

### دفاع ضد حقن الموجهات C2.1

حقن التعليمات هو واحد من أعلى المخاطر التي تواجه أنظمة الذكاء الاصطناعي. تعتمد الدفاعات ضد هذه الأسلوب على مزيج من مرشحات الأنماط الثابتة، والمصنفات الديناميكية، وفرض تسلسل التعليمات.

 #2.1.1    المستوى: 1    الدور: D/V
 تأكد من فحص مدخلات المستخدم مقابل مكتبة محدثة باستمرار لأنماط حقن المطالبات المعروفة (كلمات المرور الخاصة بكسر النظام، "تجاهل السابق"، سلاسل التمثيل الدور، الهجمات غير المباشرة عبر HTML/URL).
 #2.1.2    المستوى: 1    الدور: D/V
 تحقق من أن النظام يفرض تسلسلاً هرميًا للتعليمات حيث تتجاوز رسائل النظام أو المطور تعليمات المستخدم، حتى بعد توسيع نافذة السياق.
 #2.1.3    المستوى: 2    الدور: D/V
 التحقق من تنفيذ اختبارات التقييم العدائي (مثل مطالبات "العديد من المحاولات" لفريق الأحمر) قبل إصدار كل نموذج أو قالب مطالبة، مع تحديد حدود لمعدلات النجاح واستخدام حواجز أوتوماتيكية لمنع التراجع.
 #2.1.4    المستوى: 2    الدور: D
 تحقق من أن الطلبات التي تنشأ من محتوى طرف ثالث (صفحات الويب، ملفات PDF، رسائل البريد الإلكتروني) تتم تنقيتها في سياق تحليل معزول قبل دمجها في الطلب الرئيسي.
 #2.1.5    المستوى: 3    الدور: D/V
 تحقق من أن جميع تحديثات قواعد فلترة المطالبات، وإصدارات نماذج المصنفات، وتغييرات قائمة الحظر مُراقبة بالإصدار وقابلة للتدقيق.

---

### C2.2 مقاومة الأمثلة العدائية

نماذج معالجة اللغة الطبيعية (NLP) لا تزال معرضة للتشويش الطفيف على مستوى الحروف أو الكلمات التي غالبًا ما يغفلها البشر ولكن تميل النماذج إلى تصنيفها بشكل خاطئ.

 #2.2.1    المستوى: 1    الدور: D
 تحقق من أن خطوات تطبيع الإدخال الأساسية (Unicode NFC، تعيين الأشكال المتماثلة، تقليم الفراغات) تتم قبل عملية تقسيم النص إلى رموز.
 #2.2.2    المستوى: 2    الدور: D/V
 تحقق من أن اكتشاف الشذوذ الإحصائي يشير إلى المدخلات التي تحتوي على مسافة تحرير مرتفعة بشكل غير عادي عن معايير اللغة، أو وجود تكرار مفرط في الرموز، أو مسافات تضمين غير طبيعية.
 #2.2.3    المستوى: 2    الدور: D
 تأكد من أن خط أنابيب الاستدلال يدعم نماذج محسنة بالتدريب العدائي أو طبقات الدفاع الاختيارية (مثل العشوائية، التقطير الدفاعي) لنقاط النهاية عالية الخطورة.
 #2.2.4    المستوى: 2    الدور: V
 تحقق من وضع المدخلات المشبوهة بعدوها في الحجر الصحي، وتسجيلها مع الحمولة الكاملة (بعد إزالة المعلومات الشخصية الحساسة).
 #2.2.5    المستوى: 3    الدور: D/V
 تأكد من تتبع مقاييس المتانة (معدل نجاح مجموعات الهجوم المعروفة) مع مرور الوقت وأن الانحدارات تؤدي إلى إيقاف الإصدار.

---

### C2.3 التحقق من المخطط والنوع والطول

هجمات الذكاء الاصطناعي التي تتضمن مدخلات مشوهة أو كبيرة الحجم قد تتسبب في أخطاء في التحليل، وتسرب الأوامر عبر الحقول، واستنفاد الموارد. كما أن تطبيق قواعد صارمة للمخططات هو أيضًا شرط أساسي عند إجراء استدعاءات أدوات حتمية.

 #2.3.1    المستوى: 1    الدور: D
 تحقق من أن كل نقطة نهاية لاستدعاء API أو وظيفة تحدد مخطط إدخال صريح (مخطط JSON، Protobuf أو ما يعادله متعدد الوسائط) وأن المدخلات يتم التحقق من صحتها قبل تجميع المطالبات.
 #2.3.2    المستوى: 1    الدور: D/V
 تحقق من أن الإدخالات التي تتجاوز الحد الأقصى لعدد الرموز أو الحد الأقصى للحجم بالبايت يتم رفضها بخطأ آمن ولا يتم اقتطاعها بهدوء.
 #2.3.3    المستوى: 2    الدور: D/V
 تأكد من تطبيق فحوصات النوع (مثل نطاقات الأعداد، قيم التعداد، أنواع MIME للصور/الصوت) على جانب الخادم، وليس فقط في كود العميل.
 #2.3.4    المستوى: 2    الدور: D
 تحقق من أن أدوات التحقق الدلالي (على سبيل المثال، JSON Schema) تعمل في زمن ثابت لمنع هجمات الحرمان من الخدمة الخوارزمية (DoS).
 #2.3.5    المستوى: 3    الدور: V
 تحقق من تسجيل حالات فشل التحقق مع مقتطفات حمولة مخفية الرموز وأكواد خطأ واضحة للمساعدة في تصنيف الأمان.

---

### C2.4 فحص المحتوى والسياسة

يجب أن يكون المطورون قادرين على اكتشاف المطالبات الصياغية الصحيحة التي تطلب محتوى غير مسموح به (مثل التعليمات غير المشروعة، خطاب الكراهية، والنصوص المحمية بحقوق الطبع والنشر) ثم منع انتشارها.

 #2.4.1    المستوى: 1    الدور: D
 تحقق من أن مصنف المحتوى (بدون تدريب مسبق أو مدرب بشكل دقيق) يقوم بتقييم كل إدخال من حيث العنف، وإيذاء النفس، والكراهية، والمحتوى الجنسي، والطلبات غير القانونية، مع إمكانية ضبط العتبات بشكل قابل للتخصيص.
 #2.4.2    المستوى: 1    الدور: D/V
 تحقق من أن المدخلات التي تنتهك السياسات ستتلقى رفضات موحدة أو إكمالات آمنة بحيث لا تنتقل إلى استدعاءات نماذج اللغة الكبيرة اللاحقة.
 #2.4.3    المستوى: 2    الدور: D
 تحقق من إعادة تدريب/تحديث نموذج الفحص أو مجموعة القواعد على الأقل كل ثلاثة أشهر، مع دمج الأنماط الجديدة المكتشفة للتهكير أو تجاوز السياسات.
 #2.4.4    المستوى: 2    الدور: D
 تحقق من أن الفحص يحترم السياسات الخاصة بالمستخدم (العمر، القيود القانونية الإقليمية) من خلال قواعد مستندة إلى السمات يتم حلها عند وقت الطلب.
 #2.4.5    المستوى: 3    الدور: V
 تحقق من أن سجلات الفحص تتضمن درجات ثقة المصنف وتسميات فئة السياسة من أجل الترابط SOC وإعادة تشغيل فريق الاختبار الأحمر في المستقبل.

---

### C2.5 تحديد معدل الإدخال ومنع الإساءة

يجب على المطورين منع سوء الاستخدام، واستنفاد الموارد، والهجمات الآلية ضد أنظمة الذكاء الاصطناعي من خلال تحديد معدلات الإدخال واكتشاف أنماط الاستخدام الشاذة.

 #2.5.1    المستوى: 1    الدور: D/V
 تحقق من فرض حدود معدل الاستخدام لكل مستخدم، لكل عنوان IP، ولكل مفتاح API لجميع نقاط الإدخال.
 #2.5.2    المستوى: 2    الدور: D/V
 تحقق من أن معدلات الحد المفاجئة والمستمرة مضبوطة لمنع هجمات الحرمان من الخدمة (DoS) وهجمات القوة الغاشمة.
 #2.5.3    المستوى: 2    الدور: D/V
 تحقق من أن أنماط الاستخدام الشاذة (مثل طلبات متتالية سريعة، فيضان المدخلات) تؤدي إلى تشغيل الحجب الآلي أو التصعيدات.
 #2.5.4    المستوى: 3    الدور: V
 تحقق من الاحتفاظ بسجلات منع الانتهاكات ومراجعتها للكشف عن أنماط الهجوم الناشئة.

---

### C2.6 التحقق من صحة الإدخال متعدد الوسائط

يجب أن تتضمن أنظمة الذكاء الاصطناعي تحققًا قويًا للمدخلات غير النصية (الصور، الصوت، الملفات) لمنع الحقن أو التملص أو إساءة استخدام الموارد.

 #2.6.1    المستوى: 1    الدور: D
 تأكد من التحقق من جميع المدخلات غير النصية (الصور، الصوت، الملفات) من حيث النوع والحجم والتنسيق قبل المعالجة.
 #2.6.2    المستوى: 2    الدور: D/V
 تأكد من فحص الملفات للكشف عن البرامج الضارة والحمولات المستترة قبل الإدخال.
 #2.6.3    المستوى: 2    الدور: D/V
 تحقق من أن مدخلات الصورة/الصوت تم فحصها للكشف عن الاضطرابات التخريبية أو أنماط الهجوم المعروفة.
 #2.6.4    المستوى: 3    الدور: V
 تحقق من أن فشل التحقق من صحة الإدخال متعدد الوسائط يتم تسجيله ويؤدي إلى تنبيهات للتحقيق.

---

### C2.7 أصل الإدخال والنسبة

يجب أن تدعم أنظمة الذكاء الاصطناعي التدقيق، وتتبع الانتهاكات، والامتثال من خلال مراقبة وتأشير مصادر جميع مدخلات المستخدم.

 #2.7.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع مدخلات المستخدم مرفقة ببيانات وصفية (معرّف المستخدم، الجلسة، المصدر، الطابع الزمني، عنوان IP) عند الاستيراد.
 #2.7.2    المستوى: 2    الدور: D/V
 تحقق من أن بيانات الأصل (provenance metadata) محفوظة وقابلة للمراجعة لجميع المدخلات المعالجة.
 #2.7.3    المستوى: 2    الدور: D/V
 تحقق من أن مصادر الإدخال الشاذة أو غير الموثوقة يتم الإبلاغ عنها وتخضع لمراجعة معززة أو للحظر.

---

### C2.8 الكشف التهديدات التكيفية في الوقت الحقيقي

يجب على المطورين استخدام أنظمة كشف التهديدات المتقدمة للذكاء الاصطناعي التي تتكيف مع أنماط الهجوم الجديدة وتوفر الحماية في الوقت الفعلي من خلال مطابقة الأنماط المجمعة.

 #2.8.1    المستوى: 1    الدور: D/V
 تحقق من أن أنماط اكتشاف التهديدات قد تم تجميعها في محركات تعبيرات نمطية محسنة لأداء عالٍ في التصفية في الوقت الحقيقي مع تأثير زمني ضئيل.
 #2.8.2    المستوى: 1    الدور: D/V
 تحقق من أن أنظمة كشف التهديد تحتفظ بمكتبات أنماط منفصلة لفئات التهديد المختلفة (حقن الأوامر البرمجية، المحتوى الضار، البيانات الحساسة، أوامر النظام).
 #2.8.3    المستوى: 2    الدور: D/V
 تحقق من أن اكتشاف التهديدات التكيفية يدمج نماذج تعلم الآلة التي تقوم بتحديث حساسية التهديد بناءً على تكرار الهجمات ومعدلات النجاح.
 #2.8.4    المستوى: 2    الدور: D/V
 تحقق من أن تغذيات استخبارات التهديدات في الوقت الفعلي تقوم تلقائيًا بتحديث مكتبات الأنماط بتوقيعات الهجوم الجديدة ومؤشرات الاختراق (IOCs).
 #2.8.5    المستوى: 3    الدور: D/V
 تحقق من أن معدلات الإيجابيات الخاطئة في كشف التهديدات تتم مراقبتها بشكل مستمر وأن دقة الأنماط تُضبط تلقائيًا لتقليل التدخل في حالات الاستخدام الشرعية.
 #2.8.6    المستوى: 3    الدور: D/V
 تحقق من أن تحليل التهديد السياقي يأخذ في الاعتبار مصدر الإدخال، وأنماط سلوك المستخدم، وتاريخ الجلسة لتحسين دقة الكشف.
 #2.8.7    المستوى: 3    الدور: D/V
 تحقق من أن مؤشرات أداء اكتشاف التهديدات (معدل الكشف، زمن معالجة التأخير، استخدام الموارد) يتم مراقبتها وتحسينها في الوقت الحقيقي.

---

### C2.9 خط أنابيب التحقق من الأمان متعدد الوسائط

يجب على المطورين توفير التحقق من الأمان للنص والصورة والصوت وأنماط إدخال الذكاء الاصطناعي الأخرى باستخدام أنواع محددة من الكشف عن التهديدات وعزل الموارد.

 #2.9.1    المستوى: 1    الدور: D/V
 تحقق من أن كل نوع من أنواع الإدخال لديه مدققات أمان مخصصة مع أنماط تهديد موثقة (النص: حقن التعليمات، الصور: التضمين الخفي، الصوت: هجمات مخطط الطيف) وعوامل كشف محددة.
 #2.9.2    المستوى: 2    الدور: D/V
 تحقق من أن المدخلات متعددة الوسائط تتم معالجتها في بيئات معزولة ذات حدود موارد محددة (ذاكرة، وحدة معالجة مركزية، وقت المعالجة) خاصة بكل نوع من أنواع الوسائط وموثقة في سياسات الأمان.
 #2.9.3    المستوى: 2    الدور: D/V
 تحقق من أن الكشف عن الهجمات متعددة الأنماط يحدد الهجمات المنسقة التي تمتد عبر أنواع إدخال متعددة (مثل الحمولات الستيجانوجرافية في الصور المدمجة مع حقن التعليمات في النص) باستخدام قواعد الترابط وتوليد التنبيهات.
 #2.9.4    المستوى: 3    الدور: D/V
 تحقق من أن فشل التحقق متعدد الوسائط يُحدث تسجيلًا تفصيليًا يشمل جميع وسائط الإدخال، ونتائج التحقق، ونقاط التهديد، وتحليل الارتباط باستخدام تنسيقات تسجيل منظمة لتكامل SIEM.
 #2.9.5    المستوى: 3    الدور: D/V
 تحقق من تحديث مصنفي المحتوى الخاصين بالنمط وفقًا للجداول الموثقة (بحد أدنى ربع سنوي) باستخدام أنماط التهديد الجديدة، والأمثلة العدائية، ومعايير الأداء التي تُحافظ على مستوى أعلى من الحدود الأساسية.

---

### المراجع

LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security
Generative AI's Biggest Security Flaw Is Not Easy to Fix
Many-shot jailbreaking \ Anthropic
$PDF$ OpenAI GPT-4.5 System Card
Notebook for the CheckThat Lab at CLEF 2024
Mitigate jailbreaks and prompt injections – Anthropic
Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis
OWASP Top 10 for LLM Applications 2025 – WorldTech IT
OWASP Machine Learning Security Top Ten
Few words about AI Security – Jussi Metso
How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry
Easily enforcing valid JSON schema following – API
AI Safety + Cybersecurity R\&D Tracker – Fairly AI
Anthropic makes 'jailbreak' advance to stop AI models producing harmful results
Pattern matching filter rules - IBM
Real-time Threat Detection

## إدارة دورة حياة نموذج C3 والتحكم في التغيير

### هدف التحكم

يجب على أنظمة الذكاء الاصطناعي تنفيذ عمليات التحكم في التغيير التي تمنع التعديلات غير المصرح بها أو غير الآمنة على النموذج من الوصول إلى الإنتاج. يضمن هذا التحكم سلامة النموذج طوال دورة حياته بأكملها--من التطوير مرورًا بالنشر حتى الإيقاف--مما يتيح استجابة سريعة للحوادث ويحافظ على المساءلة عن جميع التغييرات.

الهدف الأساسي للأمن: فقط النماذج المصرح بها والمُتحقق منها تصل إلى الإنتاج من خلال استخدام عمليات محكومة تحافظ على السلامة، وقابلية التتبع، وقابلية الاسترداد.

---

### C3.1 تفويض النموذج وسلامته

تصل النماذج المصرح بها فقط والتي تم التحقق من سلامتها إلى بيئات الإنتاج.

 #3.1.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع مخرجات النموذج (الأوزان، التكوينات، محولات الرموز) موقعة تشفيرياً من قبل الكيانات المصرح بها قبل النشر.
 #3.1.2    المستوى: 1    الدور: D/V
 تحقق من أن سلامة النموذج يتم التحقق منها عند وقت النشر وأن فشل التحقق من التوقيع يمنع تحميل النموذج.
 #3.1.3    المستوى: 2    الدور: D/V
 تحقق من أن سجلات منشأ النموذج تتضمن هوية الكيان المفوض، وقيم التحقق من صحة بيانات التدريب، ونتائج اختبار التحقق مع حالة النجاح/الفشل، وطابع زمني للإنشاء.
 #3.1.4    المستوى: 2    الدور: D/V
 تحقق من أن جميع تحف النموذج تستخدم الترقيم الدلالي للإصدار (MAJOR.MINOR.PATCH) مع وجود معايير موثقة تحدد متى يتم زيادة كل مكون من مكونات الإصدار.
 #3.1.5    المستوى: 2    الدور: V
 تحقق من أن تتبع التبعيات يحافظ على جرد في الوقت الفعلي يمكّن من التعرف السريع على جميع الأنظمة المستهلكة.

---

### C3.2 التحقق من صحة النموذج والاختبار

يجب أن تجتاز النماذج عمليات التحقق المحددة للأمان والسلامة قبل النشر.

 #3.2.1    المستوى: 1    الدور: D/V
 تحقق من أن النماذج تخضع لاختبار أمني آلي يتضمن التحقق من صحة المدخلات، تنقية المخرجات، وتقييمات السلامة باستخدام حدود النجاح/الفشل المتفق عليها مسبقاً داخل المؤسسة قبل النشر.
 #3.2.2    المستوى: 1    الدور: D/V
 تحقق من أن حالات فشل التحقق تمنع تلقائيًا نشر النموذج بعد الموافقة الصريحة على التجاوز من قبل الأفراد المخولين المعينين مسبقًا مع وجود مبررات أعمال موثقة.
 #3.2.3    المستوى: 2    الدور: V
 تحقق من توقيع نتائج الاختبار تشفيرياً وربطها بشكل غير قابل للتغيير بهاش إصدار النموذج المحدد الذي يتم التحقق منه.
 #3.2.4    المستوى: 2    الدور: D/V
 تحقق من أن عمليات النشر الطارئة تتطلب تقييم مخاطر أمني موثق وموافقة من سلطة أمنية محددة مسبقًا ضمن الأطر الزمنية المتفق عليها مسبقًا.

---

### C3.3 النشر والتحكم في التراجع

يجب التحكم في نشر النماذج ومراقبته وأن يكون قابلاً للعكس.

 #3.3.1    المستوى: 1    الدور: D
 تحقق من أن عمليات النشر في بيئة الإنتاج تنفذ آليات طرح تدريجي (نشر الكناري، النشر الأزرق-الأخضر) مع مشغلات التراجع التلقائي بناءً على معدلات الأخطاء المتفق عليها مسبقًا، أو عتبات التأخير، أو معايير تنبيه الأمان.
 #3.3.2    المستوى: 1    الدور: D/V
 تحقق من أن قدرات التراجع تستعيد حالة النموذج الكاملة (الأوزان، التكوينات، التبعيات) بشكل ذري داخل النوافذ الزمنية التنظيمية المحددة مسبقًا.
 #3.3.3    المستوى: 2    الدور: D/V
 تحقق من أن عمليات النشر تتحقق من صحة التوقيعات التشفيرية وتحسب مجموعات التحقق من السلامة قبل تفعيل النموذج، مع فشل النشر في حالة وجود أي عدم تطابق.
 #3.3.4    المستوى: 2    الدور: D/V
 تحقق من أن قدرات إيقاف تشغيل النموذج في الحالات الطارئة يمكنها تعطيل نقاط نهاية النموذج ضمن أوقات استجابة محددة مسبقًا عبر قواطع الدوائر التلقائية أو مفاتيح الإيقاف اليدوية.
 #3.3.5    المستوى: 2    الدور: V
 تحقق من أن عناصر التراجع (إصدارات النماذج السابقة، التكوينات، الاعتمادات) محفوظة وفقًا لسياسات المنظمة باستخدام تخزين غير قابل للتغيير للاستجابة للحوادث.

---

### C3.4 تغيير المساءلة والتدقيق

يجب أن تكون جميع تغييرات دورة حياة النموذج قابلة للتتبع والتدقيق.

 #3.4.1    المستوى: 1    الدور: V
 تحقق من أن جميع التغييرات على النموذج (النشر، التكوين، الإيقاف) تولد سجلات تدقيق غير قابلة للتغيير تشمل طابع زمني، وهوية الممثل المصادق عليها، ونوع التغيير، والحالات قبل/بعد التغيير.
 #3.4.2    المستوى: 2    الدور: D/V
 تحقق من أن الوصول إلى سجل التدقيق يتطلب التفويض المناسب وأن جميع محاولات الوصول يتم تسجيلها بهوية المستخدم والطابع الزمني.
 #3.4.3    المستوى: 2    الدور: D/V
 تحقق من أن قوالب التعليمات الرسومية ورسائل النظام يتم التحكم في إصداراتها في مستودعات git مع مراجعة كود إلزامية والموافقة من المراجعين المعيّنين قبل النشر.
 #3.4.4    المستوى: 2    الدور: V
 تحقق من أن سجلات التدقيق تتضمن تفاصيل كافية (تجزئات النموذج، لقطات التهيئة، إصدارات التبعيات) لتمكين إعادة بناء كاملة لحالة النموذج في أي طابع زمني ضمن فترة الاحتفاظ.

---

### ممارسات التطوير الآمن C3.5

يجب أن تتبع عمليات تطوير النموذج وتدريبه ممارسات آمنة لمنع التعرض للاختراق.

 #3.5.1    المستوى: 1    الدور: D
 تحقق من أن بيئات تطوير النموذج والاختبار والإنتاج منفصلة فعليًا أو منطقيًا. لا تشترك في البنية التحتية، ولديها ضوابط وصول مميزة، ومخازن بيانات معزولة.
 #3.5.2    المستوى: 1    الدور: D
 تحقق من أن تدريب النموذج والتخصيص يتمان في بيئات معزولة مع وصول شبكة محكم التحكم.
 #3.5.3    المستوى: 1    الدور: D/V
 تحقق من أن مصادر بيانات التدريب تم التحقق من صحتها من خلال فحوصات السلامة وتم توثيقها عبر مصادر موثوقة مع وجود سجل موثق لسلسلة الحيازة قبل استخدامها في تطوير النموذج.
 #3.5.4    المستوى: 2    الدور: D
 تحقق من أن عناصر تطوير النموذج (المعلمات الفائقة، نصوص التدريب، ملفات التكوين) مخزنة في نظام التحكم في الإصدارات وتتطلب موافقة مراجعة الأقران قبل استخدامها في التدريب.

---

### C3.6 التقاعد والتصفية النموذجية

يجب إيقاف النماذج بشكل آمن عندما لا تكون هناك حاجة إليها بعد الآن أو عند تحديد مشكلات أمنية.

 #3.6.1    المستوى: 1    الدور: D
 تحقق من أن عمليات تقاعد النموذج تفحص تلقائيًا مخططات الاعتماد، وتحدد جميع الأنظمة المستهلكة، وتوفر فترات إشعار مسبقة متفق عليها قبل إيقاف التشغيل.
 #3.6.2    المستوى: 1    الدور: D/V
 تحقق من أن قطع النموذج المتقاعد يتم مسحها بأمان باستخدام المسح التشفيري أو الكتابة المتكررة متعددة المرات وفقًا لسياسات الاحتفاظ بالبيانات الموثقة مع شهادات تدمير مُحققة.
 #3.6.3    المستوى: 2    الدور: V
 تحقق من تسجيل أحداث تقاعد النماذج مع الطابع الزمني وهوية الفاعل، وإلغاء تصاريح النماذج لمنع إعادة الاستخدام.
 #3.6.4    المستوى: 2    الدور: D/V
 تحقق من أن تقاعد النموذج في حالات الطوارئ يمكن أن يعطل الوصول إلى النموذج ضمن الأطر الزمنية المحددة مسبقًا للاستجابة للطوارئ من خلال مفاتيح إيقاف تلقائية إذا تم اكتشاف ثغرات أمنية حرجة.

---

### المراجع

MLOps Principles
Securing AI/ML Ops – Cisco.com
Audit logs security: cryptographically signed tamper-proof logs
Machine Learning Model Versioning: Top Tools & Best Practices
AI Hygiene Starts with Models and Data Loaders – SEI Blog
How to handle versioning and rollback of a deployed ML model?
Reinforcement fine-tuning – OpenAI API
Auditing Machine Learning models: Governance, Data Security and …
Adversarial Training to Improve Model Robustness
What is AI adversarial robustness? – IBM Research
Exploring Data Provenance: Ensuring Data Integrity and Authenticity
MITRE ATLAS
AWS Prescriptive Guidance – Best practices for retiring applications …

## أمن البنية التحتية C4، التهيئة والنشر

### هدف التحكم

يجب تقوية بنية الذكاء الاصطناعي التحتية ضد تصعيد الامتيازات، والتلاعب بسلسلة التوريد، والتحركات الجانبية من خلال التهيئة الآمنة، والعزل أثناء التشغيل، وخطوط النشر الموثوقة، والمراقبة الشاملة. لا تصل إلى الإنتاج سوى مكونات البنية التحتية والتكوينات المصرح بها والمحققة عبر عمليات مُراقبة تحافظ على الأمن، والسلامة، وقابلية التدقيق.

الهدف الأساسي للأمن: ألا تصل إلى الإنتاج سوى مكونات البنية التحتية الموقعة تشفيرياً والتي تم فحصها للكشف عن الثغرات عبر خطوط التحقق الآلية التي تفرض سياسات الأمان وتحافظ على سجلات تدقيق غير قابلة للتغيير.

---

### C4.1 عزل بيئة وقت التشغيل

منع الهروب من الحاويات وتصعيد الامتيازات من خلال بدائيات العزل على مستوى النواة وضوابط الوصول الإلزامية.

 #4.1.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع حاويات الذكاء الاصطناعي تزيل جميع صلاحيات لينكس ما عدا CAP_SETUID و CAP_SETGID، والصلاحيات المطلوبة صراحة والموثقة في معايير الأمان.
 #4.1.2    المستوى: 1    الدور: D/V
 تحقق من أن ملفات تعريف seccomp تمنع جميع نداءات النظام باستثناء تلك الموجودة في قوائم السماح المعتمدة مسبقًا، مع إنهاء الحاوية وفي حال حدوث انتهاكات وتوليد تنبيهات أمنية.
 #4.1.3    المستوى: 2    الدور: D/V
 تحقق من أن أحمال العمل الخاصة بالذكاء الاصطناعي تعمل بأنظمة ملفات جذر قابلة للقراءة فقط، وtmpfs للبيانات المؤقتة، وأحجام مسماة للبيانات الدائمة مع فرض خيارات mount noexec.
 #4.1.4    المستوى: 2    الدور: D/V
 تحقق من أن المراقبة الزمنية القائمة على eBPF (مثل Falco أو Tetragon أو ما يعادلها) تكتشف محاولات تصعيد الامتيازات وتقوم تلقائيًا بإنهاء العمليات المخالفة ضمن متطلبات زمن استجابة المؤسسة.
 #4.1.5    المستوى: 3    الدور: D/V
 تحقق من أن عمليات الذكاء الاصطناعي عالية المخاطر تعمل في بيئات معزولة ماديًا (Intel TXT، AMD SVM، أو عقد مخصصة بنظام bare-metal) مع التحقق من الشهادة.

---

### C4.2 خطوط أنابيب البناء والنشر الآمنة

ضمان سلامة التشفير وأمان سلسلة التوريد من خلال إنشاءات قابلة لإعادة الإنتاج والتحقق من صحة الملفات الموقعة.

 #4.2.1    المستوى: 1    الدور: D/V
 تحقق من أن البنية التحتية كرمز يتم فحصها بأدوات (tfsec، Checkov، أو Terrascan) على كل التزام، مع حظر الدمج في حالة وجود نتائج شديدة أو حرجة.
 #4.2.2    المستوى: 1    الدور: D/V
 تحقق من أن بناء الحاويات قابل لإعادة الإنتاج بنفس قيمة تجزئة SHA256 عبر عمليات البناء المختلفة وأن تولد شهادات إثبات منشأ مستوى SLSA 3 موقعة باستخدام Sigstore.
 #4.2.3    المستوى: 2    الدور: D/V
 تحقق من أن صور الحاويات تضم CycloneDX أو SPDX SBOMs وموقعة باستخدام Cosign قبل دفعها إلى السجل، مع رفض الصور غير الموقعة عند النشر.
 #4.2.4    المستوى: 2    الدور: D/V
 تحقق من أن خطوط أنابيب CI/CD تستخدم رموز OIDC من HashiCorp Vault أو أدوار AWS IAM أو الهوية المدارة من Azure بفترات صلاحية لا تتجاوز حدود سياسة الأمان التنظيمية.
 #4.2.5    المستوى: 2    الدور: D/V
 تحقق من أن توقيعات Cosign ودرجة إثبات SLSA يتم التحقق منها أثناء عملية النشر قبل تنفيذ الحاوية وأن أخطاء التحقق تؤدي إلى فشل النشر.
 #4.2.6    المستوى: 2    الدور: D/V
 تحقق من أن بيئات البناء تعمل في حاويات عابرة أو آلات افتراضية بدون تخزين دائم وعزل شبكي عن شبكات VPC الإنتاجية.

---

### C4.3 أمان الشبكة والتحكم في الوصول

تنفيذ الشبكات ذات الثقة الصفرية باستخدام سياسات الرفض الافتراضية والاتصالات المشفرة.

 #4.3.1    المستوى: 1    الدور: D/V
 تحقق من أن Kubernetes NetworkPolicies أو أي ما يعادلها تقوم بتطبيق سياسة الرفض الافتراضي للوصول الوارد والصادر مع قواعد سماح صريحة للمنافذ المطلوبة (443، 8080، إلخ).
 #4.3.2    المستوى: 1    الدور: D/V
 تحقق من أن SSH (المنفذ 22)، وRDP (المنفذ 3389)، ونقاط نهاية بيانات تعريف السحابة (169.254.169.254) محجوبة أو تتطلب مصادقة تعتمد على الشهادات.
 #4.3.3    المستوى: 2    الدور: D/V
 تحقق من أن حركة المرور الصادرة يتم تصفيتها من خلال وكلاء HTTP/HTTPS (Squid، Istio، أو بوابات NAT السحابية) باستخدام قوائم السماح بالنطاقات، ويتم تسجيل الطلبات المحظورة.
 #4.3.4    المستوى: 2    الدور: D/V
 تحقق من أن التواصل بين الخدمات يستخدم بروتوكول TLS المتبادل مع تدوير الشهادات وفقًا لسياسة المنظمة وتطبيق التحقق من صحة الشهادات (بدون استخدام أعلام تخطي التحقق).
 #4.3.5    المستوى: 2    الدور: D/V
 تحقق من أن بنية الذكاء الاصطناعي تعمل في شبكات افتراضية مخصصة (VPCs/VNets) بدون وصول مباشر إلى الإنترنت، وتتواصل فقط من خلال بوابات NAT أو مضيفي الحصن (bastion hosts).

---

### C4.4 إدارة الأسرار والمفاتيح التشفيرية

حماية بيانات الاعتماد من خلال التخزين المدعوم بالأجهزة والتدوير التلقائي مع الوصول بنظام الثقة الصفرية.

 #4.4.1    المستوى: 1    الدور: D/V
 تحقق من أن الأسرار مخزنة في HashiCorp Vault أو AWS Secrets Manager أو Azure Key Vault أو Google Secret Manager مع استخدام التشفير أثناء التخزين باستخدام AES-256.
 #4.4.2    المستوى: 1    الدور: D/V
 تحقق من أن مفاتيح التشفير يتم إنشاؤها في وحدات الأمان الصلبة FIPS 140-2 المستوى 2 (AWS CloudHSM، Azure Dedicated HSM) مع تدوير المفاتيح وفقًا لسياسة التشفير التنظيمية.
 #4.4.3    المستوى: 2    الدور: D/V
 تحقق من أن تدوير الأسرار مُؤتمت مع نشر بدون توقف وبدء التدوير الفوري عند تغيير الأفراد أو حدوث حوادث أمنية.
 #4.4.4    المستوى: 2    الدور: D/V
 تحقق من مسح صور الحاويات باستخدام أدوات (GitLeaks، TruffleHog، أو detect-secrets) مع حظر بناءات تحتوي على مفاتيح API أو كلمات مرور أو شهادات.
 #4.4.5    المستوى: 2    الدور: D/V
 تحقق من أن وصول أسرار الإنتاج يتطلب المصادقة متعددة العوامل باستخدام رموز الأجهزة (YubiKey، FIDO2) ويتم تسجيلها بواسطة سجلات تدقيق غير قابلة للتغيير تحتوي على هويات المستخدمين والطوابع الزمنية.
 #4.4.6    المستوى: 2    الدور: D/V
 تحقق من أن الأسرار تم حقنها عبر أسرار Kubernetes أو وحدات التخزين المركبة أو الحاويات التمهيدية، وتأكد من أن الأسرار لا تُضمّن أبدًا في متغيرات البيئة أو الصور.

---

### C4.5 تحييد وتحليل أعباء عمل الذكاء الاصطناعي

عزل نماذج الذكاء الاصطناعي غير الموثوقة في بيئات آمنة مع تحليل سلوكي شامل.

 #4.5.1    المستوى: 1    الدور: D/V
 تحقق من أن نماذج الذكاء الاصطناعي الخارجية تعمل في gVisor، أو microVMs (مثل Firecracker، CrossVM)، أو حاويات Docker مع الخيارين --security-opt=no-new-privileges و --read-only.
 #4.5.2    المستوى: 1    الدور: D/V
 تحقق من أن بيئات الصندوق الرملية ليس لديها اتصال بالشبكة (--network=none) أو تقتصر على الوصول إلى المضيف المحلي فقط مع حظر جميع الطلبات الخارجية بواسطة قواعد iptables.
 #4.5.3    المستوى: 2    الدور: D/V
 تحقق من أن التحقق من صحة نموذج الذكاء الاصطناعي يشمل اختبار الفريق الأحمر الآلي مع تغطية اختبار محددة تنظيميًا وتحليل السلوك لاكتشاف الأبواب الخلفية.
 #4.5.4    المستوى: 2    الدور: D/V
 تأكد من أنه قبل ترقية نموذج الذكاء الاصطناعي إلى بيئة الإنتاج، يتم توقيع نتائج بيئة الاختبار المشروطة (sandbox) بشكل تشفيري من قبل موظفي الأمن المخولين وتخزينها في سجلات تدقيق غير قابلة للتغيير.
 #4.5.5    المستوى: 2    الدور: D/V
 تأكد من أن بيئات الصندوق الرمل يتم تدميرها وإعادة إنشائها من الصور الذهبية بين التقييمات مع تنظيف كامل لنظام الملفات والذاكرة.

---

### C4.6 مراقبة أمان البنية التحتية

قم بمسح البنية التحتية ومراقبتها باستمرار مع التصحيح التلقائي والتنبيهات الفورية.

 #4.6.1    المستوى: 1    الدور: D/V
 تحقق من أن صور الحاويات تتم فحصها وفقًا لجداول المؤسسة مع حظر الثغرات الأمنية الحرجة (CRITICAL) لنشرها بناءً على عتبات المخاطر الخاصة بالمؤسسة.
 #4.6.2    المستوى: 1    الدور: D/V
 تحقق من أن البنية التحتية تفي بمعايير CIS أو ضوابط NIST 800-53 مع حدود امتثال معرّفة تنظيميًا وتصحيح تلقائي للفحوصات التي تفشل.
 #4.6.3    المستوى: 2    الدور: D/V
 تحقق من أن الثغرات الأمنية ذات الخطورة العالية قد تم تصحيحها وفقًا لجداول إدارة المخاطر التنظيمية مع وجود إجراءات طوارئ للثغرات التي يتم استغلالها بنشاط.
 #4.6.4    المستوى: 2    الدور: V
 تحقق من أن تنبيهات الأمان تندمج مع منصات SIEM (سبلنك، إليستيك، أو سنتينل) باستخدام تنسيقات CEF أو STIX/TAXII مع الإثراء التلقائي.
 #4.6.5    المستوى: 3    الدور: V
 تأكد من تصدير مقاييس البنية التحتية إلى أنظمة المراقبة (Prometheus، DataDog) مع لوحات معلومات SLA والتقارير التنفيذية.
 #4.6.6    المستوى: 2    الدور: D/V
 التحقق من اكتشاف الانحراف في التكوين باستخدام الأدوات (Chef InSpec، AWS Config) وفقًا لمتطلبات المراقبة التنظيمية مع التراجع التلقائي عن التغييرات غير المصرح بها.

---

### إدارة موارد بنية الذكاء الاصطناعي التحتية C4.7

منع هجمات نفاد الموارد وضمان تخصيص الموارد بشكل عادل من خلال الحصص والمراقبة.

 #4.7.1    المستوى: 1    الدور: D/V
 تحقق من أن استخدام وحدة معالجة الرسومات / وحدة معالجة التنسور يتم مراقبته مع تفعيل التنبيهات عند الوصول إلى الحدود التي تحددها المنظمة، وأنه يتم تفعيل التوسع التلقائي أو موازنة الحمولة بناءً على سياسات إدارة السعة.
 #4.7.2    المستوى: 1    الدور: D/V
 تحقق من جمع مقاييس عبء عمل الذكاء الاصطناعي (زمن استجابة الاستدلال، الإنتاجية، معدلات الأخطاء) وفقًا لمتطلبات المراقبة التنظيمية وربطها باستخدام البنية التحتية.
 #4.7.3    المستوى: 2    الدور: D/V
 تحقق من أن Kubernetes ResourceQuotas أو ما يعادلها تقوم بتقييد الأحمال الفردية وفقًا لسياسات توزيع الموارد التنظيمية مع فرض حدود صارمة.
 #4.7.4    المستوى: 2    الدور: V
 تحقق من أن مراقبة التكاليف تتعقب الإنفاق لكل عبء عمل/مستأجر مع تنبيهات بناءً على حدود ميزانية المؤسسة وضوابط آلية لتجاوز الميزانية.
 #4.7.5    المستوى: 3    الدور: V
 تحقق من أن تخطيط السعة يستخدم البيانات التاريخية مع فترات التنبؤ المعرفة تنظيمياً وتوفير الموارد الآلي استنادًا إلى أنماط الطلب.
 #4.7.6    المستوى: 2    الدور: D/V
 تحقق من أن استنفاد الموارد يؤدي إلى تفعيل قواطع الدائرة وفقًا لمتطلبات الاستجابة التنظيمية، بما في ذلك تحديد المعدل بناءً على سياسات السعة وعزل عبء العمل.

---

### C4.8 فصل البيئة وضوابط الترحيل

فرض حدود بيئية صارمة باستخدام بوابات الترقية الآلية والتحقق الأمني.

 #4.8.1    المستوى: 1    الدور: D/V
 تحقق من أن بيئات التطوير/الاختبار/الإنتاج تعمل في VPCs/VNets منفصلة بدون أدوار IAM مشتركة أو مجموعات أمان أو اتصال شبكي مشترك.
 #4.8.2    المستوى: 1    الدور: D/V
 تحقق من أن الترقية البيئية تتطلب موافقة من الأفراد المخولين المحددين تنظيميًا باستخدام التوقيعات التشفيرية ومسارات تدقيق غير قابلة للتغيير.
 #4.8.3    المستوى: 2    الدور: D/V
 تحقق من أن بيئات الإنتاج تمنع الوصول عبر SSH، وتعطل نقاط النهاية الخاصة بالتصحيح، وتتطلب طلبات التغيير مع وجود متطلبات إشعار مسبق من المنظمة باستثناء الحالات الطارئة.
 #4.8.4    المستوى: 2    الدور: D/V
 تحقق من أن تغييرات البنية التحتية كرمز تتطلب مراجعة من الأقران مع اختبار آلي وفحص أمني قبل الدمج في الفرع الرئيسي.
 #4.8.5    المستوى: 2    الدور: D/V
 تحقق من أن بيانات غير الإنتاجية قد تم إخفاء هويتها وفقًا لمتطلبات الخصوصية التنظيمية، وتوليد البيانات الاصطناعية، أو إخفاء البيانات الكامل مع التحقق من إزالة المعلومات الشخصية التعريفية (PII).
 #4.8.6    المستوى: 2    الدور: D/V
 تحقق من أن بوابات الترقية تشمل اختبارات أمان آلية (تحليل الأمان الثابت SAST، تحليل الأمان الديناميكي DAST، فحص الحاويات) مع ضرورة عدم وجود نتائج حرجة (CRITICAL) للموافقة.

---

### نسخة احتياطية واسترداد بنية C4.9 التحتية

ضمان مرونة البنية التحتية من خلال النسخ الاحتياطي التلقائي، وإجراءات الاسترداد المختبرة، وقدرات الاسترداد من الكوارث.

 #4.9.1    المستوى: 1    الدور: D/V
 تحقق من أن تكوينات البنية التحتية يتم نسخها احتياطيًا وفقًا لجداول النسخ الاحتياطي التنظيمية إلى مناطق جغرافية منفصلة باستخدام تنفيذ استراتيجية النسخ الاحتياطي 3-2-1.
 #4.9.2    المستوى: 2    الدور: D/V
 تأكد من أن أنظمة النسخ الاحتياطي تعمل في شبكات معزولة باستخدام بيانات اعتماد منفصلة وتخزين معزول للحماية من هجمات الفدية.
 #4.9.3    المستوى: 2    الدور: V
 تحقق من أن إجراءات الاستعادة تم اختبارها والتحقق من صحتها من خلال الاختبار الآلي وفقًا لجداول المنظمة مع تحقيق أهداف RTO و RPO التي تلبي متطلبات المنظمة.
 #4.9.4    المستوى: 3    الدور: V
 تحقق من أن خطة التعافي من الكوارث تتضمن كتب تشغيل خاصة بالذكاء الاصطناعي مع استعادة أوزان النماذج، وإعادة بناء تجمع وحدات معالجة الرسوميات (GPU)، ورسم خرائط تبعيات الخدمات.

---

### C4.10 الامتثال والحوكمة الخاصة بالبنية التحتية

الحفاظ على الامتثال التنظيمي من خلال التقييم المستمر، والتوثيق، والضوابط الآلية.

 #4.10.1    المستوى: 2    الدور: D/V
 التحقق من تقييم الامتثال للبنية التحتية وفقًا للجداول التنظيمية مقابل ضوابط SOC 2 أو ISO 27001 أو FedRAMP مع جمع الأدلة تلقائيًا.
 #4.10.2    المستوى: 2    الدور: V
 تحقق من أن وثائق البنية التحتية تتضمن مخططات الشبكة، خرائط تدفق البيانات، ونماذج التهديدات محدثة وفقًا لمتطلبات إدارة تعديل المنظمة.
 #4.10.3    المستوى: 3    الدور: D/V
 تحقق من أن التغييرات في البنية التحتية تخضع لتقييم تأثير الامتثال الآلي مع سير عمل الموافقات التنظيمية للتعديلات عالية المخاطر.

---

### C4.11 أمان أجهزة الذكاء الاصطناعي

تأمين مكونات الأجهزة الخاصة بالذكاء الاصطناعي بما في ذلك وحدات معالجة الرسوميات (GPUs)، وحدات معالجة التنسور (TPUs)، ومسرعات الذكاء الاصطناعي المتخصصة.

 #4.11.1    المستوى: 2    الدور: D/V
 تحقق من أن البرنامج الثابت لمُسرّع الذكاء الاصطناعي (نظام الإدخال/الإخراج الأساسي لوحدة معالجة الرسومات، والبرنامج الثابت لوحدة معالجة تي بي يو) يتم التحقق منه باستخدام توقيعات تشفيرية ويُحدّث وفقاً لجداول إدارة تصحيح الأخطاء في المؤسسة.
 #4.11.2    المستوى: 2    الدور: D/V
 تحقق من أنه قبل تنفيذ عبء العمل، يتم التحقق من سلامة مسرع الذكاء الاصطناعي من خلال إثبات الأجهزة باستخدام TPM 2.0، أو Intel TXT، أو AMD SVM.
 #4.11.3    المستوى: 2    الدور: D/V
 تحقق من أن ذاكرة GPU معزولة بين أحمال العمل باستخدام SR-IOV أو MIG (وحدة معالجة الرسومات متعددة الحالات) أو تقسيم الأجهزة المعادل مع تطهير الذاكرة بين الوظائف.
 #4.11.4    المستوى: 3    الدور: V
 تحقق من أن سلسلة توريد أجهزة الذكاء الاصطناعي تتضمن التحقق من الأصل باستخدام شهادات المصنع والتحقق من صحة التغليف المقاوم للعبث.
 #4.11.5    المستوى: 3    الدور: D/V
 تحقق من أن وحدات أمان الأجهزة (HSMs) تحمي أوزان نماذج الذكاء الاصطناعي والمفاتيح التشفيرية بشهادة FIPS 140-2 المستوى 3 أو معيار الأمان العام EAL4+.

---

### C4.12 بنية الذكاء الاصطناعي الطرفية والموزعة

نشر الذكاء الاصطناعي الموزع بأمان بما في ذلك الحوسبة الطرفية، التعلم الفيدرالي، والهياكل متعددة المواقع.

 #4.12.1    المستوى: 2    الدور: D/V
 تحقق من أن أجهزة الذكاء الاصطناعي الطرفية تقوم بالمصادقة على البنية التحتية المركزية باستخدام بروتوكول TLS المتبادل مع شهادات الأجهزة التي يتم تدويرها وفقًا لسياسة إدارة الشهادات التنظيمية.
 #4.12.2    المستوى: 2    الدور: D/V
 تحقق من أن أجهزة الحافة تنفذ التمهيد الآمن باستخدام التوقيعات المعتمدة وحماية التراجع لمنع هجمات تخفيض مستوى البرامج الثابتة.
 #4.12.3    المستوى: 3    الدور: D/V
 تحقق من أن تنسيق الذكاء الاصطناعي الموزع يستخدم خوارزميات التوافق المتسامحة مع الأخطاء البيزنطية مع التحقق من المشاركين واكتشاف العقد الخبيثة.
 #4.12.4    المستوى: 3    الدور: D/V
 تحقق من أن الاتصال بين الحافة والسحابة يشمل التحكم في عرض النطاق الترددي، وضغط البيانات، وقدرات التشغيل بدون اتصال مع تخزين محلي آمن.

---

### C4.13 أمان البنية التحتية المتعددة السحب والهجينة

تأمين أحمال عمل الذكاء الاصطناعي عبر مزودي السحابة المتعددين وعمليات النشر الهجينة بين السحابة والمحلية.

 #4.13.1    المستوى: 2    الدور: D/V
 تحقق من أن نشرات الذكاء الاصطناعي متعددة السحابات تستخدم الاتحاد الهوية المستقل عن السحابة (OIDC، SAML) مع إدارة سياسات مركزية عبر المزودين.
 #4.13.2    المستوى: 2    الدور: D/V
 تحقق من أن نقل البيانات عبر السحابات المختلفة يستخدم التشفير من النهاية إلى النهاية مع مفاتيح يديرها العميل وأنه يتم تطبيق ضوابط إقامة البيانات وفقًا للولاية القضائية.
 #4.13.3    المستوى: 2    الدور: D/V
 تحقق من أن أحمال عمل الذكاء الاصطناعي في السحابة الهجينة تطبق سياسات أمان متسقة عبر البيئات المحلية والسحابيّة مع مراقبة وتنبيه موحدين.
 #4.13.4    المستوى: 3    الدور: V
 تحقق من أن منع الارتباط بمزود السحابة يشمل البنية التحتية كرمز المحمولة، وواجهات برمجة التطبيقات الموحدة، وإمكانات تصدير البيانات مع أدوات تحويل الصيغ.
 #4.13.5    المستوى: 3    الدور: V
 تأكد من أن تحسين تكلفة السحابات المتعددة يشمل ضوابط الأمان التي تمنع انتشار الموارد غير المرغوب فيه وكذلك تحمل تكاليف نقل البيانات عبر السحابات غير المصرح بها.

---

### C4.14 أمان أتمتة البنية التحتية وGitOps

تأمين خطوط أتمتة البنية التحتية وسير عمل GitOps لإدارة بنية الذكاء الاصطناعي.

 #4.14.1    المستوى: 2    الدور: D/V
 تحقق من أن مستودعات GitOps تتطلب توقيعات على الالتزامات باستخدام مفاتيح GPG وقواعد حماية الفروع التي تمنع الدفع المباشر إلى الفروع الرئيسية.
 #4.14.2    المستوى: 2    الدور: D/V
 تحقق من أن أتمتة البنية التحتية تشمل اكتشاف الانحراف مع قدرات التصحيح التلقائي والتراجع التي يتم تفعيلها وفقًا لمتطلبات استجابة المنظمة للتغييرات غير المصرح بها.
 #4.14.3    المستوى: 2    الدور: D/V
 تحقق من أن توفير البنية التحتية الآلي يشمل التحقق من صحة سياسة الأمان مع حظر النشر للإعدادات غير المتوافقة.
 #4.14.4    المستوى: 2    الدور: D/V
 تحقق من أن أسرار أتمتة البنية التحتية تتم إدارتها من خلال مشغلي الأسرار الخارجية (مشغل الأسرار الخارجية، بنك-فولتس) مع التدوير التلقائي.
 #4.14.5    المستوى: 3    الدور: V
 تحقق من أن البنية التحتية القادرة على الاستشفاء الذاتي تتضمن ترابط أحداث الأمان مع استجابة الحوادث الآلية وسير عمل إشعار الجهات المعنية.

---

### C4.15 أمان البنية التحتية المقاومة للحوسبة الكمية

تحضير بنية تحتية للذكاء الاصطناعي لمواجهة تهديدات الحوسبة الكمومية من خلال التشفير ما بعد الكمومي والبروتوكولات الآمنة الكمومية.

 #4.15.1    المستوى: 3    الدور: D/V
 تحقق من أن بنية تحتية الذكاء الاصطناعي تنفذ خوارزميات التشفير بعد الكمومية المعتمدة من NIST (CRYSTALS-Kyber، CRYSTALS-Dilithium، SPHINCS+) لتبادل المفاتيح والتوقيعات الرقمية.
 #4.15.2    المستوى: 3    الدور: D/V
 تحقق من تنفيذ أنظمة توزيع المفاتيح الكمومية (QKD) من أجل اتصالات الذكاء الاصطناعي عالية الأمان باستخدام بروتوكولات إدارة المفاتيح الآمنة الكمومية.
 #4.15.3    المستوى: 3    الدور: D/V
 تحقق من أن أُطُر التكيف التشفيري تمكّن من الترحيل السريع إلى خوارزميات ما بعد الكم الجديدة مع التدوير الآلي للشهادات والمفاتيح.
 #4.15.4    المستوى: 3    الدور: V
 تحقق من أن نمذجة التهديدات الكمومية تقوم بتقييم ضعف بنية الذكاء الاصطناعي التحتية أمام الهجمات الكمومية مع وجود جداول زمنية موثقة للهجرة وتقييمات المخاطر.
 #4.15.5    المستوى: 3    الدور: D/V
 تحقق من أن أنظمة التشفير الهجينة الكلاسيكية-الكمية توفر دفاعًا متعدد الطبقات أثناء فترة الانتقال الكمومي مع مراقبة الأداء.

---

### C4.16 الحوسبة السرية والحاويات الآمنة

حماية أعباء العمل الخاصة بالذكاء الاصطناعي وأوزان النماذج باستخدام بيئات التنفيذ الموثوقة المعتمدة على الأجهزة وتقنيات الحوسبة السرية.

 #4.16.1    المستوى: 3    الدور: D/V
 تحقق من أن نماذج الذكاء الاصطناعي الحساسة تعمل داخل مناطق محمية Intel SGX، أو AMD SEV-SNP، أو ARM TrustZone مع ذاكرة مشفرة والتحقق من التصديق.
 #4.16.2    المستوى: 3    الدور: D/V
 تحقق من أن الحاويات السرية (Kata Containers، gVisor مع الحوسبة السرية) تعزل أحمال عمل الذكاء الاصطناعي باستخدام تشفير الذاكرة المدعوم بواسطة الأجهزة.
 #4.16.3    المستوى: 3    الدور: D/V
 تحقق من أن التوثيق عن بُعد يصادق على سلامة الحاضنة قبل تحميل نماذج الذكاء الاصطناعي باستخدام إثبات تشفير لصدق بيئة التنفيذ.
 #4.16.4    المستوى: 3    الدور: D/V
 تحقق من أن خدمات الاستنتاج الخاصة بالذكاء الاصطناعي السرية تمنع استخراج النموذج من خلال الحوسبة المشفرة باستخدام أوزان النموذج المختومة والتنفيذ المحمي.
 #4.16.5    المستوى: 3    الدور: D/V
 تحقق من أن تنسيق بيئة التنفيذ الموثوقة يدير دورة حياة الحيز الآمن باستخدام التصديق عن بُعد وقنوات الاتصال المشفرة.
 #4.16.6    المستوى: 3    الدور: D/V
 تحقق من أن الحوسبة متعددة الأطراف الآمنة (SMPC) تمكّن التدريب التعاوني للذكاء الاصطناعي دون الكشف عن مجموعات البيانات الفردية أو معلمات النموذج.

---

### C4.17 بنية تحتية المعرفة الصفرية

تنفيذ أنظمة إثبات المعرفة الصفرية للتحقق من صحة الذكاء الاصطناعي والمصادقة مع الحفاظ على الخصوصية دون كشف المعلومات الحساسة.

 #4.17.1    المستوى: 3    الدور: D/V
 تحقق من أن الإثباتات ذات المعرفة الصفرية (ZK-SNARKs، ZK-STARKs) تتحقق من سلامة نموذج الذكاء الاصطناعي وأصل التدريب دون كشف أوزان النموذج أو بيانات التدريب.
 #4.17.2    المستوى: 3    الدور: D/V
 تحقق من أن أنظمة المصادقة المعتمدة على إثبات المعرفة الصفرية (ZK) تتيح التحقق من المستخدم مع الحفاظ على الخصوصية لخدمات الذكاء الاصطناعي دون الكشف عن المعلومات المتعلقة بالهوية.
 #4.17.3    المستوى: 3    الدور: D/V
 تحقق من أن بروتوكولات تقاطع المجموعات الخاصة (PSI) تتيح مطابقة بيانات آمنة للذكاء الاصطناعي الفيدرالي دون كشف مجموعات البيانات الفردية.
 #4.17.4    المستوى: 3    الدور: D/V
 تحقق من أن أنظمة التعلم الآلي ذات المعرفة الصفرية (ZKML) تُمكّن الاستدلالات الذكية القابلة للتحقق مع دليل تشفير على صحة الحساب.
 #4.17.5    المستوى: 3    الدور: D/V
 تحقق من أن ZK-rollups توفر معالجة معاملات الذكاء الاصطناعي القابلة للتوسع والمحافظة على الخصوصية من خلال التحقق الجماعي وتقليل الحمل الحسابي.

---

### C4.18 منع هجمات القنوات الجانبية

حماية بنية الذكاء الاصطناعي التحتية من هجمات القناة الجانبية القائمة على التوقيت والطاقة والمجالات الكهرومغناطيسية والذاكرة المخبأة التي قد تكشف عن معلومات حساسة.

 #4.18.1    المستوى: 3    الدور: D/V
 تحقق من أن توقيت الاستدلال في الذكاء الاصطناعي يتم تطبيعه باستخدام خوارزميات ذات وقت ثابت والتعبئة لمنع هجمات استخراج النموذج القائمة على التوقيت.
 #4.18.2    المستوى: 3    الدور: D/V
 تحقق من أن حماية تحليل الطاقة تشمل حقن الضوضاء، وترشيح خط الطاقة، وأنماط التنفيذ العشوائية لأجهزة الذكاء الاصطناعي.
 #4.18.3    المستوى: 3    الدور: D/V
 تحقق من أن التخفيف من قنوات الجانب القائمة على الذاكرة الوسيطة يستخدم تقطيع الذاكرة الوسيطة، التوزيع العشوائي، وتعليمات التفريغ لمنع تسرب المعلومات.
 #4.18.4    المستوى: 3    الدور: D/V
 تأكد من أن حماية الانبعاثات الكهرومغناطيسية تشمل التغطية الواقية، وترشيح الإشارة، والمعالجة العشوائية لمنع الهجمات بأسلوب TEMPEST.
 #4.18.5    المستوى: 3    الدور: D/V
 تحقق من أن دفاعات القنوات الجانبية الدقيقة الهندسة تشمل ضوابط التنفيذ التخميني وإخفاء نمط وصول الذاكرة.

---

### C4.19 الأمن في الأجهزة العصبية الاصطناعية والأجهزة المتخصصة للذكاء الاصطناعي

تأمين هندسات الأجهزة الناشئة للذكاء الاصطناعي بما في ذلك رقائق العصبية، وFPGAs، والدوائر المتكاملة المخصصة (ASICs)، وأنظمة الحوسبة البصرية.

 #4.19.1    المستوى: 3    الدور: D/V
 تحقق من أن أمان الشريحة النيورومورفية يشمل تشفير نمط النبضات، حماية أوزان الارتباط التشابكي، والتحقق من صحة قاعدة التعلم المعتمدة على العتاد.
 #4.19.2    المستوى: 3    الدور: D/V
 تحقق من أن مسرّعات الذكاء الاصطناعي القائمة على FPGA تنفذ تشفير تدفق البت، وآليات مقاومة التلاعب، وتحميل التهيئة الآمن مع التحديثات المصدقة.
 #4.19.3    المستوى: 3    الدور: D/V
 تحقق من أن أمان الـ ASIC المخصص يتضمن معالجات أمان مدمجة على الرقاقة، وجذر ثقة مادي، وتخزين مفاتيح آمن مع الكشف عن التلاعب.
 #4.19.4    المستوى: 3    الدور: D/V
 تحقق من أن أنظمة الحوسبة الضوئية تنفذ تشفيرًا ضوئيًا آمنًا من الهجمات الكمومية، وتبديلًا ضوئيًا آمنًا، ومعالجة إشارة ضوئية محمية.
 #4.19.5    المستوى: 3    الدور: D/V
 تحقق من أن شرائح الذكاء الاصطناعي الهجينة التناظرية-الرقمية تشمل حسابًا تناظريًا آمنًا، وتخزين أوزان محميًا، وتحويلًا تماثليًا إلى رقمي موثقًا.

---

### C4.20 بنية تحتية للحوسبة مع الحفاظ على الخصوصية

تنفيذ ضوابط البنية التحتية للحوسبة التي تحافظ على الخصوصية لحماية البيانات الحساسة أثناء معالجة وتحليل الذكاء الاصطناعي.

 #4.20.1    المستوى: 3    الدور: D/V
 تحقق من أن بنية التشفير المتجانس تتيح الحساب المشفر على أحمال العمل الحساسة للذكاء الاصطناعي مع التحقق من سلامة التشفير ورصد الأداء.
 #4.20.2    المستوى: 3    الدور: D/V
 تحقق من أن أنظمة استرجاع المعلومات الخاصة تمكّن من إجراء استعلامات قواعد البيانات دون كشف أنماط الاستعلام مع توفير حماية تشفيرية لأنماط الوصول.
 #4.20.3    المستوى: 3    الدور: D/V
 تحقق من أن بروتوكولات الحوسبة متعددة الأطراف الآمنة تمكن الاستدلال الذكي المحفوظ للخصوصية دون الكشف عن المدخلات الفردية أو العمليات الحسابية الوسيطة.
 #4.20.4    المستوى: 3    الدور: D/V
 تحقق من أن إدارة المفاتيح المحمية بالخصوصية تشمل توليد المفاتيح الموزعة، التشفير بالعتبة، وتدوير المفاتيح الآمن مع الحماية المدعومة بالأجهزة.
 #4.20.5    المستوى: 3    الدور: D/V
 تحقق من أن أداء الحوسبة التي تحافظ على الخصوصية مُحسّن من خلال التجميع، والتخزين المؤقت، وتسريع الأجهزة مع الحفاظ على ضمانات الأمان التشفيري.

---

### C4.15 إطار عمل الوكيل أمان تكامل السحابة والنشر المختلط

ضوابط الأمان لأطر العمل الوكيل المتكاملة مع السحابة ذات البنى الهجينة المحلية والسحابية.

 #4.15.1    المستوى: 1    الدور: D/V
 تحقق من أن تكامل التخزين السحابي يستخدم التشفير من الطرف إلى الطرف مع إدارة المفاتيح التي يتحكم بها الوكيل.
 #4.15.2    المستوى: 2    الدور: D/V
 تحقق من أن حدود أمان النشر الهجينة محددة بوضوح مع قنوات اتصال مشفرة.
 #4.15.3    المستوى: 2    الدور: D/V
 تحقق من أن وصول موارد السحابة يتضمن التحقق بنمط الثقة الصفرية مع المصادقة المستمرة.
 #4.15.4    المستوى: 3    الدور: D/V
 تحقق من أن متطلبات إقامة البيانات يتم تنفيذها من خلال إثبات تخزين المواقع باستخدام التشفير.
 #4.15.5    المستوى: 3    الدور: D/V
 تحقق من أن تقييمات أمان مزود الخدمة السحابية تشمل نمذجة التهديدات الخاصة بالوكيل وتقييم المخاطر.

---

### المراجع

NIST Cybersecurity Framework 2.0
CIS Controls v8
OWASP Container Security Verification Standard
Kubernetes Security Best Practices
SLSA Supply Chain Security Framework
NIST SP 800-190: Application Container Security Guide
Cloud Security Alliance: Cloud Controls Matrix
ENISA: Secure Infrastructure Design
NIST SP 800-53: Security Controls for Federal Information Systems
ISO 27001:2022 Information Security Management
NIST AI Risk Management Framework
CIS Kubernetes Benchmark
FIPS 140-2 Security Requirements
NIST SP 800-207: Zero Trust Architecture
IEEE 2857: Privacy Engineering for AI Systems
NIST SP 800-161: Cybersecurity Supply Chain Risk Management
NIST Post-Quantum Cryptography Standards
Intel SGX Developer Guide
AMD SEV-SNP White Paper
ARM TrustZone Technology
ZK-SNARKs: A Gentle Introduction
NIST SP 800-57: Cryptographic Key Management
Side-Channel Attack Countermeasures
Neuromorphic Computing Security Challenges
FPGA Security: Fundamentals, Evaluation, and Countermeasures
Microsoft SEAL: Homomorphic Encryption Library
HElib: Homomorphic Encryption Library
PALISADE Lattice Cryptography Library
Differential Privacy: A Survey of Results
Secure Aggregation for Federated Learning
Private Information Retrieval: Concepts and Constructions

## التحكم في الوصول و الهوية لمكونات الذكاء الاصطناعي والمستخدمين

### هدف التحكم

يتطلب التحكم الفعال في الوصول إلى أنظمة الذكاء الاصطناعي إدارة هوية قوية، وتفويضًا واعيًا للسياق، وتنفيذًا أثناء التشغيل وفقًا لمبادئ الثقة الصفرية. تضمن هذه الضوابط أن يتفاعل البشر والخدمات والوكلاء المستقلون فقط مع النماذج والبيانات والموارد الحسابية داخل النطاقات المصرح بها صراحة، مع وجود قدرات تحقق ومراجعة مستمرة.

---

### C5.1 إدارة الهوية والمصادقة

إنشاء هويات مدعومة بالتشفير لجميع الكيانات مع المصادقة متعددة العوامل للعمليات ذات الامتيازات.

 #5.1.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع المستخدمين البشر principals والخدماتية يقومون بالمصادقة من خلال موفر هوية المؤسسة المركزي (IdP) باستخدام بروتوكولات OIDC/SAML مع خرائط فريدة من الهوية إلى الرمز المميز (دون استخدام حسابات أو بيانات اعتماد مشتركة).
 #5.1.2    المستوى: 1    الدور: D/V
 تحقق من أن العمليات عالية الخطورة (نشر النموذج، تصدير الأوزان، الوصول إلى بيانات التدريب، تغييرات تكوين الإنتاج) تتطلب المصادقة متعددة العوامل أو المصادقة المتدرجة مع إعادة التحقق من الجلسة.
 #5.1.3    المستوى: 2    الدور: D
 تحقق من أن المديرين الجدد يخضعون لإثبات الهوية بما يتماشى مع معيار NIST 800-63-3 IAL-2 أو المعايير المعادلة قبل منحهم الوصول إلى نظام الإنتاج.
 #5.1.4    المستوى: 2    الدور: V
 تحقق من إجراء مراجعات الوصول بشكل ربع سنوي مع الكشف الآلي عن الحسابات الخاملة، وتطبيق تدوير بيانات الاعتماد، وسير العمل الخاص بإلغاء الت provision.
 #5.1.5    المستوى: 3    الدور: D/V
 تحقق من أن وكلاء الذكاء الاصطناعي الموحدين يقومون بالمصادقة عبر تأكيدات JWT موقعة والتي لها عمر أقصى يبلغ 24 ساعة وتتضمن إثباتًا تشفيرياً للأصل.

---

### C5.2 تفويض الموارد وأدنى امتياز

قم بتنفيذ ضوابط وصول دقيقة لجميع موارد الذكاء الاصطناعي مع نماذج أذونات صريحة ومسارات تدقيق.

 #5.2.1    المستوى: 1    الدور: D/V
 تحقق من أن كل مورد ذكاء اصطناعي (المجموعات البيانية، النماذج، نقاط النهاية، مجموعات المتجهات، مؤشرات التضمين، وحدات الحوسبة) يطبق ضوابط وصول قائمة على الأدوار مع قوائم سماح صريحة وسياسات الرفض الافتراضية.
 #5.2.2    المستوى: 1    الدور: D/V
 تحقق من تطبيق مبادئ الحد الأدنى من الامتيازات بشكل افتراضي على حسابات الخدمة بدءًا من أذونات القراءة فقط، ويجب وجود مبرر تجاري موثق للوصول للكتابة.
 #5.2.3    المستوى: 1    الدور: V
 تحقق من أن جميع تعديلات التحكم في الوصول مرتبطة بطلبات تغيير معتمدة ومسجلة بشكل غير قابل للتغيير مع الطوابع الزمنية، وهويات الجهات الفاعلة، ومعرفات الموارد، والفروق في الأذونات.
 #5.2.4    المستوى: 2    الدور: D
 تحقق من أن تسميات تصنيف البيانات (المعلومات الشخصية، المعلومات الصحية المحمية، الخاضعة للرقابة التصديرية، الملكية الخاصة) تنتقل تلقائياً إلى الموارد المستمدة (التضمينات، ذاكرات التخزين المؤقت للأوامر، مخرجات النماذج) مع تطبيق السياسة بشكل متسق.
 #5.2.5    المستوى: 2    الدور: D/V
 تحقق من أن محاولات الوصول غير المصرح به وأحداث تصعيد الامتيازات تؤدي إلى تنبيهات في الوقت الحقيقي مع البيانات الوصفية السياقية إلى أنظمة SIEM خلال 5 دقائق.

---

### C5.3 تقييم السياسات الديناميكي

نشر محركات التحكم في الوصول بناءً على السمات (ABAC) لاتخاذ قرارات التفويض المستندة إلى السياق مع قدرات التدقيق.

 #5.3.1    المستوى: 1    الدور: D/V
 تحقق من أن قرارات التفويض يتم تفويضها إلى محرك سياسة مخصص (OPA، Cedar، أو ما يعادلها) يمكن الوصول إليه عبر واجهات برمجة تطبيقات مصدقة مع حماية تكاملية تشفيرية.
 #5.3.2    المستوى: 1    الدور: D/V
 تحقق من أن السياسات تقوم بتقييم السمات الديناميكية في وقت التشغيل بما في ذلك مستوى تصنيف المستخدم، تصنيف حساسية المورد، سياق الطلب، عزل المستأجر، والقيود الزمنية.
 #5.3.3    المستوى: 2    الدور: D
 تحقق من أن تعريفات السياسات تخضع للتحكم في الإصدارات، ومراجعة الأقران، والتحقق منها من خلال الاختبارات الآلية في خطوط CI/CD قبل نشرها في بيئة الإنتاج.
 #5.3.4    المستوى: 2    الدور: V
 تحقق من أن نتائج تقييم السياسات تتضمن مبررات قرار منظمة ويتم نقلها إلى أنظمة SIEM لإجراء تحليلات الارتباط والتقارير المتعلقة بالامتثال.
 #5.3.5    المستوى: 3    الدور: D/V
 تحقق من ألا تتجاوز قيم وقت بقاء ذاكرة تخزين السياسات المؤقتة (TTL) 5 دقائق للموارد عالية الحساسية وساعة واحدة للموارد القياسية مع وجود قدرات لإبطال ذاكرة التخزين المؤقت.

---

### C5.4 تنفيذ أمان وقت الاستعلام

تنفيذ ضوابط أمان طبقة قاعدة البيانات مع التصفية الإلزامية وسياسات أمان مستوى الصف.

 #5.4.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع استعلامات قاعدة البيانات المتجهية واستعلامات SQL تتضمن عوامل تصفية أمان إلزامية (معرف المستأجر، تسميات الحساسية، نطاق المستخدم) يتم فرضها على مستوى محرك قاعدة البيانات، وليس في شفرة التطبيق.
 #5.4.2    المستوى: 1    الدور: D/V
 تحقق من تمكين سياسات أمان مستوى الصف (RLS) وإخفاء الحقول على مستوى الحقول مع وراثة السياسات لجميع قواعد بيانات المتجهات، وفهارس البحث، ومجموعات بيانات التدريب.
 #5.4.3    المستوى: 2    الدور: D
 تحقق من أن تقييمات التفويض الفاشلة ستمنع "هجمات الوكيل المحتار" من خلال إلغاء الاستعلامات على الفور وإرجاع رموز أخطاء تفويض صريحة بدلاً من إرجاع مجموعات نتائج فارغة.
 #5.4.4    المستوى: 2    الدور: V
 التحقق من أن زمن تأخير تقييم السياسات يُراقب بشكل مستمر مع وجود تنبيهات آلية لحالات انتهاء المهلة التي قد تُمكّن من تجاوز التفويض.
 #5.4.5    المستوى: 3    الدور: D/V
 تحقق من أن آليات إعادة محاولة الاستعلام تقوم بإعادة تقييم سياسات التفويض لمراعاة التغييرات الديناميكية في الأذونات داخل جلسات المستخدم النشطة.

---

### تصفية مخرجات C5.5 ومنع فقدان البيانات

نشر ضوابط المعالجة اللاحقة لمنع كشف البيانات غير المصرح به في المحتوى المولد بواسطة الذكاء الاصطناعي.

 #5.5.1    المستوى: 1    الدور: D/V
 تحقق من أن آليات التصفية بعد الاستدلال تفحص وتحجب المعلومات الشخصية غير المصرح بها، والمعلومات المصنفة، والبيانات الملكية قبل تسليم المحتوى إلى الطالبين.
 #5.5.2    المستوى: 1    الدور: D/V
 قم بالتحقق من أن الاقتباسات، والمراجع، ونسب المصادر في مخرجات النموذج قد تم التحقق من صحتها مقابل صلاحيات المستدعي وقم بإزالتها إذا تم اكتشاف وصول غير مصرح به.
 #5.5.3    المستوى: 2    الدور: D
 التحقق من تطبيق قيود تنسيق الإخراج (ملفات PDF المعالجة، والصور التي تم إزالة بياناتها الوصفية، وأنواع الملفات المعتمدة) بناءً على مستويات أذونات المستخدم وتصنيفات البيانات.
 #5.5.4    المستوى: 2    الدور: V
 تحقق من أن خوارزميات التعتيم حتمية، ومتحكم بها بالإصدار، وتحافظ على سجلات التدقيق لدعم التحقيقات في الامتثال والتحليل الجنائي.
 #5.5.5    المستوى: 3    الدور: V
 تحقق من أن أحداث الحجب ذات المخاطر العالية تولد سجلات تكيفية تتضمن تجزئات تشفيرية للمحتوى الأصلي لاسترجاع جنائي دون تعريض البيانات.

---

### C5.6 العزل متعدد المستأجرين

ضمان العزل التشفيري والمنطقي بين المستأجرين في بنية الذكاء الاصطناعي المشتركة.

 #5.6.1    المستوى: 1    الدور: D/V
 تحقق من أن مساحات الذاكرة، ومتاجر التضمين، ومدخلات التخزين المؤقت، والملفات المؤقتة مفصولة حسب مساحة الاسم لكل مستأجر مع تنفيذ حذف آمن عند حذف المستأجر أو إنهاء الجلسة.
 #5.6.2    المستوى: 1    الدور: D/V
 تحقق من أن كل طلب API يتضمن معرف مستأجر موثق يتم التحقق منه تشفيرياً مقابل سياق الجلسة وصلاحيات المستخدم.
 #5.6.3    المستوى: 2    الدور: D
 تحقق من أن سياسات الشبكة تنفذ قواعد الرفض التلقائي للتواصل عبر المستأجرين ضمن شبكات الخدمات ومنصات تنظيم الحاويات.
 #5.6.4    المستوى: 3    الدور: D
 تحقق من أن مفاتيح التشفير فريدة لكل مستأجر مع دعم مفتاح يديره العميل (CMK) وعزل تشفير بين مخازن بيانات المستأجرين.

---

### C5.7 تفويض الوكيل الذاتي

التحكم في أذونات وكلاء الذكاء الاصطناعي والأنظمة المستقلة من خلال رموز القدرات المحددة والتفويض المستمر.

 #5.7.1    المستوى: 1    الدور: D/V
 تحقق من أن الوكلاء الذاتيين يتلقون رموز صلاحية محددة تفصل الإجراءات المسموح بها، والموارد الممكن الوصول إليها، وحدود الزمن، والقيود التشغيلية بوضوح.
 #5.7.2    المستوى: 1    الدور: D/V
 تحقق من أن القدرات عالية المخاطر (الوصول إلى نظام الملفات، تنفيذ الأكواد، استدعاءات واجهات برمجة التطبيقات الخارجية، المعاملات المالية) معطلة بشكل افتراضي وتتطلب تفويضات صريحة للتفعيل مع تقديم مبررات تجارية.
 #5.7.3    المستوى: 2    الدور: D
 تحقق من أن رموز الصلاحية مرتبطة بجلسات المستخدم، وتتضمن حماية سلامة تشفيرية، وتأكد من عدم إمكانية تخزينها أو إعادة استخدامها في سيناريوهات غير متصلة بالإنترنت.
 #5.7.4    المستوى: 2    الدور: V
 تحقق من أن الإجراءات التي يبدأها الوكيل تخضع للموافقة الثانوية من خلال محرك سياسة التحكم بالوصول المُعتمد على السمات (ABAC) مع تقييم كامل للسياق وتسجيل التدقيق.
 #5.7.5    المستوى: 3    الدور: V
 تحقق من أن حالات خطأ الوكيل ومعالجة الاستثناءات تتضمن معلومات نطاق القدرات لدعم تحليل الحوادث والتحقيق الجنائي.

---

### المراجع

#### المعايير والأُطُر

NIST SP 800-63-3: Digital Identity Guidelines
Zero Trust Architecture – NIST SP 800-207
OWASP Application Security Verification Standard (AISVS)
​
#### أدلة التنفيذ

Identity and Access Management in the AI Era: 2025 Guide – IDSA
Attribute-Based Access Control with OPA – Permify
How We Designed Cedar to Be Intuitive, Fast, and Safe – AWS
​
#### الأمن الخاص بالذكاء الاصطناعي

Row Level Security in Vector DBs for RAG – Bluetuple.ai
Tenant Isolation in Multi-Tenant Systems – WorkOS
Handling AI Agent Permissions – Stytch
OWASP Top 10 for Large Language Model Applications

## C6 أمان سلسلة التوريد للنماذج والأُطر والبيانات

### هدف التحكم

تستغل هجمات سلسلة توريد الذكاء الاصطناعي نماذج الغير، أو الأُطُر، أو مجموعات البيانات لزرع أبواب خلفية، أو تحيز، أو شفرة قابلة للاستغلال. توفر هذه الضوابط تتبع كامل للمصدر وإدارة الثغرات والمراقبة لحماية دورة حياة النموذج بأكملها.

---

### C6.1 فحص النموذج المُدرب مسبقًا والأصل

قم بتقييم وأصالة أصول النموذج التابعة لجهات خارجية، والتراخيص الخاصة بها، والسلوكيات المخفية قبل أي تحسين دقيق أو نشر.

 #6.1.1    المستوى: 1    الدور: D/V
 تأكد من أن كل نموذج جهة خارجية يتضمن سجل أصل موقع يحدد مستودع المصدر ورمز الالتزام (commit hash).
 #6.1.2    المستوى: 1    الدور: D/V
 تحقق من فحص النماذج للكشف عن الطبقات الخبيثة أو مشغلات حصان طروادة باستخدام أدوات آلية قبل الاستيراد.
 #6.1.3    المستوى: 2    الدور: D
 تحقق من أن التخصيص الدقيق للتعلّم النقل يتجاوز التقييم العدائي لاكتشاف السلوكيات المخفية.
 #6.1.4    المستوى: 2    الدور: V
 تأكد من أن تراخيص النماذج وعلامات التحكم بالتصدير وبيانات مصدر البيانات مسجلة في إدخال ML-BOM.
 #6.1.5    المستوى: 3    الدور: D/V
 تحقق من بقاء النماذج عالية المخاطر (الأوزان المحملة علنًا، المنشئون غير المعتمدين) في الحجر الصحي حتى يتم مراجعتها واعتمادها من قبل الإنسان.

---

### C6.2 مسح الإطارات والمكتبات

مسح أطر عمل التعلم الآلي والمكتبات باستمرار للعثور على نقاط الضعف الأمنية (CVEs) والرموز الخبيثة للحفاظ على أمان بيئة التشغيل.

 #6.2.1    المستوى: 1    الدور: D/V
 تحقق من أن خطوط أنابيب التكامل المستمر تقوم بتشغيل ماسحات التبعيات على أطر العمل الخاصة بالذكاء الاصطناعي والمكتبات الحرجة.
 #6.2.2    المستوى: 1    الدور: D/V
 تحقق من أن الثغرات الحرجة (CVSS ≥ 7.0) تمنع الترقية إلى صور الإنتاج.
 #6.2.3    المستوى: 2    الدور: D
 تحقق من أن تحليل الشيفرة الساكنة يعمل على مكتبات التعلم الآلي المشعبة أو المزودة.
 #6.2.4    المستوى: 2    الدور: V
 تحقق من أن مقترحات ترقية الإطار تتضمن تقييم تأثير أمني يشير إلى مصادر CVE العامة.
 #6.2.5    المستوى: 3    الدور: V
 تحقق من أن حساسات وقت التشغيل تُنبه عند تحميل مكتبات ديناميكية غير متوقعة تنحرف عن SBOM الموقع.

---

### C6.3 تثبيت التبعيات والتحقق منها

قم بتثبيت كل اعتماد على هاشات ثابتة لا تتغير وأعد بناء البرامج لضمان نفس النتائج تمامًا وخالية من التلاعب.

 #6.3.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع مديري الحزم يفرضون تثبيت الإصدارات عبر ملفات القفل.
 #6.3.2    المستوى: 1    الدور: D/V
 تحقق من استخدام الملخصات غير القابلة للتغيير بدلاً من العلامات القابلة للتغيير في مراجع الحاويات.
 #6.3.3    المستوى: 2    الدور: D
 تحقق من أن فحوصات البناء القابلة لإعادة الإنتاج تقارن التجزئات عبر عمليات التكامل المستمر لضمان مخرجات متطابقة.
 #6.3.4    المستوى: 2    الدور: V
 تحقق من أن شهادات بناء البرمجيات مخزنة لمدة 18 شهرًا لضمان إمكانية تتبع التدقيق.
 #6.3.5    المستوى: 3    الدور: D
 تحقق من أن التبعيات المنتهية الصلاحية تحفز إنشاء طلبات سحب تلقائية لتحديث أو تفريع الإصدارات المثبتة.

---

### C6.4 تطبيق مصدر موثوق

السماح بتنزيل العناصر فقط من المصادر المعتمدة والمنظمة التي تم التحقق منها تشفيرياً وحظر كل شيء آخر.

 #6.4.1    المستوى: 1    الدور: D/V
 تحقق من أن أوزان النماذج، ومجموعات البيانات، والحاويات يتم تحميلها فقط من المجالات المعتمدة أو السجلات الداخلية.
 #6.4.2    المستوى: 1    الدور: D/V
 تحقق من أن توقيعات Sigstore/Cosign تقوم بالتحقق من هوية الناشر قبل أن يتم تخزين المواد على الجهاز محليًا.
 #6.4.3    المستوى: 2    الدور: D
 تحقق من أن وكلاء الخروج يمنعون تنزيل القطع غير المصادق عليها لفرض سياسة المصدر الموثوق.
 #6.4.4    المستوى: 2    الدور: V
 تحقق من مراجعة قوائم السماح للمستودعات ربعياً مع تقديم دليل يبرر كل إدخال من وجهة نظر الأعمال.
 #6.4.5    المستوى: 3    الدور: V
 تحقق من أن انتهاكات السياسات تؤدي إلى عزل القطع الفنية والتراجع عن تشغيلات الأنابيب المعتمدة.

---

### C6.5 تقييم مخاطر مجموعة بيانات الطرف الثالث

قم بتقييم مجموعات البيانات الخارجية للتحقق من التسمم والتحيز والامتثال القانوني، ومراقبتها طوال دورة حياتها.

 #6.5.1    المستوى: 1    الدور: D/V
 تحقق من أن مجموعات البيانات الخارجية تخضع لتقييم مخاطر التسميم (مثل بصمة البيانات، كشف القيم الشاذة).
 #6.5.2    المستوى: 1    الدور: D
 تحقق من حساب مقاييس الانحياز (التكافؤ الديموغرافي، الفرصة المتساوية) قبل الموافقة على مجموعة البيانات.
 #6.5.3    المستوى: 2    الدور: V
 تحقق من أن مصدر البيانات وشروط الترخيص لمجموعات البيانات مسجلة في مدخلات ML‑BOM.
 #6.5.4    المستوى: 2    الدور: V
 تحقق من أن المراقبة الدورية تكشف الانحراف أو التلف في مجموعات البيانات المستضافة.
 #6.5.5    المستوى: 3    الدور: D
 تأكد من إزالة المحتوى الممنوع (حقوق النشر، المعلومات الشخصية المعروفة) من خلال التنظيف التلقائي قبل التدريب.

---

### C6.6 مراقبة هجمات سلسلة التوريد

اكتشف تهديدات سلسلة التوريد مبكرًا من خلال تغذيات CVE، وتحليلات سجلات التدقيق، ومحاكاة فرق الهجوم الحمراء.

 #6.6.1    المستوى: 1    الدور: V
 تحقق من تدفق سجلات تدقيق CI/CD إلى SIEM للكشف عن سحب الحزم غير الاعتيادي أو خطوات البناء التي تم العبث بها.
 #6.6.2    المستوى: 2    الدور: D
 تأكد من أن كتيبات استجابة الحوادث تتضمن إجراءات التراجع للنماذج أو المكتبات التي تم اختراقها.
 #6.6.3    المستوى: 3    الدور: V
 تحقق من أن إضافة بيانات التهديد المعلوماتي تُوسّع العلامات الخاصة بمؤشرات تعلم الآلة (مثل مؤشرات تحتوي على تسميم النموذج) في فرز التنبيهات.

---

### C6.7 قائمة المواد الخاصة بالتعلم الآلي (ML-BOM) لأدلة النماذج

توليد وتوقيع قوائم المواد البرمجية الخاصة بتعلم الآلة (ML-BOMs) بشكل مفصل حتى يتمكن المستخدمون النهائيون من التحقق من سلامة المكونات أثناء وقت النشر.

 #6.7.1    المستوى: 1    الدور: D/V
 تحقق من أن كل نموذج يصدر ML‑BOM يسرد مجموعات البيانات، والأوزان، والبارامترات الفائقة، والتراخيص.
 #6.7.2    المستوى: 1    الدور: D/V
 تحقق من أن توليد ML‑BOM وتوقيع Cosign مؤتمتان في التكامل المستمر (CI) ومطلوبتان للدمج.
 #6.7.3    المستوى: 2    الدور: D
 تحقق من أن فحوصات اكتمال ML‑BOM تفشل في عملية البناء إذا كانت أي بيانات تعريفية للمكون (التجزئة، الترخيص) مفقودة.
 #6.7.4    المستوى: 2    الدور: V
 تحقق من أن المستهلكين في المستوى الأدنى يمكنهم استعلام ML-BOMs عبر API للتحقق من صحة النماذج المستوردة وقت النشر.
 #6.7.5    المستوى: 3    الدور: V
 تحقق من أن قوائم المواد الخاصة بالتعلم الآلي (ML‑BOMs) تحت السيطرة على الإصدارات ويتم مقارنة الفروقات لاكتشاف التعديلات غير المصرح بها.

---

### المراجع

ML Supply Chain Compromise – MITRE ATLAS
Supply‑chain Levels for Software Artifacts (SLSA)
CycloneDX – Machine Learning Bill of Materials
What is Data Poisoning? – SentinelOne
Transfer Learning Attack – OWASP ML Security Top 10
AI Data Security Best Practices – CISA
Secure CI/CD Supply Chain – Sumo Logic
AI & Transparency: Protect ML Models – ReversingLabs
SBOM Overview – CISA
Training Data Poisoning Guide – Lakera.ai
Dependency Pinning for Reproducible Python – Medium

## سلوك نموذج C7، التحكم في الناتج وضمان السلامة

### هدف التحكم

يجب أن تكون مخرجات النماذج منظمة وموثوقة وآمنة وقابلة للتفسير وتتم مراقبتها باستمرار في بيئة الإنتاج. يؤدي ذلك إلى تقليل الهلوسات وتسريبات الخصوصية والمحتوى الضار والإجراءات غير المتوقعة، مع زيادة ثقة المستخدم والامتثال التنظيمي.

---

### C7.1 فرض تنسيق الإخراج

توقف المخططات الصارمة، وفك التشفير المقيد، والتحقق اللاحق المحتوى المشوه أو الضار قبل أن ينتشر.

 #7.1.1    المستوى: 1    الدور: D/V
 تحقق من أن مخططات الاستجابة (مثل مخطط JSON) مُدرجة في موجه النظام وأن كل مخرج يتم التحقق من صحته تلقائيًا؛ حيث تؤدي المخرجات غير المطابقة إلى الإصلاح أو الرفض.
 #7.1.2    المستوى: 1    الدور: D/V
 تحقق من تمكين فك التشفير المقيد (رموز التوقف، التعبيرات النمطية، الحد الأقصى لعدد الرموز) لمنع فيض البيانات أو قنوات جانبية في حقن المطالبات.
 #7.1.3    المستوى: 2    الدور: D/V
 تحقق من أن المكونات التالية تتعامل مع المخرجات على أنها غير موثوقة وتقوم بالتحقق منها وفقًا للمخططات أو من خلال فك التسلسل الآمن من الحقن.
 #7.1.4    المستوى: 3    الدور: V
 تحقق من تسجيل أحداث الإخراج غير الصحيح، وتحديد معدل حدوثها، وعرضها في المراقبة.

---

### C7.2 الكشف عن الهلوسة وتقليلها

تقدير عدم اليقين واستراتيجيات التراجع يحدان من الإجابات المختلقة.

 #7.2.1    المستوى: 1    الدور: D/V
 تحقق من أن احتمالات السجل على مستوى الرموز، التوافق الذاتي للجمع، أو كاشفات الهلوسة المدربة بدقة تعطي تقييم ثقة لكل إجابة.
 #7.2.2    المستوى: 1    الدور: D/V
 تحقق من أن الردود التي تقل عن عتبة الثقة القابلة للتكوين تُفعّل تدفقات العمل الاحتياطية (مثل التوليد المدعوم بالاستخراج، النموذج الثانوي، أو المراجعة البشرية).
 #7.2.3    المستوى: 2    الدور: D/V
 تحقق من أن حوادث الهلوسة مُوسومة ببيانات تعريف سبب الجذر ومُدخلة إلى خطوط أنابيب تحليل ما بعد الحادث والتعديل الدقيق.
 #7.2.4    المستوى: 3    الدور: D/V
 تحقق من إعادة معايرة العتبات والكواشف بعد التحديثات الكبيرة للنموذج أو قاعدة المعرفة.
 #7.2.5    المستوى: 3    الدور: V
 تحقق من أن تصورات لوحة المعلومات تتتبع معدلات الهلوسة.

---

### C7.3 تصفية الأمان والخصوصية للإخراج

تعمل فلاتر السياسات وتغطية الفريق الأحمر على حماية المستخدمين والبيانات السرية.

 #7.3.1    المستوى: 1    الدور: D/V
 تحقق من أن المصنفات قبل وبعد التوليد تحجب المحتوى الذي يحض على الكراهية والتحرش وإيذاء النفس والتطرف والمحتوى الجنسي الصريح بما يتماشى مع السياسة.
 #7.3.2    المستوى: 1    الدور: D/V
 تحقق من أن الكشف عن المعلومات الشخصية الحساسة (PII) وبيانات بطاقة الدفع (PCI) والحجب التلقائي يتم تشغيلهما في كل استجابة؛ حيث تؤدي الانتهاكات إلى رفع حادثة تتعلق بالخصوصية.
 #7.3.3    المستوى: 2    الدور: D
 تحقق من أن علامات السرية (مثل الأسرار التجارية) تنتقل عبر الوسائط المختلفة لمنع التسرب في النصوص أو الصور أو الشيفرة.
 #7.3.4    المستوى: 3    الدور: D/V
 تحقق من أن محاولات تجاوز الفلتر أو التصنيفات عالية الخطورة تتطلب موافقة ثانوية أو إعادة مصادقة المستخدم.
 #7.3.5    المستوى: 3    الدور: D/V
 تحقق من أن عتبات التصفية تعكس الأطر القانونية للنطاقات القضائية وسياق عمر/دور المستخدم.

---

### C7.4 الحد من الإخراج والإجراءات

تقييدات المعدل وأبواب الموافقة تمنع الإساءة والاستقلالية المفرطة.

 #7.4.1    المستوى: 1    الدور: D
 تحقق من أن الحصص لكل مستخدم ولكل مفتاح API تقيد الطلبات، والرموز، والتكلفة مع التراجع الأسي عند أخطاء 429.
 #7.4.2    المستوى: 1    الدور: D/V
 تحقق من أن الإجراءات المميزة (كتابة الملفات، تنفيذ الشيفرة، المكالمات الشبكية) تتطلب موافقة قائمة على السياسة أو تدخل بشري.
 #7.4.3    المستوى: 2    الدور: D/V
 تحقق من أن فحوصات التناسق عبر الوسائط تضمن عدم إمكانية استخدام الصور، الشيفرة، والنص المولدة لنفس الطلب لتهريب محتوى خبيث.
 #7.4.4    المستوى: 2    الدور: D
 تأكد من أن عمق تفويض الوكيل، وحدود التكرار، وقوائم الأدوات المسموح بها تم تكوينها صراحةً.
 #7.4.5    المستوى: 3    الدور: V
 تحقق من أن تجاوز الحدود يُصدر أحداث أمان مُنظمة لعمليات استيعاب SIEM.

---

### C7.5 قابلية شرح المخرجات

الإشارات الشفافة تحسن ثقة المستخدم وتصحيح الأخطاء الداخلي.

 #7.5.1    المستوى: 2    الدور: D/V
 تحقق من أن درجات الثقة الموجهة للمستخدم أو ملخصات التفكير المختصرة معروضة عندما يرى تقييم المخاطر ذلك مناسبًا.
 #7.5.2    المستوى: 2    الدور: D/V
 تحقق من أن التفسيرات المولدة تتجنب الكشف عن مطالبات النظام الحساسة أو البيانات المملوكة.
 #7.5.3    المستوى: 3    الدور: D
 تحقق من أن النظام يلتقط احتمالات السجل على مستوى الرموز أو خرائط الانتباه ويخزنها للفحص المصرح به.
 #7.5.4    المستوى: 3    الدور: V
 تأكد من أن القطع الأثرية المتعلقة بالتفسير تحت إدارة نسخ التحكم جنبًا إلى جنب مع إصدارات النموذج لأغراض التدقيق.

---

### C7.6 تكامل الرصد

تُغلق الرصد في الوقت الفعلي الحلقة بين التطوير والإنتاج.

 #7.6.1    المستوى: 1    الدور: D
 تحقق من أن المقاييس (انتهاكات المخطط، معدل الهلوسة، السمية، تسريبات المعلومات الشخصية، الكمون، التكلفة) تتدفق إلى منصة مراقبة مركزية.
 #7.6.2    المستوى: 1    الدور: V
 تحقق من تحديد عتبات التنبيه لكل مقياس سلامة، مع وجود مسارات تصعيد للمكالمة عند الحاجة.
 #7.6.3    المستوى: 2    الدور: V
 تحقق من أن لوحات المعلومات تربط الشذوذات في الإخراج بنموذج/الإصدار، وعلم الميزات، وتغييرات البيانات upstream.
 #7.6.4    المستوى: 2    الدور: D/V
 تحقق من أن بيانات المراقبة تعود إلى عمليات إعادة التدريب أو الضبط الدقيق أو تحديث القواعد ضمن سير عمل MLOps موثق.
 #7.6.5    المستوى: 3    الدور: V
 تحقق من أن خطوط أنابيب المراقبة قد تم اختبارها ضد الاختراق وتخضع للتحكم في الوصول لتجنب تسرب السجلات الحساسة.

---

### 7.7 ضوابط أمان الوسائط التوليدية

ضمان ألا تقوم أنظمة الذكاء الاصطناعي بإنتاج محتوى وسائط غير قانوني أو ضار أو غير مصرح به من خلال تطبيق قيود السياسات، والتحقق من صحة المخرجات، وقابلية التتبع.

 #7.7.1    المستوى: 1    الدور: D/V
 تحقق من أن موجهات النظام وتعليمات المستخدم تمنع بشكل صريح توليد الوسائط العميقة المزيفة غير القانونية أو الضارة أو غير المتفق عليها (مثل الصور، الفيديو، الصوت).
 #7.7.2    المستوى: 2    الدور: D/V
 تحقق من أن التعليمات تتم تصفيتها لمنع المحاولات التي تهدف إلى توليد انتحال شخصية، أو الخدع الجنسية الصريحة، أو الوسائط التي تصوّر أفراداً حقيقيين دون موافقتهم.
 #7.7.3    المستوى: 2    الدور: V
 تحقق من أن النظام يستخدم التجزئة الإدراكية، اكتشاف العلامات المائية، أو البصمة لمنع النسخ غير المصرح به للوسائط المحمية بحقوق الطبع والنشر.
 #7.7.4    المستوى: 3    الدور: D/V
 تحقق من أن جميع الوسائط المولدة موقعة تشفيرياً، أو تحتوي على علامة مائية، أو مضمنة ببيانات أصول مقاومة للتلاعب لضمان إمكانية تتبعها في المستقبل.
 #7.7.5    المستوى: 3    الدور: V
 تحقق من اكتشاف محاولات التحايل (مثل إخفاء الطلب، استخدام اللغة العامية، الصياغة العدائية)، وتسجيلها، وتحديد معدل حدوثها؛ ويتم إعلام أنظمة المراقبة بالإساءات المتكررة.

### المراجع

NIST AI Risk Management Framework
ISO/IEC 42001:2023 – AI Management System
OWASP Top-10 for Large Language Model Applications (2025)
Improper Output Handling – OWASP LLM05:2025
Practical Techniques to Constrain LLM Output
Dataiku – Structured Text Generation Guide
VL-Uncertainty: Detecting Hallucinations
HaDeMiF: Hallucination Detection & Mitigation
Building Confidence in LLM Outputs
Explainable AI & LLMs
LLM Red-Teaming Guide
Sensitive Information Disclosure in LLMs
LangChain – Chat Model Rate Limiting
OpenAI Rate-Limit & Exponential Back-off
Arize AI – LLM Observability Platform

## أمن ذاكرة C8، والتضمينات، وقاعدة بيانات المتجهات

### هدف التحكم

تمثل التضمينات ومخازن المتجهات "الذاكرة الحية" لأنظمة الذكاء الاصطناعي المعاصرة، حيث تستقبل بيانات المستخدم باستمرار وتعيد طرحها في سياقات النموذج عبر التوليد المعزز بالاسترجاع (RAG). إذا تُركت هذه الذاكرة بدون حوكمة، فقد تتسرب معلومات التعريف الشخصية، أو تنتهك الموافقة، أو يمكن عكسها لإعادة بناء النص الأصلي. الهدف من هذه العائلة الرقابية هو تقوية خطوط أنابيب الذاكرة وقواعد بيانات المتجهات بحيث يكون الوصول بأقل امتياز ممكن، وتكون التضمينات مريحة للخصوصية، وتنتهي صلاحية المتجهات المخزنة أو يمكن إلغاؤها حسب الطلب، ولا تلوث ذاكرة كل مستخدم مطالبات أو تنتهي مستخدم آخر.

---

### C8.1 ضوابط الوصول على الذاكرة وفهارس RAG

فرض ضوابط وصول دقيقة على كل مجموعة من المتجهات.

 #8.1.1    المستوى: 1    الدور: D/V
 تحقق من أن قواعد التحكم في الوصول على مستوى الصف/النطاق تحد من عمليات الإدراج والحذف والاستعلام حسب المستأجر أو المجموعة أو علامة المستند.
 #8.1.2    المستوى: 1    الدور: D/V
 تحقق من أن مفاتيح API أو JWT تحمل مطالبات محددة النطاق (مثل معرفات المجموعات، أفعال الإجراءات) وأنها تُجدد على الأقل كل ثلاثة أشهر.
 #8.1.3    المستوى: 2    الدور: D/V
 تأكد من اكتشاف محاولات التصعيد الامتيازي (مثل استعلامات التشابه عبر النطاقات) وتسجيلها في نظام إدارة الأحداث الأمنية (SIEM) خلال 5 دقائق.
 #8.1.4    المستوى: 2    الدور: D/V
 تحقق من أن قاعدة بيانات المتجهات تسجل عمليات التدقيق للمعرّف الفرعي للموضوع، العملية، معرف/نطاق المتجه، عتبة التشابه، وعدد النتائج.
 #8.1.5    المستوى: 3    الدور: V
 تأكد من اختبار قرارات الوصول للتحقق من وجود ثغرات تجاوز كلما تم ترقية المحركات أو تغيير قواعد تقسيم الفهرس.

---

### C8.2 تنظيف التضمين والتحقق منه

قم بفحص النص مسبقًا للبيانات الشخصية الحساسة (PII)، ثم قم بحذفها أو تمويهها قبل التحويل إلى متجهات، ويمكن أيضًا معالجة التضمينات لاحقًا لإزالة الإشارات المتبقية.

 #8.2.1    المستوى: 1    الدور: D/V
 تحقق من أن المعلومات الشخصية المعروفة (PII) والبيانات المنظمة يتم الكشف عنها بواسطة المصنفات التلقائية ويتم إخفاؤها أو تحويلها إلى رموز أو حذفها قبل عملية التضمين.
 #8.2.2    المستوى: 1    الدور: D
 تحقق من أن أنابيب التضمين ترفض أو تعزل المدخلات التي تحتوي على كود قابل للتنفيذ أو على مواد غير بتنسيق UTF-8 قد تؤدي إلى تلوث الفهرس.
 #8.2.3    المستوى: 2    الدور: D/V
 تحقق من تطبيق التثبيت المحلي أو متري لخصوصية التفاضل على تمثيلات الجمل التي تكون مسافتها إلى أي رمز PII معروف أقل من حد قابل للتكوين.
 #8.2.4    المستوى: 2    الدور: V
 تحقق من أن فعالية التنقية (مثل استدعاء إخفاء المعلومات الشخصية، الانحراف الدلالي) يتم التحقق منها على الأقل نصف سنويًا مقابل مجموعات البيانات المرجعية.
 #8.2.5    المستوى: 3    الدور: D/V
 تحقق من أن إعدادات التنقية تحت التحكم الإصدار وأن التغييرات تخضع لمراجعة نظراء.

---

### C8.3 انتهاء صلاحية الذاكرة، الإلغاء والحذف

تتطلب قوانين مثل اللائحة العامة لحماية البيانات (GDPR) "الحق في النسيان" الحذف في الوقت المناسب؛ لذلك يجب أن تدعم مخازن المتجهات ميزة مدة الحياة (TTL)، والحذف النهائي، وتعليم الحذف (tomb-stoning) حتى لا يمكن استرجاع المتجهات التي تم التراجع عنها أو إعادة فهرستها.

 #8.3.1    المستوى: 1    الدور: D/V
 تحقق من أن كل متجه وسجل بيانات وصفية يحملان TTL أو ملصق احتفاظ صريح يتم احترامه بواسطة مهام التنظيف التلقائية.
 #8.3.2    المستوى: 1    الدور: D/V
 تحقق من أن طلبات الحذف التي يبدأها المستخدم تقوم بمسح المتجهات والبيانات الوصفية ونسخ الكاش والفهارس المشتقة خلال 30 يومًا.
 #8.3.3    المستوى: 2    الدور: D
 تحقق من أن الحذف المنطقي يتبعه تمزيق تشفير كتل التخزين إذا كان العتاد يدعم ذلك، أو عن طريق تدمير مفتاح قبو المفاتيح.
 #8.3.4    المستوى: 3    الدور: D/V
 تحقق من استبعاد المتجهات المنتهية الصلاحية من نتائج البحث عن أقرب الجيران في غضون أقل من 500 مللي ثانية بعد انتهاء الصلاحية.

---

### C8.4 منع عكس التضمين وتسربه

الدفاعات الحديثة—إضافة الضوضاء، شبكات الإسقاط، تعديل الخلايا العصبية المتعلقة بالخصوصية، وتشفير طبقة التطبيق—يمكن أن تخفض معدلات الانعكاس على مستوى الرموز إلى أقل من 5%.

 #8.4.1    المستوى: 1    الدور: V
 تأكيد وجود نموذج تهديد رسمي يشمل هجمات الانعكاس، وانتماء العضوية، والاستنتاج السِماتي ويتم مراجعته سنويًا.
 #8.4.2    المستوى: 2    الدور: D/V
 تحقق من أن التشفير على مستوى طبقة التطبيق أو التشفير القابل للبحث يحمي المتجهات من القراءة المباشرة بواسطة مسؤولي البنية التحتية أو موظفي السحابة.
 #8.4.3    المستوى: 3    الدور: V
 تحقق من أن معلمات الدفاع (ε لـ DP، الضوضاء σ، رتبة الإسقاط k) توازن بين الخصوصية ≥ 99% حماية الرموز والفائدة ≤ 3% فقدان الدقة.
 #8.4.4    المستوى: 3    الدور: D/V
 تحقق من أن مقاييس مقاومة الانعكاس جزء من معايير الإصدار لتحديثات النماذج، مع تحديد ميزانيات الانحدار.

---

### C8.5 فرض نطاق التنفيذ للذاكرة الخاصة بالمستخدم

تسرب البيانات بين المستأجرين يظل أحد أهم مخاطر RAG: استعلامات التشابه التي لم يتم تصفيتها بشكل صحيح قد تكشف عن مستندات خاصة بعميل آخر.

 #8.5.1    المستوى: 1    الدور: D/V
 تحقق من أن كل استعلام استرجاع يتم تنقيحه بعد المعالجة بواسطة معرف المستأجر/المستخدم قبل تمريره إلى موجه نموذج اللغة الكبير (LLM).
 #8.5.2    المستوى: 1    الدور: D
 تحقق من أن أسماء المجموعات أو معرفات النطاقات تحتوي على ملح (salted) لكل مستخدم أو مستأجر بحيث لا يمكن تصادم المتجهات عبر النطاقات.
 #8.5.3    المستوى: 2    الدور: D/V
 تحقق من أن نتائج التشابه التي تتجاوز عتبة المسافة القابلة للتهيئة ولكنها تقع خارج نطاق المتصل يتم تجاهلها وتؤدي إلى إطلاق تنبيهات أمان.
 #8.5.4    المستوى: 2    الدور: V
 تحقق من أن اختبارات الضغط متعددة المستأجرين تحاكي استفسارات عدائية تحاول استرجاع وثائق خارج النطاق وتثبت عدم وجود أي تسرب.
 #8.5.5    المستوى: 3    الدور: D/V
 تحقق من أن مفاتيح التشفير مفصولة لكل مستأجر، مما يضمن العزل التشفيري حتى إذا تم مشاركة التخزين المادي.

---

### C8.6 نظام أمان الذاكرة المتقدم

ضوابط الأمان للهياكل المعقدة للذاكرة بما في ذلك الذاكرة العرضية، والذاكرة الدلالية، والذاكرة العاملة مع متطلبات محددة للعزل والتحقق.

 #8.6.1    المستوى: 1    الدور: D/V
 تحقق من أن أنواع الذاكرة المختلفة (التذكير العرضي، الدلالي، والوظيفي) لديها سياقات أمان معزولة مع ضوابط وصول قائمة على الأدوار، مفاتيح تشفير منفصلة، وأنماط وصول موثقة لكل نوع ذاكرة.
 #8.6.2    المستوى: 2    الدور: D/V
 تحقق من أن عمليات ترسيخ الذاكرة تشمل التحقق من الأمان لمنع إدخال ذكريات خبيثة من خلال تنقية المحتوى، والتحقق من المصدر، وفحوصات السلامة قبل التخزين.
 #8.6.3    المستوى: 2    الدور: D/V
 تحقق من أن استعلامات استرجاع الذاكرة تتم مراجعتها وتنقيتها لمنع استخراج المعلومات غير المصرح بها من خلال تحليل نمط الاستعلام، وفرض ضوابط الوصول، وتصفيه النتائج.
 #8.6.4    المستوى: 3    الدور: D/V
 تحقق من أن آليات نسيان الذاكرة تحذف المعلومات الحساسة بشكل آمن مع ضمانات محو التشفير باستخدام حذف المفتاح، أو الكتابة المتعددة المراحل، أو الحذف الآمن المعتمد على الأجهزة مع شهادات التحقق.
 #8.6.5    المستوى: 3    الدور: D/V
 تحقق من أن تكامل نظام الذاكرة يتم مراقبته باستمرار لاكتشاف التعديلات أو التلف غير المصرح بها من خلال استخدام مجموعات التحقق (checksums)، سجلات التدقيق، والتنبيهات الآلية عند حدوث تغييرات في محتوى الذاكرة خارج العمليات العادية.

---

### المراجع

Vector database security: Pinecone – IronCore Labs
Securing the Backbone of AI: Safeguarding Vector Databases and Embeddings – Privacera
Enhancing Data Security with RBAC of Qdrant Vector Database – AI Advances
Mitigating Privacy Risks in LLM Embeddings from Embedding Inversion – arXiv
DPPN: Detecting and Perturbing Privacy-Sensitive Neurons – OpenReview
Art. 17 GDPR – Right to Erasure
Sensitive Data in Text Embeddings Is Recoverable – Tonic.ai
PII Identification and Removal – NVIDIA NeMo Docs
De-identifying Sensitive Data – Google Cloud DLP
Remove PII from Conversations Using Sensitive Information Filters – AWS Bedrock Guardrails
Think Your RAG Is Secure? Think Again – Medium
Design a Secure Multitenant RAG Inferencing Solution – Microsoft Learn
Best Practices for Multi-Tenancy RAG with Milvus – Milvus Blog

## 9 التنسيق المستقل والعمل الوكلي الأمني

### هدف التحكم

ضمان أن أنظمة الذكاء الاصطناعي المستقلة أو متعددة الوكلاء يمكنها تنفيذ الإجراءات فقط التي تكون مقصودة صراحة، ومصادق عليها، وقابلة للتدقيق، وتقع ضمن حدود التكلفة والمخاطر المحددة. هذا يحمي ضد تهديدات مثل اختراق النظام المستقل، سوء استخدام الأدوات، اكتشاف حلقة الوكيل، اختطاف الاتصالات، تزوير الهوية، التلاعب بالسرب، والتلاعب بالنية.

---

### 9.1 تخطيط مهام الوكيل وميزانيات الاستدعاء الذاتي

تحديد سرعة الخطط التكرارية وإجبار نقاط تدقيق بشرية للإجراءات المميزة.

 #9.1.1    المستوى: 1    الدور: D/V
 تحقق من أن الحد الأقصى لعمق الاستدعاء الذاتي، والعرض، ووقت الساعة الحائطية، وعدد الرموز، والتكلفة المالية لكل تنفيذ للوكيل مُعدة مركزيًا وتحت تحكم الإصدار.
 #9.1.2    المستوى: 1    الدور: D/V
 تحقق من أن الإجراءات ذات الامتيازات أو التي لا يمكن التراجع عنها (مثل الالتزامات البرمجية، التحويلات المالية) تتطلب موافقة بشرية صريحة عبر قناة يمكن تدقيقها قبل التنفيذ.
 #9.1.3    المستوى: 2    الدور: D
 تحقق من أن مراقبات الموارد في الوقت الحقيقي تُفعّل انقطاع قاطع الدائرة عند تجاوز أي حد للميزانية، مما يوقف توسيع المهام بشكل إضافي.
 #9.1.4    المستوى: 2    الدور: D/V
 تحقق من تسجيل أحداث قاطع الدائرة مع معرف الوكيل، شرط التنشيط، وحالة الخطة الملتقطة للمراجعة الجنائية.
 #9.1.5    المستوى: 3    الدور: V
 تحقق من أن اختبارات الأمان تغطي سيناريوهات نفاد الميزانية وسيناريوهات تنفيذ الخطط بشكل غير محدود، مع التأكد من التوقف الآمن دون فقدان البيانات.
 #9.1.6    المستوى: 3    الدور: D
 تحقق من أن سياسات الميزانية معبر عنها كسياسات كرمز ويتم فرضها في CI/CD لمنع انحراف التكوين.

---

### 9.2 عزل ملحقات الأدوات

عزل تفاعلات الأدوات لمنع الوصول غير المصرح به إلى النظام أو تنفيذ الشيفرة.

 #9.2.1    المستوى: 1    الدور: D/V
 تحقق من أن كل أداة/إضافة تعمل داخل نظام تشغيل، حاوية، أو بيئة معزولة على مستوى WASM مع سياسات صلاحيات دنيا لنظام الملفات، الشبكة، ونظام الاستدعاءات.
 #9.2.2    المستوى: 1    الدور: D/V
 تحقق من أنه يتم فرض وتسجيل حصص موارد الحاوية المعزولة (CPU، الذاكرة، القرص، خروج الشبكة) وحدود وقت التنفيذ.
 #9.2.3    المستوى: 2    الدور: D/V
 تحقق من توقيع الملفات التنفيذية للأدوات أو المواصفات الرقمية؛ يتم التحقق من صحة التوقيعات قبل التحميل.
 #9.2.4    المستوى: 2    الدور: V
 تحقق من أن تيارات القياس عن بعد للصندوق الرملية تتدفق إلى نظام إدارة المعلومات الأمنية والأحداث (SIEM)؛ وأن الشذوذات (مثل محاولات الاتصالات الصادرة) تثير التنبيهات.
 #9.2.5    المستوى: 3    الدور: V
 تحقق من أن الإضافات عالية المخاطر تخضع لمراجعة الأمان واختبار الاختراق قبل نشرها في بيئة الإنتاج.
 #9.2.6    المستوى: 3    الدور: D/V
 تحقق من أن محاولات الهروب من الصندوق الرمل تُحظر تلقائيًا ويتم حجز الإضافة المخالفة ريثما تُجرى التحقيقات.

---

### 9.3 الحلقة المستقلة وحدود التكلفة

كشف وإيقاف الاستدعاء الذاتي غير المنضبط بين الوكلاء وانفجارات التكلفة.

 #9.3.1    المستوى: 1    الدور: D/V
 تحقق من أن مكالمات بين الوكلاء تتضمن حدًا للانتقال أو TTL تقوم بيئة التشغيل بتقليله وفرضه.
 #9.3.2    المستوى: 2    الدور: D
 تحقق من أن الوكلاء يحتفظون بمعرف فريد لشجرة الاستدعاء لاكتشاف الاستدعاءات الذاتية أو الأنماط الدورية.
 #9.3.3    المستوى: 2    الدور: D/V
 تحقق من أن عدادات وحدة الحوسبة التراكمية والإنفاق يتم تتبعها لكل سلسلة طلب؛ تجاوز الحد يؤدي إلى إلغاء السلسلة.
 #9.3.4    المستوى: 3    الدور: V
 تحقق من أن التحليل الرسمي أو فحص النماذج يثبت غياب التكرار غير المحدود في بروتوكولات الوكلاء.
 #9.3.5    المستوى: 3    الدور: D
 تحقق من أن أحداث إيقاف الحلقة تُولد تنبيهات وتُغذي مقاييس التحسين المستمر.

---

### 9.4 حماية من سوء الاستخدام على مستوى البروتوكول

تأمين قنوات الاتصال بين الوكلاء والأنظمة الخارجية لمنع الاختراق أو التلاعب.

 #9.4.1    المستوى: 1    الدور: D/V
 تحقق من أن جميع الرسائل بين الوكيل والأداة وبين الوكيل والوكيل الأخرى مصدقة (مثل TLS متبادل أو JWT) ومشفرة من طرف إلى طرف.
 #9.4.2    المستوى: 1    الدور: D
 تأكد من أن المخططات يتم التحقق منها بدقة؛ يتم رفض الحقول غير المعروفة أو الرسائل غير الصحيحة الصياغة.
 #9.4.3    المستوى: 2    الدور: D/V
 تحقق من أن فحوصات السلامة (MACs أو التوقيعات الرقمية) تغطي كامل حمولة الرسالة بما في ذلك معايير الأدوات.
 #9.4.4    المستوى: 2    الدور: D
 تحقق من أن حماية إعادة التشغيل (الرموز الأحادية أو نوافذ الطوابع الزمنية) يتم تطبيقها في طبقة البروتوكول.
 #9.4.5    المستوى: 3    الدور: V
 تحقق من أن تنفيذات البروتوكول تخضع للفحص العشوائي والتحليل الثابت للكشف عن عيوب الحقن أو التسلسل العكسي.

---

### 9.5 هوية الوكيل ودليل التلاعب

تأكد من أن تكون الإجراءات قابلة للعزو وأن تكون التعديلات قابلة للكشف.

 #9.5.1    المستوى: 1    الدور: D/V
 تحقق من أن كل نسخة من الوكيل تمتلك هوية تشفير فريدة (زوج مفاتيح أو شهادة معتمدة على الأجهزة).
 #9.5.2    المستوى: 2    الدور: D/V
 تحقق من توقيع وتاريخ جميع إجراءات الوكيل؛ يجب أن تتضمن السجلات التوقيع لضمان عدم الإنكار.
 #9.5.3    المستوى: 2    الدور: V
 تحقق من أن السجلات التي تظهر التلاعب مخزنة في وسط يتيح الإضافة فقط أو كتابة لمرة واحدة.
 #9.5.4    المستوى: 3    الدور: D
 التحقق من تدوير مفاتيح الهوية وفق جدول محدد وعند وجود مؤشرات اختراق.
 #9.5.5    المستوى: 3    الدور: D/V
 تحقق من أن محاولات التزييف أو تعارض المفتاح تؤدي إلى حجر صحي فوري للوكيل المتأثر.

---

### 9.6 تقليل المخاطر في جماعات الوكلاء المتعددة

تخفيف مخاطر السلوك الجماعي من خلال العزل والنمذجة الرسمية للسلامة.

 #9.6.1    المستوى: 1    الدور: D/V
 تحقق من أن الوكلاء العاملين في مجالات أمان مختلفة يعملون في بيئات تشغيل معزولة أو في قطاعات شبكة منفصلة.
 #9.6.2    المستوى: 3    الدور: V
 تحقق من أن سلوكيات الجماعات النموذجية مُصممة ومُتحقق من صحتها رسمياً من حيث الحيوية والسلامة قبل النشر.
 #9.6.3    المستوى: 3    الدور: D
 تحقق من أن مراقبي وقت التشغيل يكتشفون الأنماط الخطرة الناشئة (مثل التذبذبات، وحالات الجمود) ويبدؤون اتخاذ الإجراءات التصحيحية.

---

### 9.7 مصادقة / تفويض المستخدم والأداة

قم بتنفيذ ضوابط وصول قوية لكل إجراء يُفعّل بواسطة الوكيل.

 #9.7.1    المستوى: 1    الدور: D/V
 تحقق من أن الوكلاء يقومون بالمصادقة كجهات فاعلة من الدرجة الأولى على الأنظمة التابعة، دون إعادة استخدام بيانات اعتماد المستخدم النهائي.
 #9.7.2    المستوى: 2    الدور: D
 تحقق من أن سياسات التفويض الدقيق تقيد الأدوات التي يمكن للوكيل استدعاؤها والمعلمات التي يمكنه تقديمها.
 #9.7.3    المستوى: 2    الدور: V
 تحقق من إعادة تقييم فحوصات الامتيازات في كل استدعاء (الترخيص المستمر)، وليس فقط عند بداية الجلسة.
 #9.7.4    المستوى: 3    الدور: D
 تحقق من أن الامتيازات المفوضة تنتهي صلاحيتها تلقائيًا وتتطلب إعادة الموافقة بعد انتهاء المهلة أو تغيير النطاق.

---

### 9.8 أمان التواصل بين الوكلاء

قم بتشفير وحماية سلامة جميع الرسائل بين الوكلاء لمنع التنصت والتلاعب.

 #9.8.1    المستوى: 1    الدور: D/V
 تحقق من أن المصادقة المتبادلة والتشفير بسريّة مثالية للأمام (مثل TLS 1.3) إلزاميان لقنوات الوكيل.
 #9.8.2    المستوى: 1    الدور: D
 تحقق من سلامة الرسالة وأصلها قبل المعالجة؛ الفشل يؤدي إلى إصدار تنبيهات وحذف الرسالة.
 #9.8.3    المستوى: 2    الدور: D/V
 تحقق من تسجيل بيانات التعريف الخاصة بالاتصالات (الطوابع الزمنية، أرقام التتابع) لدعم إعادة البناء الجنائي.
 #9.8.4    المستوى: 3    الدور: V
 تحقق من أن التحقق الرسمي أو التحقق من النموذج يؤكد أن آلات حالة البروتوكول لا يمكن دفعها إلى حالات غير آمنة.

---

### 9.9 التحقق من النية وفرض القيود

تحقق من أن أفعال الوكيل تتوافق مع نية المستخدم المعلنة وقيود النظام.

 #9.9.1    المستوى: 1    الدور: D
 تحقق من أن محركات حل القيود قبل التنفيذ تقوم بفحص الإجراءات المقترحة مقابل قواعد السلامة والسياسة المبرمجة مسبقًا.
 #9.9.2    المستوى: 2    الدور: D/V
 تأكد من أن الإجراءات ذات الأثر العالي (المالية، التدميرية، الحساسة للخصوصية) تتطلب تأكيد نية صريح من المستخدم المبادر.
 #9.9.3    المستوى: 2    الدور: V
 تحقق من أن فحوصات الشروط اللاحقة تتحقق من أن الإجراءات المكتملة حققت التأثيرات المقصودة بدون آثار جانبية؛ وأي اختلافات تؤدي إلى التراجع.
 #9.9.4    المستوى: 3    الدور: V
 تحقق من أن الأساليب الرسمية (مثل التحقق من النماذج، إثبات النظريات) أو اختبارات القائمة على الخصائص تثبت أن خطط الوكلاء تلبي جميع القيود المعلنة.
 #9.9.5    المستوى: 3    الدور: D
 تحقق من أن حوادث عدم تطابق النية أو انتهاك القيود تغذي دورات التحسين المستمر ومشاركة معلومات التهديدات.

---

### 9.10 أمان استراتيجية استدلال الوكيل

اختيار وتنفيذ آمن لاستراتيجيات التفكير المختلفة بما في ذلك أساليب ReAct و Chain-of-Thought و Tree-of-Thoughts.

 #9.10.1    المستوى: 1    الدور: D/V
 تحقق من أن اختيار استراتيجية الاستدلال يستخدم معايير حتمية (تعقيد الإدخال، نوع المهمة، سياق الأمان) وأن نفس المدخلات ينتج عنها اختيارات استراتيجية متطابقة ضمن نفس سياق الأمان.
 #9.10.2    المستوى: 1    الدور: D/V
 تحقق من أن كل استراتيجية تفكير (ReAct، سلسلة الأفكار، شجرة الأفكار) لديها تحقق مخصص للمدخلات، وتنقية مخرجات، وحدود زمن تنفيذ محددة تتناسب مع نهجها الذهني.
 #9.10.3    المستوى: 2    الدور: D/V
 تحقق من تسجيل انتقالات استراتيجية التفكير مع السياق الكامل بما في ذلك خصائص الإدخال، وقيم معايير الاختيار، وبيانات تنفيذ العمليات لأجل إعادة بناء مسار التدقيق.
 #9.10.4    المستوى: 2    الدور: D/V
 تحقق من أن استدلال شجرة الأفكار يتضمن آليات تقليم الفروع التي تنهي الاستكشاف عند اكتشاف انتهاكات السياسات أو حدود الموارد أو حدود الأمان.
 #9.10.5    المستوى: 2    الدور: D/V
 تحقق من أن دورات ReAct (التفكير-الفعل-الملاحظة) تتضمن نقاط تحقق للتحقق في كل مرحلة: التحقق من خطوة التفكير، تفويض الفعل، وتنقية الملاحظة قبل المتابعة.
 #9.10.6    المستوى: 3    الدور: D/V
 تحقق من مراقبة مقاييس أداء استراتيجية الاستدلال (وقت التنفيذ، استخدام الموارد، جودة المخرجات) مع التنبيهات التلقائية عند انحراف المقاييس عن الحدود المُعدة مسبقًا.
 #9.10.7    المستوى: 3    الدور: D/V
 تحقق من أن أساليب الاستدلال الهجينة التي تجمع بين استراتيجيات متعددة تحافظ على التحقق من صحة الإدخال وقيود الإخراج لجميع الاستراتيجيات المكونة دون تجاوز أي ضوابط أمان.
 #9.10.8    المستوى: 3    الدور: D/V
 تحقق من أن اختبار أمان استراتيجية التفكير يشمل اختبار التعثر باستخدام مدخلات مشوهة، ونصوص معادية مصممة لإجبار التنقل بين الاستراتيجيات، واختبار شروط الحدود لكل نهج معرفي.

---

### 9.11 إدارة حالة دورة حياة الوكيل والأمان

تهيئة الوكيل الآمن، والتحولات الحالة، والإنهاء مع مسارات تدقيق تشفيرية وإجراءات استرداد محددة.

 #9.11.1    المستوى: 1    الدور: D/V
 تحقق من أن تهيئة الوكيل تتضمن إنشاء هوية تشفيرية باستخدام بيانات اعتماد مدعومة بالأجهزة وسجلات تدقيق بدء تشغيل غير قابلة للتغيير تحتوي على معرف الوكيل، والطابع الزمني، وهاش التكوين، ومعلمات التهيئة.
 #9.11.2    المستوى: 2    الدور: D/V
 تحقق من أن انتقالات حالة الوكيل موقعة تشفيرياً، ومؤرخة زمنياً، ومسجلة مع السياق الكامل بما في ذلك الأحداث التي أطلقتها، هاش الحالة السابقة، هاش الحالة الجديدة، والتحققات الأمنية التي تم تنفيذها.
 #9.11.3    المستوى: 2    الدور: D/V
 تحقق من أن إجراءات إيقاف الوكيل تتضمن مسحًا آمنًا للذاكرة باستخدام المسح التشفيري أو الكتابة المتعددة المتكررة، وإلغاء صلاحيات الاعتماد مع إشعار جهة إصدار الشهادات، وإنشاء شهادات إنهاء مقاومة للتلاعب.
 #9.11.4    المستوى: 3    الدور: D/V
 تحقق من أن آليات استرداد الوكيل تتحقق من سلامة الحالة باستخدام مجموعات التحقق التشفيرية (SHA-256 كحد أدنى) وتعود إلى حالات معروفة وسليمة عند اكتشاف الفساد مع تنبيهات آلية ومتطلبات موافقة يدوية.
 #9.11.5    المستوى: 3    الدور: D/V
 تحقق من أن آليات استمرارية الوكيل تقوم بتشفير بيانات الحالة الحساسة باستخدام مفاتيح AES-256 لكل وكيل وتنفذ تدويرًا آمنًا للمفاتيح على جداول زمنية قابلة للتكوين (بحد أقصى 90 يومًا) مع نشر بدون توقف.

---

### 9.12 إطار أمان تكامل الأدوات

ضوابط الأمان لتحميل الأدوات الديناميكية، والتنفيذ، والتحقق من النتائج مع عمليات تقييم المخاطر والموافقة المحددة.

 #9.12.1    المستوى: 1    الدور: D/V
 تحقق من أن أوصاف الأدوات تتضمن بيانات أمان تحدد الصلاحيات المطلوبة (قراءة/كتابة/تنفيذ)، ومستويات المخاطر (منخفض/متوسط/عالٍ)، وحدود الموارد (وحدة المعالجة المركزية، الذاكرة، الشبكة)، ومتطلبات التحقق الموثقة في بيانات تعريف الأدوات.
 #9.12.2    المستوى: 1    الدور: D/V
 تحقق من أن نتائج تنفيذ الأدوات يتم التحقق من صحتها مقابل المخططات المتوقعة (مخطط JSON، مخطط XML) وسياسات الأمان (تنقية المخرجات، تصنيف البيانات) قبل الدمج مع حدود زمنية وإجراءات معالجة الأخطاء.
 #9.12.3    المستوى: 2    الدور: D/V
 تحقق من أن سجلات تفاعل الأدوات تتضمن سياق أمني مفصل يشمل استخدام الامتيازات، وأنماط الوصول إلى البيانات، ووقت التنفيذ، واستهلاك الموارد، وأكواد الإرجاع مع تسجيل منظم للاندماج مع نظام إدارة معلومات الأمن والأحداث (SIEM).
 #9.12.4    المستوى: 2    الدور: D/V
 تحقق من أن آليات تحميل الأدوات الديناميكية تتحقق من التوقيعات الرقمية باستخدام بنية المفاتيح العامة (PKI) وتنفذ بروتوكولات تحميل آمنة مع عزل في بيئة معزولة (sandbox) والتحقق من الأذونات قبل التنفيذ.
 #9.12.5    المستوى: 3    الدور: D/V
 تحقق من أن تقييمات أمان الأدوات يتم تفعيلها تلقائيًا للإصدارات الجديدة مع وجود بوابات موافقة إلزامية تشمل التحليل الثابت، والاختبار الديناميكي، ومراجعة فريق الأمان مع معايير موافقة موثقة ومتطلبات اتفاقية مستوى الخدمة (SLA).

---

#### المراجع

MITRE ATLAS tactics ML09
Circuit-breaker research for AI agents — Zou et al., 2024
Trend Micro analysis of sandbox escapes in AI agents — Park, 2025
Auth0 guidance on human-in-the-loop authorization for agents — Martinez, 2025
Medium deep-dive on MCP & A2A protocol hijacking — ForAISec, 2025
Rapid7 fundamentals on spoofing attack prevention — 2024
Imperial College verification of swarm systems — Lomuscio et al.
NIST AI Risk Management Framework 1.0, 2023
WIRED security briefing on encryption best practices, 2024
OWASP Top 10 for LLM Applications, 2025
Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS
[How Is LLM Reasoning Distracted by Irrelevant Context?
An Analysis Using a Controlled Benchmark](https://www.arxiv.org/pdf/2505.18761)
Large Language Model Sentinel: LLM Agent for Adversarial Purification
Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents

## 10 المتانة ضد الهجمات العدائية والدفاع عن الخصوصية

### هدف التحكم

ضمان بقاء نماذج الذكاء الاصطناعي موثوقة، ومحافظة على الخصوصية، ومقاومة لسوء الاستخدام عند مواجهة هجمات التهرب، الاستدلال، الاستغلال، أو التسميم.

---

### 10.1 محاذاة النموذج والسلامة

الحماية من المخرجات الضارة أو المخالفة للسياسات.

 #10.1.1    المستوى: 1    الدور: D/V
 تحقق من أن مجموعة اختبار المحاذاة (مطالبات الفريق الأحمر، استكشافات كسر الحماية، المحتوى الممنوع) تحت نظام إصدار ويتم تشغيلها مع كل إصدار للنموذج.
 #10.1.2    المستوى: 1    الدور: D
 التحقق من أن قواعد الرفض والحماية من الإكمال الآمن مطبقة.
 #10.1.3    المستوى: 2    الدور: D/V
 تحقق من أن المُقيّم الآلي يقيس معدل المحتوى الضار ويُحدد التراجعات التي تتجاوز العتبة المحددة.
 #10.1.4    المستوى: 2    الدور: D
 تحقق من توثيق تدريب مكافحة الهروب من الحماية وقابليته للتكرار.
 #10.1.5    المستوى: 3    الدور: V
 تحقق من أن إثباتات الامتثال للسياسات الرسمية أو المراقبة المعتمدة تغطي النطاقات الحرجة.

---

### 10.2 تقوية ضد الأمثلة التضليلية

زيادة المرونة تجاه المدخلات المُعدَّلة. التدريب العكسي المتين وتقييم المعايير المرجعية هما أفضل الممارسات الحالية.

 #10.2.1    المستوى: 1    الدور: D
 تحقق من أن مستودعات المشروع تتضمن تكوينات التدريب العدائية مع بذور قابلة لإعادة الإنتاج.
 #10.2.2    المستوى: 2    الدور: D/V
 تحقق من أن كشف الأمثلة المعادية يرفع تنبيهات الحظر في خطوط الإنتاج.
 #10.2.4    المستوى: 3    الدور: V
 تحقق من أن إثباتات المتانة المعتمدة أو شهادات حدود الفاصل تغطي على الأقل الفئات الحرجة العليا.
 #10.2.5    المستوى: 3    الدور: V
 تحقق من أن اختبارات الانحدار تستخدم هجمات تكيفية لتأكيد عدم وجود فقدان ملحوظ في الصلابة.

---

### 10.3 التخفيف من استنتاج العضوية

تقييد القدرة على تحديد ما إذا كانت السجلات ضمن بيانات التدريب. تظل الخصوصية التفاضلية وإخفاء درجة الثقة هي أكثر وسائل الدفاع المعروفة فعالية.

 #10.3.1    المستوى: 1    الدور: D
 تحقق من أن تنظيم الانتروبيا لكل استعلام أو ضبط درجة الحرارة يقلل من التوقعات المفرطة الثقة.
 #10.3.2    المستوى: 2    الدور: D
 تحقق من أن التدريب يستخدم تحسين الخصوصية التفاضلية المحدودة بـ ε للمجموعات البيانية الحساسة.
 #10.3.3    المستوى: 2    الدور: V
 تحقق من أن محاكاة الهجوم (نموذج الظل أو الصندوق الأسود) تُظهر مساحة تحت منحنى الهجوم (AUC) ≤ 0.60 على البيانات المحتجزة.

---

### 10.4 مقاومة انقلاب النموذج

منع إعادة بناء السمات الخاصة. تبرز الدراسات الحديثة تقطيع المخرجات وضمانات الخصوصية التفاضلية كدفاعات عملية.

 #10.4.1    المستوى: 1    الدور: D
 تحقق من عدم إخراج السمات الحساسة مباشرةً أبدًا؛ وعند الضرورة، استخدم التجميعات أو التحويلات ذات الاتجاه الواحد.
 #10.4.2    المستوى: 1    الدور: D/V
 تحقق من أن حدود معدل الاستعلامات تحد من تكرار الاستعلامات التكيفية من نفس الجهة الأساسية.
 #10.4.3    المستوى: 2    الدور: D
 تحقق من أن النموذج مدرب باستخدام ضوضاء تحافظ على الخصوصية.

---

### 10.5 الدفاع ضد استخراج النماذج

كشف وردع الاستنساخ غير المصرح به. يُنصح باستخدام العلامات المائية وتحليل نمط الاستعلام.

 #10.5.1    المستوى: 1    الدور: D
 تحقق من أن بوابات الاستدلال تفرض حدود معدلات عامة وعلى أساس مفتاح API مُفصلة بما يتناسب مع عتبة تذكر النموذج.
 #10.5.2    المستوى: 2    الدور: D/V
 تحقق من أن إحصائيات إنتروبيا الاستعلام وتعددية الإدخال تغذي كاشف الاستخراج الآلي.
 #10.5.3    المستوى: 2    الدور: V
 تحقق من أن العلامات المائية الهشة أو الاحتمالية يمكن إثباتها بقيمة p < 0.01 في ≤ 1 000 استعلام ضد نسخة مشبوهة.
 #10.5.4    المستوى: 3    الدور: D
 تحقق من أن مفاتيح العلامات المائية ومجموعات المشغلات مخزنة في وحدة أمان الأجهزة ويتم تدويرها سنويًا.
 #10.5.5    المستوى: 3    الدور: V
 تأكد من أن أحداث التنبيه بالاستخراج تتضمن الاستعلامات المخالفة وأنها مدمجة مع كتيبات الاستجابة للحوادث.

---

### 10.6 الكشف عن البيانات الملوثة أثناء وقت الاستدلال

تحديد المدخلات المزودة بأبواب خلفية أو الملوثة وتحييدها.

 #10.6.1    المستوى: 1    الدور: D
 تحقق من أن المدخلات تمر عبر كاشف الشذوذ (مثل STRIP، تقييم الاتساق) قبل استدلال النموذج.
 #10.6.2    المستوى: 1    الدور: V
 تحقق من ضبط عتبات الكاشف على مجموعات التحقق النظيفة/المسمومة لتحقيق نسبة أقل من 5% من الإيجابيات الخاطئة.
 #10.6.3    المستوى: 2    الدور: D
 تحقق من أن المدخلات التي تم اعتبارها ملوثة تؤدي إلى تفعيل الحظر الناعم وسير العمل الخاص بالمراجعة البشرية.
 #10.6.4    المستوى: 2    الدور: V
 تحقق من أن الكواشف تخضع لاختبارات ضغط باستخدام هجمات خلفية تكيفية بدون مشغّل.
 #10.6.5    المستوى: 3    الدور: D
 تحقق من تسجيل مقاييس فعالية الكشف وإعادة تقييمها بشكل دوري باستخدام معلومات تهديد حديثة.

---

### 10.7 التكيف الديناميكي لسياسة الأمان

تحديثات سياسة الأمان في الوقت الحقيقي بناءً على استخبارات التهديدات وتحليل السلوك.

 #10.7.1    المستوى: 1    الدور: D/V
 تحقق من إمكانية تحديث سياسات الأمان ديناميكيًا دون الحاجة لإعادة تشغيل الوكيل مع الحفاظ على سلامة إصدار السياسة.
 #10.7.2    المستوى: 2    الدور: D/V
 تحقق من أن تحديثات السياسات موقعة تشفيرياً من قبل موظفي الأمن المخولين ويتم التحقق منها قبل التطبيق.
 #10.7.3    المستوى: 2    الدور: D/V
 تحقق من تسجيل تغييرات السياسة الديناميكية مع سجلات تدقيق كاملة تشمل التبرير، وسلاسل الموافقة، وإجراءات التراجع.
 #10.7.4    المستوى: 3    الدور: D/V
 تحقق من أن آليات الأمان التكيفية تقوم بضبط حساسية اكتشاف التهديدات بناءً على سياق المخاطر وأنماط السلوك.
 #10.7.5    المستوى: 3    الدور: D/V
 تحقق من أن قرارات تكيف السياسة قابلة للتفسير وتتضمن أدلة مسارات لمراجعة فريق الأمان.

---

### 10.8 التحليل الأمني القائم على الانعكاس

التحقق الأمني من خلال التفكير الذاتي للوكيل والتحليل الميتا-معرفي.

 #10.8.1    المستوى: 1    الدور: D/V
 تحقق من أن آليات انعكاس الوكيل تشمل التقييم الذاتي المركَّز على الأمان للقرارات والإجراءات.
 #10.8.2    المستوى: 2    الدور: D/V
 تحقق من أن مخرجات الانعكاس يتم التحقق من صحتها لمنع التلاعب بآليات التقييم الذاتي عبر المدخلات العدائية.
 #10.8.3    المستوى: 2    الدور: D/V
 تحقق من أن تحليل الأمان الميتا-معرفي يحدد التحيز المحتمل أو التلاعب أو الاختراق في عمليات تفكير الوكيل.
 #10.8.4    المستوى: 3    الدور: D/V
 تحقق من أن تحذيرات الأمان المعتمدة على الانعكاس تؤدي إلى تفعيل المراقبة المعززة وسير العمل المحتمل للتدخل البشري.
 #10.8.5    المستوى: 3    الدور: D/V
 تحقق من أن التعلم المستمر من المراجعات الأمنية يحسن من اكتشاف التهديدات دون التأثير سلبًا على الوظائف الشرعية.

---

### 10.9 الأمان في التطور والتحسين الذاتي

ضوابط الأمان لأنظمة الوكلاء القادرة على التعديل الذاتي والتطور.

 #10.9.1    المستوى: 1    الدور: D/V
 تحقق من أن قدرات التعديل الذاتي مقيدة بالمناطق الآمنة المخصصة مع وجود حدود تحقق رسمية.
 #10.9.2    المستوى: 2    الدور: D/V
 تحقق من أن مقترحات التطور تخضع لتقييم تأثير الأمان قبل التنفيذ.
 #10.9.3    المستوى: 2    الدور: D/V
 تحقق من أن آليات التحسين الذاتي تشمل قدرات التراجع مع التحقق من السلامة.
 #10.9.4    المستوى: 3    الدور: D/V
 تحقق من أن الأمان في التعلم الفوقي يمنع التلاعب العدائي بخوارزميات التحسين.
 #10.9.5    المستوى: 3    الدور: D/V
 تحقق من أن التحسين الذاتي المتكرر محكوم بقيود السلامة الرسمية مع أدلة رياضية على التقارب.

---

#### المراجع

MITRE ATLAS adversary tactics for ML
NIST AI Risk Management Framework 1.0, 2023
OWASP Top 10 for LLM Applications, 2025
Adversarial Training: A Survey — Zhao et al., 2024
RobustBench adversarial-robustness benchmark
Membership-Inference & Model-Inversion Risk Survey, 2025
PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023
Model-Inversion Attacks & Defenses Survey — AI Review, 2025
Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024
Fragile Model Watermarking Survey — 2025
Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025
BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024

## 11 حماية الخصوصية وإدارة البيانات الشخصية

### هدف التحكم

الحفاظ على ضمانات خصوصية صارمة عبر دورة حياة الذكاء الاصطناعي بأكملها—الجمع، التدريب، الاستدلال، والاستجابة للحوادث—بحيث تتم معالجة البيانات الشخصية فقط بموافقة واضحة، ونطاق ضروري أدنى، ومحو قابل للإثبات، وضمانات خصوصية رسمية.

---

### 11.1 إخفاء الهوية وتقليل البيانات

 #11.1.1    المستوى: 1    الدور: D/V
 تحقق من أن المعرفات المباشرة وشبه المعرفات قد أُزيلت أو حُوّلت إلى هاش.
 #11.1.2    المستوى: 2    الدور: D/V
 تحقق من أن عمليات التدقيق الآلية تقيس التماثل-ك والتنوع-ل وتنبه عند انخفاض القيم عن الحدود المحددة في السياسة.
 #11.1.3    المستوى: 2    الدور: V
 تحقق من أن تقارير أهمية ميزات النموذج تثبت عدم وجود تسرب معرف يتجاوز ε = 0.01 من المعلومات المشتركة.
 #11.1.4    المستوى: 3    الدور: V
 تحقق من أن البراهين الرسمية أو شهادات البيانات التركيبية تظهر أن خطر إعادة التعريف ≤ 0.05 حتى في ظل هجمات الربط.

---

### 11.2 الحق في النسيان وتنفيذ الحذف

 #11.2.1    المستوى: 1    الدور: D/V
 تحقق من أن طلبات حذف بيانات الموضوع تنتقل إلى مجموعات البيانات الخام، نقاط التحقق، التضمينات، السجلات، والنسخ الاحتياطية ضمن اتفاقيات مستوى الخدمة التي تقل عن 30 يومًا.
 #11.2.2    المستوى: 2    الدور: D
 تحقق من أن إجراءات "نزع التعلم من الآلة" تعيد التدريب فعليًا أو تقرب الإزالة باستخدام خوارزميات نزع التعلم المعتمدة.
 #11.2.3    المستوى: 2    الدور: V
 تحقق من أن تقييم نموذج الظل يثبت أن السجلات المنسية تؤثر بأقل من 1% من النتائج بعد عملية النسيان.
 #11.2.4    المستوى: 3    الدور: V
 تحقق من أن أحداث الحذف مُسجلة بشكل ثابت وغير قابلة للتغيير وقابلة للتدقيق للهيئات التنظيمية.

---

### 11.3 التدابير الوقائية للخصوصية التفاضلية

 #11.3.1    المستوى: 2    الدور: D/V
 تحقق من أن لوحات عد خسارة الخصوصية تنبه عند تجاوز قيمة ε التراكمية للحدود المحددة في السياسة.
 #11.3.2    المستوى: 2    الدور: V
 تحقق من أن تدقيقات الخصوصية ذات الصندوق الأسود تقدر ε̂ ضمن 10% من القيمة المعلنة.
 #11.3.3    المستوى: 3    الدور: V
 تحقق من أن البراهين الرسمية تغطي جميع عمليات التعديل الدقيق وما بعد التدريب والتضمينات.

---

### 11.4 تحديد الغرض - الحماية من تحديد الغرض الزائد وزحف نطاق المشروع

 #11.4.1    المستوى: 1    الدور: D
 تحقق من أن كل مجموعة بيانات ونقطة فحص النموذج تحمل وسماً للغرض يمكن قراءته آليًا ومتوافقًا مع الموافقة الأصلية.
 #11.4.2    المستوى: 1    الدور: D/V
 تحقق من أن مراقبي وقت التشغيل يكتشفون الاستعلامات غير المتوافقة مع الغرض المعلن ويُطلقون الرفض الناعم.
 #11.4.3    المستوى: 3    الدور: D
 تحقق من أن بوابات السياسة ككود تمنع إعادة نشر النماذج إلى مجالات جديدة دون مراجعة تقييم تأثير حماية البيانات (DPIA).
 #11.4.4    المستوى: 3    الدور: V
 تحقق من أن إثباتات التتبع الرسمية تظهر أن دورة حياة كل بيانات شخصية تبقى ضمن نطاق الموافقة المعطاة.

---

### 11.5 إدارة الموافقات وتتبع الأساس القانوني

 #11.5.1    المستوى: 1    الدور: D/V
 تحقق من أن منصة إدارة الموافقة (CMP) تسجل حالة الموافقة، والغرض، وفترة الاحتفاظ لكل موضوع بيانات.
 #11.5.2    المستوى: 2    الدور: D
 تحقق من أن واجهات برمجة التطبيقات تعرض رموز الموافقة؛ يجب على النماذج التحقق من نطاق الرمز قبل الاستنتاج.
 #11.5.3    المستوى: 2    الدور: D/V
 تأكد من أن رفض أو سحب الموافقة يوقف خطوط معالجة البيانات خلال 24 ساعة.

---

### 11.6 التعلم الموزع مع ضوابط الخصوصية

 #11.6.1    المستوى: 1    الدور: D
 تحقق من أن تحديثات العميل تستخدم إضافة ضوضاء خصوصية تفريقية محلية قبل التجميع.
 #11.6.2    المستوى: 2    الدور: D/V
 تحقق من أن مقاييس التدريب تتسم بالخصوصية التفاضلية ولا تكشف أبداً عن خسارة عميل واحد فقط.
 #11.6.3    المستوى: 2    الدور: V
 تحقق من تمكين التجميع المقاوم للتسمم (مثل Krum/Trimmed-Mean).
 #11.6.4    المستوى: 3    الدور: V
 تحقق من أن البراهين الرسمية تثبت ميزانية ε الإجمالية مع فقدان فائدة أقل من 5.

---

#### المراجع

GDPR & AI Compliance Best Practices
EU Parliament Study on GDPR & AI, 2020
ISO 31700-1:2023 — Privacy by Design for Consumer Products
NIST Privacy Framework 1.1 (2025 Draft)
Machine Unlearning: Right-to-Be-Forgotten Techniques
A Survey of Machine Unlearning, 2024
Auditing DP-SGD — ArXiv 2024
DP-SGD Explained — PyTorch Blog
Purpose-Limitation for AI — IJLIT 2025
Data-Protection Considerations for AI — URM Consulting
Top Consent-Management Platforms, 2025
Secure Aggregation in DP Federated Learning — ArXiv 2024

## المراقبة، التسجيل واكتشاف الشذوذ في C12

### هدف التحكم

يوفر هذا القسم المتطلبات لتقديم رؤية في الوقت الحقيقي والتحليل الجنائي لما يراه النموذج ومكونات الذكاء الاصطناعي الأخرى، وما يقومون به، وما يعيدونه، بحيث يمكن اكتشاف التهديدات وتصنيفها والتعلم منها.

### C12.1 تسجيل الطلب والاستجابة

 #12.1.1    المستوى: 1    الدور: D/V
 تحقق من تسجيل جميع مطالبات المستخدم واستجابات النموذج مع البيانات الوصفية المناسبة (مثل الطابع الزمني، معرف المستخدم، معرف الجلسة، إصدار النموذج).
 #12.1.2    المستوى: 1    الدور: D/V
 تحقق من تخزين السجلات في مستودعات آمنة ومحكومة بالوصول مع سياسات احتفاظ مناسبة وإجراءات نسخ احتياطية.
 #12.1.3    المستوى: 1    الدور: D/V
 تحقق من أن أنظمة تخزين السجلات تنفذ التشفير أثناء الراحة وأثناء النقل لحماية المعلومات الحساسة الموجودة في السجلات.
 #12.1.4    المستوى: 1    الدور: D/V
 تحقق من أن البيانات الحساسة في المطالبات والمخرجات يتم تحريرها أو إخفاؤها تلقائيًا قبل تسجيلها، مع وجود قواعد تحرير قابلة للتكوين للبيانات الشخصية المعروفة (PII)، وبيانات الاعتماد، والمعلومات الملكية.
 #12.1.5    المستوى: 2    الدور: D/V
 تحقق من أن قرارات السياسات وإجراءات تصفية الأمان يتم تسجيلها بتفصيل كافٍ لتمكين التدقيق وتصحيح الأخطاء في أنظمة مراقبة المحتوى.
 #12.1.6    المستوى: 2    الدور: D/V
 تحقق من أن سلامة السجلات محمية من خلال مثلاً التوقيعات التشفيرية أو التخزين للكتابة فقط.

---

### C12.2 كشف وسيلة الإساءة والتنبيه

 #12.2.1    المستوى: 1    الدور: D/V
 تحقق من أن النظام يكتشف وينبه عند وجود أنماط الهروب المعروفة، ومحاولات حقن الأوامر، والمدخلات العدائية باستخدام الكشف القائم على التوقيع.
 #12.2.2    المستوى: 1    الدور: D/V
 تحقق من أن النظام يتكامل مع منصات إدارة معلومات وأحداث الأمان (SIEM) القائمة باستخدام تنسيقات وسجلات البروتوكولات القياسية.
 #12.2.3    المستوى: 2    الدور: D/V
 تحقق من أن الأحداث الأمنية المعززة تتضمن سياقًا خاصًا بالذكاء الاصطناعي مثل معرفات النماذج، درجات الثقة، وقرارات مرشحات الأمان.
 #12.2.4    المستوى: 2    الدور: D/V
 تحقق من أن كشف الشذوذ السلوكي يحدد أنماط المحادثة غير العادية، ومحاولات الإعادة المفرطة، أو سلوكيات الاستقصاء المنهجية.
 #12.2.5    المستوى: 2    الدور: D/V
 تحقق من أن آليات التنبيه في الوقت الحقيقي تقوم بإخطار فرق الأمن عند اكتشاف انتهاكات محتملة للسياسات أو محاولات هجوم.
 #12.2.6    المستوى: 2    الدور: D/V
 تحقق من تضمين قواعد مخصصة لاكتشاف أنماط التهديدات الخاصة بالذكاء الاصطناعي بما في ذلك محاولات الاختراق المنسقة، حملات حقن الأوامر، وهجمات استخراج النموذج.
 #12.2.7    المستوى: 3    الدور: D/V
 تحقق من أن سير العمل الآلي للاستجابة للحوادث يمكنه عزل النماذج المخترقة، وحظر المستخدمين الخبيثين، وتصعيد أحداث الأمان الحرجة.

---

### C12.3 الكشف عن انحراف النموذج

 #12.3.1    المستوى: 1    الدور: D/V
 تحقق من أن النظام يتتبع مقاييس الأداء الأساسية مثل الدقة، درجات الثقة، الكمون، ومعدلات الخطأ عبر إصدارات النماذج والفترات الزمنية.
 #12.3.2    المستوى: 2    الدور: D/V
 تحقق من أن التنبيه التلقائي يتم تفعيله عندما تتجاوز مقاييس الأداء حدود الانخفاض المحددة مسبقًا أو تنحرف بشكل كبير عن القيم الأساسية.
 #12.3.3    المستوى: 2    الدور: D/V
 تحقق من أن مراقبات كشف الهلوسة تقوم بتحديد والإشارة إلى الحالات التي تحتوي مخرجات النموذج فيها على معلومات غير صحيحة من الناحية الواقعية، أو متناقضة، أو ملفقة.

---

### C12.4 قياس أداء وسلوك النظام

 #12.4.1    المستوى: 1    الدور: D/V
 تحقق من أن مقاييس التشغيل بما في ذلك زمن استجابة الطلب، واستهلاك الرموز، واستخدام الذاكرة، ومعدل النقل يتم جمعها ومراقبتها باستمرار.
 #12.4.2    المستوى: 1    الدور: D/V
 تحقق من أن معدلات النجاح والفشل يتم تتبعها مع تصنيف أنواع الأخطاء وأسبابها الجذرية.
 #12.4.3    المستوى: 2    الدور: D/V
 تحقق من أن مراقبة استخدام الموارد تشمل استخدام وحدة معالجة الرسومات (GPU) ووحدة المعالجة المركزية (CPU)، واستهلاك الذاكرة، ومتطلبات التخزين مع التنبيه عند تجاوز الحدود المسموح بها.

---

### C12.5 تخطيط وتنفيذ الاستجابة للحوادث المتعلقة بالذكاء الاصطناعي

 #12.5.1    المستوى: 1    الدور: D/V
 تحقق من أن خطط الاستجابة للحوادث تتناول بشكل خاص أحداث الأمان المتعلقة بالذكاء الاصطناعي بما في ذلك اختراق النماذج، وتسمم البيانات، والهجمات العدائية.
 #12.5.2    المستوى: 2    الدور: D/V
 تحقق من أن فرق الاستجابة للحوادث لديها إمكانية الوصول إلى أدوات التحليل الجنائي الخاصة بالذكاء الاصطناعي والخبرات اللازمة للتحقيق في سلوك النموذج وطرق الهجوم.
 #12.5.3    المستوى: 3    الدور: D/V
 تأكد من تضمين تحليل ما بعد الحادث اعتبارات إعادة تدريب النموذج، وتحديث مرشحات الأمان، ودمج الدروس المستفادة في ضوابط الأمان.

---

### C12.5 كشف تدهور أداء الذكاء الاصطناعي

مراقبة واكتشاف تدهور أداء وجودة نموذج الذكاء الاصطناعي مع مرور الوقت.

 #12.5.1    المستوى: 1    الدور: D/V
 تحقق من أن دقة النموذج، والتحديد، والاستدعاء، وقيم F1 يتم مراقبتها باستمرار ويتم مقارنتها مع عتبات الأساس.
 #12.5.2    المستوى: 1    الدور: D/V
 تحقق من أن اكتشاف انحراف البيانات يراقب تغييرات توزيع البيانات المدخلة التي قد تؤثر على أداء النموذج.
 #12.5.3    المستوى: 2    الدور: D/V
 تحقق من أن اكتشاف انجراف المفهوم يحدد التغيرات في العلاقة بين المدخلات والمخرجات المتوقعة.
 #12.5.4    المستوى: 2    الدور: D/V
 تحقق من أن تدهور الأداء يؤدي إلى إطلاق تنبيهات تلقائية ويبدأ عمليات إعادة تدريب النموذج أو استبداله.
 #12.5.5    المستوى: 3    الدور: V
 تحقق من أن تحليل السبب الجذري للتدهور يربط بين انخفاض الأداء وتغيرات البيانات، أو مشكلات البنية التحتية، أو العوامل الخارجية.

---

### C12.6 تصور DAG وأمان سير العمل

حماية أنظمة تصور سير العمل من تسريبات المعلومات وهجمات التلاعب.

 #12.6.1    المستوى: 1    الدور: D/V
 تحقق من أن بيانات تصوُّر DAG قد تم تنقيتها لإزالة المعلومات الحساسة قبل التخزين أو الإرسال.
 #12.6.2    المستوى: 1    الدور: D/V
 تحقق من أن ضوابط وصول تصور سير العمل تضمن أن المستخدمين المخولين فقط هم من يمكنهم عرض مسارات قرارات الوكيل وتتبع الأسباب.
 #12.6.3    المستوى: 2    الدور: D/V
 تأكد من أن سلامة بيانات DAG محمية من خلال التواقيع التشفيرية وآليات التخزين المقاومة للتلاعب.
 #12.6.4    المستوى: 2    الدور: D/V
 تحقق من أن أنظمة تصور سير العمل تقوم بتنفيذ التحقق من صحة المدخلات لمنع هجمات الحقن من خلال بيانات العقد أو الحواف المعدلة.
 #12.6.5    المستوى: 3    الدور: D/V
 تحقق من أن تحديثات DAG في الوقت الحقيقي محدودة المعدل ومُتحقق منها لمنع هجمات الحرمان من الخدمة على أنظمة التصوير البياني.

---

### C12.7 مراقبة سلوك الأمان الاستباقي

الكشف والوقاية من التهديدات الأمنية من خلال تحليل سلوك الوكيل الاستباقي.

 #12.7.1    المستوى: 1    الدور: D/V
 تحقق من أن سلوكيات الوكلاء الاستباقيين قد تم التحقق من أمانها قبل التنفيذ مع دمج تقييم المخاطر.
 #12.7.2    المستوى: 2    الدور: D/V
 تحقق من أن مبادرات المبادرة المستقلة تتضمن تقييم سياق الأمان وتقييم مشهد التهديدات.
 #12.7.3    المستوى: 2    الدور: D/V
 تحقق من تحليل أنماط السلوك الاستباقي لتحديد التأثيرات الأمنية المحتملة والعواقب غير المقصودة.
 #12.7.4    المستوى: 3    الدور: D/V
 تحقق من أن الإجراءات الاستباقية الحساسة للأمان تتطلب سلاسل موافقة صريحة مع سجلات تدقيق.
 #12.7.5    المستوى: 3    الدور: D/V
 تحقق من أن نظام اكتشاف الشذوذ السلوكي يحدد الانحرافات في أنماط الوكلاء الاستباقيين التي قد تشير إلى اختراق.

---

### المراجع

NIST AI Risk Management Framework 1.0 - Manage 4.1 and 4.3
ISO/IEC 42001:2023 — AI Management Systems Requirements - Annex B 6.2.6
EU AI Act — Article 12, 13, 16 and 19 on Logging and Record-keeping

## المراجعة البشرية C13، المساءلة والحوكمة

### هدف التحكم

يوفر هذا الفصل متطلبات للحفاظ على الرقابة البشرية وسلاسل المساءلة الواضحة في أنظمة الذكاء الاصطناعي، مما يضمن سهولة التفسير والشفافية والإشراف الأخلاقي طوال دورة حياة الذكاء الاصطناعي.

---

### C13.1 آليات قتل التشغيل و آليات التجاوز

توفير مسارات للإيقاف أو التراجع عند ملاحظة سلوك غير آمن في نظام الذكاء الاصطناعي.

 #13.1.1    المستوى: 1    الدور: D/V
 تحقق من وجود آلية يدويّة لإيقاف تشغيل فوري توقف استنتاجات ونواتج نموذج الذكاء الاصطناعي.
 #13.1.2    المستوى: 1    الدور: D
 تحقق من أن ضوابط التجاوز متاحة فقط للأشخاص المصرح لهم.
 #13.1.3    المستوى: 3    الدور: D/V
 تحقق من أن إجراءات التراجع يمكنها العودة إلى إصدارات النماذج السابقة أو عمليات الوضع الآمن.
 #13.1.4    المستوى: 3    الدور: V
 تحقق من أن آليات التجاوز يتم اختبارها بانتظام.

---

### C13.2 نقاط التحقق من اتخاذ القرار بمشاركة الإنسان في الحلقة

يتطلب موافقات بشرية عندما تتجاوز المخاطر المعايير المحددة مسبقًا.

 #13.2.1    المستوى: 1    الدور: D/V
 تحقق من أن قرارات الذكاء الاصطناعي عالية المخاطر تتطلب موافقة بشرية صريحة قبل التنفيذ.
 #13.2.2    المستوى: 1    الدور: D
 تحقق من أن عتبات المخاطر محددة بوضوح وتؤدي تلقائيًا إلى تشغيل سير عمل المراجعة البشرية.
 #13.2.3    المستوى: 2    الدور: D
 تحقق من وجود إجراءات بديلة للقرارات الحساسة للزمن في حالة عدم الحصول على الموافقة البشرية ضمن الأطر الزمنية المطلوبة.
 #13.2.4    المستوى: 3    الدور: D/V
 تحقق من أن إجراءات التصعيد تحدد مستويات سلطة واضحة لأنواع القرارات المختلفة أو فئات المخاطر، إذا كان ذلك قابلاً للتطبيق.

---

### C13.3 سلسلة المسؤولية وقابلية التدقيق

سجل إجراءات المشغل وقرارات النموذج.

 #13.3.1    المستوى: 1    الدور: D/V
 تحقق من تسجيل جميع قرارات نظام الذكاء الاصطناعي والتدخلات البشرية مع الطوابع الزمنية، وهويات المستخدمين، وأسباب اتخاذ القرار.
 #13.3.2    المستوى: 2    الدور: D
 تحقق من أن سجلات التدقيق لا يمكن التلاعب بها وتتضمن آليات للتحقق من السلامة.

---

### C13.4 تقنيات الذكاء الاصطناعي القابل للتفسير

أهمية ميزات السطح، والنتائج المضادة للحقائق، والتفسيرات المحلية.

 #13.4.1    المستوى: 1    الدور: D/V
 تحقق من أن أنظمة الذكاء الاصطناعي تقدم تفسيرات أساسية لقراراتها بصيغة مفهومة للبشر.
 #13.4.2    المستوى: 2    الدور: V
 تحقق من أن جودة الشرح تم تقييمها من خلال دراسات التقييم البشري والمؤشرات.
 #13.4.3    المستوى: 3    الدور: D/V
 تحقق من توفر درجات أهمية الميزات أو طرق الإسناد (SHAP، LIME، وغيرها) للقرارات الحرجة.
 #13.4.4    المستوى: 3    الدور: V
 تحقق من أن التفسيرات المضادة للواقعية توضح كيفية تعديل المدخلات لتغيير النتائج، إذا كان ذلك قابلاً للتطبيق على حالة الاستخدام والنطاق.

---

### بطاقات النماذج C13.5 والإفصاحات المتعلقة بالاستخدام

الحفاظ على بطاقات النماذج للاستخدام المقصود، ومقاييس الأداء، والاعتبارات الأخلاقية.

 #13.5.1    المستوى: 1    الدور: D
 تحقق من أن بطاقات النماذج توثق حالات الاستخدام المقصودة، والقيود، وأنماط الفشل المعروفة.
 #13.5.2    المستوى: 1    الدور: D/V
 تحقق من الإفصاح عن مقاييس الأداء عبر حالات الاستخدام المختلفة القابلة للتطبيق.
 #13.5.3    المستوى: 2    الدور: D
 تأكد من توثيق الاعتبارات الأخلاقية وتقييمات التحيز وتقييمات العدالة وخصائص بيانات التدريب والقيود المعروفة لبيانات التدريب وتحديثها بانتظام.
 #13.5.4    المستوى: 2    الدور: D/V
 تحقق من أن بطاقات النماذج تخضع للتحكم في الإصدارات ويتم صيانتها طوال دورة حياة النموذج مع تتبع التغييرات.

---

### C13.6 قياس عدم اليقين

نقل درجات الثقة أو مقاييس الإنتروبيا في الاستجابات.

 #13.6.1    المستوى: 1    الدور: D
 تحقق من أن أنظمة الذكاء الاصطناعي تقدم درجات الثقة أو مقاييس عدم اليقين مع مخرجاتها.
 #13.6.2    المستوى: 2    الدور: D/V
 تحقق من أن عتبات عدم اليقين تؤدي إلى مراجعة بشرية إضافية أو مسارات قرار بديلة.
 #13.6.3    المستوى: 2    الدور: V
 تأكد من أن طرق قياس عدم اليقين مصححة ومعتمدة مقابل بيانات الحقيقة الأساسية.
 #13.6.4    المستوى: 3    الدور: D/V
 تحقق من أن انتشار عدم اليقين يتم الحفاظ عليه من خلال سير عمل الذكاء الاصطناعي متعدد الخطوات.

---

### C13.7 تقارير الشفافية الموجهة للمستخدمين

توفير الإفصاحات الدورية حول الحوادث والانحراف واستخدام البيانات.

 #13.7.1    المستوى: 1    الدور: D/V
 تحقق من أن سياسات استخدام البيانات وممارسات إدارة موافقة المستخدم يتم توصيلها بوضوح لأصحاب المصلحة.
 #13.7.2    المستوى: 2    الدور: D/V
 التحقق من إجراء تقييمات تأثير الذكاء الاصطناعي وتضمين النتائج في التقارير.
 #13.7.3    المستوى: 2    الدور: D/V
 تحقق من أن تقارير الشفافية التي تُنشر بانتظام تكشف عن حوادث الذكاء الاصطناعي والمقاييس التشغيلية بتفصيل معقول.

#### المراجع

EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
ISO/IEC 42001:2023 — AI Management Systems Requirements
NIST AI Risk Management Framework 1.0
NIST SP 800-53 Revision 5 — Security and Privacy Controls
A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)
Model Cards for Model Reporting (Mitchell et al., 2018)
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)
ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods
IEEE 7001-2021 — Transparency of Autonomous Systems
GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)
Human Oversight under Article 14 of the EU AI Act (Fink, 2025)

## الملحق أ: المعجم

هذا المسرد الشامل يقدم تعريفات للمصطلحات الرئيسية في الذكاء الاصطناعي وتعلم الآلة والأمان المستخدمة في جميع أنحاء AISVS لضمان الوضوح والفهم المشترك.

مثال عدائي: إدخال مصمم عمدًا للتسبب في خطأ نموذج الذكاء الاصطناعي، غالبًا عن طريق إضافة تغييرات طفيفة لا يلاحظها البشر.
​
الصلابة ضد الهجمات العدائية – تشير الصلابة ضد الهجمات العدائية في الذكاء الاصطناعي إلى قدرة النموذج على الحفاظ على أدائه ومقاومة الخداع أو التلاعب من خلال مدخلات خبيثة ومصممة عمدًا بهدف التسبب في أخطاء.
​
الوكيل – الوكلاء الذكيون هم أنظمة برمجية تستخدم الذكاء الاصطناعي لتحقيق الأهداف وإكمال المهام نيابة عن المستخدمين. يظهرون مهارات في الاستدلال والتخطيط والذاكرة، ولديهم مستوى من الاستقلالية لاتخاذ القرارات والتعلم والتكيف.
​
الذكاء الاصطناعي الوكِلي: أنظمة الذكاء الاصطناعي التي يمكنها العمل بدرجة معينة من الاستقلالية لتحقيق الأهداف، وغالبًا ما تتخذ قرارات وتتخذ إجراءات بدون تدخل بشري مباشر.
​
التحكم في الوصول المعتمد على السمات (ABAC): نموذج تحكم في الوصول حيث تُتخذ قرارات التفويض بناءً على سمات المستخدم، المورد، الإجراء، والبيئة، ويتم تقييمها في وقت الاستعلام.
​
هجوم الباب الخلفي: نوع من هجمات تسميم البيانات حيث يتم تدريب النموذج على الاستجابة بطريقة معينة لمحفزات محددة مع التصرف بشكل طبيعي في الحالات الأخرى.
​
التحيّز: أخطاء منهجية في مخرجات نموذج الذكاء الاصطناعي يمكن أن تؤدي إلى نتائج غير عادلة أو تمييزية تجاه مجموعات معينة أو في سياقات محددة.
​
استغلال التحيز: تقنية هجوم تستغل التحيزات المعروفة في نماذج الذكاء الاصطناعي للتلاعب في المخرجات أو النتائج.
​
سيدار: لغة السياسة ومحرك أمازون للأذونات الدقيقة المستخدمة في تنفيذ التحكم في الوصول المعتمد على السمات (ABAC) لأنظمة الذكاء الاصطناعي.
​
سلسلة التفكير: تقنية لتحسين عملية الاستدلال في نماذج اللغة من خلال توليد خطوات استدلال وسيطة قبل إنتاج الإجابة النهائية.
​
قواطع الدائرة: آليات توقف عمليات نظام الذكاء الاصطناعي تلقائيًا عند تجاوز حدود مخاطر معينة.
​
تسريب البيانات: الكشف غير المقصود عن معلومات حساسة من خلال مخرجات أو سلوك نموذج الذكاء الاصطناعي.
​
تسميم البيانات: الفساد المتعمد لبيانات التدريب للإضرار بسلامة النموذج، غالبًا لزرع أبواب خلفية أو تقليل الأداء.
​
الخصوصية التفاضلية – الخصوصية التفاضلية هي إطار رياضي دقيق لإصدار معلومات إحصائية حول مجموعات البيانات مع حماية خصوصية الأفراد المشاركين في البيانات. تتيح لحامل البيانات مشاركة الأنماط المجمعّة للمجموعة مع الحد من المعلومات التي يمكن تسريبها عن أفراد معينين.
​
التضمينات: تمثيلات متجهية كثيفة للبيانات (النصوص، الصور، إلخ) تلتقط المعنى الدلالي في فضاء عالي الأبعاد.
​
القابلية للتفسير – القابلية للتفسير في الذكاء الاصطناعي هي قدرة نظام الذكاء الاصطناعي على تقديم أسباب يمكن للبشر فهمها لقراراته وتنبؤاته، مما يوفر رؤى حول كيفية عمله الداخلي.
​
الذكاء الاصطناعي القابل للتفسير (XAI): أنظمة الذكاء الاصطناعي المصممة لتقديم تفسيرات يمكن للبشر فهمها لقراراتها وسلوكياتها من خلال تقنيات وأطر عمل مختلفة.
​
التعلم الموزع: هو نهج في تعلم الآلة يتم فيه تدريب النماذج عبر عدة أجهزة لا مركزية تحتفظ بعينات بيانات محلية، دون تبادل البيانات نفسها.
​
الضوابط: قيود تُنفذ لمنع أنظمة الذكاء الاصطناعي من إنتاج مخرجات ضارة أو منحازة أو غير مرغوب فيها بأي شكل من الأشكال.
​
الهلاوس – تشير هلاوس الذكاء الاصطناعي إلى ظاهرة يقوم فيها نموذج الذكاء الاصطناعي بتوليد معلومات خاطئة أو مضللة لا تستند إلى بيانات تدريبه أو الواقع الفعلي.
​
الإنسان في الحلقة (HITL): أنظمة مصممة لتتطلب إشرافًا بشريًا، أو تحققًا، أو تدخلًا في نقاط اتخاذ القرار الحرجة.
​
البنية التحتية ككود (IaC): إدارة وتوفير البنية التحتية من خلال الكود بدلاً من العمليات اليدوية، مما يتيح فحص الأمان والنشر المتسق.
​
الاختراق: تقنيات تُستخدم لتجاوز ضوابط الأمان في أنظمة الذكاء الاصطناعي، وخاصة في نماذج اللغة الكبيرة، لإنتاج محتوى محظور.
​
أقل الامتيازات: مبدأ الأمان الذي يمنح فقط حقوق الوصول اللازمة الأدنى للمستخدمين والعمليات.
​
LIME (تفسيرات محلية مستقلة عن النموذج): تقنية لشرح تنبؤات أي مصنف تعلم آلي عن طريق تقريبها محليًا بنموذج قابل للتفسير.
​
هجوم استنتاج العضوية: هو هجوم يهدف إلى تحديد ما إذا كانت نقطة بيانات محددة قد استخدمت في تدريب نموذج تعلم الآلة.
​
MITRE ATLAS: مشهد التهديدات العدائية لأنظمة الذكاء الاصطناعي؛ قاعدة معرفية للتكتيكات والتقنيات العدائية ضد أنظمة الذكاء الاصطناعي.
​
بطاقة النموذج – بطاقة النموذج هي وثيقة توفر معلومات موحدة حول أداء نموذج الذكاء الاصطناعي، وقيوده، والاستخدامات المقصودة، والاعتبارات الأخلاقية لتعزيز الشفافية وتطوير الذكاء الاصطناعي بمسؤولية.
​
استخراج النموذج: هجوم يقوم فيه الخصم باستجواب نموذج مستهدف بشكل متكرر لإنشاء نسخة مشابهة وظيفياً بدون تفويض.
​
عكس النموذج: هجوم يحاول إعادة بناء بيانات التدريب من خلال تحليل مخرجات النموذج.
​
إدارة دورة حياة النموذج – إدارة دورة حياة نموذج الذكاء الاصطناعي هي عملية الإشراف على جميع مراحل وجود نموذج الذكاء الاصطناعي، بما في ذلك تصميمه وتطويره ونشره ورصده وصيانته وتقاعده في النهاية، لضمان بقائه فعالًا ومتوافقًا مع الأهداف.
​
تسمم النموذج: إدخال ثغرات أمنية أو أبواب خلفية مباشرة في النموذج خلال عملية التدريب.
​
سرقة/سرقة النموذج: استخراج نسخة أو تقريبيّة لنموذج مملوك من خلال استعلامات متكررة.
​
نظام متعدد الوكلاء: نظام مكون من عدة وكلاء ذكاء اصطناعي متفاعلين، كل منهم قد يمتلك قدرات وأهداف مختلفة.
​
OPA (وكيل السياسات المفتوح): محرك سياسات مفتوح المصدر يتيح تطبيق السياسات بشكل موحد عبر كامل النظام.
​
التعلم الآلي مع الحفاظ على الخصوصية (PPML): تقنيات وأساليب لتدريب ونشر نماذج التعلم الآلي مع حماية خصوصية بيانات التدريب.
​
حقن المطالبات: هجوم يتم فيه تضمين تعليمات خبيثة في المدخلات لتجاوز السلوك المقصود للنموذج.
​
RAG (التوليد المدعوم بالاستخراج): تقنية تُحسّن نماذج اللغة الكبيرة عبر استرجاع المعلومات ذات الصلة من مصادر المعرفة الخارجية قبل توليد الرد.
​
الهجوم الأحمر: وهو ممارسة اختبار أنظمة الذكاء الاصطناعي بنشاط من خلال محاكاة هجمات معادية لاكتشاف الثغرات.
​
قائمة مكونات البرمجيات (SBOM): سجل رسمي يحتوي على تفاصيل وعلاقات سلسلة التوريد لمكونات مختلفة تُستخدم في بناء البرمجيات أو نماذج الذكاء الاصطناعي.
​
SHAP (تفسيرات شابلي الإضافية): نهج نظرية الألعاب لشرح مخرجات أي نموذج تعلّم آلي عن طريق حساب مساهمة كل ميزة في التنبؤ.
​
هجوم سلسلة التوريد: اختراق نظام عن طريق استهداف العناصر الأقل أمانًا في سلسلة التوريد الخاصة به، مثل المكتبات التابعة لأطراف ثالثة، مجموعات البيانات، أو النماذج المدربة مسبقًا.
​
التعلم النقال: تقنية يتم فيها إعادة استخدام نموذج تم تطويره لمهمة معينة كنقطة انطلاق لنموذج في مهمة ثانية.
​
قاعدة بيانات المتجهات: قاعدة بيانات متخصصة مصممة لتخزين المتجهات عالية الأبعاد (التضمينات) وتنفيذ عمليات بحث تشابه فعالة.
​
فحص الثغرات الأمنية: أدوات آلية تقوم بتحديد الثغرات الأمنية المعروفة في مكونات البرمجيات، بما في ذلك أطر عمل الذكاء الاصطناعي والتبعيات.
​
العلامات المائية: تقنيات تضمين علامات غير ملحوظة في المحتوى المولد بواسطة الذكاء الاصطناعي لتعقب أصله أو للكشف عن توليده بواسطة الذكاء الاصطناعي.
​
ثغرة اليوم الصفري: ثغرة غير معروفة سابقًا يمكن للمهاجمين استغلالها قبل أن يقوم المطورون بإنشاء ونشر تصحيح.

## الملحق ب: المراجع

### TODO

## الملحق ج: حوكمة أمان الذكاء الاصطناعي والتوثيق

### الهدف

يوفر هذا الملحق المتطلبات الأساسية لإنشاء هياكل تنظيمية وسياسات وعمليات لحوكمة أمن الذكاء الاصطناعي طوال دورة حياة النظام.

---

### اعتماد إطار عمل إدارة مخاطر الذكاء الاصطناعي AC.1

توفير إطار عمل رسمي لتحديد وتقييم وتخفيف المخاطر الخاصة بالذكاء الاصطناعي خلال دورة حياة النظام.

 #AC.1.1    المستوى: 1    الدور: D/V
 تحقق من توثيق وتنفيذ منهجية تقييم المخاطر المخصصة للذكاء الاصطناعي.
 #AC.1.2    المستوى: 2    الدور: D
 تأكد من إجراء تقييمات المخاطر في النقاط الرئيسية من دورة حياة الذكاء الاصطناعي وقبل التغييرات المهمة.
 #AC.1.3    المستوى: 3    الدور: D/V
 تحقق من أن إطار عمل إدارة المخاطر يتماشى مع المعايير المعمول بها (مثل إطار عمل إدارة مخاطر الذكاء الاصطناعي من NIST).

---

### AC.2 سياسة وإجراءات أمان الذكاء الاصطناعي

تحديد وفرض المعايير التنظيمية لتطوير الذكاء الاصطناعي وتأمينه ونشره وتشغيله بشكل آمن.

 #AC.2.1    المستوى: 1    الدور: D/V
 تحقق من وجود سياسات أمان للذكاء الاصطناعي موثقة.
 #AC.2.2    المستوى: 2    الدور: D
 تحقق من مراجعة السياسات وتحديثها على الأقل مرة واحدة سنويًا وبعد حدوث تغييرات كبيرة في مشهد التهديدات.
 #AC.2.3    المستوى: 3    الدور: D/V
 تحقق من أن السياسات تغطي جميع فئات AISVS والمتطلبات التنظيمية المعمول بها.

---

### الأدوار والمسؤوليات في أمان الذكاء الاصطناعي AC.3

قم بتحديد مسؤولية واضحة لأمان الذكاء الاصطناعي عبر المؤسسة.

 #AC.3.1    المستوى: 1    الدور: D/V
 تحقق من توثيق أدوار ومسؤوليات أمان الذكاء الاصطناعي.
 #AC.3.2    المستوى: 2    الدور: D
 تحقق من أن الأفراد المسؤولين يمتلكون الخبرة الأمنية المناسبة.
 #AC.3.3    المستوى: 3    الدور: D/V
 تحقق من إنشاء لجنة أخلاقيات الذكاء الاصطناعي أو مجلس حوكمة للأنظمة الذكية عالية المخاطر.

---

### AC.4 تنفيذ إرشادات الذكاء الاصطناعي الأخلاقي

ضمان عمل أنظمة الذكاء الاصطناعي وفقًا للمبادئ الأخلاقية المعتمدة.

 #AC.4.1    المستوى: 1    الدور: D/V
 تحقق من وجود إرشادات أخلاقية لتطوير ونشر الذكاء الاصطناعي.
 #AC.4.2    المستوى: 2    الدور: D
 تحقق من وجود آليات لرصد الإخلالات الأخلاقية والإبلاغ عنها.
 #AC.4.3    المستوى: 3    الدور: D/V
 تحقق من إجراء مراجعات أخلاقية منتظمة لأنظمة الذكاء الاصطناعي المنشورة.

---

### AC.5 مراقبة الامتثال التنظيمي للذكاء الاصطناعي

الحفاظ على الوعي والامتثال للوائح الذكاء الاصطناعي المتطورة.

 #AC.5.1    المستوى: 1    الدور: D/V
 تحقق من وجود عمليات لتحديد اللوائح التنظيمية للذكاء الاصطناعي المعمول بها.
 #AC.5.2    المستوى: 2    الدور: D
 تحقق من تقييم الامتثال لجميع المتطلبات التنظيمية.
 #AC.5.3    المستوى: 3    الدور: D/V
 تحقق من أن التغييرات التنظيمية تؤدي إلى مراجعات وتحديثات في الوقت المناسب لأنظمة الذكاء الاصطناعي.

### AC.6 حوكمة بيانات التدريب، التوثيق والعملية

 #1.1.2    المستوى: 1    الدور: D/V
 تحقق من أن تكون مجموعات البيانات المصرح بها فقط من حيث الجودة، والتمثيلية، والمصادر الأخلاقية، والامتثال للترخيص مسموح بها، مما يقلل من مخاطر التسمم، والتحيز المتضمن، وانتهاك حقوق الملكية الفكرية.
 #1.1.5    المستوى: 2    الدور: D/V
 تحقق من أن جودة التسمية/التعليقات التوضيحية مضمونة من خلال التحقق المتبادل للمراجعين أو التوافق الجماعي.
 #1.1.6    المستوى: 2    الدور: D/V
 تحقق من أن "بطاقات البيانات" أو "صحائف البيانات لمجموعات البيانات" يتم الحفاظ عليها لمجموعات التدريب الهامة، موضحة الخصائص، الدوافع، التركيب، عمليات التجميع، المعالجة المسبقة، والاستخدامات الموصى بها أو الممنوعة.
 #1.3.2    المستوى: 2    الدور: D/V
 التحقق من أن التحيزات المعروفة قد تم التخفيف منها عبر استراتيجيات موثقة مثل إعادة التوازن، زيادة البيانات المستهدفة، التعديلات الخوارزمية (مثل تقنيات ما قبل المعالجة، المعالجة أثناء التنفيذ، وما بعد المعالجة)، أو إعادة الوزن، وأن يتم تقييم تأثير التخفيف على كل من العدالة وأداء النموذج بشكل عام.
 #1.3.3    المستوى: 2    الدور: D/V
 تحقق من تقييم وتوثيق مقاييس العدالة بعد التدريب.
 #1.3.4    المستوى: 3    الدور: D/V
 تحقق من أن سياسة إدارة تحيز دورة الحياة تخصّص مالكين وجدول مراجعة.
 #1.4.1    المستوى: 2    الدور: D/V
 تأكد من ضمان جودة التصنيف/الوسم من خلال إرشادات واضحة، ومراجعات متبادلة من قبل المراجعين، وآليات التوافق (مثل مراقبة اتفاقية بين المصنّفين)، وعمليات محددة لحل التباينات.
 #1.4.4    المستوى: 3    الدور: D/V
 تحقق من أن العلامات الحرجة للسلامة أو الأمان أو العدالة (مثل تحديد المحتوى السام، النتائج الطبية الحرجة) تخضع لمراجعة مستقلة مزدوجة إلزامية أو تحقق متين مكافئ.
 #1.4.6    المستوى: 2    الدور: D/V
 تحقق من أن أدلة التعليمات والإرشادات الخاصة بالتوسيم شاملة، ومتحكم في إصداراتها، وتمت مراجعتها من قبل الأقران.
 #1.4.6    المستوى: 2    الدور: D/V
 تأكد من أن مخططات البيانات للتسميات معرفة بوضوح وتخضع للتحكم في الإصدارات.
 #1.3.1    المستوى: 1    الدور: D/V
 تحقق من أن مجموعات البيانات تمت معالجتها لتحديد عدم التوازن التمثيلي والتحيزات المحتملة عبر السمات المحمية قانونياً (مثل العرق، الجنس، العمر) والخصائص الحساسة أخلاقياً الأخرى ذات الصلة بمجال تطبيق النموذج (مثل الحالة الاجتماعية والاقتصادية، الموقع).
 #1.5.3    المستوى: 2    الدور: V
 تحقق من أن الفحوصات اليدوية العشوائية التي يجريها خبراء المجال تغطي عينة ذات دلالة إحصائية (على سبيل المثال، ≥1% أو 1,000 عينة، أيهما أكبر، أو كما تحدده تقييمات المخاطر) لتحديد مشكلات الجودة الدقيقة التي لا تلتقطها الأتمتة.
 #1.8.4    المستوى: 2    الدور: D/V
 تحقق من أن عمليات وضع العلامات الخارجية أو المعتمدة على الجمهور تتضمن الضمانات الفنية/الإجرائية لضمان سرية البيانات، سلامتها، جودة العلامات، ومنع تسرب البيانات.
 #1.5.4    المستوى: 2    الدور: D/V
 تحقق من إضافة خطوات العلاج إلى سجلات المصدر.
 #1.6.2    المستوى: 2    الدور: D/V
 تحقق من أن العينات المعلمة تؤدي إلى مراجعة يدوية قبل التدريب.
 #1.6.3    المستوى: 2    الدور: V
 تحقق من أن النتائج تغذي ملف أمان النموذج وتبلغ استخبارات التهديد المستمرة.
 #1.6.4    المستوى: 3    الدور: D/V
 تحقق من تحديث منطق الكشف بمعلومات التهديدات الجديدة.
 #1.6.5    المستوى: 3    الدور: D/V
 تحقق من أن خطوط أنابيب التعلم عبر الإنترنت تراقب انحراف التوزيع.
 #1.7.1    المستوى: 1    الدور: D/V
 تحقق من أن عمليات حذف بيانات التدريب تقوم بمسح البيانات الأساسية والمشتقة وتقييم تأثيرها على النموذج، وأنه يتم تقييم التأثير على النماذج المتأثرة وإذا لزم الأمر، معالجته (مثل إعادة التدريب أو إعادة المعايرة).
 #1.7.2    المستوى: 2    الدور: D
 تأكد من وجود آليات لتتبع واحترام نطاق وحالة موافقة المستخدم (والانسحابات) على البيانات المستخدمة في التدريب، وأن يتم التحقق من الموافقة قبل دمج البيانات في عمليات التدريب الجديدة أو التحديثات الكبيرة للنموذج.
 #1.7.3    المستوى: 2    الدور: V
 تحقق من اختبار سير العمل سنويًا وتسجيله.
 #1.8.1    المستوى: 2    الدور: D/V
 تحقق من أن موردي البيانات الخارجية، بما في ذلك مقدمي النماذج المدربة مسبقًا والمجموعات البيانات الخارجية، يخضعون لفحوصات العناية الواجبة المتعلقة بالأمن والخصوصية والمصادر الأخلاقية وجودة البيانات قبل دمج بياناتهم أو نماذجهم.
 #1.8.2    المستوى: 1    الدور: D
 تحقق من أن عمليات النقل الخارجية تستخدم TLS/المصادقة وفحوصات السلامة.
 #1.8.3    المستوى: 2    الدور: D/V
 تحقق من أن مصادر البيانات عالية المخاطر (مثل مجموعات البيانات المفتوحة المصدر ذات الأصل غير المعروف، والموردين غير المعتمدين) تخضع لفحص معزز، مثل التحليل في بيئة معزولة، وفحوصات جودة/تحيز شاملة، واكتشاف استهداف التسمم، قبل استخدامها في التطبيقات الحساسة.
 #1.8.4    المستوى: 3    الدور: D/V
 تحقق من أن النماذج المدربة مسبقًا التي تم الحصول عليها من أطراف ثالثة يتم تقييمها للكشف عن التحيزات المضمنة، والثغرات الخلفية المحتملة، وسلامة هيكلها، وأصل بيانات التدريب الأصلية الخاصة بها قبل عملية التخصيص أو النشر.
 #1.5.3    المستوى: 2    الدور: D/V
 تحقق من أنه إذا تم استخدام التدريب العدائي، فإن إنشاء مجموعات البيانات العدائية وإدارتها وإصدار نسخ منها يتم توثيقهما والتحكم فيهما.
 #1.5.3    المستوى: 3    الدور: D/V
 تحقق من تقييم وتأثير تدريب المتانة ضد الهجمات العدائية على أداء النموذج (مقابل كل من المدخلات النظيفة والمدخلات العدائية) ومقاييس العدالة، وأن يتم توثيقه ومراقبته.
 #1.5.4    المستوى: 3    الدور: D/V
 تحقق من أن استراتيجيات التدريب العدائي والصلابة يتم مراجعتها وتحديثها بشكل دوري لمواجهة تقنيات الهجمات العدائية المتطورة.
 #1.4.2    المستوى: 2    الدور: D/V
 تحقق من عزل مجموعات البيانات الفاشلة مع سجلات التدقيق.
 #1.4.3    المستوى: 2    الدور: D/V
 تحقق من أن بوابات الجودة تمنع مجموعات البيانات دون المستوى ما لم تتم الموافقة على استثناءات.
 #1.11.2    المستوى: 2    الدور: D/V
 تحقق من توثيق عملية التوليد والمعلمات والاستخدام المقصود للبيانات الاصطناعية.
 #1.11.3    المستوى: 2    الدور: D/V
 تأكد من تقييم المخاطر المتعلقة بالبيانات الاصطناعية من حيث التحيز، وتسرب الخصوصية، ومشاكل التمثيل قبل استخدامها في التدريب.
 #1.12.3    المستوى: 2    الدور: D/V
 تحقق من توليد التنبيهات للأحداث المشبوهة للوصول والتحقيق فيها على الفور.
 #1.13.1    المستوى: 1    الدور: D/V
 تحقق من تحديد فترات الاحتفاظ الصريحة لجميع مجموعات بيانات التدريب.
 #1.13.2    المستوى: 2    الدور: D/V
 تحقق من أن مجموعات البيانات تنتهي صلاحيتها تلقائيًا أو تُحذف أو تُراجع للحذف في نهاية دورة حياتها.
 #1.13.3    المستوى: 2    الدور: D/V
 تحقق من أن إجراءات الاحتفاظ والحذف مسجلة وقابلة للتدقيق.
 #1.14.1    المستوى: 2    الدور: D/V
 تحقق من تحديد متطلبات إقامة البيانات ونقلها عبر الحدود وفرضها على جميع مجموعات البيانات.
 #1.14.2    المستوى: 2    الدور: D/V
 تحقق من تحديد ومعالجة اللوائح الخاصة بكل قطاع (مثل الرعاية الصحية، المالية) في التعامل مع البيانات.
 #1.14.3    المستوى: 2    الدور: D/V
 تحقق من توثيق الامتثال للقوانين المتعلقة بالخصوصية ذات الصلة (مثل GDPR، CCPA) ومراجعته بانتظام.
 #1.16.1    المستوى: 2    الدور: D/V
 تحقق من وجود آليات للاستجابة لطلبات موضوع البيانات للوصول أو التصحيح أو التقييد أو الاعتراض.
 #1.16.2    المستوى: 2    الدور: D/V
 تحقق من تسجيل وتتبع وتنفيذ الطلبات ضمن الأطر الزمنية المحددة قانونيًا.
 #1.16.3    المستوى: 2    الدور: D/V
 تحقق من اختبار ومراجعة عمليات حقوق موضوع البيانات بانتظام لضمان الفعالية.
 #1.17.1    المستوى: 2    الدور: D/V
 تحقق من إجراء تحليل الأثر قبل تحديث أو استبدال إصدار مجموعة البيانات، مع تغطية أداء النموذج، والعدالة، والالتزام بالمعايير.
 #1.17.2    المستوى: 2    الدور: D/V
 تحقق من توثيق نتائج تحليل التأثير ومراجعتها من قبل أصحاب المصلحة المعنيين.
 #1.17.3    المستوى: 2    الدور: D/V
 تحقق من وجود خطط تراجع في حال أدخلت الإصدارات الجديدة مخاطر غير مقبولة أو تراجعات.
 #1.18.1    المستوى: 2    الدور: D/V
 تحقق من أن جميع العاملين المشاركين في وسم البيانات قد خضعوا لفحص الخلفية وتلقوا تدريبًا في أمن البيانات والخصوصية.
 #1.18.2    المستوى: 2    الدور: D/V
 تأكد من توقيع جميع کارکن التعليقات على اتفاقيات السرية وعدم الإفشاء.
 #1.18.3    المستوى: 2    الدور: D/V
 تحقق من أن منصات التعليقات التوضيحية تفرض ضوابط الوصول وتراقب التهديدات الداخلية.

#### المراجع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
EU Artificial Intelligence Act — Regulation (EU) 2024/1689
ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods

## الملحق د: حكم والتحقق من البرمجة الآمنة بمساعدة الذكاء الاصطناعي

### الهدف

يحدد هذا الفصل الضوابط التنظيمية الأساسية للاستخدام الآمن والفعال لأدوات الترميز بمساعدة الذكاء الاصطناعي خلال تطوير البرمجيات، مع ضمان الأمان وقابلية التتبع عبر دورة حياة تطوير البرمجيات (SDLC).

---

### AD.1 سير عمل التكويد الآمن بمساعدة الذكاء الاصطناعي

دمج أدوات الذكاء الاصطناعي في دورة حياة تطوير البرمجيات الآمنة (SSDLC) للمنظمة دون الإضرار بحواجز الأمان الموجودة.

 #AD.1.1    المستوى: 1    الدور: D/V
 تحقق من أن سير العمل الموثق يصف متى وكيف يمكن لأدوات الذكاء الاصطناعي إنشاء أو إعادة هيكلة أو مراجعة الشيفرة البرمجية.
 #AD.1.2    المستوى: 2    الدور: D
 تحقق من أن سير العمل يتوافق مع كل مرحلة من مراحل دورة حياة تطوير البرامج الآمنة (SSDLC) (التصميم، التنفيذ، مراجعة الكود، الاختبار، النشر).
 #AD.1.3    المستوى: 3    الدور: D/V
 تحقق من أن المقاييس (مثل كثافة الثغرات، ومتوسط الوقت للكشف) يتم جمعها على الشيفرة المنتجة بواسطة الذكاء الاصطناعي ويتم مقارنتها مع المعايير الأساسية الخاصة بالبشر فقط.

---

### تأهيل أدوات الذكاء الاصطناعي ونمذجة التهديدات AD.2

تأكد من تقييم أدوات الترميز المعتمدة على الذكاء الاصطناعي من حيث قدرات الأمان، والمخاطر، وتأثير سلسلة التوريد قبل الاعتماد عليها.

 #AD.2.1    المستوى: 1    الدور: D/V
 تحقق من أن نموذج التهديد لكل أداة ذكاء اصطناعي يحدد سوء الاستخدام، قلب النموذج، تسرب البيانات، ومخاطر سلسلة الاعتماد.
 #AD.2.2    المستوى: 2    الدور: D
 تحقق من أن تقييمات الأدوات تشمل التحليل الساكن/الديناميكي لأي مكونات محلية وتقييم نقاط نهاية SaaS (TLS، المصادقة/التفويض، التسجيل).
 #AD.2.3    المستوى: 3    الدور: D/V
 تحقق من أن التقييمات تتبع إطار عمل معترف به ويتم إعادة تنفيذها بعد تغييرات النسخة الرئيسية.

---

### إدارة آمنة للتعليمات والسياق AD.3

منع تسرب الأسرار، والكود المملوك، والبيانات الشخصية عند بناء المطالبات أو السياقات لنماذج الذكاء الاصطناعي.

 #AD.3.1    المستوى: 1    الدور: D/V
 تحقق من أن التوجيهات المكتوبة تحظر إرسال الأسرار أو بيانات الاعتماد أو البيانات المصنفة في المطالبات.
 #AD.3.2    المستوى: 2    الدور: D
 تحقق من أن الضوابط التقنية (حذف البيانات على جانب العميل، وفلاتر السياق المعتمدة) تقوم تلقائيًا بإزالة العناصر الحساسة.
 #AD.3.3    المستوى: 3    الدور: D/V
 تحقق من أن المطالبات والاستجابات مقسمة إلى رموز، ومشفرة أثناء النقل وفي حالة التخزين، وأن فترات الاحتفاظ تتوافق مع سياسة تصنيف البيانات.

---

### AD.4 التحقق من صحة الشفرة التي تم إنشاؤها بواسطة الذكاء الاصطناعي

اكتشف وقم بإصلاح الثغرات الأمنية التي تم إدخالها بواسطة مخرجات الذكاء الاصطناعي قبل دمج الشيفرة أو نشرها.

 #AD.4.1    المستوى: 1    الدور: D/V
 تحقق من أن الكود الذي يتم إنشاؤه بواسطة الذكاء الاصطناعي يخضع دائمًا لمراجعة بشرية للكود.
 #AD.4.2    المستوى: 2    الدور: D
 تحقق من تشغيل أجهزة الفحص الآلية (SAST/IAST/DAST) على كل طلب سحب يحتوي على رمز مولد بواسطة الذكاء الاصطناعي ومنع الدمج في حال وجود نتائج حرجة.
 #AD.4.3    المستوى: 3    الدور: D/V
 تحقق من أن اختبار التعرية التفريقي أو اختبارات الخصائص تثبت السلوكيات الحرجة للأمان (مثل التحقق من صحة المدخلات، منطق التفويض).

---

### AD.5 قابلية التفسير وقابلية تتبع اقتراحات الشفرة

زوّد المدققين والمطورين بفهم حول سبب تقديم اقتراح معين وكيف تطور مع الوقت.

 #AD.5.1    المستوى: 1    الدور: D/V
 تحقق من تسجيل أزواج الطلب/الاستجابة مع معرفات الالتزام.
 #AD.5.2    المستوى: 2    الدور: D
 تحقق من أن المطورين يمكنهم عرض استشهادات النموذج (مقتطفات التدريب، الوثائق) التي تدعم الاقتراح.
 #AD.5.3    المستوى: 3    الدور: D/V
 تحقق من أن تقارير قابلية الشرح مخزنة مع مصنوعات التصميم ومُشار إليها في مراجعات الأمان، مما يفي بمبادئ التتبع في ISO/IEC 42001.

---

### AD.6 التغذية الراجعة المستمرة وضبط نموذجي دقيق

تحسين أداء أمان النموذج مع مرور الوقت مع منع الانحراف السلبي.

 #AD.6.1    المستوى: 1    الدور: D/V
 تحقق من أن المطورين يمكنهم الإبلاغ عن الاقتراحات غير الآمنة أو غير المتوافقة، وأن يتم تتبع هذه الإشعارات.
 #AD.6.2    المستوى: 2    الدور: D
 تحقق من أن الملاحظات المجمعة تُستخدم في التعديل الدقيق الدوري أو التوليد المعزز بالاسترجاع باستخدام مجموعات بيانات التكويد الآمن المراجعة (مثل أوراق الغش OWASP).
 #AD.6.3    المستوى: 3    الدور: D/V
 تحقق من أن نظام تقييم الحلقة المغلقة يشغّل اختبارات الانحدار بعد كل ضبط دقيق؛ يجب أن تلبي مقاييس الأمان أو تتجاوز الخطوط الأساسية السابقة قبل النشر.

---

#### المراجع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
OWASP Secure Coding Practices — Quick Reference Guide

## الملحق هـ: أمثلة على الأدوات والأُطُر

### الهدف

يوفر هذا الفصل أمثلة على الأدوات والأطر التي يمكنها دعم تنفيذ أو تحقيق متطلبات AISVS معينة. لا ينبغي اعتبار هذه الأمثلة توصيات أو تأييدات من فريق AISVS أو مشروع أمان OWASP GenAI.

---

### AE.1 حوكمة بيانات التدريب وإدارة التحيز

الأدوات المستخدمة لتحليل البيانات، الحوكمة، وإدارة التحيز.

 #AE.1.1    قسم: 1.1
 أدوات جرد البيانات: أدوات إدارة جرد البيانات مثل...
 #AE.1.2    قسم: 1.2
 التشفير أثناء النقل استخدم TLS لتطبيقات HTTPS، باستخدام أدوات مثل openSSL وpython's`ssl`المكتبة.

---

### AE.2 التحقق من صحة إدخال المستخدم

الأدوات لمعالجة والتحقق من صحة مدخلات المستخدم.

 #AE.2.1    قسم: 2.1
 أدوات الدفاع ضد حقن المطالبات: استخدم أدوات الحماية مثل NeMo من NVIDIA أو Guardrails AI.

---

