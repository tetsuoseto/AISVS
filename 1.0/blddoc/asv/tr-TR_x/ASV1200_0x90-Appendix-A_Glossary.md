# Ek A: Terimler Sözlüğü

>Bu kapsamlı sözlük, AISVS genelinde kullanılan temel AI, ML ve güvenlik terimlerinin tanımlarını sunarak açıklık ve ortak anlayış sağlamaktadır.

* Rakip Örnek: İnsanların fark edemeyeceği ince bozulmalar ekleyerek bir yapay zeka modelinin hata yapmasına neden olmak için kasıtlı olarak hazırlanmış bir giriş.
  ​
* Rekabetçi Dayanıklılık – Yapay zekada rekabetçi dayanıklılık, bir modelin performansını koruma ve hataya sebep olmak için kasıtlı olarak tasarlanmış kötü niyetli girdiler tarafından kandırılmaya veya manipüle edilmeye karşı direnç gösterme yeteneğini ifade eder.
  ​
* Agent – Yapay zeka ajanları, kullanıcılar adına hedeflere ulaşmak ve görevleri tamamlamak için yapay zekayı kullanan yazılım sistemleridir. Akıl yürütme, planlama ve hafıza gösterirler ve karar verme, öğrenme ve uyum sağlama konusunda belirli bir özerkliğe sahiptirler.
  ​
* Agentik AI: Belirli bir dereceye kadar özerklikle hedeflere ulaşabilen, genellikle doğrudan insan müdahalesi olmadan kararlar alan ve eylemler gerçekleştiren AI sistemleri.
  ​
* Öznitelik Tabanlı Erişim Kontrolü (ABAC): Yetkilendirme kararlarının, sorgu zamanında değerlendirilen kullanıcının, kaynağın, eylemin ve çevrenin özniteliklerine dayandığı bir erişim kontrol paradigması.
  ​
* Arka Kapı Saldırısı: Modelin belirli tetikleyicilere karşı özel bir şekilde yanıt vermesi için eğitildiği, aksi takdirde normal davrandığı bir tür veri zehirleme saldırısıdır.
  ​
* Önyargı: Belirli gruplar veya belirli bağlamlarda adaletsiz veya ayrımcı sonuçlara yol açabilen yapay zeka modeli çıktılarındaki sistematik hatalar.
  ​
* Önyargı Sömürüsü: Çıktıları veya sonuçları manipüle etmek için yapay zeka modellerindeki bilinen önyargılardan yararlanan bir saldırı tekniği.
  ​
* Cedar: AI sistemleri için ABAC uygulanmasında kullanılan ayrıntılı izinler için Amazon’un politika dili ve motoru.
  ​
* Düşünce Zinciri: Son cevabı üretmeden önce ara akıl yürütme adımları oluşturarak dil modellerindeki akıl yürütmeyi geliştirme tekniği.
  ​
* Devre Kesiciler: Belirli risk eşiklerinin aşılması durumunda yapay zeka sistemi işlemlerini otomatik olarak durduran mekanizmalar.
  ​
* Veri Sızıntısı: AI modeli çıktıları veya davranışı aracılığıyla hassas bilgilerin istem dışı ifşası.
  ​
* Veri Zehirlenmesi: Model bütünlüğünü tehlikeye atmak amacıyla eğitim verilerinin kasıtlı olarak bozulması, genellikle arka kapılar kurmak veya performansı düşürmek için.
  ​
* Diferansiyel Mahremiyet – Diferansiyel mahremiyet, bireysel veri sahiplerinin gizliliğini korurken veri setleri hakkında istatistiksel bilgilerin yayınlanması için matematiksel olarak sağlam bir çerçevedir. Bu, veri sahibinin grup genelindeki toplu desenleri paylaşmasına olanak tanırken, belirli bireyler hakkında sızan bilgileri sınırlar.
  ​
* Gömülü Temsiller: Verinin (metin, resimler vb.) yüksek boyutlu bir uzayda anlamsal anlamını yakalayan yoğun vektör temsilleri.
  ​
* Açıklanabilirlik – Yapay zekada açıklanabilirlik, bir yapay zeka sisteminin kararları ve tahminleri için insan tarafından anlaşılabilir nedenler sunma yeteneğidir; bu da sistemin iç işleyişine dair içgörüler sağlamaktadır.
  ​
* Açıklanabilir Yapay Zeka (XAI): Kararları ve davranışları için insan tarafından anlaşılabilir açıklamalar sunmak üzere çeşitli teknikler ve çerçeveler kullanarak tasarlanmış yapay zeka sistemleri.
  ​
* Federated Learning: Verilerin kendisi değiş tokuş edilmeden, yerel veri örneklerine sahip çok sayıda merkezi olmayan cihaz üzerinde modellerin eğitildiği bir makine öğrenimi yaklaşımı.
  ​
* Koruyucu Önlemler: Yapay zeka sistemlerinin zararlı, yanlı veya diğer istenmeyen çıktılar üretmesini önlemek için uygulanan kısıtlamalar.
  ​
* Halüsinasyon – Bir yapay zeka halüsinasyonu, bir yapay zeka modelinin eğitim verilerine veya gerçek olgulara dayanmayan, yanlış veya yanıltıcı bilgi üretmesi durumunu ifade eder.
  ​
* İnsanlı Döngü (HITL): Önemli karar noktalarında insan denetimi, doğrulaması veya müdahalesi gerektirecek şekilde tasarlanmış sistemler.
  ​
* Kod olarak Altyapı (IaC): Altyapıyı manuel süreçler yerine kod aracılığıyla yönetme ve sağlama, bu sayede güvenlik taraması ve tutarlı dağıtımların mümkün kılınması.
  ​
* Jailbreak: Özellikle büyük dil modellerinde, yasaklanmış içerik üretmek için yapay zeka sistemlerindeki güvenlik önlemlerini aşmak amacıyla kullanılan teknikler.
  ​
* En Az Ayrıcalık: Kullanıcılar ve süreçler için yalnızca gerekli minimum erişim haklarının verilmesi güvenlik prensibi.
  ​
* LIME (Yerel Yorumlanabilir Model-Agnostik Açıklamalar): Herhangi bir makine öğrenimi sınıflandırıcısının tahminlerini, yerel olarak yorumlanabilir bir modelle yaklaşık olarak açıklamak için bir teknik.
  ​
* Üyelik Çıkarımı Saldırısı: Belirli bir veri noktasının bir makine öğrenimi modelini eğitmek için kullanılıp kullanılmadığını belirlemeyi amaçlayan bir saldırı.
  ​
* MITRE ATLAS: Yapay Zeka Sistemleri için Düşmanca Tehdit Manzarası; yapay zeka sistemlerine karşı düşmanca taktikler ve tekniklerin bilgi tabanı.
  ​
* Model Kartı – Model kartı, bir yapay zeka modelinin performansı, sınırlamaları, amaçlanan kullanımları ve etik değerlendirmeleri hakkında standartlaştırılmış bilgiler sağlayan, şeffaflığı ve sorumlu yapay zeka geliştirmeyi teşvik eden bir belgedir.
  ​
* Model Çıkarımı: Bir saldırı türü olup, saldırganın hedef modeli yetkisiz olarak işlevsel olarak benzer bir kopya oluşturmak için tekrar tekrar sorgulamasıdır.
  ​
* Model İnversiyonu: Model çıktıları analiz edilerek eğitim verilerini yeniden oluşturmayı amaçlayan bir saldırı.
  ​
* Model Yaşam Döngüsü Yönetimi – AI Model Yaşam Döngüsü Yönetimi, bir yapay zeka modelinin tasarımı, geliştirilmesi, dağıtımı, izlenmesi, bakımı ve nihai emekliliği dahil olmak üzere tüm varlık aşamalarının denetlenmesi sürecidir; böylece modelin etkili kalması ve hedeflerle uyumlu olması sağlanır.
  ​
* Model Zehirleme: Eğitme süreci sırasında doğrudan bir modele güvenlik açıkları veya arka kapılar eklemek.
  ​
* Model Çalma/Hırsızlığı: Tekrarlanan sorgular yoluyla bir tescilli modelin kopyasının veya yaklaşık bir versiyonunun çıkarılması.
  ​
* Çok ajanlı Sistem: Farklı yeteneklere ve hedeflere sahip olabilecek birden çok etkileşimde bulunan Yapay Zeka ajanından oluşan bir sistem.
  ​
* OPA (Open Policy Agent): Yığın genelinde birleşik politika uygulamasını sağlayan açık kaynaklı bir politika motoru.
  ​
* Gizliliği Koruyan Makine Öğrenimi (PPML): Eğitim verilerinin gizliliğini korurken ML modellerini eğitmek ve dağıtmak için teknikler ve yöntemler.
  ​
* Prompt Enjeksiyonu: Kötü niyetli talimatların, bir modelin amaçlanan davranışını geçersiz kılmak için girdilere gömüldüğü bir saldırı türü.
  ​
* RAG (Retrieval-Augmented Generation): Yanıt oluşturmadan önce harici bilgi kaynaklarından ilgili bilgileri alarak büyük dil modellerini geliştiren bir tekniktir.
  ​
* Kırmızı Takım Çalışması: Zayıf noktaları belirlemek için yapay zeka sistemlerini düşmanca saldırılar simüle ederek aktif olarak test etme uygulaması.
  ​
* SBOM (Yazılım Malzeme Listesi): Yazılım veya yapay zeka modelleri oluşturulurken kullanılan çeşitli bileşenlerin detaylarını ve tedarik zinciri ilişkilerini içeren resmi kayıt.
  ​
* SHAP (SHapley Additive exPlanations): Herhangi bir makine öğrenimi modelinin çıktısını açıklamak için her özelliğin tahmine katkısını hesaplayan oyun teorisi temelli bir yaklaşımdır.
  ​
* Tedarik Zinciri Saldırısı: Üçüncü taraf kütüphaneler, veri setleri veya önceden eğitilmiş modeller gibi tedarik zincirindeki daha az güvenli unsurları hedef alarak bir sistemi tehlikeye atma.
  ​
* Transfer Learning: Bir görev için geliştirilen bir modelin, ikinci bir görevde kullanılacak model için başlangıç noktası olarak yeniden kullanıldığı bir tekniktir.
  ​
* Vektör Veritabanı: Yüksek boyutlu vektörleri (gömülü temsilleri) depolamak ve etkili benzerlik aramaları yapmak için tasarlanmış özel bir veritabanı.
  ​
* Zafiyet Tarama: AI çerçeveleri ve bağımlılıkları dahil olmak üzere yazılım bileşenlerindeki bilinen güvenlik açıklarını tanımlayan otomatik araçlar.
  ​
* Filigranlama: AI tarafından oluşturulan içeriklerde kaynağını takip etmek veya AI üretimini tespit etmek için algılanamayan işaretler yerleştirme teknikleri.
  ​
* Sıfır-Gün Açığı: Geliştiriciler bir yama oluşturup dağıtmadan önce saldırganların istismar edebileceği daha önce bilinmeyen bir güvenlik açığı.

