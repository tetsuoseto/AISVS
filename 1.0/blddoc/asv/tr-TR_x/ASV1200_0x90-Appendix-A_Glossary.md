# Ek A: Terimler Sözlüğü

>This kapsamlı sözlük AISVS genelinde kullanılan temel yapay zeka (AI), makine öğrenmesi (ML) ve güvenlik terimlerinin tanımlarını sağlar; açıklık ve ortak anlayışın sağlanması amacıyla.

* Adversarial Örnek: Bir girdi, yapay zeka modelinin hata yapmasına yol açmak için kasıtlı olarak tasarlanmıştır; genellikle insanlar tarafından algılanamayan ince pertürbasyonlar eklenir.
  ​
* Adversarial Dayanıklılık – Yapay Zeka'da bu kavram, bir modelin performansını sürdürme ve kasıtlı olarak tasarlanmış, kötü niyetli girdiler tarafından kandırılmaya veya manipüle edilmeye karşı direnç gösterme yeteneğini ifade eder.
  ​
* Ajan – Yapay zeka ajanları, kullanıcılar adına hedeflere ulaşmak ve görevleri yerine getirmek için yapay zekayı kullanan yazılım sistemleridir. Akıl yürütmeyi, planlamayı ve belleği gösterirler ve kararlar almak, öğrenmek ve uyum sağlamak için belirli bir özerklik düzeyine sahiptirler.
  ​
* Ajansal Yapay Zeka: Hedeflere ulaşmak için bir dereceye kadar özerklikle çalışabilen ve genellikle insan müdahalesi olmadan kararlar alıp eylemler gerçekleştiren yapay zeka sistemleri.
  ​
* Öznitelik Tabanlı Erişim Denetimi (ABAC): Yetkilendirme kararlarının, kullanıcı, kaynak, eylem ve ortam özniteliklerine dayalı olarak sorgu anında değerlendirildiği bir erişim kontrol paradigması.
  ​
* Arka Kapı Saldırısı: Modelin belirli tetikleyicilere karşı belirli bir şekilde yanıt vermesi için eğitildiği, aksi halde normal davranan bir veri zehirleme saldırısı türüdür.
  ​
* Yanlılık: Yapay zeka model çıktılarında bulunan sistematik hatalar, belirli gruplar için veya belirli bağlamlarda adil olmayan veya ayrımcı sonuçlara yol açabilir.
  ​
* Önyargı Sömürüsü: Yapay zeka modellerindeki bilinen önyargılardan faydalanarak çıktıların veya sonuçların manipüle edilmesini amaçlayan bir saldırı tekniğidir.
  ​
* Cedar: Yapay zeka sistemleri için ABAC'ın uygulanmasında kullanılan, ince ayrıntılı izinler için Amazon'un politika dili ve motoru.
  ​
* Düşünce Zinciri: Nihai yanıtı üretmeden önce ara akıl yürütme adımları üreterek dil modellerinde akıl yürütmeyi geliştirmeye yönelik bir tekniktir.
  ​
* Devre Kesiciler: Belirli risk eşiklerinin aşılması durumunda yapay zeka sistemi operasyonlarını otomatik olarak durduran mekanizmalar.
  ​
* Veri Sızıntısı: Yapay zeka modelinin çıktıları veya davranışı yoluyla hassas bilgilerin istenmeyen ifşası.
  ​
* Veri Zehirlenmesi: Eğitim verilerinin kasıtlı olarak bozulmasıyla model bütünlüğünün tehlikeye atılması, çoğunlukla arka kapılar kurmak veya performansı düşürmek amacıyla.
  ​
* Farklılaştırılmış Gizlilik – Matematiksel olarak sıkı bir çerçeve, veri kümeleri hakkında istatistiksel bilgi yayımlarken bireylerin mahremiyetini korumayı sağlar. Bu, veri sahibinin grubun toplu desenlerini paylaşmasına olanak tanırken belirli bireyler hakkında sızdırılan bilgileri sınırlamaya yardımcı olur.
  ​
* Gömülü Temsiller: Verilerin (metin, görüntü vb.) semantik anlamını yüksek boyutlu bir uzayda yakalayan yoğun vektör temsilleri.
  ​
* Açıklanabilirlik – Yapay Zeka'da açıklanabilirlik, bir yapay zeka sisteminin kararları ve tahminleri için insanlar tarafından anlaşılabilir gerekçeler sunma yeteneğidir ve iç işleyişine dair içgörüler sağlar.
  ​
* Açıklanabilir Yapay Zeka (XAI): Kararları ve davranışları için insanların anlayabileceği açıklamalar sunmak üzere tasarlanmış yapay zeka sistemleri; çeşitli teknikler ve çerçeveler aracılığıyla.
  ​
* Federated Learning: Verilerin kendisini paylaşmadan, yerel veri örneklerini tutan birden çok merkezi olmayan cihaz üzerinde modellerin eğitildiği bir makine öğrenimi yaklaşımıdır.
  ​
* Koruma Önlemleri: Yapay zeka sistemlerinin zararlı, önyargılı veya başka biçimde istenmeyen çıktılar üretmesini önlemek için uygulanmış kısıtlamalar.
  ​
* Halüsinasyon – Bir yapay zeka halüsinasyonu, bir yapay zeka modelinin eğitim verilerine veya gerçekliğe dayanmayan yanlış veya yanıltıcı bilgiler ürettiği bir olguya işaret eder.
  ​
* İnsan-dahil Döngü (HITL): Kritik karar noktalarında insan gözetimi, doğrulama veya müdahalesi gerektirecek biçimde tasarlanmış sistemler.
  ​
* Kod Olarak Altyapı (IaC): Manuel süreçler yerine kod aracılığıyla altyapının yönetimi ve sağlanması, güvenlik taramasını mümkün kılarak tutarlı dağıtımlar sağlar.
  ​
* Jailbreak: Yapay zeka sistemlerindeki güvenlik kısıtlamalarını aşmak için kullanılan teknikler, özellikle büyük dil modellerinde, yasak içerik üretmek amacıyla.
  ​
* En Az Yetki İlkesi: Kullanıcılara ve süreçlere yalnızca gerekli minimum erişim haklarının verilmesi güvenlik ilkesidir.
  ​
* LIME (Yerel Yorumlanabilir Model-agnostik Açıklamalar): Herhangi bir makine öğrenimi sınıflandırıcısının tahminlerini yerel olarak yorumlanabilir bir modelle yaklaşık olarak açıklayan bir tekniktir.
  ​
* Üyelik çıkarım saldırısı: Belirli bir veri noktasının bir makine öğrenimi modelinin eğitilmesinde kullanılıp kullanılmadığını belirlemeyi amaçlayan bir saldırı.
  ​
* MITRE ATLAS: Yapay-Zeka Sistemleri İçin Kasıtlı Tehdit Manzarası; Yapay-Zeka Sistemlerine Karşı Kasıtlı Taktik ve Teknikler Hakkında Bilgi Tabanı.
  ​
* Model Kartı – Bir model kartı, bir yapay zeka modelinin performansı, sınırlamaları, amaçlanan kullanımları ve etik hususları hakkında standartlaştırılmış bilgiler sunan bir belgedir; şeffaflığı artırmak ve sorumlu yapay zeka geliştirmeyi teşvik etmek amacıyla.
  ​
* Model Çıkarımı: Yetkisiz bir tarafın hedef modele tekrarlı sorgular yaparak, yetkisi olmadan fonksiyonel olarak benzer bir kopya oluşturmaya çalıştığı bir saldırı türüdür.
  ​
* Model İnversiyonu: Model çıktılarının analiziyle eğitim verisini yeniden oluşturmaya çalışan bir saldırı.
  ​
* Model Yaşam Döngüsü Yönetimi – Yapay Zeka Model Yaşam Döngüsü Yönetimi, bir yapay zeka modelinin varoluşunun tüm aşamalarını gözetim altında tutma sürecidir; tasarımı, geliştirilmesi, dağıtımı, izlenmesi, bakımı ve nihai emekliliğini kapsar; bunun amacı modelin etkili kalmasını ve hedeflerle uyumlu olmasını sağlamaktır.
  ​
* Model zehirlenmesi: Eğitim süreci sırasında bir modele doğrudan güvenlik açıkları veya arka kapılar enjekte etmek.
  ​
* Model Çalınması/Hırsı: Tekrarlı sorgular yoluyla tescilli bir modelin bir kopyasının veya yaklaşık bir sürümünün elde edilmesi.
  ​
* Çok ajanlı sistem: Birden çok etkileşimli yapay zeka ajanından oluşan bir sistem olup, her biri potansiyel olarak farklı yeteneklere ve hedeflere sahip olabilir.
  ​
* OPA (Open Policy Agent): Yığının tüm katmanlarında birleşik politika uygulanmasını sağlayan açık kaynaklı bir politika motoru.
  ​
* Gizliliği Korumaya Yönelik Makine Öğrenimi (PPML): Eğitim verilerinin gizliliğini korurken ML modellerini eğitmek ve kullanıma sunmak için teknikler ve yöntemler.
  ​
* İstem Enjeksiyonu: Zararlı talimatların girdilere gömüldüğü ve bir modelin amaçlanan davranışını devre dışı bırakmak veya değiştirmek amacıyla yapılan bir saldırıdır.
  ​
* RAG (Retrieval-Augmented Generation): Yanıt üretmeden önce harici bilgi kaynaklarından ilgili bilgileri getirerek büyük dil modellerini güçlendiren bir tekniktir.
  ​
* Kırmızı Takım Çalışması: Yapay Zeka (AI) sistemlerini güvenlik açıklarını belirlemek amacıyla adversarial saldırıları simüle ederek aktif olarak test etme uygulamasıdır.
  ​
* SBOM (Software Bill of Materials): yazılım veya yapay zeka modellerinin inşa edilmesi için kullanılan çeşitli bileşenlerin ayrıntılarını ve tedarik zinciri ilişkilerini içeren resmi bir kayıt.
  ​
* SHAP (SHapley Additive exPlanations): Her özelliğin tahmine katkısını hesaplayarak herhangi bir makine öğrenimi modelinin çıktısını açıklamaya yönelik oyun kuramına dayalı bir yaklaşım.
  ​
* Tedarik Zinciri Saldırısı: Bir sistemi, tedarik zincirindeki daha güvenli olmayan unsurları hedef alarak ele geçirmektir; örneğin üçüncü taraf kütüphaneler, veri kümeleri veya önceden eğitilmiş modeller gibi öğeler.
  ​
* Transfer Öğrenimi: Bir görev için geliştirilmiş bir modelin, ikinci bir görev için bir modelin başlangıç noktası olarak yeniden kullanıldığı bir tekniktir.
  ​
* Vektör Veritabanı: Yüksek boyutlu vektörleri (gömülü temsiller) depolamak ve verimli benzerlik aramaları gerçekleştirmek için tasarlanmış özel bir veritabanıdır.
  ​
* Zafiyet Taraması: Otomatik araçlar, yazılım bileşenlerinde bilinen güvenlik açıklarını tespit eden, yapay zeka çerçeveleri ve bağımlılıkları da dahil.
  ​
* Filigranlama: Yapay Zeka tarafından üretilen içeriğe algılanmayan işaretler yerleştirme teknikleriyle içeriğin kökenini izlemek veya yapay zeka üretimini tespit etmek.
  ​
* Sıfır Gün Açığı: Geliştiriciler bir yama oluşturup dağıtmadan önce saldırganların istismar edebileceği, daha önce bilinmeyen bir güvenlik açığıdır.

