# Prefácio

Bem-vindo ao Padrão de Verificação de Segurança da Inteligência Artificial (AISVS) versão 1.0!

## Introdução

Estabelecido em 2025 por meio de um esforço comunitário colaborativo, AISVS define os requisitos de segurança a considerar ao projetar, desenvolver, implantar e operar modelos modernos de IA, pipelines de IA e serviços habilitados por IA.

AISVS v1.0 representa o trabalho conjunto de seus líderes de projeto, do grupo de trabalho e dos contribuidores da comunidade mais ampla, para produzir uma linha de base pragmática e testável para a segurança de sistemas de IA.

Nosso objetivo com este lançamento é tornar o AISVS fácil de adotar, mantendo o foco‑laser em seu escopo definido e enfrentando o panorama de riscos em rápida evolução, exclusivo para IA.

## Objetivos-chave para AISVS Versão 1.0

A versão 1.0 será criada com vários princípios orientadores.

### Escopo bem-definido

Cada requisito deve estar alinhado com o nome e a missão do AISVS:

* Inteligência Artificial – Os controles operam no nível de IA/ML (dados, modelo, pipeline ou inferência) e são de responsabilidade dos profissionais de IA.
* Segurança – Requisitos mitigam diretamente os riscos identificados de segurança, privacidade ou proteção.
* Verificação – A linguagem é escrita para que a conformidade possa ser validada de forma objetiva.
* Padrão – Seções seguem uma estrutura e terminologia consistentes para formar uma referência coerente.
  ​
---

Ao seguir o AISVS, as organizações podem avaliar sistematicamente e fortalecer a postura de segurança de suas soluções de IA, promovendo uma cultura de engenharia de IA segura.

