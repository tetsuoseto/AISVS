# Frontispício

## Sobre o Padrão

O Padrão de Verificação de Segurança em Inteligência Artificial (AISVS) é um catálogo orientado pela comunidade de requisitos de segurança que cientistas de dados, engenheiros de MLOps, arquitetos de software, desenvolvedores, testadores, profissionais de segurança, fornecedores de ferramentas, reguladores e consumidores podem usar para projetar, construir, testar e verificar sistemas e aplicações confiáveis habilitados por IA. Ele fornece uma linguagem comum para especificar controles de segurança ao longo do ciclo de vida da IA — desde a coleta de dados e desenvolvimento de modelos até a implantação e monitoramento contínuo — para que as organizações possam medir e melhorar a resiliência, privacidade e segurança de suas soluções de IA.

## Copyright e Licença

Versão 0.1 (Primeiro Rascunho Público - Trabalho em Andamento), 2025  

![license](../images/license.png)

Direitos autorais © 2025 O Projeto AISVS.  

Lançado sob a[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
Para qualquer reutilização ou distribuição, você deve comunicar claramente os termos da licença desta obra para os outros.

## Líderes de Projeto

|            |                         |
| ---------- | ----------------------- |
| Jim Manico | Aras “Russ” Memisyazici |

## Contribuidores e Revisores

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS é um padrão completamente novo criado especificamente para abordar os desafios únicos de segurança dos sistemas de inteligência artificial. Embora se baseie em melhores práticas de segurança mais amplas, cada requisito do AISVS foi desenvolvido do zero para refletir o cenário de ameaças da IA e ajudar as organizações a construir soluções de IA mais seguras e resilientes.

