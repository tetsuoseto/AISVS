# Frontispício

## Sobre o Padrão

O Padrão de Verificação de Segurança da Inteligência Artificial (AISVS) é um catálogo impulsionado pela comunidade de requisitos de segurança que cientistas de dados, engenheiros de MLOps, arquitetos de software, desenvolvedores, testadores, profissionais de segurança, fornecedores de ferramentas, reguladores e consumidores podem usar para projetar, construir, testar e verificar sistemas e aplicações confiáveis habilitados por IA. Ele fornece uma linguagem comum para especificar controles de segurança ao longo do ciclo de vida da IA — desde a coleta de dados e o desenvolvimento de modelos até a implantação e o monitoramento contínuo — para que as organizações possam medir e melhorar a resiliência, a privacidade e a segurança de suas soluções de IA.

## Direitos Autorais e Licença

Versão 0.1 (Primeiro rascunho público - Em andamento), 2025  

![license](../images/license.png)

Direitos autorais © 2025 The AISVS Project.  

Lançado sob o [Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
Para qualquer reutilização ou distribuição, você deve comunicar claramente os termos de licença desta obra a terceiros.

## Líderes de projeto

|            |                         |
| ---------- | ----------------------- |
| Jim Manico | Aras “Russ” Memisyazici |

## Contribuidores e Revisores

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS é um padrão brand‑new criado especificamente para enfrentar os desafios de segurança únicos de sistemas de inteligência artificial. Embora se inspire nas melhores práticas de segurança mais amplas, cada requisito do AISVS foi desenvolvido do zero para refletir o cenário de ameaças da IA e ajudar as organizações a construir soluções de IA mais seguras e resilientes.

