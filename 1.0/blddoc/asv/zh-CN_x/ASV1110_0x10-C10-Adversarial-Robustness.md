# 10 对抗鲁棒性 与 隐私防御

## 控制目标

确保 AI 模型在面对规避、推断、提取或中毒攻击时，仍然保持可靠，具备隐私保护能力并具备抗滥用能力。

---

## 10.1 模型对齐与安全

防范有害或违反政策的输出。

|   #    | 描述                                                | 等级  | 角色  |
| :----: | ------------------------------------------------- | :-: | :-: |
| 10.1.1 | 请验证对齐测试套件（红队提示、越狱探针、不允许的内容）是否已进行版本控制，并在每次模型发布时运行。 |  1  | D/V |
| 10.1.2 | 请验证拒绝和安全完成的护栏是否已生效。                               |  1  |  D  |
| 10.1.3 | 验证自动评估器是否能够衡量有害内容的比率，并对超出设定阈值的回归进行标记。             |  2  | D/V |
| 10.1.4 | 验证对抗越狱训练是否有文档记录且可复现。                              |  2  |  D  |
| 10.1.5 | 验证正式的政策合规证明或经认证的监控是否覆盖关键领域。                       |  3  |  V  |

---

## 10.2 对抗性-示例 加固

提高对被操纵输入的鲁棒性。对抗性训练和基准评分是当前的最佳实践。

|   #    | 描述                            | 等级  | 角色  |
| :----: | ----------------------------- | :-: | :-: |
| 10.2.1 | 验证项目代码库中是否包含具有可复现随机种子的对抗训练配置。 |  1  |  D  |
| 10.2.2 | 验证对抗样本检测在生产管线中是否会触发阻断告警。      |  2  | D/V |
| 10.2.4 | 验证认证‑鲁棒性证明或区间界限证书至少覆盖最关键的前几类。 |  3  |  V  |
| 10.2.5 | 验证回归测试使用自适应攻击来确认没有可测量的鲁棒性损失。  |  3  |  V  |

---

## 10.3 成员推断缓解措施

限制判断某条记录是否出现在训练数据中的能力。 差分隐私和置信度分数屏蔽仍然是已知的最有效防御措施。

|   #    | 描述                                   | 等级  | 角色  |
| :----: | ------------------------------------ | :-: | :-: |
| 10.3.1 | 验证对每个查询的熵正则化或温度缩放是否能降低过度自信的预测。       |  1  |  D  |
| 10.3.2 | 验证 训练 是否 采用 ε-有界的 差分隐私优化 用于 敏感 数据集。  |  2  |  D  |
| 10.3.3 | 验证攻击仿真（影子模型或黑盒）在留出数据上的 AUC 值 ≤ 0.60。 |  2  |  V  |

---

## 10.4 模型-反演抵抗性

防止对私有属性的重建。最近的综述强调输出截断和差分隐私（DP）保证作为实际防御措施。

|   #    | 描述                             | 等级  | 角色  |
| :----: | ------------------------------ | :-: | :-: |
| 10.4.1 | 验证敏感属性从不直接输出；如有需要，请使用桶化或单向变换。  |  1  |  D  |
| 10.4.2 | 验证查询速率限制是否对来自同一主体的重复自适应查询进行限流。 |  1  | D/V |
| 10.4.3 | 请验证模型是否在使用隐私保护噪声进行训练。          |  2  |  D  |

---

## 10.5 模型提取防御

检测并遏制未授权的克隆。建议采用水印技术和查询模式分析。

|   #    | 描述                                                | 等级  | 角色  |
| :----: | ------------------------------------------------- | :-: | :-: |
| 10.5.1 | 验证推理网关是否对全局及按每个 API 密钥的速率限制进行了与模型记忆阈值相匹配的调优。      |  1  |  D  |
| 10.5.2 | 验证查询熵和输入多样性统计数据是否为自动化提取检测器提供输入。                   |  2  | D/V |
| 10.5.3 | 验证脆性水印或概率性水印在对疑似克隆进行不超过 1 000 次查询时，其 p 值小于 0.01。  |  2  |  V  |
| 10.5.4 | 核实水印密钥和触发集是否存储在 hardware-security-module 中，并每年轮换。 |  3  |  D  |
| 10.5.5 | 验证提取警报事件是否包含违规查询，并与事件响应剧本集成。                      |  3  |  V  |

---

## 10.6 推理-时间 污染-数据 检测

识别并中和带有后门的或被污染的输入。

|   #    | 描述                                     | 等级  | 角色  |
| :----: | -------------------------------------- | :-: | :-: |
| 10.6.1 | 在模型推理之前，验证输入是否经过异常检测器（例如 STRIP、一致性评分）。 |  1  |  D  |
| 10.6.2 | 验证探测器阈值在干净/被污染的验证集上进行调优，以实现小于 5% 的误报率。 |  1  |  V  |
| 10.6.3 | 验证被标记为污染的输入是否会触发软阻塞和人工审核流程。            |  2  |  D  |
| 10.6.4 | 验证检测器是否已针对自适应、无触发器的后门攻击进行压力测试。         |  2  |  V  |
| 10.6.5 | 验证检测有效性指标是否已被记录，并以最新的威胁情报定期重新评估。       |  3  |  D  |

---

## 10.7 动态安全策略自适应

基于威胁情报和行为分析的实时-安全策略更新。

|   #    | 描述                                     | 等级  | 角色  |
| :----: | -------------------------------------- | :-: | :-: |
| 10.7.1 | 验证安全策略是否可以在不重启代理的情况下动态更新，同时保持策略版本的完整性。 |  1  | D/V |
| 10.7.2 | 验证策略更新是否由授权的安全人员进行密码学签名，并在应用之前进行验证。    |  2  | D/V |
| 10.7.3 | 验证动态策略变更是否被完整记录在审计跟踪中，包括理由说明、批准链和回滚程序。 |  2  | D/V |
| 10.7.4 | 验证自适应安全机制是否根据风险上下文和行为模式调整威胁检测的灵敏度。     |  3  | D/V |
| 10.7.5 | 验证策略自适应决策是否可解释，并包含供安全团队审核的证据链。         |  3  | D/V |

---

## 10.8 基于反射的安全分析

通过智能体的自我反省与元认知分析进行安全验证。

|   #    | 描述                                     | 等级  | 角色  |
| :----: | -------------------------------------- | :-: | :-: |
| 10.8.1 | 验证智能体的反思机制是否包含以安全为重点的对决策和行动的自我评估。      |  1  | D/V |
| 10.8.2 | 验证反思输出是否经过验证，以防止对抗性输入对自我评估机制的操纵。       |  2  | D/V |
| 10.8.3 | 验证元认知安全分析是否能够在智能代理的推理过程中识别潜在的偏见、操纵或妥协。 |  2  | D/V |
| 10.8.4 | 验证基于反射的安全警告是否会触发增强监控和潜在的人为干预工作流。       |  3  | D/V |
| 10.8.5 | 验证从安全反思中进行的持续学习是否在提高威胁检测的同时不损害合法功能。    |  3  | D/V |

---

## 10.9 进化 与 自我提升 安全

具备自我修改与进化能力的智能体系统的安全控制。

|   #    | 描述                                  | 等级  | 角色  |
| :----: | ----------------------------------- | :-: | :-: |
| 10.9.1 | 验证自我修改能力仅限于指定的安全区域，并设有形式化验证边界。      |  1  | D/V |
| 10.9.2 | 在实施之前，确保演进提案经过安全影响评估。               |  2  | D/V |
| 10.9.3 | 验证自我改进机制是否包含带有完整性验证的回滚能力。           |  2  | D/V |
| 10.9.4 | 验证元学习的安全性是否能够防止对改进算法的对抗性操纵。         |  3  | D/V |
| 10.9.5 | 验证递归自我改进是否被形式化的安全约束所约束，并给出收敛性的数学证明。 |  3  | D/V |

---

### 参考文献

* [MITRE ATLAS adversary tactics for ML](https://atlas.mitre.org/)
* [NIST AI Risk Management Framework 1.0, 2023](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [OWASP Top 10 for LLM Applications, 2025](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Adversarial Training: A Survey — Zhao et al., 2024](https://arxiv.org/abs/2410.15042)
* [RobustBench adversarial-robustness benchmark](https://robustbench.github.io/)
* [Membership-Inference & Model-Inversion Risk Survey, 2025](https://www.sciencedirect.com/science/article/abs/pii/S0950705125003867)
* [PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023](https://ojs.aaai.org/index.php/AAAI/article/view/26289)
* [Model-Inversion Attacks & Defenses Survey — AI Review, 2025](https://link.springer.com/article/10.1007/s10462-025-11248-0)
* [Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024](https://doi.org/10.1109/TDSC.2023.3261327)
* [Fragile Model Watermarking Survey — 2025](https://www.sciencedirect.com/science/article/abs/pii/S0165168425002026)
* [Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025](https://arxiv.org/abs/2503.22759)
* [BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024](https://arxiv.org/abs/2405.15269)

