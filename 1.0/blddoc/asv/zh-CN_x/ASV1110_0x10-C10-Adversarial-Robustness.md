# 10 对抗鲁棒性与隐私防护

## 控制目标

确保人工智能模型在面对规避、推断、提取或投毒攻击时保持可靠性、隐私保护和防滥用能力。

---

## 10.1 模型对齐与安全

防范有害或违反政策的输出。

|   #    | 描述                                            | 等级  | 角色  |
| :----: | --------------------------------------------- | :-: | :-: |
| 10.1.1 | 验证对齐测试套件（红队提示、越狱探测、禁止内容）是否进行版本控制，并在每次模型发布时运行。 |  1  | D/V |
| 10.1.2 | 验证拒绝和安全完成护栏是否被执行。                             |  1  |  D  |
| 10.1.3 | 验证自动评估器是否测量有害内容率并标记超过设定阈值的回归。                 |  2  | D/V |
| 10.1.4 | 验证反越狱训练是否有文档记录且可复现。                           |  2  |  D  |
| 10.1.5 | 验证正式的策略合规性证明或经过认证的监控是否涵盖关键领域。                 |  3  |  V  |

---

## 10.2 对抗样本强化

提高对操纵输入的鲁棒性。强健的对抗训练和基准评分是当前的最佳实践。

|   #    | 描述                                | 等级  | 角色  |
| :----: | --------------------------------- | :-: | :-: |
| 10.2.1 | 确认项目代码库包含带有可复现种子的对抗训练配置。          |  1  |  D  |
| 10.2.2 | 验证对抗样本检测是否在生产流水线中触发阻断警报。          |  2  | D/V |
| 10.2.4 | 验证经过认证的鲁棒性证明或区间界限证书是否至少覆盖了最关键的分类。 |  3  |  V  |
| 10.2.5 | 验证回归测试使用自适应攻击以确认没有可测量的鲁棒性损失。      |  3  |  V  |

---

## 10.3 成员推断缓解

限制决定某条记录是否存在于训练数据中的能力。差分隐私和置信度分数掩蔽仍然是已知的最有效防御措施。

|   #    | 描述                                    | 等级  | 角色  |
| :----: | ------------------------------------- | :-: | :-: |
| 10.3.1 | 验证每次查询的熵正则化或温度调节是否减少了过度自信的预测。         |  1  |  D  |
| 10.3.2 | 验证训练过程中是否对敏感数据集采用了ε-界限差分隐私优化。         |  2  |  D  |
| 10.3.3 | 验证攻击模拟（影子模型或黑盒）在保留数据上的攻击AUC是否 ≤ 0.60。 |  2  |  V  |

---

## 10.4 模型反演抗性

防止私有属性的重构。最近的调查强调输出截断和差分隐私保证作为实用的防御措施。

|   #    | 描述                             | 等级  | 角色  |
| :----: | ------------------------------ | :-: | :-: |
| 10.4.1 | 确保敏感属性绝不被直接输出；在必要时，使用分桶或单向转换。  |  1  |  D  |
| 10.4.2 | 验证查询速率限制是否对来自同一主体的重复自适应查询进行节流。 |  1  | D/V |
| 10.4.3 | 验证模型是否采用了隐私保护噪声进行训练。           |  2  |  D  |

---

## 10.5 模型提取防御

检测和阻止未经授权的克隆。建议使用水印和查询模式分析。

|   #    | 描述                                                       | 等级  | 角色  |
| :----: | -------------------------------------------------------- | :-: | :-: |
| 10.5.1 | 验证推理网关是否强制执行针对模型记忆阈值调整的全局和每个API密钥的速率限制。                  |  1  |  D  |
| 10.5.2 | 验证查询熵和输入多样性统计数据是否为自动抽取检测器提供支持。                           |  2  | D/V |
| 10.5.3 | 验证在对疑似克隆体进行不超过 1 000 次查询时，脆弱或概率水印可以以 p < 0.01 的显著性水平被证明。 |  2  |  V  |
| 10.5.4 | 验证水印密钥和触发器集是否存储在硬件安全模块中，并每年轮换一次。                         |  3  |  D  |
| 10.5.5 | 验证提取警报事件是否包含违规查询，并且与事件响应剧本集成。                            |  3  |  V  |

---

## 10.6 推理时的中毒数据检测

识别并中和带有后门或被投毒的输入。

|   #    | 描述                                    | 等级  | 角色  |
| :----: | ------------------------------------- | :-: | :-: |
| 10.6.1 | 在模型推理之前，验证输入通过异常检测器（例如，STRIP、一致性评分）。  |  1  |  D  |
| 10.6.2 | 验证检测器阈值是否在干净/中毒的验证集上进行调优，以实现低于5%的误报率。 |  1  |  V  |
| 10.6.3 | 验证被标记为中毒的输入是否会触发软阻止和人工审核工作流。          |  2  |  D  |
| 10.6.4 | 验证探测器是否通过自适应的、无触发的后门攻击进行了压力测试。        |  2  |  V  |
| 10.6.5 | 验证检测效能指标是否已被记录，并定期使用最新威胁情报进行重新评估。     |  3  |  D  |

---

## 10.7 动态安全策略适应

基于威胁情报和行为分析的实时安全策略更新。

|   #    | 描述                                     | 等级  | 角色  |
| :----: | -------------------------------------- | :-: | :-: |
| 10.7.1 | 验证安全策略能够在不重启代理的情况下动态更新，同时保持策略版本的完整性。   |  1  | D/V |
| 10.7.2 | 验证策略更新是否由授权的安全人员进行加密签名，并在应用前进行验证。      |  2  | D/V |
| 10.7.3 | 验证动态策略变更是否包含完整的审计追踪记录，包括变更理由、审批链和回滚流程。 |  2  | D/V |
| 10.7.4 | 验证自适应安全机制是否根据风险上下文和行为模式调整威胁检测的敏感性。     |  3  | D/V |
| 10.7.5 | 验证策略适应决策的可解释性，并包含供安全团队审查的证据链。          |  3  | D/V |

---

## 10.8 基于反射的安全分析

通过代理自我反思和元认知分析进行安全验证。

|   #    | 描述                                     | 等级  | 角色  |
| :----: | -------------------------------------- | :-: | :-: |
| 10.8.1 | 验证智能体反思机制是否包括针对决策和行为的安全性自我评估。          |  1  | D/V |
| 10.8.2 | 验证反射输出是否经过验证，以防止对抗性输入操纵自我评估机制。         |  2  | D/V |
| 10.8.3 | 验证元认知安全分析是否能够识别智能体推理过程中的潜在偏见、操控或妥协。    |  2  | D/V |
| 10.8.4 | 验证基于反射的安全警告是否触发了增强监控和潜在的人为干预工作流程。      |  3  | D/V |
| 10.8.5 | 验证从安全反思中持续学习能否提高威胁检测能力，同时不影响合法功能的正常运行。 |  3  | D/V |

---

## 10.9 演进与自我改进安全

具有自我修改和进化能力的代理系统的安全控制措施。

|   #    | 描述                               | 等级  | 角色  |
| :----: | -------------------------------- | :-: | :-: |
| 10.9.1 | 验证自我修改能力是否仅限于指定的安全区域，并具有形式化验证边界。 |  1  | D/V |
| 10.9.2 | 确保在实施之前，对演进提案进行安全影响评估。           |  2  | D/V |
| 10.9.3 | 验证自我改进机制包括带有完整性验证的回滚功能。          |  2  | D/V |
| 10.9.4 | 验证元学习安全性是否防止了改进算法的对抗性操纵。         |  3  | D/V |
| 10.9.5 | 通过数学收敛性证明验证递归自我提升受形式安全约束的限制。     |  3  | D/V |

---

### 参考文献

* [MITRE ATLAS adversary tactics for ML](https://atlas.mitre.org/)
* [NIST AI Risk Management Framework 1.0, 2023](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [OWASP Top 10 for LLM Applications, 2025](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Adversarial Training: A Survey — Zhao et al., 2024](https://arxiv.org/abs/2410.15042)
* [RobustBench adversarial-robustness benchmark](https://robustbench.github.io/)
* [Membership-Inference & Model-Inversion Risk Survey, 2025](https://www.sciencedirect.com/science/article/abs/pii/S0950705125003867)
* [PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023](https://ojs.aaai.org/index.php/AAAI/article/view/26289)
* [Model-Inversion Attacks & Defenses Survey — AI Review, 2025](https://link.springer.com/article/10.1007/s10462-025-11248-0)
* [Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024](https://doi.org/10.1109/TDSC.2023.3261327)
* [Fragile Model Watermarking Survey — 2025](https://www.sciencedirect.com/science/article/abs/pii/S0165168425002026)
* [Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025](https://arxiv.org/abs/2503.22759)
* [BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024](https://arxiv.org/abs/2405.15269)

