# 封面

## 关于标准

人工智能安全验证标准（AISVS）是一个社区驱动的安全需求目录，供数据科学家、MLOps工程师、软件架构师、开发人员、测试人员、安全专家、工具供应商、监管机构和用户用于设计、构建、测试和验证可信赖的AI支持系统和应用。它为AI生命周期中的安全控制提供了统一的语言——从数据收集和模型开发到部署及持续监控——从而帮助组织衡量并提升其AI解决方案的弹性、隐私性和安全性。

## 版权与许可

版本 0.1（首个公开草稿 - 正在进行中），2025  

![license](../images/license.png)

版权 © 2025 AISVS 项目。  

根据 [Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
对于任何再使用或分发，您必须明确向他人传达本作品的许可条款。

## 项目负责人

|        |                         |
| ------ | ----------------------- |
| 吉姆·马尼科 | Aras “Russ” Memisyazici |

## 贡献者与审稿人

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS 是一个全新的标准，专门针对人工智能系统的独特安全挑战而创建。虽然它借鉴了更广泛的安全最佳实践，但 AISVS 中的每一项要求都是从零开始制定的，旨在反映 AI 威胁环境，并帮助组织构建更安全、更具韧性的 AI 解决方案。

