# C2 用户输入验证

## 控制目标

对用户输入的强健验证是防御对人工智能系统造成最大损害的攻击的第一道防线。提示注入攻击可能会覆盖系统指令、泄露敏感数据，或引导模型产生不被允许的行为。除非有专门的过滤器和指令层级，否则研究表明，利用极长上下文窗口的“多次示例”越狱攻击将会奏效。此外，细微的对抗性扰动攻击——例如同形异义字替换或网络黑话——可以悄无声息地改变模型的决策。

---

## C2.1 提示注入防护

提示注入是人工智能系统面临的主要风险之一。针对这种方法的防御措施结合了静态模式过滤器、动态分类器和指令层级执行。

|   #   | 描述                                                                        | 等级  | 角色  |
| :---: | ------------------------------------------------------------------------- | :-: | :-: |
| 2.1.1 | 验证用户输入是否经过筛查，以防止已知提示注入模式（越狱关键词、“忽略之前内容”、角色扮演链条、间接HTML/URL攻击）—这些模式的库会持续更新。 |  1  | D/V |
| 2.1.2 | 验证系统是否强制执行指令层级，其中系统或开发者消息优先于用户指令，即使在上下文窗口扩展后也是如此。                         |  1  | D/V |
| 2.1.3 | 确认在每次模型或提示模板发布之前，都进行对抗性评估测试（例如，红队“多次”提示），并设置成功率阈值及自动阻止回归的机制。              |  2  | D/V |
| 2.1.4 | 验证来自第三方内容（网页、PDF、电子邮件）的提示是否在单独的解析环境中进行清理，然后再合并到主提示中。                      |  2  |  D  |
| 2.1.5 | 验证所有提示过滤规则更新、分类器模型版本和阻止列表更改均受版本控制且可审计。                                    |  3  | D/V |

---

## C2.2 对抗样本抗性

自然语言处理（NLP）模型仍然容易受到微妙的字符或词级扰动的影响，这些扰动通常被人类忽略，但模型往往会误分类。

|   #   | 描述                                                  | 等级  | 角色  |
| :---: | --------------------------------------------------- | :-: | :-: |
| 2.2.1 | 验证基本的输入规范化步骤（Unicode NFC、同形异义字符映射、空白字符修剪）是否在分词之前执行。 |  1  |  D  |
| 2.2.2 | 验证统计异常检测是否标记了与语言规范编辑距离异常高、重复标记过多或嵌入距离异常的输入。         |  2  | D/V |
| 2.2.3 | 验证推理管道是否支持可选的对抗训练强化的模型变体或防御层（例如，随机化、防御蒸馏）以应对高风险端点。  |  2  |  D  |
| 2.2.4 | 验证可疑的对抗性输入是否被隔离，并在进行个人身份信息(PII)脱敏后，完整记录其负载。         |  2  |  V  |
| 2.2.5 | 验证鲁棒性指标（已知攻击套件的成功率）是否随时间跟踪，并且回归会触发发布阻止。             |  3  | D/V |

---

## C2.3 模式、类型和长度验证

包含格式错误或超大输入的 AI 攻击可能导致解析错误、字段间提示溢出以及资源耗尽。严格的模式（schema）强制也是执行确定性工具调用的前提条件。

|   #   | 描述                                                                           | 等级  | 角色  |
| :---: | ---------------------------------------------------------------------------- | :-: | :-: |
| 2.3.1 | 验证每个 API 或函数调用端点是否定义了明确的输入模式（JSON Schema、Protobuf 或多模态等效模式），并且在提示组装前对输入进行验证。 |  1  |  D  |
| 2.3.2 | 验证超过最大令牌数或字节限制的输入是否会被拒绝，且返回安全错误，而不是被静默截断。                                    |  1  | D/V |
| 2.3.3 | 验证类型检查（例如，数字范围、枚举值、图像/音频的 MIME 类型）是否在服务器端强制执行，而不仅仅是在客户端代码中。                  |  2  | D/V |
| 2.3.4 | 验证语义验证器（例如，JSON Schema）是否以常数时间运行，以防止算法拒绝服务攻击（DoS）。                           |  2  |  D  |
| 2.3.5 | 验证验证失败是否以带有编辑过的有效载荷片段和明确的错误代码的形式记录，以帮助安全分诊。                                  |  3  |  V  |

---

## C2.4 内容与政策筛查

开发人员应能够检测请求不允许内容（例如非法指令、仇恨言论和版权文本）的语法有效提示，然后阻止其传播。

|   #   | 描述                                                          | 等级  | 角色  |
| :---: | ----------------------------------------------------------- | :-: | :-: |
| 2.4.1 | 验证内容分类器（零样本或微调版本）是否对每个输入内容进行暴力、自残、仇恨、性内容和非法请求的评分，并支持可配置的阈值。 |  1  |  D  |
| 2.4.2 | 验证违反政策的输入将收到标准化的拒绝或安全完成，从而防止它们传播到下游的语言模型调用。                 |  1  | D/V |
| 2.4.3 | 验证筛查模型或规则集至少每季度重新训练/更新一次，纳入新观察到的绕过限制或规避政策的模式。               |  2  |  D  |
| 2.4.4 | 通过基于属性的规则在请求时解析，验证筛选是否遵守用户特定的政策（年龄、地区法律限制）。                 |  2  |  D  |
| 2.4.5 | 验证筛查日志是否包含分类器置信度分数和策略类别标签，以用于SOC关联和未来的红队重放。                 |  3  |  V  |

---

## C2.5 输入速率限制与滥用防护

开发人员应通过限制输入速率和检测异常使用模式，防止滥用、资源耗尽和针对人工智能系统的自动化攻击。

|   #   | 描述                                    | 等级  | 角色  |
| :---: | ------------------------------------- | :-: | :-: |
| 2.5.1 | 验证所有输入端点是否针对每个用户、每个IP和每个API密钥实施了速率限制。 |  1  | D/V |
| 2.5.2 | 验证突发速率和持续速率限制已调整到防止拒绝服务（DoS）和暴力破解攻击。  |  2  | D/V |
| 2.5.3 | 验证异常使用模式（例如，快速连续请求、输入泛滥）是否会触发自动阻止或升级。 |  2  | D/V |
| 2.5.4 | 验证滥用预防日志是否被保留并审查以发现新出现的攻击模式。          |  3  |  V  |

---

## C2.6 多模态输入验证

AI系统应包括对非文本输入（图像、音频、文件）的强健验证，以防止注入、规避或资源滥用。

|   #   | 描述                                     | 等级  | 角色  |
| :---: | -------------------------------------- | :-: | :-: |
| 2.6.1 | 确保所有非文本输入（图像、音频、文件）在处理前均经过类型、大小和格式的验证。 |  1  |  D  |
| 2.6.2 | 验证文件在导入前是否进行了恶意软件和隐写载荷扫描。              |  2  | D/V |
| 2.6.3 | 验证图像/音频输入是否经过对抗扰动或已知攻击模式的检查。           |  2  | D/V |
| 2.6.4 | 验证多模态输入验证失败是否被记录并触发警报以供调查。             |  3  |  V  |

---

## C2.7 输入来源与归属

人工智能系统应通过监控和标记所有用户输入的来源，支持审计、滥用追踪和合规性。

|   #   | 描述                                         | 等级  | 角色  |
| :---: | ------------------------------------------ | :-: | :-: |
| 2.7.1 | 验证所有用户输入在摄取时都带有元数据标签（用户ID、会话、来源、时间戳、IP地址）。 |  1  | D/V |
| 2.7.2 | 验证所有处理过的输入的出处元数据是否被保留且可审计。                 |  2  | D/V |
| 2.7.3 | 验证异常或不可信的输入来源是否被标记并受到加强审查或阻止。              |  2  | D/V |

---

## C2.8 实时自适应威胁检测

开发人员应使用先进的针对人工智能的威胁检测系统，该系统能够适应新的攻击模式并通过编译的模式匹配提供实时保护。

|   #   | 描述                                               | 等级  | 角色  |
| :---: | ------------------------------------------------ | :-: | :-: |
| 2.8.1 | 验证威胁检测模式是否已编译成优化的正则表达式引擎，以实现高性能的实时过滤，并将延迟影响降至最低。 |  1  | D/V |
| 2.8.2 | 验证威胁检测系统是否为不同的威胁类别（提示注入、有害内容、敏感数据、系统命令）维护独立的模式库。 |  1  | D/V |
| 2.8.3 | 验证自适应威胁检测是否包含机器学习模型，该模型根据攻击频率和成功率更新威胁敏感度。        |  2  | D/V |
| 2.8.4 | 验证实时威胁情报源是否自动更新模式库，包含新的攻击特征和妥协指标（IOC）。           |  2  | D/V |
| 2.8.5 | 验证威胁检测的误报率是否持续受到监控，并自动调整模式特异性以最大限度减少对合法用例的干扰。    |  3  | D/V |
| 2.8.6 | 验证上下文威胁分析是否考虑了输入来源、用户行为模式和会话历史，以提高检测准确性。         |  3  | D/V |
| 2.8.7 | 验证威胁检测性能指标（检测率、处理延迟、资源利用率）是否被实时监控和优化。            |  3  | D/V |

---

## C2.9 多模态安全验证流程

开发人员应针对文本、图像、音频及其他 AI 输入模式，提供特定类型的威胁检测和资源隔离的安全验证。

|   #   | 描述                                                               | 等级  | 角色  |
| :---: | ---------------------------------------------------------------- | :-: | :-: |
| 2.9.1 | 验证每种输入方式是否具备专门的安全验证器，且具备文档化的威胁模式（文本：提示注入，图像：隐写术，音频：频谱图攻击）和检测阈值。  |  1  | D/V |
| 2.9.2 | 验证多模态输入是否在隔离的沙箱中处理，且每种模态类型具有定义的资源限制（内存、CPU、处理时间），并在安全策略中有相应记录。   |  2  | D/V |
| 2.9.3 | 验证跨模态攻击检测是否能够通过关联规则和告警生成识别跨多个输入类型的协调攻击（例如，图像中的隐写载荷与文本中的提示注入相结合）。 |  2  | D/V |
| 2.9.4 | 验证多模态验证失败是否触发详细日志记录，包括所有输入模态、验证结果、威胁评分以及结构化日志格式的相关性分析，以便集成SIEM。  |  3  | D/V |
| 2.9.5 | 验证特定模态内容分类器是否按照文档规定的时间表（至少每季度）更新，包括新的威胁模式、对抗性样本，并且性能基准维持在基线阈值以上。 |  3  | D/V |

---

## 参考文献

* [LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security](https://genai.owasp.org/llmrisk/llm01-prompt-injection/)
* [Generative AI's Biggest Security Flaw Is Not Easy to Fix](https://www.wired.com/story/generative-ai-prompt-injection-hacking)
* [Many-shot jailbreaking \ Anthropic](https://www.anthropic.com/research/many-shot-jailbreaking)
* [$PDF$ OpenAI GPT-4.5 System Card](https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf)
* [Notebook for the CheckThat Lab at CLEF 2024](https://ceur-ws.org/Vol-3740/paper-53.pdf)
* [Mitigate jailbreaks and prompt injections – Anthropic](https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks)
* [Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis](https://ama.drwhy.ai/mitre-attck.html)
* [OWASP Top 10 for LLM Applications 2025 – WorldTech IT](https://wtit.com/blog/2025/04/17/owasp-top-10-for-llm-applications-2025/)
* [OWASP Machine Learning Security Top Ten](https://owasp.org/www-project-machine-learning-security-top-10/)
* [Few words about AI Security – Jussi Metso](https://www.jussimetso.com/index.php/2024/09/28/few-words-about-ai-security/)
* [How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry](https://modelmetry.com/blog/how-to-ensure-llm-output-adheres-to-a-json-schema)
* [Easily enforcing valid JSON schema following – API](https://community.openai.com/t/feature-request-function-calling-easily-enforcing-valid-json-schema-following/263515?utm_source)
* [AI Safety + Cybersecurity R\&D Tracker – Fairly AI](https://www.fairly.ai/blog/ai-cybersecurity-tracker)
* [Anthropic makes 'jailbreak' advance to stop AI models producing harmful results](https://www.ft.com/content/cf11ebd8-aa0b-4ed4-945b-a5d4401d186e)
* [Pattern matching filter rules - IBM](https://www.ibm.com/docs/ssw_aix_71/security/intrusion_pattern_matching_filter_rules.html)
* [Real-time Threat Detection](https://www.darktrace.com/cyber-ai-glossary/real-time-threat-detection)

