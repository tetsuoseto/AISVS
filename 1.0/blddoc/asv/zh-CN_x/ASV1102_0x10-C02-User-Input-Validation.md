# C2 用户输入验证

## 控制目标

对用户输入进行鲁棒性验证是对 AI 系统最具破坏性的攻击之一的第一道防线。提示注入攻击可以覆盖系统指令、泄露敏感数据，或将模型引导至不被允许的行为。除非有专门的过滤器和指令层级，否则研究表明利用极长的上下文窗口的“多轮越狱攻击”将是有效的。此外，细微的对抗性扰动攻击——例如同形字替换（homoglyph）或 leetspeak——也可能悄无声息地改变模型的决策。

---

## C2.1 提示注入防御

提示注入攻击是人工智能系统面临的主要风险之一。针对这种策略的防御措施采用静态模式过滤器、动态分类器以及指令层级执行约束的组合。

|   #   | 描述                                                                      | 等级  | 角色  |
| :---: | ----------------------------------------------------------------------- | :-: | :-: |
| 2.1.1 | 验证用户输入是否与持续更新的已知提示注入模式库进行筛选（越狱关键词、“忽略先前”、角色扮演链、间接的HTML/URL攻击）。          |  1  | D/V |
| 2.1.2 | 验证系统是否强制执行一个指令层次结构，在该层次结构中，系统或开发者消息会覆盖用户指令，即使在上下文窗口扩展后也如此。              |  1  | D/V |
| 2.1.3 | 请验证在每次模型或提示模板发布之前，是否执行对抗性评估测试（例如红队“many-shot”提示），并设定成功率阈值以及用于回归的自动阻止机制。 |  2  | D/V |
| 2.1.4 | 验证来自第三方内容（网页、PDF、电子邮件）的提示，在被拼接到主提示之前，是否在一个隔离的解析上下文中进行净化。                |  2  |  D  |
| 2.1.5 | 验证所有提示过滤规则更新、分类器模型版本以及阻止名单变更均已进行版本控制且可审计。                               |  3  | D/V |

---

## C2.2 对抗-样本鲁棒性

自然语言处理（NLP）模型仍然容易受到微小的字符级或词级扰动的影响，这些扰动人类往往察觉不到，但模型往往会将其错误分类。

|   #   | 描述                                                  | 等级  | 角色  |
| :---: | --------------------------------------------------- | :-: | :-: |
| 2.2.1 | 请确认基本输入规范化步骤（Unicode NFC 归一化、同形字映射、去除前后空白）在分词之前执行。  |  1  |  D  |
| 2.2.2 | 验证统计异常检测是否会对那些与语言规范相比编辑距离异常高、重复标记过多，或嵌入距离异常的输入进行标记。 |  2  | D/V |
| 2.2.3 | 验证推理管线是否支持用于高风险端点的可选对抗性训练–加固模型变体或防御层（例如，随机化、防御性蒸馏）。 |  2  |  D  |
| 2.2.4 | 验证疑似对抗性输入是否已被隔离，在进行 PII 脱敏后，将完整有效载荷记录到日志中。          |  2  |  V  |
| 2.2.5 | 验证鲁棒性指标（已知攻击套件的成功率）是否随时间进行跟踪，若出现回归，则触发发布阻塞。         |  3  | D/V |

---

## C2.3 模式、类型与长度验证

包含格式错误或超大输入的人工智能攻击可能导致解析错误、跨字段的提示信息溢出，以及资源耗尽。在执行确定性工具调用时，严格的模式约束也是前提条件。

|   #   | 描述                                                                          | 等级  | 角色  |
| :---: | --------------------------------------------------------------------------- | :-: | :-: |
| 2.3.1 | 验证每个 API 或函数调用端点是否定义了明确的输入模式（JSON Schema、Protobuf 或多模态等效物），并在组装提示之前对输入进行验证。 |  1  |  D  |
| 2.3.2 | 验证超过最大 token 数量或字节上限的输入将被安全地拒绝，并且不会被静默截断。                                   |  1  | D/V |
| 2.3.3 | 验证类型检查（例如数值范围、枚举值、图像/音频的 MIME 类型）是否在服务器端强制执行，而不仅仅在客户端代码中。                   |  2  | D/V |
| 2.3.4 | 验证语义验证器（例如 JSON Schema）是否在常数时间内运行，以防止算法性 DoS 攻击。                            |  2  |  D  |
| 2.3.5 | 核实验证失败是否已被记录，并且带有经过脱敏的有效载荷片段和明确的错误代码，以帮助安全事件分诊。                             |  3  |  V  |

---

## C2.4 内容与政策筛查

开发者应能够检测出在语法上有效、但请求包含禁止内容的提示，然后阻止它们的传播。

|   #   | 描述                                                          | 等级  | 角色  |
| :---: | ----------------------------------------------------------- | :-: | :-: |
| 2.4.1 | 验证一个内容分类器（零样本/微调）是否对每个输入在暴力、自残、仇恨、性内容和非法请求方面进行评分，并具备可配置的阈值。 |  1  |  D  |
| 2.4.2 | 验证违反政策的输入将收到标准化拒绝或安全完成，以确保它们不会传播到下游的 LLM 调用。                |  1  | D/V |
| 2.4.3 | 验证筛选模型或规则集至少每季度重新训练/更新一次，并将新近观测到的越狱或策略绕过模式纳入其中。             |  2  |  D  |
| 2.4.4 | 验证筛选是否遵守用户特定的政策（年龄、区域性法律约束），这些规则通过在请求时解析的基于属性的规则来实现。        |  2  |  D  |
| 2.4.5 | 请验证筛查日志是否包含分类器置信度分数和策略类别标签，用于与 SOC 的相关性分析以及未来的红队回放。         |  3  |  V  |

---

## C2.5 输入速率限制 & 滥用防护

开发者应通过限制输入速率和检测异常使用模式来防止对人工智能系统的滥用、资源耗尽和自动化攻击。

|   #   | 描述                                      | 等级  | 角色  |
| :---: | --------------------------------------- | :-: | :-: |
| 2.5.1 | 验证是否对所有输入端点强制执行按用户、按 IP 和按 API 密钥的速率限制。 |  1  | D/V |
| 2.5.2 | 验证突发和持续的速率限制是否已调优，以防止 DoS 攻击和暴力破解攻击。    |  2  | D/V |
| 2.5.3 | 验证异常使用模式（例如，快速连发请求、输入泛滥）是否会触发自动封锁或升级流程。 |  2  | D/V |
| 2.5.4 | 验证滥用防护日志是否已被保留并用于识别新兴的攻击模式。             |  3  |  V  |

---

## C2.6 多模态输入验证

AI 系统应对非文本输入（图像、音频、文件）进行健壮性验证，以防止注入、规避或资源滥用。

|   #   | 描述                                  | 等级  | 角色  |
| :---: | ----------------------------------- | :-: | :-: |
| 2.6.1 | 在处理之前，验证所有非文本输入（图像、音频、文件）的类型、大小和格式。 |  1  |  D  |
| 2.6.2 | 在导入之前，请对文件进行恶意软件和隐写载荷的扫描。           |  2  | D/V |
| 2.6.3 | 验证图像/音频输入是否已针对对抗性扰动或已知攻击模式进行检测。     |  2  | D/V |
| 2.6.4 | 验证多模态输入验证失败是否已被记录并触发用于调查的告警。        |  3  |  V  |

---

## C2.7 输入溯源与归因

AI 系统应通过监控并标记所有用户输入的来源来支持审计、滥用追踪和合规性。

|   #   | 描述                                            | 等级  | 角色  |
| :---: | --------------------------------------------- | :-: | :-: |
| 2.7.1 | 在数据摄取时，请确保所有用户输入都带有元数据（用户ID、会话、来源、时间戳、IP 地址）。 |  1  | D/V |
| 2.7.2 | 确保对所有已处理输入的溯源元数据得以保留并可审计。                     |  2  | D/V |
| 2.7.3 | 请确认异常或不受信任的输入源已被标记，并对其进行加强审查或阻断。              |  2  | D/V |

---

## C2.8 实时自适应威胁检测

开发人员应采用面向人工智能的先进威胁检测系统，这些系统能够适应新的攻击模式，并通过编译的模式匹配提供实时保护。

|   #   | 描述                                               | 等级  | 角色  |
| :---: | ------------------------------------------------ | :-: | :-: |
| 2.8.1 | 验证威胁检测模式是否已编译为优化的正则表达式引擎，以实现高性能的实时过滤，并将延迟影响降至最低。 |  1  | D/V |
| 2.8.2 | 验证威胁检测系统是否为不同威胁类别维护单独的模式库（提示注入、有害内容、敏感数据、系统命令）。  |  1  | D/V |
| 2.8.3 | 验证自适应威胁检测是否包含根据攻击频率和成功率更新威胁敏感度的机器学习模型。           |  2  | D/V |
| 2.8.4 | 验证实时威胁情报源是否会自动使用新的攻击签名和 IOcs（妥协指标）来更新模式库。        |  2  | D/V |
| 2.8.5 | 验证威胁检测的误报率是否在持续监控，并自动调整模式特异性，以尽量减少对合法用例的干扰。      |  3  | D/V |
| 2.8.6 | 验证情境威胁分析是否考虑输入来源、用户行为模式和会话历史，以提高检测准确性。           |  3  | D/V |
| 2.8.7 | 验证威胁检测性能指标（检测率、处理延迟、资源利用率）是否在实时监控并优化。            |  3  | D/V |

---

## C2.9 多模态安全验证流水线

开发人员应为文本、图像、音频以及其他 AI 输入模态提供安全性验证，并采用特定类型的威胁检测与资源隔离。

|   #   | 描述                                                                                   | 等级  | 角色  |
| :---: | ------------------------------------------------------------------------------------ | :-: | :-: |
| 2.9.1 | 验证 每种 输入 模态 是否 拥有 专用 的 安全 验证 器 并 具有 有 文档化 的 威胁 模式（文本：提示注入，图像：隐写术，音频：声谱图 攻击）以及 检测 阈值。 |  1  | D/V |
| 2.9.2 | 验证多模态输入是否在隔离的沙箱中进行处理，并设定明确定义的资源限制（内存、CPU、处理时间），这些限制针对每种模态类型，并在安全策略中有文档记录。            |  2  | D/V |
| 2.9.3 | 验证跨模态攻击检测是否能够识别跨越多种输入类型的协同攻击，并通过相关性规则实现告警生成。                                         |  2  | D/V |
| 2.9.4 | 验证多模态验证失败是否会触发详细日志记录，包括所有输入模态、验证结果、威胁分数，以及使用结构化日志格式的相关性分析，以便与 SIEM 集成。               |  3  | D/V |
| 2.9.5 | 验证按文档化日程（至少每季度一次）更新模态特定的内容分类器，并确保包含新的威胁模式、对抗样本，以及性能基准保持高于基线阈值。                       |  3  | D/V |

---

## 参考文献

* [LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security](https://genai.owasp.org/llmrisk/llm01-prompt-injection/)
* [Generative AI's Biggest Security Flaw Is Not Easy to Fix](https://www.wired.com/story/generative-ai-prompt-injection-hacking)
* [Many-shot jailbreaking \ Anthropic](https://www.anthropic.com/research/many-shot-jailbreaking)
* [$PDF$ OpenAI GPT-4.5 System Card](https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf)
* [Notebook for the CheckThat Lab at CLEF 2024](https://ceur-ws.org/Vol-3740/paper-53.pdf)
* [Mitigate jailbreaks and prompt injections – Anthropic](https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks)
* [Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis](https://ama.drwhy.ai/mitre-attck.html)
* [OWASP Top 10 for LLM Applications 2025 – WorldTech IT](https://wtit.com/blog/2025/04/17/owasp-top-10-for-llm-applications-2025/)
* [OWASP Machine Learning Security Top Ten](https://owasp.org/www-project-machine-learning-security-top-10/)
* [Few words about AI Security – Jussi Metso](https://www.jussimetso.com/index.php/2024/09/28/few-words-about-ai-security/)
* [How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry](https://modelmetry.com/blog/how-to-ensure-llm-output-adheres-to-a-json-schema)
* [Easily enforcing valid JSON schema following – API](https://community.openai.com/t/feature-request-function-calling-easily-enforcing-valid-json-schema-following/263515?utm_source)
* [AI Safety + Cybersecurity R\&D Tracker – Fairly AI](https://www.fairly.ai/blog/ai-cybersecurity-tracker)
* [Anthropic makes 'jailbreak' advance to stop AI models producing harmful results](https://www.ft.com/content/cf11ebd8-aa0b-4ed4-945b-a5d4401d186e)
* [Pattern matching filter rules - IBM](https://www.ibm.com/docs/ssw_aix_71/security/intrusion_pattern_matching_filter_rules.html)
* [Real-time Threat Detection](https://www.darktrace.com/cyber-ai-glossary/real-time-threat-detection)

