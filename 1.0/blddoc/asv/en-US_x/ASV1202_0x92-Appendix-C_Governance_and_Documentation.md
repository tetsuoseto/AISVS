# Appendix C: AI Security Governance & Documentation

## Objective

This appendix outlines the foundational requirements for establishing organizational structures, policies, and processes to govern AI security throughout the system lifecycle.

---

## AC.1 AI Risk Management Framework Adoption

Provide a formal framework for identifying, assessing, and mitigating AI‑specific risks throughout the system lifecycle.

|   #    | Description                                                                                                    | Level | Role |
| :----: | -------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| AC.1.1 | Verify that an AI‑specific risk assessment methodology is documented and implemented.                          |   1   | D/V  |
| AC.1.2 | Verify that risk assessments are conducted at key points in the AI lifecycle and prior to significant changes. |   2   |  D   |
| AC.1.3 | Verify that the risk management framework aligns with established standards, such as the NIST AI RMF.          |   3   | D/V  |

---

## AC.2 AI Security Policy & Procedures

Define and enforce organizational standards for secure AI development, deployment, and operation.

|   #    | Description                                                                                                     | Level | Role |
| :----: | --------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| AC.2.1 | Verify that the documented AI security policies exist.                                                          |   1   | D/V  |
| AC.2.2 | Verify that policies are reviewed and updated at least annually and after significant threat‑landscape changes. |   2   |  D   |
| AC.2.3 | Verify that policies address all AISVS categories and any applicable regulatory requirements.                   |   3   | D/V  |

---

## AC.3 Roles and Responsibilities for AI Security

Establish clear accountability for AI security across the organization.

|   #    | Description                                                                                           | Level | Role |
| :----: | ----------------------------------------------------------------------------------------------------- | :---: | :--: |
| AC.3.1 | Verify that the roles and responsibilities for AI security are documented.                            |   1   | D/V  |
| AC.3.2 | Verify that responsible individuals possess the appropriate security expertise.                       |   2   |  D   |
| AC.3.3 | Verify that an AI ethics committee or governance board has been established for high‑risk AI systems. |   3   | D/V  |

---

## AC.4: Ethical AI Guidelines Enforcement

Ensure that AI systems operate according to established ethical principles.

|   #    | Description                                                                        | Level | Role |
| :----: | ---------------------------------------------------------------------------------- | :---: | :--: |
| AC.4.1 | Verify that ethical guidelines for AI development and deployment exist.            |   1   | D/V  |
| AC.4.2 | Verify that there are mechanisms in place to detect and report ethical violations. |   2   |  D   |
| AC.4.3 | Verify that regular ethical reviews of deployed AI systems are conducted.          |   3   | D/V  |

---

## AC.5 AI Regulatory Compliance Monitoring

Maintain awareness of and compliance with evolving AI regulations.

|   #    | Description                                                                      | Level | Role |
| :----: | -------------------------------------------------------------------------------- | :---: | :--: |
| AC.5.1 | Verify that processes are in place to identify applicable AI regulations.        |   1   | D/V  |
| AC.5.2 | Verify that compliance with all regulatory requirements is assessed.             |   2   |  D   |
| AC.5.3 | Ensure that regulatory changes trigger timely reviews and updates to AI systems. |   3   | D/V  |

## AC.6 Training Data Governance, Documentation, and Process

|   #    | Description                                                                                                                                                                                                                                                                                                                           | Level | Role |        |                                                                                                                          |     |     |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: | ------ | ------------------------------------------------------------------------------------------------------------------------ | --- | --- |
| 1.1.2  | Verify that only datasets vetted for quality, representativeness, ethical sourcing, and license compliance are allowed, thereby reducing the risks of data poisoning, embedded bias, and intellectual property infringement.                                                                                                          |   1   | D/V  |        |                                                                                                                          |     |     |
| 1.1.5  | Verify that labeling and annotation quality is ensured through reviewer cross-checks or consensus.                                                                                                                                                                                                                                    |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.1.6  | Verify that data cards or datasheets for datasets are maintained for significant training datasets, detailing their characteristics, motivations, composition, collection processes, preprocessing steps, and recommended or discouraged uses.                                                                                        |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.3.2  | Verify that identified biases are mitigated through documented strategies such as re-balancing, targeted data augmentation, algorithmic adjustments (e.g., pre-processing, in-processing, post-processing techniques), or re-weighting, and that the impact of mitigation on both fairness and overall model performance is assessed. |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.3.3  | Verify that post-training fairness metrics have been evaluated and documented.                                                                                                                                                                                                                                                        |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.3.4  | Verify that a lifecycle bias-management policy assigns owners and a review cadence.                                                                                                                                                                                                                                                   |   3   | D/V  |        |                                                                                                                          |     |     |
| 1.4.1  | Verify that labeling/annotation quality is ensured through clear guidelines, reviewer cross-checks, consensus mechanisms (e.g., monitoring inter-annotator agreement), and defined processes for resolving discrepancies.                                                                                                             |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.4.4  | Verify that labels critical to safety, security, or fairness (e.g., identifying toxic content or critical medical findings) receive mandatory independent dual review or an equivalent robust verification.                                                                                                                           |   3   | D/V  |        |                                                                                                                          |     |     |
| 1.4.6  | Verify that labeling guides and instructions are comprehensive, version-controlled, and peer-reviewed.                                                                                                                                                                                                                                |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.4.6  | Verify that the data schemas for labels are clearly defined and version-controlled.                                                                                                                                                                                                                                                   |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.3.1  | Verify that datasets are profiled for representational imbalance and potential biases across legally protected attributes (e.g., race, gender, age) and other ethically sensitive characteristics relevant to the model's application domain (e.g., socio-economic status, location).                                                 |   1   | D/V  |        |                                                                                                                          |     |     |
| 1.5.3  | Verify that manual spot-checks by domain experts cover a statistically significant sample (e.g., ≥1% or 1,000 samples, whichever is greater, or as determined by risk assessment) to identify subtle quality issues that automation does not catch.                                                                                   |   2   |  V   |        |                                                                                                                          |     |     |
| 1.8.4  | Verify that outsourced or crowdsourced labeling workflows incorporate technical and procedural safeguards to ensure data confidentiality, data integrity, and label quality, and to prevent data leakage.                                                                                                                             |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.5.4  | Verify that remediation steps are appended to provenance records.                                                                                                                                                                                                                                                                     |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.6.2  | Verify that flagged samples trigger a manual review before training.                                                                                                                                                                                                                                                                  |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.6.3  | Verify that the results feed the model's security dossier and inform ongoing threat intelligence.                                                                                                                                                                                                                                     |   2   |  V   |        |                                                                                                                          |     |     |
| 1.6.4  | Verify that the detection logic is refreshed with new threat intelligence.                                                                                                                                                                                                                                                            |   3   | D/V  |        |                                                                                                                          |     |     |
| 1.6.5  | Verify that online-learning pipelines monitor distribution drift.                                                                                                                                                                                                                                                                     |   3   | D/V  |        |                                                                                                                          |     |     |
| 1.7.1  | Verify that training data deletion workflows purge both primary and derived data and assess their impact on the models, and ensure that the impact on affected models is evaluated and, if necessary, addressed (e.g., through retraining or recalibration).                                                                          |   1   | D/V  |        |                                                                                                                          |     |     |
| 1.7.2  | Verify that mechanisms exist to track and respect the scope and status of user consent (including withdrawals) for data used in training, and that consent is validated before data is incorporated into new training processes or significant model updates.                                                                         |   2   |  D   |        |                                                                                                                          |     |     |
| 1.7.3  | Verify that workflows are tested and logged annually.                                                                                                                                                                                                                                                                                 |   2   |  V   |        |                                                                                                                          |     |     |
| 1.8.1  | Verify that third-party data suppliers, including providers of pre-trained models and external datasets, undergo security, privacy, ethical sourcing, and data quality due diligence before their data or models are integrated.                                                                                                      |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.8.2  | Verify that external transfers use TLS and authentication, along with integrity checks.                                                                                                                                                                                                                                               |   1   |  D   |        |                                                                                                                          |     |     |
| 1.8.3  | Verify that high-risk data sources (e.g., open-source datasets with unknown provenance or unvetted suppliers) receive enhanced scrutiny—such as sandboxed analysis, extensive quality and bias checks, and targeted poisoning detection—before being used in sensitive applications.                                                  |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.8.4  | Verify that pre-trained models obtained from third parties are evaluated for embedded biases, potential backdoors, the integrity of their architecture, and the provenance of their original training data before they are fine-tuned or deployed.                                                                                    |   3   | D/V  |        |                                                                                                                          |     |     |
| 1.5.3  | Verify that, when adversarial training is used, the generation, management, and versioning of adversarial datasets are documented and controlled.                                                                                                                                                                                     |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.5.3  | Verify that the impact of adversarial robustness training on model performance (for both clean and adversarial inputs) and on fairness metrics is evaluated, documented, and monitored.                                                                                                                                               |   3   | D/V  |        |                                                                                                                          |     |     |
| 1.5.4  | Ensure that strategies for adversarial training and robustness are periodically reviewed and updated to counter evolving adversarial attack techniques.                                                                                                                                                                               |   3   | D/V  |        |                                                                                                                          |     |     |
| 1.4.2  | Verify that failed datasets are quarantined and have audit trails.                                                                                                                                                                                                                                                                    |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.4.3  | Verify that quality gates block subpar datasets unless exceptions are approved.                                                                                                                                                                                                                                                       |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.11.2 | Verify that the generation process, the parameters, and the intended use of synthetic data are documented.                                                                                                                                                                                                                            |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.11.3 | Verify that synthetic data has been risk-assessed for bias, privacy leakage, and representational issues before use in training.                                                                                                                                                                                                      |   2   | D/V  | 1.12.2 | Verify that access logs are reviewed regularly for unusual patterns, such as large exports or access from new locations. | 2   | D/V |
| 1.12.3 | Verify that alerts are generated for suspicious access events and that they are investigated promptly.                                                                                                                                                                                                                                |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.13.1 | Verify that explicit retention periods are defined for all training datasets.                                                                                                                                                                                                                                                         |   1   | D/V  |        |                                                                                                                          |     |     |
| 1.13.2 | Verify that datasets are automatically expired, deleted, or reviewed for deletion at the end of their lifecycle.                                                                                                                                                                                                                      |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.13.3 | Verify that retention and deletion actions are logged and auditable.                                                                                                                                                                                                                                                                  |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.14.1 | Verify that data residency and cross-border transfer requirements are identified and enforced for all datasets.                                                                                                                                                                                                                       |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.14.2 | Verify that sector-specific regulations, such as those for healthcare and finance, are identified and addressed in data handling.                                                                                                                                                                                                     |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.14.3 | Verify that compliance with relevant privacy laws (e.g., GDPR, CCPA) is documented and regularly reviewed.                                                                                                                                                                                                                            |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.16.1 | Verify that mechanisms are in place to respond to data-subject requests for access, correction, restriction, or objection.                                                                                                                                                                                                            |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.16.2 | Verify that requests are logged, tracked, and fulfilled within legally mandated timeframes.                                                                                                                                                                                                                                           |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.16.3 | Verify that data subject rights processes are regularly tested and reviewed for effectiveness.                                                                                                                                                                                                                                        |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.17.1 | Verify that an impact analysis is conducted before updating or replacing a dataset version, and that it covers model performance, fairness, and compliance.                                                                                                                                                                           |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.17.2 | Verify that the results of the impact analysis are documented and reviewed by the relevant stakeholders.                                                                                                                                                                                                                              |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.17.3 | Verify that rollback plans are in place in case new versions introduce unacceptable risks or regressions.                                                                                                                                                                                                                             |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.18.1 | Verify that all personnel involved in data annotation have undergone background checks and are trained in data security and privacy.                                                                                                                                                                                                  |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.18.2 | Verify that all annotation personnel have signed confidentiality and non-disclosure agreements.                                                                                                                                                                                                                                       |   2   | D/V  |        |                                                                                                                          |     |     |
| 1.18.3 | Verify that annotation platforms enforce access controls and monitor for insider threats.                                                                                                                                                                                                                                             |   2   | D/V  |        |                                                                                                                          |     |     |

### References

* [NIST AI Risk Management Framework 1.0](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [ISO/IEC 42001:2023 — AI Management Systems Requirements](https://www.iso.org/standard/81230.html)
* [ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management](https://www.iso.org/standard/77304.html)
* [EU Artificial Intelligence Act — Regulation (EU) 2024/1689](https://eur-lex.europa.eu/eli/reg/2024/1689/oj)
* [ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods](https://www.iso.org/standard/79804.html)

