# Appendix C: AI Security Governance & Documentation

## Objective

This appendix outlines the fundamental requirements for creating organizational structures, policies, and processes to manage AI security throughout the system lifecycle.

---

## AC.1 AI Risk Management Framework Adoption

Provide a formal framework to identify, assess, and mitigate AI-specific risks throughout the system lifecycle.

|   #    | Description                                                                                                           | Level | Role |
| :----: | --------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| AC.1.1 | Verify that an AI-specific risk assessment methodology is documented and implemented.                                 |   1   | D/V  |
| AC.1.2 | Ensure that risk assessments are conducted at critical stages in the AI lifecycle and before any significant changes. |   2   |  D   |
| AC.1.3 | Verify that the risk management framework aligns with established standards (e.g., NIST AI RMF).                      |   3   | D/V  |

---

## AC.2 AI Security Policy and Procedures

Establish and enforce organizational standards for the secure development, deployment, and operation of AI.

|   #    | Description                                                                                                                   | Level | Role |
| :----: | ----------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| AC.2.1 | Verify that documented AI security policies are in place.                                                                     |   1   | D/V  |
| AC.2.2 | Verify that policies are reviewed and updated at least once a year and following significant changes in the threat landscape. |   2   |  D   |
| AC.2.3 | Verify that policies cover all AISVS categories and comply with applicable regulatory requirements.                           |   3   | D/V  |

---

## AC.3 Roles and Responsibilities for AI Security

Establish clear accountability for AI security throughout the organization.

|   #    | Description                                                                                     | Level | Role |
| :----: | ----------------------------------------------------------------------------------------------- | :---: | :--: |
| AC.3.1 | Verify that AI security roles and responsibilities are properly documented.                     |   1   | D/V  |
| AC.3.2 | Ensure that responsible individuals have the appropriate security expertise.                    |   2   |  D   |
| AC.3.3 | Ensure that an AI ethics committee or governance board is established for high-risk AI systems. |   3   | D/V  |

---

## AC.4 Enforcement of Ethical AI Guidelines

Ensure AI systems operate according to established ethical principles.

|   #    | Description                                                                     | Level | Role |
| :----: | ------------------------------------------------------------------------------- | :---: | :--: |
| AC.4.1 | Confirm that ethical guidelines for AI development and deployment are in place. |   1   | D/V  |
| AC.4.2 | Ensure that mechanisms are in place to detect and report ethical violations.    |   2   |  D   |
| AC.4.3 | Ensure that regular ethical reviews of deployed AI systems are conducted.       |   3   | D/V  |

---

## AC.5 AI Regulatory Compliance Monitoring

Stay informed about and comply with evolving AI regulations.

|   #    | Description                                                                     | Level | Role |
| :----: | ------------------------------------------------------------------------------- | :---: | :--: |
| AC.5.1 | Ensure that processes are in place to identify applicable AI regulations.       |   1   | D/V  |
| AC.5.2 | Verify that compliance with all regulatory requirements has been assessed.      |   2   |  D   |
| AC.5.3 | Ensure that regulatory changes prompt timely reviews and updates of AI systems. |   3   | D/V  |

## AC.6 Training Data Governance, Documentation, and Process

|   #    | Description                                                                                                                                                                                                                                                                                                                                    | Level | Role |        |                                                                                                                               |     |     |
| :----: | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: | ------ | ----------------------------------------------------------------------------------------------------------------------------- | --- | --- |
| 1.1.2  | Ensure that only datasets verified for quality, representativeness, ethical sourcing, and license compliance are used, minimizing risks of data poisoning, embedded bias, and intellectual property infringement.                                                                                                                              |   1   | D/V  |        |                                                                                                                               |     |     |
| 1.1.5  | Verify that labeling/annotation quality is ensured through reviewer cross-checks or consensus.                                                                                                                                                                                                                                                 |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.1.6  | Ensure that "data cards" or "datasheets for datasets" are maintained for significant training datasets, providing details on characteristics, motivations, composition, collection processes, preprocessing, and recommended or discouraged uses.                                                                                              |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.3.2  | Verify that the identified biases are mitigated using documented strategies such as re-balancing, targeted data augmentation, algorithmic adjustments (e.g., pre-processing, in-processing, post-processing techniques), or re-weighting, and ensure that the impact of mitigation on both fairness and overall model performance is assessed. |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.3.3  | Ensure that post-training fairness metrics are evaluated and documented.                                                                                                                                                                                                                                                                       |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.3.4  | Verify that a lifecycle bias management policy designates owners and establishes a review cadence.                                                                                                                                                                                                                                             |   3   | D/V  |        |                                                                                                                               |     |     |
| 1.4.1  | Ensure labeling and annotation quality through clear guidelines, reviewer cross-checks, consensus mechanisms (such as monitoring inter-annotator agreement), and established processes for resolving discrepancies.                                                                                                                            |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.4.4  | Ensure that labels critical to safety, security, or fairness (e.g., identifying toxic content or critical medical findings) undergo mandatory independent dual review or an equivalent robust verification process.                                                                                                                            |   3   | D/V  |        |                                                                                                                               |     |     |
| 1.4.6  | Ensure that labeling guides and instructions are thorough, version-controlled, and peer-reviewed.                                                                                                                                                                                                                                              |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.4.6  | Ensure that data schemas for labels are clearly defined and version-controlled.                                                                                                                                                                                                                                                                |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.3.1  | Verify that datasets are analyzed for representational imbalance and potential biases across legally protected attributes (e.g., race, gender, age) and other ethically sensitive characteristics relevant to the model’s application domain (e.g., socio-economic status, location).                                                          |   1   | D/V  |        |                                                                                                                               |     |     |
| 1.5.3  | Ensure that manual spot-checks conducted by domain experts cover a statistically significant sample size (e.g., ≥1% or 1,000 samples, whichever is greater, or as determined by a risk assessment) to detect subtle quality issues that automation might miss.                                                                                 |   2   |  V   |        |                                                                                                                               |     |     |
| 1.8.4  | Verify that outsourced or crowdsourced labeling workflows incorporate technical and procedural safeguards to ensure data confidentiality, integrity, label quality, and to prevent data leakage.                                                                                                                                               |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.5.4  | Verify that remediation steps are appended to the provenance records.                                                                                                                                                                                                                                                                          |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.6.2  | Confirm that flagged samples initiate manual review before training.                                                                                                                                                                                                                                                                           |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.6.3  | Verify that the results feed into the model's security dossier and inform ongoing threat intelligence.                                                                                                                                                                                                                                         |   2   |  V   |        |                                                                                                                               |     |     |
| 1.6.4  | Verify that the detection logic is updated with new threat intelligence.                                                                                                                                                                                                                                                                       |   3   | D/V  |        |                                                                                                                               |     |     |
| 1.6.5  | Ensure that online learning pipelines monitor for distribution drift.                                                                                                                                                                                                                                                                          |   3   | D/V  |        |                                                                                                                               |     |     |
| 1.7.1  | Verify that training data deletion workflows remove both primary and derived data, assess the impact on the model, and, if necessary, address the impact on affected models (e.g., through retraining or recalibration).                                                                                                                       |   1   | D/V  |        |                                                                                                                               |     |     |
| 1.7.2  | Ensure that mechanisms are in place to track and honor the scope and status of user consent (including withdrawals) for data used in training, and verify that consent is validated before the data is incorporated into new training processes or major model updates.                                                                        |   2   |  D   |        |                                                                                                                               |     |     |
| 1.7.3  | Ensure that workflows are tested annually and properly logged.                                                                                                                                                                                                                                                                                 |   2   |  V   |        |                                                                                                                               |     |     |
| 1.8.1  | Ensure that third-party data suppliers, including providers of pre-trained models and external datasets, undergo due diligence for security, privacy, ethical sourcing, and data quality before their data or models are integrated.                                                                                                           |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.8.2  | Verify that external transfers utilize TLS/authentication and integrity checks.                                                                                                                                                                                                                                                                |   1   |  D   |        |                                                                                                                               |     |     |
| 1.8.3  | Ensure that high-risk data sources (e.g., open-source datasets with unknown provenance or unvetted suppliers) undergo enhanced scrutiny—such as sandboxed analysis, thorough quality and bias assessments, and targeted poisoning detection—before being used in sensitive applications.                                                       |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.8.4  | Verify that pre-trained models obtained from third parties are evaluated for embedded biases, potential backdoors, the integrity of their architecture, and the provenance of their original training data before fine-tuning or deployment.                                                                                                   |   3   | D/V  |        |                                                                                                                               |     |     |
| 1.5.3  | Verify that when adversarial training is used, the generation, management, and versioning of adversarial datasets are properly documented and controlled.                                                                                                                                                                                      |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.5.3  | Ensure that the impact of adversarial robustness training on model performance (for both clean and adversarial inputs) and fairness metrics is evaluated, documented, and monitored.                                                                                                                                                           |   3   | D/V  |        |                                                                                                                               |     |     |
| 1.5.4  | Ensure that strategies for adversarial training and robustness are periodically reviewed and updated to address evolving adversarial attack techniques.                                                                                                                                                                                        |   3   | D/V  |        |                                                                                                                               |     |     |
| 1.4.2  | Verify that failed datasets are quarantined with audit trails.                                                                                                                                                                                                                                                                                 |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.4.3  | Verify that quality gates block subpar datasets unless exceptions are approved.                                                                                                                                                                                                                                                                |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.11.2 | Ensure that the generation process, parameters, and intended use of synthetic data are thoroughly documented.                                                                                                                                                                                                                                  |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.11.3 | Ensure that synthetic data undergoes a risk assessment for bias, privacy leakage, and representational issues before being used for training.                                                                                                                                                                                                  |   2   | D/V  | 1.12.2 | Ensure that access logs are regularly reviewed for unusual patterns, such as large data exports or access from new locations. | 2   | D/V |
| 1.12.3 | Verify that alerts are generated for suspicious access events and investigated promptly.                                                                                                                                                                                                                                                       |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.13.1 | Verify that explicit retention periods are established for all training datasets.                                                                                                                                                                                                                                                              |   1   | D/V  |        |                                                                                                                               |     |     |
| 1.13.2 | Verify that datasets are automatically expired, deleted, or reviewed for deletion at the end of their lifecycle.                                                                                                                                                                                                                               |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.13.3 | Ensure that retention and deletion actions are logged and can be audited.                                                                                                                                                                                                                                                                      |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.14.1 | Ensure that data residency and cross-border transfer requirements are identified and enforced for all datasets.                                                                                                                                                                                                                                |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.14.2 | Verify that sector-specific regulations (e.g., healthcare, finance) are identified and properly addressed in data handling.                                                                                                                                                                                                                    |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.14.3 | Ensure that compliance with applicable privacy laws (e.g., GDPR, CCPA) is documented and reviewed regularly.                                                                                                                                                                                                                                   |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.16.1 | Verify that mechanisms are in place to respond to data subject requests for access, rectification, restriction, or objection.                                                                                                                                                                                                                  |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.16.2 | Verify that requests are logged, tracked, and fulfilled within legally mandated timeframes.                                                                                                                                                                                                                                                    |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.16.3 | Verify that data subject rights processes are regularly tested and reviewed for effectiveness.                                                                                                                                                                                                                                                 |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.17.1 | Ensure that an impact analysis is conducted before updating or replacing a dataset version, addressing model performance, fairness, and compliance.                                                                                                                                                                                            |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.17.2 | Ensure that the results of the impact analysis are documented and reviewed by the appropriate stakeholders.                                                                                                                                                                                                                                    |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.17.3 | Verify that rollback plans are in place in case new versions introduce unacceptable risks or regressions.                                                                                                                                                                                                                                      |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.18.1 | Verify that all personnel involved in data annotation have undergone background checks and are trained in data security and privacy.                                                                                                                                                                                                           |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.18.2 | Ensure that all annotation personnel sign confidentiality and non-disclosure agreements.                                                                                                                                                                                                                                                       |   2   | D/V  |        |                                                                                                                               |     |     |
| 1.18.3 | Ensure that annotation platforms enforce access controls and monitor for insider threats.                                                                                                                                                                                                                                                      |   2   | D/V  |        |                                                                                                                               |     |     |

### References

* [NIST AI Risk Management Framework 1.0](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [ISO/IEC 42001:2023 — AI Management Systems Requirements](https://www.iso.org/standard/81230.html)
* [ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management](https://www.iso.org/standard/77304.html)
* [EU Artificial Intelligence Act — Regulation (EU) 2024/1689](https://eur-lex.europa.eu/eli/reg/2024/1689/oj)
* [ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods](https://www.iso.org/standard/79804.html)

