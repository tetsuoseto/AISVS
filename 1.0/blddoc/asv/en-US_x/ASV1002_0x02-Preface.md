# Preface

Welcome to version 1.0 of the Artificial Intelligence Security Verification Standard (AISVS)!

## Introduction

Established in 2025 through a collaborative community effort, AISVS defines the security requirements to consider when designing, developing, deploying, and operating modern AI models, pipelines, and AI-enabled services.

AISVS v1.0 represents the collaborative effort of its project leads, working group, and broader community contributors to create a practical, testable baseline for securing AI systems.

Our goal with this release is to make AISVS easy to adopt while remaining sharply focused on its defined scope and addressing the rapidly evolving risk landscape unique to AI.

## Key Objectives for AISVS Version 1.0

Version 1.0 will be developed based on several guiding principles.

### Well-Defined Scope

Each requirement must align with AISVS's name and mission:

* Artificial Intelligence – Controls operate at the AI/ML layer (data, model, pipeline, or inference) and are the responsibility of AI practitioners.
* Security – Requirements directly address identified security, privacy, or safety risks.
* Verification – The language is written to allow objective validation of conformance.
* Standard – Sections follow a consistent structure and terminology to create a coherent reference.
  ​
---

By following AISVS, organizations can systematically assess and enhance the security posture of their AI solutions, promoting a culture of secure AI engineering.

