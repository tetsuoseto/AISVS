# Preface

Welcome to version 1.0 of the Artificial Intelligence Security Verification Standard (AISVS)!

## Introduction

Established in 2025 through a collaborative community effort, AISVS defines the security requirements to consider when designing, developing, deploying, and operating modern AI models, pipelines, and AI-enabled services.

AISVS v1.0 represents the collaborative effort of its project leads, working group, and broader community contributors to establish a practical, testable baseline for securing AI systems.

Our goal with this release is to make AISVS easy to adopt while remaining sharply focused on its defined scope and addressing the rapidly evolving risk landscape unique to AI.

## Key Objectives for AISVS Version 1.0

Version 1.0 will be developed based on several guiding principles.

### Well-Defined Scope

Each requirement must align with AISVS's name and mission:

* Artificial Intelligence – Controls operate at the AI/ML layer (data, model, pipeline, or inference) and are the responsibility of AI practitioners.
* Security – Requirements directly address identified security, privacy, or safety risks.
* Verification – The language is written so conformance can be objectively validated.
* Standard – Sections follow a consistent structure and terminology to create a coherent reference.
  ​
---

By following AISVS, organizations can systematically evaluate and strengthen the security posture of their AI solutions, fostering a culture of secure AI engineering.

