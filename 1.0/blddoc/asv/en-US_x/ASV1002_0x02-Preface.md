# Preface

Welcome to the Artificial Intelligence Security Verification Standard (AISVS) version 1.0!

## Introduction

Established in 2025 through a collaborative community effort, AISVS defines the security requirements to consider when designing, developing, deploying, and operating modern AI models, pipelines, and AI-enabled services.

AISVS v1.0 represents the collaborative effort of its project leads, working group, and broader community contributors to establish a practical, testable baseline for securing AI systems.

Our goal with this release is to make AISVS easy to adopt while maintaining a sharp focus on its defined scope and addressing the rapidly evolving risk landscape unique to AI.

## Key Objectives for AISVS Version 1.0

Version 1.0 will be developed following several guiding principles.

### Clearly Defined Scope

Each requirement must align with AISVS's name and mission:

* Artificial Intelligence – Controls function at the AI/ML layer (data, model, pipeline, or inference) and fall under the responsibility of AI practitioners.
* Security – Requirements directly address identified security, privacy, or safety risks.
* Verification – The language is written to ensure conformance can be objectively validated.
* Standard – Sections follow a consistent structure and terminology to create a coherent reference.
  ​
---

By following AISVS, organizations can systematically assess and enhance the security posture of their AI solutions, promoting a culture of secure AI engineering.

