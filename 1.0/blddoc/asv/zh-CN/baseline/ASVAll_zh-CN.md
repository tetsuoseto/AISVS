## 封面

### 关于标准

人工智能安全验证标准（AISVS）是一个社区驱动的安全需求目录，供数据科学家、MLOps工程师、软件架构师、开发人员、测试人员、安全专家、工具供应商、监管机构和用户用于设计、构建、测试和验证可信赖的AI支持系统和应用。它为AI生命周期中的安全控制提供了统一的语言——从数据收集和模型开发到部署及持续监控——从而帮助组织衡量并提升其AI解决方案的弹性、隐私性和安全性。

### 版权与许可

版本 0.1（首个公开草稿 - 正在进行中），2025  

![license](images/license.png)
版权 © 2025 AISVS 项目。  

根据 Creative Commons Attribution‑ShareAlike 4.0 International License.
对于任何再使用或分发，您必须明确向他人传达本作品的许可条款。

### 项目负责人

吉姆·马尼科
Aras “Russ” Memisyazici

### 贡献者与审稿人

https://github.com/ottosulin
https://github.com/mbhatt1
https://github.com/vineethsai
https://github.com/cciprofm
https://github.com/deepakrpandey12


---

AISVS 是一个全新的标准，专门针对人工智能系统的独特安全挑战而创建。虽然它借鉴了更广泛的安全最佳实践，但 AISVS 中的每一项要求都是从零开始制定的，旨在反映 AI 威胁环境，并帮助组织构建更安全、更具韧性的 AI 解决方案。

## 前言

欢迎使用人工智能安全验证标准（AISVS）1.0版！

### 介绍

AISVS成立于2025年，是通过社区协作努力建立的，旨在定义设计、开发、部署和运营现代人工智能模型、流程及人工智能驱动服务时需考虑的安全要求。

AISVS v1.0 代表了其项目负责人、工作组以及更广泛社区贡献者的共同努力，旨在制定一个务实且可测试的人工智能系统安全基准。

我们此次发布的目标是使AISVS易于采用，同时始终聚焦其定义的范围，解决AI特有的快速演变的风险环境。

### AISVS 版本 1.0 的关键目标

版本1.0将根据若干指导原则创建。

#### 明确的范围

每个需求必须与AISVS的名称和使命保持一致：

人工智能——控制操作在AI/ML层（数据、模型、管道或推理），由AI从业人员负责。
安全性 – 需求直接缓解已识别的安全、隐私或安全风险。
验证 – 语言的编写方式能够客观地验证合规性。
标准 – 各部分遵循一致的结构和术语，以形成连贯的参考。
​
---

通过遵循 AISVS，组织可以系统地评估和增强其 AI 解决方案的安全态势，促进安全 AI 工程文化的形成。

## 使用 AISVS

人工智能安全验证标准（AISVS）定义了现代人工智能应用和服务的安全需求，重点关注应用开发人员可控的方面。

AISVS 适用于开发或评估人工智能应用安全性的任何人，包括开发人员、架构师、安全工程师和审核员。本章介绍了 AISVS 的结构和使用方法，包括其验证级别和预期的使用场景。

### 人工智能安全验证级别

AISVS 定义了三个逐级提升的安全验证级别。每个级别增加了深度和复杂性，使组织能够根据其 AI 系统的风险级别定制安全态势。

组织可以从一级开始，随着安全成熟度和威胁暴露的增加，逐步采用更高级别。

#### 级别定义

AISVS v1.0 中的每个需求都被分配到以下级别之一：

 一级要求

第一级包括最关键和基础的安全要求。这些要求侧重于防止不依赖其他前提条件或漏洞的常见攻击。大多数第一级控制措施要么实施起来较为简单，要么足够重要，值得付出努力。

 二级要求

第2级应对更高级或较少见的攻击，以及针对普遍威胁的多层防御。这些需求可能涉及更复杂的逻辑或针对特定攻击前提条件。

 三级要求

第3级包括通常更难实施或适用性有条件的控制措施。这些通常代表了纵深防御机制或针对小众、定向或高复杂度攻击的缓解措施。

#### 角色（D/V）

每个AISVS需求均根据主要受众进行标记：

D – 面向开发者的需求
V – 面向验证员/审计员的需求
D/V – 与开发者和验证者均相关

## C1 训练数据治理与偏差管理

### 控制目标

训练数据必须以保留来源、保障安全、保证质量和公正的方式进行获取、处理和维护。这样做既履行了法律义务，也减少了训练过程中可能出现影响整个人工智能生命周期的偏见、投毒或隐私泄露的风险。

---

### C1.1 训练数据来源

维护所有数据集的可验证清单，仅接受可信来源，并记录每次更改以便审计。

 #1.1.1    级别: 1    角色: D/V
 确保维护一份最新的所有训练数据来源的清单（来源、管理者/所有者、许可、收集方法、预期使用限制和处理历史）。
 #1.1.2    级别: 1    角色: D/V
 确认训练数据处理过程中排除了不必要的特征、属性或字段（例如，未使用的元数据、敏感的个人身份信息、泄露的测试数据）。
 #1.1.3    级别: 2    角色: D/V
 验证所有数据集更改均需经过记录的审批流程。
 #1.1.4    级别: 3    角色: D/V
 在可行的情况下，验证数据集或子集是否带有水印或指纹。

---

### C1.2 训练数据安全性与完整性

限制对训练数据的访问，对静态和传输中的数据进行加密，并验证其完整性，以防止篡改、盗窃或数据中毒。

 #1.2.1    级别: 1    角色: D/V
 验证访问控制是否保护训练数据存储和管道。
 #1.2.2    级别: 2    角色: D/V
 验证所有对训练数据的访问是否都有日志记录，包括用户、时间和操作。
 #1.2.3    级别: 2    角色: D/V
 验证训练数据集在传输和静止时均经过加密，使用行业标准的加密算法和密钥管理规范。
 #1.2.4    级别: 2    角色: D/V
 验证是否使用加密哈希或数字签名来确保训练数据存储和传输过程中的数据完整性。
 #1.2.5    级别: 2    角色: D/V
 验证是否应用了自动检测技术以防止训练数据的未经授权的修改或损坏。
 #1.2.6    级别: 2    角色: D/V
 验证过时的训练数据是否已被安全清除或匿名化。
 #1.2.7    级别: 3    角色: D/V
 验证所有训练数据集版本均有唯一标识，且以不可篡改的方式存储，并且可审计，以支持回滚和取证分析。

---

### C1.3 训练数据标注的质量、完整性与安全性

保护标签并对关键数据进行技术审核。

 #1.3.1    级别: 2    角色: D/V
 验证是否对标签工件应用了加密哈希或数字签名，以确保其完整性和真实性。
 #1.3.2    级别: 2    角色: D/V
 验证标注界面和平台是否执行强访问控制，维护所有标注活动的防篡改审计日志，并防止未经授权的修改。
 #1.3.3    级别: 3    角色: D/V
 验证标签中的敏感信息在静态和传输过程中是否在数据字段级别被编辑、匿名化或加密。

---

### C1.4 训练数据质量与安全保障

结合自动验证、人工抽查和记录的修正措施，以保证数据集的可靠性。

 #1.4.1    级别: 1    角色: D
 验证自动化测试是否能在每次摄取或重大数据转换时捕获格式错误和空值。
 #1.4.2    级别: 2    角色: D/V
 验证大语言模型训练和微调管道是否实现了投毒检测与数据完整性验证（例如，统计方法、离群点检测、嵌入分析），以识别潜在的投毒攻击（例如，标签翻转、后门触发插入、角色切换命令、影响实例攻击）或训练数据中的无意数据损坏。
 #1.4.3    级别: 3    角色: D/V
 根据风险评估，验证是否针对相关模型实施并调整了适当的防御措施，如对抗训练（使用生成的对抗样本）、带扰动输入的数据增强或鲁棒优化技术。
 #1.4.4    级别: 2    角色: D/V
 验证自动生成的标签（例如，通过大型语言模型或弱监督产生的标签）是否遵循置信度阈值和一致性检查，以检测幻觉标签、误导性标签或低置信度标签。
 #1.4.5    级别: 3    角色: D
 验证自动化测试是否能在每次数据摄取或重大数据转换时捕捉标签偏移。

---

### C1.5 数据溯源和可追踪性

追踪每个数据点从源头到模型输入的完整路径，以确保可审计性和事件响应。

 #1.5.1    级别: 2    角色: D/V
 验证每个数据点的血统，包括所有转换、增强和合并，是否都有记录且可以重建。
 #1.5.2    级别: 2    角色: D/V
 验证血统记录是不可更改的，安全存储的，并且可供审计访问。
 #1.5.3    级别: 2    角色: D/V
 确保血统追踪涵盖通过隐私保护或生成技术生成的合成数据，并且所有合成数据在整个流程中都被明确标记且可与真实数据区分开来。

---

### 参考文献

NIST AI Risk Management Framework
EU AI Act – Article 10: Data & Data Governance
MITRE ATLAS: Adversary Tactics for AI
Survey of ML Bias Mitigation Techniques – MDPI
Data Provenance & Lineage Best Practices – Nightfall AI
Data Labeling Quality Standards – LabelYourData
Training Data Poisoning Guide – Lakera.ai
CISA Advisory: Securing Data for AI Systems
ISO/IEC 23053: AI Management Systems Framework
IBM: What is AI Governance?
Google AI Principles
GDPR & AI Training Data – DataProtectionReport
Supply-Chain Security for AI Data – AppSOC
OpenAI Privacy Center – Data Deletion Controls
Adversarial ML Dataset – Kaggle

## C2 用户输入验证

### 控制目标

对用户输入的稳健验证是防御针对人工智能系统的一些最具破坏性攻击的第一道防线。提示注入攻击可以覆盖系统指令，泄露敏感数据，或者引导模型表现出不被允许的行为。除非有专门的过滤器和指令层级架构，否则研究表明利用超长上下文窗口的“多次提示”越狱攻击将会有效。此外，细微的对抗性扰动攻击——例如同形异义字替换或“网络语言”替换——能够悄无声息地改变模型的决策。

---

### C2.1 提示注入防御

提示注入是人工智能系统面临的主要风险之一。针对这种策略的防御措施采用静态模式过滤器、动态分类器和指令层级执行相结合的方法。

 #2.1.1    级别: 1    角色: D/V
 验证用户输入是否经过筛查，以防止已知的提示注入模式（越狱关键词、“忽略先前内容”、角色扮演链、间接的HTML/URL攻击），这些模式库会持续更新。
 #2.1.2    级别: 1    角色: D/V
 验证系统是否强制执行指令层级，其中系统或开发者消息覆盖用户指令，即使在上下文窗口扩展后也是如此。
 #2.1.3    级别: 2    角色: D/V
 确保在每次模型或提示模板发布之前，进行对抗性评估测试（例如，红队“多次尝试”提示），并设定成功率阈值以及用于防止回归的自动阻断机制。
 #2.1.4    级别: 2    角色: D
 验证源自第三方内容（网页、PDF、电子邮件）的提示是否在与主提示拼接之前，于隔离的解析环境中进行了清洗。
 #2.1.5    级别: 3    角色: D/V
 验证所有提示过滤规则更新、分类器模型版本和黑名单更改是否受版本控制且可审计。

---

### C2.2 对抗样本抵抗能力

自然语言处理（NLP）模型仍然容易受到细微的字符或词级扰动的影响，这些扰动人类通常会忽略，但模型往往会误判。

 #2.2.1    级别: 1    角色: D
 验证基本的输入规范化步骤（Unicode NFC、同形异构映射、空白字符修剪）在分词之前执行。
 #2.2.2    级别: 2    角色: D/V
 验证统计异常检测是否能标记出与语言规范编辑距离异常高、重复标记过多或嵌入距离异常的输入。
 #2.2.3    级别: 2    角色: D
 验证推理管道是否支持可选的对抗训练加固模型变体或防御层（例如，随机化、防御性蒸馏）以用于高风险端点。
 #2.2.4    级别: 2    角色: V
 验证可疑的对抗性输入是否被隔离，并且在去除个人身份信息（PII）后，完整有效载荷被记录。
 #2.2.5    级别: 3    角色: D/V
 验证鲁棒性指标（已知攻击套件的成功率）是否随时间跟踪，并且回归是否会触发发布阻断。

---

### C2.3 模式、类型和长度验证

包含格式错误或超大输入的 AI 攻击可能导致解析错误、字段间的提示泄露以及资源耗尽。严格的模式强制在执行确定性工具调用时也是先决条件。

 #2.3.1    级别: 1    角色: D
 验证每个API或函数调用端点是否定义了明确的输入模式（JSON Schema、Protobuf或多模态等效格式），并且在提示组装之前对输入进行验证。
 #2.3.2    级别: 1    角色: D/V
 验证超过最大令牌数或字节限制的输入是否被安全地拒绝，并且绝不会被无声截断。
 #2.3.3    级别: 2    角色: D/V
 验证类型检查（例如，数值范围、枚举值、图像/音频的 MIME 类型）是在服务器端强制执行的，而不仅仅是在客户端代码中。
 #2.3.4    级别: 2    角色: D
 验证语义验证器（例如，JSON Schema）是否以常数时间运行，以防止算法拒绝服务攻击（DoS）。
 #2.3.5    级别: 3    角色: V
 验证失败时应记录带有脱敏负载片段和明确错误代码的日志，以帮助安全分流。

---

### C2.4 内容与政策筛查

开发人员应该能够检测出请求不允许内容（例如违法指令、仇恨言论和受版权保护文本）的语法上有效的提示，然后阻止它们传播。

 #2.4.1    级别: 1    角色: D
 验证内容分类器（零样本或微调）是否对每个输入内容针对暴力、自残、仇恨、性内容和非法请求进行评分，并且阈值是可配置的。
 #2.4.2    级别: 1    角色: D/V
 验证违反政策的输入将收到标准化拒绝或安全完成，以防止其传播到下游的大型语言模型调用。
 #2.4.3    级别: 2    角色: D
 确保筛查模型或规则集至少每季度重新训练/更新一次，纳入新观察到的绕过限制或政策规避模式。
 #2.4.4    级别: 2    角色: D
 通过在请求时解析的基于属性的规则，验证筛选是否遵守用户特定的政策（年龄、地区法律约束）。
 #2.4.5    级别: 3    角色: V
 验证筛查日志是否包含分类器置信度分数和政策类别标签，以用于SOC关联和未来的红队重放。

---

### C2.5 输入速率限制与滥用防护

开发人员应通过限制输入速率和检测异常使用模式来防止针对人工智能系统的滥用、资源耗尽和自动化攻击。

 #2.5.1    级别: 1    角色: D/V
 验证所有输入端点是否对每个用户、每个IP和每个API密钥的速率限制进行了强制执行。
 #2.5.2    级别: 2    角色: D/V
 验证突发和持续速率限制是否经过调整，以防止拒绝服务（DoS）和暴力破解攻击。
 #2.5.3    级别: 2    角色: D/V
 验证异常使用模式（例如，快速请求、输入泛滥）是否会触发自动阻止或升级处理。
 #2.5.4    级别: 3    角色: V
 验证滥用预防日志是否被保留并审查以发现新出现的攻击模式。

---

### C2.6 多模态输入验证

人工智能系统应包含对非文本输入（图像、音频、文件）的严格验证，以防止注入、规避或资源滥用。

 #2.6.1    级别: 1    角色: D
 确认所有非文本输入（图像、音频、文件）在处理前均经过类型、大小和格式的验证。
 #2.6.2    级别: 2    角色: D/V
 验证文件在导入前是否已扫描恶意软件和隐写负载。
 #2.6.3    级别: 2    角色: D/V
 验证图像/音频输入是否经过对抗性扰动或已知攻击模式的检查。
 #2.6.4    级别: 3    角色: V
 验证多模态输入验证失败是否被记录并触发警报以进行调查。

---

### C2.7 输入来源及归因

人工智能系统应通过监控和标记所有用户输入的来源来支持审计、滥用跟踪和合规。

 #2.7.1    级别: 1    角色: D/V
 验证所有用户输入在接收时均附有元数据标记（用户ID、会话、来源、时间戳、IP地址）。
 #2.7.2    级别: 2    角色: D/V
 验证所有处理的输入均保留可追溯的元数据且可进行审计。
 #2.7.3    级别: 2    角色: D/V
 验证异常或不可信的输入源是否被标记并受到加强审查或阻止。

---

### C2.8 实时自适应威胁检测

开发人员应采用先进的针对 AI 的威胁检测系统，该系统能够适应新的攻击模式并通过编译模式匹配提供实时保护。

 #2.8.1    级别: 1    角色: D/V
 验证威胁检测模式是否被编译为优化的正则表达式引擎，以实现高性能的实时过滤，并最大限度地减少延迟影响。
 #2.8.2    级别: 1    角色: D/V
 验证威胁检测系统是否为不同的威胁类别（提示注入、有害内容、敏感数据、系统命令）维护独立的模式库。
 #2.8.3    级别: 2    角色: D/V
 验证自适应威胁检测是否包含基于攻击频率和成功率更新威胁敏感度的机器学习模型。
 #2.8.4    级别: 2    角色: D/V
 验证实时威胁情报源是否自动使用新的攻击特征和妥协指标（IOCs）更新模式库。
 #2.8.5    级别: 3    角色: D/V
 验证威胁检测的误报率是否被持续监控，并且是否自动调整模式特异性以最小化合法用例的干扰。
 #2.8.6    级别: 3    角色: D/V
 验证上下文威胁分析是否考虑了输入来源、用户行为模式和会话历史，以提高检测准确性。
 #2.8.7    级别: 3    角色: D/V
 验证威胁检测性能指标（检测率、处理延迟、资源利用率）是否实时监控并优化。

---

### C2.9 多模态安全验证流程

开发人员应针对文本、图像、音频和其他 AI 输入模态提供安全验证，包括特定类型的威胁检测和资源隔离。

 #2.9.1    级别: 1    角色: D/V
 验证每种输入模态是否具有专用的安全验证器，并附有文档化的威胁模式（文本：提示注入，图像：隐写术，音频：频谱图攻击）及检测阈值。
 #2.9.2    级别: 2    角色: D/V
 验证多模态输入是否在隔离的沙箱中处理，且为每种模态类型设定了明确的资源限制（内存、CPU、处理时间），并在安全策略中予以记录。
 #2.9.3    级别: 2    角色: D/V
 验证跨模态攻击检测是否能通过相关规则和警报生成，识别跨越多种输入类型（例如，图像中的隐写载荷与文本中的提示注入相结合）的协调攻击。
 #2.9.4    级别: 3    角色: D/V
 验证多模态验证失败时是否触发详细日志记录，包括所有输入模态、验证结果、威胁评分以及采用结构化日志格式进行关联分析，以便于SIEM集成。
 #2.9.5    级别: 3    角色: D/V
 验证特定模态的内容分类器是否根据记录的时间表（至少每季度一次）更新，包含新的威胁模式、对抗样本，并保持性能基准高于基线阈值。

---

### 参考文献

LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security
Generative AI's Biggest Security Flaw Is Not Easy to Fix
Many-shot jailbreaking \ Anthropic
$PDF$ OpenAI GPT-4.5 System Card
Notebook for the CheckThat Lab at CLEF 2024
Mitigate jailbreaks and prompt injections – Anthropic
Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis
OWASP Top 10 for LLM Applications 2025 – WorldTech IT
OWASP Machine Learning Security Top Ten
Few words about AI Security – Jussi Metso
How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry
Easily enforcing valid JSON schema following – API
AI Safety + Cybersecurity R\&D Tracker – Fairly AI
Anthropic makes 'jailbreak' advance to stop AI models producing harmful results
Pattern matching filter rules - IBM
Real-time Threat Detection

## C3 模型生命周期管理与变更控制

### 控制目标

人工智能系统必须实施变更控制流程，以防止未经授权或不安全的模型修改进入生产环境。该控制通过整个生命周期——从开发到部署再到退役——确保模型的完整性，从而实现快速事件响应并保持对所有变更的责任追踪。

核心安全目标：通过采用控制流程，确保只有经过授权、验证的模型才能进入生产环节，并保持完整性、可追溯性和可恢复性。

---

### C3.1 模型授权与完整性

只有经过验证完整性的授权模型才能进入生产环境。

 #3.1.1    级别: 1    角色: D/V
 在部署之前，验证所有模型产物（权重、配置、分词器）是否由授权实体进行过加密签名。
 #3.1.2    级别: 1    角色: D/V
 验证模型完整性是否在部署时进行验证，并且签名验证失败时阻止模型加载。
 #3.1.3    级别: 2    角色: D/V
 验证模型来源记录是否包含授权实体的身份、训练数据校验和、带有通过/未通过状态的验证测试结果以及创建时间戳。
 #3.1.4    级别: 2    角色: D/V
 验证所有模型工件均使用语义版本控制（主版本号.次版本号.修订号），并且有文档明确规定每个版本组件递增的具体标准。
 #3.1.5    级别: 2    角色: V
 验证依赖跟踪是否保持实时库存，从而能够快速识别所有使用该依赖的系统。

---

### C3.2 模型验证与测试

模型必须通过定义的安全性和安全验证后才能部署。

 #3.2.1    级别: 1    角色: D/V
 确保模型在部署前经过自动化安全测试，包括输入验证、输出清理和安全评估，并且符合预先商定的组织通过/不通过阈值。
 #3.2.2    级别: 1    角色: D/V
 验证验证失败是否在预先指定的授权人员明确覆盖批准后自动阻止模型部署，并附有记录在案的业务理由。
 #3.2.3    级别: 2    角色: V
 验证测试结果经过加密签名，并以不可篡改的方式链接到正在验证的特定模型版本哈希。
 #3.2.4    级别: 2    角色: D/V
 验证紧急部署是否需要记录的安全风险评估，并在预先约定的时间范围内获得预先指定的安全权限的批准。

---

### C3.3 受控部署与回滚

模型部署必须受到控制、监控且可逆。

 #3.3.1    级别: 1    角色: D
 验证生产部署是否实施了渐进式发布机制（金丝雀部署、蓝绿部署），并基于预先约定的错误率、延迟阈值或安全警报标准，设置了自动回滚触发器。
 #3.3.2    级别: 1    角色: D/V
 验证回滚功能是否能够在预定义的组织时间窗口内原子性地恢复完整的模型状态（权重、配置、依赖项）。
 #3.3.3    级别: 2    角色: D/V
 验证部署过程在模型激活前是否验证了加密签名并计算了完整性校验和，如有不匹配则部署失败。
 #3.3.4    级别: 2    角色: D/V
 验证紧急模型关闭功能是否能够通过自动断路器或手动终止开关，在预定义的响应时间内禁用模型端点。
 #3.3.5    级别: 2    角色: V
 验证回滚工件（先前的模型版本、配置、依赖项）是否按照组织政策通过不可变存储进行保留，以支持事件响应。

---

### C3.4 变更问责与审计

所有模型生命周期的变更必须可追踪且可审计。

 #3.4.1    级别: 1    角色: V
 验证所有模型更改（部署、配置、退役）是否生成不可变的审计记录，包括时间戳、经过身份验证的操作人员身份、变更类型以及变更前后的状态。
 #3.4.2    级别: 2    角色: D/V
 验证审计日志访问是否需要适当的授权，并且所有访问尝试均记录有用户身份和时间戳。
 #3.4.3    级别: 2    角色: D/V
 验证提示模板和系统消息是否在 git 仓库中进行版本控制，并且在部署前必须经过指定审核者的代码审查和批准。
 #3.4.4    级别: 2    角色: V
 验证审计记录是否包含足够的详细信息（模型哈希、配置快照、依赖版本），以便在保留期内的任何时间戳都能完整重建模型状态。

---

### C3.5 安全开发实践

模型开发和训练过程必须遵循安全实践以防止被攻击。

 #3.5.1    级别: 1    角色: D
 验证模型开发、测试和生产环境在物理上或逻辑上是分离的。它们没有共享的基础设施，拥有独立的访问控制，并且数据存储是隔离的。
 #3.5.2    级别: 1    角色: D
 验证模型训练和微调是否在具有受控网络访问的隔离环境中进行。
 #3.5.3    级别: 1    角色: D/V
 验证训练数据源通过完整性检查且通过受信任的来源进行身份验证，并在模型开发使用前具备有文件记录的责任链。
 #3.5.4    级别: 2    角色: D
 验证模型开发工件（超参数、训练脚本、配置文件）是否存储在版本控制中，并且在用于训练之前需要同行评审批准。

---

### C3.6 模型退役与停用

当模型不再需要或发现安全问题时，必须安全地退役。

 #3.6.1    级别: 1    角色: D
 验证模型退役流程是否自动扫描依赖图，识别所有使用系统，并在退役前提供预先约定的提前通知期限。
 #3.6.2    级别: 1    角色: D/V
 根据已验证的销毁证书，按照记录的数据保留政策，使用密码擦除或多遍覆盖方法，确保退役模型工件被安全清除。
 #3.6.3    级别: 2    角色: V
 验证模型退役事件是否带有时间戳和行为者身份的日志记录，并撤销模型签名以防止重复使用。
 #3.6.4    级别: 2    角色: D/V
 验证紧急模型退役功能能否通过自动断开开关在预设的紧急响应时间内禁用模型访问，以防发现关键安全漏洞。

---

### 参考文献

MLOps Principles
Securing AI/ML Ops – Cisco.com
Audit logs security: cryptographically signed tamper-proof logs
Machine Learning Model Versioning: Top Tools & Best Practices
AI Hygiene Starts with Models and Data Loaders – SEI Blog
How to handle versioning and rollback of a deployed ML model?
Reinforcement fine-tuning – OpenAI API
Auditing Machine Learning models: Governance, Data Security and …
Adversarial Training to Improve Model Robustness
What is AI adversarial robustness? – IBM Research
Exploring Data Provenance: Ensuring Data Integrity and Authenticity
MITRE ATLAS
AWS Prescriptive Guidance – Best practices for retiring applications …

## C4 基础设施、配置与部署安全

### 控制目标

人工智能基础设施必须通过安全配置、运行时隔离、可信部署管道和全面监控来强化，防止权限提升、供应链篡改和横向移动。只有经过授权和验证的基础设施组件和配置，才能通过受控流程进入生产环境，从而确保安全性、完整性和可审计性。

核心安全目标：仅通过加密签名和漏洞扫描的基础设施组件通过自动验证管道达到生产环境，该管道执行安全策略并维护不可篡改的审计记录。

---

### C4.1 运行时环境隔离

通过内核级隔离原语和强制访问控制防止容器逃逸和权限提升。

 #4.1.1    级别: 1    角色: D/V
 验证所有 AI 容器是否删除除了 CAP_SETUID、CAP_SETGID 以及安全基线中明确要求的权限外的所有 Linux 能力。
 #4.1.2    级别: 1    角色: D/V
 验证 seccomp 配置文件阻止所有系统调用，除了预先批准的允许列表中的调用，违规行为将终止容器并生成安全警报。
 #4.1.3    级别: 2    角色: D/V
 验证 AI 工作负载是否以只读根文件系统运行，临时数据使用 tmpfs，持久数据使用带有 noexec 挂载选项的命名卷。
 #4.1.4    级别: 2    角色: D/V
 验证基于 eBPF 的运行时监控（如 Falco、Tetragon 或同类工具）是否能够检测到权限提升尝试，并在组织响应时间要求内自动终止违规进程。
 #4.1.5    级别: 3    角色: D/V
 验证高风险 AI 工作负载是否在硬件隔离环境（Intel TXT、AMD SVM 或专用裸金属节点）中执行，并具备证明验证功能。

---

### C4.2 安全构建与部署流水线

通过可复现的构建和签名的工件，确保密码学完整性和供应链安全。

 #4.2.1    级别: 1    角色: D/V
 确保在每次提交时使用工具（tfsec、Checkov 或 Terrascan）扫描基础设施即代码，并阻止包含关键（CRITICAL）或高（HIGH）严重性问题的合并。
 #4.2.2    级别: 1    角色: D/V
 验证容器构建在不同构建之间具有相同的 SHA256 哈希值以确保可复现性，并生成使用 Sigstore 签名的 SLSA 三级溯源证明。
 #4.2.3    级别: 2    角色: D/V
 验证容器镜像在推送到注册表之前是否嵌入了 CycloneDX 或 SPDX 软件物料清单 (SBOM)，并且是否使用 Cosign 进行了签名；未签名的镜像将在部署时被拒绝。
 #4.2.4    级别: 2    角色: D/V
 验证CI/CD管道是否使用来自HashiCorp Vault、AWS IAM角色或Azure托管身份的OIDC令牌，且其有效期不超过组织安全策略限制。
 #4.2.5    级别: 2    角色: D/V
 验证在容器执行前的部署过程中，Cosign 签名和 SLSA 来源证明已被验证，且验证错误会导致部署失败。
 #4.2.6    级别: 2    角色: D/V
 验证构建环境是否在无持久存储且与生产VPC网络隔离的临时容器或虚拟机中运行。

---

### C4.3 网络安全与访问控制

实施零信任网络，采用默认拒绝策略和加密通信。

 #4.3.1    级别: 1    角色: D/V
 验证 Kubernetes NetworkPolicies 或任何等效方案是否实现了默认拒绝的入口/出口策略，并为所需端口（443、8080 等）设置了显式允许规则。
 #4.3.2    级别: 1    角色: D/V
 验证SSH（端口22）、RDP（端口3389）和云元数据端点（169.254.169.254）是否被阻止或需要基于证书的认证。
 #4.3.3    级别: 2    角色: D/V
 验证出站流量是否通过带有域名允许列表的 HTTP/HTTPS 代理（Squid、Istio 或云 NAT 网关）进行过滤，并记录被阻止的请求。
 #4.3.4    级别: 2    角色: D/V
 验证服务间通信是否使用双向 TLS，证书是否按照组织政策轮换，并且强制执行证书验证（不使用跳过验证标志）。
 #4.3.5    级别: 2    角色: D/V
 验证 AI 基础设施是否运行在专用的 VPC/VNet 中，且没有直接的互联网访问权限，仅通过 NAT 网关或堡垒主机进行通信。

---

### C4.4 秘密与密码密钥管理

通过硬件支持的存储和自动轮换以及零信任访问来保护凭证。

 #4.4.1    级别: 1    角色: D/V
 验证机密是否存储在 HashiCorp Vault、AWS Secrets Manager、Azure Key Vault 或 Google Secret Manager 中，并使用 AES-256 进行静态加密。
 #4.4.2    级别: 1    角色: D/V
 验证密码密钥是否在符合 FIPS 140-2 级别 2 的硬件安全模块（HSM）（如 AWS CloudHSM、Azure Dedicated HSM）中生成，并且根据组织的密码策略进行密钥轮换。
 #4.4.3    级别: 2    角色: D/V
 验证密码轮换是否实现自动化，确保零停机部署，并且在人员变动或安全事件发生时立即触发轮换。
 #4.4.4    级别: 2    角色: D/V
 验证容器镜像是否使用工具（GitLeaks、TruffleHog 或 detect-secrets）进行扫描，阻止包含 API 密钥、密码或证书的构建。
 #4.4.5    级别: 2    角色: D/V
 验证生产环境的秘密访问是否需要使用硬件令牌（如 YubiKey、FIDO2）的多因素认证（MFA），并且是否通过包含用户身份和时间戳的不可篡改审计日志进行记录。
 #4.4.6    级别: 2    角色: D/V
 验证秘密是否通过 Kubernetes secret、挂载卷或初始化容器注入，并确保秘密绝不嵌入环境变量或镜像中。

---

### C4.5 AI 工作负载沙箱和验证

在安全沙箱中隔离不受信任的 AI 模型，并进行全面的行为分析。

 #4.5.1    级别: 1    角色: D/V
 验证外部 AI 模型是否在 gVisor、微型虚拟机（如 Firecracker、CrossVM）或带有 --security-opt=no-new-privileges 和 --read-only 标志的 Docker 容器中执行。
 #4.5.2    级别: 1    角色: D/V
 验证沙箱环境没有网络连接（--network=none）或仅限本地主机访问，并通过 iptables 规则阻止所有外部请求。
 #4.5.3    级别: 2    角色: D/V
 验证人工智能模型验证是否包括具有组织定义的测试覆盖范围和行为分析的自动化红队测试，以检测后门。
 #4.5.4    级别: 2    角色: D/V
 确保在将 AI 模型投入生产之前，其沙箱结果由授权的安全人员进行加密签名，并存储在不可篡改的审计日志中。
 #4.5.5    级别: 2    角色: D/V
 验证沙箱环境在每次评估之间是否被销毁并且从黄金镜像重新创建，确保文件系统和内存的完全清理。

---

### C4.6 基础设施安全监控

通过自动修复和实时报警，持续扫描和监控基础设施。

 #4.6.1    级别: 1    角色: D/V
 验证容器镜像是否根据组织的计划进行扫描，且基于组织风险阈值，关键漏洞会阻止部署。
 #4.6.2    级别: 1    角色: D/V
 验证基础设施是否符合CIS基准或NIST 800-53控制，满足组织定义的合规阈值，并对未通过检查的项进行自动修复。
 #4.6.3    级别: 2    角色: D/V
 验证高危漏洞是否按照组织风险管理时间表进行了修补，并针对被主动利用的CVE制订紧急处理程序。
 #4.6.4    级别: 2    角色: V
 验证安全警报是否通过CEF或STIX/TAXII格式与SIEM平台（如Splunk、Elastic或Sentinel）集成，并实现自动丰富。
 #4.6.5    级别: 3    角色: V
 验证基础设施指标是否导出到监控系统（Prometheus、DataDog），并生成SLA仪表板和高管报告。
 #4.6.6    级别: 2    角色: D/V
 根据组织的监控要求，使用工具（Chef InSpec、AWS Config）验证配置漂移是否被检测到，并对未经授权的更改自动回滚。

---

### C4.7 AI基础设施资源管理

通过配额和监控，防止资源耗尽攻击并确保公平的资源分配。

 #4.7.1    级别: 1    角色: D/V
 验证是否监控GPU/TPU利用率，并在组织定义的阈值触发警报，同时根据容量管理策略激活自动扩展或负载均衡。
 #4.7.2    级别: 1    角色: D/V
 验证是否根据组织的监控要求收集了 AI 工作负载指标（推理延迟、吞吐量、错误率），并与基础设施利用率相关联。
 #4.7.3    级别: 2    角色: D/V
 验证 Kubernetes ResourceQuotas 或等效机制是否根据组织的资源分配策略对单个工作负载进行限制，并强制执行硬性限制。
 #4.7.4    级别: 2    角色: V
 验证成本监控是否能够按工作负载/租户跟踪支出，并基于组织预算阈值设置警报，以及针对预算超支的自动控制。
 #4.7.5    级别: 3    角色: V
 验证容量规划是否使用具有组织定义的预测周期的历史数据，并且基于需求模式实现自动资源配置。
 #4.7.6    级别: 2    角色: D/V
 验证资源耗尽是否根据组织响应要求触发断路器，包括基于容量策略的速率限制和工作负载隔离。

---

### C4.8 环境隔离与推广控制

通过自动推广门禁和安全验证，实施严格的环境边界控制。

 #4.8.1    级别: 1    角色: D/V
 验证开发/测试/生产环境是否在独立的 VPCs/VNets 中运行，且没有共享的 IAM 角色、安全组或网络连接。
 #4.8.2    级别: 1    角色: D/V
 验证环境晋升是否需要组织定义的授权人员的批准，并具备加密签名和不可篡改的审计追踪。
 #4.8.3    级别: 2    角色: D/V
 验证生产环境是否阻止SSH访问，禁用调试端点，并且除紧急情况外，要求变更请求符合组织的提前通知要求。
 #4.8.4    级别: 2    角色: D/V
 验证基础设施即代码的更改在合并到主分支之前需要经过同行评审、自动化测试和安全扫描。
 #4.8.5    级别: 2    角色: D/V
 验证非生产数据是否按照组织隐私要求进行了匿名化，合成数据生成或完全数据掩码，并确认已移除个人身份信息（PII）。
 #4.8.6    级别: 2    角色: D/V
 验证晋升关卡包括自动化安全测试（SAST、DAST、容器扫描），并且要求无任何CRITICAL级别的发现才能获得批准。

---

### C4.9 基础设施备份与恢复

通过自动备份、经过测试的恢复程序和灾难恢复能力，确保基础设施的弹性。

 #4.9.1    级别: 1    角色: D/V
 验证基础设施配置是否按照组织的备份计划，使用3-2-1备份策略，将备份数据存储到地理位置分离的区域。
 #4.9.2    级别: 2    角色: D/V
 验证备份系统在隔离网络中运行，使用独立凭据和隔离存储，以防范勒索软件攻击。
 #4.9.3    级别: 2    角色: V
 验证恢复程序是否通过自动化测试按照组织计划进行测试和验证，恢复时间目标（RTO）和恢复点目标（RPO）是否符合组织要求。
 #4.9.4    级别: 3    角色: V
 验证灾难恢复是否包括针对人工智能的运行手册，其中涵盖模型权重恢复、GPU 集群重建和服务依赖关系映射。

---

### C4.10 基础设施合规与治理

通过持续评估、文档记录和自动化控制，保持合规性。

 #4.10.1    级别: 2    角色: D/V
 验证基础设施合规性是否根据组织日程，针对 SOC 2、ISO 27001 或 FedRAMP 控制进行评估，并配合自动化证据收集。
 #4.10.2    级别: 2    角色: V
 验证基础设施文档是否包含根据组织变更管理要求更新的网络图、数据流图和威胁模型。
 #4.10.3    级别: 3    角色: D/V
 验证基础设施变更是否经过自动化合规影响评估，并针对高风险修改实施监管审批流程。

---

### C4.11 AI 硬件安全

保护特定于人工智能的硬件组件，包括GPU、TPU和专用的人工智能加速器。

 #4.11.1    级别: 2    角色: D/V
 验证AI加速器固件（GPU BIOS，TPU固件）是否经过加密签名验证，并按照组织的补丁管理时间表进行更新。
 #4.11.2    级别: 2    角色: D/V
 验证在工作负载执行之前，AI加速器的完整性通过使用TPM 2.0、Intel TXT或AMD SVM的硬件认证进行验证。
 #4.11.3    级别: 2    角色: D/V
 验证使用 SR-IOV、MIG（多实例 GPU）或等效硬件分区时，GPU 内存是否在工作负载之间隔离，并确保作业之间的内存清理。
 #4.11.4    级别: 3    角色: V
 验证人工智能硬件供应链是否包含带有制造商证书的来源验证以及防篡改包装的验证。
 #4.11.5    级别: 3    角色: D/V
 验证硬件安全模块（HSM）是否通过了FIPS 140-2第三级或Common Criteria EAL4+认证，以保护AI模型权重和加密密钥。

---

### C4.12 边缘与分布式人工智能基础设施

包括边缘计算、联邦学习和多站点架构的安全分布式人工智能部署。

 #4.12.1    级别: 2    角色: D/V
 验证边缘 AI 设备是否使用相互 TLS 通过设备证书向中央基础设施进行身份验证，且设备证书按照组织的证书管理政策进行轮换。
 #4.12.2    级别: 2    角色: D/V
 验证边缘设备实施了带有验证签名和回滚保护的安全启动，以防止固件降级攻击。
 #4.12.3    级别: 3    角色: D/V
 验证分布式人工智能协调是否使用具有参与者验证和恶意节点检测的拜占庭容错共识算法。
 #4.12.4    级别: 3    角色: D/V
 验证边缘到云通信包含带宽限制、数据压缩和具备安全本地存储的离线操作能力。

---

### C4.13 多云与混合基础设施安全

跨多个云提供商以及混合云本地部署中保护 AI 工作负载的安全。

 #4.13.1    级别: 2    角色: D/V
 验证多云人工智能部署是否使用云无关的身份联合（OIDC、SAML），并在各供应商之间实现集中式策略管理。
 #4.13.2    级别: 2    角色: D/V
 验证跨云数据传输是否使用端到端加密，并且使用客户管理的密钥以及根据不同司法管辖区强制执行的数据驻留控制。
 #4.13.3    级别: 2    角色: D/V
 验证混合云 AI 工作负载在本地和云环境中实施一致的安全策略，并实现统一的监控和警报。
 #4.13.4    级别: 3    角色: V
 验证防止云供应商锁定包括可移植的基础设施即代码、标准化的API以及带有格式转换工具的数据导出能力。
 #4.13.5    级别: 3    角色: V
 验证多云成本优化是否包括防止资源蔓延以及未经授权的跨云数据传输费用的安全控制。

---

### C4.14 基础设施自动化与 GitOps 安全

为人工智能基础设施管理保驾护航的安全基础设施自动化流水线和GitOps工作流。

 #4.14.1    级别: 2    角色: D/V
 验证 GitOps 仓库是否要求使用 GPG 密钥进行签名提交，并且设置了防止直接推送到主分支的分支保护规则。
 #4.14.2    级别: 2    角色: D/V
 验证基础设施自动化是否包括偏移检测，并根据组织对未授权更改的响应要求触发自动修复和回滚功能。
 #4.14.3    级别: 2    角色: D/V
 验证自动化基础设施配置是否包含安全策略验证，并对不合规配置实施部署阻止。
 #4.14.4    级别: 2    角色: D/V
 验证基础设施自动化机密是否通过外部机密操作器（External Secrets Operator、Bank-Vaults）进行管理，并实现自动轮换。
 #4.14.5    级别: 3    角色: V
 验证自愈基础设施是否包括安全事件关联，具备自动化事件响应和利益相关者通知工作流程。

---

### C4.15 量子抗性基础设施安全

通过后量子密码学和量子安全协议，为量子计算威胁准备人工智能基础设施。

 #4.15.1    级别: 3    角色: D/V
 验证AI基础设施是否实现了NIST认可的后量子密码算法（CRYSTALS-Kyber、CRYSTALS-Dilithium、SPHINCS+）用于密钥交换和数字签名。
 #4.15.2    级别: 3    角色: D/V
 验证量子密钥分发（QKD）系统是否使用量子安全密钥管理协议实施，以实现高安全性的人工智能通信。
 #4.15.3    级别: 3    角色: D/V
 验证密码灵活性框架是否通过自动证书和密钥轮换，实现对新后量子算法的快速迁移。
 #4.15.4    级别: 3    角色: V
 验证量子威胁建模是否评估了人工智能基础设施对量子攻击的脆弱性，并附有记录在案的迁移时间表和风险评估。
 #4.15.5    级别: 3    角色: D/V
 验证混合经典-量子密码系统在量子过渡期间通过性能监控实现纵深防御。

---

### C4.16 机密计算与安全环境

使用基于硬件的可信执行环境和机密计算技术保护人工智能工作负载和模型权重。

 #4.16.1    级别: 3    角色: D/V
 验证敏感的 AI 模型是否在具有加密内存和认证验证的 Intel SGX 安全区、AMD SEV-SNP 或 ARM TrustZone 中执行。
 #4.16.2    级别: 3    角色: D/V
 验证机密容器（Kata Containers、带机密计算的 gVisor）是否通过硬件强制的内存加密隔离 AI 工作负载。
 #4.16.3    级别: 3    角色: D/V
 验证远程认证是否在加载 AI 模型之前，通过加密证明执行环境的真实性来确认安全区的完整性。
 #4.16.4    级别: 3    角色: D/V
 验证机密AI推理服务通过密封的模型权重和受保护的执行，以加密计算防止模型提取。
 #4.16.5    级别: 3    角色: D/V
 验证可信执行环境编排是否通过远程证明和加密通信通道管理安全隔区的生命周期。
 #4.16.6    级别: 3    角色: D/V
 验证安全多方计算（SMPC）是否能够实现协作式AI训练，同时不泄露各自的数据集或模型参数。

---

### C4.17 零知识基础设施

实现零知识证明系统，用于隐私保护的人工智能验证和认证，且不泄露敏感信息。

 #4.17.1    级别: 3    角色: D/V
 验证零知识证明（ZK-SNARKs，ZK-STARKs）是否能在不泄露模型权重或训练数据的情况下，验证AI模型的完整性和训练出处。
 #4.17.2    级别: 3    角色: D/V
 验证基于零知识证明（ZK）的认证系统是否能够在不透露身份相关信息的情况下，实现对人工智能服务的隐私保护用户验证。
 #4.17.3    级别: 3    角色: D/V
 验证私有集合交集（PSI）协议是否能够在不泄露各自数据集的情况下，实现联邦人工智能中的安全数据匹配。
 #4.17.4    级别: 3    角色: D/V
 验证零知识机器学习（ZKML）系统是否通过加密证明实现了可验证的人工智能推理，确保计算的正确性。
 #4.17.5    级别: 3    角色: D/V
 验证ZK-rollups通过批量验证和减少计算开销，提供可扩展的、保护隐私的AI交易处理。

---

### C4.18 侧信道攻击防护

保护 AI 基础设施，防范可能泄露敏感信息的时序、功率、电磁和基于缓存的侧信道攻击。

 #4.18.1    级别: 3    角色: D/V
 验证AI推理时间是否通过使用常时算法和填充进行归一化，以防止基于时间的模型提取攻击。
 #4.18.2    级别: 3    角色: D/V
 确认功率分析防护包括噪声注入、电源线滤波和随机执行模式，以保护人工智能硬件。
 #4.18.3    级别: 3    角色: D/V
 验证基于缓存的侧信道缓解措施是否使用缓存分区、随机化和刷新指令来防止信息泄露。
 #4.18.4    级别: 3    角色: D/V
 验证电磁发射防护包括屏蔽、信号过滤和随机处理，以防止类似TEMPEST的攻击。
 #4.18.5    级别: 3    角色: D/V
 验证微体系结构侧信道防御是否包括推测执行控制和内存访问模式混淆。

---

### C4.19 类脑神经形态与专用人工智能硬件安全

保障新兴的 AI 硬件架构安全，包括类神经芯片、FPGA、自定义 ASIC 以及光计算系统。

 #4.19.1    级别: 3    角色: D/V
 验证神经形态芯片安全性包括脉冲模式加密、突触权重保护以及基于硬件的学习规则验证。
 #4.19.2    级别: 3    角色: D/V
 验证基于FPGA的人工智能加速器是否实现了比特流加密、防篡改机制以及带有认证更新的安全配置加载。
 #4.19.3    级别: 3    角色: D/V
 验证自定义ASIC安全性包括片上安全处理器、硬件根信任和带有篡改检测的安全密钥存储。
 #4.19.4    级别: 3    角色: D/V
 验证光计算系统是否实现了量子安全的光学加密、安全的光子交换和受保护的光信号处理。
 #4.19.5    级别: 3    角色: D/V
 验证混合模拟-数字人工智能芯片是否包含安全的模拟计算、受保护的权重存储以及经过认证的模拟到数字转换。

---

### C4.20 隐私保护计算基础设施

实施基础设施控制，以支持隐私保护计算，确保在人工智能处理和分析过程中保护敏感数据。

 #4.20.1    级别: 3    角色: D/V
 验证同态加密基础设施能够在敏感的人工智能工作负载上实现加密计算，并具备密码学完整性验证和性能监控功能。
 #4.20.2    级别: 3    角色: D/V
 验证私有信息检索系统是否在通过对访问模式进行加密保护的情况下，实现了数据库查询而不泄露查询模式。
 #4.20.3    级别: 3    角色: D/V
 验证安全多方计算协议能够在不暴露个体输入或中间计算结果的情况下，实现隐私保护的人工智能推理。
 #4.20.4    级别: 3    角色: D/V
 验证隐私保护的密钥管理包括分布式密钥生成、门限密码学和基于硬件的安全密钥轮换保护。
 #4.20.5    级别: 3    角色: D/V
 验证通过批处理、缓存和硬件加速优化隐私保护计算性能的同时，确保密码学安全性保障不受影响。

---

### C4.15 代理框架云集成安全与混合部署

具有混合本地/云架构的云集成代理框架的安全控制。

 #4.15.1    级别: 1    角色: D/V
 验证云存储集成使用端到端加密，并由代理控制密钥管理。
 #4.15.2    级别: 2    角色: D/V
 验证混合部署的安全边界是否明确定义，并使用加密通信通道。
 #4.15.3    级别: 2    角色: D/V
 验证云资源访问是否包含零信任验证与持续身份认证。
 #4.15.4    级别: 3    角色: D/V
 通过对存储位置进行加密证明，验证数据驻留要求的执行情况。
 #4.15.5    级别: 3    角色: D/V
 验证云服务提供商的安全评估是否包含针对代理的威胁建模和风险评估。

---

### 参考文献

NIST Cybersecurity Framework 2.0
CIS Controls v8
OWASP Container Security Verification Standard
Kubernetes Security Best Practices
SLSA Supply Chain Security Framework
NIST SP 800-190: Application Container Security Guide
Cloud Security Alliance: Cloud Controls Matrix
ENISA: Secure Infrastructure Design
NIST SP 800-53: Security Controls for Federal Information Systems
ISO 27001:2022 Information Security Management
NIST AI Risk Management Framework
CIS Kubernetes Benchmark
FIPS 140-2 Security Requirements
NIST SP 800-207: Zero Trust Architecture
IEEE 2857: Privacy Engineering for AI Systems
NIST SP 800-161: Cybersecurity Supply Chain Risk Management
NIST Post-Quantum Cryptography Standards
Intel SGX Developer Guide
AMD SEV-SNP White Paper
ARM TrustZone Technology
ZK-SNARKs: A Gentle Introduction
NIST SP 800-57: Cryptographic Key Management
Side-Channel Attack Countermeasures
Neuromorphic Computing Security Challenges
FPGA Security: Fundamentals, Evaluation, and Countermeasures
Microsoft SEAL: Homomorphic Encryption Library
HElib: Homomorphic Encryption Library
PALISADE Lattice Cryptography Library
Differential Privacy: A Survey of Results
Secure Aggregation for Federated Learning
Private Information Retrieval: Concepts and Constructions

## C5 访问控制与人工智能组件及用户身份管理

### 控制目标

对人工智能系统实施有效的访问控制需要强大的身份管理、上下文感知的授权以及遵循零信任原则的运行时执行。这些控制确保人类、服务和自主代理仅在明确授权的范围内与模型、数据和计算资源进行交互，并具备持续的验证和审计能力。

---

### C5.1 身份管理与认证

为所有实体建立由加密技术支持的身份，并针对特权操作实施多因素认证。

 #5.1.1    级别: 1    角色: D/V
 验证所有人类用户和服务主体均通过集中式企业身份提供者（IdP）使用 OIDC/SAML 协议进行身份验证，且具有唯一的身份到令牌映射（无共享账户或凭据）。
 #5.1.2    级别: 1    角色: D/V
 验证高风险操作（模型部署、权重导出、训练数据访问、生产配置更改）是否需要多因素认证或带有会话重新验证的逐级认证。
 #5.1.3    级别: 2    角色: D
 验证新负责人在获得生产系统访问权限之前，必须进行符合 NIST 800-63-3 IAL-2 或等效标准的身份验证。
 #5.1.4    级别: 2    角色: V
 验证访问审查是否每季度进行一次，并通过自动检测休眠账户、强制凭证轮换和注销工作流程来实现。
 #5.1.5    级别: 3    角色: D/V
 验证联合人工智能代理通过签名的 JWT 断言进行身份验证，该断言的最长有效期为 24 小时，并包含来源的加密证明。

---

### C5.2 资源授权与最小权限

为所有人工智能资源实施细粒度访问控制，采用明确的权限模型和审计跟踪。

 #5.2.1    级别: 1    角色: D/V
 验证每个 AI 资源（数据集、模型、端点、向量集合、嵌入索引、计算实例）是否实施基于角色的访问控制，采用显式允许列表和默认拒绝策略。
 #5.2.2    级别: 1    角色: D/V
 验证服务账户默认执行最小权限原则，权限从只读开始，写权限必须有书面业务理由。
 #5.2.3    级别: 1    角色: V
 验证所有访问控制修改是否与已批准的变更请求相关联，并以不可篡改的方式记录时间戳、操作人员身份、资源标识符和权限差异。
 #5.2.4    级别: 2    角色: D
 验证数据分类标签（个人识别信息PII、受保护健康信息PHI、出口管制信息、专有信息）能否自动传播到派生资源（嵌入、提示缓存、模型输出），并确保策略的一致执行。
 #5.2.5    级别: 2    角色: D/V
 验证未经授权的访问尝试和权限提升事件是否在5分钟内触发带有上下文元数据的实时警报发送到SIEM系统。

---

### C5.3 动态策略评估

部署基于属性的访问控制（ABAC）引擎，实现具有审计功能的上下文感知授权决策。

 #5.3.1    级别: 1    角色: D/V
 验证授权决策是否外部化到专用的策略引擎（OPA、Cedar或同类工具），并通过带有加密完整性保护的身份验证API进行访问。
 #5.3.2    级别: 1    角色: D/V
 验证策略在运行时评估动态属性，包括用户许可级别、资源敏感性分类、请求上下文、租户隔离和时间约束。
 #5.3.3    级别: 2    角色: D
 验证策略定义在生产部署前经过版本控制、同行评审，并通过CI/CD流水线中的自动化测试进行验证。
 #5.3.4    级别: 2    角色: V
 验证策略评估结果是否包含结构化的决策理由，并将其传输到 SIEM 系统以进行关联分析和合规性报告。
 #5.3.5    级别: 3    角色: D/V
 验证策略缓存的生存时间（TTL）值，对于高敏感度资源不超过5分钟，对于具有缓存失效功能的标准资源不超过1小时。

---

### C5.4 查询时的安全执行

实现数据库层的安全控制，包括强制过滤和行级安全策略。

 #5.4.1    级别: 1    角色: D/V
 验证所有向量数据库和SQL查询均包含强制性的安全过滤器（租户ID、敏感性标签、用户范围），并且这些过滤器在数据库引擎层面强制执行，而非在应用程序代码中实施。
 #5.4.2    级别: 1    角色: D/V
 验证所有向量数据库、搜索索引和训练数据集是否启用了行级安全（RLS）策略和字段级屏蔽，并且支持策略继承。
 #5.4.3    级别: 2    角色: D
 验证失败的授权评估将通过立即中止查询并返回明确的授权错误代码，而不是返回空结果集，从而防止“混淆副手攻击”。
 #5.4.4    级别: 2    角色: V
 验证策略评估延迟是否被持续监控，并且针对可能导致授权绕过的超时情况设有自动警报。
 #5.4.5    级别: 3    角色: D/V
 验证查询重试机制是否重新评估授权策略，以考虑活动用户会话中动态权限的更改。

---

### C5.5 输出过滤与数据泄露防护

部署后期处理控制，以防止AI生成内容中的未经授权的数据泄露。

 #5.5.1    级别: 1    角色: D/V
 验证推理后过滤机制在向请求者交付内容之前，是否扫描并修订未经授权的个人身份信息（PII）、机密信息和专有数据。
 #5.5.2    级别: 1    角色: D/V
 验证模型输出中的引用、参考文献和来源归属是否已根据调用者权限进行验证，如果检测到未经授权的访问，则将其移除。
 #5.5.3    级别: 2    角色: D
 根据用户权限等级和数据分类，验证输出格式限制（如净化的PDF、去除元数据的图像、批准的文件类型）是否得到执行。
 #5.5.4    级别: 2    角色: V
 验证编辑算法是确定性的，具备版本控制，并保留审计日志，以支持合规调查和取证分析。
 #5.5.5    级别: 3    角色: V
 验证高风险编辑事件是否生成包含原始内容加密哈希的自适应日志，以便在不暴露数据的情况下进行取证检索。

---

### C5.6 多租户隔离

确保共享 AI 基础设施中租户之间的加密和逻辑隔离。

 #5.6.1    级别: 1    角色: D/V
 验证内存空间、嵌入存储、缓存条目和临时文件是否按租户进行命名空间分隔，并在租户删除或会话终止时进行安全清除。
 #5.6.2    级别: 1    角色: D/V
 验证每个 API 请求都包含经过身份验证的租户标识符，该标识符通过密码学方法相对于会话上下文和用户权限进行验证。
 #5.6.3    级别: 2    角色: D
 验证网络策略是否在服务网格和容器编排平台中对跨租户通信实施默认拒绝规则。
 #5.6.4    级别: 3    角色: D
 验证加密密钥在支持客户管理密钥（CMK）的情况下是否针对每个租户唯一，并且租户数据存储之间具备密码学隔离。

---

### C5.7 自主代理授权

通过范围能力令牌和持续授权控制 AI 代理和自主系统的权限。

 #5.7.1    级别: 1    角色: D/V
 验证自主代理是否接收了明确列出允许操作、可访问资源、时间限制和操作约束的范围能力令牌。
 #5.7.2    级别: 1    角色: D/V
 验证高风险功能（文件系统访问、代码执行、外部API调用、金融交易）默认是否被禁用，并且激活这些功能是否需要明确的授权和业务理由。
 #5.7.3    级别: 2    角色: D
 验证能力令牌是否绑定到用户会话，包含加密完整性保护，并确保它们不能在离线场景中被持久化或重用。
 #5.7.4    级别: 2    角色: V
 验证代理发起的操作是否通过基于属性的访问控制（ABAC）策略引擎进行二次授权，并进行完整的上下文评估和审计日志记录。
 #5.7.5    级别: 3    角色: V
 验证代理错误条件和异常处理是否包含能力范围信息，以支持事件分析和取证调查。

---

### 参考文献

#### 标准与框架

NIST SP 800-63-3: Digital Identity Guidelines
Zero Trust Architecture – NIST SP 800-207
OWASP Application Security Verification Standard (AISVS)
​
#### 实施指南

Identity and Access Management in the AI Era: 2025 Guide – IDSA
Attribute-Based Access Control with OPA – Permify
How We Designed Cedar to Be Intuitive, Fast, and Safe – AWS
​
#### 人工智能专用安全

Row Level Security in Vector DBs for RAG – Bluetuple.ai
Tenant Isolation in Multi-Tenant Systems – WorkOS
Handling AI Agent Permissions – Stytch
OWASP Top 10 for Large Language Model Applications

## C6 模型、框架与数据的供应链安全

### 控制目标

AI供应链攻击利用第三方模型、框架或数据集嵌入后门、偏见或可利用代码。这些控制措施提供端到端的来源追踪、漏洞管理和监控，以保护整个模型生命周期。

---

### C6.1 预训练模型审核与来源

在进行任何微调或部署之前，评估并验证第三方模型的来源、许可证及隐藏行为。

 #6.1.1    级别: 1    角色: D/V
 验证每个第三方模型工件是否包含签名的来源记录，标明源代码仓库和提交哈希。
 #6.1.2    级别: 1    角色: D/V
 确保在导入模型之前，使用自动化工具扫描模型是否存在恶意层或木马触发器。
 #6.1.3    级别: 2    角色: D
 验证迁移学习微调是否通过对抗性评估以检测隐藏行为。
 #6.1.4    级别: 2    角色: V
 验证模型许可证、出口管制标记和数据来源声明是否已记录在 ML-BOM 条目中。
 #6.1.5    级别: 3    角色: D/V
 验证高风险模型（公开上传的权重、未经验证的创建者）在人工审核和批准之前保持隔离状态。

---

### C6.2 框架与库扫描

持续扫描机器学习框架和库中的CVE漏洞及恶意代码，以保持运行时堆栈的安全。

 #6.2.1    级别: 1    角色: D/V
 验证CI流水线是否对AI框架和关键库运行依赖项扫描器。
 #6.2.2    级别: 1    角色: D/V
 验证关键漏洞（CVSS ≥ 7.0）是否阻止推广到生产镜像。
 #6.2.3    级别: 2    角色: D
 验证静态代码分析是否在派生或供应的机器学习库上运行。
 #6.2.4    级别: 2    角色: V
 验证框架升级提案是否包含引用公共CVE信息源的安全影响评估。
 #6.2.5    级别: 3    角色: V
 验证运行时传感器是否会对偏离签名SBOM的意外动态库加载发出警报。

---

### C6.3 依赖项固定与验证

将每个依赖项固定到不可变摘要，并重现构建，以保证生成相同且无篡改的工件。

 #6.3.1    级别: 1    角色: D/V
 验证所有包管理器是否通过锁文件强制执行版本锁定。
 #6.3.2    级别: 1    角色: D/V
 验证在容器引用中使用的是不可变摘要而非可变标签。
 #6.3.3    级别: 2    角色: D
 验证可复现构建检查在持续集成运行中比较哈希值以确保输出一致。
 #6.3.4    级别: 2    角色: V
 验证构建证明已存储18个月以确保审计可追溯性。
 #6.3.5    级别: 3    角色: D
 确认过期的依赖项会触发自动拉取请求以更新或分叉固定版本。

---

### C6.4 可信来源强制执行

仅允许从经过密码验证的、组织批准的来源下载工件，阻止所有其他来源。

 #6.4.1    级别: 1    角色: D/V
 验证模型权重、数据集和容器仅从批准的域或内部注册表下载。
 #6.4.2    级别: 1    角色: D/V
 验证 Sigstore/Cosign 签名以确认发布者身份，然后再将工件缓存在本地。
 #6.4.3    级别: 2    角色: D
 验证出口代理是否阻止未经身份验证的工件下载以执行可信来源策略。
 #6.4.4    级别: 2    角色: V
 核实仓库允许列表是否每季度审查一次，并提供每个条目的业务理由证据。
 #6.4.5    级别: 3    角色: V
 验证策略违规是否会触发对工件的隔离以及相关管道运行的回滚。

---

### C6.5 第三方数据集风险评估

评估外部数据集的投毒、偏见和法律合规性，并在其整个生命周期内进行监控。

 #6.5.1    级别: 1    角色: D/V
 验证外部数据集是否进行过中毒风险评分（例如，数据指纹识别、异常值检测）。
 #6.5.2    级别: 1    角色: D
 确认在数据集批准之前已计算偏倚指标（人口统计平等、机会均等）。
 #6.5.3    级别: 2    角色: V
 验证数据集的来源和许可条款是否已记录在 ML-BOM 条目中。
 #6.5.4    级别: 2    角色: V
 验证定期监控是否能检测到托管数据集中的漂移或损坏。
 #6.5.5    级别: 3    角色: D
 验证在训练前是否通过自动清理删除了不允许的内容（版权信息、个人身份信息）。

---

### C6.6 供应链攻击监控

通过CVE信息源、审计日志分析和红队模拟，提前检测供应链威胁。

 #6.6.1    级别: 1    角色: V
 验证 CI/CD 审计日志是否流式传输到 SIEM 以检测异常的软件包拉取或篡改的构建步骤。
 #6.6.2    级别: 2    角色: D
 验证事故响应剧本中是否包含对受损模型或库的回滚程序。
 #6.6.3    级别: 3    角色: V
 验证威胁情报增强是否在警报分流中标记了特定于机器学习的指标（例如，模型中毒的威胁指标）。

---

### C6.7 用于模型工件的机器学习物料清单（ML-BOM）

生成并签署详细的特定于机器学习的组件物料清单（ML-BOM），以便下游使用者在部署时能够验证组件的完整性。

 #6.7.1    级别: 1    角色: D/V
 验证每个模型工件是否发布了包含数据集、权重、超参数和许可证的 ML-BOM。
 #6.7.2    级别: 1    角色: D/V
 验证 ML‑BOM 生成和 Cosign 签名在持续集成中是自动化的，并且是合并所必需的。
 #6.7.3    级别: 2    角色: D
 验证如果任何组件元数据（哈希、许可证）缺失，ML-BOM 完整性检查会导致构建失败。
 #6.7.4    级别: 2    角色: V
 验证下游消费者是否可以通过 API 查询 ML-BOM，以在部署时验证导入的模型。
 #6.7.5    级别: 3    角色: V
 验证机器学习物料清单（ML-BOMs）是否经过版本控制并进行差异比较，以检测未经授权的修改。

---

### 参考文献

ML Supply Chain Compromise – MITRE ATLAS
Supply‑chain Levels for Software Artifacts (SLSA)
CycloneDX – Machine Learning Bill of Materials
What is Data Poisoning? – SentinelOne
Transfer Learning Attack – OWASP ML Security Top 10
AI Data Security Best Practices – CISA
Secure CI/CD Supply Chain – Sumo Logic
AI & Transparency: Protect ML Models – ReversingLabs
SBOM Overview – CISA
Training Data Poisoning Guide – Lakera.ai
Dependency Pinning for Reproducible Python – Medium

## C7 模型行为、输出控制与安全保障

### 控制目标

模型输出必须具有结构化、可靠、安全、可解释性，并在生产环境中持续监控。这样可以减少幻觉、隐私泄露、有害内容和失控行为，同时提升用户信任和合规性。

---

### C7.1 输出格式强制执行

严格的模式、受限解码和下游验证在错误或恶意内容传播之前加以阻止。

 #7.1.1    级别: 1    角色: D/V
 验证系统提示中是否提供了响应模式（例如，JSON Schema），并且每个输出都自动进行验证；不符合规范的输出将触发修复或拒绝。
 #7.1.2    级别: 1    角色: D/V
 验证是否启用了受限解码（停止标记、正则表达式、最大令牌数）以防止溢出或提示注入侧信道。
 #7.1.3    级别: 2    角色: D/V
 验证下游组件将输出视为不受信任，并根据架构或注入安全的反序列化器对其进行验证。
 #7.1.4    级别: 3    角色: V
 验证不当输出事件已被记录、限速，并显示在监控中。

---

### C7.2 幻觉检测与缓解

不确定性估计和回退策略抑制虚构答案。

 #7.2.1    级别: 1    角色: D/V
 验证令牌级别的对数概率、集成自洽性或微调的虚假信息检测器是否为每个答案分配置信度得分。
 #7.2.2    级别: 1    角色: D/V
 验证低于可配置置信度阈值的响应是否会触发回退工作流程（例如，增强检索生成、二级模型或人工审核）。
 #7.2.3    级别: 2    角色: D/V
 确保幻觉事件带有根本原因元数据标签，并输入到事后分析和微调管道中。
 #7.2.4    级别: 3    角色: D/V
 确认在重大模型或知识库更新后，阈值和检测器已重新校准。
 #7.2.5    级别: 3    角色: V
 确认仪表板可视化跟踪幻觉率。

---

### C7.3 输出安全性与隐私过滤

策略过滤器和红队覆盖保护用户和机密数据。

 #7.3.1    级别: 1    角色: D/V
 验证生成前后分类器是否阻止符合政策的仇恨、骚扰、自残、极端主义和性露骨内容。
 #7.3.2    级别: 1    角色: D/V
 验证每个响应中是否运行了PII/PCI检测和自动编辑；违规行为将引发隐私事件。
 #7.3.3    级别: 2    角色: D
 验证机密性标签（例如，商业秘密）是否能跨模态传播，以防止在文本、图像或代码中泄露。
 #7.3.4    级别: 3    角色: D/V
 验证过滤器绕过尝试或高风险分类是否需要二次审批或用户重新身份验证。
 #7.3.5    级别: 3    角色: D/V
 验证过滤阈值是否反映法律管辖区以及用户年龄/角色的上下文。

---

### C7.4 输出与动作限制

速率限制和审批关卡防止滥用和过度自主。

 #7.4.1    级别: 1    角色: D
 验证每个用户和每个 API 密钥的配额是否限制请求、令牌和成本，并在遇到 429 错误时采用指数退避策略。
 #7.4.2    级别: 1    角色: D/V
 验证特权操作（文件写入、代码执行、网络调用）是否需要基于策略的批准或人工干预。
 #7.4.3    级别: 2    角色: D/V
 验证跨模态一致性检查确保为同一请求生成的图像、代码和文本不能用于走私恶意内容。
 #7.4.4    级别: 2    角色: D
 验证代理委托深度、递归限制和允许的工具列表是否已明确配置。
 #7.4.5    级别: 3    角色: V
 验证超出限制是否会触发结构化的安全事件以供SIEM摄取。

---

### C7.5 输出可解释性

透明信号提升用户信任和内部调试能力。

 #7.5.1    级别: 2    角色: D/V
 确认在风险评估认为适当时，向用户展示置信度分数或简要推理总结。
 #7.5.2    级别: 2    角色: D/V
 验证生成的解释是否避免泄露敏感的系统提示或专有数据。
 #7.5.3    级别: 3    角色: D
 验证系统是否捕获了令牌级别的对数概率或注意力映射，并将其存储以供授权检查。
 #7.5.4    级别: 3    角色: V
 确保可解释性产物与模型发布一起进行版本控制，以便审计。

---

### C7.6 监控集成

实时可观测性实现了开发与生产之间的闭环。

 #7.6.1    级别: 1    角色: D
 验证指标（模式违规、幻觉率、毒性、个人身份信息泄露、延迟、成本）是否传输到中央监控平台。
 #7.6.2    级别: 1    角色: V
 验证是否为每个安全指标定义了警报阈值，并设有值班升级路径。
 #7.6.3    级别: 2    角色: V
 验证仪表板是否将输出异常与模型/版本、功能标志和上游数据更改相关联。
 #7.6.4    级别: 2    角色: D/V
 验证监控数据是否反馈到已记录的 MLOps 工作流程中的再训练、微调或规则更新中。
 #7.6.5    级别: 3    角色: V
 确保监控流水线经过渗透测试并实施访问控制，以避免敏感日志泄露。

---

### 7.7 生成媒体安全措施

通过执行政策约束、输出验证和可追溯性，确保人工智能系统不生成非法、有害或未经授权的媒体内容。

 #7.7.1    级别: 1    角色: D/V
 确保系统提示和用户指令明确禁止生成非法、有害或未经同意的深度伪造媒体（例如图像、视频、音频）。
 #7.7.2    级别: 2    角色: D/V
 验证提示是否经过过滤，以防止生成冒充行为、色情深度伪造内容或未经同意展示真实个人的媒体。
 #7.7.3    级别: 2    角色: V
 验证系统是否使用感知哈希、水印检测或指纹识别来防止未经授权复制受版权保护的媒体。
 #7.7.4    级别: 3    角色: D/V
 验证所有生成的媒体是否经过加密签名、加水印，或嵌入防篡改的来源元数据，以便后续追踪。
 #7.7.5    级别: 3    角色: V
 验证绕过尝试（例如，提示混淆、俚语、对抗性措辞）是否被检测、记录和限速；重复滥用情况是否被反馈到监控系统。

### 参考文献

NIST AI Risk Management Framework
ISO/IEC 42001:2023 – AI Management System
OWASP Top-10 for Large Language Model Applications (2025)
Improper Output Handling – OWASP LLM05:2025
Practical Techniques to Constrain LLM Output
Dataiku – Structured Text Generation Guide
VL-Uncertainty: Detecting Hallucinations
HaDeMiF: Hallucination Detection & Mitigation
Building Confidence in LLM Outputs
Explainable AI & LLMs
LLM Red-Teaming Guide
Sensitive Information Disclosure in LLMs
LangChain – Chat Model Rate Limiting
OpenAI Rate-Limit & Exponential Back-off
Arize AI – LLM Observability Platform

## C8 内存、嵌入与向量数据库安全

### 控制目标

嵌入和向量存储作为当代人工智能系统的“实时记忆”，持续接受用户提供的数据，并通过检索增强生成（RAG）将其反馈到模型上下文中。如果不加以管理，这种记忆可能泄露个人身份信息（PII）、违反同意规定，或者被逆向利用以重建原始文本。本控制系列的目标是强化记忆处理流程和向量数据库，确保访问权限最小化，嵌入具有隐私保护，存储的向量可过期或按需撤销，并且每个用户的记忆绝不污染其他用户的提示或生成内容。

---

### C8.1 内存和RAG索引的访问控制

对每个向量集合实施细粒度访问控制。

 #8.1.1    级别: 1    角色: D/V
 验证行/命名空间级访问控制规则是否限制每个租户、集合或文档标签的插入、删除和查询操作。
 #8.1.2    级别: 1    角色: D/V
 验证 API 密钥或 JWT 是否包含作用域声明（例如，集合 ID、操作动词），并且至少每季度轮换一次。
 #8.1.3    级别: 2    角色: D/V
 确认权限提升尝试（例如，跨命名空间的相似性查询）能够在5分钟内被检测到并记录到安全信息和事件管理系统（SIEM）中。
 #8.1.4    级别: 2    角色: D/V
 验证向量数据库审核日志是否记录主题标识符、操作、向量ID/命名空间、相似度阈值和结果数量。
 #8.1.5    级别: 3    角色: V
 在引擎升级或索引分片规则变化时，确保访问决策进行绕过缺陷的测试。

---

### C8.2 嵌入清理与验证

在向量化之前，预先筛查文本中的个人身份信息，进行遮盖或假名化，并可选择性地对嵌入进行后处理，以去除残留信号。

 #8.2.1    级别: 1    角色: D/V
 验证通过自动分类器检测到的个人身份信息（PII）和受监管数据是否在嵌入前被掩码、标记化或删除。
 #8.2.2    级别: 1    角色: D
 验证嵌入管道是否拒绝或隔离包含可执行代码或非UTF-8格式的输入，这些输入可能会污染索引。
 #8.2.3    级别: 2    角色: D/V
 验证对与任何已知PII令牌的距离低于可配置阈值的句子嵌入应用了局部或度量差分隐私的脱敏处理。
 #8.2.4    级别: 2    角色: V
 验证清理效果（例如，个人识别信息（PII）去除的召回率，语义漂移）至少每半年通过基准语料库进行验证。
 #8.2.5    级别: 3    角色: D/V
 验证清理配置是否受版本控制，并且更改经过同行评审。

---

### C8.3 内存过期、撤销与删除

GDPR “被遗忘权”及类似法律要求及时删除；因此，向量存储必须支持TTL、硬删除和墓碑机制，以确保被撤销的向量无法被恢复或重新索引。

 #8.3.1    级别: 1    角色: D/V
 验证每个向量和元数据记录是否带有 TTL 或被自动清理任务遵守的显式保留标签。
 #8.3.2    级别: 1    角色: D/V
 验证用户发起的删除请求能在30天内清除向量、元数据、缓存副本和衍生索引。
 #8.3.3    级别: 2    角色: D
 验证逻辑删除操作是否紧随其后进行存储块的加密销毁（如果硬件支持），或者通过密钥保管库中的密钥销毁实现。
 #8.3.4    级别: 3    角色: D/V
 验证过期向量在过期后不到 500 毫秒内被排除在最近邻搜索结果之外。

---

### C8.4 防止嵌入反演和泄露

最近的防御方法——噪声叠加、投影网络、隐私神经元扰动和应用层加密——可以将令牌级别的反演率降低到5%以下。

 #8.4.1    级别: 1    角色: V
 验证是否存在涵盖反演攻击、成员资格攻击和属性推断攻击的正式威胁模型，并且该模型每年进行审核。
 #8.4.2    级别: 2    角色: D/V
 验证应用层加密或可搜索加密是否能够保护向量，防止基础设施管理员或云工作人员的直接读取。
 #8.4.3    级别: 3    角色: V
 验证防御参数（DP的ε值、噪声σ、投影秩k）是否在隐私保护≥99%令牌保护和实用性≤3%准确率损失之间达到平衡。
 #8.4.4    级别: 3    角色: D/V
 验证反转鲁棒性指标是否作为模型更新的发布门控的一部分，并且定义了回归预算。

---

### C8.5 针对用户特定内存的范围强制执行

跨租户泄漏仍然是RAG的主要风险：处理不当的相似性查询可能暴露另一个客户的私人文档。

 #8.5.1    级别: 1    角色: D/V
 确保每个检索查询在传递给大型语言模型（LLM）提示之前，均经过租户/用户ID的后置过滤。
 #8.5.2    级别: 1    角色: D
 验证集合名称或命名空间ID是否按照用户或租户进行加盐处理，以确保向量在不同作用域之间不会发生冲突。
 #8.5.3    级别: 2    角色: D/V
 验证超过可配置距离阈值但超出调用者范围的相似性结果被丢弃并触发安全警报。
 #8.5.4    级别: 2    角色: V
 验证多租户压力测试是否模拟了试图检索超出范围文档的对抗性查询，并展示零泄漏。
 #8.5.5    级别: 3    角色: D/V
 验证加密密钥是否按租户划分，确保即使物理存储共享，也实现密码学隔离。

---

### C8.6 高级内存系统安全

针对包含情景记忆、语义记忆和工作记忆在内的复杂内存架构的安全控制，包含特定的隔离和验证要求。

 #8.6.1    级别: 1    角色: D/V
 验证不同类型的记忆（情景记忆、语义记忆、工作记忆）是否具有独立的安全上下文，采用基于角色的访问控制、独立的加密密钥，并为每种记忆类型记录访问模式。
 #8.6.2    级别: 2    角色: D/V
 验证记忆整合过程是否包括安全验证，以通过内容净化、来源验证和存储前的完整性检查来防止恶意记忆的注入。
 #8.6.3    级别: 2    角色: D/V
 验证内存检索查询是否经过验证和清理，以防止通过查询模式分析、访问控制执行和结果过滤提取未授权的信息。
 #8.6.4    级别: 3    角色: D/V
 验证记忆遗忘机制通过密钥删除、多次覆盖或基于硬件的安全删除及验证证书，具备加密擦除保障，能够安全删除敏感信息。
 #8.6.5    级别: 3    角色: D/V
 通过校验和、审计日志以及当内存内容在正常操作之外发生变化时的自动警报，验证内存系统完整性是否被持续监控以防止未经授权的修改或损坏。

---

### 参考文献

Vector database security: Pinecone – IronCore Labs
Securing the Backbone of AI: Safeguarding Vector Databases and Embeddings – Privacera
Enhancing Data Security with RBAC of Qdrant Vector Database – AI Advances
Mitigating Privacy Risks in LLM Embeddings from Embedding Inversion – arXiv
DPPN: Detecting and Perturbing Privacy-Sensitive Neurons – OpenReview
Art. 17 GDPR – Right to Erasure
Sensitive Data in Text Embeddings Is Recoverable – Tonic.ai
PII Identification and Removal – NVIDIA NeMo Docs
De-identifying Sensitive Data – Google Cloud DLP
Remove PII from Conversations Using Sensitive Information Filters – AWS Bedrock Guardrails
Think Your RAG Is Secure? Think Again – Medium
Design a Secure Multitenant RAG Inferencing Solution – Microsoft Learn
Best Practices for Multi-Tenancy RAG with Milvus – Milvus Blog

## 9 自主编排与代理行为安全

### 控制目标

确保自主或多智能体人工智能系统只能执行明确意图、经过认证、可审计且在成本和风险边界内的操作。这可以防范诸如自主系统被攻陷、工具误用、智能体循环检测、通信劫持、身份伪造、群体操控和意图操纵等威胁。

---

### 9.1 代理任务规划与递归预算

限制递归计划的执行速度，并对特权操作强制设置人工检查点。

 #9.1.1    级别: 1    角色: D/V
 验证每个代理执行的最大递归深度、广度、实时时间、令牌数和货币成本是否已集中配置并受版本控制。
 #9.1.2    级别: 1    角色: D/V
 验证特权或不可逆操作（例如，代码提交、资金转账）在执行前需要通过可审计渠道获得明确的人类批准。
 #9.1.3    级别: 2    角色: D
 验证实时资源监控器在任何预算阈值被超过时触发断路器中断，停止进一步的任务扩展。
 #9.1.4    级别: 2    角色: D/V
 验证电路断路器事件是否记录了代理 ID、触发条件和捕获的计划状态，以供取证审查。
 #9.1.5    级别: 3    角色: V
 验证安全测试涵盖预算耗尽和失控方案情景，确保在无数据丢失的情况下安全停止。
 #9.1.6    级别: 3    角色: D
 验证预算策略以策略即代码的形式表达，并在CI/CD中强制执行，以阻止配置漂移。

---

### 9.2 工具插件沙箱化

隔离工具交互以防止未经授权的系统访问或代码执行。

 #9.2.1    级别: 1    角色: D/V
 验证每个工具/插件是否都在操作系统、容器或 WASM 级别的沙箱中执行，并具备最小权限的文件系统、网络和系统调用策略。
 #9.2.2    级别: 1    角色: D/V
 验证沙箱资源配额（CPU、内存、磁盘、网络出口）和执行超时是否被强制执行并记录。
 #9.2.3    级别: 2    角色: D/V
 验证工具二进制文件或描述符是否经过数字签名；在加载前验证签名。
 #9.2.4    级别: 2    角色: V
 验证沙箱遥测是否流向 SIEM；异常情况（例如，尝试的出站连接）会触发警报。
 #9.2.5    级别: 3    角色: V
 确保高风险插件在生产部署前经过安全审查和渗透测试。
 #9.2.6    级别: 3    角色: D/V
 验证沙箱逃逸尝试是否被自动阻止，并且违规插件是否被隔离以待调查。

---

### 9.3 自主循环与成本界限

检测并阻止失控的代理间递归和成本激增。

 #9.3.1    级别: 1    角色: D/V
 验证代理间调用是否包含由运行时递减和执行的跳数限制或TTL。
 #9.3.2    级别: 2    角色: D
 验证代理是否保持唯一的调用图 ID，以识别自我调用或循环模式。
 #9.3.3    级别: 2    角色: D/V
 验证累计计算单元和支出计数器是否按请求链进行跟踪；超过限制将中止该链。
 #9.3.4    级别: 3    角色: V
 验证形式分析或模型检测证明代理协议中不存在无界递归。
 #9.3.5    级别: 3    角色: D
 验证循环中止事件是否生成警报并反馈持续改进指标。

---

### 9.4 协议级别误用防护

在代理和外部系统之间建立安全的通信渠道，以防止劫持或篡改。

 #9.4.1    级别: 1    角色: D/V
 验证所有代理到工具以及代理到代理的消息是否经过身份验证（例如，双向 TLS 或 JWT）并且实现端到端加密。
 #9.4.2    级别: 1    角色: D
 验证模式是否被严格校验；未知字段或格式错误的消息应被拒绝。
 #9.4.3    级别: 2    角色: D/V
 验证完整性校验（MAC 或数字签名）是否涵盖了整个消息负载，包括工具参数。
 #9.4.4    级别: 2    角色: D
 确保在协议层强制执行重放保护（随机数或时间戳窗口）。
 #9.4.5    级别: 3    角色: V
 验证协议实现是否经过模糊测试和静态分析，以检测注入或反序列化漏洞。

---

### 9.5 代理身份与防篡改证据

确保操作可追溯且修改可检测。

 #9.5.1    级别: 1    角色: D/V
 验证每个代理实例是否拥有唯一的加密身份（密钥对或硬件根凭证）。
 #9.5.2    级别: 2    角色: D/V
 验证所有代理操作均已签名并加盖时间戳；日志包含签名以确保不可否认性。
 #9.5.3    级别: 2    角色: V
 验证篡改证明日志是否存储在仅追加或一次写入介质中。
 #9.5.4    级别: 3    角色: D
 验证身份密钥是否按定义的计划以及在妥协指示时进行轮换。
 #9.5.5    级别: 3    角色: D/V
 验证欺骗或密钥冲突尝试是否会立即触发对受影响代理的隔离。

---

### 9.6 多智能体群体风险降低

通过隔离和正式的安全建模来缓解群体行为风险。

 #9.6.1    级别: 1    角色: D/V
 验证在不同安全域中运行的代理是否在隔离的运行时沙箱或网络分段中执行。
 #9.6.2    级别: 3    角色: V
 在部署之前，确保群体行为已被建模并经过正式验证，以保证其活跃性和安全性。
 #9.6.3    级别: 3    角色: D
 验证运行时监视器是否能够检测到新出现的不安全模式（例如，振荡、死锁）并启动纠正措施。

---

### 9.7 用户与工具认证/授权

为每个代理触发的操作实施严格的访问控制。

 #9.7.1    级别: 1    角色: D/V
 确保代理作为一类主体对下游系统进行身份验证，且绝不重复使用终端用户凭据。
 #9.7.2    级别: 2    角色: D
 验证细粒度授权策略是否限制了代理可以调用哪些工具以及可以提供哪些参数。
 #9.7.3    级别: 2    角色: V
 验证权限检查是否在每次调用时重新评估（持续授权），而不仅仅是在会话开始时。
 #9.7.4    级别: 3    角色: D
 验证委托权限是否会自动过期，并在超时或范围变更后要求重新同意。

---

### 9.8 代理与代理之间的通信安全

加密并完整性保护所有代理间消息，以防止窃听和篡改。

 #9.8.1    级别: 1    角色: D/V
 验证代理通道必须使用双向认证和完美前向保密加密（例如 TLS 1.3）。
 #9.8.2    级别: 1    角色: D
 在处理之前，验证消息的完整性和来源；验证失败时触发警报并丢弃该消息。
 #9.8.3    级别: 2    角色: D/V
 验证通信元数据（时间戳，序列号）是否被记录以支持取证重建。
 #9.8.4    级别: 3    角色: V
 验证形式化验证或模型检查确认协议状态机无法进入不安全状态。

---

### 9.9 意图验证与约束执行

验证代理操作是否符合用户陈述的意图和系统约束。

 #9.9.1    级别: 1    角色: D
 验证预执行约束求解器是否根据硬编码的安全和策略规则检查所提议的操作。
 #9.9.2    级别: 2    角色: D/V
 验证高影响操作（财务、破坏性、隐私敏感型）是否需要发起用户的明确意图确认。
 #9.9.3    级别: 2    角色: V
 验证后置条件检查，以确保已完成的操作实现预期效果且无副作用；若有不符，触发回滚。
 #9.9.4    级别: 3    角色: V
 验证形式方法（例如，模型检验、定理证明）或基于属性的测试能够证明智能体计划满足所有声明的约束条件。
 #9.9.5    级别: 3    角色: D
 验证意图不匹配或约束违规事件是否促进持续改进循环和威胁情报共享。

---

### 9.10 代理推理策略安全

安全选择和执行包括ReAct、Chain-of-Thought和Tree-of-Thoughts方法在内的不同推理策略。

 #9.10.1    级别: 1    角色: D/V
 验证推理策略选择使用确定性标准（输入复杂性、任务类型、安全上下文），并且在相同安全上下文中，相同输入产生相同的策略选择。
 #9.10.2    级别: 1    角色: D/V
 验证每种推理策略（ReAct、Chain-of-Thought、Tree-of-Thoughts）是否具有针对其认知方法的专用输入验证、输出清理和执行时间限制。
 #9.10.3    级别: 2    角色: D/V
 验证推理策略转换是否记录了完整的上下文，包括输入特征、选择标准值和执行元数据，以便审计轨迹重建。
 #9.10.4    级别: 2    角色: D/V
 验证 Tree-of-Thoughts 推理是否包括分支剪枝机制，当检测到策略违规、资源限制或安全边界时终止探索。
 #9.10.5    级别: 2    角色: D/V
 验证 ReAct（推理-行动-观察）循环在每个阶段包含验证检查点：推理步骤验证、行动授权以及观察净化，然后再继续。
 #9.10.6    级别: 3    角色: D/V
 验证推理策略的性能指标（执行时间、资源使用、输出质量）是否被监控，并且当指标偏离配置的阈值时是否有自动警报。
 #9.10.7    级别: 3    角色: D/V
 验证结合多种策略的混合推理方法是否保持所有组成策略的输入验证和输出约束，且不绕过任何安全控制。
 #9.10.8    级别: 3    角色: D/V
 验证推理策略安全测试包括使用格式错误的输入进行模糊测试、设计用于强制策略切换的对抗性提示，以及对每种认知方法进行边界条件测试。

---

### 9.11 代理生命周期状态管理与安全

通过加密审计轨迹和定义的恢复程序实现安全的代理初始化、状态转换和终止。

 #9.11.1    级别: 1    角色: D/V
 验证代理初始化是否包括使用硬件支持的凭证建立加密身份，以及包含代理ID、时间戳、配置哈希和值初始化参数的不可变启动审计日志。
 #9.11.2    级别: 2    角色: D/V
 验证代理状态转换是否经过加密签名、时间戳标记，并且记录完整的上下文信息，包括触发事件、先前状态哈希、新状态哈希以及所执行的安全验证。
 #9.11.3    级别: 2    角色: D/V
 验证代理关闭程序是否包括使用加密擦除或多遍覆盖进行安全内存清除，凭证撤销并通知证书颁发机构，以及生成防篡改的终止证书。
 #9.11.4    级别: 3    角色: D/V
 验证代理恢复机制通过使用加密校验和（至少为 SHA-256）来验证状态完整性，并在检测到损坏时回滚到已知良好状态，同时具备自动警报和人工审批要求。
 #9.11.5    级别: 3    角色: D/V
 验证代理持久化机制是否使用每个代理的 AES-256 密钥加密敏感状态数据，并在可配置的计划（最多 90 天）上实现安全的密钥轮换，且支持零停机部署。

---

### 9.12 工具集成安全框架

针对动态工具加载、执行和结果验证的安全控制，包含定义的风险评估和审批流程。

 #9.12.1    级别: 1    角色: D/V
 验证工具描述符是否包含指定所需权限（读/写/执行）、风险级别（低/中/高）、资源限制（CPU、内存、网络）以及工具清单中记录的校验要求的安全元数据。
 #9.12.2    级别: 1    角色: D/V
 确认工具执行结果在与超时限制和错误处理程序集成之前，已根据预期的架构（JSON 架构、XML 架构）和安全策略（输出清理、数据分类）进行验证。
 #9.12.3    级别: 2    角色: D/V
 验证工具交互日志是否包含详细的安全上下文，包括权限使用情况、数据访问模式、执行时间、资源消耗和返回代码，并采用结构化日志记录以便集成安全信息和事件管理系统（SIEM）。
 #9.12.4    级别: 2    角色: D/V
 验证动态工具加载机制是否使用基于公钥基础设施（PKI）的数字签名进行验证，并在执行前实施具有沙箱隔离和权限验证的安全加载协议。
 #9.12.5    级别: 3    角色: D/V
 验证工具安全评估是否会针对新版本自动触发，且包含强制审批关卡，包括静态分析、动态测试和安全团队审核，并具备有文档记录的审批标准和服务级别协议（SLA）要求。

---

#### 参考文献

MITRE ATLAS tactics ML09
Circuit-breaker research for AI agents — Zou et al., 2024
Trend Micro analysis of sandbox escapes in AI agents — Park, 2025
Auth0 guidance on human-in-the-loop authorization for agents — Martinez, 2025
Medium deep-dive on MCP & A2A protocol hijacking — ForAISec, 2025
Rapid7 fundamentals on spoofing attack prevention — 2024
Imperial College verification of swarm systems — Lomuscio et al.
NIST AI Risk Management Framework 1.0, 2023
WIRED security briefing on encryption best practices, 2024
OWASP Top 10 for LLM Applications, 2025
Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS
[How Is LLM Reasoning Distracted by Irrelevant Context?
An Analysis Using a Controlled Benchmark](https://www.arxiv.org/pdf/2505.18761)
Large Language Model Sentinel: LLM Agent for Adversarial Purification
Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents

## 10 对抗性鲁棒性与隐私防御

### 控制目标

确保在面对规避、推断、提取或投毒攻击时，人工智能模型保持可靠性、隐私保护性和抗滥用能力。

---

### 10.1 模型对齐与安全

防范有害或违反政策的输出。

 #10.1.1    级别: 1    角色: D/V
 验证对齐测试套件（红队提示、越狱探测、不允许内容）是否进行版本控制，并在每次模型发布时执行。
 #10.1.2    级别: 1    角色: D
 验证拒绝和安全完成保护措施是否得到执行。
 #10.1.3    级别: 2    角色: D/V
 验证自动评估器是否测量有害内容率并标记超过设定阈值的回归。
 #10.1.4    级别: 2    角色: D
 验证反越狱训练是否有文档记录且可复现。
 #10.1.5    级别: 3    角色: V
 验证正式的政策合规证明或认证监控是否涵盖关键领域。

---

### 10.2 对抗样本强化

提高对操纵输入的弹性。稳健的对抗训练和基准评分是当前的最佳实践。

 #10.2.1    级别: 1    角色: D
 验证项目仓库是否包含带有可复现种子的对抗训练配置。
 #10.2.2    级别: 2    角色: D/V
 验证对抗样本检测是否在生产流程中触发拦截警报。
 #10.2.4    级别: 3    角色: V
 验证认证的鲁棒性证明或区间界证书是否至少覆盖了最关键的顶级类别。
 #10.2.5    级别: 3    角色: V
 验证回归测试使用自适应攻击以确认没有可测量的鲁棒性损失。

---

### 10.3 会员推断缓解

限制判断某条记录是否在训练数据中的能力。差分隐私和置信度分数掩码仍然是已知的最有效防御手段。

 #10.3.1    级别: 1    角色: D
 验证每次查询的熵正则化或温度缩放是否减少过度自信的预测。
 #10.3.2    级别: 2    角色: D
 验证训练过程中对敏感数据集采用了ε-界限差分隐私优化。
 #10.3.3    级别: 2    角色: V
 验证攻击模拟（影子模型或黑盒）在保留数据上的攻击AUC是否≤ 0.60。

---

### 10.4 模型反演抗性

防止私有属性的重建。近期调查强调输出截断和差分隐私（DP）保证作为实用防御措施。

 #10.4.1    级别: 1    角色: D
 确保敏感属性绝不被直接输出；在需要时，使用分桶或单向变换。
 #10.4.2    级别: 1    角色: D/V
 验证查询速率限制是否对同一主体的重复自适应查询进行节流。
 #10.4.3    级别: 2    角色: D
 验证模型是否经过隐私保护噪声训练。

---

### 10.5 模型提取防御

检测并阻止未经授权的克隆。建议使用水印和查询模式分析。

 #10.5.1    级别: 1    角色: D
 验证推理网关是否实施了针对模型记忆阈值调整的全局和每个API密钥的速率限制。
 #10.5.2    级别: 2    角色: D/V
 验证查询熵和输入复数统计是否为自动提取检测器提供数据。
 #10.5.3    级别: 2    角色: V
 验证脆弱或概率水印在对疑似克隆体进行不超过1000次查询时，是否能够以p < 0.01的显著性水平被证实。
 #10.5.4    级别: 3    角色: D
 验证水印密钥和触发集是否存储在硬件安全模块中，并且每年进行轮换。
 #10.5.5    级别: 3    角色: V
 验证提取警报事件是否包含违规查询，并且是否已集成到事件响应剧本中。

---

### 10.6 推理时的中毒数据检测

识别并中和带有后门或被投毒的输入。

 #10.6.1    级别: 1    角色: D
 在模型推理之前，验证输入是否通过异常检测器（例如，STRIP、一致性评分）。
 #10.6.2    级别: 1    角色: V
 验证检测器阈值是否已在干净/被污染的验证集上调整，以实现低于5%的误报率。
 #10.6.3    级别: 2    角色: D
 验证被标记为中毒的输入是否触发软阻断和人工审核工作流程。
 #10.6.4    级别: 2    角色: V
 验证检测器是否经过自适应、无触发器后门攻击的压力测试。
 #10.6.5    级别: 3    角色: D
 验证检测效能指标是否被记录，并且定期使用最新的威胁情报进行重新评估。

---

### 10.7 动态安全策略适应

基于威胁情报和行为分析的实时安全策略更新。

 #10.7.1    级别: 1    角色: D/V
 验证安全策略是否可以在不重启代理的情况下动态更新，同时保持策略版本完整性。
 #10.7.2    级别: 2    角色: D/V
 验证策略更新是否由授权的安全人员进行加密签名，并在应用前进行验证。
 #10.7.3    级别: 2    角色: D/V
 验证动态策略变更是否记录了完整的审计追踪，包括理由、审批链和回滚程序。
 #10.7.4    级别: 3    角色: D/V
 验证自适应安全机制是否根据风险上下文和行为模式调整威胁检测灵敏度。
 #10.7.5    级别: 3    角色: D/V
 验证策略调整决策的可解释性，并包含供安全团队审查的证据链。

---

### 10.8 基于反射的安全分析

通过代理自我反思和元认知分析进行安全验证。

 #10.8.1    级别: 1    角色: D/V
 验证代理反思机制是否包括针对安全性的决策和行动自我评估。
 #10.8.2    级别: 2    角色: D/V
 验证反射输出以防止对抗性输入操纵自我评估机制。
 #10.8.3    级别: 2    角色: D/V
 验证元认知安全分析是否识别代理推理过程中的潜在偏见、操纵或妥协。
 #10.8.4    级别: 3    角色: D/V
 验证基于反射的安全警告是否会触发增强监控和潜在人为干预工作流程。
 #10.8.5    级别: 3    角色: D/V
 验证从安全反思中持续学习能够提升威胁检测能力，同时不降低合法功能的性能。

---

### 10.9 进化与自我提升安全

具备自我修改和演化能力的代理系统的安全控制措施。

 #10.9.1    级别: 1    角色: D/V
 验证自我修改能力仅限于指定的安全区域，并具有正式验证边界。
 #10.9.2    级别: 2    角色: D/V
 确保进化提案在实施前经过安全影响评估。
 #10.9.3    级别: 2    角色: D/V
 验证自我改进机制包括带有完整性验证的回滚功能。
 #10.9.4    级别: 3    角色: D/V
 验证元学习安全性是否防止对改进算法的对抗性操纵。
 #10.9.5    级别: 3    角色: D/V
 验证递归自我改进受形式安全约束的限制，并通过数学收敛性证明证明其有效性。

---

#### 参考文献

MITRE ATLAS adversary tactics for ML
NIST AI Risk Management Framework 1.0, 2023
OWASP Top 10 for LLM Applications, 2025
Adversarial Training: A Survey — Zhao et al., 2024
RobustBench adversarial-robustness benchmark
Membership-Inference & Model-Inversion Risk Survey, 2025
PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023
Model-Inversion Attacks & Defenses Survey — AI Review, 2025
Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024
Fragile Model Watermarking Survey — 2025
Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025
BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024

## 11 隐私保护与个人数据管理

### 控制目标

在整个 AI 生命周期——数据收集、训练、推理和事件响应中保持严格的隐私保障，确保个人数据仅在明确同意、最小必要范围、可证明的删除以及正式的隐私保证下被处理。

---

### 11.1 匿名化与数据最小化

 #11.1.1    级别: 1    角色: D/V
 验证直接标识符和准标识符是否被删除或哈希处理。
 #11.1.2    级别: 2    角色: D/V
 验证自动审核是否测量k-匿名性/l-多样性，并在阈值低于策略时发出警报。
 #11.1.3    级别: 2    角色: V
 验证模型特征重要性报告，证明标识符泄露的互信息不超过ε = 0.01。
 #11.1.4    级别: 3    角色: V
 验证正式证明或合成数据认证即使在关联攻击下也能显示再识别风险 ≤ 0.05。

---

### 11.2 被遗忘权与删除执行

 #11.2.1    级别: 1    角色: D/V
 验证数据主体删除请求是否在少于30天的服务级别协议内传播到原始数据集、检查点、嵌入、日志和备份。
 #11.2.2    级别: 2    角色: D
 验证“机器遗忘”程序是否通过经过认证的遗忘算法实际重新训练或近似删除。
 #11.2.3    级别: 2    角色: V
 验证影子模型评估证明遗忘记录在遗忘后对输出的影响少于1%。
 #11.2.4    级别: 3    角色: V
 验证删除事件是否以不可变方式记录并可供监管机构审计。

---

### 11.3 差分隐私保护措施

 #11.3.1    级别: 2    角色: D/V
 验证隐私损失核算仪表板在累积ε超过政策阈值时发出警报。
 #11.3.2    级别: 2    角色: V
 验证黑箱隐私审计在宣称值的10%范围内估计ε̂。
 #11.3.3    级别: 3    角色: V
 验证形式化证明涵盖所有训练后微调和嵌入。

---

### 11.4 目的限制与范围蔓延保护

 #11.4.1    级别: 1    角色: D
 验证每个数据集和模型检查点是否附有与原始同意一致的机器可读用途标签。
 #11.4.2    级别: 1    角色: D/V
 验证运行时监视器是否能够检测出与声明用途不一致的查询并触发软拒绝。
 #11.4.3    级别: 3    角色: D
 验证策略即代码门禁，确保未经DPIA审查，模型不能重新部署到新领域。
 #11.4.4    级别: 3    角色: V
 验证正式的可追溯性证明，确保每一个个人数据生命周期都保持在已同意的范围内。

---

### 11.5 同意管理与合法依据跟踪

 #11.5.1    级别: 1    角色: D/V
 验证同意管理平台（CMP）是否记录了每个数据主体的选择加入状态、目的和保留期限。
 #11.5.2    级别: 2    角色: D
 验证API是否公开了同意令牌；模型在推理前必须验证令牌的范围。
 #11.5.3    级别: 2    角色: D/V
 验证拒绝或撤销的同意是否在24小时内停止处理流程。

---

### 11.6 带隐私控制的联邦学习

 #11.6.1    级别: 1    角色: D
 验证客户端更新在聚合之前是否采用了本地差分隐私噪声添加。
 #11.6.2    级别: 2    角色: D/V
 验证训练指标具有差分隐私性，且绝不泄露单个客户的损失。
 #11.6.3    级别: 2    角色: V
 确认已启用抗中毒聚合（例如，Krum/修剪均值）。
 #11.6.4    级别: 3    角色: V
 验证形式证明显示整体 ε 预算的效用损失小于 5。

---

#### 参考文献

GDPR & AI Compliance Best Practices
EU Parliament Study on GDPR & AI, 2020
ISO 31700-1:2023 — Privacy by Design for Consumer Products
NIST Privacy Framework 1.1 (2025 Draft)
Machine Unlearning: Right-to-Be-Forgotten Techniques
A Survey of Machine Unlearning, 2024
Auditing DP-SGD — ArXiv 2024
DP-SGD Explained — PyTorch Blog
Purpose-Limitation for AI — IJLIT 2025
Data-Protection Considerations for AI — URM Consulting
Top Consent-Management Platforms, 2025
Secure Aggregation in DP Federated Learning — ArXiv 2024

## C12 监控、日志记录与异常检测

### 控制目标

本节提供了关于实现对模型和其他人工智能组件所见、所做及所返回内容的实时和取证可见性的要求，以便能够检测、分级处理和从中学习威胁。

### C12.1 请求与响应日志记录

 #12.1.1    级别: 1    角色: D/V
 验证所有用户提示和模型响应是否记录了适当的元数据（例如时间戳、用户ID、会话ID、模型版本）。
 #12.1.2    级别: 1    角色: D/V
 验证日志是否存储在安全的、受访问控制的库中，并且具备适当的保留政策和备份程序。
 #12.1.3    级别: 1    角色: D/V
 验证日志存储系统是否实现了静态加密和传输加密，以保护日志中包含的敏感信息。
 #12.1.4    级别: 1    角色: D/V
 验证提示和输出中的敏感数据在记录之前是否会被自动编辑或屏蔽，并且针对个人身份信息（PII）、凭证和专有信息具有可配置的编辑规则。
 #12.1.5    级别: 2    角色: D/V
 验证策略决策和安全过滤操作是否有足够的详细记录，以便对内容审核系统进行审计和调试。
 #12.1.6    级别: 2    角色: D/V
 验证日志完整性是否通过例如加密签名或只写存储得到了保护。

---

### C12.2 滥用检测与警报

 #12.2.1    级别: 1    角色: D/V
 验证系统是否能够使用基于签名的检测方法，检测并警报已知的越狱模式、提示注入尝试和对抗性输入。
 #12.2.2    级别: 1    角色: D/V
 验证系统是否通过标准日志格式和协议与现有的安全信息与事件管理（SIEM）平台集成。
 #12.2.3    级别: 2    角色: D/V
 验证丰富的安全事件是否包含特定于人工智能的上下文，例如模型标识符、置信度评分和安全过滤器决策。
 #12.2.4    级别: 2    角色: D/V
 验证行为异常检测是否能识别异常的对话模式、过多的重试尝试或系统性的探测行为。
 #12.2.5    级别: 2    角色: D/V
 验证实时警报机制在检测到潜在的策略违规或攻击尝试时是否通知安全团队。
 #12.2.6    级别: 2    角色: D/V
 验证是否包含用于检测特定于人工智能的威胁模式的自定义规则，包括协调的越狱尝试、提示注入活动和模型提取攻击。
 #12.2.7    级别: 3    角色: D/V
 验证自动化事件响应工作流是否能够隔离被攻陷的模型、阻止恶意用户，以及升级关键安全事件。

---

### C12.3 模型漂移检测

 #12.3.1    级别: 1    角色: D/V
 验证系统是否跟踪基本性能指标，如准确率、置信度分数、延迟和错误率，涵盖不同模型版本和时间段。
 #12.3.2    级别: 2    角色: D/V
 验证当性能指标超过预定义退化阈值或显著偏离基线时，自动告警是否触发。
 #12.3.3    级别: 2    角色: D/V
 验证幻觉检测监控是否能够识别并标记模型输出中包含事实错误、不一致或虚构信息的情况。

---

### C12.4 性能与行为遥测

 #12.4.1    级别: 1    角色: D/V
 验证包括请求延迟、令牌消耗、内存使用情况和吞吐量在内的操作指标是否被持续收集和监控。
 #12.4.2    级别: 1    角色: D/V
 确认成功率和失败率是否被跟踪，并对错误类型及其根本原因进行分类。
 #12.4.3    级别: 2    角色: D/V
 验证资源利用监控是否包括GPU/CPU使用率、内存消耗和存储需求，并在阈值超出时发出警报。

---

### C12.5 人工智能事件响应计划与执行

 #12.5.1    级别: 1    角色: D/V
 验证事件响应计划是否具体涵盖与人工智能相关的安全事件，包括模型被破坏、数据投毒和对抗攻击。
 #12.5.2    级别: 2    角色: D/V
 确保事件响应团队能够访问专门针对人工智能的取证工具和专业知识，以便调查模型行为和攻击路径。
 #12.5.3    级别: 3    角色: D/V
 验证事后分析是否包括模型再训练的考虑、安全过滤器的更新以及教训融入安全控制中。

---

### C12.5 人工智能性能退化检测

监控并检测AI模型性能和质量随时间的退化。

 #12.5.1    级别: 1    角色: D/V
 验证模型的准确率、精确率、召回率和F1分数是否被持续监控并与基准阈值进行比较。
 #12.5.2    级别: 1    角色: D/V
 验证数据漂移检测是否监控可能影响模型性能的输入分布变化。
 #12.5.3    级别: 2    角色: D/V
 验证概念漂移检测是否识别输入与期望输出之间关系的变化。
 #12.5.4    级别: 2    角色: D/V
 验证性能下降是否触发自动警报并启动模型重新训练或替换工作流程。
 #12.5.5    级别: 3    角色: V
 验证降级根本原因分析是否将性能下降与数据变化、基础设施问题或外部因素相关联。

---

### C12.6 DAG 可视化与工作流安全

保护工作流可视化系统，防止信息泄露和篡改攻击。

 #12.6.1    级别: 1    角色: D/V
 验证DAG可视化数据在存储或传输前已被清理，以移除敏感信息。
 #12.6.2    级别: 1    角色: D/V
 验证工作流可视化访问控制，确保只有授权用户可以查看代理决策路径和推理轨迹。
 #12.6.3    级别: 2    角色: D/V
 验证DAG数据完整性是否通过加密签名和防篡改存储机制得到保护。
 #12.6.4    级别: 2    角色: D/V
 验证工作流可视化系统是否实施了输入验证，以防止通过特制的节点或边数据进行注入攻击。
 #12.6.5    级别: 3    角色: D/V
 验证实时DAG更新是否受速率限制并经过验证，以防止对可视化系统的拒绝服务攻击。

---

### C12.7 主动安全行为监控

通过主动代理行为分析进行安全威胁的检测与预防。

 #12.7.1    级别: 1    角色: D/V
 在执行之前，验证主动代理行为经过安全验证，并集成风险评估。
 #12.7.2    级别: 2    角色: D/V
 验证自主主动触发机制是否包括安全上下文评估和威胁态势评估。
 #12.7.3    级别: 2    角色: D/V
 验证主动行为模式是否经过分析，以评估潜在的安全影响和意外后果。
 #12.7.4    级别: 3    角色: D/V
 验证安全关键的主动措施需要有明确的批准链和审计跟踪。
 #12.7.5    级别: 3    角色: D/V
 验证行为异常检测是否能够识别主动代理模式中的偏差，这些偏差可能表明存在被攻击风险。

---

### 参考文献

NIST AI Risk Management Framework 1.0 - Manage 4.1 and 4.3
ISO/IEC 42001:2023 — AI Management Systems Requirements - Annex B 6.2.6
EU AI Act — Article 12, 13, 16 and 19 on Logging and Record-keeping

## C13 人类监督、问责与治理

### 控制目标

本章提供了在人工智能系统中维护人类监督和明确责任链的要求，确保在整个人工智能生命周期中实现可解释性、透明度和伦理管理。

---

### C13.1 终止开关与覆盖机制

当观察到人工智能系统存在不安全行为时，应提供关机或回滚路径。

 #13.1.1    级别: 1    角色: D/V
 验证是否存在手动杀死开关机制，以立即停止 AI 模型推理和输出。
 #13.1.2    级别: 1    角色: D
 确认覆盖控制仅对授权人员可访问。
 #13.1.3    级别: 3    角色: D/V
 验证回滚程序能够恢复到先前的模型版本或安全模式操作。
 #13.1.4    级别: 3    角色: V
 验证覆盖机制是否定期测试。

---

### C13.2 人类参与决策检查点

当风险超出预设阈值时，要求人工审批。

 #13.2.1    级别: 1    角色: D/V
 验证高风险的人工智能决策在执行前需要明确的人类批准。
 #13.2.2    级别: 1    角色: D
 验证风险阈值是否被明确定义并自动触发人工审核工作流程。
 #13.2.3    级别: 2    角色: D
 确认在无法在规定时间内获得人工批准时，时间敏感的决策有备选程序。
 #13.2.4    级别: 3    角色: D/V
 如适用，验证升级程序是否为不同的决策类型或风险类别定义了明确的权限级别。

---

### C13.3 责任链与可审计性

记录操作员动作和模型决策。

 #13.3.1    级别: 1    角色: D/V
 验证所有人工智能系统的决策和人工干预均记录有时间戳、用户身份和决策理由。
 #13.3.2    级别: 2    角色: D
 验证审计日志无法被篡改，并包含完整性验证机制。

---

### C13.4 可解释人工智能技术

表面特征重要性、反事实和局部解释。

 #13.4.1    级别: 1    角色: D/V
 验证人工智能系统是否以人类可读的格式提供其决策的基本解释。
 #13.4.2    级别: 2    角色: V
 通过人工评估研究和指标验证解释质量。
 #13.4.3    级别: 3    角色: D/V
 验证关键决策是否提供特征重要性分数或归因方法（SHAP、LIME 等）。
 #13.4.4    级别: 3    角色: V
 验证反事实解释是否展示了如何修改输入以改变结果（如果适用于使用案例和领域）。

---

### C13.5 模型卡与使用披露

维护模型卡片，以记录预期用途、性能指标和伦理考量。

 #13.5.1    级别: 1    角色: D
 验证模型卡是否记录了预期的使用场景、限制条件和已知的失败模式。
 #13.5.2    级别: 1    角色: D/V
 核实是否披露了不同适用用例中的性能指标。
 #13.5.3    级别: 2    角色: D
 确认伦理考量、偏见评估、公平性评价、训练数据特征以及已知的训练数据限制已被记录并定期更新。
 #13.5.4    级别: 2    角色: D/V
 确认模型卡在整个模型生命周期中经过版本控制和维护，并进行变更跟踪。

---

### C13.6 不确定性量化

在响应中传播置信度分数或熵度量。

 #13.6.1    级别: 1    角色: D
 验证 AI 系统是否在其输出中提供置信度评分或不确定性度量。
 #13.6.2    级别: 2    角色: D/V
 验证不确定性阈值是否触发额外的人类审核或替代决策路径。
 #13.6.3    级别: 2    角色: V
 验证不确定性量化方法是否经过校准并且已针对真实数据进行验证。
 #13.6.4    级别: 3    角色: D/V
 验证不确定性传播在多步骤人工智能工作流中得以维持。

---

### C13.7 面向用户的透明度报告

定期披露事件、漂移和数据使用情况。

 #13.7.1    级别: 1    角色: D/V
 确认数据使用政策和用户同意管理实践已清晰传达给利益相关者。
 #13.7.2    级别: 2    角色: D/V
 验证是否已进行人工智能影响评估，并将结果纳入报告中。
 #13.7.3    级别: 2    角色: D/V
 验证定期发布的透明度报告是否以合理的细节披露了人工智能事件和运营指标。

#### 参考文献

EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
ISO/IEC 42001:2023 — AI Management Systems Requirements
NIST AI Risk Management Framework 1.0
NIST SP 800-53 Revision 5 — Security and Privacy Controls
A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)
Model Cards for Model Reporting (Mitchell et al., 2018)
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)
ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods
IEEE 7001-2021 — Transparency of Autonomous Systems
GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)
Human Oversight under Article 14 of the EU AI Act (Fink, 2025)

## 附录 A：术语表

本综合词汇表提供了AISVS中使用的关键AI、机器学习和安全术语的定义，以确保清晰和共识。

对抗样本：一种故意设计的输入，旨在使人工智能模型发生错误，通常通过添加人类难以察觉的微小扰动实现。
​
对抗鲁棒性——在人工智能中，对抗鲁棒性指的是模型保持其性能并抵抗由故意设计的恶意输入所造成错误的能力。
​
代理——AI代理是使用人工智能代表用户追求目标和完成任务的软件系统。它们表现出推理、规划和记忆能力，具备一定程度的自主性以进行决策、学习和适应。
​
代理人工智能：能够在一定程度上自主运行以实现目标的人工智能系统，通常能够在没有直接人工干预的情况下做出决策和采取行动。
​
基于属性的访问控制（ABAC）：一种访问控制范式，其授权决策基于用户、资源、操作和环境的属性，这些属性在查询时进行评估。
​
后门攻击：一种数据投毒攻击，模型被训练成在遇到特定触发器时以特定方式响应，而在其他情况下表现正常。
​
偏差：人工智能模型输出中的系统性错误，可能导致对特定群体或在特定情境下产生不公平或歧视性的结果。
​
偏见利用：一种利用AI模型中已知偏见来操控输出或结果的攻击技术。
​
Cedar：亚马逊用于实现 AI 系统基于属性的访问控制（ABAC）的细粒度权限的策略语言和引擎。
​
连锁思维：一种通过在生成最终答案之前产生中间推理步骤来提升语言模型推理能力的技术。
​
断路器：当超过特定风险阈值时，自动停止 AI 系统操作的机制。
​
数据泄露：通过人工智能模型的输出或行为无意中暴露敏感信息。
​
数据投毒：故意篡改训练数据以破坏模型完整性，通常用于植入后门或降低性能。
​
差分隐私——差分隐私是一种数学上严谨的框架，用于在保护个人数据主体隐私的同时发布有关数据集的统计信息。它使数据持有者能够共享群体的汇总模式，同时限制泄露关于特定个体的信息。
​
嵌入：数据（文本、图像等）的稠密向量表示，能够在高维空间中捕捉语义意义。
​
可解释性——人工智能中的可解释性是指AI系统能够为其决策和预测提供人类可理解的理由，揭示其内部运作机制的能力。
​
可解释人工智能（XAI）：旨在通过各种技术和框架，为其决策和行为提供人类可理解解释的人工智能系统。
​
联邦学习：一种机器学习方法，在多个分散的设备上训练模型，这些设备持有本地数据样本，但不交换数据本身。
​
警戒线：为防止人工智能系统产生有害的、带偏见的或其他不良输出而实施的限制。
​
幻觉——AI幻觉指的是一种现象，其中AI模型生成的不正确或误导性的信息并非基于其训练数据或事实现实。
​
人机协同（HITL）：设计为在关键决策点需要人工监督、验证或干预的系统。
​
基础设施即代码（IaC）：通过代码而非手动过程管理和配置基础设施，实现安全扫描和一致的部署。
​
越狱：用于规避AI系统中安全防护措施的技术，尤其是在大型语言模型中，以生成被禁止的内容。
​
最小权限原则：授予用户和进程仅所需的最低访问权限的安全原则。
​
LIME（局部可解释模型无关解释）：一种通过局部近似可解释模型来解释任何机器学习分类器预测结果的技术。
​
成员推断攻击：一种旨在确定特定数据点是否被用来训练机器学习模型的攻击。
​
MITRE ATLAS：针对人工智能系统的对抗威胁全景；一个关于针对AI系统的对抗策略和技术的知识库。
​
模型卡——模型卡是一种文档，提供关于人工智能模型的性能、局限性、预期用途和伦理考虑的标准化信息，以促进透明性和负责任的人工智能开发。
​
模型提取：一种攻击方式，攻击者通过反复查询目标模型，未经授权创建一个功能上相似的副本。
​
模型反演：一种通过分析模型输出尝试重建训练数据的攻击。
​
模型生命周期管理——AI模型生命周期管理是指监督AI模型存在的所有阶段的过程，包括其设计、开发、部署、监控、维护以及最终退役，以确保其持续有效并符合目标。
​
模型投毒：在训练过程中直接向模型引入漏洞或后门。
​
模型窃取/盗用：通过反复查询提取专有模型的副本或近似版本。
​
多智能体系统：由多个相互作用的AI智能体组成的系统，每个智能体可能具有不同的能力和目标。
​
OPA（开源策略代理）：一个开源的策略引擎，可实现跨整个技术栈的统一策略执行。
​
隐私保护机器学习（PPML）：在保护训练数据隐私的同时训练和部署机器学习模型的技术和方法。
​
提示注入：一种攻击方式，将恶意指令嵌入输入中，以覆盖模型的预期行为。
​
RAG（检索增强生成）：一种通过在生成回复之前从外部知识源检索相关信息来增强大型语言模型的技术。
​
红队演练：通过模拟对抗性攻击积极测试人工智能系统以识别漏洞的做法。
​
SBOM（软件物料清单）：一份正式记录，包含构建软件或AI模型所使用的各个组件的详细信息及其供应链关系。
​
SHAP（Shapley加性解释）：一种博弈论方法，通过计算每个特征对预测结果的贡献，来解释任何机器学习模型的输出。
​
供应链攻击：通过攻击系统供应链中安全性较低的元素（如第三方库、数据集或预训练模型）来入侵系统。
​
迁移学习：一种技术，其中为一项任务开发的模型被重新用作另一项任务模型的起点。
​
向量数据库：一种专门设计用于存储高维向量（嵌入）并执行高效相似性搜索的数据库。
​
漏洞扫描：自动化工具，用于识别软件组件中的已知安全漏洞，包括人工智能框架和依赖项。
​
水印技术：在 AI 生成的内容中嵌入难以察觉的标记，以追踪其来源或检测 AI 生成。
​
零日漏洞：指攻击者在开发人员创建和部署补丁之前即可利用的先前未知的漏洞。

## 附录 B：参考文献

### TODO

## 附录 C：人工智能安全治理与文档管理

### 目标

本附录提供了建立组织结构、政策和流程的基础性要求，以贯穿系统生命周期管理人工智能安全。

---

### AC.1 人工智能风险管理框架采纳

提供一个正式的框架，用于在系统生命周期中识别、评估和缓解特定于人工智能的风险。

 #AC.1.1    级别: 1    角色: D/V
 验证是否有针对人工智能的风险评估方法论已经文档化并实施。
 #AC.1.2    级别: 2    角色: D
 验证在人工智能生命周期的关键点以及重大变更之前是否进行了风险评估。
 #AC.1.3    级别: 3    角色: D/V
 验证风险管理框架是否符合既定标准（例如，NIST AI RMF）。

---

### AC.2 人工智能安全政策与程序

定义并执行组织标准，以确保人工智能的安全开发、部署和运行。

 #AC.2.1    级别: 1    角色: D/V
 核实是否存在已记录的人工智能安全政策。
 #AC.2.2    级别: 2    角色: D
 确保政策至少每年审查和更新一次，并且在发生重大威胁态势变化后进行更新。
 #AC.2.3    级别: 3    角色: D/V
 验证政策是否涵盖所有AISVS类别以及适用的监管要求。

---

### AC.3 AI 安全的角色与职责

在整个组织内建立明确的AI安全责任。

 #AC.3.1    级别: 1    角色: D/V
 确认人工智能安全角色和职责已被记录。
 #AC.3.2    级别: 2    角色: D
 验证相关人员具备适当的安全专业知识。
 #AC.3.3    级别: 3    角色: D/V
 确认已为高风险人工智能系统设立了人工智能伦理委员会或治理委员会。

---

### AC.4 伦理人工智能指南执行

确保人工智能系统按照既定的伦理原则运行。

 #AC.4.1    级别: 1    角色: D/V
 验证是否存在人工智能开发和部署的伦理指南。
 #AC.4.2    级别: 2    角色: D
 核实是否已建立机制来检测和报告伦理违规行为。
 #AC.4.3    级别: 3    角色: D/V
 验证已部署的人工智能系统是否定期进行伦理审查。

---

### AC.5 人工智能合规监测

保持对不断变化的人工智能法规的关注和遵守。

 #AC.5.1    级别: 1    角色: D/V
 验证是否存在识别适用的人工智能法规的流程。
 #AC.5.2    级别: 2    角色: D
 确认已评估遵守所有监管要求的情况。
 #AC.5.3    级别: 3    角色: D/V
 核实监管变更能否及时触发对人工智能系统的审查和更新。

### AC.6 训练数据治理、文档和流程

 #1.1.2    级别: 1    角色: D/V
 确保仅允许经过质量审查、代表性验证、道德采购和许可合规性审核的数据集，以减少投毒、潜在偏见和知识产权侵权的风险。
 #1.1.5    级别: 2    角色: D/V
 通过审核者交叉检查或达成共识，确保标注/注释质量。
 #1.1.6    级别: 2    角色: D/V
 验证是否为重要的训练数据集维护了“数据卡”或“数据集说明书”，详细说明其特征、动机、组成、收集过程、预处理以及推荐/不推荐的用途。
 #1.3.2    级别: 2    角色: D/V
 验证识别出的偏差是否通过有文档记录的策略得以缓解，例如重新平衡、有针对性的数据增强、算法调整（如预处理、处理中、后处理技术）或重新加权，并评估缓解措施对公平性和整体模型性能的影响。
 #1.3.3    级别: 2    角色: D/V
 验证是否评估并记录了训练后公平性指标。
 #1.3.4    级别: 3    角色: D/V
 验证生命周期偏差管理策略是否分配了所有者和审核频率。
 #1.4.1    级别: 2    角色: D/V
 通过明确的指导方针、审阅者交叉检查、一致性机制（例如监控标注者间一致性）以及定义的差异解决流程，确保标注/注释质量。
 #1.4.4    级别: 3    角色: D/V
 确保对安全性、保密性或公平性至关重要的标签（例如，识别有害内容、关键医疗发现）进行强制性的独立双重审核或同等严格的验证。
 #1.4.6    级别: 2    角色: D/V
 确保标签指南和说明全面、版本受控且经过同行评审。
 #1.4.6    级别: 2    角色: D/V
 验证标签的数据模式是否定义清晰且进行了版本控制。
 #1.3.1    级别: 1    角色: D/V
 验证数据集是否针对代表性不平衡和潜在偏见进行了分析，涵盖法律保护属性（如种族、性别、年龄）以及与模型应用领域相关的其他伦理敏感特征（如社会经济状况、地理位置）。
 #1.5.3    级别: 2    角色: V
 验证领域专家的手工抽查覆盖了具有统计学显著性的样本（例如，≥1%或1,000个样本，以较大者为准，或根据风险评估确定），以识别自动化未能发现的细微质量问题。
 #1.8.4    级别: 2    角色: D/V
 验证外包或众包标注工作流程是否包含技术/程序上的保障措施，以确保数据的机密性、完整性、标签质量，并防止数据泄露。
 #1.5.4    级别: 2    角色: D/V
 验证修复步骤是否已附加到源记录中。
 #1.6.2    级别: 2    角色: D/V
 验证标记的样本在训练前会触发人工审核。
 #1.6.3    级别: 2    角色: V
 验证结果是否输入模型的安全档案并为持续的威胁情报提供信息。
 #1.6.4    级别: 3    角色: D/V
 验证检测逻辑是否已根据新的威胁情报进行了刷新。
 #1.6.5    级别: 3    角色: D/V
 验证在线学习管道是否监控分布漂移。
 #1.7.1    级别: 1    角色: D/V
 验证训练数据删除工作流程是否清除主数据和派生数据，并评估对模型的影响，确保对受影响模型的影响得到评估，并在必要时进行处理（例如，通过重新训练或重新校准）。
 #1.7.2    级别: 2    角色: D
 验证是否已建立机制，以跟踪并尊重用户对用于训练的数据的同意范围和状态（包括撤回），并且在将数据纳入新的训练过程或重大模型更新之前，确认同意已被验证。
 #1.7.3    级别: 2    角色: V
 验证工作流程是否每年测试并记录。
 #1.8.1    级别: 2    角色: D/V
 确保第三方数据供应商，包括预训练模型提供者和外部数据集提供者，在其数据或模型被集成之前，经过安全、隐私、伦理采购和数据质量的尽职调查。
 #1.8.2    级别: 1    角色: D
 验证外部传输是否使用 TLS/认证和完整性检查。
 #1.8.3    级别: 2    角色: D/V
 确保对高风险数据源（例如，来源不明的开源数据集、未经审核的供应商）进行增强审查，例如沙箱分析、广泛的质量/偏差检查以及针对性中毒检测，然后再用于敏感应用。
 #1.8.4    级别: 3    角色: D/V
 确保对从第三方获得的预训练模型在微调或部署之前进行评估，包括嵌入的偏见、潜在的后门、架构的完整性以及其原始训练数据的来源。
 #1.5.3    级别: 2    角色: D/V
 验证如果使用对抗训练，是否对抗性数据集的生成、管理和版本控制均有记录并受控。
 #1.5.3    级别: 3    角色: D/V
 验证对抗鲁棒性训练对模型性能（针对干净和对抗输入）及公平性指标的影响是否已被评估、记录和监控。
 #1.5.4    级别: 3    角色: D/V
 验证对抗训练和鲁棒性策略是否定期审查和更新，以应对不断发展的对抗攻击技术。
 #1.4.2    级别: 2    角色: D/V
 验证失败的数据集是否被隔离，并附有审计跟踪。
 #1.4.3    级别: 2    角色: D/V
 验证质量门控是否阻止不合格的数据集，除非获得例外批准。
 #1.11.2    级别: 2    角色: D/V
 验证合成数据的生成过程、参数和预期用途是否有文档记录。
 #1.11.3    级别: 2    角色: D/V
 在用于训练之前，确保对合成数据进行偏差、隐私泄露和表现问题的风险评估。
 #1.12.3    级别: 2    角色: D/V
 验证是否针对可疑访问事件生成警报并及时进行调查。
 #1.13.1    级别: 1    角色: D/V
 验证是否为所有训练数据集定义了明确的保留期限。
 #1.13.2    级别: 2    角色: D/V
 验证数据集在其生命周期结束时是否会自动过期、删除或进行删除审核。
 #1.13.3    级别: 2    角色: D/V
 验证保留和删除操作是否被记录并可审计。
 #1.14.1    级别: 2    角色: D/V
 验证所有数据集的数据驻留和跨境传输要求均已识别并执行。
 #1.14.2    级别: 2    角色: D/V
 确认已识别并处理特定行业法规（例如，医疗保健、金融）在数据处理中的要求。
 #1.14.3    级别: 2    角色: D/V
 确认相关的隐私法律（例如 GDPR、CCPA）的合规性已被记录并定期审查。
 #1.16.1    级别: 2    角色: D/V
 验证是否存在机制来响应数据主体关于访问、更正、限制或反对的请求。
 #1.16.2    级别: 2    角色: D/V
 验证请求是否在法律规定的时间范围内被记录、跟踪和完成。
 #1.16.3    级别: 2    角色: D/V
 验证数据主体权利流程是否经过定期测试和审查以确保其有效性。
 #1.17.1    级别: 2    角色: D/V
 在更新或替换数据集版本之前，验证是否进行了影响分析，涵盖模型性能、公平性和合规性。
 #1.17.2    级别: 2    角色: D/V
 确认影响分析的结果已被记录并由相关利益相关者审查。
 #1.17.3    级别: 2    角色: D/V
 确认存在回滚计划，以防新版本引入不可接受的风险或回退。
 #1.18.1    级别: 2    角色: D/V
 确保所有参与数据标注的人员都经过背景审查，并接受过数据安全和隐私方面的培训。
 #1.18.2    级别: 2    角色: D/V
 确保所有标注人员签署保密和不披露协议。
 #1.18.3    级别: 2    角色: D/V
 验证注释平台是否执行访问控制并监控内部威胁。

#### 参考文献

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
EU Artificial Intelligence Act — Regulation (EU) 2024/1689
ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods

## 附录 D：人工智能辅助的安全编码治理与验证

### 目标

本章定义了在软件开发过程中安全有效使用 AI 辅助编码工具的基础组织控制措施，确保软件开发生命周期（SDLC）中的安全性和可追溯性。

---

### AD.1 AI辅助的安全编码工作流程

将AI工具集成到组织的安全软件开发生命周期（SSDLC）中，同时不削弱现有的安全防线。

 #AD.1.1    级别: 1    角色: D/V
 验证已记录的工作流程是否描述了 AI 工具何时以及如何生成、重构或审查代码。
 #AD.1.2    级别: 2    角色: D
 验证工作流程是否映射到每个SSDLC阶段（设计、实施、代码审查、测试、部署）。
 #AD.1.3    级别: 3    角色: D/V
 验证是否收集了 AI 生成代码的度量指标（例如，漏洞密度、平均检测时间），并将其与仅人工基准进行比较。

---

### AD.2 AI工具资格认证与威胁建模

确保在采用 AI 编码工具之前，对其安全能力、风险和供应链影响进行评估。

 #AD.2.1    级别: 1    角色: D/V
 验证每个人工智能工具的威胁模型是否识别了误用、模型反演、数据泄露和依赖链风险。
 #AD.2.2    级别: 2    角色: D
 验证工具评估是否包含对任何本地组件的静态/动态分析以及对SaaS端点（TLS、身份验证/授权、日志记录）的评估。
 #AD.2.3    级别: 3    角色: D/V
 验证评估是否遵循公认的框架，并在主要版本更改后重新执行评估。

---

### AD.3 安全提示与上下文管理

在为 AI 模型构建提示或上下文时，防止泄露机密、专有代码和个人数据。

 #AD.3.1    级别: 1    角色: D/V
 请确认书面指导中禁止在提示中发送秘密信息、凭证或机密数据。
 #AD.3.2    级别: 2    角色: D
 验证技术控制措施（客户端编辑、批准的上下文过滤器）是否自动剥离敏感内容。
 #AD.3.3    级别: 3    角色: D/V
 验证提示和响应在传输和存储过程中是否经过分词和加密，并且保留期限是否符合数据分类政策。

---

### AD.4 AI生成代码的验证

在代码合并或部署之前，检测并修复由 AI 输出引入的漏洞。

 #AD.4.1    级别: 1    角色: D/V
 确保 AI 生成的代码始终经过人工代码审查。
 #AD.4.2    级别: 2    角色: D
 验证自动扫描器（SAST/IAST/DAST）是否针对每个包含 AI 生成代码的拉取请求运行，并在发现关键问题时阻止合并。
 #AD.4.3    级别: 3    角色: D/V
 验证差分模糊测试或基于属性的测试是否证明了安全关键行为（例如，输入验证、授权逻辑）。

---

### AD.5 代码建议的可解释性和可追溯性

为审计人员和开发人员提供关于为何提出建议以及建议如何演变的深入了解。

 #AD.5.1    级别: 1    角色: D/V
 验证提示/响应对是否记录了提交ID。
 #AD.5.2    级别: 2    角色: D
 验证开发者是否能够展示支持建议的模型引用（训练片段、文档）。
 #AD.5.3    级别: 3    角色: D/V
 验证可解释性报告是否与设计工件一起存储，并在安全评审中引用，以满足 ISO/IEC 42001 可追溯性原则。

---

### AD.6 持续反馈与模型微调

随着时间的推移提升模型安全性能，同时防止负面漂移。

 #AD.6.1    级别: 1    角色: D/V
 验证开发者是否可以标记不安全或不合规的建议，并确保标记得到跟踪。
 #AD.6.2    级别: 2    角色: D
 验证汇总的反馈是否用于定期微调或结合经过审核的安全编码语料库（例如 OWASP 备忘单）的检索增强生成。
 #AD.6.3    级别: 3    角色: D/V
 验证闭环评估环境在每次微调后运行回归测试；安全指标必须达到或超过之前的基线才能部署。

---

#### 参考文献

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
OWASP Secure Coding Practices — Quick Reference Guide

## 附录 E：示例工具和框架

### 目标

本章提供了一些工具和框架的示例，这些工具和框架可以支持实现或满足特定的AISVS需求。这些示例不应被视为AISVS团队或OWASP GenAI安全项目的推荐或认可。

---

### AE.1 训练数据治理与偏差管理

用于数据分析、治理和偏见管理的工具。

 #AE.1.1    章节: 1.1
 数据清单工具：数据清单管理工具，例如...
 #AE.1.2    章节: 1.2
 传输中加密 对基于 HTTPS 的应用使用 TLS，工具如 openSSL 以及 python 的`ssl` 库。

---

### AE.2 用户输入验证

用于处理和验证用户输入的工具。

 #AE.2.1    章节: 2.1
 提示注入防御工具：使用类似NVIDIA的NeMo或Guardrails AI的防护工具。

---

