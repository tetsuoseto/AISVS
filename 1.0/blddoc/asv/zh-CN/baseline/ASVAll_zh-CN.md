## 扉页

### 关于标准

人工智能安全验证标准（AISVS）是一个由社区推动的安全需求目录，数据科学家、MLOps工程师、软件架构师、开发人员、测试人员、安全专业人员、工具供应商、监管机构和消费者可以利用该目录来设计、构建、测试和验证可信赖的人工智能系统和应用。它为人工智能生命周期中从数据收集、模型开发到部署及持续监控的安全控制提供了统一的表达语言，帮助组织衡量并提升其人工智能解决方案的弹性、隐私和安全性。

### 版权和许可

版本 0.1（首个公开草稿 - 进行中），2025  

![license](images/license.png)
版权所有 © 2025 AISVS 项目。  

根据 Creative Commons Attribution‑ShareAlike 4.0 International License.
对于任何再利用或分发，您必须清楚地将本作品的许可条款传达给他人。

### 项目负责人

吉姆·马尼科
Aras “Russ” Memisyazici

### 贡献者和审阅者

https://github.com/ottosulin
https://github.com/mbhatt1
https://github.com/vineethsai
https://github.com/cciprofm
https://github.com/deepakrpandey12


---

AISVS 是一个全新的标准，专门针对人工智能系统的独特安全挑战而创建。尽管它借鉴了更广泛的安全最佳实践，但AISVS中的每一项要求都是从零开始开发的，旨在反映人工智能威胁环境，帮助组织构建更安全、更具弹性的人工智能解决方案。

## 前言

欢迎使用人工智能安全验证标准（AISVS）1.0版本！

### 介绍

AISVS成立于2025年，是通过社区协作努力建立的，定义了在设计、开发、部署和运营现代人工智能模型、管道及人工智能驱动的服务时需要考虑的安全要求。

AISVS v1.0 代表了其项目负责人、工作组和更广泛社区贡献者的共同努力，旨在制定一个务实且可测试的人工智能系统安全基线。

我们此次发布的目标是让AISVS易于采用，同时保持对其既定范围的高度关注，并应对人工智能独特的快速变化的风险环境。

### AISVS版本1.0的关键目标

版本 1.0 将依据若干指导原则创建。

#### 明确的范围

每个需求都必须与AISVS的名称和使命保持一致：

人工智能——控制措施在AI/ML层（数据、模型、管道或推理）运行，由AI从业人员负责。
安全性 – 需求直接缓解已识别的安全、隐私或安全风险。
验证——语言编写使符合性能够被客观验证。
标准 – 各部分遵循一致的结构和术语，形成连贯的参考。
​
---

通过遵循AISVS，组织可以系统地评估和加强其人工智能解决方案的安全态势，促进安全人工智能工程文化的建设。

## 使用 AISVS

人工智能安全验证标准（AISVS）定义了现代人工智能应用和服务的安全要求，重点关注应用开发者可控的方面。

AISVS 面向所有开发或评估 AI 应用安全性的人员，包括开发人员、架构师、安全工程师和审计员。本章介绍了 AISVS 的结构和使用方法，包括其验证级别和预期使用场景。

### 人工智能安全验证级别

AISVS定义了三个逐级递增的安全验证级别。每个级别都增加了深度和复杂性，使组织能够根据其人工智能系统的风险级别调整安全态势。

组织可以从第1级开始，随着安全成熟度和威胁暴露的增加，逐步采用更高级别。

#### 级别定义

AISVS v1.0 中的每个需求都被分配到以下级别之一：

 一级要求

第一级包括最关键和基础的安全要求。这些要求侧重于防止不依赖其他前提条件或漏洞的常见攻击。大多数第一级控制措施要么易于实施，要么足够重要，值得投入精力。

 2级要求

第2级涵盖了更高级或较少见的攻击，以及对广泛威胁的多层防御。这些要求可能涉及更复杂的逻辑或针对特定攻击前提条件。

 三级要求

等级3包括通常较难实施或适用情境有限的控制措施。这些通常代表纵深防御机制或针对小众、有针对性或高复杂度攻击的缓解措施。

#### 角色（D/V）

每个 AISVS 要求都根据主要受众进行标记：

D – 面向开发者的需求
V – 面向验证者/审计员的需求
D/V – 与开发人员和验证人员相关

## C1 训练数据治理与偏差管理

### 控制目标

训练数据必须以保持来源、安全、质量和公平的方式获取、处理和维护。这样做既履行了法律责任，也减少了在训练过程中出现的偏见、中毒或隐私泄露的风险，这些风险可能影响整个人工智能生命周期。

---

### C1.1 训练数据出处

维护所有数据集的可验证清单，仅接受可信来源，并记录每次更改以便审计。

 #1.1.1    级别: 1    角色: D/V
 确保维护一份最新的每个训练数据源的清单（来源、管理者/所有者、许可、收集方法、预期使用限制和处理历史）。
 #1.1.2    级别: 1    角色: D/V
 验证训练数据处理过程中排除了不必要的特征、属性或字段（例如，未使用的元数据、敏感的个人身份信息、泄露的测试数据）。
 #1.1.3    级别: 2    角色: D/V
 验证所有数据集更改均需经过记录的审批流程。
 #1.1.4    级别: 3    角色: D/V
 在可行的情况下，验证数据集或子集是否已添加水印或指纹。

---

### C1.2 训练数据安全与完整性

限制对训练数据的访问，对静止和传输中的数据进行加密，并验证其完整性以防止篡改、盗窃或数据投毒。

 #1.2.1    级别: 1    角色: D/V
 验证访问控制是否保护训练数据存储和管道。
 #1.2.2    级别: 2    角色: D/V
 验证所有对训练数据的访问是否被记录，包括用户、时间和操作。
 #1.2.3    级别: 2    角色: D/V
 验证训练数据集在传输和静止时均被加密，使用行业标准的加密算法和密钥管理实践。
 #1.2.4    级别: 2    角色: D/V
 验证在训练数据存储和传输过程中是否使用加密哈希或数字签名来确保数据完整性。
 #1.2.5    级别: 2    角色: D/V
 验证是否应用自动检测技术以防止对训练数据的未经授权的修改或损坏。
 #1.2.6    级别: 2    角色: D/V
 验证过时的训练数据已被安全清除或匿名化。
 #1.2.7    级别: 3    角色: D/V
 验证所有训练数据集版本均被唯一标识、以不可更改的方式存储，并且可审计，以支持回滚和取证分析。

---

### C1.3 训练数据标注的质量、完整性和安全性

保护标签并对关键数据要求进行技术审查。

 #1.3.1    级别: 2    角色: D/V
 验证是否对标签工件应用了加密哈希或数字签名，以确保其完整性和真实性。
 #1.3.2    级别: 2    角色: D/V
 验证标注界面和平台是否执行严格的访问控制，保持所有标注活动的防篡改审计日志，并防止未经授权的修改。
 #1.3.3    级别: 3    角色: D/V
 验证标签中的敏感信息在静态和传输过程中是否在数据字段级别进行了编辑、匿名化或加密。

---

### C1.4 训练数据质量与安全保障

结合自动验证、人工抽查和记录的修复措施，以确保数据集的可靠性。

 #1.4.1    级别: 1    角色: D
 验证自动化测试是否能捕获每次数据导入或重大数据转换中的格式错误和空值。
 #1.4.2    级别: 2    角色: D/V
 验证大型语言模型训练和微调流水线是否实施了中毒检测和数据完整性验证（例如，统计方法、异常值检测、嵌入分析），以识别潜在的中毒攻击（例如，标签翻转、后门触发插入、角色切换命令、影响实例攻击）或训练数据中的无意数据损坏。
 #1.4.3    级别: 3    角色: D/V
 验证是否根据风险评估，为相关模型实施并调整了适当的防御措施，例如对抗性训练（使用生成的对抗样本）、扰动输入的数据增强或鲁棒优化技术。
 #1.4.4    级别: 2    角色: D/V
 验证自动生成的标签（例如，通过大型语言模型或弱监督生成的标签）是否遵循置信度阈值和一致性检查，以检测虚假、误导或置信度低的标签。
 #1.4.5    级别: 3    角色: D
 验证自动化测试是否能在每次数据摄取或重大数据转换时捕捉标签偏差。

---

### C1.5 数据血缘和可追溯性

跟踪每个数据点从源头到模型输入的完整过程，以便审计和事件响应。

 #1.5.1    级别: 2    角色: D/V
 验证每个数据点的血统，包括所有转换、增强和合并，都已被记录并且可以重建。
 #1.5.2    级别: 2    角色: D/V
 验证血统记录是不可更改的，安全存储的，并且可供审计访问。
 #1.5.3    级别: 2    角色: D/V
 验证谱系追踪覆盖通过隐私保护或生成技术生成的合成数据，并确保所有合成数据在整个流程中均被清晰标注并可与真实数据区分。

---

### 参考文献

NIST AI Risk Management Framework
EU AI Act – Article 10: Data & Data Governance
MITRE ATLAS: Adversary Tactics for AI
Survey of ML Bias Mitigation Techniques – MDPI
Data Provenance & Lineage Best Practices – Nightfall AI
Data Labeling Quality Standards – LabelYourData
Training Data Poisoning Guide – Lakera.ai
CISA Advisory: Securing Data for AI Systems
ISO/IEC 23053: AI Management Systems Framework
IBM: What is AI Governance?
Google AI Principles
GDPR & AI Training Data – DataProtectionReport
Supply-Chain Security for AI Data – AppSOC
OpenAI Privacy Center – Data Deletion Controls
Adversarial ML Dataset – Kaggle

## C2 用户输入验证

### 控制目标

对用户输入进行强有力的验证是防御针对人工智能系统一些最具破坏性攻击的第一道防线。提示注入攻击可以覆盖系统指令、泄露敏感数据，或引导模型产生不被允许的行为。除非设置了专门的过滤器和指令层级，研究表明利用超长上下文窗口的“多次射击”越狱攻击将会是有效的。此外，诸如同形异义字替换或字母数字混写等微妙的对抗性扰动攻击，也能悄无声息地改变模型的决策。

---

### C2.1 提示注入防护

提示注入是人工智能系统面临的主要风险之一。针对这一策略的防御措施结合了静态模式过滤器、动态分类器和指令层级执行。

 #2.1.1    级别: 1    角色: D/V
 验证用户输入是否经过筛查，确保其符合不断更新的已知提示注入模式库（包含越狱关键字、“忽略之前内容”、角色扮演链条、间接HTML/URL攻击等）。
 #2.1.2    级别: 1    角色: D/V
 验证系统是否执行指令层级，其中系统或开发者消息优先于用户指令，即使在上下文窗口扩展之后也是如此。
 #2.1.3    级别: 2    角色: D/V
 验证对抗性评估测试（例如，红队“多次尝试”提示）是否在每次模型或提示模板发布前运行，并且设有成功率阈值和针对回归的自动阻断机制。
 #2.1.4    级别: 2    角色: D
 验证来自第三方内容（网页、PDF、电子邮件）的提示是否在独立的解析环境中经过清理，然后再连接到主提示中。
 #2.1.5    级别: 3    角色: D/V
 验证所有提示过滤规则的更新、分类器模型版本和黑名单更改均受版本控制且可审计。

---

### C2.2 对抗样本抵抗能力

自然语言处理（NLP）模型仍然容易受到人类常常忽视但模型容易误分类的细微字符或词级扰动的影响。

 #2.2.1    级别: 1    角色: D
 验证基本输入规范化步骤（Unicode NFC，同形异义字映射，空白字符修剪）在分词之前执行。
 #2.2.2    级别: 2    角色: D/V
 验证统计异常检测是否能够标记与语言规范有异常高编辑距离、过多重复标记或异常嵌入距离的输入。
 #2.2.3    级别: 2    角色: D
 验证推理流水线是否支持针对高风险端点的可选对抗训练强化模型变体或防御层（例如，随机化、防御蒸馏）。
 #2.2.4    级别: 2    角色: V
 验证疑似对抗性输入是否被隔离，并在去除个人身份信息后记录完整载荷。
 #2.2.5    级别: 3    角色: D/V
 验证鲁棒性指标（已知攻击套件的成功率）是否随着时间被跟踪，并且回归是否会触发行发布阻止。

---

### C2.3 模式、类型和长度验证

包含格式错误或过大输入的AI攻击可能导致解析错误、提示跨字段泄露及资源耗尽。严格的模式强制在执行确定性工具调用时也是前提条件。

 #2.3.1    级别: 1    角色: D
 验证每个 API 或函数调用端点是否定义了明确的输入模式（JSON Schema、Protobuf 或多模态等效格式），并且在组装提示之前对输入进行了验证。
 #2.3.2    级别: 1    角色: D/V
 验证超过最大令牌或字节限制的输入被拒绝，并返回安全错误，且绝不被静默截断。
 #2.3.3    级别: 2    角色: D/V
 验证类型检查（例如，数值范围、枚举值、图像/音频的 MIME 类型）是在服务器端强制执行的，而不仅仅是在客户端代码中。
 #2.3.4    级别: 2    角色: D
 验证语义验证器（例如，JSON Schema）以常数时间运行，以防止算法性拒绝服务攻击。
 #2.3.5    级别: 3    角色: V
 验证失败是否以带有涂黑有效载荷片段和明确错误代码的方式记录，以便安全分类。

---

### C2.4 内容与政策筛查

开发人员应该能够检测出请求不允许内容（如非法指令、仇恨言论和版权文本）的语法有效的提示，然后阻止其传播。

 #2.4.1    级别: 1    角色: D
 验证内容分类器（零样本或微调版）是否对每个输入内容按暴力、自残、仇恨、性内容和非法请求进行评分，并支持可配置的阈值。
 #2.4.2    级别: 1    角色: D/V
 验证违反政策的输入将收到标准化拒绝或安全完成回复，以防止其传递到后续的大型语言模型调用中。
 #2.4.3    级别: 2    角色: D
 验证筛选模型或规则集是否至少每季度重新训练/更新一次，纳入新观察到的越狱或策略绕过模式。
 #2.4.4    级别: 2    角色: D
 通过在请求时解析基于属性的规则，验证筛选是否遵守用户特定的政策（年龄、地区法律限制）。
 #2.4.5    级别: 3    角色: V
 验证筛查日志是否包含分类器置信度分数和政策类别标签，以用于SOC关联和未来红队重放。

---

### C2.5 输入速率限制与滥用防范

开发人员应通过限制输入速率和检测异常使用模式来防止对 AI 系统的滥用、资源耗尽和自动化攻击。

 #2.5.1    级别: 1    角色: D/V
 验证所有输入端点是否对每个用户、每个IP和每个API密钥实施了速率限制。
 #2.5.2    级别: 2    角色: D/V
 验证突发和持续速率限制是否已调整以防止拒绝服务（DoS）和暴力破解攻击。
 #2.5.3    级别: 2    角色: D/V
 验证异常使用模式（例如，快速请求、输入泛滥）是否会触发自动封锁或升级处理。
 #2.5.4    级别: 3    角色: V
 验证滥用防护日志是否被保留并审查以发现新出现的攻击模式。

---

### C2.6 多模态输入验证

人工智能系统应包括对非文本输入（图像、音频、文件）的强健验证，以防止注入、规避或资源滥用。

 #2.6.1    级别: 1    角色: D
 验证所有非文本输入（图像、音频、文件）在处理前均已验证其类型、大小和格式。
 #2.6.2    级别: 2    角色: D/V
 确认在导入之前对文件进行恶意软件和隐写载荷的扫描。
 #2.6.3    级别: 2    角色: D/V
 验证图像/音频输入是否经过对抗性扰动或已知攻击模式的检测。
 #2.6.4    级别: 3    角色: V
 验证多模态输入验证失败是否已记录并触发调查警报。

---

### C2.7 输入来源与归属

人工智能系统应通过监控和标记所有用户输入的来源来支持审计、滥用追踪和合规性。

 #2.7.1    级别: 1    角色: D/V
 验证所有用户输入在摄取时均附有元数据标签（用户ID、会话、来源、时间戳、IP地址）。
 #2.7.2    级别: 2    角色: D/V
 验证所有处理输入的溯源元数据是否被保留且可审计。
 #2.7.3    级别: 2    角色: D/V
 验证异常或不可信的输入来源是否被标记并受到加强审查或阻止。

---

### C2.8 实时自适应威胁检测

开发人员应使用先进的AI威胁检测系统，这些系统能够适应新的攻击模式，并通过编译的模式匹配提供实时保护。

 #2.8.1    级别: 1    角色: D/V
 验证威胁检测模式已被编译到优化的正则表达式引擎中，以实现高性能的实时过滤，同时对延迟的影响最小。
 #2.8.2    级别: 1    角色: D/V
 验证威胁检测系统是否为不同的威胁类别（提示注入、有害内容、敏感数据、系统命令）维护独立的模式库。
 #2.8.3    级别: 2    角色: D/V
 验证自适应威胁检测是否包含根据攻击频率和成功率更新威胁灵敏度的机器学习模型。
 #2.8.4    级别: 2    角色: D/V
 验证实时威胁情报源是否自动使用新的攻击特征和IOC（妥协指标）更新模式库。
 #2.8.5    级别: 3    角色: D/V
 确保持续监控威胁检测的误报率，并自动调整模式的特异性，以最小化对合法用例的干扰。
 #2.8.6    级别: 3    角色: D/V
 验证上下文威胁分析是否考虑了输入来源、用户行为模式和会话历史，以提高检测准确性。
 #2.8.7    级别: 3    角色: D/V
 确保威胁检测性能指标（检测率、处理延迟、资源利用率）得到实时监控和优化。

---

### C2.9 多模态安全验证流程

开发人员应为文本、图像、音频及其他AI输入模态提供安全验证，采用特定类型的威胁检测和资源隔离。

 #2.9.1    级别: 1    角色: D/V
 验证每个输入模态是否具有专门的安全验证器，并附有记录的威胁模式（文本：提示注入，图像：隐写术，音频：频谱图攻击）和检测阈值。
 #2.9.2    级别: 2    角色: D/V
 验证多模态输入是否在具有特定于每种模态类型的定义资源限制（内存、CPU、处理时间）且在安全策略中有文档记录的隔离沙箱中处理。
 #2.9.3    级别: 2    角色: D/V
 验证跨模态攻击检测是否能够通过关联规则和警报生成识别涵盖多种输入类型的协调攻击（例如，图像中的隐写载荷与文本中的提示注入相结合）。
 #2.9.4    级别: 3    角色: D/V
 验证多模态验证失败是否触发详细日志记录，包括所有输入模态、验证结果、威胁评分以及使用结构化日志格式进行的关联分析，以便与SIEM集成。
 #2.9.5    级别: 3    角色: D/V
 验证模态特定内容分类器是否根据文档规定的时间表（至少每季度一次）进行更新，更新内容包括新的威胁模式、对抗样本，并确保性能基准维持在基线阈值以上。

---

### 参考文献

LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security
Generative AI's Biggest Security Flaw Is Not Easy to Fix
Many-shot jailbreaking \ Anthropic
$PDF$ OpenAI GPT-4.5 System Card
Notebook for the CheckThat Lab at CLEF 2024
Mitigate jailbreaks and prompt injections – Anthropic
Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis
OWASP Top 10 for LLM Applications 2025 – WorldTech IT
OWASP Machine Learning Security Top Ten
Few words about AI Security – Jussi Metso
How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry
Easily enforcing valid JSON schema following – API
AI Safety + Cybersecurity R\&D Tracker – Fairly AI
Anthropic makes 'jailbreak' advance to stop AI models producing harmful results
Pattern matching filter rules - IBM
Real-time Threat Detection

## C3 模型生命周期管理与变更控制

### 控制目标

人工智能系统必须实施变更控制流程，防止未经授权或不安全的模型修改进入生产环境。该控制确保模型在整个生命周期中的完整性——从开发到部署再到退役——从而实现快速事件响应并保持对所有变更的问责。

核心安全目标：通过采用受控流程确保只有经过授权和验证的模型能够进入生产，以维护完整性、可追溯性和可恢复性。

---

### C3.1 模型授权与完整性

只有经过验证完整性的授权模型才能进入生产环境。

 #3.1.1    级别: 1    角色: D/V
 在部署之前，验证所有模型工件（权重、配置、分词器）均由授权实体进行加密签名。
 #3.1.2    级别: 1    角色: D/V
 确保在部署时验证模型的完整性，并且签名验证失败会阻止模型加载。
 #3.1.3    级别: 2    角色: D/V
 验证模型来源记录是否包含授权实体的身份、训练数据校验和、带有通过/失败状态的验证测试结果以及创建时间戳。
 #3.1.4    级别: 2    角色: D/V
 验证所有模型工件是否使用语义化版本控制（MAJOR.MINOR.PATCH），并附有明确的标准说明每个版本组件何时递增。
 #3.1.5    级别: 2    角色: V
 验证依赖关系跟踪是否维护了一个实时库存，从而能够快速识别所有使用该资源的系统。

---

### C3.2 模型验证与测试

模型必须通过定义的安全和安全性验证后方可部署。

 #3.2.1    级别: 1    角色: D/V
 验证模型在部署前经过自动化安全测试，包括输入验证、输出清理和安全评估，并符合预先商定的组织通过/失败标准。
 #3.2.2    级别: 1    角色: D/V
 验证验证失败在经过预先指定的授权人员明确覆盖批准并附有书面业务理由后，是否会自动阻止模型部署。
 #3.2.3    级别: 2    角色: V
 验证测试结果是否经过加密签名，并且不可变地链接到正在验证的特定模型版本哈希。
 #3.2.4    级别: 2    角色: D/V
 确认紧急部署需要在预先约定的时间范围内，由预指定的安全权限机构进行书面安全风险评估和批准。

---

### C3.3 受控部署与回滚

模型部署必须受到控制、监控并且可以逆转。

 #3.3.1    级别: 1    角色: D
 验证生产部署是否实施了渐进式发布机制（金丝雀部署、蓝绿部署），并且基于预先约定的错误率、延迟阈值或安全警报标准具备自动回滚触发机制。
 #3.3.2    级别: 1    角色: D/V
 验证回滚功能是否能够在预定义的组织时间窗口内原子性地恢复完整的模型状态（权重、配置、依赖项）。
 #3.3.3    级别: 2    角色: D/V
 验证部署流程在模型激活之前是否验证加密签名并计算完整性校验和，若发现不匹配则部署失败。
 #3.3.4    级别: 2    角色: D/V
 验证紧急模型关闭功能是否能通过自动断路器或手动杀死开关在预定义响应时间内禁用模型端点。
 #3.3.5    级别: 2    角色: V
 验证回滚工件（先前的模型版本、配置、依赖项）是否按照组织政策通过不可变存储进行保留，以便于事件响应。

---

### C3.4 变更责任与审计

所有模型生命周期的变更都必须可追溯且可审计。

 #3.4.1    级别: 1    角色: V
 验证所有模型变更（部署、配置、退役）均生成不可变的审计记录，包含时间戳、经过身份验证的操作用户身份、变更类型以及变更前后的状态。
 #3.4.2    级别: 2    角色: D/V
 验证审计日志访问是否需要适当的授权，并且所有访问尝试均记录用户身份和时间戳。
 #3.4.3    级别: 2    角色: D/V
 验证提示模板和系统消息是否在 git 仓库中进行版本控制，并且在部署前必须经过指定审阅者的代码审查和批准。
 #3.4.4    级别: 2    角色: V
 验证审计记录是否包含足够的细节（模型哈希、配置快照、依赖版本），以便在保留期限内的任何时间点完全重建模型状态。

---

### C3.5 安全开发实践

模型开发和训练过程必须遵循安全实践以防止被破坏。

 #3.5.1    级别: 1    角色: D
 验证模型开发、测试和生产环境在物理或逻辑上是隔离的。它们没有共享的基础设施，具有独立的访问控制和隔离的数据存储。
 #3.5.2    级别: 1    角色: D
 验证模型训练和微调是否在具有受控网络访问的隔离环境中进行。
 #3.5.3    级别: 1    角色: D/V
 确保训练数据源在用于模型开发之前通过完整性检查验证，并通过具有文档化链条的可信来源进行身份验证。
 #3.5.4    级别: 2    角色: D
 验证模型开发工件（超参数、训练脚本、配置文件）已存储在版本控制中，并且在用于训练之前需要经过同行评审批准。

---

### C3.6 模型退休与退役

当模型不再需要或发现安全问题时，必须安全地退役模型。

 #3.6.1    级别: 1    角色: D
 验证模型退役流程是否能够自动扫描依赖关系图，识别所有使用系统，并在停用前提供预先约定的通知期限。
 #3.6.2    级别: 1    角色: D/V
 根据已验证的销毁证书，按照记录的数据保留政策，使用加密擦除或多次覆盖方法，确保退役模型工件被安全清除。
 #3.6.3    级别: 2    角色: V
 验证模型退役事件是否记录了时间戳和执行者身份，并且模型签名是否已被撤销以防止重新使用。
 #3.6.4    级别: 2    角色: D/V
 验证紧急模型退役是否能够在预设的紧急响应时间范围内，通过自动关闭开关禁用模型访问，以防发现关键安全漏洞。

---

### 参考文献

MLOps Principles
Securing AI/ML Ops – Cisco.com
Audit logs security: cryptographically signed tamper-proof logs
Machine Learning Model Versioning: Top Tools & Best Practices
AI Hygiene Starts with Models and Data Loaders – SEI Blog
How to handle versioning and rollback of a deployed ML model?
Reinforcement fine-tuning – OpenAI API
Auditing Machine Learning models: Governance, Data Security and …
Adversarial Training to Improve Model Robustness
What is AI adversarial robustness? – IBM Research
Exploring Data Provenance: Ensuring Data Integrity and Authenticity
MITRE ATLAS
AWS Prescriptive Guidance – Best practices for retiring applications …

## C4 基础设施、配置与部署安全

### 控制目标

人工智能基础设施必须通过安全配置、运行时隔离、可信部署管道和全面监控来增强防护，防止权限提升、供应链篡改和横向移动。只有经过授权和验证的基础设施组件及配置通过受控流程进入生产环境，以确保安全性、完整性和可审计性。

核心安全目标：只有经过加密签名、漏洞扫描的基础设施组件才能通过自动化验证管道进入生产环境，这些管道执行安全策略并维护不可变的审计跟踪。

---

### C4.1 运行时环境隔离

通过内核级隔离原语和强制访问控制防止容器逃逸和权限提升。

 #4.1.1    级别: 1    角色: D/V
 验证所有AI容器是否删除所有Linux权限，除CAP_SETUID、CAP_SETGID以及安全基线中明确要求的权限外。
 #4.1.2    级别: 1    角色: D/V
 验证 seccomp 配置文件是否阻止除预先批准的允许列表中的所有系统调用之外的所有系统调用，违规行为将导致容器终止并生成安全警报。
 #4.1.3    级别: 2    角色: D/V
 验证 AI 工作负载是否以只读根文件系统运行，临时数据使用 tmpfs，持久数据使用带 noexec 挂载选项的命名卷。
 #4.1.4    级别: 2    角色: D/V
 验证基于 eBPF 的运行时监控（Falco、Tetragon 或同类工具）能够检测权限提升尝试，并在组织响应时间要求内自动终止违规进程。
 #4.1.5    级别: 3    角色: D/V
 验证高风险 AI 工作负载是否在硬件隔离环境中执行（Intel TXT、AMD SVM 或专用裸金属节点），并进行证明验证。

---

### C4.2 安全构建与部署流水线

通过可重现构建和签名的工件，确保密码学完整性和供应链安全。

 #4.2.1    级别: 1    角色: D/V
 验证基础设施即代码在每次提交时均使用工具（tfsec、Checkov 或 Terrascan）进行扫描，且当发现严重性为 CRITICAL 或 HIGH 的问题时阻止合并。
 #4.2.2    级别: 1    角色: D/V
 验证容器构建在多次构建中具有相同的 SHA256 哈希，从而确保可重现性，并生成使用 Sigstore 签名的 SLSA 3 级可溯源证明。
 #4.2.3    级别: 2    角色: D/V
 验证容器镜像在推送到注册表前已嵌入 CycloneDX 或 SPDX SBOM，并且使用 Cosign 进行签名，未签名的镜像在部署时被拒绝。
 #4.2.4    级别: 2    角色: D/V
 验证 CI/CD 管道使用来自 HashiCorp Vault、AWS IAM 角色或 Azure 托管身份的 OIDC 令牌，其有效期不超过组织安全策略规定的限制。
 #4.2.5    级别: 2    角色: D/V
 验证在部署过程中容器执行前是否验证了 Cosign 签名和 SLSA 源信息，并确保验证错误会导致部署失败。
 #4.2.6    级别: 2    角色: D/V
 验证构建环境是否运行在临时容器或虚拟机中，这些环境没有持久存储且与生产虚拟私有云（VPC）网络隔离。

---

### C4.3 网络安全与访问控制

通过默认拒绝策略和加密通信实现零信任网络。

 #4.3.1    级别: 1    角色: D/V
 验证 Kubernetes NetworkPolicies 或任何等效策略是否通过显式允许规则实现默认拒绝的入口/出口流量，适用于所需端口（443、8080 等）。
 #4.3.2    级别: 1    角色: D/V
 验证 SSH（端口 22）、RDP（端口 3389）和云元数据端点（169.254.169.254）是否被阻止或需要基于证书的身份验证。
 #4.3.3    级别: 2    角色: D/V
 验证出站流量是否通过带有域名允许列表的 HTTP/HTTPS 代理（Squid、Istio 或云 NAT 网关）进行过滤，并记录被阻止的请求。
 #4.3.4    级别: 2    角色: D/V
 验证跨服务通信使用双向 TLS，证书按照组织策略进行轮换，并强制执行证书验证（不使用跳过验证的标志）。
 #4.3.5    级别: 2    角色: D/V
 验证 AI 基础设施是否运行在专用的 VPC/VNet 中，且无直接互联网访问，仅通过 NAT 网关或堡垒主机进行通信。

---

### C4.4 密钥与加密密钥管理

通过硬件支持的存储和自动轮换结合零信任访问来保护凭据。

 #4.4.1    级别: 1    角色: D/V
 验证秘密是否存储在 HashiCorp Vault、AWS Secrets Manager、Azure Key Vault 或 Google Secret Manager 中，并使用 AES-256 进行静态加密。
 #4.4.2    级别: 1    角色: D/V
 验证加密密钥是否在符合 FIPS 140-2 级别 2 的 HSM（如 AWS CloudHSM、Azure Dedicated HSM）中生成，并根据组织的密码策略执行密钥轮换。
 #4.4.3    级别: 2    角色: D/V
 验证秘密轮换是否实现自动化，确保零停机部署，并能在人员变动或安全事件发生时立即触发轮换。
 #4.4.4    级别: 2    角色: D/V
 验证容器镜像是否使用工具（GitLeaks、TruffleHog 或 detect-secrets）进行扫描，阻止包含 API 密钥、密码或证书的构建。
 #4.4.5    级别: 2    角色: D/V
 验证生产环境的秘密访问是否需要使用硬件令牌（YubiKey，FIDO2）进行多因素认证（MFA），并且该访问通过包含用户身份和时间戳的不可变审计日志进行记录。
 #4.4.6    级别: 2    角色: D/V
 验证机密是否通过 Kubernetes secrets、挂载卷或初始化容器注入，并确保机密绝不嵌入环境变量或镜像中。

---

### C4.5 AI 工作负载沙箱和验证

在安全沙箱中隔离不可信的 AI 模型，并进行全面的行为分析。

 #4.5.1    级别: 1    角色: D/V
 验证外部 AI 模型是否在 gVisor、微虚拟机（如 Firecracker、CrossVM）或带有 --security-opt=no-new-privileges 和 --read-only 标志的 Docker 容器中执行。
 #4.5.2    级别: 1    角色: D/V
 验证沙箱环境没有网络连接（--network=none）或仅允许本地主机访问，所有外部请求均被 iptables 规则阻止。
 #4.5.3    级别: 2    角色: D/V
 验证 AI 模型的验证包括使用组织定义的测试覆盖范围和行为分析进行自动化红队测试，以检测后门。
 #4.5.4    级别: 2    角色: D/V
 确认在将 AI 模型投入生产之前，其沙箱结果由授权的安全人员进行加密签名，并存储在不可变的审计日志中。
 #4.5.5    级别: 2    角色: D/V
 验证沙箱环境在每次评估之间是否从黄金镜像销毁并重新创建，确保完全清理文件系统和内存。

---

### C4.6 基础设施安全监控

通过自动修复和实时警报，持续扫描和监控基础设施。

 #4.6.1    级别: 1    角色: D/V
 验证容器镜像是否按照组织的计划进行扫描，且基于组织的风险阈值，关键漏洞会阻止部署。
 #4.6.2    级别: 1    角色: D/V
 验证基础设施是否符合CIS基准或NIST 800-53控制标准，依据组织定义的合规阈值，并对检查失败项进行自动修复。
 #4.6.3    级别: 2    角色: D/V
 根据组织的风险管理时间表，验证高严重性漏洞是否已修补，并对被积极利用的CVE采取应急措施。
 #4.6.4    级别: 2    角色: V
 验证安全警报是否通过CEF或STIX/TAXII格式与SIEM平台（如Splunk、Elastic或Sentinel）集成，并实现自动丰富功能。
 #4.6.5    级别: 3    角色: V
 验证基础设施指标是否导出到监控系统（Prometheus，DataDog），并配备SLA仪表板和高管报告。
 #4.6.6    级别: 2    角色: D/V
 根据组织的监控要求，使用工具（Chef InSpec、AWS Config）验证配置漂移被检测到，并对未授权的更改进行自动回滚。

---

### C4.7 人工智能基础设施资源管理

通过配额和监控防止资源耗尽攻击，确保资源公平分配。

 #4.7.1    级别: 1    角色: D/V
 验证GPU/TPU的利用率是否被监控，并在组织定义的阈值触发警报，同时基于容量管理策略激活自动扩展或负载均衡。
 #4.7.2    级别: 1    角色: D/V
 验证是否根据组织的监控要求收集了 AI 工作负载指标（推理延迟、吞吐量、错误率），并将其与基础设施利用率进行关联。
 #4.7.3    级别: 2    角色: D/V
 验证 Kubernetes ResourceQuotas 或等效机制是否根据组织的资源分配政策限制单个工作负载，并执行硬限制。
 #4.7.4    级别: 2    角色: V
 验证成本监控能够跟踪每个工作负载/租户的支出，并根据组织预算阈值发出警报，同时对预算超支进行自动控制。
 #4.7.5    级别: 3    角色: V
 验证容量规划是否使用具有组织定义的预测周期的历史数据，并基于需求模式进行自动资源配置。
 #4.7.6    级别: 2    角色: D/V
 验证资源耗尽是否根据组织响应要求触发断路器，包括基于容量策略的速率限制和工作负载隔离。

---

### C4.8 环境隔离与推广控制

通过自动化升级门控和安全验证，强制执行严格的环境边界。

 #4.8.1    级别: 1    角色: D/V
 验证开发/测试/生产环境是否运行在独立的 VPC/VNet 中，且没有共享的 IAM 角色、安全组或网络连接。
 #4.8.2    级别: 1    角色: D/V
 验证环境推广是否需要经过组织定义的授权人员的审批，并且具有加密签名和不可篡改的审计记录。
 #4.8.3    级别: 2    角色: D/V
 验证生产环境是否阻止SSH访问，禁用调试端点，并且除紧急情况外，要求通过变更请求并满足组织的提前通知要求。
 #4.8.4    级别: 2    角色: D/V
 验证基础设施即代码的更改在合并到主分支之前需经过同行评审，并通过自动化测试和安全扫描。
 #4.8.5    级别: 2    角色: D/V
 验证非生产数据是否按照组织隐私要求进行匿名化，合成数据生成，或通过验证的完全数据掩码和个人身份信息(PII)的移除。
 #4.8.6    级别: 2    角色: D/V
 验证晋升门控是否包含自动化安全测试（SAST、DAST、容器扫描），并且要求无CRITICAL级别的发现才能获得批准。

---

### C4.9 基础设施备份与恢复

通过自动备份、测试恢复程序和灾难恢复能力，确保基础设施的韧性。

 #4.9.1    级别: 1    角色: D/V
 验证基础设施配置是否根据组织的备份时间表备份到地理上分离的区域，并实施3-2-1备份策略。
 #4.9.2    级别: 2    角色: D/V
 验证备份系统是否在隔离网络中运行，使用独立凭证并采用隔离存储，以防勒索软件攻击。
 #4.9.3    级别: 2    角色: V
 根据组织计划，验证恢复程序通过自动化测试进行了测试和验证，并且恢复时间目标（RTO）和恢复点目标（RPO）符合组织要求。
 #4.9.4    级别: 3    角色: V
 验证灾难恢复是否包含针对 AI 的专用操作手册，包括模型权重恢复、GPU 集群重建和服务依赖关系映射。

---

### C4.10 基础设施合规性与治理

通过持续评估、文档记录和自动化控制，实现合规管理。

 #4.10.1    级别: 2    角色: D/V
 验证基础设施合规性是否根据组织的时间表，针对 SOC 2、ISO 27001 或 FedRAMP 控制进行评估，并通过自动化证据收集完成。
 #4.10.2    级别: 2    角色: V
 核实基础设施文档是否包含网络拓扑图、数据流图和威胁模型，并且这些内容是否根据组织变更管理要求进行了更新。
 #4.10.3    级别: 3    角色: D/V
 验证基础设施变更是否经过自动化合规性影响评估，并针对高风险修改执行监管审批流程。

---

### C4.11 AI 硬件安全

保护专用于人工智能的硬件组件，包括 GPU、TPU 以及专门的 AI 加速器。

 #4.11.1    级别: 2    角色: D/V
 验证 AI 加速器固件（GPU BIOS、TPU 固件）是否通过密码学签名进行验证，并按照组织的补丁管理时间表进行更新。
 #4.11.2    级别: 2    角色: D/V
 确保在工作负载执行前，通过使用TPM 2.0、Intel TXT或AMD SVM进行硬件认证来验证AI加速器的完整性。
 #4.11.3    级别: 2    角色: D/V
 使用 SR-IOV、MIG（多实例 GPU）或等效的硬件分区，并在任务之间进行内存清理，验证 GPU 内存是否在工作负载之间隔离。
 #4.11.4    级别: 3    角色: V
 确认人工智能硬件供应链包括带有制造商证书的来源验证以及防篡改包装的验证。
 #4.11.5    级别: 3    角色: D/V
 验证硬件安全模块（HSM）是否通过了FIPS 140-2 第3级或通用标准EAL4+认证，以保护AI模型权重和加密密钥。

---

### C4.12 边缘与分布式人工智能基础设施

安全的分布式人工智能部署，包括边缘计算、联邦学习和多站点架构。

 #4.12.1    级别: 2    角色: D/V
 验证边缘 AI 设备是否使用双向 TLS 通过设备证书认证到中央基础设施，且设备证书按照组织的证书管理策略进行轮换。
 #4.12.2    级别: 2    角色: D/V
 验证边缘设备是否实现了具有验证签名和回滚保护的安全启动，以防止固件降级攻击。
 #4.12.3    级别: 3    角色: D/V
 验证分布式人工智能协调是否使用了具有参与者验证和恶意节点检测的拜占庭容错共识算法。
 #4.12.4    级别: 3    角色: D/V
 验证边缘到云通信包括带宽限制、数据压缩以及具备安全本地存储的离线操作能力。

---

### C4.13 多云与混合基础设施安全

确保跨多个云提供商以及混合云和本地部署的 AI 工作负载的安全。

 #4.13.1    级别: 2    角色: D/V
 验证多云 AI 部署是否使用云无关的身份联合（OIDC，SAML）以及跨供应商的集中式策略管理。
 #4.13.2    级别: 2    角色: D/V
 验证跨云数据传输是否使用端到端加密，并采用客户管理的密钥，以及根据各司法管辖区实施数据驻留控制。
 #4.13.3    级别: 2    角色: D/V
 验证混合云 AI 工作负载在本地和云环境中实施一致的安全策略，并实现统一的监控和警报。
 #4.13.4    级别: 3    角色: V
 验证云厂商锁定预防措施是否包括可移植的基础设施即代码、标准化的API以及具备格式转换工具的数据导出功能。
 #4.13.5    级别: 3    角色: V
 验证多云成本优化是否包括防止资源泛滥的安全控制，以及防止未经授权的跨云数据传输费用。

---

### C4.14 基础设施自动化与 GitOps 安全

为 AI 基础设施管理确保基础设施自动化流水线和 GitOps 工作流的安全。

 #4.14.1    级别: 2    角色: D/V
 验证 GitOps 仓库是否要求使用 GPG 密钥进行签名提交，并且设置分支保护规则以防止直接推送到主分支。
 #4.14.2    级别: 2    角色: D/V
 验证基础设施自动化包括偏移检测，并具备根据组织响应要求触发的自动修复和回滚功能，以应对未授权更改。
 #4.14.3    级别: 2    角色: D/V
 验证自动化基础设施配置包含安全策略验证，并对不符合要求的配置阻止部署。
 #4.14.4    级别: 2    角色: D/V
 验证基础设施自动化密钥是否通过外部密钥管理操作器（External Secrets Operator，Bank-Vaults）进行管理，并具备自动轮换功能。
 #4.14.5    级别: 3    角色: V
 验证自愈基础设施是否包含具有自动化事件响应和利益相关者通知工作流程的安全事件关联。

---

### C4.15 量子抗性基础设施安全

通过后量子密码学和量子安全协议，为量子计算威胁做好人工智能基础设施的准备。

 #4.15.1    级别: 3    角色: D/V
 验证 AI 基础设施是否实施了经 NIST 批准的后量子密码算法（CRYSTALS-Kyber、CRYSTALS-Dilithium、SPHINCS+）用于密钥交换和数字签名。
 #4.15.2    级别: 3    角色: D/V
 验证量子密钥分发（QKD）系统的实施，确保其采用量子安全的密钥管理协议，以实现高安全性的人工智能通信。
 #4.15.3    级别: 3    角色: D/V
 验证加密灵活性框架能够通过自动证书和密钥轮换，快速迁移到新的后量子算法。
 #4.15.4    级别: 3    角色: V
 验证量子威胁建模是否评估了 AI 基础设施对量子攻击的脆弱性，并附有记录的迁移时间表和风险评估。
 #4.15.5    级别: 3    角色: D/V
 验证混合经典-量子密码系统在量子过渡期间通过性能监控实现纵深防御。

---

### C4.16 机密计算与安全保障区

使用基于硬件的可信执行环境和机密计算技术保护人工智能工作负载和模型权重。

 #4.16.1    级别: 3    角色: D/V
 验证敏感的 AI 模型是否在 Intel SGX 安全环境、AMD SEV-SNP 或带有加密内存和认证验证的 ARM TrustZone 中执行。
 #4.16.2    级别: 3    角色: D/V
 验证机密容器（Kata Containers、使用机密计算的 gVisor）是否通过硬件强制的内存加密隔离 AI 工作负载。
 #4.16.3    级别: 3    角色: D/V
 验证远程证明在加载人工智能模型之前通过加密证明执行环境的真实性来确认可信执行环境的完整性。
 #4.16.4    级别: 3    角色: D/V
 验证机密 AI 推理服务通过加密计算、封装模型权重和受保护执行来防止模型提取。
 #4.16.5    级别: 3    角色: D/V
 验证受信任执行环境编排通过远程认证和加密通信通道管理安全区域的生命周期。
 #4.16.6    级别: 3    角色: D/V
 验证安全多方计算（SMPC）能够实现协作式人工智能训练，同时不暴露各自的数据集或模型参数。

---

### C4.17 零知识基础设施

实现零知识证明系统，用于隐私保护的人工智能验证和认证，且不泄露敏感信息。

 #4.17.1    级别: 3    角色: D/V
 验证零知识证明（ZK-SNARKs，ZK-STARKs）能够在不泄露模型权重或训练数据的情况下，验证人工智能模型的完整性和训练来源。
 #4.17.2    级别: 3    角色: D/V
 验证基于零知识（ZK）的身份验证系统能够在不透露身份相关信息的情况下，实现对人工智能服务用户的隐私保护验证。
 #4.17.3    级别: 3    角色: D/V
 验证私有集合交集（PSI）协议是否能够在不暴露各自数据集的情况下，实现联邦人工智能中的安全数据匹配。
 #4.17.4    级别: 3    角色: D/V
 验证零知识机器学习（ZKML）系统能够通过加密证明正确计算，实现在人工智能推理中的可验证性。
 #4.17.5    级别: 3    角色: D/V
 验证 ZK-rollups 是否通过批量验证和减少计算开销，实现可扩展且保护隐私的 AI 交易处理。

---

### C4.18 侧信道攻击防护

保护人工智能基础设施免受可能泄露敏感信息的时间、功率、电磁和基于缓存的侧信道攻击。

 #4.18.1    级别: 3    角色: D/V
 验证AI推理时间是否通过使用常数时间算法和填充进行归一化，以防止基于时间的模型提取攻击。
 #4.18.2    级别: 3    角色: D/V
 验证功率分析防护包括噪声注入、电源线滤波和随机执行模式，以保护人工智能硬件。
 #4.18.3    级别: 3    角色: D/V
 验证基于缓存的侧信道缓解技术是否使用缓存分区、随机化和刷新指令来防止信息泄露。
 #4.18.4    级别: 3    角色: D/V
 验证电磁发射保护是否包括屏蔽、信号过滤和随机处理，以防止TEMPEST式攻击。
 #4.18.5    级别: 3    角色: D/V
 验证微架构侧信道防御措施是否包括推测执行控制和内存访问模式混淆。

---

### C4.19 神经形态与专用人工智能硬件安全

保护新兴的 AI 硬件架构，包括神经形态芯片、FPGA、自定义 ASIC 以及光学计算系统。

 #4.19.1    级别: 3    角色: D/V
 验证神经形态芯片安全性应包括脉冲模式加密、突触权重保护以及基于硬件的学习规则验证。
 #4.19.2    级别: 3    角色: D/V
 验证基于FPGA的人工智能加速器是否实现了比特流加密、防篡改机制以及通过身份验证的更新进行安全配置加载。
 #4.19.3    级别: 3    角色: D/V
 验证定制ASIC安全性是否包括片上安全处理器、硬件根信任和具备防篡改检测的安全密钥存储。
 #4.19.4    级别: 3    角色: D/V
 验证光学计算系统是否实现了量子安全光学加密、安全光子交换以及受保护的光信号处理。
 #4.19.5    级别: 3    角色: D/V
 验证混合模拟-数字 AI 芯片是否包含安全的模拟计算、受保护的权重存储和经过认证的模拟到数字转换。

---

### C4.20 隐私保护计算基础设施

实施基础设施控制以实现隐私保护计算，保护人工智能处理和分析过程中敏感数据的安全。

 #4.20.1    级别: 3    角色: D/V
 验证同态加密基础设施能够在敏感的人工智能工作负载上实现加密计算，并具备密码学完整性验证和性能监控功能。
 #4.20.2    级别: 3    角色: D/V
 验证私有信息检索系统通过对访问模式的密码学保护，实现数据库查询而不泄露查询模式。
 #4.20.3    级别: 3    角色: D/V
 验证安全多方计算协议是否能够在不暴露单个输入或中间计算结果的情况下，实现隐私保护的人工智能推理。
 #4.20.4    级别: 3    角色: D/V
 验证隐私保护的密钥管理包括分布式密钥生成、门限密码学以及带有硬件支持保护的安全密钥轮换。
 #4.20.5    级别: 3    角色: D/V
 验证通过批处理、缓存和硬件加速优化隐私保护计算性能，同时保持密码学安全保证。

---

### C4.15 代理框架云集成安全与混合部署

具有混合本地/云架构的云集成代理框架的安全控制措施。

 #4.15.1    级别: 1    角色: D/V
 验证云存储集成是否采用端到端加密，并由代理控制密钥管理。
 #4.15.2    级别: 2    角色: D/V
 验证混合部署的安全边界是否明确定义，并使用加密通信通道。
 #4.15.3    级别: 2    角色: D/V
 验证云资源访问是否包含零信任验证和持续身份验证。
 #4.15.4    级别: 3    角色: D/V
 通过对存储位置的加密证明，验证数据驻留要求的执行情况。
 #4.15.5    级别: 3    角色: D/V
 验证云提供商的安全评估是否包含针对代理的威胁建模和风险评估。

---

### 参考文献

NIST Cybersecurity Framework 2.0
CIS Controls v8
OWASP Container Security Verification Standard
Kubernetes Security Best Practices
SLSA Supply Chain Security Framework
NIST SP 800-190: Application Container Security Guide
Cloud Security Alliance: Cloud Controls Matrix
ENISA: Secure Infrastructure Design
NIST SP 800-53: Security Controls for Federal Information Systems
ISO 27001:2022 Information Security Management
NIST AI Risk Management Framework
CIS Kubernetes Benchmark
FIPS 140-2 Security Requirements
NIST SP 800-207: Zero Trust Architecture
IEEE 2857: Privacy Engineering for AI Systems
NIST SP 800-161: Cybersecurity Supply Chain Risk Management
NIST Post-Quantum Cryptography Standards
Intel SGX Developer Guide
AMD SEV-SNP White Paper
ARM TrustZone Technology
ZK-SNARKs: A Gentle Introduction
NIST SP 800-57: Cryptographic Key Management
Side-Channel Attack Countermeasures
Neuromorphic Computing Security Challenges
FPGA Security: Fundamentals, Evaluation, and Countermeasures
Microsoft SEAL: Homomorphic Encryption Library
HElib: Homomorphic Encryption Library
PALISADE Lattice Cryptography Library
Differential Privacy: A Survey of Results
Secure Aggregation for Federated Learning
Private Information Retrieval: Concepts and Constructions

## C5 AI组件和用户的访问控制与身份管理

### 控制目标

针对人工智能系统的有效访问控制需要强大的身份管理、上下文感知的授权以及遵循零信任原则的运行时执行。这些控制确保人类、服务和自主代理仅在明确授予的范围内与模型、数据和计算资源进行交互，并具备持续的验证和审计能力。

---

### C5.1 身份管理与认证

为所有实体建立基于密码学支持的身份，并为特权操作实施多因素认证。

 #5.1.1    级别: 1    角色: D/V
 验证所有人类用户和服务主体均通过使用 OIDC/SAML 协议的集中式企业身份提供者（IdP）进行身份验证，确保唯一的身份到令牌映射（不使用共享账户或凭据）。
 #5.1.2    级别: 1    角色: D/V
 验证高风险操作（模型部署、权重导出、训练数据访问、生产配置更改）是否需要多因素认证或带有会话重新验证的提升认证。
 #5.1.3    级别: 2    角色: D
 确保新负责人在获得生产系统访问权限之前，经过符合 NIST 800-63-3 IAL-2 或同等标准的身份验证。
 #5.1.4    级别: 2    角色: V
 验证访问审查是否每季度进行一次，并自动检测闲置账户、强制执行凭证轮换以及执行注销工作流程。
 #5.1.5    级别: 3    角色: D/V
 验证联合 AI 代理通过签名的 JWT 断言进行身份验证，该断言的最长有效期为 24 小时，并包含来源的加密证明。

---

### C5.2 资源授权与最小特权

为所有人工智能资源实施细粒度访问控制，采用明确的权限模型和审计跟踪。

 #5.2.1    级别: 1    角色: D/V
 验证每个 AI 资源（数据集、模型、端点、向量集合、嵌入索引、计算实例）都执行基于角色的访问控制，并采用显式允许列表和默认拒绝策略。
 #5.2.2    级别: 1    角色: D/V
 验证默认情况下服务账户遵循最小权限原则，从只读权限开始，并且写权限需有书面业务理由。
 #5.2.3    级别: 1    角色: V
 验证所有访问控制修改均与已批准的变更请求相关联，并以不可篡改的方式记录，包括时间戳、操作者身份、资源标识符和权限变化。
 #5.2.4    级别: 2    角色: D
 验证数据分类标签（PII、PHI、出口管制、专有）是否自动传播到派生资源（嵌入、提示缓存、模型输出），并确保策略执行的一致性。
 #5.2.5    级别: 2    角色: D/V
 验证未授权访问尝试和权限提升事件是否在5分钟内触发带有上下文元数据的实时警报到SIEM系统。

---

### C5.3 动态策略评估

部署基于属性的访问控制（ABAC）引擎，以实现具备审计功能的上下文感知授权决策。

 #5.3.1    级别: 1    角色: D/V
 验证授权决策是否外部化到通过经过身份验证的API且具有密码完整性保护的专用策略引擎（如OPA、Cedar或同类）中。
 #5.3.2    级别: 1    角色: D/V
 验证策略在运行时评估动态属性，包括用户权限级别、资源敏感性分类、请求上下文、租户隔离和时间限制。
 #5.3.3    级别: 2    角色: D
 验证策略定义在生产部署前通过版本控制、同行评审以及CI/CD管道中的自动化测试进行验证。
 #5.3.4    级别: 2    角色: V
 验证策略评估结果是否包含结构化的决策理由，并确保这些结果被传输到 SIEM 系统以进行关联分析和合规报告。
 #5.3.5    级别: 3    角色: D/V
 验证策略缓存的生存时间（TTL）值，对于高敏感度资源不超过5分钟，对于具有缓存失效功能的标准资源不超过1小时。

---

### C5.4 查询时安全执行

实施数据库层安全控制，包括强制过滤和行级安全策略。

 #5.4.1    级别: 1    角色: D/V
 验证所有向量数据库和 SQL 查询都包含强制性的安全过滤器（租户 ID、敏感性标签、用户范围），且这些过滤器在数据库引擎层面强制执行，而非应用程序代码中。
 #5.4.2    级别: 1    角色: D/V
 验证所有向量数据库、搜索索引和训练数据集是否启用了具有策略继承的行级安全性（RLS）策略和字段级掩码。
 #5.4.3    级别: 2    角色: D
 验证失败的授权评估将通过立即中止查询并返回明确的授权错误代码，而不是返回空结果集，从而防止“混淆代理攻击”。
 #5.4.4    级别: 2    角色: V
 验证策略评估延迟是否被持续监控，并针对可能导致授权绕过的超时情况设有自动警报。
 #5.4.5    级别: 3    角色: D/V
 验证查询重试机制是否重新评估授权策略，以考虑活动用户会话中的动态权限变化。

---

### C5.5 输出过滤与数据丢失防护

部署后处理控制以防止未经授权的数据在AI生成内容中泄露。

 #5.5.1    级别: 1    角色: D/V
 验证推理后过滤机制是否扫描并编辑未经授权的个人身份信息（PII）、机密信息和专有数据，确保在将内容交付给请求者之前进行处理。
 #5.5.2    级别: 1    角色: D/V
 验证模型输出中的引文、参考文献和来源归属，确保其符合调用者的授权条件，若检测到未经授权的访问，则将其删除。
 #5.5.3    级别: 2    角色: D
 根据用户权限级别和数据分类，验证输出格式限制（如已消毒的PDF、已去除元数据的图像、经批准的文件类型）是否得到强制执行。
 #5.5.4    级别: 2    角色: V
 验证涂黑算法是确定性的、版本可控的，并保持审计日志以支持合规调查和法医分析。
 #5.5.5    级别: 3    角色: V
 验证高风险涂黑事件生成的自适应日志是否包含原始内容的加密哈希，以便在不暴露数据的情况下进行取证检索。

---

### C5.6 多租户隔离

确保共享人工智能基础设施中租户之间的加密和逻辑隔离。

 #5.6.1    级别: 1    角色: D/V
 验证内存空间、嵌入存储、缓存条目和临时文件是否按租户进行命名空间分隔，并确保在租户删除或会话终止时进行安全清除。
 #5.6.2    级别: 1    角色: D/V
 验证每个 API 请求都包含经过身份验证的租户标识符，并且该标识符通过密码学方法与会话上下文和用户权限进行验证。
 #5.6.3    级别: 2    角色: D
 验证网络策略是否在服务网格和容器编排平台中针对跨租户通信实施默认拒绝规则。
 #5.6.4    级别: 3    角色: D
 验证每个租户使用客户管理密钥（CMK）支持时加密密钥的唯一性，并确保租户数据存储之间的加密隔离。

---

### C5.7 自主代理授权

通过作用域能力令牌和持续授权控制人工智能代理和自主系统的权限。

 #5.7.1    级别: 1    角色: D/V
 验证自治代理是否接收范围限定的能力令牌，该令牌明确列出允许的操作、可访问的资源、时间边界和操作限制。
 #5.7.2    级别: 1    角色: D/V
 验证高风险功能（文件系统访问、代码执行、外部API调用、财务交易）默认被禁用，并且激活这些功能需要明确的授权和业务理由。
 #5.7.3    级别: 2    角色: D
 验证能力令牌是否绑定到用户会话，包含加密完整性保护，并确保它们不能在离线场景中被持久化或重用。
 #5.7.4    级别: 2    角色: V
 验证代理发起的操作通过 ABAC 策略引擎进行二次授权，包含完整的上下文评估和审计日志记录。
 #5.7.5    级别: 3    角色: V
 验证代理错误条件和异常处理是否包含能力范围信息，以支持事件分析和取证调查。

---

### 参考文献

#### 标准与框架

NIST SP 800-63-3: Digital Identity Guidelines
Zero Trust Architecture – NIST SP 800-207
OWASP Application Security Verification Standard (AISVS)
​
#### 实施指南

Identity and Access Management in the AI Era: 2025 Guide – IDSA
Attribute-Based Access Control with OPA – Permify
How We Designed Cedar to Be Intuitive, Fast, and Safe – AWS
​
#### 特定于人工智能的安全

Row Level Security in Vector DBs for RAG – Bluetuple.ai
Tenant Isolation in Multi-Tenant Systems – WorkOS
Handling AI Agent Permissions – Stytch
OWASP Top 10 for Large Language Model Applications

## C6 模型、框架与数据的供应链安全

### 控制目标

AI 供应链攻击利用第三方模型、框架或数据集植入后门、偏见或可利用的代码。这些控制措施提供端到端的来源管理、漏洞管理和监控，以保护整个模型生命周期。

---

### C6.1 预训练模型审查与来源验证

在进行任何微调或部署之前，评估并验证第三方模型的来源、许可证和隐藏行为。

 #6.1.1    级别: 1    角色: D/V
 验证每个第三方模型工件是否包含一个签名的来源记录，以识别源代码库和提交哈希。
 #6.1.2    级别: 1    角色: D/V
 确保在导入模型之前，使用自动化工具扫描模型中的恶意层或特洛伊木马触发器。
 #6.1.3    级别: 2    角色: D
 验证迁移学习微调通过对抗性评估以检测隐藏行为。
 #6.1.4    级别: 2    角色: V
 验证模型许可证、出口管制标签和数据来源声明是否已记录在 ML-BOM 条目中。
 #6.1.5    级别: 3    角色: D/V
 验证高风险模型（公开上传的权重、未经验证的创建者）在人工审核和签署之前保持隔离状态。

---

### C6.2 框架与库扫描

持续扫描机器学习框架和库中的CVE漏洞及恶意代码，以确保运行时堆栈的安全。

 #6.2.1    级别: 1    角色: D/V
 验证 CI 管道是否对 AI 框架和关键库运行依赖扫描器。
 #6.2.2    级别: 1    角色: D/V
 验证严重漏洞（CVSS ≥ 7.0）是否阻止推广到生产镜像。
 #6.2.3    级别: 2    角色: D
 验证静态代码分析是否在派生或内置的机器学习库上运行。
 #6.2.4    级别: 2    角色: V
 验证框架升级提案是否包含引用公共CVE源的安全影响评估。
 #6.2.5    级别: 3    角色: V
 验证运行时传感器是否对偏离签名 SBOM 的意外动态库加载发出警报。

---

### C6.3 依赖项固定与验证

将每个依赖项固定到不可变的摘要，并重现构建以保证生成相同且防篡改的工件。

 #6.3.1    级别: 1    角色: D/V
 验证所有包管理器是否通过锁定文件强制执行版本固定。
 #6.3.2    级别: 1    角色: D/V
 验证在容器引用中使用的是不可变摘要，而不是可变标签。
 #6.3.3    级别: 2    角色: D
 验证可重现构建检查在持续集成（CI）运行之间比较哈希值，以确保输出一致。
 #6.3.4    级别: 2    角色: V
 验证构建证明是否存储了18个月以确保审计可追溯性。
 #6.3.5    级别: 3    角色: D
 验证过期的依赖项是否会触发自动拉取请求以更新或分叉固定版本。

---

### C6.4 可信来源执行

只允许从经过密码学验证且组织批准的来源下载工件，阻止所有其他来源。

 #6.4.1    级别: 1    角色: D/V
 验证模型权重、数据集和容器仅从批准的域或内部注册表下载。
 #6.4.2    级别: 1    角色: D/V
 验证 Sigstore/Cosign 签名以确认发布者身份，然后再将制品缓存到本地。
 #6.4.3    级别: 2    角色: D
 验证出口代理是否阻止未经身份验证的制品下载，以强制执行可信来源策略。
 #6.4.4    级别: 2    角色: V
 验证存储库允许列表是否每季度审查一次，并提供每个条目的业务理由证明。
 #6.4.5    级别: 3    角色: V
 验证策略违规是否会触发工件隔离和依赖流水线运行的回滚。

---

### C6.5 第三方数据集风险评估

评估外部数据集的投毒、偏差和法律合规性，并在其整个生命周期内进行监控。

 #6.5.1    级别: 1    角色: D/V
 验证外部数据集是否经过中毒风险评分（例如，数据指纹识别、离群检测）。
 #6.5.2    级别: 1    角色: D
 确认在数据集批准之前计算偏差指标（人口统计平等性、均等机会）。
 #6.5.3    级别: 2    角色: V
 验证数据集的来源和许可条款是否已记录在 ML-BOM 条目中。
 #6.5.4    级别: 2    角色: V
 验证定期监控是否能够检测托管数据集中的漂移或损坏。
 #6.5.5    级别: 3    角色: D
 确认在训练前通过自动清理移除禁止内容（版权、个人身份信息）。

---

### C6.6 供应链攻击监控

通过CVE信息源、审计日志分析和红队模拟，及早发现供应链威胁。

 #6.6.1    级别: 1    角色: V
 验证 CI/CD 审计日志是否传输到 SIEM 以检测异常的软件包拉取或被篡改的构建步骤。
 #6.6.2    级别: 2    角色: D
 验证事件响应剧本中是否包含受损模型或库的回滚程序。
 #6.6.3    级别: 3    角色: V
 验证威胁情报增强是否在警报分类中标记了机器学习特定指标（例如，模型投毒指示器）。

---

### C6.7 模型工件的机器学习物料清单 (ML-BOM)

生成并签署详细的特定于机器学习的软体物料清单（ML-BOMs），以便下游使用者能够在部署时验证组件的完整性。

 #6.7.1    级别: 1    角色: D/V
 验证每个模型工件是否发布了包含数据集、权重、超参数和许可证的机器学习物料清单（ML-BOM）。
 #6.7.2    级别: 1    角色: D/V
 验证 ML‑BOM 生成和 Cosign 签名是否在持续集成（CI）中自动执行，并且是合并的必需条件。
 #6.7.3    级别: 2    角色: D
 验证如果任何组件元数据（哈希、许可证）缺失，ML-BOM 完整性检查会导致构建失败。
 #6.7.4    级别: 2    角色: V
 验证下游消费者是否可以通过API查询ML-BOM，以在部署时验证导入的模型。
 #6.7.5    级别: 3    角色: V
 验证 ML‑BOM 是否进行了版本控制并差异比较，以检测未经授权的修改。

---

### 参考文献

ML Supply Chain Compromise – MITRE ATLAS
Supply‑chain Levels for Software Artifacts (SLSA)
CycloneDX – Machine Learning Bill of Materials
What is Data Poisoning? – SentinelOne
Transfer Learning Attack – OWASP ML Security Top 10
AI Data Security Best Practices – CISA
Secure CI/CD Supply Chain – Sumo Logic
AI & Transparency: Protect ML Models – ReversingLabs
SBOM Overview – CISA
Training Data Poisoning Guide – Lakera.ai
Dependency Pinning for Reproducible Python – Medium

## C7 模型行为、输出控制与安全保障

### 控制目标

模型输出必须结构化、可靠、安全、可解释，并在生产中持续监控。这样可以减少幻觉、隐私泄露、有害内容和失控行为，同时提升用户信任和法规合规性。

---

### C7.1 输出格式强制执行

严格的模式、受限解码和下游验证在错误或恶意内容传播之前予以阻止。

 #7.1.1    级别: 1    角色: D/V
 验证系统提示中是否提供了响应模式（例如，JSON 模式），并确保每个输出都经过自动验证；不符合规范的输出将触发修复或拒绝。
 #7.1.2    级别: 1    角色: D/V
 验证已启用约束解码（停止令牌、正则表达式、最大令牌数）以防止溢出或提示注入侧信道。
 #7.1.3    级别: 2    角色: D/V
 验证下游组件将输出视为不可信，并根据模式或防注入的反序列化器进行验证。
 #7.1.4    级别: 3    角色: V
 验证不当输出事件是否被记录、限流，并显示在监控中。

---

### C7.2 幻觉检测与缓解

不确定性估计和回退策略抑制虚构答案。

 #7.2.1    级别: 1    角色: D/V
 验证令牌级别的对数概率、集成自洽性或微调的幻觉检测器是否为每个答案分配置信度评分。
 #7.2.2    级别: 1    角色: D/V
 验证低于可配置置信度阈值的响应是否会触发后备工作流（例如，检索增强生成、辅助模型或人工审核）。
 #7.2.3    级别: 2    角色: D/V
 验证幻觉事件是否带有根本原因元数据标签，并送入事后分析和微调流程。
 #7.2.4    级别: 3    角色: D/V
 确认在重大模型或知识库更新后阈值和检测器已重新校准。
 #7.2.5    级别: 3    角色: V
 验证仪表板可视化是否跟踪幻觉率。

---

### C7.3 输出安全与隐私过滤

策略过滤器和红队覆盖保护用户和机密数据。

 #7.3.1    级别: 1    角色: D/V
 验证生成前和生成后分类器是否按照政策阻止仇恨、骚扰、自残、极端主义和性露骨内容。
 #7.3.2    级别: 1    角色: D/V
 验证每个响应中是否运行了个人身份信息/支付卡信息检测和自动涂黑；违规行为会引发隐私事件。
 #7.3.3    级别: 2    角色: D
 验证机密性标签（例如商业秘密）是否在不同模态间传播，以防止文本、图像或代码泄露。
 #7.3.4    级别: 3    角色: D/V
 验证过滤器绕过尝试或高风险分类是否需要二次批准或用户重新认证。
 #7.3.5    级别: 3    角色: D/V
 验证过滤阈值是否反映法律管辖区以及用户年龄/角色的上下文。

---

### C7.4 输出与动作限制

速率限制和批准门控防止滥用和过度自主。

 #7.4.1    级别: 1    角色: D
 验证每个用户和每个 API 密钥的配额限制请求次数、令牌数和成本，并在遇到 429 错误时采用指数退避机制。
 #7.4.2    级别: 1    角色: D/V
 验证特权操作（文件写入、代码执行、网络调用）是否需要基于策略的批准或人为干预。
 #7.4.3    级别: 2    角色: D/V
 验证跨模态一致性检查确保为同一请求生成的图像、代码和文本不能被用来夹带恶意内容。
 #7.4.4    级别: 2    角色: D
 验证代理委托深度、递归限制和允许的工具列表是否已明确配置。
 #7.4.5    级别: 3    角色: V
 验证超限违规则是否会生成结构化的安全事件以供SIEM采集。

---

### C7.5 输出可解释性

透明信号提升用户信任并有助于内部调试。

 #7.5.1    级别: 2    角色: D/V
 在风险评估认为适当时，验证是否公开了面向用户的置信度评分或简要推理摘要。
 #7.5.2    级别: 2    角色: D/V
 验证生成的解释是否避免泄露敏感的系统提示或专有数据。
 #7.5.3    级别: 3    角色: D
 验证系统是否捕捉了令牌级别的对数概率或注意力图，并为授权检查存储了这些数据。
 #7.5.4    级别: 3    角色: V
 验证解释性工件是否与模型发布一起进行版本控制，以便于审计。

---

### C7.6 监控集成

实时可观测性实现了开发与生产之间的闭环。

 #7.6.1    级别: 1    角色: D
 验证度量指标（架构违规、幻觉率、毒性、个人身份信息泄露、延迟、成本）是否流向中央监控平台。
 #7.6.2    级别: 1    角色: V
 验证是否为每个安全指标定义了警报阈值，并且设置了值班升级路径。
 #7.6.3    级别: 2    角色: V
 验证仪表板是否将输出异常与模型/版本、功能开关和上游数据变化相关联。
 #7.6.4    级别: 2    角色: D/V
 验证监控数据是否反馈到带有文档记录的MLOps工作流中的重新训练、微调或规则更新。
 #7.6.5    级别: 3    角色: V
 验证监控流水线是否经过渗透测试并实施了访问控制，以避免敏感日志泄露。

---

### 7.7 生成媒体防护措施

确保人工智能系统通过执行政策约束、输出验证和可追溯性，避免生成非法、有害或未经授权的媒体内容。

 #7.7.1    级别: 1    角色: D/V
 请确认系统提示和用户指令明确禁止生成非法、有害或未经同意的深度伪造媒体（例如图像、视频、音频）。
 #7.7.2    级别: 2    角色: D/V
 验证提示是否经过筛选，以防止生成冒充、性露骨深度伪造，或未经同意描绘真实个人的媒体。
 #7.7.3    级别: 2    角色: V
 验证系统是否使用感知哈希、水印检测或指纹识别来防止未经授权复制受版权保护的媒体。
 #7.7.4    级别: 3    角色: D/V
 验证所有生成的媒体是否经过加密签名、加水印，或嵌入防篡改的来源元数据，以确保下游的可追溯性。
 #7.7.5    级别: 3    角色: V
 验证绕过尝试（例如，提示混淆、俚语、对抗性措辞）是否被检测、记录和限速；重复滥用应被反馈到监控系统。

### 参考文献

NIST AI Risk Management Framework
ISO/IEC 42001:2023 – AI Management System
OWASP Top-10 for Large Language Model Applications (2025)
Improper Output Handling – OWASP LLM05:2025
Practical Techniques to Constrain LLM Output
Dataiku – Structured Text Generation Guide
VL-Uncertainty: Detecting Hallucinations
HaDeMiF: Hallucination Detection & Mitigation
Building Confidence in LLM Outputs
Explainable AI & LLMs
LLM Red-Teaming Guide
Sensitive Information Disclosure in LLMs
LangChain – Chat Model Rate Limiting
OpenAI Rate-Limit & Exponential Back-off
Arize AI – LLM Observability Platform

## C8 存储器、嵌入表示与向量数据库安全

### 控制目标

嵌入和向量存储作为当代人工智能系统的“实时记忆”，不断接受用户提供的数据，并通过检索增强生成（RAG）将其反馈到模型上下文中。如果不加以管理，这种记忆可能会泄露个人身份信息（PII）、违反同意，或被反转以重构原始文本。该控制类别的目标是强化记忆流程和向量数据库，使访问权限最小化，嵌入具备隐私保护，存储的向量能过期或按需撤销，并且每个用户的记忆不会污染其他用户的提示或生成内容。

---

### C8.1 对内存和RAG索引的访问控制

对每个向量集合实施细粒度访问控制。

 #8.1.1    级别: 1    角色: D/V
 验证行级/命名空间级访问控制规则是否限制了每个租户、集合或文档标签的插入、删除和查询操作。
 #8.1.2    级别: 1    角色: D/V
 验证 API 密钥或 JWT 是否携带限定的声明（例如，集合 ID、操作动词），并且至少每季度进行一次轮换。
 #8.1.3    级别: 2    角色: D/V
 验证特权提升尝试（例如跨命名空间的相似性查询）是否在5分钟内被检测到并记录到SIEM中。
 #8.1.4    级别: 2    角色: D/V
 验证向量数据库的审计日志中是否记录了主体标识符、操作、向量 ID/命名空间、相似度阈值和结果数量。
 #8.1.5    级别: 3    角色: V
 每当引擎升级或索引分片规则变化时，验证访问决策是否存在绕过缺陷。

---

### C8.2 嵌入的清理与验证

预先筛查文本中的个人身份信息（PII），在向量化之前进行删除或假名处理，并可选择在嵌入后处理阶段去除残留信号。

 #8.2.1    级别: 1    角色: D/V
 验证通过自动分类器检测到的个人身份信息（PII）和受监管数据，并在嵌入处理前进行掩码、标记化或丢弃。
 #8.2.2    级别: 1    角色: D
 验证嵌入管道是否拒绝或隔离包含可执行代码或非UTF-8不良数据的输入，这些内容可能会污染索引。
 #8.2.3    级别: 2    角色: D/V
 验证对与任何已知PII令牌距离低于可配置阈值的句子嵌入应用了本地或度量差分隐私清理。
 #8.2.4    级别: 2    角色: V
 验证清理效果（例如，个人身份信息消除的召回率、语义漂移）至少每半年通过基准语料库进行验证。
 #8.2.5    级别: 3    角色: D/V
 验证清理配置是否实行版本控制，并确保变更经过同级审查。

---

### C8.3 内存到期、撤销与删除

GDPR“被遗忘权”和类似法律要求及时删除；因此，向量存储必须支持TTL、硬删除和墓碑机制，以确保被撤销的向量无法被恢复或重新索引。

 #8.3.1    级别: 1    角色: D/V
 验证每个向量和元数据记录是否具有由自动清理任务执行的TTL或明确保留标签。
 #8.3.2    级别: 1    角色: D/V
 确认用户发起的删除请求在30天内清除向量、元数据、缓存副本和派生索引。
 #8.3.3    级别: 2    角色: D
 验证逻辑删除后，如果硬件支持，则紧随其后进行存储块的加密销毁，或者通过密钥库密钥销毁来实现。
 #8.3.4    级别: 3    角色: D/V
 验证过期向量在过期后500毫秒内被排除在最近邻搜索结果之外。

---

### C8.4 防止嵌入反演与泄露

最近的防御措施——噪声叠加、投影网络、隐私神经元扰动和应用层加密——可以将令牌级别的反演率降低到5%以下。

 #8.4.1    级别: 1    角色: V
 确认存在涵盖反演攻击、成员攻击和属性推断攻击的正式威胁模型，并且该模型每年进行审查。
 #8.4.2    级别: 2    角色: D/V
 验证应用层加密或可搜索加密能否保护向量，防止基础设施管理员或云工作人员直接读取。
 #8.4.3    级别: 3    角色: V
 验证防御参数（DP 的 ε，噪声 σ，投影秩 k）是否在隐私保护 ≥ 99% 令牌保护和效用损失 ≤ 3% 准确率下降之间取得平衡。
 #8.4.4    级别: 3    角色: D/V
 验证逆转稳健性指标是否作为模型更新的发布门控的一部分，并定义回归预算。

---

### C8.5 用户特定内存的范围强制执行

跨租户泄漏仍然是RAG的主要风险：未正确过滤的相似性查询可能会暴露其他客户的私人文档。

 #8.5.1    级别: 1    角色: D/V
 验证每个检索查询在传递给大语言模型提示之前，是否通过租户/用户ID进行了后过滤。
 #8.5.2    级别: 1    角色: D
 验证集合名称或命名空间ID是否针对每个用户或租户进行了加盐处理，以防止向量在不同范围内发生冲突。
 #8.5.3    级别: 2    角色: D/V
 验证超过可配置距离阈值但超出调用者范围的相似性结果被丢弃并触发安全警报。
 #8.5.4    级别: 2    角色: V
 验证多租户压力测试是否模拟了试图检索超出范围文档的对抗性查询，并展示零泄露情况。
 #8.5.5    级别: 3    角色: D/V
 验证加密密钥是否按租户隔离，确保即使物理存储共享也能实现密码学隔离。

---

### C8.6 高级内存系统安全

针对复杂内存架构（包括情景记忆、语义记忆和工作记忆）具有特定隔离和验证要求的安全控制。

 #8.6.1    级别: 1    角色: D/V
 验证不同类型的记忆（情景记忆、语义记忆、工作记忆）是否具有隔离的安全上下文，配备基于角色的访问控制、独立的加密密钥，以及为每种记忆类型记录的访问模式。
 #8.6.2    级别: 2    角色: D/V
 验证记忆整合过程包括安全验证，以通过内容清理、来源验证和存储前的完整性检查，防止恶意记忆的注入。
 #8.6.3    级别: 2    角色: D/V
 验证内存检索查询是否经过验证和清理，以防止通过查询模式分析、访问控制执行和结果过滤提取未授权的信息。
 #8.6.4    级别: 3    角色: D/V
 验证内存遗忘机制是否通过密钥删除、多遍覆盖或带有验证证书的硬件安全删除，以密码擦除保证安全地删除敏感信息。
 #8.6.5    级别: 3    角色: D/V
 验证通过校验和、审计日志以及当内存内容在正常操作之外发生变化时的自动警报，持续监控内存系统的完整性是否遭到未经授权的修改或损坏。

---

### 参考文献

Vector database security: Pinecone – IronCore Labs
Securing the Backbone of AI: Safeguarding Vector Databases and Embeddings – Privacera
Enhancing Data Security with RBAC of Qdrant Vector Database – AI Advances
Mitigating Privacy Risks in LLM Embeddings from Embedding Inversion – arXiv
DPPN: Detecting and Perturbing Privacy-Sensitive Neurons – OpenReview
Art. 17 GDPR – Right to Erasure
Sensitive Data in Text Embeddings Is Recoverable – Tonic.ai
PII Identification and Removal – NVIDIA NeMo Docs
De-identifying Sensitive Data – Google Cloud DLP
Remove PII from Conversations Using Sensitive Information Filters – AWS Bedrock Guardrails
Think Your RAG Is Secure? Think Again – Medium
Design a Secure Multitenant RAG Inferencing Solution – Microsoft Learn
Best Practices for Multi-Tenancy RAG with Milvus – Milvus Blog

## 9 自主编排与代理行为安全

### 控制目标

确保自主或多代理人工智能系统只能执行明确意图、已认证、可审计且在有限成本和风险阈值内的操作。这有助于防范自主系统被攻破、工具滥用、代理循环检测、通信劫持、身份伪造、群体操控和意图篡改等威胁。

---

### 9.1 代理任务规划与递归预算

限制递归计划并强制设置针对特权操作的人为检查点。

 #9.1.1    级别: 1    角色: D/V
 验证最大递归深度、广度、实际时间、令牌数量和每次代理执行的货币成本是否由中央配置并进行版本控制。
 #9.1.2    级别: 1    角色: D/V
 验证特权或不可逆操作（例如，代码提交、财务转账）在执行前需通过可审计渠道获得明确的人为批准。
 #9.1.3    级别: 2    角色: D
 验证实时资源监控器在任何预算阈值被超出时触发断路器中断，从而停止进一步的任务扩展。
 #9.1.4    级别: 2    角色: D/V
 验证断路器事件是否已记录代理ID、触发条件和捕获的计划状态以供取证审查。
 #9.1.5    级别: 3    角色: V
 验证安全测试覆盖预算耗尽和失控计划场景，确保在无数据丢失的情况下安全停止。
 #9.1.6    级别: 3    角色: D
 验证预算策略以代码形式表达，并在CI/CD中执行，以阻止配置偏移。

---

### 9.2 工具插件沙箱机制

隔离工具交互以防止未经授权的系统访问或代码执行。

 #9.2.1    级别: 1    角色: D/V
 验证每个工具/插件是否在操作系统、容器或WASM级别的沙箱内执行，并具备最小权限的文件系统、网络和系统调用策略。
 #9.2.2    级别: 1    角色: D/V
 验证沙箱资源配额（CPU、内存、磁盘、网络出口）和执行超时是否被强制执行并记录。
 #9.2.3    级别: 2    角色: D/V
 验证工具二进制文件或描述符是否经过数字签名；在加载前验证签名。
 #9.2.4    级别: 2    角色: V
 验证沙箱遥测是否传输到SIEM；异常情况（例如，尝试的外部连接）会触发警报。
 #9.2.5    级别: 3    角色: V
 确保高风险插件在投入生产部署前经过安全审查和渗透测试。
 #9.2.6    级别: 3    角色: D/V
 验证沙箱逃逸尝试是否被自动阻止，且违规插件在调查期间被隔离。

---

### 9.3 自主循环与成本界定

检测并阻止失控的代理间递归和成本爆炸。

 #9.3.1    级别: 1    角色: D/V
 验证代理间调用是否包含运行时递减和执行的跳数限制或生存时间（TTL）。
 #9.3.2    级别: 2    角色: D
 验证代理是否维护唯一的调用图 ID，以识别自调用或循环模式。
 #9.3.3    级别: 2    角色: D/V
 验证累计的计算单元和消费计数器是否按请求链进行跟踪；超出限制将中止该链。
 #9.3.4    级别: 3    角色: V
 验证形式分析或模型检测是否证明了代理协议中不存在无界递归。
 #9.3.5    级别: 3    角色: D
 验证循环中止事件是否生成警报并反馈持续改进指标。

---

### 9.4 协议级误用防护

在代理和外部系统之间建立安全通信通道，以防止劫持或操控。

 #9.4.1    级别: 1    角色: D/V
 验证所有代理到工具和代理到代理的消息均经过身份验证（例如，双向TLS或JWT）并且端到端加密。
 #9.4.2    级别: 1    角色: D
 验证模式是否被严格校验；未知字段或格式错误的消息将被拒绝。
 #9.4.3    级别: 2    角色: D/V
 验证完整性检查（MAC或数字签名）覆盖整个消息负载，包括工具参数。
 #9.4.4    级别: 2    角色: D
 验证在协议层是否实施了重放保护（随机数或时间戳窗口）。
 #9.4.5    级别: 3    角色: V
 验证协议实现是否经过模糊测试和静态分析，以检测注入或反序列化漏洞。

---

### 9.5 代理身份与防篡改机制

确保操作可追溯，修改可检测。

 #9.5.1    级别: 1    角色: D/V
 验证每个代理实例是否拥有唯一的加密身份（密钥对或硬件根凭证）。
 #9.5.2    级别: 2    角色: D/V
 验证所有代理操作均已签名并带有时间戳；日志包含签名以实现不可否认性。
 #9.5.3    级别: 2    角色: V
 验证防篡改日志是否存储在仅追加或一次性写入的媒介中。
 #9.5.4    级别: 3    角色: D
 验证身份密钥是否按照预定的时间表和在出现妥协指示时进行轮换。
 #9.5.5    级别: 3    角色: D/V
 验证欺骗或密钥冲突尝试是否会立即触发受影响代理的隔离。

---

### 9.6 多智能体群体风险降低

通过隔离和正式安全建模来减轻集体行为风险。

 #9.6.1    级别: 1    角色: D/V
 验证在不同安全域中运行的代理是否在隔离的运行时沙箱或网络分段中执行。
 #9.6.2    级别: 3    角色: V
 确保群体行为在部署前经过模型建立并形式化验证其活性和安全性。
 #9.6.3    级别: 3    角色: D
 验证运行时监控器是否检测到新出现的不安全模式（例如，振荡、死锁）并启动纠正措施。

---

### 9.7 用户与工具身份验证/授权

为每个代理触发的操作实现强健的访问控制。

 #9.7.1    级别: 1    角色: D/V
 确保代理作为一级主体向下游系统进行身份验证，且绝不重用终端用户凭据。
 #9.7.2    级别: 2    角色: D
 验证细粒度授权策略限制代理可以调用的工具及其可以提供的参数。
 #9.7.3    级别: 2    角色: V
 验证权限检查是否在每次调用时重新评估（持续授权），而不仅仅是在会话开始时。
 #9.7.4    级别: 3    角色: D
 验证委托权限是否会自动过期，并在超时或范围更改后需要重新同意。

---

### 9.8 代理到代理的通信安全

对所有代理之间的消息进行加密和完整性保护，以防止窃听和篡改。

 #9.8.1    级别: 1    角色: D/V
 验证代理通道必须具备双向认证和完美前向保密加密（例如 TLS 1.3）。
 #9.8.2    级别: 1    角色: D
 验证消息完整性和来源在处理之前已被验证；验证失败将触发警报并丢弃消息。
 #9.8.3    级别: 2    角色: D/V
 验证通信元数据（时间戳、序列号）是否被记录，以支持取证重建。
 #9.8.4    级别: 3    角色: V
 验证形式化验证或模型检查确认协议状态机无法进入不安全状态。

---

### 9.9 意图验证与约束执行

验证代理操作是否与用户陈述的意图和系统约束相符。

 #9.9.1    级别: 1    角色: D
 验证预执行约束求解器是否根据硬编码的安全和政策规则检查提议的操作。
 #9.9.2    级别: 2    角色: D/V
 验证高影响操作（财务、破坏性、隐私敏感）是否需要发起用户的明确意图确认。
 #9.9.3    级别: 2    角色: V
 验证后置条件检查以确认已完成的操作实现了预期效果且无副作用；如有差异，则触发回滚。
 #9.9.4    级别: 3    角色: V
 验证形式化方法（例如，模型检验、定理证明）或基于属性的测试是否证明代理计划满足所有声明的约束。
 #9.9.5    级别: 3    角色: D
 验证意图不匹配或约束违规事件是否促进持续改进循环和威胁情报共享。

---

### 9.10 代理推理策略安全

安全地选择和执行包括 ReAct、链式思维（Chain-of-Thought）和思维树（Tree-of-Thoughts）方法在内的不同推理策略。

 #9.10.1    级别: 1    角色: D/V
 验证推理策略选择是否使用确定性标准（输入复杂性、任务类型、安全上下文），并且在相同的安全上下文中，相同的输入是否产生相同的策略选择。
 #9.10.2    级别: 1    角色: D/V
 验证每种推理策略（ReAct、Chain-of-Thought、Tree-of-Thoughts）是否具有针对其认知方法的专用输入验证、输出清理和执行时间限制。
 #9.10.3    级别: 2    角色: D/V
 验证推理策略转换是否记录了完整的上下文，包括输入特征、选择标准值和执行元数据，以便审计轨迹重建。
 #9.10.4    级别: 2    角色: D/V
 验证 Tree-of-Thoughts 推理是否包含分支剪枝机制，当检测到策略违规、资源限制或安全边界时终止探索。
 #9.10.5    级别: 2    角色: D/V
 验证 ReAct（推理-行动-观察）循环在每个阶段都包含验证检查点：推理步骤验证、行动授权以及观察数据清洗，确保在继续之前的安全与准确性。
 #9.10.6    级别: 3    角色: D/V
 验证推理策略的性能指标（执行时间、资源使用、输出质量）是否在指标超出配置阈值时通过自动警报进行监控。
 #9.10.7    级别: 3    角色: D/V
 验证结合多种策略的混合推理方法是否保持所有组成策略的输入验证和输出约束，且不绕过任何安全控制措施。
 #9.10.8    级别: 3    角色: D/V
 验证推理策略安全测试包括使用格式错误的输入进行模糊测试、设计用于强制策略切换的对抗性提示，以及对每种认知方法进行边界条件测试。

---

### 9.11 代理生命周期状态管理与安全

通过加密审计跟踪和定义的恢复程序，实现安全的代理初始化、状态转换和终止。

 #9.11.1    级别: 1    角色: D/V
 验证代理初始化是否包括使用硬件支持的凭据建立密码学身份，以及包含代理ID、时间戳、配置哈希和初始化参数的不可变启动审核日志。
 #9.11.2    级别: 2    角色: D/V
 验证代理状态转换是否经过密码学签名、带时间戳，并完整记录上下文，包括触发事件、之前状态哈希、新状态哈希以及执行的安全验证。
 #9.11.3    级别: 2    角色: D/V
 验证代理关闭程序包括使用加密擦除或多遍覆盖进行安全内存清除、凭证注销并通知证书颁发机构，以及生成防篡改终止证书。
 #9.11.4    级别: 3    角色: D/V
 验证代理恢复机制是否使用加密校验和（至少使用 SHA-256）来验证状态完整性，并在检测到损坏时回滚到已知的良好状态，同时配备自动警报和人工审批要求。
 #9.11.5    级别: 3    角色: D/V
 验证代理持久化机制是否使用每个代理的 AES-256 密钥加密敏感状态数据，并在可配置的计划（最长 90 天）内实施安全密钥轮换，且实现零停机部署。

---

### 9.12 工具集成安全框架

具有定义的风险评估和审批流程的动态工具加载、执行及结果验证的安全控制。

 #9.12.1    级别: 1    角色: D/V
 验证工具描述符是否包含安全元数据，指定所需的权限（读/写/执行）、风险级别（低/中/高）、资源限制（CPU、内存、网络）以及工具清单中记录的验证要求。
 #9.12.2    级别: 1    角色: D/V
 验证工具执行结果是否符合预期的模式（JSON 模式、XML 模式）和安全策略（输出清理、数据分类），并在集成前设置超时限制和错误处理程序。
 #9.12.3    级别: 2    角色: D/V
 验证工具交互日志是否包含详细的安全上下文，包括权限使用情况、数据访问模式、执行时间、资源消耗和返回代码，并采用结构化日志记录以便于 SIEM 集成。
 #9.12.4    级别: 2    角色: D/V
 验证动态工具加载机制是否使用公钥基础设施（PKI）验证数字签名，并在执行前实施带有沙箱隔离和权限验证的安全加载协议。
 #9.12.5    级别: 3    角色: D/V
 验证工具安全评估是否会自动触发新版本的评估，且包含强制审批门槛，包括静态分析、动态测试和安全团队审查，并具备有文件记录的审批标准和服务水平协议（SLA）要求。

---

#### 参考文献

MITRE ATLAS tactics ML09
Circuit-breaker research for AI agents — Zou et al., 2024
Trend Micro analysis of sandbox escapes in AI agents — Park, 2025
Auth0 guidance on human-in-the-loop authorization for agents — Martinez, 2025
Medium deep-dive on MCP & A2A protocol hijacking — ForAISec, 2025
Rapid7 fundamentals on spoofing attack prevention — 2024
Imperial College verification of swarm systems — Lomuscio et al.
NIST AI Risk Management Framework 1.0, 2023
WIRED security briefing on encryption best practices, 2024
OWASP Top 10 for LLM Applications, 2025
Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS
[How Is LLM Reasoning Distracted by Irrelevant Context?
An Analysis Using a Controlled Benchmark](https://www.arxiv.org/pdf/2505.18761)
Large Language Model Sentinel: LLM Agent for Adversarial Purification
Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents

## 10 对抗鲁棒性与隐私防御

### 控制目标

确保人工智能模型在面对规避、推断、提取或投毒攻击时保持可靠、保护隐私并具备抗滥用能力。

---

### 10.1 模型对齐与安全

防范有害或违反政策的输出。

 #10.1.1    级别: 1    角色: D/V
 验证对齐测试套件（红队提示、越狱探测、禁止内容）是否进行了版本控制，并在每次模型发布时运行。
 #10.1.2    级别: 1    角色: D
 验证拒绝和安全完成保护栏是否被执行。
 #10.1.3    级别: 2    角色: D/V
 验证自动评估器是否测量有害内容率并标记超过设定阈值的回归。
 #10.1.4    级别: 2    角色: D
 验证反越狱训练是否有文档记录且可复现。
 #10.1.5    级别: 3    角色: V
 验证正式的政策合规性证明或认证监控是否涵盖关键领域。

---

### 10.2 对抗样本加固

增强对篡改输入的抵抗力。稳健的对抗训练和基准评分是当前的最佳实践。

 #10.2.1    级别: 1    角色: D
 验证项目仓库是否包含带有可复现种子的对抗训练配置。
 #10.2.2    级别: 2    角色: D/V
 验证对抗样本检测是否在生产流水线中触发阻断警报。
 #10.2.4    级别: 3    角色: V
 验证认证的鲁棒性证明或区间界限证书是否至少涵盖了最关键的顶级类别。
 #10.2.5    级别: 3    角色: V
 验证回归测试使用自适应攻击以确认没有可测量的鲁棒性损失。

---

### 10.3 成员推断缓解

限制判断记录是否在训练数据中的能力。差分隐私和置信度分数掩蔽仍然是目前已知的最有效防御措施。

 #10.3.1    级别: 1    角色: D
 验证每次查询的熵正则化或温度缩放是否能够减少过度自信的预测。
 #10.3.2    级别: 2    角色: D
 验证训练过程中对敏感数据集采用了ε-界限差分隐私优化。
 #10.3.3    级别: 2    角色: V
 验证攻击模拟（影子模型或黑盒）在保留数据上的攻击AUC是否≤0.60。

---

### 10.4 模型反演抗性

防止重建私有属性。最近的调查强调输出截断和差分隐私保证作为实用防御措施。

 #10.4.1    级别: 1    角色: D
 确认敏感属性绝不被直接输出；在必要时，使用分段或单向变换。
 #10.4.2    级别: 1    角色: D/V
 验证查询速率限制是否限制来自同一主体的重复自适应查询。
 #10.4.3    级别: 2    角色: D
 验证模型是否经过保护隐私的噪声训练。

---

### 10.5 模型提取防御

检测并阻止未经授权的克隆。建议采用水印技术和查询模式分析。

 #10.5.1    级别: 1    角色: D
 验证推理网关是否强制执行针对模型记忆阈值调整的全局和每个 API 密钥的速率限制。
 #10.5.2    级别: 2    角色: D/V
 验证查询熵和输入复数性统计是否为自动提取检测器提供数据。
 #10.5.3    级别: 2    角色: V
 验证脆弱或概率水印是否可以在对疑似克隆进行不超过 1,000 次查询时，以 p < 0.01 证明。
 #10.5.4    级别: 3    角色: D
 验证水印密钥和触发集合是否存储在硬件安全模块中，并且每年轮换。
 #10.5.5    级别: 3    角色: V
 验证提取警报事件是否包含违规查询，并且已与事件响应剧本集成。

---

### 10.6 推理时的中毒数据检测

识别并中和带有后门或被投毒的输入。

 #10.6.1    级别: 1    角色: D
 验证输入在模型推理前通过异常检测器（例如，STRIP，一致性评分）。
 #10.6.2    级别: 1    角色: V
 验证检测器阈值是否在干净/中毒验证集上调优，以实现低于5%的误报率。
 #10.6.3    级别: 2    角色: D
 验证被标记为中毒的输入是否会触发软阻断和人工审核流程。
 #10.6.4    级别: 2    角色: V
 验证检测器是否通过自适应、无触发器的后门攻击进行了压力测试。
 #10.6.5    级别: 3    角色: D
 验证检测效能指标是否已记录，并定期使用最新的威胁情报重新评估。

---

### 10.7 动态安全策略适应

基于威胁情报和行为分析的实时安全策略更新。

 #10.7.1    级别: 1    角色: D/V
 验证安全策略能够在不重启代理的情况下动态更新，同时保持策略版本的完整性。
 #10.7.2    级别: 2    角色: D/V
 验证策略更新是否由授权的安全人员进行加密签名，并在应用之前进行验证。
 #10.7.3    级别: 2    角色: D/V
 验证动态策略更改是否记录了完整的审计追踪，包括理由、审批链和回滚程序。
 #10.7.4    级别: 3    角色: D/V
 验证自适应安全机制是否根据风险环境和行为模式调整威胁检测的灵敏度。
 #10.7.5    级别: 3    角色: D/V
 验证策略调整决策是否具有可解释性，并包含供安全团队审查的证据轨迹。

---

### 10.8 基于反射的安全分析

通过代理自我反思和元认知分析进行安全验证。

 #10.8.1    级别: 1    角色: D/V
 验证代理反思机制是否包含以安全为重点的决策和行动自我评估。
 #10.8.2    级别: 2    角色: D/V
 验证反射输出是否经过验证，以防止通过对抗性输入操纵自我评估机制。
 #10.8.3    级别: 2    角色: D/V
 验证元认知安全分析是否能识别代理推理过程中的潜在偏见、操控或妥协。
 #10.8.4    级别: 3    角色: D/V
 验证基于反射的安全警告是否触发了增强监控和潜在的人为干预流程。
 #10.8.5    级别: 3    角色: D/V
 验证从安全反思中持续学习能够提升威胁检测能力，同时不降低合法功能的性能。

---

### 10.9 演化与自我改进安全

具备自我修改和进化能力的代理系统的安全控制措施。

 #10.9.1    级别: 1    角色: D/V
 验证自我修改能力是否仅限于具有正式验证边界的指定安全区域。
 #10.9.2    级别: 2    角色: D/V
 确保在实施演进提案之前进行安全影响评估。
 #10.9.3    级别: 2    角色: D/V
 验证自我改进机制包括带有完整性验证的回滚功能。
 #10.9.4    级别: 3    角色: D/V
 验证元学习安全性是否防止了对改进算法的对抗性操纵。
 #10.9.5    级别: 3    角色: D/V
 验证递归自我改进受限于形式安全约束，并提供收敛的数学证明。

---

#### 参考文献

MITRE ATLAS adversary tactics for ML
NIST AI Risk Management Framework 1.0, 2023
OWASP Top 10 for LLM Applications, 2025
Adversarial Training: A Survey — Zhao et al., 2024
RobustBench adversarial-robustness benchmark
Membership-Inference & Model-Inversion Risk Survey, 2025
PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023
Model-Inversion Attacks & Defenses Survey — AI Review, 2025
Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024
Fragile Model Watermarking Survey — 2025
Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025
BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024

## 11 隐私保护与个人数据管理

### 控制目标

在整个人工智能生命周期——数据收集、训练、推理和事件响应过程中，保持严格的隐私保障，确保个人数据仅在明确同意、最小必要范围、可验证删除和正式隐私保证的前提下处理。

---

### 11.1 匿名化与数据最小化

 #11.1.1    级别: 1    角色: D/V
 验证直接标识符和准标识符是否已被删除或哈希处理。
 #11.1.2    级别: 2    角色: D/V
 验证自动审计是否测量 k-匿名性/l-多样性，并在阈值低于策略时发出警报。
 #11.1.3    级别: 2    角色: V
 验证模型特征重要性报告，确保标识符泄露的互信息不超过 ε = 0.01。
 #11.1.4    级别: 3    角色: V
 验证形式证明或合成数据认证，即使在关联攻击下，重新识别风险也 ≤ 0.05。

---

### 11.2 被遗忘权与删除执行

 #11.2.1    级别: 1    角色: D/V
 验证数据主体删除请求是否在少于30天的服务水平协议内传播到原始数据集、检查点、嵌入、日志和备份。
 #11.2.2    级别: 2    角色: D
 验证“机器遗忘”程序是否通过经过认证的遗忘算法进行物理重新训练或近似删除。
 #11.2.3    级别: 2    角色: V
 验证影子模型评估证明遗忘记录在取消学习后对输出的影响低于1%。
 #11.2.4    级别: 3    角色: V
 验证删除事件是否被不可变地记录并且可供监管机构审计。

---

### 11.3 差分隐私保护措施

 #11.3.1    级别: 2    角色: D/V
 验证隐私损失核算仪表板在累计 ε 超过策略阈值时发出警报。
 #11.3.2    级别: 2    角色: V
 验证黑盒隐私审计是否能在宣称值的10%范围内估计ε̂。
 #11.3.3    级别: 3    角色: V
 验证形式证明涵盖所有训练后微调和嵌入。

---

### 11.4 目的限制与范围蔓延保护

 #11.4.1    级别: 1    角色: D
 验证每个数据集和模型检查点是否都带有与原始同意一致的机器可读目的标签。
 #11.4.2    级别: 1    角色: D/V
 验证运行时监控器是否能检测到与声明目的不一致的查询并触发软拒绝。
 #11.4.3    级别: 3    角色: D
 验证代码即政策门控是否阻止在未经数据保护影响评估（DPIA）审查的情况下，将模型重新部署到新领域。
 #11.4.4    级别: 3    角色: V
 验证正式的可追溯性证明，确保每个个人数据生命周期均在获得同意的范围内。

---

### 11.5 同意管理与合法依据追踪

 #11.5.1    级别: 1    角色: D/V
 验证同意管理平台（CMP）是否记录每个数据主体的选择加入状态、目的和保留期限。
 #11.5.2    级别: 2    角色: D
 验证API是否公开了同意令牌；模型在推理前必须验证令牌范围。
 #11.5.3    级别: 2    角色: D/V
 验证被拒绝或撤回的同意是否在24小时内停止处理流程。

---

### 11.6 带有隐私控制的联邦学习

 #11.6.1    级别: 1    角色: D
 验证客户端更新在聚合前采用了本地差分隐私噪声添加。
 #11.6.2    级别: 2    角色: D/V
 验证训练指标是否具有差分隐私，且绝不泄露单个客户的损失。
 #11.6.3    级别: 2    角色: V
 验证是否启用了抗投毒聚合（例如，Krum/修剪均值）。
 #11.6.4    级别: 3    角色: V
 验证形式证明显示整体 ε 预算的效用损失小于 5。

---

#### 参考文献

GDPR & AI Compliance Best Practices
EU Parliament Study on GDPR & AI, 2020
ISO 31700-1:2023 — Privacy by Design for Consumer Products
NIST Privacy Framework 1.1 (2025 Draft)
Machine Unlearning: Right-to-Be-Forgotten Techniques
A Survey of Machine Unlearning, 2024
Auditing DP-SGD — ArXiv 2024
DP-SGD Explained — PyTorch Blog
Purpose-Limitation for AI — IJLIT 2025
Data-Protection Considerations for AI — URM Consulting
Top Consent-Management Platforms, 2025
Secure Aggregation in DP Federated Learning — ArXiv 2024

## C12 监控、日志记录与异常检测

### 控制目标

本节提供了实现对模型及其他人工智能组件所看到内容、所执行操作和所返回结果的实时及取证可见性的要求，以便能够检测、分类和学习威胁。

### C12.1 请求与响应日志记录

 #12.1.1    级别: 1    角色: D/V
 验证所有用户提示和模型响应是否带有适当的元数据（例如时间戳、用户ID、会话ID、模型版本）进行日志记录。
 #12.1.2    级别: 1    角色: D/V
 验证日志是否存储在安全的、受访问控制的存储库中，并具有适当的保留策略和备份程序。
 #12.1.3    级别: 1    角色: D/V
 验证日志存储系统是否实现了静态加密和传输加密，以保护日志中包含的敏感信息。
 #12.1.4    级别: 1    角色: D/V
 验证提示和输出中的敏感数据在记录之前是否被自动编辑或遮蔽，并且支持针对个人身份信息（PII）、凭据和专有信息的可配置编辑规则。
 #12.1.5    级别: 2    角色: D/V
 验证政策决策和安全过滤操作是否有足够的详细日志记录，以支持内容审核系统的审计和调试。
 #12.1.6    级别: 2    角色: D/V
 验证日志完整性是否通过例如加密签名或只写存储得到保护。

---

### C12.2 滥用检测与警报

 #12.2.1    级别: 1    角色: D/V
 验证系统是否使用基于特征的检测方法，识别并警报已知的越狱模式、提示注入尝试和对抗性输入。
 #12.2.2    级别: 1    角色: D/V
 验证系统是否通过标准日志格式和协议与现有的安全信息和事件管理（SIEM）平台集成。
 #12.2.3    级别: 2    角色: D/V
 验证丰富的安全事件是否包含特定于人工智能的上下文信息，如模型标识符、置信度评分和安全过滤决策。
 #12.2.4    级别: 2    角色: D/V
 验证行为异常检测是否能识别异常的对话模式、过多的重试尝试或系统性的探测行为。
 #12.2.5    级别: 2    角色: D/V
 验证实时警报机制在检测到潜在的策略违规或攻击尝试时，是否通知安全团队。
 #12.2.6    级别: 2    角色: D/V
 验证是否包含自定义规则以检测特定于AI的威胁模式，包括协调的越狱尝试、提示注入活动和模型提取攻击。
 #12.2.7    级别: 3    角色: D/V
 验证自动化事件响应工作流能够隔离受损模型、阻止恶意用户并升级关键安全事件。

---

### C12.3 模型漂移检测

 #12.3.1    级别: 1    角色: D/V
 验证系统是否跟踪基本性能指标，如准确率、置信度分数、延迟和错误率，涵盖不同模型版本和时间段。
 #12.3.2    级别: 2    角色: D/V
 验证当性能指标超过预定义的降级阈值或与基准显著偏离时，自动警报是否触发。
 #12.3.3    级别: 2    角色: D/V
 验证幻觉检测监测器是否能够识别并标记模型输出中包含事实错误、不一致或虚构信息的实例。

---

### C12.4 性能与行为遥测

 #12.4.1    级别: 1    角色: D/V
 验证操作指标，包括请求延迟、令牌消耗、内存使用和吞吐量，是否持续收集和监控。
 #12.4.2    级别: 1    角色: D/V
 验证成功率和失败率是否被跟踪，并对错误类型及其根本原因进行分类。
 #12.4.3    级别: 2    角色: D/V
 验证资源利用率监控是否包含 GPU/CPU 使用率、内存消耗和存储需求，并在阈值超出时发出警报。

---

### C12.5 AI事件响应规划与执行

 #12.5.1    级别: 1    角色: D/V
 验证事件响应计划是否专门针对与人工智能相关的安全事件，包括模型泄露、数据投毒和对抗性攻击。
 #12.5.2    级别: 2    角色: D/V
 确认事件响应团队能够访问针对人工智能的取证工具和具备相应专业知识，以调查模型行为和攻击向量。
 #12.5.3    级别: 3    角色: D/V
 验证事故后分析是否包括模型再训练的考虑、安全过滤器的更新以及将经验教训整合到安全控制中。

---

### C12.5 AI性能退化检测

监控并检测 AI 模型性能和质量随时间的退化。

 #12.5.1    级别: 1    角色: D/V
 确保模型的准确率、精确率、召回率和F1分数得到持续监控，并与基线阈值进行比较。
 #12.5.2    级别: 1    角色: D/V
 验证数据漂移检测是否监控可能影响模型性能的输入分布变化。
 #12.5.3    级别: 2    角色: D/V
 验证概念漂移检测是否能够识别输入与预期输出之间关系的变化。
 #12.5.4    级别: 2    角色: D/V
 验证性能下降是否触发自动警报并启动模型重新训练或更换工作流程。
 #12.5.5    级别: 3    角色: V
 验证退化根本原因分析是否将性能下降与数据变化、基础设施问题或外部因素相关联。

---

### C12.6 有向无环图可视化与工作流安全

保护工作流可视化系统免受信息泄露和篡改攻击。

 #12.6.1    级别: 1    角色: D/V
 验证DAG可视化数据在存储或传输之前已进行清理，以移除敏感信息。
 #12.6.2    级别: 1    角色: D/V
 验证工作流可视化访问控制，确保只有授权用户才能查看代理决策路径和推理轨迹。
 #12.6.3    级别: 2    角色: D/V
 验证DAG数据完整性是否通过加密签名和防篡改存储机制得到保护。
 #12.6.4    级别: 2    角色: D/V
 验证工作流可视化系统是否实施了输入验证，以防止通过精心构造的节点或边数据进行的注入攻击。
 #12.6.5    级别: 3    角色: D/V
 验证实时DAG更新是否经过速率限制和验证，以防止对可视化系统的拒绝服务攻击。

---

### C12.7 主动安全行为监控

通过主动代理行为分析实现安全威胁的检测和预防。

 #12.7.1    级别: 1    角色: D/V
 确保带有风险评估集成的主动代理行为在执行前经过安全验证。
 #12.7.2    级别: 2    角色: D/V
 验证自治行动触发因素包括安全上下文评估和威胁态势评估。
 #12.7.3    级别: 2    角色: D/V
 验证主动行为模式是否已被分析，以评估潜在的安全影响和意外后果。
 #12.7.4    级别: 3    角色: D/V
 验证安全关键的主动措施需要明确的审批链和审计追踪。
 #12.7.5    级别: 3    角色: D/V
 验证行为异常检测是否能够识别主动代理模式中的偏差，这些偏差可能表明存在被攻破的情况。

---

### 参考文献

NIST AI Risk Management Framework 1.0 - Manage 4.1 and 4.3
ISO/IEC 42001:2023 — AI Management Systems Requirements - Annex B 6.2.6
EU AI Act — Article 12, 13, 16 and 19 on Logging and Record-keeping

## C13 人类监督、问责与治理

### 控制目标

本章提供了保持人工监督和明确责任链的要求，确保在整个人工智能生命周期中实现可解释性、透明性和伦理管理。

---

### C13.1 终止开关与覆盖机制

当观察到人工智能系统出现不安全行为时，提供关闭或回滚路径。

 #13.1.1    级别: 1    角色: D/V
 验证是否存在手动紧急停止机制，以立即停止AI模型推理和输出。
 #13.1.2    级别: 1    角色: D
 验证覆盖控制仅对授权人员可访问。
 #13.1.3    级别: 3    角色: D/V
 验证回滚程序是否能够恢复到先前的模型版本或安全模式操作。
 #13.1.4    级别: 3    角色: V
 验证覆盖机制是否定期进行测试。

---

### C13.2 人工干预决策检查点

当风险超过预定义阈值时，需要人工审批。

 #13.2.1    级别: 1    角色: D/V
 验证高风险人工智能决策在执行前需获得明确的人类批准。
 #13.2.2    级别: 1    角色: D
 验证风险阈值是否已明确定义并能自动触发人工审查工作流程。
 #13.2.3    级别: 2    角色: D
 确认在无法在规定时间内获得人工批准时，时间敏感的决策具有备用程序。
 #13.2.4    级别: 3    角色: D/V
 验证升级程序是否为不同的决策类型或风险类别定义了明确的权限级别（如适用）。

---

### C13.3 责任链与可审计性

记录操作员操作和模型决策。

 #13.3.1    级别: 1    角色: D/V
 验证所有人工智能系统的决策和人工干预均已记录时间戳、用户身份及决策理由。
 #13.3.2    级别: 2    角色: D
 验证审计日志不能被篡改，并包含完整性验证机制。

---

### C13.4 可解释人工智能技术

表面特征重要性、反事实和局部解释。

 #13.4.1    级别: 1    角色: D/V
 验证 AI 系统是否以人类可读的格式提供其决策的基本解释。
 #13.4.2    级别: 2    角色: V
 通过人工评估研究和指标验证解释质量。
 #13.4.3    级别: 3    角色: D/V
 验证关键决策是否提供了特征重要性得分或归因方法（如 SHAP、LIME 等）。
 #13.4.4    级别: 3    角色: V
 验证反事实解释是否展示了如何修改输入以改变结果（如果适用于使用案例和领域）。

---

### C13.5 模型卡与使用披露

维护模型卡以记录预期用途、性能指标和伦理考量。

 #13.5.1    级别: 1    角色: D
 验证模型卡是否记录了预期使用场景、限制和已知的故障模式。
 #13.5.2    级别: 1    角色: D/V
 验证是否披露了不同适用用例的性能指标。
 #13.5.3    级别: 2    角色: D
 验证伦理考虑、偏见评估、公平性评估、训练数据特征以及已知训练数据限制是否有文档记录并定期更新。
 #13.5.4    级别: 2    角色: D/V
 验证模型卡是否经过版本控制，并在整个模型生命周期内进行维护和变更跟踪。

---

### C13.6 不确定性量化

在响应中传播置信度得分或熵度量。

 #13.6.1    级别: 1    角色: D
 验证人工智能系统是否在其输出中提供置信度分数或不确定性度量。
 #13.6.2    级别: 2    角色: D/V
 验证不确定性阈值是否触发额外的人类审核或替代决策路径。
 #13.6.3    级别: 2    角色: V
 验证不确定性量化方法是否经过校准并针对真实数据进行了验证。
 #13.6.4    级别: 3    角色: D/V
 验证不确定性传播在多步骤 AI 工作流程中得以保持。

---

### C13.7 面向用户的透明度报告

定期披露事件、偏移和数据使用情况。

 #13.7.1    级别: 1    角色: D/V
 确保数据使用政策和用户同意管理实践清晰地传达给相关利益方。
 #13.7.2    级别: 2    角色: D/V
 核实是否已进行人工智能影响评估，并确认结果已包含在报告中。
 #13.7.3    级别: 2    角色: D/V
 验证定期发布的透明度报告是否合理详细地披露了人工智能事件和运营指标。

#### 参考文献

EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
ISO/IEC 42001:2023 — AI Management Systems Requirements
NIST AI Risk Management Framework 1.0
NIST SP 800-53 Revision 5 — Security and Privacy Controls
A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)
Model Cards for Model Reporting (Mitchell et al., 2018)
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)
ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods
IEEE 7001-2021 — Transparency of Autonomous Systems
GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)
Human Oversight under Article 14 of the EU AI Act (Fink, 2025)

## 附录 A：术语表

本综合术语表提供了AISVS中使用的关键人工智能、机器学习和安全术语的定义，以确保清晰和共同理解。

对抗样本：一种故意设计的输入，旨在导致人工智能模型出现错误，通常通过添加人类难以察觉的微小扰动实现。
​
对抗鲁棒性——在人工智能中，对抗鲁棒性指的是模型维持其性能并抵抗那些经过故意设计、具有恶意的输入以导致错误的能力。
​
代理——AI代理是利用人工智能代表用户追求目标和完成任务的软件系统。它们具备推理、规划和记忆能力，并拥有一定程度的自主性，以做出决策、学习和适应。
​
自主智能体：能够以一定程度的自主性运作以实现目标的人工智能系统，通常在没有直接人为干预的情况下做出决策并采取行动。
​
基于属性的访问控制（ABAC）：一种访问控制范式，其中授权决策基于用户、资源、操作和环境的属性，在查询时进行评估。
​
后门攻击：一种数据投毒攻击，模型被训练成对特定触发器做出特定响应，而在其他情况下表现正常。
​
偏差：AI模型输出中的系统性错误，可能导致对特定群体或特定情境的不公平或歧视性结果。
​
偏见利用：一种攻击技术，利用人工智能模型中已知的偏见来操控输出或结果。
​
Cedar：亚马逊用于实现人工智能系统基于属性的访问控制（ABAC）的细粒度权限策略语言和引擎。
​
思维链：一种通过在生成最终答案之前生成中间推理步骤来改进语言模型推理能力的技术。
​
断路器：当超过特定风险阈值时，自动停止 AI 系统运行的机制。
​
数据泄露：通过人工智能模型输出或行为无意中暴露敏感信息。
​
数据投毒：故意破坏训练数据以破坏模型完整性，通常用于植入后门或降低性能。
​
差分隐私——差分隐私是一种数学严谨的框架，用于在保护个体数据主体隐私的同时发布关于数据集的统计信息。它使数据持有者能够共享群体的总体模式，同时限制泄露关于特定个体的信息。
​
嵌入：数据（文本、图像等）的密集向量表示，在高维空间中捕捉语义意义。
​
可解释性 – 人工智能中的可解释性是指AI系统能够为其决策和预测提供人类可理解的理由，从而揭示其内部工作机制的能力。
​
可解释人工智能（XAI）：设计用于通过各种技术和框架，为其决策和行为提供人类可理解解释的人工智能系统。
​
联邦学习：一种机器学习方法，其中模型在多个持有本地数据样本的分散设备上进行训练，而不交换数据本身。
​
保护措施：为防止人工智能系统产出有害、带偏见或其他不良输出而实施的约束。
​
幻觉——AI幻觉指的是AI模型生成不基于其训练数据或事实现实的错误或误导性信息的现象。
​
人为参与循环（HITL）：设计为在关键决策点需要人工监督、验证或干预的系统。
​
基础设施即代码（IaC）：通过代码管理和配置基础设施，取代手动操作，实现安全扫描和一致的部署。
​
越狱：用于规避人工智能系统中安全防护措施的技术，特别是在大型语言模型中，以生成被禁止的内容。
​
最小权限原则：授予用户和进程仅限于最低必要访问权限的安全原则。
​
LIME（局部可解释模型无关解释）：一种通过用可解释模型在局部近似任何机器学习分类器的预测结果的技术。
​
成员推断攻击：一种旨在确定特定数据点是否被用来训练机器学习模型的攻击。
​
MITRE ATLAS：人工智能系统的对抗威胁格局；针对人工智能系统的对抗策略和技术的知识库。
​
模型卡——模型卡是一种文档，提供有关人工智能模型的性能、限制、预期用途和伦理考虑的标准化信息，以促进透明度和负责任的人工智能开发。
​
模型提取：一种攻击方式，攻击者通过反复查询目标模型，未经授权创建一个功能相似的副本。
​
模型反演：一种通过分析模型输出尝试重建训练数据的攻击手段。
​
模型生命周期管理——AI模型生命周期管理是监督AI模型存在的所有阶段的过程，包括其设计、开发、部署、监控、维护以及最终的退役，以确保其保持有效并与目标一致。
​
模型中毒：在训练过程中直接向模型引入漏洞或后门。
​
模型盗用/窃取：通过反复查询提取专有模型的副本或近似版本。
​
多智能体系统：由多个相互作用的人工智能代理组成的系统，每个代理可能具有不同的能力和目标。
​
OPA（开放策略代理）：一个开源的策略引擎，能够实现跨堆栈的统一策略执行。
​
隐私保护机器学习（PPML）：在保护训练数据隐私的同时，训练和部署机器学习模型的技术和方法。
​
提示注入：一种攻击手段，恶意指令被嵌入输入中以覆盖模型的预期行为。
​
RAG（检索增强生成）：一种通过在生成响应之前从外部知识源检索相关信息来增强大规模语言模型的技术。
​
红队演练：通过模拟对抗性攻击来主动测试人工智能系统，以识别其漏洞的做法。
​
SBOM（软件物料清单）：一份正式记录，包含构建软件或 AI 模型中使用的各种组件的详细信息及其供应链关系。
​
SHAP（Shapley加性解释）：一种博弈论方法，通过计算每个特征对预测结果的贡献，来解释任何机器学习模型的输出。
​
供应链攻击：通过针对其供应链中安全性较低的元素，如第三方库、数据集或预训练模型，来破坏系统。
​
迁移学习：一种技术，即将为一个任务开发的模型作为第二个任务模型的起点重复使用。
​
向量数据库：一种专门设计用于存储高维向量（嵌入）并执行高效相似性搜索的数据库。
​
漏洞扫描：自动化工具，用于识别软件组件中已知的安全漏洞，包括人工智能框架及其依赖项。
​
水印技术：在人工智能生成内容中嵌入不可察觉的标记，以追踪其来源或检测人工智能生成。
​
零日漏洞：一种之前未知的漏洞，攻击者可以在开发人员创建和部署补丁之前利用该漏洞。

## 附录 B: 参考文献

### TODO

## 附录C：人工智能安全治理与文档

### 目标

本附录提供了建立组织结构、政策和流程的基础性要求，以在整个系统生命周期内管理人工智能安全。

---

### AC.1 人工智能风险管理框架采纳

提供一个正式框架，以识别、评估和缓解贯穿系统生命周期的人工智能特有风险。

 #AC.1.1    级别: 1    角色: D/V
 验证是否有专门针对人工智能的风险评估方法论的文档记录并实施。
 #AC.1.2    级别: 2    角色: D
 确保在人工智能生命周期的关键节点以及重大变更之前进行风险评估。
 #AC.1.3    级别: 3    角色: D/V
 验证风险管理框架是否符合既定标准（例如，NIST AI RMF）。

---

### AC.2 人工智能安全政策与程序

定义并执行组织标准，以确保人工智能的安全开发、部署和运行。

 #AC.2.1    级别: 1    角色: D/V
 验证已存在的记录的人工智能安全策略。
 #AC.2.2    级别: 2    角色: D
 确认策略至少每年审查和更新一次，并在重大威胁环境变化后进行更新。
 #AC.2.3    级别: 3    角色: D/V
 验证政策是否涵盖所有AISVS类别及适用的监管要求。

---

### AC.3 AI 安全的角色与职责

在整个组织内建立明确的人工智能安全责任体系。

 #AC.3.1    级别: 1    角色: D/V
 验证人工智能安全角色和职责是否有文档记录。
 #AC.3.2    级别: 2    角色: D
 确认相关人员具备适当的安全专业知识。
 #AC.3.3    级别: 3    角色: D/V
 确认已为高风险 AI 系统建立了 AI 伦理委员会或治理委员会。

---

### AC.4 伦理人工智能指南执行

确保人工智能系统按照既定的伦理原则运行。

 #AC.4.1    级别: 1    角色: D/V
 验证是否存在AI开发和部署的伦理指南。
 #AC.4.2    级别: 2    角色: D
 验证是否已建立机制以检测和报告伦理违规行为。
 #AC.4.3    级别: 3    角色: D/V
 确保对已部署的人工智能系统定期进行伦理审查。

---

### AC.5 人工智能监管合规监测

保持对不断变化的人工智能法规的意识并遵守相关规定。

 #AC.5.1    级别: 1    角色: D/V
 验证是否存在识别适用的人工智能法规的流程。
 #AC.5.2    级别: 2    角色: D
 确认已评估所有监管要求的合规情况。
 #AC.5.3    级别: 3    角色: D/V
 确保监管变化能够及时触发对人工智能系统的审查和更新。

### AC.6 训练数据治理、文档编制及流程

 #1.1.2    级别: 1    角色: D/V
 确保仅允许经过质量、代表性、伦理来源和许可合规性审核的数据集，从而降低中毒风险、内嵌偏见和知识产权侵权的风险。
 #1.1.5    级别: 2    角色: D/V
 通过审核人员交叉检查或共识，确保标签/注释质量。
 #1.1.6    级别: 2    角色: D/V
 确认针对重要训练数据集维护“数据卡”或“数据集说明书”，详细说明其特征、动机、组成、收集过程、预处理以及推荐/不推荐的使用方式。
 #1.3.2    级别: 2    角色: D/V
 验证已识别的偏差是否通过文档化的策略得到缓解，例如重新平衡、有针对性的数据增强、算法调整（例如，预处理、处理中、后处理技术）或重新加权，并评估缓解措施对公平性和整体模型性能的影响。
 #1.3.3    级别: 2    角色: D/V
 验证是否已评估并记录训练后公平性指标。
 #1.3.4    级别: 3    角色: D/V
 验证生命周期偏差管理策略是否分配了负责人和审查频率。
 #1.4.1    级别: 2    角色: D/V
 通过明确的指导方针、审核员交叉核查、一致性机制（例如监测标注者间的一致性）以及解决分歧的定义流程，确保标注/注释质量。
 #1.4.4    级别: 3    角色: D/V
 确保对安全性、保安性或公平性至关重要的标签（例如，识别有害内容、关键医疗发现）进行强制性的独立双重审查或等效的严格验证。
 #1.4.6    级别: 2    角色: D/V
 确保标签指南和说明是全面的、版本受控的且经过同行评审。
 #1.4.6    级别: 2    角色: D/V
 验证标签的数据模式是否明确定义并进行版本控制。
 #1.3.1    级别: 1    角色: D/V
 验证数据集是否对代表性不平衡和潜在偏见进行了分析，涵盖法律保护属性（例如，种族、性别、年龄）以及与模型应用领域相关的其他伦理敏感特征（例如，社会经济状态、地理位置）。
 #1.5.3    级别: 2    角色: V
 验证领域专家的手动抽查覆盖了统计学上显著的样本（例如，≥1%或1000个样本，以较大者为准，或根据风险评估确定），以识别自动化未发现的细微质量问题。
 #1.8.4    级别: 2    角色: D/V
 验证外包或众包标注工作流程是否包含技术/程序上的保障措施，以确保数据的机密性、完整性、标签质量，并防止数据泄露。
 #1.5.4    级别: 2    角色: D/V
 验证修复步骤是否已附加到溯源记录。
 #1.6.2    级别: 2    角色: D/V
 验证被标记的样本在训练前会触发人工审核。
 #1.6.3    级别: 2    角色: V
 验证结果是否用于丰富模型的安全档案并反馈持续的威胁情报。
 #1.6.4    级别: 3    角色: D/V
 验证检测逻辑是否已通过新的威胁情报进行刷新。
 #1.6.5    级别: 3    角色: D/V
 验证在线学习管道是否监控分布漂移。
 #1.7.1    级别: 1    角色: D/V
 验证训练数据删除工作流程是否清除主数据和派生数据，并评估对模型的影响，且对受影响的模型进行评估，如有必要，通过重新训练或重新校准等方式加以处理。
 #1.7.2    级别: 2    角色: D
 验证是否已建立机制以跟踪和尊重用户同意（及撤回）的范围和状态，用于训练的数据在纳入新的训练过程或重大模型更新之前，确保同意已被验证。
 #1.7.3    级别: 2    角色: V
 确保工作流程每年进行测试并记录。
 #1.8.1    级别: 2    角色: D/V
 确认第三方数据供应商，包括预训练模型提供商和外部数据集，在其数据或模型被整合之前，已经经过安全、隐私、伦理来源和数据质量的尽职调查。
 #1.8.2    级别: 1    角色: D
 验证外部传输是否使用TLS/身份验证和完整性校验。
 #1.8.3    级别: 2    角色: D/V
 确认高风险数据源（例如，来源不明的开源数据集、未经审核的供应商）在用于敏感应用之前，接受加强审查，例如沙箱分析、全面的质量/偏差检查和针对性的中毒检测。
 #1.8.4    级别: 3    角色: D/V
 确保对从第三方获得的预训练模型进行评估，内容包括内嵌偏见、潜在后门、架构完整性以及其原始训练数据的来源，然后再进行微调或部署。
 #1.5.3    级别: 2    角色: D/V
 验证如果使用对抗训练，是否对抗性数据集的生成、管理和版本控制都有文档记录和管理。
 #1.5.3    级别: 3    角色: D/V
 验证对抗鲁棒性训练对模型性能（针对干净输入和对抗输入）及公平性指标的影响是否进行了评估、记录和监控。
 #1.5.4    级别: 3    角色: D/V
 验证对抗训练和鲁棒性策略是否定期审查和更新，以应对不断演变的对抗攻击技术。
 #1.4.2    级别: 2    角色: D/V
 验证失败的数据集是否被隔离并附有审计追踪。
 #1.4.3    级别: 2    角色: D/V
 验证质量门控是否阻止低于标准的数据集，除非获得例外批准。
 #1.11.2    级别: 2    角色: D/V
 确保生成过程、参数及合成数据的预期用途均有文档记录。
 #1.11.3    级别: 2    角色: D/V
 在用于训练之前，验证合成数据是否经过偏差、隐私泄露和表现问题的风险评估。
 #1.12.3    级别: 2    角色: D/V
 验证是否针对可疑访问事件生成警报并及时进行调查。
 #1.13.1    级别: 1    角色: D/V
 验证是否为所有训练数据集定义了明确的保留期限。
 #1.13.2    级别: 2    角色: D/V
 验证数据集在其生命周期结束时是否自动过期、删除或审查以决定是否删除。
 #1.13.3    级别: 2    角色: D/V
 验证保留和删除操作是否被记录和可审计。
 #1.14.1    级别: 2    角色: D/V
 验证所有数据集的数据驻留和跨境传输要求是否已被识别并强制执行。
 #1.14.2    级别: 2    角色: D/V
 验证是否识别并处理了特定行业的法规（例如，医疗保健、金融）中的数据处理要求。
 #1.14.3    级别: 2    角色: D/V
 确认符合相关隐私法律（例如 GDPR、CCPA）的情况已被记录并定期审查。
 #1.16.1    级别: 2    角色: D/V
 验证是否存在回应数据主体关于访问、更正、限制或反对请求的机制。
 #1.16.2    级别: 2    角色: D/V
 验证请求是否在法律规定的时间范围内被记录、跟踪和完成。
 #1.16.3    级别: 2    角色: D/V
 验证数据主体权利流程是否定期进行测试和审查以确保其有效性。
 #1.17.1    级别: 2    角色: D/V
 在更新或替换数据集版本之前，验证是否进行了影响分析，涵盖模型性能、公平性和合规性。
 #1.17.2    级别: 2    角色: D/V
 验证影响分析的结果是否已被相关利益相关者记录并审查。
 #1.17.3    级别: 2    角色: D/V
 确认存在回滚计划，以防新版本引入不可接受的风险或回归。
 #1.18.1    级别: 2    角色: D/V
 确认所有参与数据标注的人员均经过背景审查并接受了数据安全与隐私培训。
 #1.18.2    级别: 2    角色: D/V
 确认所有标注人员签署保密和不披露协议。
 #1.18.3    级别: 2    角色: D/V
 验证注释平台是否执行访问控制并监控内部威胁。

#### 参考文献

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
EU Artificial Intelligence Act — Regulation (EU) 2024/1689
ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods

## 附录D：人工智能辅助安全编码治理与验证

### 目标

本章节定义了在软件开发过程中安全有效使用AI辅助编码工具的基线组织控制，确保在软件开发生命周期（SDLC）中实现安全性和可追溯性。

---

### AD.1 人工智能辅助的安全编码工作流程

将 AI 工具集成到组织的安全软件开发生命周期 (SSDLC) 中，同时不削弱现有的安全防护措施。

 #AD.1.1    级别: 1    角色: D/V
 验证已记录的工作流程是否描述了何时以及如何使用人工智能工具生成、重构或审查代码。
 #AD.1.2    级别: 2    角色: D
 验证工作流程是否对应每个SSDLC阶段（设计、实现、代码审查、测试、部署）。
 #AD.1.3    级别: 3    角色: D/V
 验证是否对AI生成的代码收集了度量指标（例如漏洞密度、平均检测时间），并将其与仅有人类的基线进行比较。

---

### AD.2 AI 工具资格认证与威胁建模

确保在采用人工智能编码工具之前评估其安全能力、风险和供应链影响。

 #AD.2.1    级别: 1    角色: D/V
 验证每个 AI 工具的威胁模型是否识别了滥用、模型反演、数据泄漏和依赖链风险。
 #AD.2.2    级别: 2    角色: D
 验证工具评估是否包括对任何本地组件的静态/动态分析以及对SaaS端点（TLS、身份验证/授权、日志记录）的评估。
 #AD.2.3    级别: 3    角色: D/V
 确认评估遵循公认的框架，并在主要版本更改后重新执行。

---

### AD.3 安全提示与上下文管理

在构建AI模型的提示或上下文时，防止泄露机密信息、专有代码和个人数据。

 #AD.3.1    级别: 1    角色: D/V
 验证书面指导是否禁止在提示中发送秘密、凭证或机密数据。
 #AD.3.2    级别: 2    角色: D
 验证技术控制（客户端屏蔽，批准的上下文过滤器）是否自动剥离敏感信息。
 #AD.3.3    级别: 3    角色: D/V
 验证提示和响应是否经过分词处理，在传输和静态时均已加密，并且保留期限符合数据分类政策。

---

### AD.4 AI生成代码的验证

在代码合并或部署之前检测并修复由人工智能输出引入的漏洞。

 #AD.4.1    级别: 1    角色: D/V
 确保 AI 生成的代码始终经过人工代码审查。
 #AD.4.2    级别: 2    角色: D
 验证自动扫描器（SAST/IAST/DAST）是否对包含 AI 生成代码的每个拉取请求运行，并在发现关键问题时阻止合并。
 #AD.4.3    级别: 3    角色: D/V
 验证差分模糊测试或基于属性的测试是否证明了安全关键行为（例如，输入验证、授权逻辑）。

---

### AD.5 代码建议的可解释性与可追溯性

向审计员和开发人员提供有关建议原因及其演变过程的见解。

 #AD.5.1    级别: 1    角色: D/V
 验证提示/响应对是否已通过提交 ID 进行日志记录。
 #AD.5.2    级别: 2    角色: D
 验证开发者是否能够展示支持建议的模型引用（训练片段、文档）。
 #AD.5.3    级别: 3    角色: D/V
 验证可解释性报告是否与设计工件一同存储，并在安全评审中被引用，以满足 ISO/IEC 42001 可追溯性原则。

---

### AD.6 持续反馈与模型微调

随着时间的推移提升模型的安全性能，同时防止负面漂移。

 #AD.6.1    级别: 1    角色: D/V
 验证开发人员是否能够标记不安全或不合规的建议，并且这些标记是否被跟踪。
 #AD.6.2    级别: 2    角色: D
 验证汇总的反馈是否用于定期微调或基于审查过的安全编码语料库（例如 OWASP 备忘单）的检索增强生成。
 #AD.6.3    级别: 3    角色: D/V
 验证封闭环评估工具在每次微调后运行回归测试；安全指标必须达到或超过之前的基线才能部署。

---

#### 参考文献

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
OWASP Secure Coding Practices — Quick Reference Guide

## 附录 E：示例工具和框架

### 目标

本章节提供了支持实现或满足特定AISVS需求的工具和框架示例。这些示例不应被视为AISVS团队或OWASP GenAI安全项目的推荐或背书。

---

### AE.1 训练数据治理与偏差管理

用于数据分析、治理和偏差管理的工具。

 #AE.1.1    章节: 1.1
 数据清单工具：数据清单管理工具如...
 #AE.1.2    章节: 1.2
 传输加密 对于基于 HTTPS 的应用程序，使用 TLS，并结合 openSSL 和 python 等工具`ssl`库。

---

### AE.2 用户输入验证

处理和验证用户输入的工具。

 #AE.2.1    章节: 2.1
 提示注入防御工具：使用如NVIDIA的NeMo或Guardrails AI等保护栏工具。

---

