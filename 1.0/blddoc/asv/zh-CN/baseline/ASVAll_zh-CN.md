## 扉页

### 关于标准

人工智能安全验证标准（AISVS）是一个由社区推动的安全需求目录，供数据科学家、MLOps工程师、软件架构师、开发人员、测试人员、安全专业人员、工具供应商、监管机构和消费者使用，以设计、构建、测试和验证可信的人工智能驱动系统和应用。它为在人工智能生命周期内——从数据收集和模型开发到部署及持续监控——指定安全控制提供了统一的语言，从而使组织能够衡量和提升其人工智能解决方案的韧性、隐私性和安全性。

### 版权与许可证

版本 0.1（首个公开草稿 - 工作进行中），2025  

![license](images/license.png)
版权所有 © 2025 AISVS 项目。  

根据…发布Creative Commons Attribution‑ShareAlike 4.0 International License.
对于任何再使用或分发，您必须清楚地向他人传达本作品的许可条款。

### 项目负责人

吉姆·马尼科
Aras “Russ” Memisyazici

### 贡献者和审核者

https://github.com/ottosulin
https://github.com/mbhatt1
https://github.com/vineethsai
https://github.com/cciprofm
https://github.com/deepakrpandey12


---

AISVS 是一个全新的标准，专门为应对人工智能系统的独特安全挑战而创建。虽然它借鉴了更广泛的安全最佳实践，但 AISVS 中的每一条要求都是从零开始开发的，以反映 AI 威胁环境，并帮助组织构建更安全、更具弹性的 AI 解决方案。

## 前言

欢迎使用人工智能安全验证标准（AISVS）1.0版！

### 介绍

AISVS成立于2025年，源于一次协作社区的共同努力，定义了设计、开发、部署和运行现代AI模型、流程以及AI驱动服务时需要考虑的安全需求。

AISVS v1.0 代表了其项目负责人、工作组以及更广泛社区贡献者的共同努力，旨在制定一个务实且可测试的 AI 系统安全基线。

我们此次发布的目标是使AISVS易于采用，同时保持对其定义范围的高度专注，并应对AI独特的快速变化的风险环境。

### AISVS 版本 1.0 的关键目标

版本 1.0 将基于若干指导原则创建。

#### 明确的范围

每项需求都必须与AISVS的名称和使命保持一致：

人工智能——控制措施在AI/ML层（数据、模型、管道或推断）上运行，由人工智能从业人员负责。
安全性 – 需求直接缓解已识别的安全、隐私或安全风险。
验证 – 语言的编写方式使得合规性可以被客观验证。
标准 – 各部分遵循一致的结构和术语，以形成连贯的参考。
​
---

通过遵循AISVS，组织可以系统地评估和增强其人工智能解决方案的安全态势，促进安全人工智能工程的文化建设。

## 使用 AISVS

人工智能安全验证标准（AISVS）定义了现代人工智能应用和服务的安全需求，重点关注应用开发者可控的方面。

AISVS 适用于开发或评估 AI 应用安全性的任何人员，包括开发人员、架构师、安全工程师和审计人员。本章介绍了 AISVS 的结构及其使用方法，包括其验证级别和预期使用场景。

### 人工智能安全验证等级

AISVS 定义了三个逐级递增的安全验证等级。每个等级增加了深度和复杂性，使组织能够根据其人工智能系统的风险级别调整安全策略。

组织可以从第1级开始，随着安全成熟度和威胁暴露的增加，逐步采用更高级别。

#### 级别的定义

AISVS v1.0 中的每个需求均被分配到以下级别之一：

 第1级要求

第一级包括最关键和基础的安全要求。这些要求侧重于防止不依赖其他前提条件或漏洞的常见攻击。大多数第一级控制措施要么实施简单，要么足够重要，值得投入精力。

 等级 2 要求

第2级涵盖更高级或不常见的攻击，以及针对广泛威胁的分层防御。这些要求可能涉及更复杂的逻辑或针对特定攻击前提条件。

 三级要求

第三级包含的控制措施通常更难实施或适用于特定情境。这些通常代表纵深防御机制或针对小众、定向或高复杂度攻击的缓解措施。

#### 角色（D/V）

每个 AISVS 需求都根据主要受众进行标记：

D – 开发者导向的需求
V – 验证者/审计者导向的需求
D/V – 既适用于开发人员，也适用于验证人员

## C1 训练数据治理与偏差管理

### 控制目标

训练数据必须以保留来源、保障安全、确保质量和公平的方式进行获取、处理和维护。这样不仅履行法律义务，还能减少在训练过程中出现的偏见、数据中毒或隐私泄露等风险，这些风险可能影响整个人工智能生命周期。

---

### C1.1 训练数据来源

维护所有数据集的可验证清单，仅接受可信来源，并记录每次更改以便审计。

 #1.1.1    等级: 1    角色: D/V
 确保维护一份最新的培训数据源清单，涵盖每个数据源的来源、管理员/所有者、许可、收集方法、预期使用限制以及处理历史。
 #1.1.2    等级: 1    角色: D/V
 验证训练数据处理是否排除了不必要的特征、属性或字段（例如，未使用的元数据、敏感的个人身份信息、泄露的测试数据）。
 #1.1.3    等级: 2    角色: D/V
 验证所有数据集更改均需经过记录的审批流程。
 #1.1.4    等级: 3    角色: D/V
 在可行的情况下，验证数据集或子集是否进行了水印或指纹识别。

---

### C1.2 训练数据安全性与完整性

限制对训练数据的访问，对静态和传输中的数据进行加密，并验证其完整性，以防止篡改、盗窃或数据投毒。

 #1.2.1    等级: 1    角色: D/V
 验证访问控制是否保护训练数据存储和管道。
 #1.2.2    等级: 2    角色: D/V
 验证所有对训练数据的访问均有记录，包括用户、时间和操作。
 #1.2.3    等级: 2    角色: D/V
 验证训练数据集在传输和静态存储时均经过加密，采用行业标准的密码算法和密钥管理实践。
 #1.2.4    等级: 2    角色: D/V
 验证在训练数据存储和传输过程中是否使用了密码哈希或数字签名以确保数据完整性。
 #1.2.5    等级: 2    角色: D/V
 验证是否应用了自动检测技术以防止训练数据的未授权修改或损坏。
 #1.2.6    等级: 2    角色: D/V
 确保过时的训练数据被安全清除或匿名化。
 #1.2.7    等级: 3    角色: D/V
 验证所有训练数据集版本均具有唯一标识，且以不可变方式存储且可审计，以支持回滚和取证分析。

---

### C1.3 训练数据标注质量、完整性与安全性

保护标签并对关键数据要求技术审核。

 #1.3.1    等级: 2    角色: D/V
 验证是否对标签工件应用了加密哈希或数字签名，以确保其完整性和真实性。
 #1.3.2    等级: 2    角色: D/V
 验证标注接口和平台是否执行严格的访问控制，保持所有标注活动的防篡改审计日志，并防止未经授权的修改。
 #1.3.3    等级: 3    角色: D/V
 验证标签中的敏感信息在静态和传输过程中的数据字段级别是否被编辑、匿名化或加密。

---

### C1.4 训练数据质量与安全保障

结合自动验证、手动抽查和记录的补救措施，以确保数据集的可靠性。

 #1.4.1    等级: 1    角色: D
 验证自动化测试是否在每次数据摄取或重大数据转换时捕捉格式错误和空值。
 #1.4.2    等级: 2    角色: D/V
 验证大规模语言模型（LLM）训练和微调流程是否实施了投毒检测与数据完整性验证（例如，统计方法、异常点检测、嵌入分析），以识别潜在的投毒攻击（例如，标签翻转、后门触发器插入、角色切换命令、有影响力的实例攻击）或训练数据中的无意数据损坏。
 #1.4.3    等级: 3    角色: D/V
 验证是否根据风险评估为相关模型实施并调整了适当的防御措施，例如对抗训练（使用生成的对抗样本）、带扰动输入的数据增强或鲁棒优化技术。
 #1.4.4    等级: 2    角色: D/V
 验证自动生成的标签（例如，通过大语言模型或弱监督生成的标签）是否经过置信度阈值和一致性检查，以检测虚假、误导或置信度低的标签。
 #1.4.5    等级: 3    角色: D
 验证自动化测试是否能够捕捉到每次数据摄取或重大数据转换中的标签偏移。

---

### C1.5 数据血缘和可追溯性

跟踪每个数据点从来源到模型输入的完整历程，以便审计和事件响应。

 #1.5.1    等级: 2    角色: D/V
 验证每个数据点的血统，包括所有转换、增强和合并，均已记录且能够重构。
 #1.5.2    等级: 2    角色: D/V
 验证血缘记录是不可篡改的，安全存储的，并且可供审计访问。
 #1.5.3    等级: 2    角色: D/V
 验证系谱追踪涵盖通过隐私保护或生成技术生成的合成数据，并确保所有合成数据在整个流程中都有明确标注且可区分于真实数据。

---

### 参考文献

NIST AI Risk Management Framework
EU AI Act – Article 10: Data & Data Governance
MITRE ATLAS: Adversary Tactics for AI
Survey of ML Bias Mitigation Techniques – MDPI
Data Provenance & Lineage Best Practices – Nightfall AI
Data Labeling Quality Standards – LabelYourData
Training Data Poisoning Guide – Lakera.ai
CISA Advisory: Securing Data for AI Systems
ISO/IEC 23053: AI Management Systems Framework
IBM: What is AI Governance?
Google AI Principles
GDPR & AI Training Data – DataProtectionReport
Supply-Chain Security for AI Data – AppSOC
OpenAI Privacy Center – Data Deletion Controls
Adversarial ML Dataset – Kaggle

## C2 用户输入验证

### 控制目标

对用户输入的强健验证是防御对人工智能系统造成最大损害的攻击的第一道防线。提示注入攻击可能会覆盖系统指令、泄露敏感数据，或引导模型产生不被允许的行为。除非有专门的过滤器和指令层级，否则研究表明，利用极长上下文窗口的“多次示例”越狱攻击将会奏效。此外，细微的对抗性扰动攻击——例如同形异义字替换或网络黑话——可以悄无声息地改变模型的决策。

---

### C2.1 提示注入防护

提示注入是人工智能系统面临的主要风险之一。针对这种方法的防御措施结合了静态模式过滤器、动态分类器和指令层级执行。

 #2.1.1    等级: 1    角色: D/V
 验证用户输入是否经过筛查，以防止已知提示注入模式（越狱关键词、“忽略之前内容”、角色扮演链条、间接HTML/URL攻击）—这些模式的库会持续更新。
 #2.1.2    等级: 1    角色: D/V
 验证系统是否强制执行指令层级，其中系统或开发者消息优先于用户指令，即使在上下文窗口扩展后也是如此。
 #2.1.3    等级: 2    角色: D/V
 确认在每次模型或提示模板发布之前，都进行对抗性评估测试（例如，红队“多次”提示），并设置成功率阈值及自动阻止回归的机制。
 #2.1.4    等级: 2    角色: D
 验证来自第三方内容（网页、PDF、电子邮件）的提示是否在单独的解析环境中进行清理，然后再合并到主提示中。
 #2.1.5    等级: 3    角色: D/V
 验证所有提示过滤规则更新、分类器模型版本和阻止列表更改均受版本控制且可审计。

---

### C2.2 对抗样本抗性

自然语言处理（NLP）模型仍然容易受到微妙的字符或词级扰动的影响，这些扰动通常被人类忽略，但模型往往会误分类。

 #2.2.1    等级: 1    角色: D
 验证基本的输入规范化步骤（Unicode NFC、同形异义字符映射、空白字符修剪）是否在分词之前执行。
 #2.2.2    等级: 2    角色: D/V
 验证统计异常检测是否标记了与语言规范编辑距离异常高、重复标记过多或嵌入距离异常的输入。
 #2.2.3    等级: 2    角色: D
 验证推理管道是否支持可选的对抗训练强化的模型变体或防御层（例如，随机化、防御蒸馏）以应对高风险端点。
 #2.2.4    等级: 2    角色: V
 验证可疑的对抗性输入是否被隔离，并在进行个人身份信息(PII)脱敏后，完整记录其负载。
 #2.2.5    等级: 3    角色: D/V
 验证鲁棒性指标（已知攻击套件的成功率）是否随时间跟踪，并且回归会触发发布阻止。

---

### C2.3 模式、类型和长度验证

包含格式错误或超大输入的 AI 攻击可能导致解析错误、字段间提示溢出以及资源耗尽。严格的模式（schema）强制也是执行确定性工具调用的前提条件。

 #2.3.1    等级: 1    角色: D
 验证每个 API 或函数调用端点是否定义了明确的输入模式（JSON Schema、Protobuf 或多模态等效模式），并且在提示组装前对输入进行验证。
 #2.3.2    等级: 1    角色: D/V
 验证超过最大令牌数或字节限制的输入是否会被拒绝，且返回安全错误，而不是被静默截断。
 #2.3.3    等级: 2    角色: D/V
 验证类型检查（例如，数字范围、枚举值、图像/音频的 MIME 类型）是否在服务器端强制执行，而不仅仅是在客户端代码中。
 #2.3.4    等级: 2    角色: D
 验证语义验证器（例如，JSON Schema）是否以常数时间运行，以防止算法拒绝服务攻击（DoS）。
 #2.3.5    等级: 3    角色: V
 验证验证失败是否以带有编辑过的有效载荷片段和明确的错误代码的形式记录，以帮助安全分诊。

---

### C2.4 内容与政策筛查

开发人员应能够检测请求不允许内容（例如非法指令、仇恨言论和版权文本）的语法有效提示，然后阻止其传播。

 #2.4.1    等级: 1    角色: D
 验证内容分类器（零样本或微调版本）是否对每个输入内容进行暴力、自残、仇恨、性内容和非法请求的评分，并支持可配置的阈值。
 #2.4.2    等级: 1    角色: D/V
 验证违反政策的输入将收到标准化的拒绝或安全完成，从而防止它们传播到下游的语言模型调用。
 #2.4.3    等级: 2    角色: D
 验证筛查模型或规则集至少每季度重新训练/更新一次，纳入新观察到的绕过限制或规避政策的模式。
 #2.4.4    等级: 2    角色: D
 通过基于属性的规则在请求时解析，验证筛选是否遵守用户特定的政策（年龄、地区法律限制）。
 #2.4.5    等级: 3    角色: V
 验证筛查日志是否包含分类器置信度分数和策略类别标签，以用于SOC关联和未来的红队重放。

---

### C2.5 输入速率限制与滥用防护

开发人员应通过限制输入速率和检测异常使用模式，防止滥用、资源耗尽和针对人工智能系统的自动化攻击。

 #2.5.1    等级: 1    角色: D/V
 验证所有输入端点是否针对每个用户、每个IP和每个API密钥实施了速率限制。
 #2.5.2    等级: 2    角色: D/V
 验证突发速率和持续速率限制已调整到防止拒绝服务（DoS）和暴力破解攻击。
 #2.5.3    等级: 2    角色: D/V
 验证异常使用模式（例如，快速连续请求、输入泛滥）是否会触发自动阻止或升级。
 #2.5.4    等级: 3    角色: V
 验证滥用预防日志是否被保留并审查以发现新出现的攻击模式。

---

### C2.6 多模态输入验证

AI系统应包括对非文本输入（图像、音频、文件）的强健验证，以防止注入、规避或资源滥用。

 #2.6.1    等级: 1    角色: D
 确保所有非文本输入（图像、音频、文件）在处理前均经过类型、大小和格式的验证。
 #2.6.2    等级: 2    角色: D/V
 验证文件在导入前是否进行了恶意软件和隐写载荷扫描。
 #2.6.3    等级: 2    角色: D/V
 验证图像/音频输入是否经过对抗扰动或已知攻击模式的检查。
 #2.6.4    等级: 3    角色: V
 验证多模态输入验证失败是否被记录并触发警报以供调查。

---

### C2.7 输入来源与归属

人工智能系统应通过监控和标记所有用户输入的来源，支持审计、滥用追踪和合规性。

 #2.7.1    等级: 1    角色: D/V
 验证所有用户输入在摄取时都带有元数据标签（用户ID、会话、来源、时间戳、IP地址）。
 #2.7.2    等级: 2    角色: D/V
 验证所有处理过的输入的出处元数据是否被保留且可审计。
 #2.7.3    等级: 2    角色: D/V
 验证异常或不可信的输入来源是否被标记并受到加强审查或阻止。

---

### C2.8 实时自适应威胁检测

开发人员应使用先进的针对人工智能的威胁检测系统，该系统能够适应新的攻击模式并通过编译的模式匹配提供实时保护。

 #2.8.1    等级: 1    角色: D/V
 验证威胁检测模式是否已编译成优化的正则表达式引擎，以实现高性能的实时过滤，并将延迟影响降至最低。
 #2.8.2    等级: 1    角色: D/V
 验证威胁检测系统是否为不同的威胁类别（提示注入、有害内容、敏感数据、系统命令）维护独立的模式库。
 #2.8.3    等级: 2    角色: D/V
 验证自适应威胁检测是否包含机器学习模型，该模型根据攻击频率和成功率更新威胁敏感度。
 #2.8.4    等级: 2    角色: D/V
 验证实时威胁情报源是否自动更新模式库，包含新的攻击特征和妥协指标（IOC）。
 #2.8.5    等级: 3    角色: D/V
 验证威胁检测的误报率是否持续受到监控，并自动调整模式特异性以最大限度减少对合法用例的干扰。
 #2.8.6    等级: 3    角色: D/V
 验证上下文威胁分析是否考虑了输入来源、用户行为模式和会话历史，以提高检测准确性。
 #2.8.7    等级: 3    角色: D/V
 验证威胁检测性能指标（检测率、处理延迟、资源利用率）是否被实时监控和优化。

---

### C2.9 多模态安全验证流程

开发人员应针对文本、图像、音频及其他 AI 输入模式，提供特定类型的威胁检测和资源隔离的安全验证。

 #2.9.1    等级: 1    角色: D/V
 验证每种输入方式是否具备专门的安全验证器，且具备文档化的威胁模式（文本：提示注入，图像：隐写术，音频：频谱图攻击）和检测阈值。
 #2.9.2    等级: 2    角色: D/V
 验证多模态输入是否在隔离的沙箱中处理，且每种模态类型具有定义的资源限制（内存、CPU、处理时间），并在安全策略中有相应记录。
 #2.9.3    等级: 2    角色: D/V
 验证跨模态攻击检测是否能够通过关联规则和告警生成识别跨多个输入类型的协调攻击（例如，图像中的隐写载荷与文本中的提示注入相结合）。
 #2.9.4    等级: 3    角色: D/V
 验证多模态验证失败是否触发详细日志记录，包括所有输入模态、验证结果、威胁评分以及结构化日志格式的相关性分析，以便集成SIEM。
 #2.9.5    等级: 3    角色: D/V
 验证特定模态内容分类器是否按照文档规定的时间表（至少每季度）更新，包括新的威胁模式、对抗性样本，并且性能基准维持在基线阈值以上。

---

### 参考文献

LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security
Generative AI's Biggest Security Flaw Is Not Easy to Fix
Many-shot jailbreaking \ Anthropic
$PDF$ OpenAI GPT-4.5 System Card
Notebook for the CheckThat Lab at CLEF 2024
Mitigate jailbreaks and prompt injections – Anthropic
Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis
OWASP Top 10 for LLM Applications 2025 – WorldTech IT
OWASP Machine Learning Security Top Ten
Few words about AI Security – Jussi Metso
How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry
Easily enforcing valid JSON schema following – API
AI Safety + Cybersecurity R\&D Tracker – Fairly AI
Anthropic makes 'jailbreak' advance to stop AI models producing harmful results
Pattern matching filter rules - IBM
Real-time Threat Detection

## C3 模型生命周期管理与变更控制

### 控制目标

人工智能系统必须实施变更控制流程，防止未经授权或不安全的模型修改进入生产环境。该控制确保模型在整个生命周期中的完整性——从开发到部署再到退役——从而实现快速事件响应并保持对所有变更的责任追踪。

核心安全目标：通过采用受控流程，确保只有经过授权和验证的模型才能进入生产环境，并保持完整性、可追溯性和可恢复性。

---

### C3.1 模型授权与完整性

只有经过验证完整性的授权模型才能进入生产环境。

 #3.1.1    等级: 1    角色: D/V
 在部署之前，验证所有模型工件（权重、配置、分词器）是否由授权实体进行过密码学签名。
 #3.1.2    等级: 1    角色: D/V
 验证模型完整性在部署时已被确认，并且签名验证失败会阻止模型加载。
 #3.1.3    等级: 2    角色: D/V
 验证模型溯源记录是否包含授权实体的身份、训练数据校验和、带有通过/未通过状态的验证测试结果以及创建时间戳。
 #3.1.4    等级: 2    角色: D/V
 验证所有模型产物均使用语义版本控制（MAJOR.MINOR.PATCH），并具备规定每个版本组件递增条件的文档说明。
 #3.1.5    等级: 2    角色: V
 验证依赖跟踪能够维护实时库存，从而实现对所有使用系统的快速识别。

---

### C3.2 模型验证与测试

模型在部署前必须通过定义的安全性和可靠性验证。

 #3.2.1    等级: 1    角色: D/V
 验证模型在部署前必须经过自动化安全测试，测试内容包括输入验证、输出清理以及安全评估，并且需符合事先约定的组织通过/不通过标准。
 #3.2.2    等级: 1    角色: D/V
 验证在经过预先指定的授权人员明确覆盖批准并附有书面业务理由后，验证失败是否会自动阻止模型部署。
 #3.2.3    等级: 2    角色: V
 验证测试结果是否经过加密签名，并且不可变地链接到正在验证的特定模型版本哈希。
 #3.2.4    等级: 2    角色: D/V
 验证紧急部署是否需要在预先约定的时间范围内，经过预先指定的安全权威进行记录的安全风险评估和批准。

---

### C3.3 受控部署与回滚

模型部署必须受到控制、监控且可逆。

 #3.3.1    等级: 1    角色: D
 验证生产部署是否实施渐进式发布机制（灰度发布、蓝绿部署），并基于预先约定的错误率、延迟阈值或安全警报标准设置自动回滚触发器。
 #3.3.2    等级: 1    角色: D/V
 验证回滚功能是否在预定义的组织时间窗口内，原子性地恢复完整的模型状态（权重、配置、依赖项）。
 #3.3.3    等级: 2    角色: D/V
 验证部署过程在模型激活前是否验证了加密签名并计算了完整性校验和，若有任何不匹配则使部署失败。
 #3.3.4    等级: 2    角色: D/V
 验证紧急模型关闭功能能够通过自动断路器或手动终止开关在预定义响应时间内禁用模型端点。
 #3.3.5    等级: 2    角色: V
 验证回滚工件（先前的模型版本、配置、依赖项）是否根据组织政策保留，并使用不可变存储以便于事故响应。

---

### C3.4 变更问责与审计

所有模型生命周期的更改必须可追踪和可审计。

 #3.4.1    等级: 1    角色: V
 验证所有模型变更（部署、配置、淘汰）均生成不可变的审计记录，包括时间戳、经过身份验证的操作人员身份、变更类型以及变更前后状态。
 #3.4.2    等级: 2    角色: D/V
 验证审计日志访问是否需要适当的授权，并且所有访问尝试均记录用户身份和时间戳。
 #3.4.3    等级: 2    角色: D/V
 验证提示模板和系统消息是否在git代码库中进行版本控制，并且在部署之前必须经过指定审核者的代码审查和批准。
 #3.4.4    等级: 2    角色: V
 验证审计记录是否包含足够的详细信息（模型哈希值、配置快照、依赖版本），以便在保留期限内的任何时间点能够完整重建模型状态。

---

### C3.5 安全开发实践

模型开发和训练过程必须遵循安全规范以防止被攻破。

 #3.5.1    等级: 1    角色: D
 验证模型开发、测试和生产环境在物理上或逻辑上是分离的。它们没有共享的基础设施，具有独立的访问控制，并且数据存储是隔离的。
 #3.5.2    等级: 1    角色: D
 验证模型训练和微调是否在具有受控网络访问的隔离环境中进行。
 #3.5.3    等级: 1    角色: D/V
 确保训练数据源在用于模型开发之前通过完整性检查进行验证，并通过有文档记录的监管链由可信来源进行身份验证。
 #3.5.4    等级: 2    角色: D
 验证模型开发工件（超参数、训练脚本、配置文件）是否存储在版本控制中，并且在用于训练之前需要同行评审批准。

---

### C3.6 模型退役与停用

模型在不再需要或发现安全问题时必须安全退役。

 #3.6.1    等级: 1    角色: D
 验证模型退役流程是否自动扫描依赖图，识别所有使用系统，并在退役前提供预先商定的通知期。
 #3.6.2    等级: 1    角色: D/V
 根据记录的数据保留政策，使用加密擦除或多遍覆盖方法，验证已退役模型工件的安全擦除，并确保有已验证的销毁证书。
 #3.6.3    等级: 2    角色: V
 验证模型退役事件是否带有时间戳和行为者身份的日志记录，并且模型签名已被吊销以防止重复使用。
 #3.6.4    等级: 2    角色: D/V
 验证紧急模型退役是否能够通过自动杀死开关，在预先设定的紧急响应时间内禁用模型访问，以防发现关键安全漏洞。

---

### 参考文献

MLOps Principles
Securing AI/ML Ops – Cisco.com
Audit logs security: cryptographically signed tamper-proof logs
Machine Learning Model Versioning: Top Tools & Best Practices
AI Hygiene Starts with Models and Data Loaders – SEI Blog
How to handle versioning and rollback of a deployed ML model?
Reinforcement fine-tuning – OpenAI API
Auditing Machine Learning models: Governance, Data Security and …
Adversarial Training to Improve Model Robustness
What is AI adversarial robustness? – IBM Research
Exploring Data Provenance: Ensuring Data Integrity and Authenticity
MITRE ATLAS
AWS Prescriptive Guidance – Best practices for retiring applications …

## C4 基础设施、配置与部署安全

### 控制目标

人工智能基础设施必须通过安全配置、运行时隔离、可信部署管道和全面监控，强化防范特权提升、供应链篡改和横向移动。只有经过授权和验证的基础设施组件和配置，才能通过受控流程进入生产环境，以保持安全性、完整性和可审计性。

核心安全目标：只有经过加密签名和漏洞扫描的基础设施组件，才能通过自动化验证管道进入生产环境，这些管道执行安全策略并维护不可变的审计记录。

---

### C4.1 运行时环境隔离

通过内核级隔离原语和强制访问控制，防止容器逃逸和特权升级。

 #4.1.1    等级: 1    角色: D/V
 验证所有 AI 容器是否丢弃除了 CAP_SETUID、CAP_SETGID 以及安全基线中明确要求的能力之外的所有 Linux 能力。
 #4.1.2    等级: 1    角色: D/V
 验证 seccomp 配置文件是否阻止所有系统调用，除预先批准的允许列表中的系统调用外，对于违规行为终止容器并生成安全警报。
 #4.1.3    等级: 2    角色: D/V
 验证AI工作负载是否以只读根文件系统运行，临时数据使用tmpfs，持久数据使用具备noexec挂载选项的命名卷。
 #4.1.4    等级: 2    角色: D/V
 验证基于 eBPF 的运行时监控（如 Falco、Tetragon 或同类工具）是否能够检测到权限提升尝试，并在组织响应时间要求内自动终止违规进程。
 #4.1.5    等级: 3    角色: D/V
 验证高风险 AI 工作负载是否在硬件隔离环境中执行（如 Intel TXT、AMD SVM 或专用裸机节点），并进行证明验证。

---

### C4.2 安全构建与部署管道

通过可重现构建和签名工件确保密码学完整性和供应链安全。

 #4.2.1    等级: 1    角色: D/V
 确保每次提交时使用工具（tfsec、Checkov 或 Terrascan）扫描基础设施即代码（infrastructure-as-code），并阻止包含关键（CRITICAL）或高危（HIGH）严重性问题的合并。
 #4.2.2    等级: 1    角色: D/V
 验证容器构建是否具有可重复性，即跨构建具有相同的 SHA256 哈希值，并使用 Sigstore 签名生成符合 SLSA 三级的来源证明。
 #4.2.3    等级: 2    角色: D/V
 验证容器镜像在推送到注册表之前是否嵌入了 CycloneDX 或 SPDX SBOM，并且已使用 Cosign 签名，未签名的镜像在部署时被拒绝。
 #4.2.4    等级: 2    角色: D/V
 验证 CI/CD 管道是否使用来自 HashiCorp Vault、AWS IAM 角色或 Azure 托管身份的 OIDC 令牌，且其有效期不超过组织安全策略的限制。
 #4.2.5    等级: 2    角色: D/V
 验证在部署过程中 Cosign 签名和 SLSA 溯源已被验证，并且验证错误会导致部署失败，确保在容器执行前完成此验证。
 #4.2.6    等级: 2    角色: D/V
 验证构建环境是否运行在临时容器或虚拟机中，这些环境没有持久存储并且与生产VPC实现网络隔离。

---

### C4.3 网络安全与访问控制

实现零信任网络，采用默认拒绝策略和加密通信。

 #4.3.1    等级: 1    角色: D/V
 验证 Kubernetes NetworkPolicies 或任何等效方案是否通过显式允许所需端口（443、8080 等）的规则来实现默认拒绝的入口/出口流量控制。
 #4.3.2    等级: 1    角色: D/V
 验证 SSH（端口 22）、RDP（端口 3389）和云元数据端点（169.254.169.254）是否被阻止或需要基于证书的身份验证。
 #4.3.3    等级: 2    角色: D/V
 验证出站流量是否通过带有域名允许列表的 HTTP/HTTPS 代理（如 Squid、Istio 或云 NAT 网关）进行过滤，并且被阻止的请求已被记录。
 #4.3.4    等级: 2    角色: D/V
 验证服务间通信使用双向TLS，证书根据组织策略定期轮换，并强制执行证书验证（不允许跳过验证标志）。
 #4.3.5    等级: 2    角色: D/V
 验证人工智能基础设施是否运行在专用的 VPC/VNet 中，没有直接的互联网访问，并且仅通过 NAT 网关或堡垒主机进行通信。

---

### C4.4 秘密与密码密钥管理

通过硬件支持的存储和自动轮换，结合零信任访问，保护凭证安全。

 #4.4.1    等级: 1    角色: D/V
 验证秘密是否存储在 HashiCorp Vault、AWS Secrets Manager、Azure Key Vault 或 Google Secret Manager 中，并使用 AES-256 进行静态加密。
 #4.4.2    等级: 1    角色: D/V
 验证加密密钥是否在符合 FIPS 140-2 2 级的硬件安全模块（HSM）（如 AWS CloudHSM、Azure Dedicated HSM）中生成，并且按照组织的密码策略进行密钥轮换。
 #4.4.3    等级: 2    角色: D/V
 验证秘密轮换是否实现自动化，具备零停机部署，并且能在人员变动或安全事件发生时立即触发轮换。
 #4.4.4    等级: 2    角色: D/V
 验证容器镜像是否使用工具（GitLeaks、TruffleHog 或 detect-secrets）进行扫描，阻止包含 API 密钥、密码或证书的构建。
 #4.4.5    等级: 2    角色: D/V
 验证生产环境的秘密访问是否需要使用带有硬件令牌（YubiKey、FIDO2）的多因素认证（MFA），并且是否通过带有用户身份和时间戳的不可变审计日志进行记录。
 #4.4.6    等级: 2    角色: D/V
 验证机密是否通过 Kubernetes 机密、挂载的卷或初始化容器注入，并确保机密永远不会嵌入在环境变量或镜像中。

---

### C4.5 AI 工作负载沙箱测试与验证

在安全沙箱中隔离不受信任的 AI 模型，并进行全面的行为分析。

 #4.5.1    等级: 1    角色: D/V
 验证外部人工智能模型是否在 gVisor、微虚拟机（如 Firecracker、CrossVM）或带有 --security-opt=no-new-privileges 和 --read-only 标志的 Docker 容器中执行。
 #4.5.2    等级: 1    角色: D/V
 验证沙箱环境没有网络连接（--network=none）或仅限本地主机访问，所有外部请求均由 iptables 规则阻止。
 #4.5.3    等级: 2    角色: D/V
 验证人工智能模型的验证过程中包括组织定义的测试覆盖范围内的自动化红队测试和用于后门检测的行为分析。
 #4.5.4    等级: 2    角色: D/V
 在将 AI 模型投入生产之前，验证其沙箱结果是否由授权的安全人员进行密码签名，并存储在不可篡改的审计日志中。
 #4.5.5    等级: 2    角色: D/V
 验证沙箱环境在每次评估之间通过完整的文件系统和内存清理，从黄金镜像销毁并重新创建。

---

### C4.6 基础设施安全监控

通过自动修复和实时警报，持续扫描和监控基础设施。

 #4.6.1    等级: 1    角色: D/V
 验证容器镜像是否按照组织调度进行扫描，且根据组织的风险阈值，关键漏洞（CRITICAL）会阻止部署。
 #4.6.2    等级: 1    角色: D/V
 验证基础设施是否符合组织定义的合规阈值的 CIS 基准或 NIST 800-53 控制，并对失败的检查进行自动修复。
 #4.6.3    等级: 2    角色: D/V
 验证高严重性漏洞是否按照组织的风险管理时间表进行修补，并针对已被积极利用的CVE实施应急程序。
 #4.6.4    等级: 2    角色: V
 验证安全警报是否使用 CEF 或 STIX/TAXII 格式，通过自动丰富功能与 SIEM 平台（Splunk、Elastic 或 Sentinel）集成。
 #4.6.5    等级: 3    角色: V
 验证基础设施指标是否已导出到监控系统（Prometheus，DataDog），并配备有SLA仪表盘和高层报告。
 #4.6.6    等级: 2    角色: D/V
 根据组织的监控要求，使用工具（Chef InSpec，AWS Config）验证是否检测到配置漂移，并对未经授权的更改进行自动回滚。

---

### C4.7 AI基础设施资源管理

通过配额和监控防止资源耗尽攻击并确保资源分配公平。

 #4.7.1    等级: 1    角色: D/V
 验证GPU/TPU利用率是否被监控，并在组织定义的阈值触发告警，同时根据容量管理策略启用自动扩展或负载均衡。
 #4.7.2    等级: 1    角色: D/V
 验证AI工作负载指标（推理延迟、吞吐量、错误率）是否按照组织的监控要求进行收集，并与基础设施利用率相关联。
 #4.7.3    等级: 2    角色: D/V
 验证 Kubernetes ResourceQuotas 或等效机制是否根据组织的资源分配政策对单个工作负载进行限制，并强制执行硬性限制。
 #4.7.4    等级: 2    角色: V
 验证成本监控是否能够按工作负载/租户跟踪支出，并基于组织预算阈值发出警报，以及针对预算超支实施自动控制。
 #4.7.5    等级: 3    角色: V
 验证容量规划是否使用了具有组织定义预测周期的历史数据，以及基于需求模式的自动化资源配置。
 #4.7.6    等级: 2    角色: D/V
 验证资源耗尽是否根据组织响应要求触发断路器，包括基于容量策略的速率限制和工作负载隔离。

---

### C4.8 环境隔离与推广控制

通过自动化升级门和安全验证实施严格的环境边界控制。

 #4.8.1    等级: 1    角色: D/V
 验证开发/测试/生产环境是否运行在独立的 VPC/VNet 中，且没有共享的 IAM 角色、安全组或网络连接。
 #4.8.2    等级: 1    角色: D/V
 验证环境提升是否需要组织定义的授权人员通过密码签名和不可篡改的审计追踪进行批准。
 #4.8.3    等级: 2    角色: D/V
 验证生产环境阻止SSH访问，禁用调试端点，并要求变更请求符合组织的提前通知要求，紧急情况除外。
 #4.8.4    等级: 2    角色: D/V
 验证基础设施即代码的更改在合并到主分支之前，必须经过同行评审，并通过自动化测试和安全扫描。
 #4.8.5    等级: 2    角色: D/V
 验证非生产数据是否根据组织的隐私要求进行了匿名处理，合成数据生成，或通过验证的个人身份信息（PII）移除实现完全数据掩码。
 #4.8.6    等级: 2    角色: D/V
 验证晋升门禁包括自动化安全测试（静态应用安全测试SAST、动态应用安全测试DAST、容器扫描），且批准时必须没有关键漏洞（CRITICAL）发现。

---

### C4.9 基础设施备份与恢复

通过自动备份、经过测试的恢复程序和灾难恢复能力，确保基础设施的弹性。

 #4.9.1    等级: 1    角色: D/V
 验证基础设施配置是否根据组织的备份计划，采用3-2-1备份策略备份到地理上分离的区域。
 #4.9.2    等级: 2    角色: D/V
 验证备份系统是否在隔离的网络中运行，使用独立的凭据，并配备为空气隔离存储以防止勒索软件攻击。
 #4.9.3    等级: 2    角色: V
 根据组织的计划，通过自动化测试验证恢复程序的测试和验证，确保恢复时间目标（RTO）和恢复点目标（RPO）符合组织要求。
 #4.9.4    等级: 3    角色: V
 验证灾难恢复是否包括针对AI的专用操作手册，其中涵盖模型权重恢复、GPU集群重建以及服务依赖关系映射。

---

### C4.10 基础设施合规性与治理

通过持续评估、文档记录和自动化控制，保持合规性。

 #4.10.1    等级: 2    角色: D/V
 验证基础设施合规性是否根据组织的时间表，针对SOC 2、ISO 27001或FedRAMP控制进行评估，并使用自动化证据收集。
 #4.10.2    等级: 2    角色: V
 验证基础设施文档是否包含网络图、数据流图和根据组织变更管理要求更新的威胁模型。
 #4.10.3    等级: 3    角色: D/V
 验证基础设施变更是否经过自动化合规性影响评估，并针对高风险修改执行监管审批流程。

---

### C4.11 人工智能硬件安全

保护专门用于 AI 的硬件组件，包括 GPU、TPU 以及专用 AI 加速器。

 #4.11.1    等级: 2    角色: D/V
 验证 AI 加速器固件（GPU BIOS、TPU 固件）是否经过密码学签名验证，并根据组织的补丁管理时间表进行更新。
 #4.11.2    等级: 2    角色: D/V
 在工作负载执行之前，通过使用 TPM 2.0、Intel TXT 或 AMD SVM 的硬件证明验证 AI 加速器的完整性。
 #4.11.3    等级: 2    角色: D/V
 使用 SR-IOV、MIG（多实例 GPU）或等效的硬件分区，并在作业之间进行内存清理，验证 GPU 内存是否在不同工作负载间实现隔离。
 #4.11.4    等级: 3    角色: V
 验证AI硬件供应链是否包含带有制造商证书的来源验证以及防篡改包装的验证。
 #4.11.5    等级: 3    角色: D/V
 验证硬件安全模块（HSM）是否通过了FIPS 140-2第三级或Common Criteria EAL4+认证，以保护AI模型权重和加密密钥。

---

### C4.12 边缘与分布式人工智能基础设施

包括边缘计算、联邦学习和多站点架构在内的安全分布式人工智能部署。

 #4.12.1    等级: 2    角色: D/V
 验证边缘 AI 设备是否使用双向 TLS 通过设备证书进行身份验证，并根据组织的证书管理策略进行证书轮换。
 #4.12.2    等级: 2    角色: D/V
 验证边缘设备是否实现了带有已验证签名和回滚保护的安全启动，以防止固件降级攻击。
 #4.12.3    等级: 3    角色: D/V
 验证分布式人工智能协调是否使用了拜占庭容错共识算法，并具备参与者验证和恶意节点检测功能。
 #4.12.4    等级: 3    角色: D/V
 验证边缘到云端通信包括带宽限制、数据压缩以及具备安全本地存储的离线操作能力。

---

### C4.13 多云与混合基础设施安全

在多个云服务提供商和混合云本地部署中保障 AI 工作负载的安全。

 #4.13.1    等级: 2    角色: D/V
 验证多云 AI 部署是否使用云无关的身份联合（OIDC，SAML），并在各供应商之间实现集中式策略管理。
 #4.13.2    等级: 2    角色: D/V
 验证跨云数据传输是否使用端到端加密，采用客户管理的密钥，并根据司法管辖区实施数据驻留控制。
 #4.13.3    等级: 2    角色: D/V
 验证混合云人工智能工作负载在本地和云环境中实施一致的安全策略，并具备统一的监控和告警功能。
 #4.13.4    等级: 3    角色: V
 验证防止云供应商锁定的方法是否包括可移植的基础设施即代码、标准化的API以及带有格式转换工具的数据导出功能。
 #4.13.5    等级: 3    角色: V
 验证多云成本优化是否包括防止资源泛滥的安全控制以及防止未经授权的跨云数据传输费用。

---

### C4.14 基础设施自动化与 GitOps 安全

为 AI 基础设施管理保障基础设施自动化流水线和 GitOps 工作流的安全。

 #4.14.1    等级: 2    角色: D/V
 验证 GitOps 仓库是否要求使用 GPG 密钥进行签名提交，并且设置了分支保护规则，防止直接推送到主分支。
 #4.14.2    等级: 2    角色: D/V
 验证基础设施自动化包括偏差检测，并具备根据组织响应要求触发的自动修复和回滚功能，用于处理未经授权的更改。
 #4.14.3    等级: 2    角色: D/V
 验证自动化基础设施配置是否包含安全策略验证，并对不合规的配置进行部署阻止。
 #4.14.4    等级: 2    角色: D/V
 验证基础设施自动化的密钥是否通过外部密钥操作器（External Secrets Operator，Bank-Vaults）进行管理，并支持自动轮换。
 #4.14.5    等级: 3    角色: V
 验证自愈基础设施是否包含安全事件关联以及自动化事件响应和相关方通知工作流。

---

### C4.15 量子抗性基础设施安全

通过后量子密码学和量子安全协议，为量子计算威胁准备人工智能基础设施。

 #4.15.1    等级: 3    角色: D/V
 验证人工智能基础设施是否实施了NIST批准的后量子密码算法（CRYSTALS-Kyber、CRYSTALS-Dilithium、SPHINCS+）用于密钥交换和数字签名。
 #4.15.2    等级: 3    角色: D/V
 验证量子密钥分发（QKD）系统是否已实施，用于具备量子安全密钥管理协议的高安全性人工智能通信。
 #4.15.3    等级: 3    角色: D/V
 验证加密敏捷框架是否通过自动证书和密钥轮换，实现对新后量子算法的快速迁移。
 #4.15.4    等级: 3    角色: V
 验证量子威胁建模是否评估了 AI 基础设施对量子攻击的脆弱性，并附有记录的迁移时间表和风险评估。
 #4.15.5    等级: 3    角色: D/V
 验证混合经典-量子密码系统在量子过渡期通过性能监控提供纵深防御。

---

### C4.16 机密计算与安全区域

使用基于硬件的受信任执行环境和机密计算技术保护 AI 工作负载和模型权重。

 #4.16.1    等级: 3    角色: D/V
 验证敏感的 AI 模型是否在具有加密内存和认证验证的 Intel SGX 安全隔区、AMD SEV-SNP 或 ARM TrustZone 内执行。
 #4.16.2    等级: 3    角色: D/V
 验证机密容器（Kata Containers、使用机密计算的 gVisor）是否通过硬件强制的内存加密隔离 AI 工作负载。
 #4.16.3    等级: 3    角色: D/V
 验证远程证明在加载人工智能模型之前，通过加密证明执行环境的真实性来确认安全隔区的完整性。
 #4.16.4    等级: 3    角色: D/V
 验证机密的 AI 推理服务通过加密计算实现防止模型被提取，采用封装的模型权重和受保护的执行环境。
 #4.16.5    等级: 3    角色: D/V
 验证受信任执行环境编排通过远程认证和加密通信通道管理安全保密区的生命周期。
 #4.16.6    等级: 3    角色: D/V
 验证安全多方计算（SMPC）是否支持在不暴露各自数据集或模型参数的情况下进行协作式人工智能训练。

---

### C4.17 零知识基础设施

实现零知识证明系统，用于隐私保护的人工智能验证和认证，且不泄露敏感信息。

 #4.17.1    等级: 3    角色: D/V
 验证零知识证明（ZK-SNARKs，ZK-STARKs）能够在不暴露模型权重或训练数据的情况下，验证AI模型的完整性和训练来源。
 #4.17.2    等级: 3    角色: D/V
 验证基于零知识证明的身份验证系统能够实现隐私保护的用户验证，确保在不泄露身份相关信息的情况下为人工智能服务提供身份认证。
 #4.17.3    等级: 3    角色: D/V
 验证私有集合交集（PSI）协议能够在不暴露各自数据集的前提下，实现联邦人工智能中的安全数据匹配。
 #4.17.4    等级: 3    角色: D/V
 验证零知识机器学习（ZKML）系统通过加密证明正确计算，实现可验证的人工智能推理。
 #4.17.5    等级: 3    角色: D/V
 验证ZK-rollups是否通过批量验证和降低计算开销，实现了可扩展且保护隐私的AI交易处理。

---

### C4.18 侧信道攻击防护

保护人工智能基础设施免受可能泄露敏感信息的时间、电力、电磁和基于缓存的侧信道攻击。

 #4.18.1    等级: 3    角色: D/V
 验证 AI 推理时间是否通过常数时间算法和填充进行了归一化，以防止基于时间的模型提取攻击。
 #4.18.2    等级: 3    角色: D/V
 验证功率分析防护是否包括噪声注入、电源线滤波以及随机化执行模式，以保护人工智能硬件。
 #4.18.3    等级: 3    角色: D/V
 验证基于缓存的侧信道缓解措施是否使用缓存分区、随机化和刷新指令来防止信息泄露。
 #4.18.4    等级: 3    角色: D/V
 验证电磁发射保护包括屏蔽、信号滤波和随机化处理，以防止TEMPEST风格的攻击。
 #4.18.5    等级: 3    角色: D/V
 验证微架构侧信道防御措施是否包括推测执行控制和内存访问模式混淆。

---

### C4.19 神经形态与专用人工智能硬件安全

保护新兴的 AI 硬件架构，包括神经形态芯片、FPGA、定制 ASIC 和光学计算系统。

 #4.19.1    等级: 3    角色: D/V
 验证神经形态芯片安全性包括脉冲模式加密、突触权重保护和基于硬件的学习规则验证。
 #4.19.2    等级: 3    角色: D/V
 验证基于 FPGA 的 AI 加速器是否实现了比特流加密、防篡改机制以及具有身份验证更新的安全配置加载。
 #4.19.3    等级: 3    角色: D/V
 验证定制ASIC安全性是否包括片上安全处理器、硬件信任根和带有防篡改检测的安全密钥存储。
 #4.19.4    等级: 3    角色: D/V
 验证光计算系统是否实现了量子安全的光学加密、安全的光子交换以及受保护的光学信号处理。
 #4.19.5    等级: 3    角色: D/V
 验证混合模拟-数字 AI 芯片是否包括安全的模拟计算、受保护的权重存储和经过认证的模拟到数字转换。

---

### C4.20 隐私保护计算基础设施

实施隐私保护计算的基础设施控制，以在人工智能处理和分析过程中保护敏感数据。

 #4.20.1    等级: 3    角色: D/V
 验证同态加密基础设施能够对敏感的人工智能工作负载进行加密计算，同时具备密码学完整性验证和性能监控功能。
 #4.20.2    等级: 3    角色: D/V
 验证私有信息检索系统通过对访问模式的加密保护，实现数据库查询而不泄露查询模式。
 #4.20.3    等级: 3    角色: D/V
 验证安全多方计算协议是否能够实现隐私保护的人工智能推理，而不暴露单个输入或中间计算过程。
 #4.20.4    等级: 3    角色: D/V
 验证隐私保护密钥管理是否包括分布式密钥生成、阈值密码学和具有硬件支持保护的安全密钥轮换。
 #4.20.5    等级: 3    角色: D/V
 验证通过批处理、缓存和硬件加速优化隐私保护计算性能，同时保持密码学安全保证。

---

### C4.15 代理框架云集成安全与混合部署

具有混合本地/云架构的云集成代理框架的安全控制。

 #4.15.1    等级: 1    角色: D/V
 验证云存储集成是否使用端到端加密，并由代理控制密钥管理。
 #4.15.2    等级: 2    角色: D/V
 验证混合部署的安全边界是否明确定义，并且通信通道是否已加密。
 #4.15.3    等级: 2    角色: D/V
 验证云资源访问包含零信任验证和持续身份验证。
 #4.15.4    等级: 3    角色: D/V
 通过对存储位置进行密码学证明，验证数据驻留要求的执行情况。
 #4.15.5    等级: 3    角色: D/V
 验证云服务提供商的安全评估是否包括针对代理的威胁建模和风险评估。

---

### 参考文献

NIST Cybersecurity Framework 2.0
CIS Controls v8
OWASP Container Security Verification Standard
Kubernetes Security Best Practices
SLSA Supply Chain Security Framework
NIST SP 800-190: Application Container Security Guide
Cloud Security Alliance: Cloud Controls Matrix
ENISA: Secure Infrastructure Design
NIST SP 800-53: Security Controls for Federal Information Systems
ISO 27001:2022 Information Security Management
NIST AI Risk Management Framework
CIS Kubernetes Benchmark
FIPS 140-2 Security Requirements
NIST SP 800-207: Zero Trust Architecture
IEEE 2857: Privacy Engineering for AI Systems
NIST SP 800-161: Cybersecurity Supply Chain Risk Management
NIST Post-Quantum Cryptography Standards
Intel SGX Developer Guide
AMD SEV-SNP White Paper
ARM TrustZone Technology
ZK-SNARKs: A Gentle Introduction
NIST SP 800-57: Cryptographic Key Management
Side-Channel Attack Countermeasures
Neuromorphic Computing Security Challenges
FPGA Security: Fundamentals, Evaluation, and Countermeasures
Microsoft SEAL: Homomorphic Encryption Library
HElib: Homomorphic Encryption Library
PALISADE Lattice Cryptography Library
Differential Privacy: A Survey of Results
Secure Aggregation for Federated Learning
Private Information Retrieval: Concepts and Constructions

## C5 访问控制与人工智能组件及用户的身份管理

### 控制目标

对人工智能系统实施有效的访问控制需要强大的身份管理、上下文感知授权以及遵循零信任原则的运行时执行。这些控制措施确保人类、服务和自主代理只能在明确授权的范围内与模型、数据和计算资源进行交互，并具备持续验证和审计能力。

---

### C5.1 身份管理与认证

为所有实体建立基于密码学支持的身份，并为特权操作启用多因素认证。

 #5.1.1    等级: 1    角色: D/V
 验证所有人类用户和服务主体通过集中式企业身份提供者（IdP）使用 OIDC/SAML 协议进行身份验证，且具有唯一的身份到令牌映射（无共享账户或凭据）。
 #5.1.2    等级: 1    角色: D/V
 验证高风险操作（模型部署、权重导出、训练数据访问、生产配置更改）是否需要多因素身份验证或带有会话重新验证的升级身份验证。
 #5.1.3    等级: 2    角色: D
 确保新的负责人在获得生产系统访问权限之前，经过与 NIST 800-63-3 IAL-2 或等效标准一致的身份验证。
 #5.1.4    等级: 2    角色: V
 验证是否每季度进行访问审查，并自动检测休眠账户、执行凭证轮换及实施账号注销流程。
 #5.1.5    等级: 3    角色: D/V
 验证联合 AI 代理通过签名的 JWT 声明进行身份验证，该声明的最大有效期为 24 小时，并包含来源的密码学证明。

---

### C5.2 资源授权与最小特权

为所有人工智能资源实施细粒度访问控制，采用明确的权限模型和审计跟踪。

 #5.2.1    等级: 1    角色: D/V
 验证每个AI资源（数据集、模型、端点、向量集合、嵌入索引、计算实例）是否实施基于角色的访问控制，且具有明确的允许列表和默认拒绝策略。
 #5.2.2    等级: 1    角色: D/V
 验证服务账户默认执行最小权限原则，初始权限为只读，且写权限需有书面业务理由证明。
 #5.2.3    等级: 1    角色: V
 验证所有访问控制修改是否与已批准的变更请求相关联，并且以不可变的方式记录时间戳、执行者身份、资源标识符和权限差异。
 #5.2.4    等级: 2    角色: D
 验证数据分类标签（PII、PHI、出口管制、专有）是否自动传播到派生资源（嵌入、提示缓存、模型输出），并且策略执行是否一致。
 #5.2.5    等级: 2    角色: D/V
 验证未经授权的访问尝试和权限提升事件是否在5分钟内触发带有上下文元数据的实时警报，并发送到SIEM系统。

---

### C5.3 动态策略评估

部署基于属性的访问控制（ABAC）引擎，实现具有审计功能的上下文感知授权决策。

 #5.3.1    等级: 1    角色: D/V
 验证授权决策是否外部化到一个专用的策略引擎（如 OPA、Cedar 或同等产品），并通过带有加密完整性保护的认证 API 进行访问。
 #5.3.2    等级: 1    角色: D/V
 验证策略在运行时评估动态属性，包括用户许可级别、资源敏感性分类、请求上下文、租户隔离和时间限制。
 #5.3.3    等级: 2    角色: D
 验证策略定义在生产部署前经过版本控制、同行评审，并通过持续集成/持续交付（CI/CD）管道中的自动化测试进行验证。
 #5.3.4    等级: 2    角色: V
 验证策略评估结果是否包含结构化的决策理由，并传输到 SIEM 系统以进行关联分析和合规性报告。
 #5.3.5    等级: 3    角色: D/V
 验证策略缓存的存活时间（TTL）值，对于高敏感性资源不超过5分钟，对于具有缓存失效功能的标准资源不超过1小时。

---

### C5.4 查询时安全强制执行

在数据库层实施安全控件，应用强制过滤和行级安全策略。

 #5.4.1    等级: 1    角色: D/V
 验证所有向量数据库和SQL查询均包含强制的安全筛选条件（租户ID、敏感标签、用户范围），且这些筛选条件由数据库引擎层面强制执行，而非应用程序代码中实现。
 #5.4.2    等级: 1    角色: D/V
 验证所有向量数据库、搜索索引和训练数据集的行级安全（RLS）策略和字段级掩码已启用，并且具有策略继承功能。
 #5.4.3    等级: 2    角色: D
 验证失败的授权评估将通过立即中止查询并返回明确的授权错误代码来防止“混淆代理攻击”，而不是返回空结果集。
 #5.4.4    等级: 2    角色: V
 验证策略评估延迟是否被持续监控，并对可能导致授权绕过的超时条件设置自动警报。
 #5.4.5    等级: 3    角色: D/V
 验证查询重试机制是否重新评估授权策略，以考虑活动用户会话中的动态权限变更。

---

### C5.5 输出过滤与数据泄露防护

部署后处理控制以防止未经授权的数据泄露在AI生成的内容中。

 #5.5.1    等级: 1    角色: D/V
 验证推理后过滤机制是否在将内容交付给请求者之前扫描并删除未经授权的个人身份信息（PII）、机密信息和专有数据。
 #5.5.2    等级: 1    角色: D/V
 验证模型输出中的引用、参考文献和来源归属是否符合调用方权限，若检测到未授权访问则予以删除。
 #5.5.3    等级: 2    角色: D
 根据用户权限级别和数据分类，验证是否强制执行输出格式限制（如清理过的PDF、去除元数据的图像、批准的文件类型）。
 #5.5.4    等级: 2    角色: V
 验证编辑算法是确定性的、受版本控制的，并保持审计日志以支持合规性调查和取证分析。
 #5.5.5    等级: 3    角色: V
 验证高风险编辑事件是否生成包含原始内容的加密哈希的自适应日志，以便进行取证检索且不暴露数据。

---

### C5.6 多租户隔离

确保在共享的人工智能基础设施中租户之间的加密和逻辑隔离。

 #5.6.1    等级: 1    角色: D/V
 验证内存空间、嵌入存储、缓存条目和临时文件是否按租户进行命名空间隔离，并在租户删除或会话终止时进行安全清除。
 #5.6.2    等级: 1    角色: D/V
 验证每个 API 请求都包含经过身份验证的租户标识符，并对其进行加密验证以匹配会话上下文和用户权限。
 #5.6.3    等级: 2    角色: D
 验证网络策略是否针对服务网格和容器编排平台中的跨租户通信实施了默认拒绝规则。
 #5.6.4    等级: 3    角色: D
 验证使用客户管理密钥（CMK）支持的各租户加密密钥的唯一性，并确保租户数据存储之间的加密隔离。

---

### C5.7 自主代理授权

通过作用域能力令牌和持续授权来控制人工智能代理和自主系统的权限。

 #5.7.1    等级: 1    角色: D/V
 验证自治代理是否接收了范围限定的能力令牌，这些令牌明确列出了允许的操作、可访问的资源、时间限制和操作约束。
 #5.7.2    等级: 1    角色: D/V
 验证高风险功能（文件系统访问、代码执行、外部API调用、财务交易）默认是否被禁用，并且激活这些功能是否需要明确授权及业务理由。
 #5.7.3    等级: 2    角色: D
 验证能力令牌是否绑定到用户会话，包含加密完整性保护，并确保它们无法在离线场景中被持久化或重用。
 #5.7.4    等级: 2    角色: V
 验证代理发起的操作通过具有完整上下文评估和审计日志的 ABAC 策略引擎进行二次授权。
 #5.7.5    等级: 3    角色: V
 验证代理错误条件和异常处理是否包含能力范围信息，以支持事件分析和取证调查。

---

### 参考文献

#### 标准与框架

NIST SP 800-63-3: Digital Identity Guidelines
Zero Trust Architecture – NIST SP 800-207
OWASP Application Security Verification Standard (AISVS)
​
#### 实施指南

Identity and Access Management in the AI Era: 2025 Guide – IDSA
Attribute-Based Access Control with OPA – Permify
How We Designed Cedar to Be Intuitive, Fast, and Safe – AWS
​
#### 人工智能专用安全

Row Level Security in Vector DBs for RAG – Bluetuple.ai
Tenant Isolation in Multi-Tenant Systems – WorkOS
Handling AI Agent Permissions – Stytch
OWASP Top 10 for Large Language Model Applications

## C6 模型、框架和数据的供应链安全

### 控制目标

AI供应链攻击利用第三方模型、框架或数据集来嵌入后门、偏见或可利用的代码。这些控制措施提供端到端的源头追踪、漏洞管理和监控，以保护整个模型生命周期。

---

### C6.1 预训练模型审查与来源追踪

在进行任何微调或部署之前，评估并验证第三方模型的来源、许可和隐藏行为。

 #6.1.1    等级: 1    角色: D/V
 验证每个第三方模型组件都包含一个签名的来源记录，标识源代码仓库和提交哈希。
 #6.1.2    等级: 1    角色: D/V
 确保在导入模型之前，使用自动化工具扫描模型是否包含恶意层或木马触发器。
 #6.1.3    等级: 2    角色: D
 验证迁移学习微调通过对抗性评估，以检测隐藏行为。
 #6.1.4    等级: 2    角色: V
 验证模型许可证、出口控制标签和数据来源声明是否已记录在 ML-BOM 条目中。
 #6.1.5    等级: 3    角色: D/V
 验证高风险模型（公开上传的权重、未经验证的创建者）在人工审核和签署前保持隔离状态。

---

### C6.2 框架与库扫描

持续扫描机器学习框架和库中的CVE（公共漏洞与暴露）和恶意代码，以保持运行时堆栈的安全。

 #6.2.1    等级: 1    角色: D/V
 验证 CI 流水线是否对 AI 框架和关键库运行依赖扫描器。
 #6.2.2    等级: 1    角色: D/V
 验证关键漏洞（CVSS ≥ 7.0）是否阻止晋升到生产镜像。
 #6.2.3    等级: 2    角色: D
 验证静态代码分析是否在派生或供应的机器学习库上运行。
 #6.2.4    等级: 2    角色: V
 验证框架升级提案是否包含引用公共CVE信息源的安全影响评估。
 #6.2.5    等级: 3    角色: V
 验证运行时传感器是否能够对偏离签名SBOM的意外动态库加载发出警报。

---

### C6.3 依赖固定与验证

将每个依赖项固定到不可变的摘要，并重现构建以保证生成完全相同且无篡改的工件。

 #6.3.1    等级: 1    角色: D/V
 验证所有包管理器是否通过锁文件强制执行版本固定。
 #6.3.2    等级: 1    角色: D/V
 验证在容器引用中使用的是不可变的摘要而不是可变的标签。
 #6.3.3    等级: 2    角色: D
 验证可重复构建检查是否在持续集成运行中比较哈希值以确保输出一致。
 #6.3.4    等级: 2    角色: V
 验证构建证明已存储18个月以确保审计追溯性。
 #6.3.5    等级: 3    角色: D
 验证过期的依赖是否会触发自动拉取请求以更新或分叉固定版本。

---

### C6.4 可信来源强制执行

仅允许从经过密码学验证、组织批准的来源下载制品，阻止所有其他来源。

 #6.4.1    等级: 1    角色: D/V
 验证模型权重、数据集和容器仅从批准的域或内部注册表下载。
 #6.4.2    等级: 1    角色: D/V
 验证 Sigstore/Cosign 签名在工件被本地缓存之前是否确认发布者身份。
 #6.4.3    等级: 2    角色: D
 验证出口代理阻止未经过身份验证的工件下载，以执行可信来源策略。
 #6.4.4    等级: 2    角色: V
 验证存储库允许列表是否每季度审查一次，并提供每个条目的业务理由作为证据。
 #6.4.5    等级: 3    角色: V
 验证策略违规是否触发工件的隔离以及相关管道运行的回滚。

---

### C6.5 第三方数据集风险评估

评估外部数据集的投毒情况、偏差和法律合规性，并在其整个生命周期内进行监控。

 #6.5.1    等级: 1    角色: D/V
 验证外部数据集是否经过投毒风险评分（例如，数据指纹识别、异常值检测）。
 #6.5.2    等级: 1    角色: D
 在数据集批准之前，验证偏差指标（人口统计平等性、机会均等）是否已计算。
 #6.5.3    等级: 2    角色: V
 验证数据集的来源和许可条款是否被记录在 ML-BOM 条目中。
 #6.5.4    等级: 2    角色: V
 验证定期监控是否能够检测托管数据集中的漂移或损坏。
 #6.5.5    等级: 3    角色: D
 在训练之前，验证通过自动清理已移除禁止内容（版权信息、个人身份信息）。

---

### C6.6 供应链攻击监控

通过CVE源、审计日志分析和红队模拟，及早发现供应链威胁。

 #6.6.1    等级: 1    角色: V
 验证 CI/CD 审计日志是否流向 SIEM 以检测异常的软件包拉取或被篡改的构建步骤。
 #6.6.2    等级: 2    角色: D
 确认事件响应剧本中包含针对受损模型或库的回滚流程。
 #6.6.3    等级: 3    角色: V
 验证威胁情报增强是否在警报分流中标记了特定于机器学习的指标（例如，模型投毒的IoC）。

---

### C6.7 模型工件的机器学习物料清单 (ML-BOM)

生成并签署详细的专用于机器学习的软体物料清单（ML-BOM），以便下游使用者在部署时能够验证组件的完整性。

 #6.7.1    等级: 1    角色: D/V
 验证每个模型工件是否发布了 ML-BOM，其中列出了数据集、权重、超参数和许可证。
 #6.7.2    等级: 1    角色: D/V
 验证在持续集成(CI)中，ML-BOM 生成和 Cosign 签名是自动化的，并且是合并所必需的。
 #6.7.3    等级: 2    角色: D
 验证如果任何组件元数据（哈希、许可证）缺失，ML-BOM 完整性检查会导致构建失败。
 #6.7.4    等级: 2    角色: V
 验证下游消费者是否能够通过 API 查询 ML-BOM，以在部署时验证导入的模型。
 #6.7.5    等级: 3    角色: V
 验证 ML-BOM 是否进行版本控制和差异比较，以检测未经授权的修改。

---

### 参考文献

ML Supply Chain Compromise – MITRE ATLAS
Supply‑chain Levels for Software Artifacts (SLSA)
CycloneDX – Machine Learning Bill of Materials
What is Data Poisoning? – SentinelOne
Transfer Learning Attack – OWASP ML Security Top 10
AI Data Security Best Practices – CISA
Secure CI/CD Supply Chain – Sumo Logic
AI & Transparency: Protect ML Models – ReversingLabs
SBOM Overview – CISA
Training Data Poisoning Guide – Lakera.ai
Dependency Pinning for Reproducible Python – Medium

## C7 模型行为、输出控制与安全保障

### 控制目标

模型输出必须具有结构化、可靠、安全、可解释性，并在生产环境中持续监控。这样可以减少幻想、隐私泄露、有害内容和失控行为，同时提升用户信任和合规性。

---

### C7.1 输出格式强制执行

严格的模式、受限的解码和后续验证在内容传播之前阻止了格式错误或恶意内容。

 #7.1.1    等级: 1    角色: D/V
 验证系统提示中是否提供了响应模式（例如，JSON Schema），并且每个输出都自动进行验证；不符合规范的输出将触发修复或拒绝。
 #7.1.2    等级: 1    角色: D/V
 验证已启用受限解码（停止令牌、正则表达式、最大令牌数），以防止溢出或提示注入侧信道。
 #7.1.3    等级: 2    角色: D/V
 验证下游组件将输出视为不受信任的，并根据模式或注入安全的反序列化器对其进行验证。
 #7.1.4    等级: 3    角色: V
 验证不正确输出事件是否被记录、限速，并呈现于监控系统。

---

### C7.2 幻觉检测与缓解

不确定性估计和回退策略抑制了虚构答案。

 #7.2.1    等级: 1    角色: D/V
 验证标记级对数概率、集成自洽性或微调后的幻觉检测器是否为每个答案分配置信度评分。
 #7.2.2    等级: 1    角色: D/V
 验证低于可配置置信度阈值的响应是否触发回退工作流程（例如，增强检索生成、二级模型或人工审查）。
 #7.2.3    等级: 2    角色: D/V
 验证幻觉事件是否带有根本原因元数据标记，并输入到事后分析和微调流程中。
 #7.2.4    等级: 3    角色: D/V
 确保在重大模型或知识库更新后，阈值和检测器已重新校准。
 #7.2.5    等级: 3    角色: V
 验证仪表盘可视化是否跟踪幻觉率。

---

### C7.3 输出安全与隐私过滤

策略过滤器和红队覆盖保护用户和机密数据。

 #7.3.1    等级: 1    角色: D/V
 验证生成前和生成后分类器是否阻止符合政策的仇恨、骚扰、自残、极端主义和性露骨内容。
 #7.3.2    等级: 1    角色: D/V
 验证每个响应中是否运行了PII/PCI检测和自动编辑；违规将引发隐私事故。
 #7.3.3    等级: 2    角色: D
 验证保密标签（例如，商业机密）是否跨模态传播，以防止在文本、图像或代码中泄露。
 #7.3.4    等级: 3    角色: D/V
 验证过滤器绕过尝试或高风险分类是否需要二次审批或用户重新身份验证。
 #7.3.5    等级: 3    角色: D/V
 验证过滤阈值是否反映法律管辖区以及用户年龄/角色的上下文。

---

### C7.4 输出与操作限制

速率限制和审批门控防止滥用和过度自治。

 #7.4.1    等级: 1    角色: D
 验证每个用户和每个 API 密钥的配额是否限制请求、令牌和成本，并在遇到 429 错误时实行指数退避。
 #7.4.2    等级: 1    角色: D/V
 验证特权操作（文件写入、代码执行、网络调用）是否需要基于策略的审批或人工参与。
 #7.4.3    等级: 2    角色: D/V
 验证跨模态一致性检查确保为同一请求生成的图像、代码和文本不能被用来传递恶意内容。
 #7.4.4    等级: 2    角色: D
 验证代理委托深度、递归限制和允许的工具列表是否已明确配置。
 #7.4.5    等级: 3    角色: V
 验证违规限制是否会触发用于SIEM摄取的结构化安全事件。

---

### C7.5 输出可解释性

透明信号提升用户信任和内部调试效率。

 #7.5.1    等级: 2    角色: D/V
 当风险评估认为适当时，验证是否显示面向用户的置信度分数或简要推理摘要。
 #7.5.2    等级: 2    角色: D/V
 验证生成的解释避免泄露敏感的系统提示或专有数据。
 #7.5.3    等级: 3    角色: D
 验证系统是否捕获了令牌级别的对数概率或注意力图，并将其存储以供授权检查。
 #7.5.4    等级: 3    角色: V
 确保可解释性工件与模型版本一起进行版本控制，以便审计。

---

### C7.6 监控集成

实时可观察性关闭了开发与生产之间的闭环。

 #7.6.1    等级: 1    角色: D
 验证指标（模式违规、幻觉率、毒性、个人身份信息泄露、延迟、成本）是否流向中央监控平台。
 #7.6.2    等级: 1    角色: V
 验证是否为每个安全指标定义了警报阈值，并设有值班升级路径。
 #7.6.3    等级: 2    角色: V
 验证仪表板是否将输出异常与模型/版本、功能标志和上游数据变化关联起来。
 #7.6.4    等级: 2    角色: D/V
 验证监控数据是否反馈回已记录的 MLOps 工作流程中，用于重新训练、微调或规则更新。
 #7.6.5    等级: 3    角色: V
 验证监控管道是否经过渗透测试并实施访问控制，以避免敏感日志泄露。

---

### 7.7 生成媒体安全措施

通过执行政策约束、输出验证和可追溯性，确保 AI 系统不生成非法、有害或未经授权的媒体内容。

 #7.7.1    等级: 1    角色: D/V
 验证系统提示和用户指令是否明确禁止生成非法、有害或未经同意的深度伪造媒体（例如，图像、视频、音频）。
 #7.7.2    等级: 2    角色: D/V
 验证提示是否被过滤，以防止生成冒充、性露骨的深度伪造或未经同意展示真实个人的媒体。
 #7.7.3    等级: 2    角色: V
 验证系统是否使用感知哈希、水印检测或指纹识别来防止未经授权的版权媒体复制。
 #7.7.4    等级: 3    角色: D/V
 验证所有生成的媒体是否经过密码学签名、水印处理，或嵌入防篡改的溯源元数据，以便下游可追溯。
 #7.7.5    等级: 3    角色: V
 验证绕过尝试（例如，提示混淆、俚语、对抗性措辞）是否被检测、记录并进行速率限制；重复滥用行为应被报告到监控系统。

### 参考文献

NIST AI Risk Management Framework
ISO/IEC 42001:2023 – AI Management System
OWASP Top-10 for Large Language Model Applications (2025)
Improper Output Handling – OWASP LLM05:2025
Practical Techniques to Constrain LLM Output
Dataiku – Structured Text Generation Guide
VL-Uncertainty: Detecting Hallucinations
HaDeMiF: Hallucination Detection & Mitigation
Building Confidence in LLM Outputs
Explainable AI & LLMs
LLM Red-Teaming Guide
Sensitive Information Disclosure in LLMs
LangChain – Chat Model Rate Limiting
OpenAI Rate-Limit & Exponential Back-off
Arize AI – LLM Observability Platform

## C8存储、嵌入与向量数据库安全

### 控制目标

嵌入和向量存储作为现代人工智能系统的“活记忆”，不断接受用户提供的数据，并通过检索增强生成（RAG）机制将其重新引入模型上下文。如果不加以管理，这种记忆可能会泄露个人身份信息（PII）、违反同意协议，或被反向利用来重建原始文本。该控制措施系列的目标是强化记忆管道和向量数据库，确保访问采用最小权限原则，嵌入具有隐私保护功能，存储的向量具备过期机制或可按需撤销，以及保证每个用户的记忆信息不会污染其他用户的提示或生成内容。

---

### C8.1 内存和 RAG 索引的访问控制

对每个向量集合实施细粒度访问控制。

 #8.1.1    等级: 1    角色: D/V
 验证行/命名空间级访问控制规则是否限制每个租户、集合或文档标签的插入、删除和查询操作。
 #8.1.2    等级: 1    角色: D/V
 验证 API 密钥或 JWT 是否携带范围限定的声明（例如，集合 ID、操作动词），并且至少每季度轮换一次。
 #8.1.3    等级: 2    角色: D/V
 验证特权升级尝试（例如，跨命名空间相似性查询）是否在5分钟内被检测并记录到SIEM中。
 #8.1.4    等级: 2    角色: D/V
 验证向量数据库审计日志中记录的主体标识符、操作、向量ID/命名空间、相似度阈值和结果数量。
 #8.1.5    等级: 3    角色: V
 验证每当引擎升级或索引分片规则更改时，访问决策是否经过绕过漏洞的测试。

---

### C8.2 嵌入清理与验证

在向量化之前，对文本进行预筛选以识别个人身份信息（PII），并进行遮盖或假名化，随后可选择对嵌入进行后处理以去除残留信号。

 #8.2.1    等级: 1    角色: D/V
 验证通过自动分类器检测的个人身份信息（PII）和受监管数据是否在嵌入前被掩码、标记化或丢弃。
 #8.2.2    等级: 1    角色: D
 验证嵌入管道是否拒绝或隔离包含可执行代码或非 UTF-8 产物的输入，这些输入可能会污染索引。
 #8.2.3    等级: 2    角色: D/V
 验证是否对与任何已知个人身份信息（PII）标记的距离低于可配置阈值的句子嵌入应用了局部或度量差分隐私清理。
 #8.2.4    等级: 2    角色: V
 验证清理效果（例如，个人身份信息(PII)删除的召回率、语义漂移）是否至少每半年针对基准语料库进行一次验证。
 #8.2.5    等级: 3    角色: D/V
 验证清理配置是否受版本控制，并且变更经过同行评审。

---

### C8.3 内存过期、撤销与删除

GDPR“被遗忘权”和类似法律要求及时删除；因此，向量存储必须支持TTL、硬删除和墓碑标记，以确保被撤销的向量无法恢复或重新索引。

 #8.3.1    等级: 1    角色: D/V
 验证每个向量和元数据记录是否具有 TTL 或被自动清理作业认可的明确保留标签。
 #8.3.2    等级: 1    角色: D/V
 验证用户发起的删除请求是否在30天内清除向量、元数据、缓存副本和派生索引。
 #8.3.3    等级: 2    角色: D
 验证如果硬件支持，逻辑删除后是否紧跟存储块的加密销毁，或者通过密钥库密钥销毁进行处理。
 #8.3.4    等级: 3    角色: D/V
 验证过期向量在过期后500毫秒内被排除在最近邻搜索结果之外。

---

### C8.4 防止嵌入反演与泄露

最近的防御措施——噪声叠加、投影网络、隐私神经元扰动和应用层加密——可以将令牌级反演率降低到5%以下。

 #8.4.1    等级: 1    角色: V
 确认存在涵盖反演攻击、成员资格攻击和属性推断攻击的正式威胁模型，并且该模型每年进行审查。
 #8.4.2    等级: 2    角色: D/V
 验证应用层加密或可搜索加密是否能够保护向量免受基础设施管理员或云工作人员的直接读取。
 #8.4.3    等级: 3    角色: V
 验证防御参数（DP的ε，噪声σ，投影秩k）在隐私保护≥99%令牌保护与效用≤3%准确率损失之间的平衡。
 #8.4.4    等级: 3    角色: D/V
 验证反转鲁棒性指标是否作为模型更新的发布门控的一部分，并定义回归预算。

---

### C8.5 针对用户特定内存的范围执行

跨租户泄露仍然是生成式增强检索（RAG）中的重大风险：过滤不当的相似性查询可能会暴露其他客户的私有文档。

 #8.5.1    等级: 1    角色: D/V
 验证每个检索查询在传递给大语言模型提示之前，是否通过租户/用户ID进行了后过滤。
 #8.5.2    等级: 1    角色: D
 验证集合名称或命名空间 ID 是否针对每个用户或租户进行了加盐处理，以防止向量在不同作用域中发生冲突。
 #8.5.3    等级: 2    角色: D/V
 验证在可配置距离阈值以上但超出调用者范围的相似度结果是否被丢弃并触发安全警报。
 #8.5.4    等级: 2    角色: V
 验证多租户压力测试是否模拟了试图检索超出范围文档的对抗性查询，并证明无泄漏。
 #8.5.5    等级: 3    角色: D/V
 验证加密密钥是否按租户划分，确保即使在物理存储共享的情况下也实现加密隔离。

---

### C8.6 高级内存系统安全

针对复杂内存架构（包括情景记忆、语义记忆和工作记忆）设立的安全控制，涵盖特定的隔离和验证要求。

 #8.6.1    等级: 1    角色: D/V
 验证不同类型的记忆（情节记忆、语义记忆、工作记忆）是否具有隔离的安全上下文，采用基于角色的访问控制，使用独立的加密密钥，并为每种记忆类型记录访问模式。
 #8.6.2    等级: 2    角色: D/V
 验证记忆整合过程是否包含安全验证，以通过内容清理、来源验证和存储前的完整性检查，防止恶意记忆的注入。
 #8.6.3    等级: 2    角色: D/V
 验证内存检索查询是否经过验证和清理，以防止通过查询模式分析、访问控制执行和结果过滤提取未经授权的信息。
 #8.6.4    等级: 3    角色: D/V
 通过使用密钥删除、多次覆盖或带有验证证书的基于硬件的安全删除，验证内存遗忘机制能够以密码擦除保证安全地删除敏感信息。
 #8.6.5    等级: 3    角色: D/V
 验证内存系统完整性是否通过校验和、审计日志以及当内存内容在正常操作之外发生变化时自动报警来持续监控未授权的修改或损坏。

---

### 参考文献

Vector database security: Pinecone – IronCore Labs
Securing the Backbone of AI: Safeguarding Vector Databases and Embeddings – Privacera
Enhancing Data Security with RBAC of Qdrant Vector Database – AI Advances
Mitigating Privacy Risks in LLM Embeddings from Embedding Inversion – arXiv
DPPN: Detecting and Perturbing Privacy-Sensitive Neurons – OpenReview
Art. 17 GDPR – Right to Erasure
Sensitive Data in Text Embeddings Is Recoverable – Tonic.ai
PII Identification and Removal – NVIDIA NeMo Docs
De-identifying Sensitive Data – Google Cloud DLP
Remove PII from Conversations Using Sensitive Information Filters – AWS Bedrock Guardrails
Think Your RAG Is Secure? Think Again – Medium
Design a Secure Multitenant RAG Inferencing Solution – Microsoft Learn
Best Practices for Multi-Tenancy RAG with Milvus – Milvus Blog

## 9 自主编排与代理行动安全

### 控制目标

确保自主或多智能体人工智能系统只能执行明确意图的、经过认证的、可审计的且在成本和风险阈值范围内的操作。这防范了自主系统被攻破、工具滥用、智能体循环检测、通信劫持、身份欺骗、群体操控和意图操控等威胁。

---

### 9.1 代理任务规划与递归预算

限制递归计划的执行速度，并强制在特权操作时进行人工检查。

 #9.1.1    等级: 1    角色: D/V
 验证最大递归深度、宽度、实际运行时间、令牌数以及每次代理执行的货币成本是否集中配置并进行版本控制。
 #9.1.2    等级: 1    角色: D/V
 验证特权或不可逆操作（例如，代码提交、资金转移）在执行前必须通过可审计的渠道由人工明确批准。
 #9.1.3    等级: 2    角色: D
 验证实时资源监控器在任何预算阈值被超出时触发断路器中断，从而停止进一步的任务扩展。
 #9.1.4    等级: 2    角色: D/V
 验证电路断路器事件是否记录了代理ID、触发条件和捕获的计划状态以供取证审查。
 #9.1.5    等级: 3    角色: V
 验证安全测试是否涵盖预算耗尽和失控计划场景，确认能够安全停止且无数据丢失。
 #9.1.6    等级: 3    角色: D
 验证预算策略是否以策略即代码的形式表达，并在 CI/CD 中执行以阻止配置漂移。

---

### 9.2 工具插件沙箱化

隔离工具交互以防止未授权的系统访问或代码执行。

 #9.2.1    等级: 1    角色: D/V
 验证每个工具/插件是否在操作系统、容器或 WASM 级沙箱内执行，并采用最小权限的文件系统、网络和系统调用策略。
 #9.2.2    等级: 1    角色: D/V
 验证沙箱资源配额（CPU、内存、磁盘、网络出口）和执行超时是否被强制执行并记录。
 #9.2.3    等级: 2    角色: D/V
 验证工具二进制文件或描述符是否经过数字签名；在加载之前验证签名。
 #9.2.4    等级: 2    角色: V
 验证沙箱遥测是否发送到 SIEM；异常情况（例如，尝试的出站连接）会触发警报。
 #9.2.5    等级: 3    角色: V
 确保高风险插件在生产部署前经过安全审查和渗透测试。
 #9.2.6    等级: 3    角色: D/V
 验证沙盒逃逸尝试是否被自动阻止，并将违规插件隔离以待调查。

---

### 9.3 自主循环与成本界限

检测并阻止无控制的代理间递归和成本爆炸。

 #9.3.1    等级: 1    角色: D/V
 验证代理之间的调用是否包含跳数限制或生存时间（TTL），并且运行时会递减并执行该限制。
 #9.3.2    等级: 2    角色: D
 验证代理是否维护唯一的调用图 ID，以便识别自我调用或循环模式。
 #9.3.3    等级: 2    角色: D/V
 验证累计计算单元和支出计数器是否按请求链跟踪；超出限制将中止该链。
 #9.3.4    等级: 3    角色: V
 验证形式分析或模型检测是否证明了代理协议中不存在无界递归。
 #9.3.5    等级: 3    角色: D
 验证循环中止事件是否生成警报并提供持续改进指标。

---

### 9.4 协议级误用防护

在代理与外部系统之间建立安全的通信渠道，以防止劫持或篡改。

 #9.4.1    等级: 1    角色: D/V
 验证所有代理到工具和代理到代理的消息是否经过身份验证（例如，双向 TLS 或 JWT）并且端到端加密。
 #9.4.2    等级: 1    角色: D
 验证模式是否严格校验；未知字段或格式错误的消息会被拒绝。
 #9.4.3    等级: 2    角色: D/V
 验证完整性校验（MAC或数字签名）是否涵盖整个消息负载，包括工具参数。
 #9.4.4    等级: 2    角色: D
 验证协议层是否实施了重放保护（随机数或时间戳窗口）。
 #9.4.5    等级: 3    角色: V
 验证协议实现是否经过模糊测试和静态分析，以检测注入或反序列化漏洞。

---

### 9.5 代理身份与防篡改证据

确保操作可追溯且修改可检测。

 #9.5.1    等级: 1    角色: D/V
 验证每个代理实例是否具有唯一的加密身份（密钥对或硬件根凭证）。
 #9.5.2    等级: 2    角色: D/V
 验证所有代理操作均已签名并带有时间戳；日志包含签名以实现不可否认性。
 #9.5.3    等级: 2    角色: V
 验证防篡改日志是否存储在仅追加或一次性写入的媒介中。
 #9.5.4    等级: 3    角色: D
 验证身份密钥是否按定义的时间表和在遭到泄露指示时进行轮换。
 #9.5.5    等级: 3    角色: D/V
 验证伪造或密钥冲突尝试是否会立即触发对受影响代理的隔离。

---

### 9.6 多智能体群体风险降低

通过隔离和正式安全建模来缓解集体行为风险。

 #9.6.1    等级: 1    角色: D/V
 验证在不同安全域中运行的代理在隔离的运行时沙箱或网络分段中执行。
 #9.6.2    等级: 3    角色: V
 验证群体行为在部署前已被建模并形式化验证其活性和安全性。
 #9.6.3    等级: 3    角色: D
 验证运行时监视器是否能够检测到新出现的不安全模式（例如，振荡、死锁）并启动纠正措施。

---

### 9.7 用户与工具认证/授权

为每个由代理触发的操作实施强有力的访问控制。

 #9.7.1    等级: 1    角色: D/V
 验证代理作为一流主体对下游系统进行身份验证，绝不重复使用终端用户凭证。
 #9.7.2    等级: 2    角色: D
 验证细粒度授权策略是否限制代理可以调用的工具以及它可以提供的参数。
 #9.7.3    等级: 2    角色: V
 验证权限检查是否在每次调用时重新评估（持续授权），而不仅仅是在会话开始时。
 #9.7.4    等级: 3    角色: D
 验证委托权限是否会自动过期，并在超时或范围更改后需要重新同意。

---

### 9.8 代理与代理之间的通信安全

对所有代理间消息进行加密和完整性保护，以防止窃听和篡改。

 #9.8.1    等级: 1    角色: D/V
 验证代理通道必须使用相互认证和完美前向保密加密（例如 TLS 1.3）。
 #9.8.2    等级: 1    角色: D
 验证消息完整性和来源在处理之前已被确认；失败时触发警报并丢弃消息。
 #9.8.3    等级: 2    角色: D/V
 验证通信元数据（时间戳、序列号）是否被记录，以支持法医重建。
 #9.8.4    等级: 3    角色: V
 验证形式化验证或模型检测确认协议状态机无法进入不安全状态。

---

### 9.9 意图验证与约束执行

验证代理操作是否符合用户的陈述意图和系统约束。

 #9.9.1    等级: 1    角色: D
 验证预执行约束求解器是否根据硬编码的安全和政策规则检查提议的操作。
 #9.9.2    等级: 2    角色: D/V
 验证高影响操作（财务性、破坏性、隐私敏感性）是否需要发起用户的明确意图确认。
 #9.9.3    等级: 2    角色: V
 验证后置条件检查是否确认已完成的操作实现了预期效果且无副作用；若有不符则触发回滚。
 #9.9.4    等级: 3    角色: V
 验证形式方法（例如，模型检验、定理证明）或基于属性的测试是否证明代理计划满足所有声明的约束。
 #9.9.5    等级: 3    角色: D
 验证意图不匹配或约束违规事件是否促进持续改进循环和威胁情报共享。

---

### 9.10 代理推理策略安全

安全选择和执行包括ReAct、Chain-of-Thought和Tree-of-Thoughts方法在内的不同推理策略。

 #9.10.1    等级: 1    角色: D/V
 验证推理策略选择是否使用确定性标准（输入复杂度、任务类型、安全上下文），并确保在相同安全上下文中， 相同的输入产生相同的策略选择。
 #9.10.2    等级: 1    角色: D/V
 验证每种推理策略（ReAct、Chain-of-Thought、Tree-of-Thoughts）是否具有针对其认知方法的专用输入验证、输出清理和执行时间限制。
 #9.10.3    等级: 2    角色: D/V
 验证推理策略转换是否完整记录了上下文，包括输入特征、选择标准值和执行元数据，以便审计追踪重建。
 #9.10.4    等级: 2    角色: D/V
 验证思维树推理是否包括分支剪枝机制，当检测到策略违规、资源限制或安全边界时，终止探索。
 #9.10.5    等级: 2    角色: D/V
 验证 ReAct（推理-行动-观察）循环在每个阶段都包含验证检查点：推理步骤验证、行动授权以及观察净化，然后才继续下一步。
 #9.10.6    等级: 3    角色: D/V
 验证推理策略的性能指标（执行时间、资源使用、输出质量）在指标超出配置阈值时是否通过自动警报进行监控。
 #9.10.7    等级: 3    角色: D/V
 验证结合多种策略的混合推理方法是否保持了所有组成策略的输入验证和输出约束，且未绕过任何安全控制。
 #9.10.8    等级: 3    角色: D/V
 验证推理策略的安全测试是否包括使用格式错误的输入进行模糊测试、设计用于强制策略切换的对抗性提示，以及针对每种认知方法的边界条件测试。

---

### 9.11 代理生命周期状态管理与安全

通过加密审计跟踪和定义的恢复程序，实现安全代理初始化、状态转换和终止。

 #9.11.1    等级: 1    角色: D/V
 验证代理初始化包括使用硬件支持的凭证建立加密身份，以及包含代理ID、时间戳、配置哈希和初始化参数的不可变启动审计日志。
 #9.11.2    等级: 2    角色: D/V
 验证代理状态转换是否经过加密签名、时间戳标注，并且记录了完整的上下文信息，包括触发事件、前一个状态哈希、新状态哈希以及执行的安全验证。
 #9.11.3    等级: 2    角色: D/V
 验证代理关闭程序包括使用密码擦除或多遍覆盖进行安全内存擦除，凭证吊销并通知证书颁发机构，以及生成防篡改的终止证书。
 #9.11.4    等级: 3    角色: D/V
 验证代理恢复机制使用加密校验和（至少使用 SHA-256）来验证状态完整性，并在检测到损坏时自动回滚到已知良好状态，同时启用自动警报和人工批准要求。
 #9.11.5    等级: 3    角色: D/V
 验证代理持久化机制是否使用每个代理的 AES-256 密钥加密敏感状态数据，并在可配置的时间表（最大 90 天）上实现安全的密钥轮换，且支持零停机部署。

---

### 9.12 工具集成安全框架

针对动态工具加载、执行和结果验证的安全控制，配有明确的风险评估和审批流程。

 #9.12.1    等级: 1    角色: D/V
 验证工具描述符是否包含安全元数据，具体说明所需权限（读/写/执行）、风险级别（低/中/高）、资源限制（CPU、内存、网络）以及在工具清单中记录的验证要求。
 #9.12.2    等级: 1    角色: D/V
 验证工具执行结果是否根据预期的模式（JSON Schema，XML Schema）和安全策略（输出净化，数据分类）进行验证，并在集成前设置超时限制和错误处理程序。
 #9.12.3    等级: 2    角色: D/V
 验证工具交互日志是否包含详细的安全上下文，包括权限使用情况、数据访问模式、执行时间、资源消耗和返回代码，并采用结构化日志记录以便于SIEM集成。
 #9.12.4    等级: 2    角色: D/V
 验证动态工具加载机制是否使用公钥基础设施（PKI）验证数字签名，并在执行前实施带有沙箱隔离和权限验证的安全加载协议。
 #9.12.5    等级: 3    角色: D/V
 验证工具安全评估是否针对新版本自动触发，并包含强制性的审批关卡，涵盖静态分析、动态测试和安全团队审查，且具备有文件记录的审批标准和服务等级协议（SLA）要求。

---

#### 参考文献

MITRE ATLAS tactics ML09
Circuit-breaker research for AI agents — Zou et al., 2024
Trend Micro analysis of sandbox escapes in AI agents — Park, 2025
Auth0 guidance on human-in-the-loop authorization for agents — Martinez, 2025
Medium deep-dive on MCP & A2A protocol hijacking — ForAISec, 2025
Rapid7 fundamentals on spoofing attack prevention — 2024
Imperial College verification of swarm systems — Lomuscio et al.
NIST AI Risk Management Framework 1.0, 2023
WIRED security briefing on encryption best practices, 2024
OWASP Top 10 for LLM Applications, 2025
Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS
[How Is LLM Reasoning Distracted by Irrelevant Context?
An Analysis Using a Controlled Benchmark](https://www.arxiv.org/pdf/2505.18761)
Large Language Model Sentinel: LLM Agent for Adversarial Purification
Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents

## 10 对抗鲁棒性与隐私防护

### 控制目标

确保人工智能模型在面对规避、推断、提取或投毒攻击时保持可靠性、隐私保护和防滥用能力。

---

### 10.1 模型对齐与安全

防范有害或违反政策的输出。

 #10.1.1    等级: 1    角色: D/V
 验证对齐测试套件（红队提示、越狱探测、禁止内容）是否进行版本控制，并在每次模型发布时运行。
 #10.1.2    等级: 1    角色: D
 验证拒绝和安全完成护栏是否被执行。
 #10.1.3    等级: 2    角色: D/V
 验证自动评估器是否测量有害内容率并标记超过设定阈值的回归。
 #10.1.4    等级: 2    角色: D
 验证反越狱训练是否有文档记录且可复现。
 #10.1.5    等级: 3    角色: V
 验证正式的策略合规性证明或经过认证的监控是否涵盖关键领域。

---

### 10.2 对抗样本强化

提高对操纵输入的鲁棒性。强健的对抗训练和基准评分是当前的最佳实践。

 #10.2.1    等级: 1    角色: D
 确认项目代码库包含带有可复现种子的对抗训练配置。
 #10.2.2    等级: 2    角色: D/V
 验证对抗样本检测是否在生产流水线中触发阻断警报。
 #10.2.4    等级: 3    角色: V
 验证经过认证的鲁棒性证明或区间界限证书是否至少覆盖了最关键的分类。
 #10.2.5    等级: 3    角色: V
 验证回归测试使用自适应攻击以确认没有可测量的鲁棒性损失。

---

### 10.3 成员推断缓解

限制决定某条记录是否存在于训练数据中的能力。差分隐私和置信度分数掩蔽仍然是已知的最有效防御措施。

 #10.3.1    等级: 1    角色: D
 验证每次查询的熵正则化或温度调节是否减少了过度自信的预测。
 #10.3.2    等级: 2    角色: D
 验证训练过程中是否对敏感数据集采用了ε-界限差分隐私优化。
 #10.3.3    等级: 2    角色: V
 验证攻击模拟（影子模型或黑盒）在保留数据上的攻击AUC是否 ≤ 0.60。

---

### 10.4 模型反演抗性

防止私有属性的重构。最近的调查强调输出截断和差分隐私保证作为实用的防御措施。

 #10.4.1    等级: 1    角色: D
 确保敏感属性绝不被直接输出；在必要时，使用分桶或单向转换。
 #10.4.2    等级: 1    角色: D/V
 验证查询速率限制是否对来自同一主体的重复自适应查询进行节流。
 #10.4.3    等级: 2    角色: D
 验证模型是否采用了隐私保护噪声进行训练。

---

### 10.5 模型提取防御

检测和阻止未经授权的克隆。建议使用水印和查询模式分析。

 #10.5.1    等级: 1    角色: D
 验证推理网关是否强制执行针对模型记忆阈值调整的全局和每个API密钥的速率限制。
 #10.5.2    等级: 2    角色: D/V
 验证查询熵和输入多样性统计数据是否为自动抽取检测器提供支持。
 #10.5.3    等级: 2    角色: V
 验证在对疑似克隆体进行不超过 1 000 次查询时，脆弱或概率水印可以以 p < 0.01 的显著性水平被证明。
 #10.5.4    等级: 3    角色: D
 验证水印密钥和触发器集是否存储在硬件安全模块中，并每年轮换一次。
 #10.5.5    等级: 3    角色: V
 验证提取警报事件是否包含违规查询，并且与事件响应剧本集成。

---

### 10.6 推理时的中毒数据检测

识别并中和带有后门或被投毒的输入。

 #10.6.1    等级: 1    角色: D
 在模型推理之前，验证输入通过异常检测器（例如，STRIP、一致性评分）。
 #10.6.2    等级: 1    角色: V
 验证检测器阈值是否在干净/中毒的验证集上进行调优，以实现低于5%的误报率。
 #10.6.3    等级: 2    角色: D
 验证被标记为中毒的输入是否会触发软阻止和人工审核工作流。
 #10.6.4    等级: 2    角色: V
 验证探测器是否通过自适应的、无触发的后门攻击进行了压力测试。
 #10.6.5    等级: 3    角色: D
 验证检测效能指标是否已被记录，并定期使用最新威胁情报进行重新评估。

---

### 10.7 动态安全策略适应

基于威胁情报和行为分析的实时安全策略更新。

 #10.7.1    等级: 1    角色: D/V
 验证安全策略能够在不重启代理的情况下动态更新，同时保持策略版本的完整性。
 #10.7.2    等级: 2    角色: D/V
 验证策略更新是否由授权的安全人员进行加密签名，并在应用前进行验证。
 #10.7.3    等级: 2    角色: D/V
 验证动态策略变更是否包含完整的审计追踪记录，包括变更理由、审批链和回滚流程。
 #10.7.4    等级: 3    角色: D/V
 验证自适应安全机制是否根据风险上下文和行为模式调整威胁检测的敏感性。
 #10.7.5    等级: 3    角色: D/V
 验证策略适应决策的可解释性，并包含供安全团队审查的证据链。

---

### 10.8 基于反射的安全分析

通过代理自我反思和元认知分析进行安全验证。

 #10.8.1    等级: 1    角色: D/V
 验证智能体反思机制是否包括针对决策和行为的安全性自我评估。
 #10.8.2    等级: 2    角色: D/V
 验证反射输出是否经过验证，以防止对抗性输入操纵自我评估机制。
 #10.8.3    等级: 2    角色: D/V
 验证元认知安全分析是否能够识别智能体推理过程中的潜在偏见、操控或妥协。
 #10.8.4    等级: 3    角色: D/V
 验证基于反射的安全警告是否触发了增强监控和潜在的人为干预工作流程。
 #10.8.5    等级: 3    角色: D/V
 验证从安全反思中持续学习能否提高威胁检测能力，同时不影响合法功能的正常运行。

---

### 10.9 演进与自我改进安全

具有自我修改和进化能力的代理系统的安全控制措施。

 #10.9.1    等级: 1    角色: D/V
 验证自我修改能力是否仅限于指定的安全区域，并具有形式化验证边界。
 #10.9.2    等级: 2    角色: D/V
 确保在实施之前，对演进提案进行安全影响评估。
 #10.9.3    等级: 2    角色: D/V
 验证自我改进机制包括带有完整性验证的回滚功能。
 #10.9.4    等级: 3    角色: D/V
 验证元学习安全性是否防止了改进算法的对抗性操纵。
 #10.9.5    等级: 3    角色: D/V
 通过数学收敛性证明验证递归自我提升受形式安全约束的限制。

---

#### 参考文献

MITRE ATLAS adversary tactics for ML
NIST AI Risk Management Framework 1.0, 2023
OWASP Top 10 for LLM Applications, 2025
Adversarial Training: A Survey — Zhao et al., 2024
RobustBench adversarial-robustness benchmark
Membership-Inference & Model-Inversion Risk Survey, 2025
PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023
Model-Inversion Attacks & Defenses Survey — AI Review, 2025
Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024
Fragile Model Watermarking Survey — 2025
Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025
BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024

## 11 隐私保护与个人数据管理

### 控制目标

在整个人工智能生命周期——数据收集、训练、推理和事件响应中保持严格的隐私保障，确保个人数据仅在明确同意、最小必要范围、可验证删除和正式隐私保障的条件下被处理。

---

### 11.1 匿名化与数据最小化

 #11.1.1    等级: 1    角色: D/V
 验证直接识别符和准识别符是否已被删除或哈希处理。
 #11.1.2    等级: 2    角色: D/V
 验证自动审计是否测量k-匿名性/l-多样性，并在阈值低于政策时发出警报。
 #11.1.3    等级: 2    角色: V
 验证模型特征重要性报告，确保不存在超过 ε = 0.01 互信息的标识符泄露。
 #11.1.4    等级: 3    角色: V
 验证形式化证明或合成数据认证是否显示即使在链接攻击下，重新识别风险也 ≤ 0.05。

---

### 11.2 被遗忘权与删除执行

 #11.2.1    等级: 1    角色: D/V
 验证数据主体删除请求在30天以内的服务水平协议内传播到原始数据集、检查点、嵌入、日志和备份中。
 #11.2.2    等级: 2    角色: D
 验证“机器遗忘”程序是否通过认证的遗忘算法进行物理再训练或近似移除。
 #11.2.3    等级: 2    角色: V
 验证影子模型评估证明遗忘记录在消除学习后对输出的影响不足1%。
 #11.2.4    等级: 3    角色: V
 验证删除事件是否被不可变地记录并且可供监管机构审计。

---

### 11.3 差分隐私保护措施

 #11.3.1    等级: 2    角色: D/V
 验证隐私损失核算仪表板在累积ε超过政策阈值时是否发出警报。
 #11.3.2    等级: 2    角色: V
 验证黑盒隐私审计是否能在声明值的10%以内估计ε̂。
 #11.3.3    等级: 3    角色: V
 验证形式证明是否涵盖所有训练后微调和嵌入。

---

### 11.4 目的限制与范围蔓延保护

 #11.4.1    等级: 1    角色: D
 验证每个数据集和模型检查点是否都带有与原始同意一致的机器可读用途标签。
 #11.4.2    等级: 1    角色: D/V
 验证运行时监控器是否检测到与声明目的不一致的查询并触发软拒绝。
 #11.4.3    等级: 3    角色: D
 验证策略即代码门控是否阻止在未经DPIA审查的情况下将模型重新部署到新域。
 #11.4.4    等级: 3    角色: V
 验证正式的可追溯性证明，确保每个个人数据生命周期均在被同意的范围内。

---

### 11.5 同意管理与合法依据追踪

 #11.5.1    等级: 1    角色: D/V
 验证同意管理平台（CMP）是否记录每个数据主体的选择加入状态、目的和保留期限。
 #11.5.2    等级: 2    角色: D
 验证API是否暴露同意令牌；模型在推理前必须验证令牌范围。
 #11.5.3    等级: 2    角色: D/V
 验证被拒绝或撤回的同意是否在24小时内停止处理流程。

---

### 11.6 带有隐私控制的联邦学习

 #11.6.1    等级: 1    角色: D
 验证客户端更新在聚合前是否采用了局部差分隐私噪声添加。
 #11.6.2    等级: 2    角色: D/V
 验证训练指标具备差分隐私性，且绝不泄露单个客户端的损失。
 #11.6.3    等级: 2    角色: V
 确认启用了抗投毒聚合（例如，Krum/Trimmed-Mean）。
 #11.6.4    等级: 3    角色: V
 验证形式证明表明整体ε预算的效用损失少于5。

---

#### 参考文献

GDPR & AI Compliance Best Practices
EU Parliament Study on GDPR & AI, 2020
ISO 31700-1:2023 — Privacy by Design for Consumer Products
NIST Privacy Framework 1.1 (2025 Draft)
Machine Unlearning: Right-to-Be-Forgotten Techniques
A Survey of Machine Unlearning, 2024
Auditing DP-SGD — ArXiv 2024
DP-SGD Explained — PyTorch Blog
Purpose-Limitation for AI — IJLIT 2025
Data-Protection Considerations for AI — URM Consulting
Top Consent-Management Platforms, 2025
Secure Aggregation in DP Federated Learning — ArXiv 2024

## C12 监控、日志记录与异常检测

### 控制目标

本节提供了交付实时和取证可视化的要求，以展示模型及其他人工智能组件所见、所做及所返回的内容，从而能够检测、分类和学习威胁。

### C12.1 请求与响应日志记录

 #12.1.1    等级: 1    角色: D/V
 验证所有用户提示和模型响应是否都记录了适当的元数据（例如时间戳、用户ID、会话ID、模型版本）。
 #12.1.2    等级: 1    角色: D/V
 验证日志是否存储在安全的、具有访问控制的存储库中，并且具备适当的保留政策和备份程序。
 #12.1.3    等级: 1    角色: D/V
 验证日志存储系统是否实现了静态加密和传输加密，以保护日志中包含的敏感信息。
 #12.1.4    等级: 1    角色: D/V
 验证提示和输出中的敏感数据在记录之前是否自动被编辑或屏蔽，并且具有可配置的针对个人身份信息（PII）、凭证和专有信息的编辑规则。
 #12.1.5    等级: 2    角色: D/V
 验证策略决策和安全过滤操作是否被详细记录，以便审计和调试内容审核系统。
 #12.1.6    等级: 2    角色: D/V
 验证日志完整性是否通过例如加密签名或只写存储得到保护。

---

### C12.2 滥用检测与警报

 #12.2.1    等级: 1    角色: D/V
 验证系统是否使用基于签名的检测方法检测并警报已知的越狱模式、提示注入尝试和对抗性输入。
 #12.2.2    等级: 1    角色: D/V
 验证系统是否使用标准日志格式和协议与现有的安全信息和事件管理（SIEM）平台集成。
 #12.2.3    等级: 2    角色: D/V
 验证丰富的安全事件是否包含特定于人工智能的上下文，如模型标识符、置信度分数和安全过滤决策。
 #12.2.4    等级: 2    角色: D/V
 验证行为异常检测是否能够识别异常的对话模式、过多的重试尝试或系统性的探测行为。
 #12.2.5    等级: 2    角色: D/V
 验证实时警报机制在检测到潜在的策略违规或攻击尝试时是否通知安全团队。
 #12.2.6    等级: 2    角色: D/V
 验证是否包含用于检测特定于 AI 的威胁模式的自定义规则，包括协调的越狱尝试、提示注入活动和模型提取攻击。
 #12.2.7    等级: 3    角色: D/V
 验证自动化事件响应工作流是否能够隔离被攻破的模型，阻止恶意用户，并升级关键安全事件。

---

### C12.3 模型漂移检测

 #12.3.1    等级: 1    角色: D/V
 验证系统是否跟踪了基本性能指标，例如准确率、置信度评分、延迟和错误率，涵盖不同模型版本和时间段。
 #12.3.2    等级: 2    角色: D/V
 确认当性能指标超过预定义的降级阈值或与基线严重偏离时，自动警报能够触发。
 #12.3.3    等级: 2    角色: D/V
 验证幻觉检测监控器是否能够识别并标记模型输出中包含事实错误、不一致或捏造信息的实例。

---

### C12.4 性能与行为遥测

 #12.4.1    等级: 1    角色: D/V
 确保持续收集和监控包括请求延迟、令牌消耗、内存使用和吞吐量在内的运营指标。
 #12.4.2    等级: 1    角色: D/V
 验证成功率和失败率是否通过错误类型及其根本原因的分类进行跟踪。
 #12.4.3    等级: 2    角色: D/V
 验证资源利用率监控是否包括GPU/CPU使用率、内存消耗和存储需求，并在阈值超出时进行报警。

---

### C12.5 人工智能事件响应规划与执行

 #12.5.1    等级: 1    角色: D/V
 验证事件响应计划是否专门涵盖与人工智能相关的安全事件，包括模型被破坏、数据中毒和对抗性攻击。
 #12.5.2    等级: 2    角色: D/V
 确保事件响应团队能够使用专门针对人工智能的取证工具和专业知识，以调查模型行为和攻击向量。
 #12.5.3    等级: 3    角色: D/V
 验证事故后分析是否包括模型再训练的考虑、安全过滤器的更新以及将经验教训整合到安全控制中。

---

### C12.5 人工智能性能下降检测

监测并检测 AI 模型性能和质量随时间的下降情况。

 #12.5.1    等级: 1    角色: D/V
 确保持续监控模型的准确率、精确率、召回率和F1分数，并与基线阈值进行比较。
 #12.5.2    等级: 1    角色: D/V
 验证数据漂移检测是否监控可能影响模型性能的输入分布变化。
 #12.5.3    等级: 2    角色: D/V
 验证概念漂移检测是否能够识别输入与预期输出之间关系的变化。
 #12.5.4    等级: 2    角色: D/V
 验证性能下降是否会触发自动警报并启动模型重新训练或替换工作流程。
 #12.5.5    等级: 3    角色: V
 验证降级根本原因分析是否将性能下降与数据变化、基础设施问题或外部因素相关联。

---

### C12.6 有向无环图可视化与工作流安全

保护工作流可视化系统免受信息泄漏和篡改攻击。

 #12.6.1    等级: 1    角色: D/V
 验证DAG可视化数据是否经过清理，确保在存储或传输之前去除敏感信息。
 #12.6.2    等级: 1    角色: D/V
 验证工作流可视化访问控制，确保只有授权用户才能查看代理决策路径和推理轨迹。
 #12.6.3    等级: 2    角色: D/V
 验证DAG数据完整性是否通过加密签名和防篡改存储机制得到保护。
 #12.6.4    等级: 2    角色: D/V
 验证工作流可视化系统是否实现了输入验证，以防止通过精心构造的节点或边数据进行的注入攻击。
 #12.6.5    等级: 3    角色: D/V
 验证实时DAG更新是否受到速率限制和验证，以防止对可视化系统的拒绝服务攻击。

---

### C12.7 主动安全行为监控

通过主动代理行为分析实现安全威胁的检测和预防。

 #12.7.1    等级: 1    角色: D/V
 在执行之前，通过风险评估集成验证主动代理行为的安全性。
 #12.7.2    等级: 2    角色: D/V
 验证自主主动性触发因素是否包括安全上下文评估和威胁态势评估。
 #12.7.3    等级: 2    角色: D/V
 验证是否分析了主动行为模式以评估潜在的安全影响和意外后果。
 #12.7.4    等级: 3    角色: D/V
 验证安全关键的主动措施需要明确的审批链和审计追踪。
 #12.7.5    等级: 3    角色: D/V
 验证行为异常检测是否能够识别出主动代理模式中的偏差，这些偏差可能表明存在被入侵的情况。

---

### 参考文献

NIST AI Risk Management Framework 1.0 - Manage 4.1 and 4.3
ISO/IEC 42001:2023 — AI Management Systems Requirements - Annex B 6.2.6
EU AI Act — Article 12, 13, 16 and 19 on Logging and Record-keeping

## C13 人类监督、问责与治理

### 控制目标

本章提供了维护人工监督和明确责任链的要求，确保在人工智能系统的整个生命周期中实现可解释性、透明度和伦理管理。

---

### C13.1 杀死开关和覆盖机制

在观察到 AI 系统存在不安全行为时，提供关闭或回滚路径。

 #13.1.1    等级: 1    角色: D/V
 验证是否存在手动紧急停止机制，以立即停止AI模型的推理和输出。
 #13.1.2    等级: 1    角色: D
 验证覆盖控制措施仅对授权人员可访问。
 #13.1.3    等级: 3    角色: D/V
 验证回滚程序能够恢复到之前的模型版本或安全模式操作。
 #13.1.4    等级: 3    角色: V
 验证覆盖机制是否定期测试。

---

### C13.2 人工干预决策检查点

当风险超过预定阈值时，需要人工审批。

 #13.2.1    等级: 1    角色: D/V
 确保高风险的人工智能决策在执行前需要明确的人类批准。
 #13.2.2    等级: 1    角色: D
 确保风险阈值被明确定义并自动触发人工审核流程。
 #13.2.3    等级: 2    角色: D
 确认在无法在规定时间内获得人工批准时，时间敏感的决策具有后备处理程序。
 #13.2.4    等级: 3    角色: D/V
 验证升级程序是否为不同的决策类型或风险类别（如适用）定义了明确的权限级别。

---

### C13.3 责任链与可审计性

记录操作员行为和模型决策。

 #13.3.1    等级: 1    角色: D/V
 验证所有 AI 系统的决策和人工干预均有时间戳、用户身份以及决策理由的日志记录。
 #13.3.2    等级: 2    角色: D
 验证审计日志不能被篡改，并包含完整性验证机制。

---

### C13.4 可解释人工智能技术

表面特征重要性、反事实和局部解释。

 #13.4.1    等级: 1    角色: D/V
 验证人工智能系统是否以人类可读的格式提供其决策的基本解释。
 #13.4.2    等级: 2    角色: V
 验证解释质量通过人工评估研究和指标进行确认。
 #13.4.3    等级: 3    角色: D/V
 确认关键决策是否具备特征重要性分数或归因方法（如SHAP、LIME等）。
 #13.4.4    等级: 3    角色: V
 验证反事实解释是否展示了如何修改输入以改变结果（如果适用于使用案例和领域）。

---

### C13.5 模型卡与使用披露

维护模型卡以记录预期用途、性能指标和伦理考量。

 #13.5.1    等级: 1    角色: D
 验证模型卡是否记录了预期用途、限制和已知的失败模式。
 #13.5.2    等级: 1    角色: D/V
 验证是否披露了适用于不同用例的性能指标。
 #13.5.3    等级: 2    角色: D
 确保伦理考量、偏见评估、公平性评价、训练数据特征及已知训练数据限制有记录并定期更新。
 #13.5.4    等级: 2    角色: D/V
 验证模型卡在整个模型生命周期内是否进行了版本控制和维护，并具备变更追踪。

---

### C13.6 不确定性量化

在响应中传播置信度分数或熵度量。

 #13.6.1    等级: 1    角色: D
 验证人工智能系统是否为其输出提供置信度分数或不确定性度量。
 #13.6.2    等级: 2    角色: D/V
 验证不确定性阈值是否触发额外的人类审核或替代决策途径。
 #13.6.3    等级: 2    角色: V
 验证不确定性量化方法是否经过校准并根据真实数据进行验证。
 #13.6.4    等级: 3    角色: D/V
 验证不确定性传播在多步骤人工智能工作流程中的保持。

---

### C13.7 面向用户的透明度报告

定期披露事件、漂移和数据使用情况。

 #13.7.1    等级: 1    角色: D/V
 确保数据使用政策和用户同意管理实践清晰地传达给利益相关者。
 #13.7.2    等级: 2    角色: D/V
 验证是否进行了人工智能影响评估，并将结果纳入报告中。
 #13.7.3    等级: 2    角色: D/V
 核实定期发布的透明度报告是否以合理的细节披露了人工智能事件和运营指标。

#### 参考文献

EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
ISO/IEC 42001:2023 — AI Management Systems Requirements
NIST AI Risk Management Framework 1.0
NIST SP 800-53 Revision 5 — Security and Privacy Controls
A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)
Model Cards for Model Reporting (Mitchell et al., 2018)
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)
ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods
IEEE 7001-2021 — Transparency of Autonomous Systems
GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)
Human Oversight under Article 14 of the EU AI Act (Fink, 2025)

## 附录A：术语表

本综合词汇表提供了AISVS中使用的关键人工智能、机器学习和安全术语的定义，以确保清晰和共识理解。

对抗样本：一种故意设计的输入，旨在使 AI 模型出错，通常通过添加对人类难以察觉的微妙扰动实现。
​
对抗鲁棒性——在人工智能中，对抗鲁棒性指的是模型保持其性能并抵抗被恶意设计的、旨在引发错误的输入所欺骗或操纵的能力。
​
代理——AI代理是使用人工智能代表用户追求目标和完成任务的软件系统。它们具备推理、规划和记忆能力，并具有一定程度的自主性，能够进行决策、学习和适应。
​
代理型人工智能：能够在一定程度上自主运行以实现目标的人工智能系统，通常在没有直接人工干预的情况下做出决策和采取行动。
​
基于属性的访问控制（ABAC）：一种访问控制范式，其中授权决策基于用户、资源、操作和环境的属性，在查询时进行评估。
​
后门攻击：一种数据投毒攻击，模型被训练成在某些触发条件下以特定方式响应，而在其他情况下表现正常。
​
偏差：人工智能模型输出中的系统性错误，可能导致某些群体或特定情境下出现不公平或歧视性的结果。
​
偏见利用：一种利用 AI 模型中已知偏见来操纵输出或结果的攻击技术。
​
Cedar：亚马逊用于实现 AI 系统基于属性的访问控制 (ABAC) 的细粒度权限策略语言和引擎。
​
思路链：一种通过在生成最终答案之前产生中间推理步骤来提升语言模型推理能力的技术。
​
断路器：一种机制，当超过特定风险阈值时，自动停止人工智能系统的运行。
​
数据泄露：通过 AI 模型输出或行为无意中暴露敏感信息。
​
数据投毒：故意破坏训练数据以损害模型完整性，通常用于安装后门或降低性能。
​
差分隐私——差分隐私是一种数学上严谨的框架，用于在保护个体数据主体隐私的同时发布关于数据集的统计信息。它使数据持有者能够共享群体的汇总模式，同时限制泄露关于特定个体的信息。
​
嵌入：数据（文本、图像等）的密集向量表示，能够在高维空间中捕捉语义意义。
​
可解释性 – AI中的可解释性是指AI系统能够为其决策和预测提供人类可理解的理由，从而揭示其内部运行机制。
​
可解释人工智能（XAI）：通过各种技术和框架，设计用于为其决策和行为提供人类可理解解释的人工智能系统。
​
联邦学习：一种机器学习方法，模型在多个分散的设备上训练，这些设备持有本地数据样本，而不交换数据本身。
​
保护措施：为防止人工智能系统产生有害的、带有偏见的或其他不良输出而实施的约束。
​
幻觉——AI幻觉指的是AI模型生成的错误或误导性信息，这些信息并非基于其训练数据或事实现实。
​
人类参与环节（HITL）：设计用于在关键决策点需要人类监督、验证或干预的系统。
​
基础设施即代码 (IaC)：通过代码而非手动流程来管理和配置基础设施，实现安全扫描和一致的部署。
​
越狱：用于规避人工智能系统中安全防护措施的技术，尤其是在大型语言模型中，以生成被禁止的内容。
​
最小权限原则：授予用户和进程仅需的最低访问权限的安全原则。
​
LIME（局部可解释模型无关解释）：一种通过在局部用可解释模型近似任何机器学习分类器的预测结果的技术。
​
成员推断攻击：一种旨在确定特定数据点是否被用于训练机器学习模型的攻击。
​
MITRE ATLAS：人工智能系统的对抗威胁态势；针对AI系统的对抗策略和技术的知识库。
​
模型卡 —— 模型卡是一种文档，提供有关人工智能模型的性能、限制、预期用途和伦理考量的标准化信息，以促进透明度和负责任的人工智能开发。
​
模型抽取：一种攻击方式，攻击者通过反复查询目标模型，在未获授权的情况下创建一个功能上相似的副本。
​
模型反演：一种通过分析模型输出尝试重建训练数据的攻击方法。
​
模型生命周期管理——AI模型生命周期管理是对AI模型存在的所有阶段进行监督的过程，包括其设计、开发、部署、监控、维护以及最终退役，以确保其保持有效并与目标保持一致。
​
模型中毒：在训练过程中直接向模型引入漏洞或后门。
​
模型窃取/盗用：通过重复查询提取专有模型的副本或近似版本。
​
多智能体系统：由多个相互作用的人工智能代理组成的系统，每个代理可能具有不同的能力和目标。
​
OPA（开放策略代理）：一个开源的策略引擎，能够实现跨整个堆栈的统一策略执行。
​
隐私保护机器学习（PPML）：在保护训练数据隐私的同时训练和部署机器学习模型的技术和方法。
​
提示注入：一种攻击方式，其中恶意指令嵌入输入中，以覆盖模型的预期行为。
​
RAG（检索增强生成）：一种通过在生成响应之前从外部知识源检索相关信息来增强大型语言模型的技术。
​
红队测试：通过模拟对抗性攻击主动测试人工智能系统以识别漏洞的实践。
​
SBOM（软件物料清单）：包含用于构建软件或人工智能模型的各种组件的详细信息及其供应链关系的正式记录。
​
SHAP（Shapley 加性解释）：一种博弈论方法，通过计算每个特征对预测的贡献来解释任何机器学习模型的输出。
​
供应链攻击：通过针对供应链中安全性较低的元素（如第三方库、数据集或预训练模型）来攻陷系统。
​
迁移学习：一种技术，其中为一个任务开发的模型被重新用作第二个任务模型的起点。
​
向量数据库：一种专门设计用于存储高维向量（嵌入）并执行高效相似性搜索的数据库。
​
漏洞扫描：自动化工具，用于识别软件组件中的已知安全漏洞，包括人工智能框架和依赖项。
​
水印技术：在 AI 生成内容中嵌入不可察觉的标记，以追踪其来源或检测 AI 生成。
​
零日漏洞：一种之前未知的漏洞，攻击者可以在开发人员创建和部署补丁之前利用该漏洞。

## 附录 B：参考文献

### TODO

## 附录C：人工智能安全治理与文档

### 目标

本附录提供了建立组织架构、政策和流程以管理整个系统生命周期中人工智能安全的基础性要求。

---

### AC.1 人工智能风险管理框架采纳

提供一个正式框架，以在系统生命周期内识别、评估和减轻特定于人工智能的风险。

 #AC.1.1    等级: 1    角色: D/V
 确认已记录并实施专项针对人工智能的风险评估方法。
 #AC.1.2    等级: 2    角色: D
 确保在人工智能生命周期的关键节点以及重大变更之前进行风险评估。
 #AC.1.3    等级: 3    角色: D/V
 验证风险管理框架是否符合既定标准（例如，NIST AI RMF）。

---

### AC.2 人工智能安全政策与程序

定义并执行组织标准，以确保人工智能的安全开发、部署和运营。

 #AC.2.1    等级: 1    角色: D/V
 验证是否存在已记录的人工智能安全政策。
 #AC.2.2    等级: 2    角色: D
 确保政策至少每年审查和更新一次，并在重大威胁环境变化后进行更新。
 #AC.2.3    等级: 3    角色: D/V
 验证政策是否涵盖所有AISVS类别及适用的监管要求。

---

### AC.3 人工智能安全的角色与职责

在整个组织内建立明确的 AI 安全责任。

 #AC.3.1    等级: 1    角色: D/V
 核实人工智能安全角色和职责是否有文档记录。
 #AC.3.2    等级: 2    角色: D
 验证相关人员是否具备适当的安全专业知识。
 #AC.3.3    等级: 3    角色: D/V
 确认已为高风险人工智能系统成立人工智能伦理委员会或治理委员会。

---

### AC.4 伦理人工智能指南执行

确保人工智能系统按既定的伦理原则运行。

 #AC.4.1    等级: 1    角色: D/V
 验证是否存在人工智能开发和部署的伦理准则。
 #AC.4.2    等级: 2    角色: D
 验证是否已建立机制来检测和报告伦理违规行为。
 #AC.4.3    等级: 3    角色: D/V
 验证已部署的人工智能系统定期进行常规的伦理审查。

---

### AC.5 人工智能合规监管监测

保持对不断变化的人工智能法规的认识和遵守。

 #AC.5.1    等级: 1    角色: D/V
 验证是否存在识别适用人工智能法规的流程。
 #AC.5.2    等级: 2    角色: D
 确认已评估所有监管要求的合规性。
 #AC.5.3    等级: 3    角色: D/V
 验证监管变更是否触发对人工智能系统的及时审查和更新。

### AC.6 训练数据治理、文档编制与流程

 #1.1.2    等级: 1    角色: D/V
 确保仅允许经过质量、代表性、伦理来源和许可证合规性审核的数据集，以减少中毒、内嵌偏见和知识产权侵权的风险。
 #1.1.5    等级: 2    角色: D/V
 确认通过审稿人交叉核对或共识确保标注/注释质量。
 #1.1.6    等级: 2    角色: D/V
 确认为重要的训练数据集维护“数据卡”或“数据表”，详细说明其特征、动机、组成、收集过程、预处理以及推荐/不推荐的使用方式。
 #1.3.2    等级: 2    角色: D/V
 验证所识别的偏差是否通过有文档记录的策略得到缓解，例如重新平衡、针对性数据增强、算法调整（如预处理、处理中、后处理技术）或重新加权，并评估缓解措施对公平性和整体模型性能的影响。
 #1.3.3    等级: 2    角色: D/V
 验证训练后公平性指标是否已被评估和记录。
 #1.3.4    等级: 3    角色: D/V
 验证生命周期偏差管理策略是否指定了所有者和审查频率。
 #1.4.1    等级: 2    角色: D/V
 通过明确的指南、审核人员交叉检查、共识机制（例如，监测注释者间一致性）以及定义的差异解决流程，确保标注/注释质量。
 #1.4.4    等级: 3    角色: D/V
 验证对安全性、保密性或公平性关键的标签（例如，识别有害内容、关键医疗发现）是否接受强制性的独立双重复核或同等强有力的验证。
 #1.4.6    等级: 2    角色: D/V
 验证标注指南和说明是否全面，受版本控制，并经过同行评审。
 #1.4.6    等级: 2    角色: D/V
 验证标签的数据模式是否明确定义，并且受版本控制。
 #1.3.1    等级: 1    角色: D/V
 确认数据集是否针对具有法律保护属性（例如种族、性别、年龄）以及与模型应用领域相关的其他伦理敏感特征（例如社会经济状况、地理位置）进行了代表性不平衡和潜在偏差的分析。
 #1.5.3    等级: 2    角色: V
 验证领域专家的手动抽查是否覆盖统计学上显著的样本（例如，≥1%或1000个样本，以较大者为准，或根据风险评估确定），以识别自动化未能发现的细微质量问题。
 #1.8.4    等级: 2    角色: D/V
 验证外包或众包标注工作流程是否包括技术/程序保障措施，以确保数据机密性、完整性、标签质量，并防止数据泄露。
 #1.5.4    等级: 2    角色: D/V
 验证补救步骤是否已附加到溯源记录中。
 #1.6.2    等级: 2    角色: D/V
 验证被标记的样本在训练前触发人工审核。
 #1.6.3    等级: 2    角色: V
 验证结果是否反馈到模型的安全档案中，并为持续的威胁情报提供信息。
 #1.6.4    等级: 3    角色: D/V
 验证检测逻辑是否已使用新的威胁情报进行刷新。
 #1.6.5    等级: 3    角色: D/V
 验证在线学习管道是否监控分布漂移。
 #1.7.1    等级: 1    角色: D/V
 验证训练数据删除工作流程是否清除主数据和派生数据，并评估对模型的影响，同时评估受影响模型的影响，并在必要时进行处理（例如，通过重新训练或重新校准）。
 #1.7.2    等级: 2    角色: D
 验证是否已建立机制来跟踪并尊重用户同意（及撤回）的范围和状态，确保在将数据纳入新的训练过程或重大模型更新之前，对同意进行验证。
 #1.7.3    等级: 2    角色: V
 验证工作流程是否每年进行测试并记录。
 #1.8.1    等级: 2    角色: D/V
 确保第三方数据供应商，包括预训练模型提供商和外部数据集提供商，在其数据或模型被集成之前，经过安全、隐私、伦理采购和数据质量的尽职调查。
 #1.8.2    等级: 1    角色: D
 验证外部传输是否使用TLS/认证和完整性检查。
 #1.8.3    等级: 2    角色: D/V
 确保对高风险数据源（例如，来源不明的开源数据集、未经审查的供应商）进行加强审查，例如在敏感应用使用前进行沙箱分析、广泛的质量/偏差检查，以及有针对性的投毒检测。
 #1.8.4    等级: 3    角色: D/V
 确保在微调或部署之前，对从第三方获得的预训练模型进行评估，重点检查其内嵌偏差、潜在后门、架构完整性以及其原始训练数据的来源。
 #1.5.3    等级: 2    角色: D/V
 验证如果使用了对抗训练，对抗数据集的生成、管理和版本控制是否有文档记录和受控。
 #1.5.3    等级: 3    角色: D/V
 验证对抗鲁棒性训练对模型性能（针对干净输入和对抗输入）及公平性指标的影响是否已被评估、记录和监控。
 #1.5.4    等级: 3    角色: D/V
 验证对抗训练和鲁棒性策略是否定期审查和更新，以应对不断发展的对抗攻击技术。
 #1.4.2    等级: 2    角色: D/V
 验证失败的数据集是否被隔离并带有审计追踪。
 #1.4.3    等级: 2    角色: D/V
 验证质量关卡是否阻止不合格的数据集，除非获得例外批准。
 #1.11.2    等级: 2    角色: D/V
 验证合成数据的生成过程、参数及预期用途已被记录。
 #1.11.3    等级: 2    角色: D/V
 在用于训练之前，验证合成数据是否经过偏差、隐私泄露和表现问题的风险评估。
 #1.12.3    等级: 2    角色: D/V
 验证是否对可疑访问事件生成了警报并及时进行了调查。
 #1.13.1    等级: 1    角色: D/V
 验证所有训练数据集是否定义了明确的保留期限。
 #1.13.2    等级: 2    角色: D/V
 验证数据集在其生命周期结束时是否会自动过期、删除或被审核以决定是否删除。
 #1.13.3    等级: 2    角色: D/V
 验证保留和删除操作是否被记录和可审核。
 #1.14.1    等级: 2    角色: D/V
 核实所有数据集的数据驻留和跨境传输要求是否已被识别和执行。
 #1.14.2    等级: 2    角色: D/V
 验证是否识别并处理了特定行业的法规（例如，医疗保健、金融）在数据处理中的要求。
 #1.14.3    等级: 2    角色: D/V
 确保符合相关隐私法律（例如GDPR、CCPA）的规定已被记录并定期审查。
 #1.16.1    等级: 2    角色: D/V
 验证是否存在回应数据主体关于访问、更正、限制或反对请求的机制。
 #1.16.2    等级: 2    角色: D/V
 验证请求是否在法律规定的时间范围内被记录、跟踪和完成。
 #1.16.3    等级: 2    角色: D/V
 验证数据主体权利流程是否经过定期测试和审查以确保其有效性。
 #1.17.1    等级: 2    角色: D/V
 在更新或替换数据集版本之前，确保执行影响分析，涵盖模型性能、公平性和合规性。
 #1.17.2    等级: 2    角色: D/V
 确认影响分析的结果已被相关利益相关者记录并审核。
 #1.17.3    等级: 2    角色: D/V
 确认存在回滚计划，以防新版本引入不可接受的风险或退化。
 #1.18.1    等级: 2    角色: D/V
 确保所有参与数据标注的人员都经过背景审查并接受过数据安全和隐私方面的培训。
 #1.18.2    等级: 2    角色: D/V
 确保所有标注人员签署保密和不披露协议。
 #1.18.3    等级: 2    角色: D/V
 验证注释平台是否执行访问控制并监控内部威胁。

#### 参考文献

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
EU Artificial Intelligence Act — Regulation (EU) 2024/1689
ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods

## 附录D：人工智能辅助的安全编码治理与验证

### 目标

本章定义了在软件开发过程中安全有效使用 AI 辅助编码工具的基本组织控制，确保软件开发生命周期（SDLC）中的安全性和可追溯性。

---

### AD.1 AI辅助的安全编码工作流程

将 AI 工具集成到组织的安全软件开发生命周期（SSDLC）中，同时不削弱现有的安全关卡。

 #AD.1.1    等级: 1    角色: D/V
 验证已记录的工作流程是否描述了人工智能工具在何时以及如何生成、重构或审查代码。
 #AD.1.2    等级: 2    角色: D
 验证该工作流程是否映射到每个SSDLC阶段（设计、实施、代码审查、测试、部署）。
 #AD.1.3    等级: 3    角色: D/V
 验证是否收集了针对AI生成代码的度量指标（例如，漏洞密度、平均检测时间），并将其与仅由人工生成的基线进行比较。

---

### AD.2 AI 工具资格认证与威胁建模

确保在采用 AI 编码工具之前评估其安全能力、风险和供应链影响。

 #AD.2.1    等级: 1    角色: D/V
 验证每个人工智能工具的威胁模型是否识别了滥用、模型反演、数据泄露和依赖链风险。
 #AD.2.2    等级: 2    角色: D
 验证工具评估是否包括对任何本地组件的静态/动态分析以及对SaaS端点（TLS、身份验证/授权、日志记录）的评估。
 #AD.2.3    等级: 3    角色: D/V
 验证评估是否遵循公认的框架，并在主要版本更改后重新执行评估。

---

### AD.3 安全提示与上下文管理

在为AI模型构建提示或上下文时，防止机密信息、专有代码和个人数据泄露。

 #AD.3.1    等级: 1    角色: D/V
 验证书面指导是否禁止在提示中发送秘密、凭据或机密数据。
 #AD.3.2    等级: 2    角色: D
 验证技术控制（客户端脱敏、批准的上下文过滤器）是否自动剥离敏感信息。
 #AD.3.3    等级: 3    角色: D/V
 验证提示和响应在传输和静止时均经过分词和加密，并且保留期限符合数据分类政策。

---

### AD.4 AI生成代码的验证

在代码合并或部署之前，检测并修复由AI输出引入的漏洞。

 #AD.4.1    等级: 1    角色: D/V
 确保 AI 生成的代码始终经过人工代码审查。
 #AD.4.2    等级: 2    角色: D
 验证每个包含 AI 生成代码的拉取请求是否运行自动扫描器（SAST/IAST/DAST），并在发现严重问题时阻止合并。
 #AD.4.3    等级: 3    角色: D/V
 验证差分模糊测试或基于属性的测试是否证明了安全关键行为（例如，输入验证、授权逻辑）。

---

### AD.5 代码建议的可解释性与可追溯性

为审计员和开发人员提供对建议为何提出及其演变过程的深入了解。

 #AD.5.1    等级: 1    角色: D/V
 验证提示/响应对是否已使用提交ID进行记录。
 #AD.5.2    等级: 2    角色: D
 验证开发者是否能够显示支持建议的模型引用（训练片段、文档）。
 #AD.5.3    等级: 3    角色: D/V
 验证可解释性报告是否与设计工件一起存储，并在安全审核中引用，以满足 ISO/IEC 42001 可追溯性原则。

---

### AD.6 持续反馈与模型微调

随着时间推移提升模型安全性能，同时防止负向漂移。

 #AD.6.1    等级: 1    角色: D/V
 验证开发人员是否可以标记不安全或不合规的建议，并且这些标记是否被跟踪。
 #AD.6.2    等级: 2    角色: D
 验证汇总的反馈是否用于定期微调或通过经审核的安全编码语料库（例如，OWASP 备忘单）进行检索增强生成。
 #AD.6.3    等级: 3    角色: D/V
 验证闭环评估系统在每次微调后运行回归测试；安全指标必须达到或超过先前基线才能部署。

---

#### 参考文献

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
OWASP Secure Coding Practices — Quick Reference Guide

## 附录 E：示例工具和框架

### 目标

本章提供了可支持实现或满足特定AISVS需求的工具和框架示例。这些不应被视为AISVS团队或OWASP GenAI安全项目的推荐或认可。

---

### AE.1 训练数据治理与偏差管理

用于数据分析、治理和偏见管理的工具。

 #AE.1.1    章节: 1.1
 数据清单工具：诸如数据清单管理工具之类的...
 #AE.1.2    章节: 1.2
 传输加密 对于基于 HTTPS 的应用，使用 TLS，加密工具如 openSSL 和 python 的`ssl`库。

---

### AE.2 用户输入验证

用于处理和验证用户输入的工具。

 #AE.2.1    章节: 2.1
 提示注入防御工具：使用如NVIDIA的NeMo或Guardrails AI等防护工具。

---

