## 封面页

### 关于标准

人工智能安全验证标准（AISVS）是一个社区驱动的安全需求目录，供数据科学家、MLOps工程师、软件架构师、开发人员、测试人员、安全专业人员、工具供应商、监管机构及用户使用，以设计、构建、测试和验证可信赖的人工智能系统及应用。该标准为人工智能生命周期中的安全控制规范提供了统一语言——涵盖数据收集、模型开发、部署到持续监控各个阶段，帮助组织衡量并提升其人工智能解决方案的韧性、隐私保护和安全性。

### 版权与许可

版本 0.1（首个公开草稿 - 进行中），2025  

![license](images/license.png)
版权 © 2025 AISVS 项目。  

根据 Creative Commons Attribution‑ShareAlike 4.0 International License.
对于任何再利用或分发，您必须明确向他人传达本作品的许可条款。

### 项目负责人

吉姆·马尼科
Aras “Russ” Memisyazici

### 贡献者和审阅者

https://github.com/ottosulin
https://github.com/mbhatt1
https://github.com/vineethsai
https://github.com/cciprofm
https://github.com/deepakrpandey12


---

AISVS是一个全新的标准，专门为应对人工智能系统的独特安全挑战而创建。虽然它借鉴了更广泛的安全最佳实践，但AISVS中的每一项要求都是从零开始制定的，以反映人工智能威胁格局，并帮助组织构建更安全、更具弹性的人工智能解决方案。

## 前言

欢迎使用人工智能安全验证标准（AISVS）1.0版！

### 介绍

AISVS于2025年通过协作社区努力成立，定义了在设计、开发、部署和运营现代人工智能模型、流程以及人工智能驱动服务时需要考虑的安全要求。

AISVS v1.0代表其项目负责人、工作组及更广泛社区贡献者共同努力的成果，旨在为保障人工智能系统提供一个务实且可测试的基线。

我们此次发布的目标是让AISVS易于采用，同时保持对其既定范围的高度关注，并应对AI独特的快速变化风险环境。

### AISVS 1.0 版本的关键目标

版本 1.0 将基于若干指导原则创建。

#### 明确的范围

每项要求必须符合AISVS的名称和使命：

人工智能 – 控制操作在 AI/ML 层（数据、模型、管道或推理）进行，由 AI 从业人员负责。
安全性 – 需求直接缓解已识别的安全、隐私或安全风险。
验证 – 语言的编写方式使符合性能够被客观验证。
标准 – 各章节遵循一致的结构和术语，形成连贯的参考。
​
---

通过遵循AISVS，组织可以系统地评估和强化其人工智能解决方案的安全态势，促进安全人工智能工程的文化发展。

## 使用AISVS

人工智能安全验证标准（AISVS）定义了现代人工智能应用和服务的安全需求，重点关注应用开发者可控的方面。

AISVS 适用于任何开发或评估人工智能应用安全性的人士，包括开发人员、架构师、安全工程师和审计人员。本章介绍了 AISVS 的结构和使用方法，包括其验证级别和预期的使用场景。

### 人工智能安全验证级别

AISVS 定义了三个递增的安全验证级别。每个级别都增加了深度和复杂性，使组织能够根据其人工智能系统的风险级别调整其安全态势。

组织可以从第一级开始，并随着安全成熟度和威胁暴露的增加，逐步采用更高级别。

#### 级别的定义

AISVS v1.0 中的每个需求都被分配到以下等级之一：

 一级需求

第一级包括最关键和最基础的安全需求。这些侧重于防止不依赖其他前提条件或漏洞的常见攻击。大多数第一级控制措施要么实现起来简单，要么足够重要，值得投入精力。

 等级 2 要求

第二级涵盖了更高级或不太常见的攻击，以及针对广泛威胁的多层防御。这些要求可能涉及更复杂的逻辑或针对特定攻击前提条件。

 三级要求

第三级包括通常较难实施或在适用性上有特定情境限制的控制措施。这些通常代表深度防御机制或针对小众、定向或高复杂性攻击的缓解措施。

#### 角色 (D/V)

每个 AISVS 要求均根据主要受众进行标注：

D – 面向开发者的需求
V – 面向验证者/审计员的需求
D/V – 相关于开发者和验证者

## C1 训练数据治理与偏差管理

### 控制目标

训练数据必须以保护来源、安全性、质量和公平性的方式进行获取、处理和维护。这样做不仅履行了法律义务，还减少了在训练过程中可能出现的偏见、中毒或隐私泄露风险，这些风险可能影响整个人工智能生命周期。

---

### C1.1 训练数据来源

维护所有数据集的可验证清单，仅接受可信来源，并记录每次变更以确保可审计性。

 #1.1.1    等级: 1    角色: D/V
 确保维护一份最新的培训数据源清单，涵盖其来源、管理者/所有者、许可、收集方法、预期使用限制以及处理历史。
 #1.1.2    等级: 1    角色: D/V
 验证训练数据处理是否排除不必要的特征、属性或字段（例如，未使用的元数据、敏感的个人身份信息、泄露的测试数据）。
 #1.1.3    等级: 2    角色: D/V
 确认所有数据集的更改均须经过记录的审批流程。
 #1.1.4    等级: 3    角色: D/V
 在可行的情况下，验证数据集或子集是否已被加水印或指纹标识。

---

### C1.2 训练数据安全与完整性

限制对训练数据的访问，对静止和传输中的数据进行加密，并验证其完整性，以防止篡改、盗窃或数据投毒。

 #1.2.1    等级: 1    角色: D/V
 验证访问控制是否保护训练数据存储和管道。
 #1.2.2    等级: 2    角色: D/V
 验证所有对训练数据的访问是否被记录，包括用户、时间和操作。
 #1.2.3    等级: 2    角色: D/V
 验证训练数据集在传输和静止状态下均已加密，采用行业标准的加密算法和密钥管理方法。
 #1.2.4    等级: 2    角色: D/V
 验证在训练数据存储和传输过程中是否使用了加密哈希或数字签名以确保数据完整性。
 #1.2.5    等级: 2    角色: D/V
 验证是否应用了自动检测技术来防止训练数据的未经授权修改或损坏。
 #1.2.6    等级: 2    角色: D/V
 验证过时的训练数据是否已被安全清除或匿名化。
 #1.2.7    等级: 3    角色: D/V
 确保所有训练数据集版本都有唯一标识，且以不可变方式存储，并且可审计，以支持回滚和取证分析。

---

### C1.3 训练数据标注的质量、完整性与安全性

保护标签并对关键数据要求技术审查。

 #1.3.1    等级: 2    角色: D/V
 验证是否对标签工件应用了加密哈希或数字签名，以确保其完整性和真实性。
 #1.3.2    等级: 2    角色: D/V
 验证标注接口和平台是否强制执行严格的访问控制，维护所有标注活动的防篡改审计日志，并防止未经授权的修改。
 #1.3.3    等级: 3    角色: D/V
 验证标签中的敏感信息在静态和传输过程中是否在数据字段级别被删除、匿名化或加密。

---

### C1.4 训练数据质量与安全保障

结合自动验证、人工抽查和记录的修正措施，以保证数据集的可靠性。

 #1.4.1    等级: 1    角色: D
 验证自动化测试是否能够捕捉每次摄取或重要数据转换中的格式错误和空值。
 #1.4.2    等级: 2    角色: D/V
 验证大型语言模型（LLM）训练和微调管道是否实现了投毒检测和数据完整性验证（例如，统计方法、异常值检测、嵌入分析），以识别训练数据中可能的投毒攻击（例如，标签翻转、后门触发插入、角色切换指令、影响力实例攻击）或无意的数据损坏。
 #1.4.3    等级: 3    角色: D/V
 根据风险评估，核实是否对相关模型实施并调整了适当的防御措施，如对抗性训练（使用生成的对抗样本）、带有扰动输入的数据增强或鲁棒优化技术。
 #1.4.4    等级: 2    角色: D/V
 验证自动生成的标签（例如，通过大型语言模型或弱监督生成的标签）是否经过置信度阈值和一致性检查，以检测产生幻觉、误导性或低置信度的标签。
 #1.4.5    等级: 3    角色: D
 验证自动化测试是否能捕捉每次数据摄取或重大数据转换中的标签偏移。

---

### C1.5 数据血统和可追溯性

跟踪每个数据点从源头到模型输入的完整路径，以实现可审计性和事件响应。

 #1.5.1    等级: 2    角色: D/V
 验证每个数据点的血统，包括所有变换、增强和合并，都已被记录并且可以被重建。
 #1.5.2    等级: 2    角色: D/V
 验证血统记录是不可变的、安全存储的，并且可供审计访问。
 #1.5.3    等级: 2    角色: D/V
 验证系谱追踪是否涵盖通过隐私保护或生成技术生成的合成数据，并确保所有合成数据在整个流程中都被明确标记且可区分于真实数据。

---

### 参考文献

NIST AI Risk Management Framework
EU AI Act – Article 10: Data & Data Governance
MITRE ATLAS: Adversary Tactics for AI
Survey of ML Bias Mitigation Techniques – MDPI
Data Provenance & Lineage Best Practices – Nightfall AI
Data Labeling Quality Standards – LabelYourData
Training Data Poisoning Guide – Lakera.ai
CISA Advisory: Securing Data for AI Systems
ISO/IEC 23053: AI Management Systems Framework
IBM: What is AI Governance?
Google AI Principles
GDPR & AI Training Data – DataProtectionReport
Supply-Chain Security for AI Data – AppSOC
OpenAI Privacy Center – Data Deletion Controls
Adversarial ML Dataset – Kaggle

## C2 用户输入验证

### 控制目标

对用户输入的严格验证是防御针对人工智能系统的一些最具破坏性攻击的第一道防线。提示注入攻击可以覆盖系统指令，泄露敏感数据，或引导模型产生不被允许的行为。除非设置了专门的过滤器和指令层级，研究表明利用超长上下文窗口的“多次尝试”越狱攻击将非常有效。此外，微妙的对抗扰动攻击——例如同形异义字替换或勒特语——可以悄无声息地改变模型的决策。

---

### C2.1 提示注入防御

提示注入是人工智能系统面临的主要风险之一。针对这一策略的防御措施结合了静态模式过滤器、动态分类器和指令层级执行。

 #2.1.1    等级: 1    角色: D/V
 验证用户输入是否经过筛查，针对一个持续更新的已知提示注入模式库（越狱关键词、“忽略之前内容”、角色扮演链条、间接的HTML/URL攻击）。
 #2.1.2    等级: 1    角色: D/V
 验证系统是否强制执行指令层级，其中系统或开发者消息优先于用户指令，即使在上下文窗口扩展后也是如此。
 #2.1.3    等级: 2    角色: D/V
 确认在每次模型或提示模板发布之前，都会进行对抗性评估测试（例如，红队“多次”提示），并设定成功率阈值及自动阻断机制以防止性能回退。
 #2.1.4    等级: 2    角色: D
 验证来自第三方内容（网页、PDF、电子邮件）的提示在合并到主提示之前，是否在隔离的解析环境中进行了清理。
 #2.1.5    等级: 3    角色: D/V
 验证所有提示过滤规则的更新、分类器模型版本和阻止列表的更改都已进行版本控制且可审计。

---

### C2.2 对抗示例抗性

自然语言处理（NLP）模型仍然容易受到细微的字符或词级扰动的影响，这些扰动人类常常忽略，但模型往往会误分类。

 #2.2.1    等级: 1    角色: D
 验证基本的输入规范化步骤（Unicode NFC，同形字映射，空白字符修剪）是否在分词前执行。
 #2.2.2    等级: 2    角色: D/V
 验证统计异常检测是否能标记与语言规范编辑距离异常高、重复标记过多或嵌入距离异常的输入。
 #2.2.3    等级: 2    角色: D
 验证推理流程是否支持可选的对抗性训练加固模型变体或防御层（例如，随机化、防御蒸馏）用于高风险端点。
 #2.2.4    等级: 2    角色: V
 验证疑似对抗性输入是否被隔离，并在对个人身份信息（PII）进行脱敏后完整记录其载荷。
 #2.2.5    等级: 3    角色: D/V
 验证鲁棒性指标（已知攻击套件的成功率）是否随时间被跟踪，并且回归是否会触发发布阻止。

---

### C2.3 模式、类型和长度验证

包含格式错误或超大输入的 AI 攻击可能导致解析错误、提示信息跨字段溢出以及资源耗尽。在执行确定性工具调用时，严格的模式执行也是前提条件。

 #2.3.1    等级: 1    角色: D
 验证每个 API 或函数调用端点是否定义了明确的输入模式（JSON Schema、Protobuf 或多模态等效模式），并且在提示组装之前对输入进行了验证。
 #2.3.2    等级: 1    角色: D/V
 验证超过最大令牌或字节限制的输入会被安全地拒绝，并且绝不会被静默截断。
 #2.3.3    等级: 2    角色: D/V
 确认类型检查（例如，数值范围、枚举值、图像/音频的 MIME 类型）是在服务器端强制执行的，而不仅仅是在客户端代码中。
 #2.3.4    等级: 2    角色: D
 验证语义验证器（例如，JSON Schema）是否以常数时间运行，以防止算法性拒绝服务攻击（DoS）。
 #2.3.5    等级: 3    角色: V
 验证确保验证失败时使用经过编辑的有效负载片段和明确的错误代码进行记录，以帮助安全分类。

---

### C2.4 内容与政策筛查

开发者应该能够检测出语法上有效但请求禁止内容的提示（例如非法指令、仇恨言论和版权受保护的文本），并防止其传播。

 #2.4.1    等级: 1    角色: D
 验证内容分类器（零样本或微调版）是否对每个输入进行暴力、自残、仇恨、性内容和非法请求的评分，并且这些评分阈值可配置。
 #2.4.2    等级: 1    角色: D/V
 验证违反政策的输入将收到标准化的拒绝或安全完成响应，以确保它们不会传播到下游的语言模型调用。
 #2.4.3    等级: 2    角色: D
 验证筛选模型或规则集是否至少每季度重新训练/更新一次，纳入新观察到的越狱或策略绕过模式。
 #2.4.4    等级: 2    角色: D
 通过在请求时解析基于属性的规则，验证筛选是否符合用户特定的政策（年龄、地区法律限制）。
 #2.4.5    等级: 3    角色: V
 验证筛选日志是否包含分类器置信度分数和策略类别标签，以便进行SOC关联和未来红队重放。

---

### C2.5 输入速率限制与滥用防护

开发者应通过限制输入速率和检测异常使用模式，防止针对人工智能系统的滥用、资源耗尽和自动化攻击。

 #2.5.1    等级: 1    角色: D/V
 验证对所有输入端点实施了每用户、每IP和每API密钥的速率限制。
 #2.5.2    等级: 2    角色: D/V
 验证突发和持续速率限制是否已调整，以防止拒绝服务攻击和暴力破解攻击。
 #2.5.3    等级: 2    角色: D/V
 验证异常使用模式（例如，快速请求、输入泛滥）是否会触发自动阻止或升级。
 #2.5.4    等级: 3    角色: V
 验证滥用防范日志是否被保存并审查以发现新兴的攻击模式。

---

### C2.6 多模态输入验证

人工智能系统应包含针对非文本输入（图像、音频、文件）的强健验证，以防止注入、规避或资源滥用。

 #2.6.1    等级: 1    角色: D
 在处理之前，验证所有非文本输入（图像、音频、文件）的类型、大小和格式。
 #2.6.2    等级: 2    角色: D/V
 确保在数据摄取之前，对文件进行恶意软件和隐写负载的扫描。
 #2.6.3    等级: 2    角色: D/V
 验证图像/音频输入是否存在对抗扰动或已知攻击模式。
 #2.6.4    等级: 3    角色: V
 验证多模态输入验证失败是否被记录并触发调查警报。

---

### C2.7 输入来源与归属

人工智能系统应通过监控和标记所有用户输入的来源，支持审计、滥用跟踪和合规性。

 #2.7.1    等级: 1    角色: D/V
 验证所有用户输入在采集时均附带元数据（用户ID、会话、来源、时间戳、IP地址）。
 #2.7.2    等级: 2    角色: D/V
 验证所有处理输入的源数据元信息是否被保留且可审计。
 #2.7.3    等级: 2    角色: D/V
 确保对异常或不受信任的输入源进行标记，并受到加强的审查或阻止。

---

### C2.8 实时自适应威胁检测

开发人员应采用先进的人工智能威胁检测系统，该系统能够适应新的攻击模式，并通过编译模式匹配提供实时保护。

 #2.8.1    等级: 1    角色: D/V
 验证威胁检测模式是否被编译成优化的正则表达式引擎，以实现高性能的实时过滤并最大限度地减少延迟影响。
 #2.8.2    等级: 1    角色: D/V
 验证威胁检测系统是否为不同的威胁类别（提示注入、有害内容、敏感数据、系统命令）维护独立的模式库。
 #2.8.3    等级: 2    角色: D/V
 验证自适应威胁检测是否包含基于攻击频率和成功率更新威胁敏感度的机器学习模型。
 #2.8.4    等级: 2    角色: D/V
 验证实时威胁情报源是否自动使用新的攻击签名和妥协指标（IOC）更新模式库。
 #2.8.5    等级: 3    角色: D/V
 确保持续监控威胁检测的误报率，并自动调整模式特异性，以最小化对合法使用场景的干扰。
 #2.8.6    等级: 3    角色: D/V
 验证上下文威胁分析是否考虑了输入来源、用户行为模式和会话历史，以提高检测准确性。
 #2.8.7    等级: 3    角色: D/V
 验证威胁检测性能指标（检测率、处理延迟、资源利用率）是否被实时监控和优化。

---

### C2.9 多模态安全验证管道

开发人员应针对文本、图像、音频和其他AI输入方式，提供具有特定威胁检测类型和资源隔离的安全验证。

 #2.9.1    等级: 1    角色: D/V
 验证每个输入模态是否具备专用的安全验证器，且具备文档化的威胁模式（文本：提示注入，图像：隐写术，音频：频谱图攻击）及检测阈值。
 #2.9.2    等级: 2    角色: D/V
 确认多模态输入在隔离的沙箱中处理，针对每种模态类型设定了明确定义的资源限制（内存、CPU、处理时间），并在安全策略中进行了记录。
 #2.9.3    等级: 2    角色: D/V
 验证跨模态攻击检测是否能够通过关联规则和告警生成，识别跨越多种输入类型的协同攻击（例如，图像中的隐写负载与文本中的提示注入相结合）。
 #2.9.4    等级: 3    角色: D/V
 验证多模态验证失败是否触发详细日志记录，包括所有输入模态、验证结果、威胁评分以及用于SIEM集成的结构化关联分析日志格式。
 #2.9.5    等级: 3    角色: D/V
 验证特定模态内容分类器是否根据已记录的计划（至少每季度一次）进行了更新，内容包括新的威胁模式、对抗示例，并确保性能基准维持在基线阈值之上。

---

### 参考文献

LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security
Generative AI's Biggest Security Flaw Is Not Easy to Fix
Many-shot jailbreaking \ Anthropic
$PDF$ OpenAI GPT-4.5 System Card
Notebook for the CheckThat Lab at CLEF 2024
Mitigate jailbreaks and prompt injections – Anthropic
Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis
OWASP Top 10 for LLM Applications 2025 – WorldTech IT
OWASP Machine Learning Security Top Ten
Few words about AI Security – Jussi Metso
How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry
Easily enforcing valid JSON schema following – API
AI Safety + Cybersecurity R\&D Tracker – Fairly AI
Anthropic makes 'jailbreak' advance to stop AI models producing harmful results
Pattern matching filter rules - IBM
Real-time Threat Detection

## C3 模型生命周期管理与变更控制

### 控制目标

人工智能系统必须实施变更控制流程，防止未经授权或不安全的模型修改进入生产环节。此控制确保模型在整个生命周期内的完整性——从开发到部署再到退役——从而实现快速事件响应并保持对所有变更的问责。

核心安全目标：通过采用受控流程，确保只有经过授权和验证的模型才能进入生产，保持完整性、可追溯性和可恢复性。

---

### C3.1 模型授权与完整性

只有经过验证完整性的授权模型才能进入生产环境。

 #3.1.1    等级: 1    角色: D/V
 在部署之前，验证所有模型工件（权重、配置、分词器）均由授权实体进行加密签名。
 #3.1.2    等级: 1    角色: D/V
 验证模型完整性在部署时得到确认，且签名验证失败会阻止模型加载。
 #3.1.3    等级: 2    角色: D/V
 验证模型来源记录是否包括授权实体的身份、训练数据校验和、带有通过/失败状态的验证测试结果以及创建时间戳。
 #3.1.4    等级: 2    角色: D/V
 验证所有模型工件均使用语义版本控制（MAJOR.MINOR.PATCH），并具备明确记录的标准，规定每个版本组件何时递增。
 #3.1.5    等级: 2    角色: V
 验证依赖跟踪是否维护了实时库存，从而实现快速识别所有使用系统。

---

### C3.2 模型验证与测试

模型必须通过定义的安全和安全性验证后才能部署。

 #3.2.1    等级: 1    角色: D/V
 验证模型在部署前是否经过自动化安全测试，包括输入验证、输出净化和安全评估，并且达到预先商定的组织通过/失败阈值。
 #3.2.2    等级: 1    角色: D/V
 验证当预先指定的授权人员明确批准覆盖且有书面业务理由时，验证失败是否会自动阻止模型部署。
 #3.2.3    等级: 2    角色: V
 验证测试结果是否经过加密签名，并与被验证的特定模型版本哈希不可变地关联。
 #3.2.4    等级: 2    角色: D/V
 验证紧急部署是否需要在预先约定的时间范围内，由预先指定的安全权限机构进行记录在案的安全风险评估和批准。

---

### C3.3 受控部署与回滚

模型部署必须受到控制、监控并且可逆。

 #3.3.1    等级: 1    角色: D
 验证生产环境部署是否实施了渐进式发布机制（金丝雀发布，蓝绿发布），并基于预先约定的错误率、延迟阈值或安全警报标准具备自动回滚触发功能。
 #3.3.2    等级: 1    角色: D/V
 验证回滚功能在预定义的组织时间窗口内以原子方式恢复完整的模型状态（权重、配置、依赖关系）。
 #3.3.3    等级: 2    角色: D/V
 验证部署流程在模型激活前是否验证加密签名并计算完整性校验和，如有不匹配则部署失败。
 #3.3.4    等级: 2    角色: D/V
 验证紧急模型关闭功能能够通过自动断路器或手动断开开关，在预定义的响应时间内禁用模型端点。
 #3.3.5    等级: 2    角色: V
 验证回滚工件（先前的模型版本、配置、依赖项）是否根据组织政策保留，并采用不可变存储以支持事件响应。

---

### C3.4 变更责任与审计

所有模型生命周期的变更必须可追溯且可审计。

 #3.4.1    等级: 1    角色: V
 验证所有模型变更（部署、配置、退役）都生成不可变的审计记录，包括时间戳、经过身份验证的操作身份、变更类型以及变更前/后的状态。
 #3.4.2    等级: 2    角色: D/V
 验证审计日志访问是否需要适当的授权，并确保所有访问尝试都记录有用户身份和时间戳。
 #3.4.3    等级: 2    角色: D/V
 验证提示模板和系统消息是否在git代码库中进行版本控制，并且在部署前必须经过指定审阅者的代码审查和批准。
 #3.4.4    等级: 2    角色: V
 验证审计记录是否包含足够的详细信息（模型哈希、配置快照、依赖版本），以便能够在保留期限内的任何时间戳完整重建模型状态。

---

### C3.5 安全开发实践

模型开发和训练过程必须遵循安全规范以防止被攻破。

 #3.5.1    等级: 1    角色: D
 验证模型开发、测试和生产环境在物理上或逻辑上是分开的。它们没有共享的基础设施，具有不同的访问控制，并且数据存储是隔离的。
 #3.5.2    等级: 1    角色: D
 验证模型训练和微调是否在具有受控网络访问的隔离环境中进行。
 #3.5.3    等级: 1    角色: D/V
 验证训练数据源通过完整性检查并通过可信源进行身份验证，且在模型开发使用前具有记录的托管链。
 #3.5.4    等级: 2    角色: D
 验证模型开发工件（超参数、训练脚本、配置文件）是否存储在版本控制中，并且在用于训练之前需要经过同行评审批准。

---

### C3.6 模型退役与停用

模型在不再需要或发现安全问题时，必须安全退役。

 #3.6.1    等级: 1    角色: D
 确认模型退役流程能自动扫描依赖关系图，识别所有使用系统，并在退役前提供预先约定的通知期限。
 #3.6.2    等级: 1    角色: D/V
 根据已验证的销毁证明，按照记录的数据保留政策，使用加密擦除或多遍覆盖的方法，确认已退役的模型工件被安全擦除。
 #3.6.3    等级: 2    角色: V
 核实模型退役事件是否被记录了时间戳和操作人员身份，并且模型签名是否被撤销以防止重复使用。
 #3.6.4    等级: 2    角色: D/V
 验证紧急模型退役是否能够通过自动终止开关，在预先设定的紧急响应时间内禁用模型访问，以防发现关键安全漏洞。

---

### 参考文献

MLOps Principles
Securing AI/ML Ops – Cisco.com
Audit logs security: cryptographically signed tamper-proof logs
Machine Learning Model Versioning: Top Tools & Best Practices
AI Hygiene Starts with Models and Data Loaders – SEI Blog
How to handle versioning and rollback of a deployed ML model?
Reinforcement fine-tuning – OpenAI API
Auditing Machine Learning models: Governance, Data Security and …
Adversarial Training to Improve Model Robustness
What is AI adversarial robustness? – IBM Research
Exploring Data Provenance: Ensuring Data Integrity and Authenticity
MITRE ATLAS
AWS Prescriptive Guidance – Best practices for retiring applications …

## C4 基础设施、配置与部署安全

### 控制目标

人工智能基础设施必须通过安全配置、运行时隔离、可信部署管道和全面监控来强化防护，抵御权限提升、供应链篡改和横向移动。只有经过授权和验证的基础设施组件及配置，才能通过受控流程进入生产环境，并确保安全性、完整性和可审计性。

核心安全目标：只有经过加密签名、漏洞扫描的基础设施组件，才能通过自动验证管道达到生产环境，这些管道执行安全策略并维护不可变的审计记录。

---

### C4.1 运行时环境隔离

通过内核级隔离原语和强制访问控制防止容器逃逸和权限提升。

 #4.1.1    等级: 1    角色: D/V
 验证所有 AI 容器除了 CAP_SETUID、CAP_SETGID 以及安全基线中明确要求的能力外，是否剥夺了所有 Linux 能力。
 #4.1.2    等级: 1    角色: D/V
 验证 seccomp 配置文件是否阻止所有系统调用，除预先批准的白名单中的调用外，违规行为将终止容器并生成安全警报。
 #4.1.3    等级: 2    角色: D/V
 验证AI工作负载是否在只读根文件系统、用于临时数据的tmpfs以及带有noexec挂载选项强制执行的命名卷用于持久数据的环境中运行。
 #4.1.4    等级: 2    角色: D/V
 验证基于 eBPF 的运行时监控（如 Falco、Tetragon 或同类工具）是否能够检测到权限提升尝试，并在组织响应时间要求内自动终止违规进程。
 #4.1.5    等级: 3    角色: D/V
 验证高风险 AI 工作负载是否在硬件隔离环境中执行（如 Intel TXT、AMD SVM 或专用裸机节点），并进行认证验证。

---

### C4.2 安全构建与部署流水线

通过可重现的构建和签名工件确保加密完整性和供应链安全。

 #4.2.1    等级: 1    角色: D/V
 验证基础设施即代码在每次提交时都使用工具（tfsec、Checkov 或 Terrascan）进行扫描，且当发现严重或高危问题时阻止合并。
 #4.2.2    等级: 1    角色: D/V
 验证容器构建是否具有可重现性，确保不同构建之间具有相同的 SHA256 哈希值，并使用 Sigstore 签名生成 SLSA 三级溯源证明。
 #4.2.3    等级: 2    角色: D/V
 验证容器镜像在推送到注册表之前嵌入了 CycloneDX 或 SPDX SBOM 并使用 Cosign 进行签名，未签名的镜像在部署时被拒绝。
 #4.2.4    等级: 2    角色: D/V
 验证 CI/CD 管道使用来源于 HashiCorp Vault、AWS IAM 角色或 Azure 托管身份的 OIDC 令牌，其生命周期不超过组织安全策略的限制。
 #4.2.5    等级: 2    角色: D/V
 验证在容器执行之前的部署过程中，Cosign 签名和 SLSA 溯源已被验证，并且验证错误会导致部署失败。
 #4.2.6    等级: 2    角色: D/V
 验证构建环境是否运行在临时容器或虚拟机中，且无持久存储，并与生产VPC网络隔离。

---

### C4.3 网络安全与访问控制

通过默认拒绝策略和加密通信实现零信任网络。

 #4.3.1    等级: 1    角色: D/V
 验证 Kubernetes NetworkPolicies 或任何等效实现是否具备默认拒绝入站/出站流量的功能，并对所需端口（如 443、8080 等）设置明确的允许规则。
 #4.3.2    等级: 1    角色: D/V
 验证 SSH（端口 22）、RDP（端口 3389）和云元数据端点（169.254.169.254）是否被阻止或是否需要基于证书的身份验证。
 #4.3.3    等级: 2    角色: D/V
 验证出口流量是否通过带有域名允许列表的 HTTP/HTTPS 代理（Squid、Istio 或云 NAT 网关）进行过滤，并记录被阻止的请求。
 #4.3.4    等级: 2    角色: D/V
 验证服务间通信是否使用双向TLS，证书是否按照组织政策进行轮换，并强制执行证书验证（不允许使用跳过验证标志）。
 #4.3.5    等级: 2    角色: D/V
 验证 AI 基础设施是否运行在专用的 VPCs/VNets 中，且无直接互联网访问权限，仅通过 NAT 网关或堡垒主机进行通信。

---

### C4.4 秘密和密码密钥管理

通过硬件支持的存储和自动轮换，结合零信任访问，保护凭证安全。

 #4.4.1    等级: 1    角色: D/V
 验证机密是否存储在 HashiCorp Vault、AWS Secrets Manager、Azure Key Vault 或 Google Secret Manager 中，并且使用 AES-256 进行静态加密。
 #4.4.2    等级: 1    角色: D/V
 验证密码密钥是否在 FIPS 140-2 级别 2 的 HSM（AWS CloudHSM、Azure Dedicated HSM）中生成，并且密钥轮换符合组织的密码学策略。
 #4.4.3    等级: 2    角色: D/V
 验证秘密轮换是否实现自动化，具备零停机部署，并且能在人员变动或安全事件触发时立即轮换。
 #4.4.4    等级: 2    角色: D/V
 验证容器镜像是否使用工具（GitLeaks、TruffleHog 或 detect-secrets）进行扫描，阻止包含 API 密钥、密码或证书的构建。
 #4.4.5    等级: 2    角色: D/V
 验证生产环境的秘密访问是否需要使用带有硬件令牌（YubiKey，FIDO2）的多因素身份验证（MFA），并且是否通过包含用户身份和时间戳的不可篡改审计日志进行记录。
 #4.4.6    等级: 2    角色: D/V
 验证机密是否通过 Kubernetes 机密、挂载卷或初始化容器注入，并确保机密绝不嵌入环境变量或镜像中。

---

### C4.5 AI 工作负载沙箱与验证

在安全沙箱中隔离不受信任的 AI 模型，并进行全面的行为分析。

 #4.5.1    等级: 1    角色: D/V
 验证外部AI模型是否在gVisor、microVM（如Firecracker、CrossVM）或带有--security-opt=no-new-privileges和--read-only标志的Docker容器中执行。
 #4.5.2    等级: 1    角色: D/V
 验证沙箱环境没有网络连接（--network=none）或仅允许本地主机访问，且通过 iptables 规则阻止所有外部请求。
 #4.5.3    等级: 2    角色: D/V
 验证人工智能模型的验证过程包括与组织定义的测试覆盖范围和行为分析相结合的自动化红队测试，以检测后门。
 #4.5.4    等级: 2    角色: D/V
 验证在AI模型投入生产之前，其沙箱结果由授权的安全人员进行加密签名并存储在不可篡改的审计日志中。
 #4.5.5    等级: 2    角色: D/V
 验证沙箱环境在每次评估之间被销毁并从黄金镜像重新创建，确保文件系统和内存的完全清理。

---

### C4.6 基础设施安全监控

通过自动修复和实时警报，持续扫描和监控基础设施。

 #4.6.1    等级: 1    角色: D/V
 验证容器镜像是否按照组织的计划进行扫描，并根据组织的风险阈值，阻止存在关键漏洞的镜像部署。
 #4.6.2    等级: 1    角色: D/V
 验证基础设施是否通过了 CIS 基准或 NIST 800-53 控制，符合组织定义的合规阈值，并对未通过的检查实施自动修复。
 #4.6.3    等级: 2    角色: D/V
 验证高严重性漏洞是否已根据组织的风险管理时间表进行修补，并针对正在被主动利用的CVE制定紧急处理程序。
 #4.6.4    等级: 2    角色: V
 验证安全警报是否使用CEF或STIX/TAXII格式与SIEM平台（Splunk、Elastic或Sentinel）集成，并实现自动丰富。
 #4.6.5    等级: 3    角色: V
 验证基础设施指标是否导出到监控系统（Prometheus、DataDog），并具备SLA仪表板和高管报告功能。
 #4.6.6    等级: 2    角色: D/V
 根据组织的监控要求，使用工具（Chef InSpec、AWS Config）验证配置漂移是否被检测到，并对未经授权的更改进行自动回滚。

---

### C4.7 AI基础设施资源管理

通过配额和监控防止资源耗尽攻击，确保资源公平分配。

 #4.7.1    等级: 1    角色: D/V
 验证GPU/TPU利用率是否被监控，并在组织定义的阈值触发警报，同时根据容量管理策略启用自动扩展或负载均衡。
 #4.7.2    等级: 1    角色: D/V
 验证是否根据组织的监控要求收集了 AI 工作负载指标（推理延迟、吞吐量、错误率），并将其与基础设施利用率相关联。
 #4.7.3    等级: 2    角色: D/V
 验证 Kubernetes ResourceQuotas 或等效机制是否根据组织的资源分配策略限制单个工作负载，并强制执行硬性限制。
 #4.7.4    等级: 2    角色: V
 验证成本监控是否根据组织预算阈值跟踪每个工作负载/租户的支出，并基于此触发警报及自动控制预算超支。
 #4.7.5    等级: 3    角色: V
 验证容量规划是否使用具有组织定义预测期的历史数据，并根据需求模式进行自动化资源配置。
 #4.7.6    等级: 2    角色: D/V
 验证资源耗尽是否根据组织响应要求触发断路器，包括基于容量策略的速率限制和工作负载隔离。

---

### C4.8 环境隔离与推广控制

通过自动化推广门和安全验证，强制执行严格的环境边界。

 #4.8.1    等级: 1    角色: D/V
 验证开发、测试和生产环境是否在独立的VPC/VNet中运行，且没有共享的IAM角色、安全组或网络连接。
 #4.8.2    等级: 1    角色: D/V
 验证环境推广确实需要组织定义的授权人员通过加密签名和不可篡改的审计追踪进行批准。
 #4.8.3    等级: 2    角色: D/V
 验证生产环境是否阻止SSH访问，禁用调试端点，并且除了紧急情况外，要求变更请求符合组织的提前通知要求。
 #4.8.4    等级: 2    角色: D/V
 确认基础设施即代码的更改在合并到主分支之前需要经过同行评审，并进行自动化测试和安全扫描。
 #4.8.5    等级: 2    角色: D/V
 验证非生产数据是否根据组织的隐私要求进行了匿名处理，合成数据生成，或通过去除个人身份信息（PII）实现完全数据掩码并经过验证。
 #4.8.6    等级: 2    角色: D/V
 验证发布关卡是否包括自动化安全测试（静态应用程序安全测试SAST、动态应用程序安全测试DAST、容器扫描），且无任何关键级别发现方可批准。

---

### C4.9 基础设施备份与恢复

通过自动备份、经过测试的恢复程序和灾难恢复能力，确保基础设施的韧性。

 #4.9.1    等级: 1    角色: D/V
 验证基础设施配置是否根据组织的备份计划备份到地理上分离的区域，并实施3-2-1备份策略。
 #4.9.2    等级: 2    角色: D/V
 验证备份系统在隔离网络中运行，使用独立凭证，并采用气隙存储以防范勒索软件攻击。
 #4.9.3    等级: 2    角色: V
 根据组织的计划，通过自动化测试验证恢复程序是否经过测试和验证，确保恢复时间目标（RTO）和恢复点目标（RPO）符合组织要求。
 #4.9.4    等级: 3    角色: V
 验证灾难恢复是否包含针对AI的专用运行手册，包括模型权重恢复、GPU集群重建和服务依赖关系映射。

---

### C4.10 基础设施合规与治理

通过持续评估、文档记录和自动化控制，保持法规合规性。

 #4.10.1    等级: 2    角色: D/V
 验证基础设施合规性是否根据组织的时间表，针对SOC 2、ISO 27001或FedRAMP控制进行评估，并通过自动化证据收集完成。
 #4.10.2    等级: 2    角色: V
 验证基础设施文档是否包括根据组织变更管理要求更新的网络图、数据流地图和威胁模型。
 #4.10.3    等级: 3    角色: D/V
 验证基础设施变更是否经过自动化的合规性影响评估，并针对高风险修改执行监管审批流程。

---

### C4.11 人工智能硬件安全

保护特定于人工智能的硬件组件，包括GPU、TPU和专用的人工智能加速器。

 #4.11.1    等级: 2    角色: D/V
 验证AI加速器固件（GPU BIOS、TPU固件）是否通过加密签名进行了验证，并且按照组织的补丁管理时间表进行更新。
 #4.11.2    等级: 2    角色: D/V
 确认在工作负载执行之前，通过使用 TPM 2.0、Intel TXT 或 AMD SVM 的硬件证明验证 AI 加速器的完整性。
 #4.11.3    等级: 2    角色: D/V
 验证使用 SR-IOV、MIG（多实例 GPU）或等效硬件分区时，工作负载之间的 GPU 内存是否被隔离，并在作业之间进行内存清理。
 #4.11.4    等级: 3    角色: V
 验证人工智能硬件供应链是否包含制造商证书的来源验证以及防篡改包装的验证。
 #4.11.5    等级: 3    角色: D/V
 验证硬件安全模块（HSMs）是否通过FIPS 140-2 三级或通用准则EAL4+认证来保护AI模型权重和加密密钥。

---

### C4.12 边缘与分布式人工智能基础设施

安全的分布式人工智能部署，包括边缘计算、联邦学习和多站点架构。

 #4.12.1    等级: 2    角色: D/V
 验证边缘 AI 设备是否使用相互 TLS 通过设备证书进行对中央基础设施的身份验证，并根据组织的证书管理政策进行证书轮换。
 #4.12.2    等级: 2    角色: D/V
 验证边缘设备是否实现了带有签名验证和回滚保护的安全启动，以防止固件降级攻击。
 #4.12.3    等级: 3    角色: D/V
 验证分布式人工智能协调采用拜占庭容错共识算法，并具备参与者验证和恶意节点检测机制。
 #4.12.4    等级: 3    角色: D/V
 验证边缘到云通信包括带宽限制、数据压缩和具有安全本地存储的离线操作能力。

---

### C4.13 多云与混合基础设施安全

保障跨多个云服务提供商及混合云-本地部署中的 AI 工作负载安全。

 #4.13.1    等级: 2    角色: D/V
 验证多云 AI 部署是否使用跨云平台的身份联合（OIDC，SAML），并在各提供商之间实现集中式策略管理。
 #4.13.2    等级: 2    角色: D/V
 验证跨云数据传输是否使用端到端加密，并采用客户管理的密钥以及按司法管辖区强制执行的数据驻留控制。
 #4.13.3    等级: 2    角色: D/V
 验证混合云人工智能工作负载在本地和云环境中实施一致的安全策略，并实现统一的监控和警报。
 #4.13.4    等级: 3    角色: V
 验证云供应商锁定预防措施是否包括可移植的基础设施即代码、标准化的 API 以及带有格式转换工具的数据导出功能。
 #4.13.5    等级: 3    角色: V
 验证多云成本优化是否包括防止资源扩散的安全控制以及防止未经授权的跨云数据传输费用。

---

### C4.14 基础设施自动化与 GitOps 安全

为人工智能基础设施管理提供安全的基础设施自动化流水线和GitOps工作流程。

 #4.14.1    等级: 2    角色: D/V
 验证 GitOps 仓库是否要求使用 GPG 密钥进行签名提交，并且设置了防止直接推送到主分支的分支保护规则。
 #4.14.2    等级: 2    角色: D/V
 验证基础设施自动化是否包括漂移检测，以及根据组织对未经授权更改的响应要求触发的自动补救和回滚功能。
 #4.14.3    等级: 2    角色: D/V
 验证自动化基础设施配置是否包括安全策略验证，并对不合规配置进行部署阻止。
 #4.14.4    等级: 2    角色: D/V
 验证基础设施自动化的密钥通过外部密钥操作器（External Secrets Operator、Bank-Vaults）进行管理，并实现自动轮换。
 #4.14.5    等级: 3    角色: V
 验证自愈基础设施是否包括带有自动化事件响应和利益相关者通知工作流的安全事件关联。

---

### C4.15 量子抗性基础设施安全

通过后量子密码学和量子安全协议，为量子计算威胁准备人工智能基础设施。

 #4.15.1    等级: 3    角色: D/V
 验证人工智能基础设施是否实施了NIST批准的后量子密码算法（CRYSTALS-Kyber、CRYSTALS-Dilithium、SPHINCS+）用于密钥交换和数字签名。
 #4.15.2    等级: 3    角色: D/V
 验证量子密钥分发（QKD）系统的实施，以实现具有量子安全密钥管理协议的高安全性人工智能通信。
 #4.15.3    等级: 3    角色: D/V
 验证密码灵活性框架通过自动化证书和密钥轮换，实现向新的后量子算法的快速迁移。
 #4.15.4    等级: 3    角色: V
 确认量子威胁建模评估了 AI 基础设施对量子攻击的脆弱性，并附有记录的迁移时间表和风险评估。
 #4.15.5    等级: 3    角色: D/V
 验证混合经典-量子加密系统在量子过渡期间通过性能监控实现纵深防御。

---

### C4.16 机密计算与安全隔区

使用基于硬件的可信执行环境和机密计算技术保护 AI 工作负载和模型权重。

 #4.16.1    等级: 3    角色: D/V
 验证敏感的人工智能模型是否在具有加密内存和认证验证的Intel SGX安全区域、AMD SEV-SNP或ARM TrustZone中执行。
 #4.16.2    等级: 3    角色: D/V
 验证机密容器（Kata Containers，搭配机密计算的 gVisor）是否通过硬件强制的内存加密对 AI 工作负载进行隔离。
 #4.16.3    等级: 3    角色: D/V
 在加载 AI 模型之前，验证远程认证以通过加密证明执行环境的真实性，从而确保安全区的完整性。
 #4.16.4    等级: 3    角色: D/V
 验证机密 AI 推理服务通过加密计算、封闭模型权重和受保护执行来防止模型提取。
 #4.16.5    等级: 3    角色: D/V
 验证可信执行环境编排是否通过远程证明和加密通信通道管理安全区域的生命周期。
 #4.16.6    等级: 3    角色: D/V
 验证安全多方计算（SMPC）是否能够在不暴露各自数据集或模型参数的情况下，实现协作式人工智能训练。

---

### C4.17 零知识基础设施

实现零知识证明系统，用于隐私保护的人工智能验证和认证，且不泄露敏感信息。

 #4.17.1    等级: 3    角色: D/V
 验证零知识证明（ZK-SNARKs，ZK-STARKs）能够在不暴露模型权重或训练数据的情况下，核实人工智能模型的完整性和训练来源。
 #4.17.2    等级: 3    角色: D/V
 验证基于零知识（ZK）认证系统是否能够在不透露身份相关信息的情况下，实现对人工智能服务的隐私保护用户验证。
 #4.17.3    等级: 3    角色: D/V
 验证私有集合交集（PSI）协议是否能够在不暴露各自数据集的情况下，实现联邦人工智能的数据安全匹配。
 #4.17.4    等级: 3    角色: D/V
 验证零知识机器学习（ZKML）系统能够通过正确计算的密码学证明实现可验证的人工智能推理。
 #4.17.5    等级: 3    角色: D/V
 验证ZK-rollups通过批量验证和减少计算开销，提供可扩展的、保护隐私的AI交易处理。

---

### C4.18 侧信道攻击防护

保护人工智能基础设施免受可能泄露敏感信息的时间、电力、电磁和基于缓存的侧信道攻击。

 #4.18.1    等级: 3    角色: D/V
 验证人工智能推理时间是否通过恒定时间算法和填充进行了归一化，以防止基于时间的模型提取攻击。
 #4.18.2    等级: 3    角色: D/V
 验证功率分析防护是否包括噪声注入、电源线过滤和随机执行模式，以保护AI硬件。
 #4.18.3    等级: 3    角色: D/V
 验证基于缓存的侧信道缓解措施是否使用缓存分区、随机化和刷新指令来防止信息泄漏。
 #4.18.4    等级: 3    角色: D/V
 确认电磁辐射防护包括屏蔽、信号滤波和随机化处理，以防止类似TEMPEST的攻击。
 #4.18.5    等级: 3    角色: D/V
 验证微架构侧信道防御措施是否包括推测执行控制和内存访问模式混淆。

---

### C4.19 神经形态与专用人工智能硬件安全

保障新兴的人工智能硬件架构的安全，包括类脑芯片、FPGA、定制ASIC和光学计算系统。

 #4.19.1    等级: 3    角色: D/V
 验证神经形态芯片安全性包括脉冲模式加密、突触权重保护以及基于硬件的学习规则验证。
 #4.19.2    等级: 3    角色: D/V
 验证基于FPGA的AI加速器是否实现了比特流加密、防篡改机制以及带有认证更新的安全配置加载。
 #4.19.3    等级: 3    角色: D/V
 验证定制ASIC安全性是否包含片上安全处理器、硬件信任根以及带有防篡改检测的安全密钥存储。
 #4.19.4    等级: 3    角色: D/V
 验证光计算系统是否实现量子安全的光学加密、安全的光子交换以及受保护的光学信号处理。
 #4.19.5    等级: 3    角色: D/V
 验证混合模拟-数字AI芯片是否包含安全的模拟计算、受保护的权重存储和经过认证的模拟到数字转换。

---

### C4.20 隐私保护计算基础设施

实施隐私保护计算的基础设施控制，以在人工智能处理和分析过程中保护敏感数据。

 #4.20.1    等级: 3    角色: D/V
 验证同态加密基础设施能够在敏感的 AI 工作负载上实现加密计算，并具备密码学完整性验证和性能监控功能。
 #4.20.2    等级: 3    角色: D/V
 验证私有信息检索系统能够在不泄露查询模式的情况下，实现数据库查询，并通过密码学手段保护访问模式。
 #4.20.3    等级: 3    角色: D/V
 验证安全多方计算协议能够实现隐私保护的人工智能推理，同时不暴露各方的单独输入或中间计算结果。
 #4.20.4    等级: 3    角色: D/V
 验证隐私保护的密钥管理是否包括分布式密钥生成、门限密码学以及带有硬件支持保护的安全密钥轮换。
 #4.20.5    等级: 3    角色: D/V
 验证在保持密码学安全保证的同时，通过批处理、缓存和硬件加速优化隐私保护计算性能。

---

### C4.15 代理框架云集成安全与混合部署

具有混合本地/云架构的云集成代理框架的安全控制。

 #4.15.1    等级: 1    角色: D/V
 验证云存储集成是否使用端到端加密，并且密钥管理由代理控制。
 #4.15.2    等级: 2    角色: D/V
 验证混合部署的安全边界是否明确定义，并使用加密通信通道。
 #4.15.3    等级: 2    角色: D/V
 验证云资源访问是否包含零信任验证与持续认证。
 #4.15.4    等级: 3    角色: D/V
 通过对存储位置进行密码学证明，验证数据驻留要求的执行情况。
 #4.15.5    等级: 3    角色: D/V
 验证云服务提供商的安全评估是否包含针对代理的威胁建模和风险评估。

---

### 参考文献

NIST Cybersecurity Framework 2.0
CIS Controls v8
OWASP Container Security Verification Standard
Kubernetes Security Best Practices
SLSA Supply Chain Security Framework
NIST SP 800-190: Application Container Security Guide
Cloud Security Alliance: Cloud Controls Matrix
ENISA: Secure Infrastructure Design
NIST SP 800-53: Security Controls for Federal Information Systems
ISO 27001:2022 Information Security Management
NIST AI Risk Management Framework
CIS Kubernetes Benchmark
FIPS 140-2 Security Requirements
NIST SP 800-207: Zero Trust Architecture
IEEE 2857: Privacy Engineering for AI Systems
NIST SP 800-161: Cybersecurity Supply Chain Risk Management
NIST Post-Quantum Cryptography Standards
Intel SGX Developer Guide
AMD SEV-SNP White Paper
ARM TrustZone Technology
ZK-SNARKs: A Gentle Introduction
NIST SP 800-57: Cryptographic Key Management
Side-Channel Attack Countermeasures
Neuromorphic Computing Security Challenges
FPGA Security: Fundamentals, Evaluation, and Countermeasures
Microsoft SEAL: Homomorphic Encryption Library
HElib: Homomorphic Encryption Library
PALISADE Lattice Cryptography Library
Differential Privacy: A Survey of Results
Secure Aggregation for Federated Learning
Private Information Retrieval: Concepts and Constructions

## C5 人工智能组件与用户的访问控制与身份管理

### 控制目标

针对人工智能系统的有效访问控制需要强大的身份管理、上下文感知授权以及遵循零信任原则的运行时执行。这些控制确保人类、服务和自主代理仅在明确授予的范围内与模型、数据和计算资源交互，并具备持续的验证和审计能力。

---

### C5.1 身份管理与认证

为所有实体建立基于加密的身份认证，并对特权操作实施多因素身份验证。

 #5.1.1    等级: 1    角色: D/V
 验证所有人类用户和服务主体通过集中式企业身份提供者（IdP）使用 OIDC/SAML 协议进行身份验证，且采用唯一的身份到令牌映射（不使用共享账户或凭据）。
 #5.1.2    等级: 1    角色: D/V
 验证高风险操作（模型部署、权重导出、训练数据访问、生产配置更改）是否需要多因素认证或带有会话重新验证的升级认证。
 #5.1.3    等级: 2    角色: D
 验证新负责人在获得生产系统访问权限之前，是否进行了符合 NIST 800-63-3 IAL-2 或同等标准的身份验证。
 #5.1.4    等级: 2    角色: V
 验证访问审查是否每季度进行一次，并且具备自动检测休眠账户、强制凭证轮换以及取消权限工作流。
 #5.1.5    等级: 3    角色: D/V
 验证联合人工智能代理通过带有最大生命周期为24小时且包含加密原点证明的签名 JWT 断言进行身份验证。

---

### C5.2 资源授权及最小权限原则

为所有人工智能资源实施细粒度访问控制，采用明确的权限模型和审计跟踪。

 #5.2.1    等级: 1    角色: D/V
 验证每个 AI 资源（数据集、模型、端点、向量集合、嵌入索引、计算实例）都实施基于角色的访问控制，并采用显式允许列表和默认拒绝策略。
 #5.2.2    等级: 1    角色: D/V
 验证默认情况下通过服务账户强制执行最小权限原则，起始权限为只读，并且写入权限需要有书面业务理由。
 #5.2.3    等级: 1    角色: V
 验证所有访问控制修改是否关联至经批准的变更请求，并以不可变方式记录时间戳、操作主体身份、资源标识符及权限变更。
 #5.2.4    等级: 2    角色: D
 验证数据分类标签（PII、PHI、受出口管制、专有）是否自动传播到派生资源（嵌入、提示缓存、模型输出），并确保策略执行一致。
 #5.2.5    等级: 2    角色: D/V
 验证未经授权的访问尝试和权限提升事件是否在5分钟内触发包含上下文元数据的实时警报并发送到SIEM系统。

---

### C5.3 动态策略评估

部署基于属性的访问控制（ABAC）引擎，用于具备审计功能的上下文感知授权决策。

 #5.3.1    等级: 1    角色: D/V
 验证授权决策是否外部化到专用的策略引擎（如 OPA、Cedar 或同等功能的引擎），并通过经身份验证的 API 访问，且具备加密完整性保护。
 #5.3.2    等级: 1    角色: D/V
 验证策略在运行时评估动态属性，包括用户权限级别、资源敏感性分类、请求上下文、租户隔离和时间约束。
 #5.3.3    等级: 2    角色: D
 确认策略定义在生产部署前通过版本控制、同行评审，并通过CI/CD管道中的自动化测试进行验证。
 #5.3.4    等级: 2    角色: V
 验证策略评估结果是否包含结构化的决策理由，并传输到 SIEM 系统以进行关联分析和合规报告。
 #5.3.5    等级: 3    角色: D/V
 验证高敏感资源的策略缓存生存时间（TTL）值不超过5分钟，标准资源具有缓存失效能力的策略缓存生存时间不超过1小时。

---

### C5.4 查询时安全执行

实施数据库层安全控制，包括强制过滤和行级安全策略。

 #5.4.1    等级: 1    角色: D/V
 验证所有向量数据库和SQL查询包含强制性的安全过滤器（租户ID、敏感性标签、用户范围），并且这些过滤器在数据库引擎层面强制执行，而非在应用程序代码中实现。
 #5.4.2    等级: 1    角色: D/V
 验证所有向量数据库、搜索索引和训练数据集是否启用了行级安全（RLS）策略和字段级屏蔽，并且支持策略继承。
 #5.4.3    等级: 2    角色: D
 验证失败的授权评估将通过立即中止查询并返回明确的授权错误代码，而不是返回空结果集，从而防止“混淆代理攻击”。
 #5.4.4    等级: 2    角色: V
 验证策略评估延迟是否被持续监控，并针对可能导致授权绕过的超时情况设置了自动警报。
 #5.4.5    等级: 3    角色: D/V
 验证查询重试机制是否重新评估授权策略，以考虑活动用户会话中权限的动态变化。

---

### C5.5 输出过滤与数据丢失防护

部署后处理控制以防止未经授权的数据在人工智能生成的内容中泄露。

 #5.5.1    等级: 1    角色: D/V
 验证推理后过滤机制是否在向请求者传递内容之前，扫描并删除未经授权的个人身份信息（PII）、分类信息和专有数据。
 #5.5.2    等级: 1    角色: D/V
 验证模型输出中的引用、参考文献和来源归属是否符合调用者的权限，如发现未经授权的访问则将其移除。
 #5.5.3    等级: 2    角色: D
 根据用户权限级别和数据分类，验证输出格式限制（经过清理的PDF、去除元数据的图像、批准的文件类型）是否得到强制执行。
 #5.5.4    等级: 2    角色: V
 验证涂黑算法是确定性的、版本受控的，并保持审计日志以支持合规调查和法证分析。
 #5.5.5    等级: 3    角色: V
 验证高风险涂黑事件是否生成包含原始内容加密哈希的自适应日志，以便进行取证检索且不暴露数据。

---

### C5.6 多租户隔离

确保共享人工智能基础设施中租户之间的加密和逻辑隔离。

 #5.6.1    等级: 1    角色: D/V
 验证内存空间、嵌入存储、缓存条目和临时文件是否按租户进行命名空间隔离，并在租户删除或会话终止时进行安全清除。
 #5.6.2    等级: 1    角色: D/V
 验证每个API请求是否包含经过身份验证的租户标识符，并对其进行加密验证，以确保其与会话上下文和用户权限相符。
 #5.6.3    等级: 2    角色: D
 验证网络策略是否在服务网格和容器编排平台中对跨租户通信实施默认拒绝规则。
 #5.6.4    等级: 3    角色: D
 验证每个租户的加密密钥是否唯一，支持客户管理密钥（CMK），并确保租户数据存储之间的加密隔离。

---

### C5.7 自主代理授权

通过作用域能力令牌和持续授权来控制 AI 代理和自主系统的权限。

 #5.7.1    等级: 1    角色: D/V
 验证自治代理是否接收了范围限定的能力令牌，这些令牌明确列出了允许的操作、可访问的资源、时间限制和操作约束。
 #5.7.2    等级: 1    角色: D/V
 确认高风险功能（文件系统访问、代码执行、外部 API 调用、金融交易）默认禁用，并且激活这些功能需要明确的授权和业务理由。
 #5.7.3    等级: 2    角色: D
 验证能力令牌是否绑定到用户会话，包含加密完整性保护，并确保它们无法在离线场景中被持久保存或重复使用。
 #5.7.4    等级: 2    角色: V
 验证代理发起的操作通过ABAC策略引擎进行次级授权，包含完整的上下文评估和审计日志记录。
 #5.7.5    等级: 3    角色: V
 验证代理错误条件和异常处理是否包含能力范围信息，以支持事件分析和取证调查。

---

### 参考文献

#### 标准与框架

NIST SP 800-63-3: Digital Identity Guidelines
Zero Trust Architecture – NIST SP 800-207
OWASP Application Security Verification Standard (AISVS)
​
#### 实施指南

Identity and Access Management in the AI Era: 2025 Guide – IDSA
Attribute-Based Access Control with OPA – Permify
How We Designed Cedar to Be Intuitive, Fast, and Safe – AWS
​
#### 特定于人工智能的安全性

Row Level Security in Vector DBs for RAG – Bluetuple.ai
Tenant Isolation in Multi-Tenant Systems – WorkOS
Handling AI Agent Permissions – Stytch
OWASP Top 10 for Large Language Model Applications

## C6 模型、框架与数据的供应链安全

### 控制目标

人工智能供应链攻击利用第三方模型、框架或数据集植入后门、偏见或可利用的代码。这些控制措施提供端到端的溯源、漏洞管理和监控，以保护整个模型生命周期。

---

### C6.1 预训练模型审核与来源验证

在进行任何微调或部署之前，评估并验证第三方模型的来源、许可证及隐藏行为。

 #6.1.1    等级: 1    角色: D/V
 验证每个第三方模型工件是否包含签名的溯源记录，标明源代码仓库和提交哈希。
 #6.1.2    等级: 1    角色: D/V
 验证模型在导入前是否通过自动化工具扫描了恶意层或特洛伊触发器。
 #6.1.3    等级: 2    角色: D
 验证迁移学习微调是否通过对抗性评估来检测隐藏行为。
 #6.1.4    等级: 2    角色: V
 验证模型许可证、出口控制标签和数据来源声明是否已记录在 ML-BOM 条目中。
 #6.1.5    等级: 3    角色: D/V
 验证高风险模型（公开上传的权重、未经验证的创建者）在人工审查和签署之前保持隔离状态。

---

### C6.2 框架与库扫描

持续扫描机器学习框架和库中的CVE和恶意代码，以保持运行时堆栈的安全。

 #6.2.1    等级: 1    角色: D/V
 验证 CI 流水线是否对 AI 框架和关键库运行依赖扫描器。
 #6.2.2    等级: 1    角色: D/V
 验证关键漏洞（CVSS ≥ 7.0）是否阻止推广到生产镜像。
 #6.2.3    等级: 2    角色: D
 验证静态代码分析是否在分叉的或供应的机器学习库上运行。
 #6.2.4    等级: 2    角色: V
 验证框架升级提案是否包含引用公共CVE信息源的安全影响评估。
 #6.2.5    等级: 3    角色: V
 验证运行时传感器是否对偏离签名SBOM的意外动态库加载发出警报。

---

### C6.3 依赖项固定与验证

将每个依赖项固定到不可变摘要，并重现构建以保证生成完全相同且无篡改的工件。

 #6.3.1    等级: 1    角色: D/V
 验证所有包管理器是否通过锁定文件强制执行版本固定。
 #6.3.2    等级: 1    角色: D/V
 验证容器引用中使用的是不可变摘要，而不是可变标签。
 #6.3.3    等级: 2    角色: D
 验证可复现构建检查是否跨持续集成运行比较哈希，以确保输出一致。
 #6.3.4    等级: 2    角色: V
 验证构建证明已保存18个月以确保审计可追溯性。
 #6.3.5    等级: 3    角色: D
 验证已过期的依赖是否会触发自动拉取请求以更新或分叉固定版本。

---

### C6.4 受信任源强制执行

仅允许从经过密码学验证且组织批准的来源下载工件，阻止所有其他来源。

 #6.4.1    等级: 1    角色: D/V
 验证模型权重、数据集和容器只从批准的域或内部注册表下载。
 #6.4.2    等级: 1    角色: D/V
 验证 Sigstore/Cosign 签名以确认发布者身份，然后再将工件缓存到本地。
 #6.4.3    等级: 2    角色: D
 验证出口代理是否阻止未经身份验证的工件下载，以执行受信任源策略。
 #6.4.4    等级: 2    角色: V
 验证存储库白名单是否每季度审查一次，并提供每个条目的业务理由证明。
 #6.4.5    等级: 3    角色: V
 验证策略违规是否会触发工件隔离和依赖流水线运行的回滚。

---

### C6.5 第三方数据集风险评估

评估外部数据集的投毒、偏见和法律合规性，并在其整个生命周期内进行监控。

 #6.5.1    等级: 1    角色: D/V
 验证外部数据集是否经过中毒风险评分（例如，数据指纹识别、异常值检测）。
 #6.5.2    等级: 1    角色: D
 确认在数据集批准之前计算偏差指标（人口统计平等、机会均等）。
 #6.5.3    等级: 2    角色: V
 验证在 ML-BOM 条目中是否已捕获数据集的来源和许可条款。
 #6.5.4    等级: 2    角色: V
 验证定期监控是否能够检测托管数据集中的漂移或损坏。
 #6.5.5    等级: 3    角色: D
 验证在训练之前，通过自动清理已移除禁止内容（版权、个人身份信息）。

---

### C6.6 供应链攻击监控

通过 CVE 信息源、审计日志分析和红队演练，及早发现供应链威胁。

 #6.6.1    等级: 1    角色: V
 验证 CI/CD 审计日志是否流向 SIEM，以检测异常的软件包拉取或被篡改的构建步骤。
 #6.6.2    等级: 2    角色: D
 验证事件响应剧本是否包含对受损模型或库的回滚程序。
 #6.6.3    等级: 3    角色: V
 验证威胁情报丰富功能是否在警报分类中标记了特定于机器学习的指标（例如，模型投毒的 IoC）。

---

### C6.7 模型工件的机器学习物料清单 (ML-BOM)

生成并签署详细的专用于机器学习的软 件物料清单（ML-BOMs），以便下游使用者在部署时验证组件的完整性。

 #6.7.1    等级: 1    角色: D/V
 确保每个模型产物都发布一个机器学习物料清单（ML-BOM），列出数据集、权重、超参数和许可证。
 #6.7.2    等级: 1    角色: D/V
 验证 ML-BOM 生成和 Cosign 签名已在持续集成（CI）中自动化，并且为合并所必需。
 #6.7.3    等级: 2    角色: D
 验证如果任何组件元数据（哈希、许可证）缺失，ML-BOM 完整性检查会导致构建失败。
 #6.7.4    等级: 2    角色: V
 验证下游使用者是否能够通过API查询ML-BOM，以在部署时验证导入的模型。
 #6.7.5    等级: 3    角色: V
 验证 ML-BOM 是否经过版本控制并进行差异比较以检测未授权的修改。

---

### 参考文献

ML Supply Chain Compromise – MITRE ATLAS
Supply‑chain Levels for Software Artifacts (SLSA)
CycloneDX – Machine Learning Bill of Materials
What is Data Poisoning? – SentinelOne
Transfer Learning Attack – OWASP ML Security Top 10
AI Data Security Best Practices – CISA
Secure CI/CD Supply Chain – Sumo Logic
AI & Transparency: Protect ML Models – ReversingLabs
SBOM Overview – CISA
Training Data Poisoning Guide – Lakera.ai
Dependency Pinning for Reproducible Python – Medium

## C7 模型行为、输出控制与安全保障

### 控制目标

模型输出必须具有结构化、可靠、安全、可解释性，并在生产环境中持续监控。这样可以减少幻觉、隐私泄露、有害内容和失控行为，同时提升用户信任和合规性。

---

### C7.1 输出格式强制执行

严格的模式、受限解码和下游验证在错误格式或恶意内容传播之前将其阻止。

 #7.1.1    等级: 1    角色: D/V
 验证系统提示中是否提供了响应模式（例如，JSON Schema），并且每个输出都自动进行验证；不符合规范的输出会触发修复或拒绝。
 #7.1.2    等级: 1    角色: D/V
 验证是否启用了受限解码（停止标记、正则表达式、最大令牌数）以防止溢出或提示注入侧信道。
 #7.1.3    等级: 2    角色: D/V
 验证下游组件将输出视为不可信，并根据模式或防注入的反序列化器对其进行验证。
 #7.1.4    等级: 3    角色: V
 验证不当输出事件是否被记录、速率限制并呈现于监控系统。

---

### C7.2 幻觉检测与缓解

不确定性估计和回退策略抑制虚假回答。

 #7.2.1    等级: 1    角色: D/V
 验证令牌级别的对数概率、集成自洽性或微调的幻觉检测器是否为每个答案分配了置信度分数。
 #7.2.2    等级: 1    角色: D/V
 验证低于可配置置信度阈值的响应是否触发回退工作流（例如，检索增强生成、二级模型或人工审核）。
 #7.2.3    等级: 2    角色: D/V
 验证幻觉事件是否带有根本原因元数据标记，并传送至事后分析和微调流程。
 #7.2.4    等级: 3    角色: D/V
 确认在重大模型或知识库更新后，阈值和检测器已重新校准。
 #7.2.5    等级: 3    角色: V
 验证仪表板可视化是否跟踪幻觉率。

---

### C7.3 输出安全与隐私过滤

策略过滤器和红队覆盖保护用户和机密数据。

 #7.3.1    等级: 1    角色: D/V
 验证生成前后分类器是否阻止符合政策的仇恨、骚扰、自残、极端主义和性露骨内容。
 #7.3.2    等级: 1    角色: D/V
 验证每个响应中是否运行了PII/PCI检测和自动涂黑；违规情况将引发隐私事件。
 #7.3.3    等级: 2    角色: D
 验证机密性标签（例如，商业秘密）是否在多模态间传播，以防止在文本、图像或代码中泄露。
 #7.3.4    等级: 3    角色: D/V
 验证过滤器绕过尝试或高风险分类是否需要二次审批或用户重新身份验证。
 #7.3.5    等级: 3    角色: D/V
 验证过滤阈值是否符合法律管辖区以及用户年龄/角色的上下文。

---

### C7.4 输出与操作限制

速率限制和审批门槛防止滥用和过度自主。

 #7.4.1    等级: 1    角色: D
 验证每个用户和每个 API 密钥的配额是否限制请求、令牌和成本，并在出现 429 错误时进行指数回退。
 #7.4.2    等级: 1    角色: D/V
 验证特权操作（文件写入、代码执行、网络调用）是否需要基于策略的批准或人机交互审批。
 #7.4.3    等级: 2    角色: D/V
 验证跨模态一致性检查确保为同一请求生成的图像、代码和文本无法用于走私恶意内容。
 #7.4.4    等级: 2    角色: D
 验证代理委托深度、递归限制和允许的工具列表是否已明确配置。
 #7.4.5    等级: 3    角色: V
 验证限制违规是否会触发结构化的安全事件以供 SIEM 采集。

---

### C7.5 输出可解释性

透明信号提升了用户信任和内部调试效率。

 #7.5.1    等级: 2    角色: D/V
 确认在风险评估认为适当时，向用户展示信心分数或简要的推理摘要。
 #7.5.2    等级: 2    角色: D/V
 验证生成的解释是否避免泄露敏感的系统提示或专有数据。
 #7.5.3    等级: 3    角色: D
 验证系统是否捕获了令牌级别的对数概率或注意力图，并将其存储以供授权检查。
 #7.5.4    等级: 3    角色: V
 验证解释性工件是否与模型发布一起进行版本控制以确保可审计性。

---

### C7.6 监控集成

实时可观察性实现了开发与生产之间的闭环。

 #7.6.1    等级: 1    角色: D
 验证指标（模式违规、幻觉率、毒性、个人身份信息泄露、延迟、成本）是否流向中央监控平台。
 #7.6.2    等级: 1    角色: V
 验证是否为每个安全指标定义了警报阈值，并设有呼叫升级路径。
 #7.6.3    等级: 2    角色: V
 验证仪表板是否将输出异常与模型/版本、功能标志和上游数据变化相关联。
 #7.6.4    等级: 2    角色: D/V
 验证监控数据是否反馈到重新训练、微调或规则更新中，并且这一过程在有文档记录的 MLOps 工作流程中。
 #7.6.5    等级: 3    角色: V
 确保监控管道经过渗透测试并实施访问控制，以避免敏感日志泄露。

---

### 7.7 生成媒体安全措施

通过执行政策约束、输出验证和可追溯性，确保人工智能系统不生成非法、有害或未经授权的媒体内容。

 #7.7.1    等级: 1    角色: D/V
 验证系统提示和用户指令明确禁止生成非法、有害或非自愿的深度伪造媒体（例如，图像、视频、音频）。
 #7.7.2    等级: 2    角色: D/V
 验证提示是否经过筛选，以防止生成冒充、色情深度假象或未经同意描绘真实个人的媒体内容。
 #7.7.3    等级: 2    角色: V
 验证系统是否使用感知哈希、水印检测或指纹识别来防止未经授权复制版权媒体。
 #7.7.4    等级: 3    角色: D/V
 验证所有生成的媒体是否经过加密签名、水印处理或嵌入防篡改的来源元数据，以确保下游可追溯性。
 #7.7.5    等级: 3    角色: V
 验证绕过尝试（例如，提示混淆、俚语、对抗性措辞）是否被检测、记录和限速；反复滥用情况会被反馈到监控系统。

### 参考文献

NIST AI Risk Management Framework
ISO/IEC 42001:2023 – AI Management System
OWASP Top-10 for Large Language Model Applications (2025)
Improper Output Handling – OWASP LLM05:2025
Practical Techniques to Constrain LLM Output
Dataiku – Structured Text Generation Guide
VL-Uncertainty: Detecting Hallucinations
HaDeMiF: Hallucination Detection & Mitigation
Building Confidence in LLM Outputs
Explainable AI & LLMs
LLM Red-Teaming Guide
Sensitive Information Disclosure in LLMs
LangChain – Chat Model Rate Limiting
OpenAI Rate-Limit & Exponential Back-off
Arize AI – LLM Observability Platform

## C8 存储器、嵌入和向量数据库安全

### 控制目标

嵌入和向量存储作为当代人工智能系统的“实时记忆”，不断接收用户提供的数据，并通过检索增强生成（RAG）将其重新呈现在模型上下文中。如果不加以管理，这种记忆可能泄露个人身份信息（PII）、违反用户同意，或者被逆向工程以重建原始文本。该控制类别的目标是强化记忆管道和向量数据库，确保访问权限最小化，嵌入具有隐私保护功能，存储的向量具有过期机制或能够按需撤销，并且每个用户的记忆绝不污染其他用户的提示或生成内容。

---

### C8.1 内存和RAG索引的访问控制

对每个向量集合实施细粒度访问控制。

 #8.1.1    等级: 1    角色: D/V
 验证行/命名空间级访问控制规则是否限制每个租户、集合或文档标签的插入、删除和查询操作。
 #8.1.2    等级: 1    角色: D/V
 验证 API 密钥或 JWT 是否包含作用域声明（例如，集合 ID、操作动词），并且至少每季度轮换一次。
 #8.1.3    等级: 2    角色: D/V
 验证权限提升尝试（例如，跨命名空间的相似性查询）是否在5分钟内被检测并记录到SIEM中。
 #8.1.4    等级: 2    角色: D/V
 验证向量数据库审计日志是否记录了主体标识符、操作、向量ID/命名空间、相似度阈值和结果数量。
 #8.1.5    等级: 3    角色: V
 确保在引擎升级或索引分片规则变更时，访问决策经过旁路缺陷测试。

---

### C8.2 嵌入清理与验证

在向量化之前，对文本进行预筛查以识别个人身份信息（PII），并进行遮盖或假名化，必要时对嵌入进行后处理以去除残留信号。

 #8.2.1    等级: 1    角色: D/V
 验证通过自动分类器检测到的个人身份信息（PII）和受监管数据是否在嵌入前被屏蔽、标记化或丢弃。
 #8.2.2    等级: 1    角色: D
 验证嵌入管道是否拒绝或隔离包含可执行代码或非 UTF-8 代码片段的输入，这些代码片段可能会污染索引。
 #8.2.3    等级: 2    角色: D/V
 验证对与任何已知个人身份信息（PII）标记的距离低于可配置阈值的句子嵌入应用了局部或度量差分隐私清理。
 #8.2.4    等级: 2    角色: V
 验证清理效果（例如，个人身份信息去除的召回率、语义漂移）是否至少每半年针对基准语料库进行一次验证。
 #8.2.5    等级: 3    角色: D/V
 验证清理配置是否受到版本控制，并且更改经过同行评审。

---

### C8.3 内存过期、撤销与删除

GDPR中的“被遗忘权”及类似法律要求及时删除；因此，向量存储必须支持TTL、硬删除和墓碑标记，以确保被撤销的向量无法恢复或重新索引。

 #8.3.1    等级: 1    角色: D/V
 验证每个向量和元数据记录是否包含由自动清理任务遵守的TTL或显式保留标签。
 #8.3.2    等级: 1    角色: D/V
 验证用户发起的删除请求在30天内清除向量、元数据、缓存副本和派生索引。
 #8.3.3    等级: 2    角色: D
 验证逻辑删除后，如果硬件支持，应进行存储块的加密销毁；否则应通过密钥库密钥销毁来完成。
 #8.3.4    等级: 3    角色: D/V
 验证过期向量在过期后500毫秒内从最近邻搜索结果中被排除。

---

### C8.4 防止嵌入反演和泄露

最近的防御措施——噪声叠加、投影网络、隐私神经扰动和应用层加密——可以将令牌级反转率降低到5%以下。

 #8.4.1    等级: 1    角色: V
 验证是否存在涵盖反演攻击、成员资格攻击和属性推断攻击的正式威胁模型，并且该模型每年进行审核。
 #8.4.2    等级: 2    角色: D/V
 验证应用层加密或可搜索加密是否能防止基础设施管理员或云工作人员直接读取向量。
 #8.4.3    等级: 3    角色: V
 验证防御参数（DP的ε值，噪声σ，投影秩k）在隐私保护≥99%令牌保护和效用≤3%准确率损失之间的平衡。
 #8.4.4    等级: 3    角色: D/V
 验证反转抗性指标是否作为模型更新发布门控的一部分，同时定义回归预算。

---

### C8.5 针对用户特定内存的范围强制执行

跨租户泄露仍然是RAG的主要风险：不当过滤的相似性查询可能会暴露其他客户的私人文档。

 #8.5.1    等级: 1    角色: D/V
 在传递给大型语言模型（LLM）提示之前，确保每个检索查询都经过租户/用户ID的后过滤。
 #8.5.2    等级: 1    角色: D
 验证集合名称或命名空间 ID 是否针对每个用户或租户进行了加盐处理，以确保向量在不同作用域间不会冲突。
 #8.5.3    等级: 2    角色: D/V
 验证超出调用者范围但超过可配置距离阈值的相似性结果是否被丢弃并触发安全警报。
 #8.5.4    等级: 2    角色: V
 验证多租户压力测试模拟了试图检索超出范围文档的对抗性查询，并且证明没有信息泄露。
 #8.5.5    等级: 3    角色: D/V
 验证加密密钥是否按租户隔离，确保即使物理存储共享也能实现密码学隔离。

---

### C8.6 高级内存系统安全

针对复杂内存架构（包括情景记忆、语义记忆和工作记忆）具有特定隔离和验证要求的安全控制。

 #8.6.1    等级: 1    角色: D/V
 验证不同的记忆类型（情景记忆、语义记忆、工作记忆）是否具有隔离的安全上下文，配备基于角色的访问控制、独立的加密密钥以及每种记忆类型的文档化访问模式。
 #8.6.2    等级: 2    角色: D/V
 验证记忆巩固过程是否包含安全验证，通过内容净化、来源验证和存储前的完整性检查，防止恶意记忆的注入。
 #8.6.3    等级: 2    角色: D/V
 验证内存检索查询是否经过验证和清理，以防止通过查询模式分析、访问控制执行和结果过滤提取未授权的信息。
 #8.6.4    等级: 3    角色: D/V
 验证内存遗忘机制是否通过密钥删除、多重覆盖或带有验证证书的基于硬件的安全删除，提供具有密码学擦除保证的敏感信息安全删除。
 #8.6.5    等级: 3    角色: D/V
 通过校验和、审计日志以及当内存内容在正常操作之外发生变化时的自动警报，验证内存系统完整性是否被持续监控，以防止未经授权的修改或损坏。

---

### 参考文献

Vector database security: Pinecone – IronCore Labs
Securing the Backbone of AI: Safeguarding Vector Databases and Embeddings – Privacera
Enhancing Data Security with RBAC of Qdrant Vector Database – AI Advances
Mitigating Privacy Risks in LLM Embeddings from Embedding Inversion – arXiv
DPPN: Detecting and Perturbing Privacy-Sensitive Neurons – OpenReview
Art. 17 GDPR – Right to Erasure
Sensitive Data in Text Embeddings Is Recoverable – Tonic.ai
PII Identification and Removal – NVIDIA NeMo Docs
De-identifying Sensitive Data – Google Cloud DLP
Remove PII from Conversations Using Sensitive Information Filters – AWS Bedrock Guardrails
Think Your RAG Is Secure? Think Again – Medium
Design a Secure Multitenant RAG Inferencing Solution – Microsoft Learn
Best Practices for Multi-Tenancy RAG with Milvus – Milvus Blog

## 9 自主编排与代理行动安全

### 控制目标

确保自主或多智能体 AI 系统只能执行明确意图的、经过身份验证的、可审计的操作，并且这些操作在有限的成本和风险阈值内。这可以防止自主系统被攻破、工具滥用、智能体循环检测、通信劫持、身份伪造、群体操控以及意图操控等威胁。

---

### 9.1 代理任务规划与递归预算

对递归计划进行限制，并强制在特权操作中设立人工检查点。

 #9.1.1    等级: 1    角色: D/V
 验证每个代理执行的最大递归深度、宽度、实际时间、令牌数和货币成本是否集中配置并进行版本控制。
 #9.1.2    等级: 1    角色: D/V
 验证特权或不可逆操作（例如，代码提交、资金转账）在执行前是否需要通过可审计渠道进行明确的人类批准。
 #9.1.3    等级: 2    角色: D
 验证实时资源监控器在任何预算阈值被超过时触发断路器中断，停止进一步的任务扩展。
 #9.1.4    等级: 2    角色: D/V
 验证断路器事件是否记录了代理ID、触发条件和捕获的计划状态以供法医审查。
 #9.1.5    等级: 3    角色: V
 验证安全测试涵盖预算耗尽和计划失控场景，确认能够安全终止且无数据丢失。
 #9.1.6    等级: 3    角色: D
 验证预算策略以代码即策略的形式表达，并在持续集成/持续交付（CI/CD）中强制执行，以阻止配置漂移。

---

### 9.2 工具插件沙箱化

隔离工具交互以防止未授权的系统访问或代码执行。

 #9.2.1    等级: 1    角色: D/V
 验证每个工具/插件是否在操作系统、容器或 WASM 级别的沙箱内执行，并且具有最小权限的文件系统、网络和系统调用策略。
 #9.2.2    等级: 1    角色: D/V
 验证沙箱资源配额（CPU、内存、磁盘、网络出口）和执行超时是否被强制执行并记录。
 #9.2.3    等级: 2    角色: D/V
 验证工具二进制文件或描述符是否经过数字签名；在加载之前验证签名。
 #9.2.4    等级: 2    角色: V
 验证沙箱遥测数据流是否传输到 SIEM；异常情况（例如，尝试的出站连接）会触发警报。
 #9.2.5    等级: 3    角色: V
 确保高风险插件在生产部署前经过安全审查和渗透测试。
 #9.2.6    等级: 3    角色: D/V
 验证沙箱逃逸尝试是否被自动阻止，并且违规插件是否被隔离以待调查。

---

### 9.3 自主循环与成本界定

检测并阻止失控的代理间递归和成本爆炸。

 #9.3.1    等级: 1    角色: D/V
 验证代理间调用是否包含运行时会递减并强制执行的跳数限制或生存时间（TTL）。
 #9.3.2    等级: 2    角色: D
 验证代理是否维护唯一的调用图ID，以便发现自我调用或循环模式。
 #9.3.3    等级: 2    角色: D/V
 验证累积计算单元和支出计数器是否按请求链进行跟踪；超出限制会中止该链。
 #9.3.4    等级: 3    角色: V
 验证形式分析或模型检查是否证明了代理协议中不存在无界递归。
 #9.3.5    等级: 3    角色: D
 验证循环中断事件是否生成警报并反馈持续改进指标。

---

### 9.4 协议级误用保护

保护代理与外部系统之间的安全通信通道，防止劫持或篡改。

 #9.4.1    等级: 1    角色: D/V
 验证所有代理到工具和代理到代理的消息是否经过身份验证（例如，双向 TLS 或 JWT）并且端到端加密。
 #9.4.2    等级: 1    角色: D
 确保架构被严格验证；未知字段或格式错误的消息将被拒绝。
 #9.4.3    等级: 2    角色: D/V
 验证完整性校验（消息认证码或数字签名）是否覆盖整个消息负载，包括工具参数。
 #9.4.4    等级: 2    角色: D
 验证在协议层强制执行重放保护（随机数或时间戳窗口）。
 #9.4.5    等级: 3    角色: V
 验证协议实现是否经过模糊测试和静态分析，以检测注入或反序列化漏洞。

---

### 9.5 代理身份与防篡改性

确保操作可溯源且修改可被检测。

 #9.5.1    等级: 1    角色: D/V
 验证每个代理实例是否拥有唯一的加密身份（密钥对或硬件根凭证）。
 #9.5.2    等级: 2    角色: D/V
 验证所有代理操作均已签名并带有时间戳；日志包含签名以实现不可否认性。
 #9.5.3    等级: 2    角色: V
 确认防篡改日志存储在仅追加或一次写入介质中。
 #9.5.4    等级: 3    角色: D
 验证身份密钥是否按照定义的时间表及在发现妥协指标时进行轮换。
 #9.5.5    等级: 3    角色: D/V
 验证欺骗或密钥冲突尝试是否会立即触发受影响代理的隔离。

---

### 9.6 多智能体群体风险降低

通过隔离和正式的安全建模来缓解集体行为风险。

 #9.6.1    等级: 1    角色: D/V
 验证在不同安全域中运行的代理是否在隔离的运行时沙箱或网络分段中执行。
 #9.6.2    等级: 3    角色: V
 在部署之前，验证群体行为的建模和形式验证是否覆盖了活性和安全性。
 #9.6.3    等级: 3    角色: D
 验证运行时监视器是否检测到紧急的不安全模式（例如，振荡、死锁）并启动纠正措施。

---

### 9.7 用户与工具认证/授权

为每个代理触发的操作实施强健的访问控制。

 #9.7.1    等级: 1    角色: D/V
 验证代理作为一流主体对下游系统进行身份验证，切勿重用终端用户凭据。
 #9.7.2    等级: 2    角色: D
 验证细粒度授权策略是否限制代理可调用的工具以及其可提供的参数。
 #9.7.3    等级: 2    角色: V
 验证权限检查是否在每次调用时重新评估（持续授权），而不仅仅是在会话开始时进行。
 #9.7.4    等级: 3    角色: D
 验证委托的权限是否会自动过期，并在超时或范围更改后需要重新同意。

---

### 9.8 代理到代理通信安全

加密并完整性保护所有代理间消息，以防止窃听和篡改。

 #9.8.1    等级: 1    角色: D/V
 验证代理通道必须使用双向身份验证和完美前向保密加密（例如 TLS 1.3）。
 #9.8.2    等级: 1    角色: D
 在处理之前验证消息的完整性和来源；验证失败将触发警报并丢弃该消息。
 #9.8.3    等级: 2    角色: D/V
 验证通信元数据（时间戳、序列号）是否被记录，以支持取证重构。
 #9.8.4    等级: 3    角色: V
 验证形式化验证或模型检验是否确认协议状态机无法进入不安全状态。

---

### 9.9 意图验证与约束执行

验证代理行为是否与用户的陈述意图和系统约束保持一致。

 #9.9.1    等级: 1    角色: D
 验证预执行约束求解器是否根据硬编码的安全和政策规则检查所提议的动作。
 #9.9.2    等级: 2    角色: D/V
 验证高影响操作（财务、破坏性、隐私敏感）是否需要发起用户的明确意图确认。
 #9.9.3    等级: 2    角色: V
 验证后置条件检查以确认已完成的操作实现了预期效果且无副作用；若有差异则触发回滚。
 #9.9.4    等级: 3    角色: V
 验证形式化方法（例如，模型检测、定理证明）或基于属性的测试是否证明代理计划满足所有声明的约束。
 #9.9.5    等级: 3    角色: D
 确认意图不匹配或约束违规事件能够推动持续改进周期和威胁情报共享。

---

### 9.10 代理推理策略安全

包括ReAct、Chain-of-Thought和Tree-of-Thoughts方法在内的不同推理策略的安全选择与执行。

 #9.10.1    等级: 1    角色: D/V
 验证推理策略选择是否使用确定性标准（输入复杂性、任务类型、安全上下文），并确保在相同安全上下文中，完全相同的输入产生相同的策略选择。
 #9.10.2    等级: 1    角色: D/V
 验证每种推理策略（ReAct、Chain-of-Thought、Tree-of-Thoughts）是否具有专门针对其认知方法的输入验证、输出清理和执行时间限制。
 #9.10.3    等级: 2    角色: D/V
 验证推理策略转换是否记录了完整的上下文，包括输入特性、选择标准值和执行元数据，以便进行审计跟踪重建。
 #9.10.4    等级: 2    角色: D/V
 验证树状思维推理是否包含分支剪枝机制，当检测到策略违规、资源限制或安全边界时终止探索。
 #9.10.5    等级: 2    角色: D/V
 验证 ReAct（推理-行动-观察）循环在每个阶段均包含验证检查点：推理步骤验证、行动授权和观察清理，确保在继续进行之前完成这些步骤。
 #9.10.6    等级: 3    角色: D/V
 验证当度量指标偏离配置阈值时，推理策略的性能指标（执行时间、资源使用、输出质量）是否通过自动警报进行监控。
 #9.10.7    等级: 3    角色: D/V
 验证结合多种策略的混合推理方法是否保持所有组成策略的输入验证和输出约束，且未绕过任何安全控制。
 #9.10.8    等级: 3    角色: D/V
 验证推理策略安全测试是否包括使用格式错误的输入进行模糊测试、设计用于强制策略切换的对抗性提示，以及对每种认知方法进行边界条件测试。

---

### 9.11 代理生命周期状态管理与安全

通过加密审计轨迹和定义的恢复程序，实现安全代理初始化、状态转换和终止。

 #9.11.1    等级: 1    角色: D/V
 验证代理初始化是否包括使用硬件支持的凭证建立加密身份以及包含代理ID、时间戳、配置哈希和初始化参数的不可变启动审计日志。
 #9.11.2    等级: 2    角色: D/V
 验证代理状态转换是否经过加密签名、时间戳标记，并且完整记录上下文信息，包括触发事件、前一状态哈希、新状态哈希以及执行的安全验证。
 #9.11.3    等级: 2    角色: D/V
 验证代理关闭程序是否包括使用加密擦除或多遍覆盖进行安全内存清除、凭证吊销并通知证书颁发机构，以及生成防篡改的终止证书。
 #9.11.4    等级: 3    角色: D/V
 验证代理恢复机制是否使用加密校验和（至少为SHA-256）来验证状态完整性，并在检测到损坏时回滚到已知良好状态，同时配备自动警报和人工审批要求。
 #9.11.5    等级: 3    角色: D/V
 验证代理持久化机制是否使用每个代理的 AES-256 密钥加密敏感状态数据，并在可配置的时间表（最长 90 天）上实现安全的密钥轮换，且支持零停机部署。

---

### 9.12 工具集成安全框架

动态工具加载、执行和结果验证的安全控制，配合已定义的风险评估和审批流程。

 #9.12.1    等级: 1    角色: D/V
 验证工具描述符是否包含安全元数据，指定所需权限（读/写/执行）、风险级别（低/中/高）、资源限制（CPU、内存、网络）以及在工具清单中记录的验证要求。
 #9.12.2    等级: 1    角色: D/V
 验证工具执行结果是否符合预期的架构（JSON Schema、XML Schema）和安全策略（输出清理、数据分类），并在集成前设定超时限制和错误处理流程。
 #9.12.3    等级: 2    角色: D/V
 验证工具交互日志是否包含详细的安全上下文，包括权限使用情况、数据访问模式、执行时间、资源消耗和返回码，并采用结构化日志记录以便集成SIEM。
 #9.12.4    等级: 2    角色: D/V
 验证动态工具加载机制是否使用公钥基础设施（PKI）验证数字签名，并实施具有沙箱隔离和执行前权限验证的安全加载协议。
 #9.12.5    等级: 3    角色: D/V
 验证工具安全评估是否针对新版本自动触发，并包含强制性的审批关卡，包括静态分析、动态测试和安全团队审查，且具备文档化的审批标准和服务等级协议（SLA）要求。

---

#### 参考文献

MITRE ATLAS tactics ML09
Circuit-breaker research for AI agents — Zou et al., 2024
Trend Micro analysis of sandbox escapes in AI agents — Park, 2025
Auth0 guidance on human-in-the-loop authorization for agents — Martinez, 2025
Medium deep-dive on MCP & A2A protocol hijacking — ForAISec, 2025
Rapid7 fundamentals on spoofing attack prevention — 2024
Imperial College verification of swarm systems — Lomuscio et al.
NIST AI Risk Management Framework 1.0, 2023
WIRED security briefing on encryption best practices, 2024
OWASP Top 10 for LLM Applications, 2025
Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS
[How Is LLM Reasoning Distracted by Irrelevant Context?
An Analysis Using a Controlled Benchmark](https://www.arxiv.org/pdf/2505.18761)
Large Language Model Sentinel: LLM Agent for Adversarial Purification
Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents

## 10 对抗鲁棒性与隐私防护

### 控制目标

确保在面对规避、推断、提取或中毒攻击时，人工智能模型依然保持可靠性、隐私保护和抗滥用能力。

---

### 10.1 模型对齐与安全

防范有害或违反政策的输出。

 #10.1.1    等级: 1    角色: D/V
 验证对齐测试套件（红队提示、越狱探针、禁止内容）是否进行版本控制，并在每个模型发布时运行。
 #10.1.2    等级: 1    角色: D
 验证拒绝和安全完成保护措施是否得到执行。
 #10.1.3    等级: 2    角色: D/V
 验证自动评估器是否测量有害内容率并标记超过设定阈值的回归。
 #10.1.4    等级: 2    角色: D
 验证反越狱训练是否有文档记录且可复现。
 #10.1.5    等级: 3    角色: V
 验证正式的政策合规性证明或认证监控是否涵盖关键领域。

---

### 10.2 对抗样本强化

提高对操纵输入的弹性。稳健的对抗训练和基准评分是当前的最佳实践。

 #10.2.1    等级: 1    角色: D
 验证项目代码库中是否包含带有可复现种子的对抗训练配置。
 #10.2.2    等级: 2    角色: D/V
 验证对抗样本检测是否在生产流水线中触发阻断警报。
 #10.2.4    等级: 3    角色: V
 验证经过认证的鲁棒性证明或区间边界证书是否涵盖至少最关键的顶级类别。
 #10.2.5    等级: 3    角色: V
 验证回归测试使用自适应攻击以确认没有可测量的鲁棒性损失。

---

### 10.3 成员推断缓解

限制判断某条记录是否在训练数据中的能力。差分隐私和置信度得分掩蔽仍然是已知最有效的防御措施。

 #10.3.1    等级: 1    角色: D
 验证每个查询的熵正则化或温度缩放是否能减少过度自信的预测。
 #10.3.2    等级: 2    角色: D
 验证训练是否对敏感数据集采用了ε界限差分隐私优化。
 #10.3.3    等级: 2    角色: V
 验证攻击仿真（影子模型或黑盒攻击）在保留数据上的攻击AUC ≤ 0.60。

---

### 10.4 模型反演抗性

防止私有属性的重建。近期调查强调输出截断和差分隐私（DP）保障作为实用的防御措施。

 #10.4.1    等级: 1    角色: D
 确保敏感属性绝不直接输出；在必要时，使用分桶或单向转换。
 #10.4.2    等级: 1    角色: D/V
 验证查询速率限制是否对来自同一主体的重复自适应查询进行节流。
 #10.4.3    等级: 2    角色: D
 验证模型是否经过隐私保护噪声训练。

---

### 10.5 模型提取防御

检测和阻止未经授权的克隆。建议采用水印技术和查询模式分析。

 #10.5.1    等级: 1    角色: D
 验证推理网关是否执行全局和每个 API 密钥的速率限制，并调整到模型的记忆阈值。
 #10.5.2    等级: 2    角色: D/V
 验证查询熵和输入复数度统计是否为自动提取检测器提供数据。
 #10.5.3    等级: 2    角色: V
 验证脆弱或概率水印可通过对疑似克隆的≤ 1 000次查询，以p < 0.01的显著性水平进行证明。
 #10.5.4    等级: 3    角色: D
 验证水印密钥和触发集是否存储在硬件安全模块中并每年轮换。
 #10.5.5    等级: 3    角色: V
 验证提取警报事件是否包含违规查询，并且是否已与事件响应剧本集成。

---

### 10.6 推理时的中毒数据检测

识别并中和带有后门或被投毒的输入。

 #10.6.1    等级: 1    角色: D
 在模型推理之前，验证输入是否通过异常检测器（例如，STRIP、一致性评分）。
 #10.6.2    等级: 1    角色: V
 验证检测器阈值是否在干净/被污染的验证集上进行调整，以实现低于5%的假阳性率。
 #10.6.3    等级: 2    角色: D
 验证被标记为中毒的输入是否会触发软阻止和人工审核工作流程。
 #10.6.4    等级: 2    角色: V
 验证检测器是否经过适应性、无触发后门攻击的压力测试。
 #10.6.5    等级: 3    角色: D
 验证检测效果指标是否已被记录，并定期使用最新的威胁情报重新评估。

---

### 10.7 动态安全策略适应

基于威胁情报和行为分析的实时安全策略更新。

 #10.7.1    等级: 1    角色: D/V
 验证安全策略是否可以动态更新且无需重启代理，同时保持策略版本的完整性。
 #10.7.2    等级: 2    角色: D/V
 验证策略更新是否由授权的安全人员进行加密签名，并在应用前进行验证。
 #10.7.3    等级: 2    角色: D/V
 验证动态策略变更是否带有完整的审计跟踪记录，包括理由、审批链和回滚程序。
 #10.7.4    等级: 3    角色: D/V
 验证自适应安全机制是否根据风险环境和行为模式调整威胁检测的灵敏度。
 #10.7.5    等级: 3    角色: D/V
 验证策略调整决策的可解释性，并包含供安全团队审查的证据链。

---

### 10.8 基于反射的安全分析

通过代理自我反思和元认知分析进行安全验证。

 #10.8.1    等级: 1    角色: D/V
 验证代理反思机制是否包括针对决策和行动的以安全为中心的自我评估。
 #10.8.2    等级: 2    角色: D/V
 验证反射输出以防止敌对输入操控自我评估机制。
 #10.8.3    等级: 2    角色: D/V
 验证元认知安全分析是否能识别代理推理过程中的潜在偏见、操纵或妥协。
 #10.8.4    等级: 3    角色: D/V
 验证基于反射的安全警告是否触发了增强监控和潜在人为干预工作流程。
 #10.8.5    等级: 3    角色: D/V
 验证从安全反思中进行的持续学习是否能提升威胁检测能力且不影响合法功能。

---

### 10.9 演化与自我改进安全

具备自我修改和进化能力的智能体系统的安全控制措施。

 #10.9.1    等级: 1    角色: D/V
 验证自我修改功能是否仅限于指定的安全区域，并设有正式验证边界。
 #10.9.2    等级: 2    角色: D/V
 确保演进提案在实施前经过安全影响评估。
 #10.9.3    等级: 2    角色: D/V
 验证自我改进机制包括带有完整性验证的回滚能力。
 #10.9.4    等级: 3    角色: D/V
 验证元学习安全性是否能够防止改进算法的对抗性操纵。
 #10.9.5    等级: 3    角色: D/V
 证明递归自我改进受形式安全约束的限制，并用数学证明其收敛性。

---

#### 参考文献

MITRE ATLAS adversary tactics for ML
NIST AI Risk Management Framework 1.0, 2023
OWASP Top 10 for LLM Applications, 2025
Adversarial Training: A Survey — Zhao et al., 2024
RobustBench adversarial-robustness benchmark
Membership-Inference & Model-Inversion Risk Survey, 2025
PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023
Model-Inversion Attacks & Defenses Survey — AI Review, 2025
Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024
Fragile Model Watermarking Survey — 2025
Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025
BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024

## 11 隐私保护与个人数据管理

### 控制目标

在整个 AI 生命周期——数据收集、训练、推理和事件响应过程中，保持严格的隐私保证，确保个人数据仅在明确同意、最小必要范围、可验证删除以及正式隐私保障的前提下进行处理。

---

### 11.1 匿名化与数据最小化

 #11.1.1    等级: 1    角色: D/V
 验证直接标识符和准标识符已被移除或哈希处理。
 #11.1.2    等级: 2    角色: D/V
 验证自动审计是否测量了k-匿名性/l-多样性，并在阈值低于策略时发出警报。
 #11.1.3    等级: 2    角色: V
 验证模型特征重要性报告，确保没有超过 ε = 0.01 互信息的标识符泄露。
 #11.1.4    等级: 3    角色: V
 验证形式化证明或合成数据认证即使在链接攻击下也能显示重新识别风险 ≤ 0.05。

---

### 11.2 被遗忘权与删除执行

 #11.2.1    等级: 1    角色: D/V
 验证数据主体删除请求是否在少于30天的服务水平协议内传播到原始数据集、检查点、嵌入、日志和备份。
 #11.2.2    等级: 2    角色: D
 验证“机器遗忘”程序是否通过认证的遗忘算法进行物理再训练或近似移除。
 #11.2.3    等级: 2    角色: V
 验证影子模型评估证明遗忘记录在消除学习后对输出的影响小于1%。
 #11.2.4    等级: 3    角色: V
 验证删除事件是否被不可变地记录并且可供监管机构审计。

---

### 11.3 差分隐私保护措施

 #11.3.1    等级: 2    角色: D/V
 验证隐私损失核算仪表板在累计ε超过政策阈值时发出警报。
 #11.3.2    等级: 2    角色: V
 验证黑盒隐私审计是否能在声明值的10%范围内估计出 ε̂。
 #11.3.3    等级: 3    角色: V
 验证形式证明是否涵盖所有训练后微调和嵌入。

---

### 11.4 目的限制与范围蔓延保护

 #11.4.1    等级: 1    角色: D
 验证每个数据集和模型检查点都携带与原始同意一致的机器可读用途标签。
 #11.4.2    等级: 1    角色: D/V
 验证运行时监控器是否检测到与声明目的不一致的查询并触发软拒绝。
 #11.4.3    等级: 3    角色: D
 验证策略即代码门禁是否阻止在未经数据保护影响评估（DPIA）审查的情况下，将模型重新部署到新域。
 #11.4.4    等级: 3    角色: V
 验证正式的可追溯性证明，确保每个个人数据生命周期均保持在已同意的范围内。

---

### 11.5 同意管理与合法依据跟踪

 #11.5.1    等级: 1    角色: D/V
 验证同意管理平台（CMP）是否记录了每个数据主体的同意状态、用途和保留期限。
 #11.5.2    等级: 2    角色: D
 验证API是否暴露同意令牌；模型在推理前必须验证令牌的范围。
 #11.5.3    等级: 2    角色: D/V
 验证被拒绝或撤回的同意是否在24小时内停止处理流程。

---

### 11.6 带有隐私控制的联邦学习

 #11.6.1    等级: 1    角色: D
 验证客户端更新在聚合之前是否采用局部差分隐私噪声添加。
 #11.6.2    等级: 2    角色: D/V
 验证训练指标具有差分隐私性，且绝不泄露单个客户端的损失。
 #11.6.3    等级: 2    角色: V
 验证已启用抗投毒聚合（例如，Krum/裁剪均值）。
 #11.6.4    等级: 3    角色: V
 验证形式证明显示总体ε预算下效用损失小于5。

---

#### 参考文献

GDPR & AI Compliance Best Practices
EU Parliament Study on GDPR & AI, 2020
ISO 31700-1:2023 — Privacy by Design for Consumer Products
NIST Privacy Framework 1.1 (2025 Draft)
Machine Unlearning: Right-to-Be-Forgotten Techniques
A Survey of Machine Unlearning, 2024
Auditing DP-SGD — ArXiv 2024
DP-SGD Explained — PyTorch Blog
Purpose-Limitation for AI — IJLIT 2025
Data-Protection Considerations for AI — URM Consulting
Top Consent-Management Platforms, 2025
Secure Aggregation in DP Federated Learning — ArXiv 2024

## C12 监控、日志记录与异常检测

### 控制目标

本节提供了对模型及其他人工智能组件所见、所做和所返回内容的实时和取证可见性交付要求，以便能够检测、分类和学习威胁。

### C12.1 请求与响应日志记录

 #12.1.1    等级: 1    角色: D/V
 验证所有用户提示和模型响应是否使用适当的元数据（例如时间戳、用户ID、会话ID、模型版本）进行记录。
 #12.1.2    等级: 1    角色: D/V
 验证日志是否存储在安全的、受访问控制的存储库中，并具有适当的保留策略和备份程序。
 #12.1.3    等级: 1    角色: D/V
 验证日志存储系统是否实现了静态加密和传输加密，以保护日志中包含的敏感信息。
 #12.1.4    等级: 1    角色: D/V
 验证提示和输出中的敏感数据在记录之前是否被自动编辑或遮蔽，并且具有可配置的编辑规则，用于个人身份信息（PII）、凭证和专有信息。
 #12.1.5    等级: 2    角色: D/V
 验证策略决策和安全过滤操作是否以足够详细的方式记录，以便对内容审核系统进行审计和调试。
 #12.1.6    等级: 2    角色: D/V
 通过例如加密签名或只写存储验证日志完整性是否受到保护。

---

### C12.2 滥用检测和警报

 #12.2.1    等级: 1    角色: D/V
 验证系统是否能够使用基于特征的检测方法识别并警报已知的越狱模式、提示注入尝试和对抗性输入。
 #12.2.2    等级: 1    角色: D/V
 验证系统是否使用标准日志格式和协议与现有的安全信息与事件管理（SIEM）平台集成。
 #12.2.3    等级: 2    角色: D/V
 验证丰富的安全事件是否包含特定于人工智能的上下文，例如模型标识符、置信度评分和安全过滤器决策。
 #12.2.4    等级: 2    角色: D/V
 验证行为异常检测是否能够识别异常的对话模式、过多的重试尝试或系统性的探测行为。
 #12.2.5    等级: 2    角色: D/V
 验证实时警报机制在检测到潜在的政策违规或攻击尝试时是否通知安全团队。
 #12.2.6    等级: 2    角色: D/V
 验证是否包含自定义规则以检测特定于人工智能的威胁模式，包括协调的越狱尝试、提示注入活动和模型提取攻击。
 #12.2.7    等级: 3    角色: D/V
 验证自动化事件响应工作流能否隔离受损模型、阻止恶意用户并升级关键安全事件。

---

### C12.3 模型漂移检测

 #12.3.1    等级: 1    角色: D/V
 验证系统是否跟踪基本的性能指标，如准确率、置信度评分、延迟和错误率，涵盖不同模型版本和时间段。
 #12.3.2    等级: 2    角色: D/V
 验证当性能指标超过预定义的降级阈值或明显偏离基线时，自动告警是否触发。
 #12.3.3    等级: 2    角色: D/V
 验证幻觉检测监控是否能够识别并标记模型输出中包含事实错误、不一致或虚构信息的情况。

---

### C12.4 性能与行为遥测

 #12.4.1    等级: 1    角色: D/V
 验证操作指标，包括请求延迟、令牌消耗、内存使用和吞吐量，是否被持续收集和监控。
 #12.4.2    等级: 1    角色: D/V
 验证是否对成功率和失败率进行跟踪，并对错误类型及其根本原因进行分类。
 #12.4.3    等级: 2    角色: D/V
 验证资源利用率监控包括GPU/CPU使用率、内存消耗和存储需求，并在阈值突破时发出警报。

---

### C12.5 AI 事件响应计划与执行

 #12.5.1    等级: 1    角色: D/V
 验证事件响应计划是否专门针对与人工智能相关的安全事件，包括模型被破坏、数据投毒和对抗性攻击，进行了具体应对。
 #12.5.2    等级: 2    角色: D/V
 确认事件响应团队具备访问针对人工智能特定的取证工具和专业知识，以调查模型行为和攻击向量。
 #12.5.3    等级: 3    角色: D/V
 验证事故后分析是否包括模型再训练的考虑、安全过滤器的更新，以及将经验教训整合到安全控制中。

---

### C12.5 AI性能下降检测

监控并检测AI模型性能和质量随时间的下降。

 #12.5.1    等级: 1    角色: D/V
 确保持续监控模型的准确率、精确率、召回率和F1分数，并将其与基线阈值进行比较。
 #12.5.2    等级: 1    角色: D/V
 验证数据漂移检测是否监控可能影响模型性能的输入分布变化。
 #12.5.3    等级: 2    角色: D/V
 验证概念漂移检测能够识别输入与预期输出之间关系的变化。
 #12.5.4    等级: 2    角色: D/V
 验证性能下降是否触发自动警报并启动模型再训练或替换工作流程。
 #12.5.5    等级: 3    角色: V
 验证性能下降的根本原因分析是否将性能下降与数据变化、基础设施问题或外部因素相关联。

---

### C12.6 DAG 可视化与工作流安全

保护工作流可视化系统免受信息泄漏和操控攻击。

 #12.6.1    等级: 1    角色: D/V
 验证DAG可视化数据在存储或传输前已被清理，以移除敏感信息。
 #12.6.2    等级: 1    角色: D/V
 验证工作流可视化访问控制，确保只有授权用户才能查看代理决策路径和推理轨迹。
 #12.6.3    等级: 2    角色: D/V
 验证通过加密签名和防篡改存储机制保护DAG数据完整性。
 #12.6.4    等级: 2    角色: D/V
 验证工作流可视化系统是否实施了输入验证，以防止通过精心构造的节点或边数据进行的注入攻击。
 #12.6.5    等级: 3    角色: D/V
 验证实时DAG更新是否受到速率限制和验证，以防止对可视化系统的拒绝服务攻击。

---

### C12.7 主动安全行为监控

通过主动代理行为分析进行安全威胁的检测和预防。

 #12.7.1    等级: 1    角色: D/V
 在执行前，验证主动代理行为经过安全验证，并集成风险评估。
 #12.7.2    等级: 2    角色: D/V
 验证自主主动触发器是否包括安全上下文评估和威胁态势评估。
 #12.7.3    等级: 2    角色: D/V
 验证主动行为模式是否被分析以识别潜在的安全影响和意外后果。
 #12.7.4    等级: 3    角色: D/V
 验证安全关键的主动操作需要明确的审批链和审计跟踪。
 #12.7.5    等级: 3    角色: D/V
 验证行为异常检测能识别前瞻性代理模式中的偏差，这些偏差可能表明被攻破。

---

### 参考文献

NIST AI Risk Management Framework 1.0 - Manage 4.1 and 4.3
ISO/IEC 42001:2023 — AI Management Systems Requirements - Annex B 6.2.6
EU AI Act — Article 12, 13, 16 and 19 on Logging and Record-keeping

## C13 人类监督、问责与治理

### 控制目标

本章提供了维护人工监督和明确责任链的要求，确保在人工智能系统的整个生命周期中实现可解释性、透明度和伦理管理。

---

### C13.1 终止开关与覆盖机制

在观察到 AI 系统出现不安全行为时，提供关闭或回滚路径。

 #13.1.1    等级: 1    角色: D/V
 确认存在手动停机机制，以立即停止 AI 模型推理和输出。
 #13.1.2    等级: 1    角色: D
 核实覆盖控制仅对授权人员可访问。
 #13.1.3    等级: 3    角色: D/V
 验证回滚程序是否能够恢复到先前的模型版本或安全模式操作。
 #13.1.4    等级: 3    角色: V
 验证覆盖机制是否定期进行测试。

---

### C13.2 人工参与决策检查点

当风险超过预定义阈值时，要求人工批准。

 #13.2.1    等级: 1    角色: D/V
 确保高风险的人工智能决策在执行前需要明确的人类批准。
 #13.2.2    等级: 1    角色: D
 验证风险阈值是否明确定义并自动触发人工审核流程。
 #13.2.3    等级: 2    角色: D
 验证在无法在规定时间内获得人工批准时，时间敏感的决策是否有备用程序。
 #13.2.4    等级: 3    角色: D/V
 如果适用，请确认升级程序为不同的决策类型或风险类别规定了明确的权限级别。

---

### C13.3 责任链与可审计性

记录操作者的操作和模型的决策。

 #13.3.1    等级: 1    角色: D/V
 验证所有 AI 系统决策和人工干预均已记录时间戳、用户身份及决策理由。
 #13.3.2    等级: 2    角色: D
 验证审计日志无法被篡改，并包括完整性验证机制。

---

### C13.4 可解释人工智能技术

表面特征重要性、反事实和局部解释。

 #13.4.1    等级: 1    角色: D/V
 验证AI系统是否以可供人类理解的格式提供其决策的基本解释。
 #13.4.2    等级: 2    角色: V
 确保解释质量通过人工评估研究和指标进行验证。
 #13.4.3    等级: 3    角色: D/V
 确认关键决策是否具有特征重要性分数或归因方法（SHAP、LIME 等）。
 #13.4.4    等级: 3    角色: V
 验证反事实解释是否展示了如何修改输入以改变结果，前提是这适用于具体的用例和领域。

---

### C13.5 模型卡与使用披露

维护模型卡，以记录预期用途、性能指标和伦理考量。

 #13.5.1    等级: 1    角色: D
 验证模型卡是否记录了预期的使用案例、局限性及已知的失败模式。
 #13.5.2    等级: 1    角色: D/V
 验证是否披露了不同适用用例中的性能指标。
 #13.5.3    等级: 2    角色: D
 确保伦理考量、偏见评估、公平性评估、训练数据特征及已知训练数据限制均有记录并定期更新。
 #13.5.4    等级: 2    角色: D/V
 验证模型卡是否在整个模型生命周期中进行版本控制和维护，并带有变更跟踪。

---

### C13.6 不确定性量化

在响应中传播置信度分数或熵度量。

 #13.6.1    等级: 1    角色: D
 验证人工智能系统是否为其输出提供置信度分数或不确定性度量。
 #13.6.2    等级: 2    角色: D/V
 验证不确定性阈值是否触发额外的人类审核或替代决策路径。
 #13.6.3    等级: 2    角色: V
 验证不确定性量化方法是否经过校准并以真实数据进行验证。
 #13.6.4    等级: 3    角色: D/V
 验证不确定性传播在多步骤人工智能工作流程中得以保持。

---

### C13.7 面向用户的透明度报告

定期披露关于事件、漂移和数据使用的情况。

 #13.7.1    等级: 1    角色: D/V
 确保数据使用政策和用户同意管理措施清晰地传达给利益相关者。
 #13.7.2    等级: 2    角色: D/V
 核实是否进行了人工智能影响评估，并将结果纳入报告中。
 #13.7.3    等级: 2    角色: D/V
 验证定期发布的透明度报告是否以合理的详细程度披露了人工智能事件和运营指标。

#### 参考文献

EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
ISO/IEC 42001:2023 — AI Management Systems Requirements
NIST AI Risk Management Framework 1.0
NIST SP 800-53 Revision 5 — Security and Privacy Controls
A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)
Model Cards for Model Reporting (Mitchell et al., 2018)
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)
ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods
IEEE 7001-2021 — Transparency of Autonomous Systems
GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)
Human Oversight under Article 14 of the EU AI Act (Fink, 2025)

## 附录 A：术语表

本综合词汇表提供了AISVS中使用的关键人工智能、机器学习和安全术语的定义，以确保清晰和共识。

对抗样本：一种故意设计的输入，旨在导致人工智能模型出错，通常通过添加人类难以察觉的微妙扰动。
​
对抗鲁棒性——AI中的对抗鲁棒性指的是模型保持其性能并抵抗那些故意设计用来引起错误的恶意输入所造成的欺骗或操控的能力。
​
智能体——智能体是使用人工智能代表用户追求目标和完成任务的软件系统。它们表现出推理、规划和记忆能力，并具备一定程度的自主性，能够做出决策、学习和适应。
​
具代理性的人工智能：能够以一定程度的自主性运行以实现目标的人工智能系统，通常在没有直接人工干预的情况下做出决策和采取行动。
​
基于属性的访问控制（ABAC）：一种访问控制范式，其授权决策基于用户、资源、操作和环境的属性，并在查询时进行评估。
​
后门攻击：一种数据投毒攻击，模型被训练成对某些触发器作出特定响应，而在其他情况下表现正常。
​
偏差：AI模型输出中的系统性错误，可能导致某些群体或特定情境下的不公平或歧视性结果。
​
偏见利用：一种利用人工智能模型中已知偏见来操纵输出或结果的攻击技术。
​
Cedar：亚马逊用于实现 AI 系统基于属性的访问控制（ABAC）的细粒度权限策略语言和引擎。
​
思维链：一种通过在生成最终答案之前产生中间推理步骤来提升语言模型推理能力的技术。
​
断路器：当超过特定风险阈值时，自动停止人工智能系统操作的机制。
​
数据泄露：通过AI模型输出或行为无意中暴露敏感信息。
​
数据投毒：故意破坏训练数据以损害模型完整性的行为，通常目的是植入后门或降低性能。
​
差分隐私——差分隐私是一种数学上严格的框架，用于在保护个体数据主体隐私的同时发布关于数据集的统计信息。它使数据持有者能够共享群体的汇总模式，同时限制泄露关于特定个体的信息。
​
嵌入：数据（文本、图像等）的密集向量表示，能够在高维空间中捕捉语义意义。
​
可解释性——人工智能中的可解释性是指AI系统能够为其决策和预测提供人类可理解的原因，从而揭示其内部工作原理的能力。
​
可解释人工智能（XAI）：通过各种技术和框架设计的人工智能系统，旨在为其决策和行为提供人类可理解的解释。
​
联邦学习：一种机器学习方法，模型在多个持有本地数据样本的去中心化设备上进行训练，而无需交换数据本身。
​
护栏：为防止人工智能系统产生有害的、带有偏见的或其他不良输出而实施的约束。
​
幻觉——人工智能幻觉是指AI模型生成不正确或误导性信息的现象，这些信息既不基于其训练数据，也不符合事实现实。
​
人类参与循环（HITL）：设计成在关键决策点需要人类监督、验证或干预的系统。
​
基础设施即代码（IaC）：通过代码管理和配置基础设施，取代手动流程，实现安全扫描和一致的部署。
​
越狱：用于规避人工智能系统，特别是大型语言模型中的安全防护措施，以生成被禁止内容的技术。
​
最小特权：一种安全原则，仅授予用户和进程所需的最低访问权限。
​
LIME（局部可解释模型无关解释）：一种通过用可解释模型在局部近似来解释任何机器学习分类器预测的技术。
​
成员推断攻击：一种旨在确定特定数据点是否被用于训练机器学习模型的攻击。
​
MITRE ATLAS：针对人工智能系统的对抗性威胁格局；一个关于针对AI系统的对抗策略和技术的知识库。
​
模型卡——模型卡是一种文件，提供关于人工智能模型的性能、局限性、预期用途以及伦理考虑的标准化信息，以促进透明度和负责任的人工智能开发。
​
模型提取：一种攻击方式，攻击者反复查询目标模型，以未经授权的方式创建一个功能相似的副本。
​
模型反演：一种通过分析模型输出尝试重建训练数据的攻击。
​
模型生命周期管理 – AI模型生命周期管理是监督AI模型存在的所有阶段的过程，包括其设计、开发、部署、监控、维护以及最终退役，以确保模型保持有效并符合目标。
​
模型中毒：在训练过程中直接向模型引入漏洞或后门。
​
模型窃取/盗用：通过反复查询提取专有模型的副本或近似版本。
​
多智能体系统：由多个相互作用的人工智能代理组成的系统，每个代理可能具有不同的能力和目标。
​
OPA（开放策略代理）：一个开源的策略引擎，能够实现跨堆栈的统一策略执行。
​
隐私保护机器学习（PPML）：在保护训练数据隐私的同时训练和部署机器学习模型的技术和方法。
​
提示注入：一种攻击手段，通过在输入中嵌入恶意指令来覆盖模型的预期行为。
​
RAG（检索增强生成）：一种通过在生成回复之前从外部知识源检索相关信息来增强大型语言模型的技术。
​
红队演练：通过模拟对抗性攻击来主动测试人工智能系统，以识别其漏洞的做法。
​
SBOM（软件物料清单）：一份正式记录，包含用于构建软件或人工智能模型的各种组件的详细信息及其供应链关系。
​
SHAP（Shapley加法解释）：一种博弈论方法，通过计算每个特征对预测结果的贡献来解释任何机器学习模型的输出。
​
供应链攻击：通过针对供应链中安全性较低的环节，如第三方库、数据集或预训练模型，来破坏系统。
​
迁移学习：一种技术，其中为一个任务开发的模型被重新用作第二个任务模型的起点。
​
向量数据库：一种专门设计用于存储高维向量（嵌入）并执行高效相似度搜索的数据库。
​
漏洞扫描：自动化工具，用于识别软件组件中的已知安全漏洞，包括人工智能框架和依赖项。
​
水印技术：在 AI 生成的内容中嵌入不可察觉的标记，以追踪其来源或检测 AI 生成。
​
零日漏洞：一种先前未知的漏洞，攻击者可以在开发人员创建和部署补丁之前利用该漏洞。

## 附录 B：参考文献

### TODO

## 附录 C：人工智能安全治理与文档

### 目标

本附录提供了建立组织结构、政策和流程的基础要求，以在整个系统生命周期中管理人工智能安全。

---

### AC.1 人工智能风险管理框架采纳

提供一个正式框架，以识别、评估和减轻整个系统生命周期中的特定于人工智能的风险。

 #AC.1.1    等级: 1    角色: D/V
 验证是否有针对人工智能的风险评估方法论的文件记录并得到实施。
 #AC.1.2    等级: 2    角色: D
 确保在人工智能生命周期的关键节点以及重大变更之前进行风险评估。
 #AC.1.3    等级: 3    角色: D/V
 验证风险管理框架是否符合既定标准（例如，NIST AI RMF）。

---

### AC.2 人工智能安全政策与程序

定义并执行组织标准，确保人工智能的安全开发、部署和运行。

 #AC.2.1    等级: 1    角色: D/V
 验证是否存在已记录的AI安全策略。
 #AC.2.2    等级: 2    角色: D
 确保策略至少每年以及在重大威胁环境变化后进行审核和更新。
 #AC.2.3    等级: 3    角色: D/V
 验证政策是否涵盖所有AISVS类别及适用的法规要求。

---

### AC.3 人工智能安全的角色与职责

在整个组织中建立明确的人工智能安全责任。

 #AC.3.1    等级: 1    角色: D/V
 验证人工智能安全角色和职责是否有文档记录。
 #AC.3.2    等级: 2    角色: D
 验证相关人员是否具备适当的安全专业知识。
 #AC.3.3    等级: 3    角色: D/V
 验证是否为高风险 AI 系统设立了 AI 伦理委员会或治理委员会。

---

### AC.4 伦理人工智能指南执行

确保人工智能系统按照既定的伦理原则运行。

 #AC.4.1    等级: 1    角色: D/V
 验证是否存在人工智能开发和部署的伦理准则。
 #AC.4.2    等级: 2    角色: D
 验证是否已建立机制来检测和报告伦理违规行为。
 #AC.4.3    等级: 3    角色: D/V
 验证已部署的人工智能系统是否定期进行伦理审查。

---

### AC.5 人工智能合规性监测

保持对不断变化的人工智能法规的认识和遵守。

 #AC.5.1    等级: 1    角色: D/V
 验证是否存在识别适用人工智能法规的流程。
 #AC.5.2    等级: 2    角色: D
 核实是否对所有法规要求的合规性进行了评估。
 #AC.5.3    等级: 3    角色: D/V
 验证监管变更是否能及时触发对人工智能系统的审查和更新。

### AC.6 训练数据治理、文档编制与流程

 #1.1.2    等级: 1    角色: D/V
 验证只允许经过质量、代表性、伦理采购和许可合规性审查的数据集，减少中毒、内嵌偏见和知识产权侵权的风险。
 #1.1.5    等级: 2    角色: D/V
 确保通过审核人员交叉检查或共识来保证标签/注释的质量。
 #1.1.6    等级: 2    角色: D/V
 确认对重要的训练数据集维护“数据卡”或“数据集说明书”，详细说明其特征、动机、组成、收集过程、预处理以及推荐/不推荐的使用方式。
 #1.3.2    等级: 2    角色: D/V
 验证已识别的偏差是否通过有文档记录的策略得到缓解，例如重新平衡、定向数据增强、算法调整（如预处理、处理中、后处理技术）或重新加权，并评估缓解措施对公平性和整体模型性能的影响。
 #1.3.3    等级: 2    角色: D/V
 确认已评估和记录训练后公平性指标。
 #1.3.4    等级: 3    角色: D/V
 验证生命周期偏差管理策略是否分配了责任人和审查频率。
 #1.4.1    等级: 2    角色: D/V
 确保标注/注释质量，通过明确的指南、审核者交叉检查、共识机制（例如，监控注释者间一致性），以及定义的解决分歧的流程。
 #1.4.4    等级: 3    角色: D/V
 确保对安全性、可靠性或公平性至关重要的标签（例如，识别有害内容、关键医疗发现）进行强制性的独立双重审核或等效的严格验证。
 #1.4.6    等级: 2    角色: D/V
 验证标注指南和说明是否全面、具有版本控制且经过同行评审。
 #1.4.6    等级: 2    角色: D/V
 验证标签的数据模式是否定义清晰且进行版本控制。
 #1.3.1    等级: 1    角色: D/V
 验证数据集是否针对具有法律保护属性（如种族、性别、年龄）以及与模型应用领域相关的其他伦理敏感特征（如社会经济地位、地理位置）存在的代表性不平衡和潜在偏见进行了分析。
 #1.5.3    等级: 2    角色: V
 验证领域专家的人工抽查覆盖了具有统计显著性的样本（例如，≥1%或1000个样本，以较大者为准，或根据风险评估确定），以识别自动化未能发现的细微质量问题。
 #1.8.4    等级: 2    角色: D/V
 验证外包或众包标注工作流程是否包含技术/程序保障措施，以确保数据机密性、完整性、标签质量，并防止数据泄露。
 #1.5.4    等级: 2    角色: D/V
 验证修复步骤是否已附加到溯源记录。
 #1.6.2    等级: 2    角色: D/V
 验证被标记的样本在训练前触发人工审核。
 #1.6.3    等级: 2    角色: V
 验证结果是否反馈到模型的安全档案，并为持续的威胁情报提供信息。
 #1.6.4    等级: 3    角色: D/V
 验证检测逻辑是否已通过新的威胁情报进行更新。
 #1.6.5    等级: 3    角色: D/V
 验证在线学习管道是否监控分布漂移。
 #1.7.1    等级: 1    角色: D/V
 验证训练数据删除工作流是否清除原始数据和派生数据，并评估对模型的影响；同时评估受影响模型的影响，并在必要时进行处理（例如，通过重新训练或重新校准）。
 #1.7.2    等级: 2    角色: D
 验证是否已建立机制来追踪和尊重用于训练的数据的用户同意（及撤回）的范围和状态，并且在将数据纳入新的训练流程或重大模型更新之前，需先确认同意的有效性。
 #1.7.3    等级: 2    角色: V
 验证工作流是否每年进行测试并记录备案。
 #1.8.1    等级: 2    角色: D/V
 确保第三方数据供应商，包括预训练模型提供者和外部数据集提供者，在其数据或模型被整合之前，经过安全、隐私、道德采购和数据质量的尽职调查。
 #1.8.2    等级: 1    角色: D
 验证外部传输是否使用TLS/身份验证和完整性检查。
 #1.8.3    等级: 2    角色: D/V
 验证高风险数据源（例如，来源不明的开源数据集、未经审核的供应商）在用于敏感应用之前，是否接受了加强的审查，例如隔离环境分析、广泛的质量/偏差检查和针对性数据投毒检测。
 #1.8.4    等级: 3    角色: D/V
 确保从第三方获得的预训练模型在微调或部署之前，经过嵌入偏差、潜在后门、架构完整性以及其原始训练数据来源的评估。
 #1.5.3    等级: 2    角色: D/V
 验证如果使用对抗训练，是否对对抗数据集的生成、管理和版本控制进行了记录和控制。
 #1.5.3    等级: 3    角色: D/V
 验证对抗鲁棒性训练对模型性能（针对干净输入和对抗输入）及公平性指标的影响是否已被评估、记录并监控。
 #1.5.4    等级: 3    角色: D/V
 验证对抗训练和鲁棒性策略是否定期审查和更新，以应对不断发展的对抗攻击技术。
 #1.4.2    等级: 2    角色: D/V
 验证失败的数据集是否被隔离并带有审计跟踪。
 #1.4.3    等级: 2    角色: D/V
 验证质量门禁确保阻止不合格的数据集，除非获得例外批准。
 #1.11.2    等级: 2    角色: D/V
 验证生成过程、参数和合成数据的预期用途是否有文档记录。
 #1.11.3    等级: 2    角色: D/V
 确保在用于训练之前，对合成数据进行偏见、隐私泄漏和表现问题的风险评估。
 #1.12.3    等级: 2    角色: D/V
 验证是否对可疑访问事件生成警报并及时进行调查。
 #1.13.1    等级: 1    角色: D/V
 验证是否为所有训练数据集明确定义了保留期限。
 #1.13.2    等级: 2    角色: D/V
 验证数据集在其生命周期结束时是否自动过期、删除或被审核以进行删除。
 #1.13.3    等级: 2    角色: D/V
 验证保留和删除操作是否有记录并且可审计。
 #1.14.1    等级: 2    角色: D/V
 验证所有数据集是否识别并执行了数据驻留和跨境传输要求。
 #1.14.2    等级: 2    角色: D/V
 验证是否已识别并处理与特定行业相关的法规（例如，医疗保健、金融）在数据处理中的要求。
 #1.14.3    等级: 2    角色: D/V
 验证相关隐私法规（例如 GDPR、CCPA）的合规性是否有文档记录并定期审核。
 #1.16.1    等级: 2    角色: D/V
 验证是否存在响应数据主体请求访问、更正、限制或反对的机制。
 #1.16.2    等级: 2    角色: D/V
 验证请求是否在法律规定的时间范围内被记录、跟踪和完成。
 #1.16.3    等级: 2    角色: D/V
 验证数据主体权利流程是否定期进行测试和审查以确保其有效性。
 #1.17.1    等级: 2    角色: D/V
 在更新或替换数据集版本之前，验证已执行影响分析，涵盖模型性能、公平性和合规性。
 #1.17.2    等级: 2    角色: D/V
 验证影响分析的结果是否已记录并由相关利益相关者审查。
 #1.17.3    等级: 2    角色: D/V
 验证是否存在回滚计划，以防新版本引入不可接受的风险或回归。
 #1.18.1    等级: 2    角色: D/V
 确保所有参与数据注释的人员都经过背景调查，并接受了数据安全和隐私的培训。
 #1.18.2    等级: 2    角色: D/V
 确保所有注释人员签署保密和不披露协议。
 #1.18.3    等级: 2    角色: D/V
 验证注释平台是否执行访问控制并监控内部威胁。

#### 参考文献

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
EU Artificial Intelligence Act — Regulation (EU) 2024/1689
ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods

## 附录D：AI辅助安全编码治理与验证

### 目标

本章节定义了在软件开发过程中安全有效使用人工智能辅助编码工具的基础组织控制，确保整个软件开发生命周期中的安全性和可追溯性。

---

### AD.1 AI辅助安全编码工作流程

将人工智能工具集成到组织的安全软件开发生命周期（SSDLC）中，同时不削弱现有的安全防护措施。

 #AD.1.1    等级: 1    角色: D/V
 验证已记录的工作流程是否描述了AI工具何时以及如何生成、重构或审查代码。
 #AD.1.2    等级: 2    角色: D
 验证工作流程是否对应每个SSDLC阶段（设计、实施、代码审查、测试、部署）。
 #AD.1.3    等级: 3    角色: D/V
 验证是否收集了针对 AI 生成代码的指标（例如，漏洞密度、平均检测时间），并将其与仅人工代码的基线进行比较。

---

### AD.2 AI 工具资格认证与威胁建模

确保在采用人工智能编码工具之前，评估其安全能力、风险及供应链影响。

 #AD.2.1    等级: 1    角色: D/V
 验证每个 AI 工具的威胁模型是否识别了滥用、模型反演、数据泄露和依赖链风险。
 #AD.2.2    等级: 2    角色: D
 验证工具评估是否包括对任何本地组件的静态/动态分析以及对SaaS端点（TLS、身份验证/授权、日志记录）的评估。
 #AD.2.3    等级: 3    角色: D/V
 验证评估是否遵循公认的框架，并在主要版本更改后重新执行评估。

---

### AD.3 安全提示与上下文管理

在为 AI 模型构建提示或上下文时，防止泄露机密信息、专有代码和个人数据。

 #AD.3.1    等级: 1    角色: D/V
 验证书面指导是否禁止在提示中发送机密信息、凭据或机密数据。
 #AD.3.2    等级: 2    角色: D
 验证技术控制措施（客户端编辑、批准的上下文过滤器）是否自动剥离敏感信息。
 #AD.3.3    等级: 3    角色: D/V
 验证提示和响应是否经过分词处理、传输和存储时加密，并且保留期限符合数据分类政策。

---

### AD.4 AI生成代码的验证

在代码合并或部署之前，检测并修复由AI输出引入的漏洞。

 #AD.4.1    等级: 1    角色: D/V
 确保 AI 生成的代码始终经过人工代码审核。
 #AD.4.2    等级: 2    角色: D
 验证对每个包含AI生成代码的拉取请求运行自动扫描器（SAST/IAST/DAST），并在发现严重问题时阻止合并。
 #AD.4.3    等级: 3    角色: D/V
 验证差分模糊测试或基于属性的测试是否能够证明安全关键行为（例如，输入验证、授权逻辑）。

---

### AD.5 代码建议的可解释性与可追溯性

为审核员和开发人员提供有关建议为何提出以及如何演变的见解。

 #AD.5.1    等级: 1    角色: D/V
 验证提示/响应对是否已使用提交ID进行记录。
 #AD.5.2    等级: 2    角色: D
 验证开发人员是否能够展示支持建议的模型引用（训练片段、文档）。
 #AD.5.3    等级: 3    角色: D/V
 验证可解释性报告是否与设计工件一起存储，并在安全审查中引用，以满足 ISO/IEC 42001 可追溯性原则。

---

### AD.6 持续反馈与模型微调

随着时间的推移提升模型安全性能，同时防止负向漂移。

 #AD.6.1    等级: 1    角色: D/V
 验证开发人员是否能够标记不安全或不合规的建议，并且标记是否被跟踪。
 #AD.6.2    等级: 2    角色: D
 验证汇总的反馈是否用于定期微调或结合经过验证的安全编码语料库（例如 OWASP 备忘单）的检索增强生成。
 #AD.6.3    等级: 3    角色: D/V
 验证闭环评估框架在每次微调后运行回归测试；安全指标必须达到或超过先前的基线水平方可部署。

---

#### 参考文献

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
OWASP Secure Coding Practices — Quick Reference Guide

## 附录 E：示例工具和框架

### 目标

本章提供了可支持实现或满足特定AISVS需求的工具和框架示例。这些示例不应被视为AISVS团队或OWASP GenAI安全项目的推荐或认可。

---

### AE.1 训练数据治理与偏差管理

用于数据分析、治理和偏差管理的工具。

 #AE.1.1    章节: 1.1
 数据清单工具：数据清单管理工具例如...
 #AE.1.2    章节: 1.2
 传输中加密 对于基于 HTTPS 的应用程序，使用 TLS，结合 openSSL 和 python 等工具`ssl`库。

---

### AE.2 用户输入验证

处理和验证用户输入的工具。

 #AE.2.1    章节: 2.1
 提示注入防御工具：使用类似 NVIDIA 的 NeMo 或 Guardrails AI 这样的防护工具。

---

