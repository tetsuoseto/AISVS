## 扉页

### 关于该标准

人工智能安全验证标准（AISVS）是一个由社区驱动的安全需求目录，供数据科学家、MLOps 工程师、软件架构师、开发人员、测试人员、安全专业人员、工具供应商、监管机构和消费者使用，以设计、构建、测试和验证可信的 AI‑启用系统和应用程序。它为在 AI 生命周期中指定安全控制提供了一种共同语言——从数据收集和模型开发到部署与持续监控——以便组织能够衡量并提升其 AI 解决方案的鲁棒性、隐私性和安全性。

### 版权与许可证

版本 0.1 （首次公开草案 - 正在进行中）， 2025  

![license](images/license.png)
版权所有 © 2025 The AISVS Project.  

在以下许可下发布 Creative Commons Attribution‑ShareAlike 4.0 International License.
对于任何再利用或再分发，您必须向他人清楚地传达本作品的许可条款。

### 项目负责人

吉姆·曼尼科
阿拉斯 “Russ” 梅米斯亚兹伊吉

### 贡献者与评审者

https://github.com/ottosulin
https://github.com/mbhatt1
https://github.com/vineethsai
https://github.com/cciprofm
https://github.com/deepakrpandey12


---

AISVS 是一个 brand‑new 标准，专门为应对人工智能系统独特的安全挑战而创建。尽管它汲取了更广泛的安全最佳实践的灵感，AISVS 的每一项要求都从头开始开发，以反映人工智能威胁格局，并帮助组织构建更安全、更具韧性的人工智能解决方案。

## 前言

欢迎来到人工智能安全验证标准（AISVS）版本 1.0！

### 简介

AISVS 于 2025 年通过社区协作成立，定义在设计、开发、部署和运营现代 AI 模型、流水线以及 AI‑驱动的服务时应考虑的安全要求。

AISVS v1.0 代表其项目负责人、工作组以及更广泛的社区贡献者共同努力的成果，旨在为确保人工智能系统的安全性提供一个务实、可测试的基线。

本次发布的目标是使 AISVS 易于采用，同时在其既定范围内保持 laser‑focused，并应对人工智能独特且快速演变的风险格局。

### AISVS 版本 1.0 的关键目标

版本 1.0 将以若干指导原则为基础来创建。

#### 定义明确的范围

每项要求都应与 AISVS 的名称和使命保持一致：

人工智能 – 控制在 AI/ML 层面上运作（数据、模型、流水线或推理），并由 AI 实践者负责。
安全性 – 要求直接缓解已识别的安全性、隐私或安全风险。
验证 – 语言被编写成便于客观验证符合性。
标准 – 章节遵循一致的结构和术语，以形成一个连贯的参考。
​
---

通过遵循 AISVS，组织可以系统地评估并加强其 AI 解决方案的安全态势，培养安全的 AI 工程文化。

## 使用 AISVS

人工智能安全验证标准（AISVS）为现代人工智能应用与服务定义安全要求，聚焦于应用开发者可控的方面。

AISVS 面向任何开发或评估 AI 应用安全性的人士，包括开发人员、架构师、安全工程师和审计人员。本章介绍 AISVS 的结构与使用方式，包括其验证级别和预期使用场景。

### 人工智能安全验证等级

AISVS 定义了三种递增的安全验证等级。 每个等级增加了深度和复杂性，使组织能够根据其人工智能系统的风险水平来定制其安全态势。

组织可以从等级 1 开始，并随着安全成熟度和威胁暴露的增加，逐步采用更高等级。

#### 层级定义

AISVS v1.0 中的每个需求都被分配到以下等级之一：

 等级 1 要求

一级包含最关键和基础的安全要求。它们专注于防止不依赖其他先决条件或漏洞的常见攻击。大多数一级控制措施要么易于实施，要么重要性足以证明投入的努力是值得的。

 等级 2 的要求

二级旨在应对更先进或较少见的攻击，以及针对广泛威胁的分层防御。这些要求可能涉及更复杂的逻辑，或针对特定的攻击前提条件。

 等级 3 要求

第3级包含通常更难实现，或在适用性方面具有情境性的控制措施。这些通常代表分层防御机制，或针对小众、定向或高复杂度攻击的缓解措施。

#### 角色 (D/V)

每个 AISVS 要求根据主要受众进行标注：

D – 面向开发者的需求
V – 面向验证者/审计员的要求
D/V – 对开发者和验证者都相关

## C1 训练数据治理 & 偏见管理

### 控制目标

训练数据必须以能够保持来源可追溯性、保障安全、质量和公正的方式来获取、处理和维护。这样做可以履行法律义务，降低在训练过程中出现的偏见、数据投毒或隐私泄露等风险，这些风险若在训练阶段暴露，可能影响整个 AI 生命周期。

---

### C1.1 训练数据溯源

维护所有数据集的可核验清单，仅接受可信来源，并记录每次变更以确保可审计性。

 #1.1.1    等级: 1    角色: D/V
 核实并确保对每个训练数据源维持最新的清单（来源、管理者/所有者、许可、数据收集方法、预期用途的限制，以及处理历史）。
 #1.1.2    等级: 1    角色: D/V
 验证训练数据处理是否排除不必要的特征、属性或字段（例如未使用的元数据、敏感个人身份信息、泄露的测试数据）。
 #1.1.3    等级: 2    角色: D/V
 验证所有数据集变更都需通过带日志的审批工作流。
 #1.1.4    等级: 3    角色: D/V
 在可行的情况下，验证数据集或子集是否带有水印或指纹标记。

---

### C1.2 训练数据的安全性与完整性

限制对训练数据的访问，在静态存储和传输过程中对其进行加密，并验证其完整性以防止篡改、窃取或数据污染。

 #1.2.1    等级: 1    角色: D/V
 验证访问控制是否保护训练数据的存储和数据管道。
 #1.2.2    等级: 2    角色: D/V
 请确保对训练数据的所有访问都已被记录，包括用户、时间和操作。
 #1.2.3    等级: 2    角色: D/V
 验证训练数据集在传输过程中和静态存储时是否使用行业标准的加密算法和密钥管理实践进行加密。
 #1.2.4    等级: 2    角色: D/V
 验证在训练数据的存储与传输过程中，是否使用密码学哈希值或数字签名来确保数据完整性。
 #1.2.5    等级: 2    角色: D/V
 验证是否已应用自动检测技术，以防止对训练数据的未授权修改或损坏。
 #1.2.6    等级: 2    角色: D/V
 请验证过时的训练数据是否已被安全清除或匿名化。
 #1.2.7    等级: 3    角色: D/V
 验证所有训练数据集版本是否具有唯一标识、以不可变方式存储，并且可审计，以支持回滚和取证分析。

---

### C1.3 训练数据标注的质量、完整性与安全性

保护标签，并对关键数据进行技术评审。

 #1.3.1    等级: 2    角色: D/V
 验证是否对标签工件应用了密码学哈希值或数字签名，以确保它们的完整性和真实性。
 #1.3.2    等级: 2    角色: D/V
 验证标注接口和平台是否实施强访问控制，是否维护对所有标注活动的防篡改审计日志，以及是否防止未经授权的修改。
 #1.3.3    等级: 3    角色: D/V
 请验证标签中的敏感信息在静态存储和传输过程中，是否在数据字段级别被脱敏、匿名化或加密。

---

### C1.4 训练数据质量与安全保障

结合自动化验证、人工抽查和已记录的纠正措施，以确保数据集的可靠性。

 #1.4.1    等级: 1    角色: D
 验证自动化测试能够在每次数据摄取或重大数据转换中捕获格式错误和空值。
 #1.4.2    等级: 2    角色: D/V
 验证 LLM 训练和微调管道是否实现中毒检测与数据完整性校验（例如统计方法、离群值检测、嵌入分析），以识别潜在的中毒攻击（例如标签翻转、后门触发器插入、角色切换命令、影响力样本攻击）或训练数据中的非故意损坏。
 #1.4.3    等级: 3    角色: D/V
 根据风险评估，对相关模型实现并调优合适的防御措施，例如对抗性训练（使用生成的对抗样本）、带扰动输入的数据增强，或鲁棒优化技术。
 #1.4.4    等级: 2    角色: D/V
 验证自动生成的标签（例如，通过 LLMs 或弱监督）是否受置信阈值和一致性检查的约束，以检测幻觉、误导性或低置信度的标签。
 #1.4.5    等级: 3    角色: D
 验证自动化测试是否能够在每次数据摄取或任何重大数据转换时捕捉标签偏斜。

---

### C1.5 数据血缘与可追溯性

跟踪每个数据点从数据源到模型输入的完整轨迹，以实现可审计性和事件响应。

 #1.5.1    等级: 2    角色: D/V
 验证每个数据点的血统信息（包括所有转换、数据增强和合并）是否已被记录并且可以重建。
 #1.5.2    等级: 2    角色: D/V
 验证数据血统记录是否不可变、被安全存储、并且可用于审计。
 #1.5.3    等级: 2    角色: D/V
 验证数据血缘追踪是否覆盖通过隐私保护或生成式技术生成的合成数据，并确保在整个数据管道中，所有合成数据都被清晰标注，且能够与真实数据清晰区分。

---

### 参考文献

NIST AI Risk Management Framework
EU AI Act – Article 10: Data & Data Governance
MITRE ATLAS: Adversary Tactics for AI
Survey of ML Bias Mitigation Techniques – MDPI
Data Provenance & Lineage Best Practices – Nightfall AI
Data Labeling Quality Standards – LabelYourData
Training Data Poisoning Guide – Lakera.ai
CISA Advisory: Securing Data for AI Systems
ISO/IEC 23053: AI Management Systems Framework
IBM: What is AI Governance?
Google AI Principles
GDPR & AI Training Data – DataProtectionReport
Supply-Chain Security for AI Data – AppSOC
OpenAI Privacy Center – Data Deletion Controls
Adversarial ML Dataset – Kaggle

## C2 用户输入验证

### 控制目标

对用户输入进行鲁棒性验证是对 AI 系统最具破坏性的攻击之一的第一道防线。提示注入攻击可以覆盖系统指令、泄露敏感数据，或将模型引导至不被允许的行为。除非有专门的过滤器和指令层级，否则研究表明利用极长的上下文窗口的“多轮越狱攻击”将是有效的。此外，细微的对抗性扰动攻击——例如同形字替换（homoglyph）或 leetspeak——也可能悄无声息地改变模型的决策。

---

### C2.1 提示注入防御

提示注入攻击是人工智能系统面临的主要风险之一。针对这种策略的防御措施采用静态模式过滤器、动态分类器以及指令层级执行约束的组合。

 #2.1.1    等级: 1    角色: D/V
 验证用户输入是否与持续更新的已知提示注入模式库进行筛选（越狱关键词、“忽略先前”、角色扮演链、间接的HTML/URL攻击）。
 #2.1.2    等级: 1    角色: D/V
 验证系统是否强制执行一个指令层次结构，在该层次结构中，系统或开发者消息会覆盖用户指令，即使在上下文窗口扩展后也如此。
 #2.1.3    等级: 2    角色: D/V
 请验证在每次模型或提示模板发布之前，是否执行对抗性评估测试（例如红队“many-shot”提示），并设定成功率阈值以及用于回归的自动阻止机制。
 #2.1.4    等级: 2    角色: D
 验证来自第三方内容（网页、PDF、电子邮件）的提示，在被拼接到主提示之前，是否在一个隔离的解析上下文中进行净化。
 #2.1.5    等级: 3    角色: D/V
 验证所有提示过滤规则更新、分类器模型版本以及阻止名单变更均已进行版本控制且可审计。

---

### C2.2 对抗-样本鲁棒性

自然语言处理（NLP）模型仍然容易受到微小的字符级或词级扰动的影响，这些扰动人类往往察觉不到，但模型往往会将其错误分类。

 #2.2.1    等级: 1    角色: D
 请确认基本输入规范化步骤（Unicode NFC 归一化、同形字映射、去除前后空白）在分词之前执行。
 #2.2.2    等级: 2    角色: D/V
 验证统计异常检测是否会对那些与语言规范相比编辑距离异常高、重复标记过多，或嵌入距离异常的输入进行标记。
 #2.2.3    等级: 2    角色: D
 验证推理管线是否支持用于高风险端点的可选对抗性训练–加固模型变体或防御层（例如，随机化、防御性蒸馏）。
 #2.2.4    等级: 2    角色: V
 验证疑似对抗性输入是否已被隔离，在进行 PII 脱敏后，将完整有效载荷记录到日志中。
 #2.2.5    等级: 3    角色: D/V
 验证鲁棒性指标（已知攻击套件的成功率）是否随时间进行跟踪，若出现回归，则触发发布阻塞。

---

### C2.3 模式、类型与长度验证

包含格式错误或超大输入的人工智能攻击可能导致解析错误、跨字段的提示信息溢出，以及资源耗尽。在执行确定性工具调用时，严格的模式约束也是前提条件。

 #2.3.1    等级: 1    角色: D
 验证每个 API 或函数调用端点是否定义了明确的输入模式（JSON Schema、Protobuf 或多模态等效物），并在组装提示之前对输入进行验证。
 #2.3.2    等级: 1    角色: D/V
 验证超过最大 token 数量或字节上限的输入将被安全地拒绝，并且不会被静默截断。
 #2.3.3    等级: 2    角色: D/V
 验证类型检查（例如数值范围、枚举值、图像/音频的 MIME 类型）是否在服务器端强制执行，而不仅仅在客户端代码中。
 #2.3.4    等级: 2    角色: D
 验证语义验证器（例如 JSON Schema）是否在常数时间内运行，以防止算法性 DoS 攻击。
 #2.3.5    等级: 3    角色: V
 核实验证失败是否已被记录，并且带有经过脱敏的有效载荷片段和明确的错误代码，以帮助安全事件分诊。

---

### C2.4 内容与政策筛查

开发者应能够检测出在语法上有效、但请求包含禁止内容的提示，然后阻止它们的传播。

 #2.4.1    等级: 1    角色: D
 验证一个内容分类器（零样本/微调）是否对每个输入在暴力、自残、仇恨、性内容和非法请求方面进行评分，并具备可配置的阈值。
 #2.4.2    等级: 1    角色: D/V
 验证违反政策的输入将收到标准化拒绝或安全完成，以确保它们不会传播到下游的 LLM 调用。
 #2.4.3    等级: 2    角色: D
 验证筛选模型或规则集至少每季度重新训练/更新一次，并将新近观测到的越狱或策略绕过模式纳入其中。
 #2.4.4    等级: 2    角色: D
 验证筛选是否遵守用户特定的政策（年龄、区域性法律约束），这些规则通过在请求时解析的基于属性的规则来实现。
 #2.4.5    等级: 3    角色: V
 请验证筛查日志是否包含分类器置信度分数和策略类别标签，用于与 SOC 的相关性分析以及未来的红队回放。

---

### C2.5 输入速率限制 & 滥用防护

开发者应通过限制输入速率和检测异常使用模式来防止对人工智能系统的滥用、资源耗尽和自动化攻击。

 #2.5.1    等级: 1    角色: D/V
 验证是否对所有输入端点强制执行按用户、按 IP 和按 API 密钥的速率限制。
 #2.5.2    等级: 2    角色: D/V
 验证突发和持续的速率限制是否已调优，以防止 DoS 攻击和暴力破解攻击。
 #2.5.3    等级: 2    角色: D/V
 验证异常使用模式（例如，快速连发请求、输入泛滥）是否会触发自动封锁或升级流程。
 #2.5.4    等级: 3    角色: V
 验证滥用防护日志是否已被保留并用于识别新兴的攻击模式。

---

### C2.6 多模态输入验证

AI 系统应对非文本输入（图像、音频、文件）进行健壮性验证，以防止注入、规避或资源滥用。

 #2.6.1    等级: 1    角色: D
 在处理之前，验证所有非文本输入（图像、音频、文件）的类型、大小和格式。
 #2.6.2    等级: 2    角色: D/V
 在导入之前，请对文件进行恶意软件和隐写载荷的扫描。
 #2.6.3    等级: 2    角色: D/V
 验证图像/音频输入是否已针对对抗性扰动或已知攻击模式进行检测。
 #2.6.4    等级: 3    角色: V
 验证多模态输入验证失败是否已被记录并触发用于调查的告警。

---

### C2.7 输入溯源与归因

AI 系统应通过监控并标记所有用户输入的来源来支持审计、滥用追踪和合规性。

 #2.7.1    等级: 1    角色: D/V
 在数据摄取时，请确保所有用户输入都带有元数据（用户ID、会话、来源、时间戳、IP 地址）。
 #2.7.2    等级: 2    角色: D/V
 确保对所有已处理输入的溯源元数据得以保留并可审计。
 #2.7.3    等级: 2    角色: D/V
 请确认异常或不受信任的输入源已被标记，并对其进行加强审查或阻断。

---

### C2.8 实时自适应威胁检测

开发人员应采用面向人工智能的先进威胁检测系统，这些系统能够适应新的攻击模式，并通过编译的模式匹配提供实时保护。

 #2.8.1    等级: 1    角色: D/V
 验证威胁检测模式是否已编译为优化的正则表达式引擎，以实现高性能的实时过滤，并将延迟影响降至最低。
 #2.8.2    等级: 1    角色: D/V
 验证威胁检测系统是否为不同威胁类别维护单独的模式库（提示注入、有害内容、敏感数据、系统命令）。
 #2.8.3    等级: 2    角色: D/V
 验证自适应威胁检测是否包含根据攻击频率和成功率更新威胁敏感度的机器学习模型。
 #2.8.4    等级: 2    角色: D/V
 验证实时威胁情报源是否会自动使用新的攻击签名和 IOcs（妥协指标）来更新模式库。
 #2.8.5    等级: 3    角色: D/V
 验证威胁检测的误报率是否在持续监控，并自动调整模式特异性，以尽量减少对合法用例的干扰。
 #2.8.6    等级: 3    角色: D/V
 验证情境威胁分析是否考虑输入来源、用户行为模式和会话历史，以提高检测准确性。
 #2.8.7    等级: 3    角色: D/V
 验证威胁检测性能指标（检测率、处理延迟、资源利用率）是否在实时监控并优化。

---

### C2.9 多模态安全验证流水线

开发人员应为文本、图像、音频以及其他 AI 输入模态提供安全性验证，并采用特定类型的威胁检测与资源隔离。

 #2.9.1    等级: 1    角色: D/V
 验证 每种 输入 模态 是否 拥有 专用 的 安全 验证 器 并 具有 有 文档化 的 威胁 模式（文本：提示注入，图像：隐写术，音频：声谱图 攻击）以及 检测 阈值。
 #2.9.2    等级: 2    角色: D/V
 验证多模态输入是否在隔离的沙箱中进行处理，并设定明确定义的资源限制（内存、CPU、处理时间），这些限制针对每种模态类型，并在安全策略中有文档记录。
 #2.9.3    等级: 2    角色: D/V
 验证跨模态攻击检测是否能够识别跨越多种输入类型的协同攻击，并通过相关性规则实现告警生成。
 #2.9.4    等级: 3    角色: D/V
 验证多模态验证失败是否会触发详细日志记录，包括所有输入模态、验证结果、威胁分数，以及使用结构化日志格式的相关性分析，以便与 SIEM 集成。
 #2.9.5    等级: 3    角色: D/V
 验证按文档化日程（至少每季度一次）更新模态特定的内容分类器，并确保包含新的威胁模式、对抗样本，以及性能基准保持高于基线阈值。

---

### 参考文献

LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security
Generative AI's Biggest Security Flaw Is Not Easy to Fix
Many-shot jailbreaking \ Anthropic
$PDF$ OpenAI GPT-4.5 System Card
Notebook for the CheckThat Lab at CLEF 2024
Mitigate jailbreaks and prompt injections – Anthropic
Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis
OWASP Top 10 for LLM Applications 2025 – WorldTech IT
OWASP Machine Learning Security Top Ten
Few words about AI Security – Jussi Metso
How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry
Easily enforcing valid JSON schema following – API
AI Safety + Cybersecurity R\&D Tracker – Fairly AI
Anthropic makes 'jailbreak' advance to stop AI models producing harmful results
Pattern matching filter rules - IBM
Real-time Threat Detection

## C3 模型生命周期管理与变更控制

### 控制目标

AI 系统必须实施变更控制流程，防止未经授权或不安全的模型修改进入生产环境。该控制措施确保在整个生命周期--从开发到部署再到退役--从而实现快速事件响应并对所有变更保持问责。

核心安全目标：仅有经授权、经过验证的模型通过采用能够维护完整性、可追溯性和可恢复性的受控流程进入生产环境。

---

### C3.1 模型授权与完整性

只有经授权且完整性已验证的模型才能进入生产环境。

 #3.1.1    等级: 1    角色: D/V
 在部署之前，验证所有模型产物（权重、配置、分词器）是否已由经授权的实体进行密码学签名。
 #3.1.2    等级: 1    角色: D/V
 确保在部署时对模型完整性进行验证，若签名验证失败将阻止模型加载。
 #3.1.3    等级: 2    角色: D/V
 验证模型溯源记录是否包含授权实体的身份、训练数据校验和、带有通过/失败状态的验证测试结果，以及创建时间戳。
 #3.1.4    等级: 2    角色: D/V
 验证所有模型产物是否使用语义化版本控制（MAJOR.MINOR.PATCH），并附有文档化的标准，规定何时对每个版本组件进行递增。
 #3.1.5    等级: 2    角色: V
 验证依赖跟踪是否维护一个实时清单，以便快速识别所有使用中的系统。

---

### C3.2 模型验证与测试

模型在部署前必须通过已定义的安全性和稳健性验证。

 #3.2.1    等级: 1    角色: D/V
 在部署之前，验证模型是否经过自动化的安全测试，该测试包括输入验证、输出净化，以及带有事先商定的组织通过/不通过阈值的安全评估。
 #3.2.2    等级: 1    角色: D/V
 请验证：在获得来自预先指定的授权人员且附有书面业务理由的明确覆盖批准后，验证失败会自动阻止模型部署。
 #3.2.3    等级: 2    角色: V
 验证测试结果是否已进行密码学签名，并且与正在验证的特定模型版本哈希值不可变地关联。
 #3.2.4    等级: 2    角色: D/V
 请确认，紧急部署需要有书面的安全风险评估，并在事先约定的时间框架内获得来自事先指定的安全权威的批准。

---

### C3.3 受控部署与回滚

模型部署必须可控、可监控，并且可逆。

 #3.3.1    等级: 1    角色: D
 请验证生产环境部署是否实现了渐进式部署机制（金丝雀部署、蓝绿部署），并具备基于事先约定的错误率、延迟阈值或安全警报标准的自动回滚触发条件。
 #3.3.2    等级: 1    角色: D/V
 验证回滚能力是否能够在预定义的组织时间窗口内原子地恢复完整的模型状态（权重、配置、依赖项）。
 #3.3.3    等级: 2    角色: D/V
 确保部署流程在模型激活之前验证数字签名并计算完整性校验和，若有任一不匹配，部署将失败。
 #3.3.4    等级: 2    角色: D/V
 验证紧急模型停机能力是否能够在预定义的响应时间内，通过自动断路器或手动停止开关，禁用模型端点。
 #3.3.5    等级: 2    角色: V
 确保回滚制品（先前的模型版本、配置和依赖项）按照组织政策进行保留，并使用不可变存储以用于事件响应。

---

### C3.4 变更问责与审计

所有模型生命周期的变更必须可追踪并可审计。

 #3.4.1    等级: 1    角色: V
 确保所有模型变更（部署、配置、下线）生成不可变的审计记录，这些记录应包括时间戳、经身份验证的执行者身份、变更类型，以及变更前状态与变更后状态。
 #3.4.2    等级: 2    角色: D/V
 验证审计日志的访问是否需要适当授权，并且所有访问尝试都应记录用户身份和时间戳。
 #3.4.3    等级: 2    角色: D/V
 验证提示模板和系统消息在 Git 仓库中进行版本控制，并在部署前必须经过指定评审人员的代码审查与批准。
 #3.4.4    等级: 2    角色: V
 验证审计记录是否包含足够的细节（模型哈希、配置快照、依赖版本），以在保留期内的任意时间戳实现对模型状态的完整重建。

---

### C3.5 安全开发实践

模型开发与训练过程必须遵循安全实践，以防止被妥协。

 #3.5.1    等级: 1    角色: D
 验证模型开发、测试和生产环境在物理上或逻辑上是分离的。它们没有共享的基础设施、各自独立的访问控制，并且数据存储彼此隔离。
 #3.5.2    等级: 1    角色: D
 请验证模型训练和微调是否在隔离的环境中进行，且网络访问受控。
 #3.5.3    等级: 1    角色: D/V
 在用于模型开发之前，确保训练数据源已通过完整性检查进行验证，并通过可信来源进行身份认证，并具备文档化的保管链以便追溯。
 #3.5.4    等级: 2    角色: D
 验证模型开发工件（超参数、训练脚本、配置文件）是否已被放入版本控制，并且在用于训练之前需要获得同行评审的批准。

---

### C3.6 模型退役与下线

模型在不再需要或发现安全问题时，必须被安全地退役。

 #3.6.1    等级: 1    角色: D
 验证模型退役流程是否会自动扫描依赖图、识别所有使用该模型输出结果的系统，并在退役之前提供事先商定的通知期。
 #3.6.2    等级: 1    角色: D/V
 验证已退役的模型工件是否通过密码擦除或多次覆盖被安全清除，符合已记录的数据保留策略，并附有经过验证的销毁证明。
 #3.6.3    等级: 2    角色: V
 验证模型下线事件是否记录了时间戳和执行者身份，以及模型签名是否已被吊销以防止重复使用。
 #3.6.4    等级: 2    角色: D/V
 验证在发现关键安全漏洞时，紧急模型退役是否能够在 pre-established 应急响应时间框架内，通过自动化的关停开关禁用对模型的访问。

---

### 参考文献

MLOps Principles
Securing AI/ML Ops – Cisco.com
Audit logs security: cryptographically signed tamper-proof logs
Machine Learning Model Versioning: Top Tools & Best Practices
AI Hygiene Starts with Models and Data Loaders – SEI Blog
How to handle versioning and rollback of a deployed ML model?
Reinforcement fine-tuning – OpenAI API
Auditing Machine Learning models: Governance, Data Security and …
Adversarial Training to Improve Model Robustness
What is AI adversarial robustness? – IBM Research
Exploring Data Provenance: Ensuring Data Integrity and Authenticity
MITRE ATLAS
AWS Prescriptive Guidance – Best practices for retiring applications …

## C4 基础设施、配置与部署安全

### 控制目标

AI 基础设施必须通过安全配置、运行时隔离、可信的部署管线和全面监控等措施加强防护，以抵御特权提升、供应链篡改和横向移动。只有经过授权、经过验证的基础设施组件和配置通过受控流程进入生产环境，保持安全性、完整性和可审计性。

核心安全目标：只有经过密码学签名且经过漏洞扫描的基础设施组件才能通过自动化验证流水线进入生产环境，这些流水线执行安全策略并维护不可篡改的审计日志。

---

### C4.1 运行时环境隔离

通过内核级隔离原语和强制访问控制来防止容器逃逸和提权。

 #4.1.1    等级: 1    角色: D/V
 验证所有 AI 容器在 Linux 能力集上丢弃除 CAP_SETUID、CAP_SETGID 以及在安全基线中明确要求的能力之外的所有能力。
 #4.1.2    等级: 1    角色: D/V
 验证 seccomp 配置文件是否阻止所有系统调用，只有位于预先批准的白名单中的调用才被允许，违规时将终止容器并生成安全警报。
 #4.1.3    等级: 2    角色: D/V
 验证 AI 工作负载在只读根文件系统、用于临时数据的 tmpfs，以及用于持久数据的命名卷上运行，并强制实施 noexec 挂载选项。
 #4.1.4    等级: 2    角色: D/V
 验证基于 eBPF 的运行时监控（Falco、Tetragon，或等效方案）能够检测特权提升的尝试，并在组织的响应时间要求内自动终止违规进程。
 #4.1.5    等级: 3    角色: D/V
 验证高风险 AI 工作负载在硬件隔离环境中执行（Intel TXT、AMD SVM，或专用裸机节点），并进行鉴证。

---

### C4.2 安全的构建与部署流水线

通过可复现的构建和已签名的产物来确保密码学完整性和供应链安全。

 #4.2.1    等级: 1    角色: D/V
 验证基础设施即代码在每次提交时使用工具（tfsec、Checkov 或 Terrascan）进行扫描；若发现 CRITICAL 或 HIGH 严重性，则阻止合并。
 #4.2.2    等级: 1    角色: D/V
 验证容器构建在不同构建之间具有相同的 SHA256 哈希值以实现可重复性，并生成由 Sigstore 签名的 SLSA 三级溯源证明。
 #4.2.3    等级: 2    角色: D/V
 在将容器镜像推送到镜像注册表之前，验证它们是否嵌入 CycloneDX 或 SPDX SBOM，并且是否已使用 Cosign 进行签名；未签名的镜像在部署时应被拒绝。
 #4.2.4    等级: 2    角色: D/V
 验证 CI/CD 流水线是否使用来自 HashiCorp Vault、AWS IAM 角色或 Azure 托管身份的 OIDC 令牌，且其有效期不超过组织安全策略的上限。
 #4.2.5    等级: 2    角色: D/V
 在容器执行之前的部署过程中，验证 Cosign 签名和 SLSA 溯源信息；若验证失败，部署将失败。
 #4.2.6    等级: 2    角色: D/V
 请验证构建环境是否在临时容器或虚拟机中运行，且没有持久存储，并与生产 VPC 的网络隔离。

---

### C4.3 网络安全与访问控制

实现零信任网络，采用默认拒绝策略并实现加密通信。

 #4.3.1    等级: 1    角色: D/V
 验证 Kubernetes 网络策略（NetworkPolicies）或任何等效实现，是否实现默认拒绝入口流量/出口流量，并对所需端口（443、8080 等）设有明确的允许规则。
 #4.3.2    等级: 1    角色: D/V
 验证 SSH（端口 22）、RDP（端口 3389）以及云元数据端点（169.254.169.254）是否被阻止或需要基于证书的身份验证。
 #4.3.3    等级: 2    角色: D/V
 验证出站流量是否通过 HTTP/HTTPS 代理（Squid、Istio，或云 NAT 网关）进行过滤，并具有域名白名单且对被阻止的请求进行日志记录。
 #4.3.4    等级: 2    角色: D/V
 验证服务间通信是否使用双向 TLS，并按照组织策略轮换证书，同时强制执行证书校验（不允许 skip-verify 标志）。
 #4.3.5    等级: 2    角色: D/V
 验证 AI 基础设施在专用的 VPCs/VNets 中运行，且无直接互联网访问，并仅通过 NAT 网关或堡垒主机进行通信。

---

### C4.4 机密信息与加密密钥管理

通过硬件支持的存储来保护凭据，并实现自动轮换，同时采用零信任访问。

 #4.4.1    等级: 1    角色: D/V
 验证机密信息是否存储在 HashiCorp Vault、AWS Secrets Manager、Azure Key Vault 或 Google Secret Manager 中，并在静态加密下使用 AES-256。
 #4.4.2    等级: 1    角色: D/V
 验证密钥是否在 FIPS 140-2 Level 2 硬件安全模块（AWS CloudHSM、Azure Dedicated HSM）中生成，并根据组织的加密策略进行密钥轮换。
 #4.4.3    等级: 2    角色: D/V
 验证密钥轮换是否实现自动化、具备零停机部署，并在人员变动或安全事件触发时立即轮换。
 #4.4.4    等级: 2    角色: D/V
 验证容器镜像是否已使用工具进行扫描（GitLeaks、TruffleHog 或 detect-secrets），以阻止包含 API 密钥、密码或证书的构建。
 #4.4.5    等级: 2    角色: D/V
 验证对生产环境秘密的访问是否需要多因素身份验证（使用硬件令牌，如 YubiKey、FIDO2），并且被不可变审计日志记录，日志中包含用户身份和时间戳。
 #4.4.6    等级: 2    角色: D/V
 验证机密数据是否通过 Kubernetes Secret 资源、挂载卷或初始化容器注入，并确保机密数据从不嵌入环境变量或镜像中。

---

### C4.5 AI 工作负载 沙箱化 & 验证

在安全的沙箱中隔离不可信的人工智能模型，并进行全面的行为分析。

 #4.5.1    等级: 1    角色: D/V
 验证 外部人工智能模型 是否 在 gVisor、微型虚拟机（如 Firecracker、CrossVM） 或 带有 --security-opt=no-new-privileges 和 --read-only 标志 的 Docker 容器 中 执行。
 #4.5.2    等级: 1    角色: D/V
 验证沙箱环境是否没有网络连接（--network=none），或仅允许来自本地主机的访问，并通过 iptables 规则阻止所有外部请求。
 #4.5.3    等级: 2    角色: D/V
 确保 AI 模型验证包含自动化红队测试、按组织定义的测试覆盖范围，以及用于检测后门的行为分析。
 #4.5.4    等级: 2    角色: D/V
 请在将 AI 模型提升到生产环境之前，验证其沙箱结果是否已由经授权的安全人员进行密码学签名，并且已存储在不可变的审计日志中。
 #4.5.5    等级: 2    角色: D/V
 在评估之间，验证沙箱环境是否已从黄金映像中销毁并重新创建，并进行完整的文件系统和内存清理。

---

### C4.6 基础设施安全监控

通过自动化修复和实时告警，持续对基础设施进行扫描和监控。

 #4.6.1    等级: 1    角色: D/V
 验证容器镜像是否按照组织日程进行扫描，并在检测到严重漏洞时，依据组织风险阈值阻止部署。
 #4.6.2    等级: 1    角色: D/V
 验证基础设施是否通过 CIS 基准或 NIST 800-53 控制，具备组织定义的合规阈值，并对未通过的检查实现自动修复。
 #4.6.3    等级: 2    角色: D/V
 验证高危漏洞是否已按组织的风险管理时间表打补丁，并为正在被利用的 CVE 设置应急程序。
 #4.6.4    等级: 2    角色: V
 验证安全告警是否能够与 SIEM 平台（Splunk、Elastic 或 Sentinel）集成，使用 CEF 或 STIX/TAXII 格式，并进行自动化事件富化。
 #4.6.5    等级: 3    角色: V
 验证基础设施指标是否已导出到监控系统（Prometheus, DataDog），并具备 SLA 仪表板和高管报告。
 #4.6.6    等级: 2    角色: D/V
 按照组织的监控要求，使用工具（Chef InSpec、AWS Config）检测配置漂移，并对未经授权的变更实现自动回滚。

---

### C4.7 AI 基础设施资源管理

通过配额和监控防止资源耗尽攻击，并确保资源分配的公平性。

 #4.7.1    等级: 1    角色: D/V
 验证 GPU/TPU 使用率是否被监控，并在组织定义的阈值下触发警报，以及基于容量管理策略激活自动伸缩或负载均衡。
 #4.7.2    等级: 1    角色: D/V
 验证人工智能工作负载指标（推理延迟、吞吐量、错误率）是否按照组织的监控要求收集，并将其与基础设施利用率相关联。
 #4.7.3    等级: 2    角色: D/V
 验证 Kubernetes ResourceQuotas（或等效方案）是否按照组织的资源分配策略对单个工作负载进行限制，并强制执行硬性上限。
 #4.7.4    等级: 2    角色: V
 验证成本监控是否按工作负载/租户跟踪支出，并基于组织预算阈值触发警报，以及用于预算超支的自动化控制。
 #4.7.5    等级: 3    角色: V
 验证容量规划是否使用历史数据、并包含由组织定义的预测周期，以及基于需求模式的自动资源配置。
 #4.7.6    等级: 2    角色: D/V
 验证资源耗尽是否根据组织响应要求触发断路器，包括基于容量策略的速率限制和工作负载隔离。

---

### C4.8 环境分离与发布控制

通过自动化发布门控和安全验证来强制执行严格的环境边界。

 #4.8.1    等级: 1    角色: D/V
 验证开发/测试/生产环境在各自的 VPCs/VNets 中运行，且没有共享的 IAM 角色、安全组或网络连通性。
 #4.8.2    等级: 1    角色: D/V
 验证环境推广需要由组织定义的授权人员的批准，并具备密码学签名和不可变的审计日志。
 #4.8.3    等级: 2    角色: D/V
 请验证生产环境是否阻止 SSH 访问、禁用调试端点，以及是否要求变更请求具备组织层面的提前通知要求，紧急情况除外。
 #4.8.4    等级: 2    角色: D/V
 确保基础设施即代码（IaC）变更在合并到主分支之前需要经过同行评审、自动化测试和安全扫描。
 #4.8.5    等级: 2    角色: D/V
 验证非生产数据是否已根据组织隐私要求进行匿名化、进行合成数据生成，或在移除PII的前提下完成完全数据脱敏并已通过验证。
 #4.8.6    等级: 2    角色: D/V
 验证发布门控包含自动化安全测试（SAST、DAST、容器扫描），并且批准所需的 CRITICAL 发现为零。

---

### C4.9 基础设施 备份 & 恢复

通过自动化备份、经过测试的恢复流程和灾难恢复能力，确保基础设施的弹性。

 #4.9.1    等级: 1    角色: D/V
 请验证基础设施配置是否已按照组织的备份计划进行备份，并在地理上分离的区域实施 3-2-1 备份策略。
 #4.9.2    等级: 2    角色: D/V
 验证备份系统在隔离网络中运行，使用单独的凭据，并采用物理隔离存储以防勒索软件攻击。
 #4.9.3    等级: 2    角色: V
 验证恢复程序是否按照组织的时间表通过自动化测试进行测试和验证，并确保 RTO 和 RPO 目标符合组织要求。
 #4.9.4    等级: 3    角色: V
 验证灾难恢复是否包含针对 AI 的专用运行手册，其中包含模型权重恢复、GPU 集群重建，以及服务依赖关系映射。

---

### C4.10 基础设施合规与治理

通过持续评估、文档化和自动化控制来保持监管合规性。

 #4.10.1    等级: 2    角色: D/V
 验证基础设施合规性是否按照组织日程对 SOC 2、ISO 27001 或 FedRAMP 控制进行评估，并进行自动化证据收集。
 #4.10.2    等级: 2    角色: V
 验证基础设施文档是否包含网络拓扑图、数据流图和威胁模型，并根据组织变更管理要求进行更新。
 #4.10.3    等级: 3    角色: D/V
 验证基础设施变更是否经过自动化合规性影响评估，并通过监管批准工作流对高风险修改进行处理。

---

### C4.11 AI 硬件 安全

确保 AI 专用硬件组件的安全性，包括 GPU、TPU 和专用的 AI 加速器。

 #4.11.1    等级: 2    角色: D/V
 验证AI加速器固件（GPU BIOS、TPU固件）是否已通过密码学签名进行验证，并按组织的补丁管理时间表更新。
 #4.11.2    等级: 2    角色: D/V
 在工作负载执行之前，通过硬件信任证明验证人工智能加速器的完整性，使用 TPM 2.0、Intel TXT 或 AMD SVM。
 #4.11.3    等级: 2    角色: D/V
 验证在工作负载之间是否通过 SR-IOV、MIG（Multi-Instance GPU）或等效的硬件分区实现 GPU 内存隔离，并在作业之间进行内存清理。
 #4.11.4    等级: 3    角色: V
 验证 AI 硬件供应链是否包含源头可追溯性验证、制造商证书以及防篡改包装验证。
 #4.11.5    等级: 3    角色: D/V
 验证硬件安全模块（HSM）是否通过 FIPS 140-2 Level 3 或 Common Criteria EAL4+ 认证，以保护 AI 模型权重和加密密钥。

---

### C4.12 边缘与分布式 AI 基础设施

包括边缘计算、联邦学习和多站点架构在内的安全分布式人工智能部署。

 #4.12.1    等级: 2    角色: D/V
 验证边缘 AI 设备是否通过双向 TLS 对中心基础设施进行身份验证，并按组织证书管理策略轮换设备证书。
 #4.12.2    等级: 2    角色: D/V
 验证边缘设备是否实现安全启动，并具备经过验证的签名和防止固件降级攻击的回滚保护。
 #4.12.3    等级: 3    角色: D/V
 请验证分布式人工智能协同是否使用拜占庭容错共识算法，并具备参与者验证和恶意节点检测。
 #4.12.4    等级: 3    角色: D/V
 验证边缘到云端通信是否包含带宽节流、数据压缩，以及具备安全本地存储的离线运行能力。

---

### C4.13 多云与混合基础设施安全

在跨多家云提供商和混合云-本地部署环境中保障 AI 工作负载的安全。

 #4.13.1    等级: 2    角色: D/V
 验证多云 AI 部署是否使用云无关的身份联合（OIDC、SAML），并在跨提供商之间实现集中策略管理。
 #4.13.2    等级: 2    角色: D/V
 验证跨云数据传输是否使用端到端加密、采用客户管理密钥，并在各司法辖区强制执行数据驻留控制。
 #4.13.3    等级: 2    角色: D/V
 验证混合云人工智能工作负载在本地环境与云环境之间实现一致的安全策略，并具备统一的监控与告警。
 #4.13.4    等级: 3    角色: V
 请验证云厂商锁定防护是否包含可移植的基础设施即代码、标准化的 API，以及具备格式转换工具的数据导出能力。
 #4.13.5    等级: 3    角色: V
 验证多云成本优化是否包含防止资源蔓延的安全控制，以及防止未授权跨云数据传输所产生的费用的措施。

---

### C4.14 基础设施自动化 & GitOps 安全性

为 AI 基础设施管理提供安全的基础设施自动化流水线和 GitOps 工作流。

 #4.14.1    等级: 2    角色: D/V
 请核实 GitOps 仓库是否要求提交经过 GPG 密钥签名，并具备防止直接推送到主分支的分支保护规则。
 #4.14.2    等级: 2    角色: D/V
 验证基础设施自动化是否包含漂移检测、自动修复，以及在未授权变更时根据组织响应要求触发的回滚能力。
 #4.14.3    等级: 2    角色: D/V
 确保自动化基础设施配置包含安全策略验证，并对不合规配置实施部署阻止。
 #4.14.4    等级: 2    角色: D/V
 验证基础设施自动化的机密信息是否通过外部密钥运算符（External Secrets Operator、Bank-Vaults）进行管理，并具备自动轮换功能。
 #4.14.5    等级: 3    角色: V
 验证自愈基础设施是否包含安全事件关联，并具备自动化事件响应和利益相关者通知工作流。

---

### C4.15 量子抗性基础设施安全

通过后量子密码学和量子安全协议来构建人工智能基础设施，以应对量子计算威胁。

 #4.15.1    等级: 3    角色: D/V
 验证 AI 基础设施是否实现了 NIST 批准的后量子密码学算法（CRYSTALS-Kyber、CRYSTALS-Dilithium、SPHINCS+），用于密钥交换和数字签名。
 #4.15.2    等级: 3    角色: D/V
 请验证是否已为高安全性 AI 通信实现了量子密钥分发（QKD）系统，并采用量子安全的密钥管理协议。
 #4.15.3    等级: 3    角色: D/V
 验证密码学灵活性框架是否能够在证书与密钥自动轮换的情况下，快速迁移到新的后量子算法。
 #4.15.4    等级: 3    角色: V
 请验证量子威胁建模是否能够评估人工智能基础设施对量子攻击的脆弱性，并具备文档化的迁移时间表和风险评估。
 #4.15.5    等级: 3    角色: D/V
 验证混合经典-量子密码系统在量子过渡期提供纵深防御，并进行性能监控。

---

### C4.16 机密计算与安全可信执行环境

使用基于硬件的可信执行环境和机密计算技术来保护 AI 工作负载和模型权重。

 #4.16.1    等级: 3    角色: D/V
 验证敏感 AI 模型是否在英特尔 SGX 安全区、AMD SEV-SNP 或 ARM TrustZone 中执行，并具备加密内存与鉴证能力。
 #4.16.2    等级: 3    角色: D/V
 验证机密容器（Kata Containers、具机密计算的 gVisor）是否利用硬件强制的内存加密来隔离 AI 工作负载。
 #4.16.3    等级: 3    角色: D/V
 在加载 AI 模型之前，确保远程证明能够验证执行区的完整性，并提供执行环境真实性的密码学证明。
 #4.16.4    等级: 3    角色: D/V
 验证机密 AI 推理服务是否通过带有密封模型权重和受保护执行的加密计算来防止模型提取。
 #4.16.5    等级: 3    角色: D/V
 验证受信任执行环境编排是否在远程认证和加密通信通道的条件下管理安全执行环境（Enclave）的生命周期。
 #4.16.6    等级: 3    角色: D/V
 验证安全多方计算（SMPC）是否能够在不暴露单个数据集或模型参数的情况下实现协同式人工智能训练。

---

### C4.17 零知识基础设施

实现零知识证明系统，用于隐私保护的 AI 验证与身份认证，同时不泄露敏感信息。

 #4.17.1    等级: 3    角色: D/V
 验证零知识证明（ZK-SNARKs、ZK-STARKs）在不暴露模型权重或训练数据的情况下，是否能够验证 AI 模型的完整性和训练溯源。
 #4.17.2    等级: 3    角色: D/V
 验证基于零知识证明的身份验证系统是否能够在不披露身份相关信息的情况下，为 AI 服务提供隐私保护的用户验证。
 #4.17.3    等级: 3    角色: D/V
 验证 PSI 协议是否能够实现用于联邦式人工智能的安全数据匹配，同时不暴露单独的数据集。
 #4.17.4    等级: 3    角色: D/V
 验证零知识机器学习（ZKML）系统是否能够通过对正确计算的密码学证明，实现对 AI 推断的可验证性。
 #4.17.5    等级: 3    角色: D/V
 验证 ZK-rollups 是否提供可扩展、隐私保护的 AI 交易处理，并具备批量验证和更低的计算开销。

---

### C4.18 侧信道攻击防护

保护人工智能基础设施免受可能泄露敏感信息的时序、功耗、电磁和基于缓存的侧信道攻击。

 #4.18.1    等级: 3    角色: D/V
 验证 AI 推理时间是否已通过常数时间算法和填充进行归一化，以防止基于时间的模型提取攻击。
 #4.18.2    等级: 3    角色: D/V
 请验证功耗分析防护是否包括噪声注入、电源线滤波，以及用于 AI 硬件的随机化执行模式。
 #4.18.3    等级: 3    角色: D/V
 验证基于缓存的侧信道缓解措施是否使用缓存分区、随机化和刷新指令以防止信息泄漏。
 #4.18.4    等级: 3    角色: D/V
 验证对电磁辐射发射的防护措施是否包括屏蔽、信号滤波和随机化处理，以防止 TEMPEST 式攻击。
 #4.18.5    等级: 3    角色: D/V
 验证微架构层面的侧信道防御是否包含对投机执行的控制以及对内存访问模式的混淆。

---

### C4.19 神经形态与专用人工智能硬件安全

确保新兴的人工智能硬件架构的安全性，包括神经形态芯片、FPGA、定制 ASIC 以及光子计算系统。

 #4.19.1    等级: 3    角色: D/V
 请验证神经形态芯片安全是否包括脉冲模式加密、突触权重保护，以及基于硬件的学习规则验证。
 #4.19.2    等级: 3    角色: D/V
 请验证基于 FPGA 的 AI 加速器是否实现了比特流加密、防篡改机制，以及带有经过认证更新的安全配置加载。
 #4.19.3    等级: 3    角色: D/V
 验证定制 ASIC 的安全性是否包含片上安全处理器、硬件信任根，以及带篡改检测的安全密钥存储。
 #4.19.4    等级: 3    角色: D/V
 验证光学计算系统是否实现量子安全光学加密、安全的光子交换，以及受保护的光信号处理。
 #4.19.5    等级: 3    角色: D/V
 验证混合模拟-数字 AI 芯片是否具备安全的模拟计算、受保护的权重存储，以及经过认证的模拟-数字转换。

---

### C4.20 隐私保护计算基础设施

实现用于隐私保护计算的基础设施控制，以在人工智能处理和分析过程中保护敏感数据。

 #4.20.1    等级: 3    角色: D/V
 验证同态加密基础设施在对敏感人工智能工作负载进行加密计算时，是否具备加密完整性验证和性能监控。
 #4.20.2    等级: 3    角色: D/V
 验证私有信息检索系统是否能够在对访问模式进行密码学保护的前提下执行数据库查询，同时不暴露查询模式。
 #4.20.3    等级: 3    角色: D/V
 验证安全多方计算协议是否能够在不暴露单个输入或中间计算结果的前提下实现隐私保护的人工智能推理。
 #4.20.4    等级: 3    角色: D/V
 请验证隐私保护的密钥管理是否包含分布式密钥生成、阈值密码学，以及带有硬件保护的密钥轮换。
 #4.20.5    等级: 3    角色: D/V
 验证隐私保护计算的性能是否通过批处理、缓存和硬件加速得到优化，同时保持密码学安全性保障。

---

### C4.15 代理框架 云端集成安全性与混合部署

针对具有混合本地与云架构的云集成代理框架的安全控制

 #4.15.1    等级: 1    角色: D/V
 验证云存储集成是否使用端到端加密，并采用由代理控制的密钥管理。
 #4.15.2    等级: 2    角色: D/V
 验证混合部署的安全边界是否被明确界定，并通过加密通信通道进行保护。
 #4.15.3    等级: 2    角色: D/V
 请验证云资源访问是否包含零信任验证及持续身份验证。
 #4.15.4    等级: 3    角色: D/V
 验证数据驻留要求是否由对存储位置的密码学证明来强制执行。
 #4.15.5    等级: 3    角色: D/V
 核实云服务提供商的安全评估是否包含面向代理的威胁建模和风险评估。

---

### 参考文献

NIST Cybersecurity Framework 2.0
CIS Controls v8
OWASP Container Security Verification Standard
Kubernetes Security Best Practices
SLSA Supply Chain Security Framework
NIST SP 800-190: Application Container Security Guide
Cloud Security Alliance: Cloud Controls Matrix
ENISA: Secure Infrastructure Design
NIST SP 800-53: Security Controls for Federal Information Systems
ISO 27001:2022 Information Security Management
NIST AI Risk Management Framework
CIS Kubernetes Benchmark
FIPS 140-2 Security Requirements
NIST SP 800-207: Zero Trust Architecture
IEEE 2857: Privacy Engineering for AI Systems
NIST SP 800-161: Cybersecurity Supply Chain Risk Management
NIST Post-Quantum Cryptography Standards
Intel SGX Developer Guide
AMD SEV-SNP White Paper
ARM TrustZone Technology
ZK-SNARKs: A Gentle Introduction
NIST SP 800-57: Cryptographic Key Management
Side-Channel Attack Countermeasures
Neuromorphic Computing Security Challenges
FPGA Security: Fundamentals, Evaluation, and Countermeasures
Microsoft SEAL: Homomorphic Encryption Library
HElib: Homomorphic Encryption Library
PALISADE Lattice Cryptography Library
Differential Privacy: A Survey of Results
Secure Aggregation for Federated Learning
Private Information Retrieval: Concepts and Constructions

## C5 面向 AI 组件与用户的访问控制与身份认证

### 控制目标

对 AI 系统的有效访问控制需要强健的身份管理、上下文感知的授权，以及在零信任原则指导下的运行时强制执行。这些控制确保人类、服务以及自治代理仅在明确授予的范围内与模型、数据和计算资源交互，并具备持续的验证与审计能力。

---

### C5.1 身份管理与认证

为所有实体建立基于密码学的身份，并对特权操作实施多因素认证。

 #5.1.1    等级: 1    角色: D/V
 请验证所有人类用户和服务主体是否通过集中式企业身份提供者（IdP）进行身份验证，使用 OIDC/SAML 协议，并实现唯一的身份到令牌映射（不使用共享账户或凭据）。
 #5.1.2    等级: 1    角色: D/V
 请验证高风险操作（模型部署、权重导出、训练数据访问、生产配置变更）是否需要多因素认证或带有会话重新验证的分步认证。
 #5.1.3    等级: 2    角色: D
 在获得生产系统访问权限之前，确保新主体的身份核验符合 NIST 800-63-3 的 IAL-2 或等效标准。
 #5.1.4    等级: 2    角色: V
 验证访问权限审查是否按季度进行，并具备对不活跃账户的自动检测、凭据轮换的强制执行，以及注销访问的工作流。
 #5.1.5    等级: 3    角色: D/V
 验证联邦 AI 代理通过签名的 JWT 断言进行身份验证，这些断言的最大有效期为 24 小时，并包含来源的密码学证明。

---

### C5.2 资源授权与最小权限原则

为所有 AI 资源实现细粒度访问控制，采用显式权限模型并提供审计日志。

 #5.2.1    等级: 1    角色: D/V
 验证每个 AI 资源（数据集、模型、端点、向量集合、嵌入索引、计算实例）是否实施基于角色的访问控制，并具备显式允许列表与默认拒绝策略。
 #5.2.2    等级: 1    角色: D/V
 请验证默认情况下是否强制执行最小权限原则：服务账户从只读权限开始，写访问需要提供书面业务正当性证明。
 #5.2.3    等级: 1    角色: V
 验证所有访问控制修改是否与已批准的变更请求相关联，并以不可变的方式记录，包含时间戳、执行者身份、资源标识符和权限变更。
 #5.2.4    等级: 2    角色: D
 验证数据分类标签（PII、PHI、出口受控、专有）是否会自动传播到派生资源（嵌入向量、提示缓存、模型输出），并实现一致的策略执行。
 #5.2.5    等级: 2    角色: D/V
 验证未授权访问尝试和权限提升事件是否在5分钟内触发带有上下文元数据的实时警报，并将警报发送到 SIEM 系统。

---

### C5.3 动态策略评估

部署基于属性的访问控制（ABAC）引擎，以实现上下文感知的授权决策，并具备审计能力。

 #5.3.1    等级: 1    角色: D/V
 验证授权决策是否外部化到一个专用的策略引擎（OPA、Cedar 或同等产品），该引擎通过经过身份验证的 API 访问，并具备密码学完整性保护。
 #5.3.2    等级: 1    角色: D/V
 验证策略在运行时对动态属性进行评估，包括用户授权级别、资源敏感性分类、请求上下文、租户隔离以及时间约束。
 #5.3.3    等级: 2    角色: D
 在生产部署之前，确保策略定义经过版本控制、同行评审，并通过 CI/CD 流水线中的自动化测试进行验证。
 #5.3.4    等级: 2    角色: V
 验证策略评估结果是否包含结构化的决策依据，并将其传输到 SIEM 系统以用于关联分析和合规报告。
 #5.3.5    等级: 3    角色: D/V
 请核实策略缓存的生存时间（TTL）值在高敏感资源上不得超过 5 分钟，在具备缓存失效能力的标准资源上不得超过 1 小时。

---

### C5.4 查询时的安全执行

实现数据库层面的安全控制，包含强制性过滤和行级安全策略。

 #5.4.1    等级: 1    角色: D/V
 验证所有向量数据库和 SQL 查询是否包含强制性的安全过滤器（租户 ID、敏感性标签、用户作用域），这些过滤器在数据库引擎层面强制执行，而非应用程序代码中。
 #5.4.2    等级: 1    角色: D/V
 请验证对所有向量数据库、搜索索引和训练数据集，是否启用带策略继承的行级安全策略（RLS）和字段级掩码。
 #5.4.3    等级: 2    角色: D
 验证失败的授权评估将通过立即中止查询并返回明确的授权错误代码来防止“混淆代理攻击”，而不是返回空的结果集。
 #5.4.4    等级: 2    角色: V
 验证策略评估延迟是否被持续监控，并对可能导致授权绕过的超时条件设置自动警报。
 #5.4.5    等级: 3    角色: D/V
 验证查询重试机制是否会重新评估授权策略，以适应活跃用户会话中的动态权限变化。

---

### C5.5 输出过滤与数据丢失防护

部署后处理控制，以防止 AI 生成内容中的未授权数据暴露。

 #5.5.1    等级: 1    角色: D/V
 请核实，在向请求方交付内容之前，推理后过滤机制是否能够对未授权的个人身份信息（PII）、机密信息和专有数据进行扫描并将其涂黑。
 #5.5.2    等级: 1    角色: D/V
 验证模型输出中的引用、参考文献和来源归属是否已根据调用方权限进行校验，并在检测到未授权访问时将其移除。
 #5.5.3    等级: 2    角色: D
 验证输出格式限制（已脱敏的PDF、元数据已移除的图片、经批准的文件类型）是否根据用户权限级别和数据分类被强制执行。
 #5.5.4    等级: 2    角色: V
 验证脱敏算法具有确定性、具备版本控制，并能维护审计日志，以支持合规调查和取证分析。
 #5.5.5    等级: 3    角色: V
 验证高风险脱敏事件是否会生成自适应日志，其中包含原始内容的密码学哈希值，以便在不暴露数据的前提下用于取证检索。

---

### C5.6 多租户-隔离

在共享的 AI 基础设施中确保租户之间的密码学与逻辑隔离。

 #5.6.1    等级: 1    角色: D/V
 验证内存空间、嵌入向量存储、缓存条目和临时文件是否按租户进行命名空间隔离，并在租户删除或会话终止时进行安全擦除。
 #5.6.2    等级: 1    角色: D/V
 验证每个 API 请求是否包含经过身份验证的租户标识符，并且该标识符应通过密码学方法，与会话上下文和用户权限进行校验。
 #5.6.3    等级: 2    角色: D
 验证网络策略是否在服务网格和容器编排平台内实现默认拒绝规则，以阻止跨租户通信。
 #5.6.4    等级: 3    角色: D
 验证对每个租户的加密密钥是否唯一，并且支持客户管理密钥（CMK），以及在租户数据存储之间实现加密隔离。

---

### C5.7 自主代理授权

通过带有作用域的能力令牌和持续授权来控制对人工智能代理和自主系统的权限。

 #5.7.1    等级: 1    角色: D/V
 验证自治代理是否接收具作用域的能力令牌，该令牌明确列出被许可的操作、可访问的资源、时间边界以及运行约束。
 #5.7.2    等级: 1    角色: D/V
 请验证默认情况下高风险能力（文件系统访问、代码执行、外部 API 调用、金融交易）已被禁用，并在激活时需要明确的授权以及业务正当性理由。
 #5.7.3    等级: 2    角色: D
 验证能力令牌是否绑定到用户会话，包含密码学完整性保护，并确保它们在离线场景中不能被持久化或重复使用。
 #5.7.4    等级: 2    角色: V
 验证代理-发起的操作是否通过 ABAC 策略引擎进行二次授权，并进行完整的上下文评估和审计日志记录。
 #5.7.5    等级: 3    角色: V
 验证代理的错误条件和异常处理是否包含能力范围信息，以支持事件分析和取证调查。

---

### 参考文献

#### 标准与框架

NIST SP 800-63-3: Digital Identity Guidelines
Zero Trust Architecture – NIST SP 800-207
OWASP Application Security Verification Standard (AISVS)
​
#### 实现指南

Identity and Access Management in the AI Era: 2025 Guide – IDSA
Attribute-Based Access Control with OPA – Permify
How We Designed Cedar to Be Intuitive, Fast, and Safe – AWS
​
#### AI-专用安全

Row Level Security in Vector DBs for RAG – Bluetuple.ai
Tenant Isolation in Multi-Tenant Systems – WorkOS
Handling AI Agent Permissions – Stytch
OWASP Top 10 for Large Language Model Applications

## C6 模型、框架与数据的供应链安全

### 控制目标

AI 供应‑链攻击 利用 第三方 模型、框架 或 数据集 来 植入 后门、偏见 或 易被 利用 的 代码。这些 控制 措施 提供 端‑到‑端 的 溯源、漏洞 管理 和 监控，以 保护 整个 模型 生命周期。

---

### C6.1 预训练模型审核与溯源

在进行任何微调或部署之前，评估并认证第三方模型的来源、许可和隐藏行为。

 #6.1.1    等级: 1    角色: D/V
 验证确保每个第三方模型产物包含一个已签名的溯源记录，该记录标识源代码仓库及提交哈希。
 #6.1.2    等级: 1    角色: D/V
 在导入之前，使用自动化工具对模型进行扫描，以检查是否存在恶意层或木马触发器。
 #6.1.3    等级: 2    角色: D
 验证迁移学习中的微调是否通过对抗性评估，以检测隐藏行为。
 #6.1.4    等级: 2    角色: V
 核实在 ML‑BOM 条目中是否记录了模型许可、出口控制标签和数据来源声明。
 #6.1.5    等级: 3    角色: D/V
 验证高风险模型（公开上传的权重、未经验证的创建者）在经过人工审查和签署批准之前仍保持隔离。

---

### C6.2 框架与库扫描

持续对机器学习框架和库进行 CVE 漏洞和恶意代码的扫描，以确保运行时栈的安全。

 #6.2.1    等级: 1    角色: D/V
 验证 CI 流水线是否对 AI 框架和关键库运行依赖性扫描工具。
 #6.2.2    等级: 1    角色: D/V
 验证关键漏洞（CVSS ≥ 7.0）是否会阻止将镜像推广到生产环境。
 #6.2.3    等级: 2    角色: D
 验证静态代码分析是否能够在分叉的或 vendor 目录中的机器学习库上运行。
 #6.2.4    等级: 2    角色: V
 请确保框架升级提案包含安全影响评估，并引用公开的 CVE 数据源。
 #6.2.5    等级: 3    角色: V
 验证运行时传感器是否对偏离已签名的 SBOM 的意外动态库加载发出告警。

---

### C6.3 依赖项锁定与验证

将每个依赖项锁定到不可变摘要值，并重现构建以确保产物完全相同且防篡改。

 #6.3.1    等级: 1    角色: D/V
 验证所有包管理器是否通过锁定文件执行版本锁定。
 #6.3.2    等级: 1    角色: D/V
 验证在容器引用中使用不可变摘要，而不是可变标签。
 #6.3.3    等级: 2    角色: D
 验证可复现构建检查在 CI 运行之间比较哈希值，以确保输出完全一致。
 #6.3.4    等级: 2    角色: V
 验证构建鉴证信息是否存储18个月，以确保审计可追溯性。
 #6.3.5    等级: 3    角色: D
 验证过期的依赖是否会触发自动化拉取请求来更新或分叉固定版本。

---

### C6.4 可信来源的强制执行

仅允许从经过密码学验证、经组织‑批准的来源下载制品，并阻止其他一切来源。

 #6.4.1    等级: 1    角色: D/V
 请确保模型权重、数据集和容器仅从经批准的域名或内部注册表下载。
 #6.4.2    等级: 1    角色: D/V
 在本地缓存工件之前，验证 Sigstore/Cosign 签名以确保发布者身份。
 #6.4.3    等级: 2    角色: D
 验证出站代理是否阻止未认证制品的下载，以强制执行可信源策略。
 #6.4.4    等级: 2    角色: V
 验证代码库的允许名单是否每季度进行审查，并为每个条目提供业务合理性证据。
 #6.4.5    等级: 3    角色: V
 验证策略违规是否会触发对工件的隔离以及对依赖流水线运行的回滚。

---

### C6.5 第三方-数据集 风险评估

评估外部数据集的数据污染、偏见和法律合规性，并在它们的整个生命周期内对它们进行监控。

 #6.5.1    等级: 1    角色: D/V
 验证外部数据集是否经过污染风险评分（例如，数据指纹分析、异常检测）。
 #6.5.2    等级: 1    角色: D
 在数据集批准之前，确认偏倚指标（人口统计平等、机会均等）已被计算。
 #6.5.3    等级: 2    角色: V
 核实数据集的溯源信息和许可条款是否已在 ML‑BOM 条目中被记录。
 #6.5.4    等级: 2    角色: V
 验证定期监控是否能够检测托管数据集中的数据漂移或损坏。
 #6.5.5    等级: 3    角色: D
 在训练之前，验证不允许的内容（版权信息、个人身份信息）是否已通过自动清洗移除。

---

### C6.6 供应链攻击监控

通过 CVE 数据源、审计日志分析和红队演练，及早发现供应链威胁。

 #6.6.1    等级: 1    角色: V
 验证 CI/CD 审计日志是否流入 SIEM，以检测异常的包拉取或被篡改的构建步骤。
 #6.6.2    等级: 2    角色: D
 请验证事件响应手册是否包含针对被入侵的模型或库的回滚程序。
 #6.6.3    等级: 3    角色: V
 验证在告警分诊中，威胁情报富集标签是否对 ML 专用指标（例如模型中毒 IoCs）进行标记。

---

### C6.7 ML‑BOM 用于模型产物

生成并对详细的面向 ML 的 SBOMs（ML‑BOMs）进行签名，以便下游用户在部署时验证组件完整性。

 #6.7.1    等级: 1    角色: D/V
 验证每个模型产物是否发布一个 ML‑BOM，其中列出数据集、权重、超参数和许可证。
 #6.7.2    等级: 1    角色: D/V
 验证 ML‑BOM 生成和 Cosign 签名在持续集成中实现自动化，并且在合并时是必需的。
 #6.7.3    等级: 2    角色: D
 验证在缺少任意组件元数据（哈希值、许可证）时，ML‑BOM 完整性检查是否会导致构建失败。
 #6.7.4    等级: 2    角色: V
 验证下游消费者是否能够通过 API 查询 ML-BOMs，以在部署时验证导入的模型。
 #6.7.5    等级: 3    角色: V
 验证 ML‑BOMs 是否处于版本控制并进行差异比对，以检测未授权修改。

---

### 参考文献

ML Supply Chain Compromise – MITRE ATLAS
Supply‑chain Levels for Software Artifacts (SLSA)
CycloneDX – Machine Learning Bill of Materials
What is Data Poisoning? – SentinelOne
Transfer Learning Attack – OWASP ML Security Top 10
AI Data Security Best Practices – CISA
Secure CI/CD Supply Chain – Sumo Logic
AI & Transparency: Protect ML Models – ReversingLabs
SBOM Overview – CISA
Training Data Poisoning Guide – Lakera.ai
Dependency Pinning for Reproducible Python – Medium

## C7 模型行为、 输出控制与安全保障

### 控制目标

模型输出在生产环境中必须具备结构化、可靠、安全、可解释，并且要持续监控。这将有助于减少幻觉、隐私泄露、有害内容和失控行为，同时提高用户信任与监管合规性。

---

### C7.1 输出格式强制执行

严格的模式、受限解码和下游验证在传播之前就能阻止格式错误或恶意内容。

 #7.1.1    等级: 1    角色: D/V
 验证系统提示中是否提供响应模式（例如 JSON Schema），并对每个输出进行自动验证；不符合要求的输出将触发修复或拒绝。
 #7.1.2    等级: 1    角色: D/V
 验证已启用受约束解码（停止标记、正则表达式、最大令牌数），以防止溢出或提示注入相关的侧信道。
 #7.1.3    等级: 2    角色: D/V
 验证下游组件将输出视为不可信，并基于模式对其进行校验，或使用防注入的反序列化器进行校验。
 #7.1.4    等级: 3    角色: V
 验证不当输出事件是否已被记录、已进行速率限制、并暴露给监控系统。

---

### C7.2 幻觉检测与缓解

不确定性估计和回退策略抑制编造的回答。

 #7.2.1    等级: 1    角色: D/V
 验证 token-level log-probabilities、ensemble self-consistency、或 fine-tuned hallucination detectors为每个答案分配置信度分数。
 #7.2.2    等级: 1    角色: D/V
 验证低于可配置的置信阈值的响应是否会触发回退工作流（例如，检索增强生成、次级模型或人工审核）。
 #7.2.3    等级: 2    角色: D/V
 验证幻觉事件是否带有根本原因元数据，并将其送入事后分析管线和微调管线。
 #7.2.4    等级: 3    角色: D/V
 验证在重大模型或知识库更新后，阈值与检测器是否已重新校准。
 #7.2.5    等级: 3    角色: V
 验证仪表板的可视化是否跟踪幻觉率。

---

### C7.3 输出安全性与隐私过滤

策略过滤器和红队覆盖保护用户和机密数据。

 #7.3.1    等级: 1    角色: D/V
 验证生成前的分类器和生成后的分类器是否按政策屏蔽仇恨、骚扰、自残、极端主义以及露骨性内容。
 #7.3.2    等级: 1    角色: D/V
 验证 PII/PCI 检测和自动脱敏是否在每个响应中运行；违规将引发隐私事件。
 #7.3.3    等级: 2    角色: D
 验证保密标签（例如商业秘密）是否能够在跨模态之间传播，以防止文本、图像或代码泄漏。
 #7.3.4    等级: 3    角色: D/V
 验证过滤绕过尝试或高风险分类是否需要二次审批或用户重新认证。
 #7.3.5    等级: 3    角色: D/V
 验证过滤阈值是否考虑到法律辖区和用户年龄/角色上下文。

---

### C7.4 输出 & 动作限制

速率限制与审批门槛可防止滥用和过度自治。

 #7.4.1    等级: 1    角色: D
 验证每个用户和每个 API 密钥的配额是否对请求、令牌和成本施加限制，并在 429 错误时使用指数退避策略。
 #7.4.2    等级: 1    角色: D/V
 验证特权操作（文件写入、代码执行、网络调用）是否需要基于策略的审批或人工在环。
 #7.4.3    等级: 2    角色: D/V
 验证跨模态一致性检查，确保为同一请求生成的图像、代码和文本不能被用于隐藏恶意内容。
 #7.4.4    等级: 2    角色: D
 验证智能体的委托深度、递归限制以及允许的工具列表是否已显式配置。
 #7.4.5    等级: 3    角色: V
 验证对超出限制的违规行为是否会产生结构化的安全事件，以供 SIEM 摄取。

---

### C7.5 输出可解释性

透明的信号提升用户信任和内部调试效率。

 #7.5.1    等级: 2    角色: D/V
 验证在风险评估被认为适当时，是否向用户披露置信度分数或简要推理摘要。
 #7.5.2    等级: 2    角色: D/V
 验证生成的解释是否避免泄露敏感的系统提示或专有数据。
 #7.5.3    等级: 3    角色: D
 验证系统是否能够捕获逐个令牌的对数概率或注意力图，并将其存储以供授权人员查看。
 #7.5.4    等级: 3    角色: V
 请验证可解释性产物是否与模型发布一起进行版本控制，以便审计。

---

### C7.6 监控集成

实时可观测性在开发与生产之间实现闭环。

 #7.6.1    等级: 1    角色: D
 验证这些指标（模式违规、幻觉率、有害性、PII 泄漏、延迟、成本）是否传输到中央监控平台。
 #7.6.2    等级: 1    角色: V
 验证是否为每个安全指标定义了告警阈值，并具备值班升级路径。
 #7.6.3    等级: 2    角色: V
 验证仪表板是否将输出异常与模型/版本、功能开关以及上游数据变更相关联。
 #7.6.4    等级: 2    角色: D/V
 验证监控数据是否在有文档化的 MLOps 工作流中反馈用于再训练、微调或规则更新。
 #7.6.5    等级: 3    角色: V
 确保监控管线经过渗透测试并实施访问控制，以防止敏感日志泄漏。

---

### 7.7 生成式媒体安全措施

通过执行政策约束、输出验证和可追溯性来确保 AI 系统不生成非法、有害或未经授权的媒体内容。

 #7.7.1    等级: 1    角色: D/V
 验证系统提示和用户指令是否明确禁止生成非法、有害或未经同意的深度伪造媒体（例如图像、视频、音频）。
 #7.7.2    等级: 2    角色: D/V
 请确保对试图生成冒充、性露骨的深度伪造内容，或未获同意便展示真实个人的媒体内容的尝试进行过滤。
 #7.7.3    等级: 2    角色: V
 请验证系统是否使用感知哈希算法、水印检测或指纹识别来防止未经授权复制受版权保护的媒体。
 #7.7.4    等级: 3    角色: D/V
 验证所有生成的媒体是否进行了密码学签名、嵌入水印，或嵌入防篡改的溯源元数据，以实现下游可追溯性。
 #7.7.5    等级: 3    角色: V
 验证旁路尝试（例如，提示混淆、俚语、对抗性措辞）是否被检测、记录并实施速率限制；重复滥用将上报至监控系统。

### 参考文献

NIST AI Risk Management Framework
ISO/IEC 42001:2023 – AI Management System
OWASP Top-10 for Large Language Model Applications (2025)
Improper Output Handling – OWASP LLM05:2025
Practical Techniques to Constrain LLM Output
Dataiku – Structured Text Generation Guide
VL-Uncertainty: Detecting Hallucinations
HaDeMiF: Hallucination Detection & Mitigation
Building Confidence in LLM Outputs
Explainable AI & LLMs
LLM Red-Teaming Guide
Sensitive Information Disclosure in LLMs
LangChain – Chat Model Rate Limiting
OpenAI Rate-Limit & Exponential Back-off
Arize AI – LLM Observability Platform

## C8 内存、嵌入与向量数据库安全

### 控制目标

嵌入向量与向量存储充当当代 AI 系统的“实时记忆”，持续接受用户提供的数据，并通过检索增强生成（RAG）将其重新引入到模型上下文中。若不加治理，这些记忆可能泄露个人身份信息（PII）、侵犯同意，或被反向利用以重构原始文本。本控制族的目标是对内存管线和向量数据库进行加固，使访问遵循最小权限原则，嵌入向量实现隐私保护，存储的向量到期或可按需撤销，且每个用户的记忆不会污染其他用户的提示或完成内容。

---

### C8.1 内存 & RAG 指标的访问控制

对每个向量集合实施细粒度访问控制。

 #8.1.1    等级: 1    角色: D/V
 验证行级和命名空间级访问控制规则是否对按租户、集合或文档标签的插入、删除和查询操作进行限制。
 #8.1.2    等级: 1    角色: D/V
 验证 API 密钥或 JWTs 是否携带具有作用域的声明（例如集合 ID、操作动词），并且至少每季度轮换一次。
 #8.1.3    等级: 2    角色: D/V
 验证 是否 权限升级 尝试（例如，跨命名空间相似性查询） 是否 被 检测 并 记录 到 SIEM 在 5 分钟 内。
 #8.1.4    等级: 2    角色: D/V
 验证向量数据库的审计日志是否记录主体标识符、操作、向量 ID/命名空间、相似性阈值和结果计数。
 #8.1.5    等级: 3    角色: V
 请确保在引擎升级或 index-sharding 规则变更时，对访问控制决策进行绕过漏洞测试。

---

### C8.2 嵌入净化与验证

在向量化之前对文本进行 PII 的预筛查、对敏感信息进行涂黑或伪匿名化处理，并可选择对嵌入向量进行后处理以去除残留信号。

 #8.2.1    等级: 1    角色: D/V
 验证 个人身份信息 和 受监管数据 是否 通过 自动 分类器 检测 到，并 在 嵌入 前 进行 屏蔽、 令牌化 或 丢弃。
 #8.2.2    等级: 1    角色: D
 验证嵌入管线是否会拒绝或对包含可执行代码或非 UTF-8 片段的输入进行隔离，这些输入可能污染索引。
 #8.2.3    等级: 2    角色: D/V
 验证对句子嵌入应用的本地差分-隐私净化（或度量差分-隐私净化）是否被应用于与任何已知个人身份信息（PII）令牌的距离低于可配置阈值的句子嵌入。
 #8.2.4    等级: 2    角色: V
 请验证脱敏有效性（例如，PII 脱敏的召回率、语义漂移）是否至少每六个月针对基准语料库进行验证。
 #8.2.5    等级: 3    角色: D/V
 确保净化配置处于版本控制之中，变更需经过同行评审。

---

### C8.3 记忆到期、撤销与删除

GDPR 的“被遗忘权”和类似法律要求及时删除；因此，向量存储必须支持 TTL（生存时间）、硬删除和墓碑化处理，以确保被撤销的向量无法被恢复或重新索引。

 #8.3.1    等级: 1    角色: D/V
 请验证每个向量及其元数据记录是否携带 TTL 或显式保留标签，并且自动清理作业会遵循该标签。
 #8.3.2    等级: 1    角色: D/V
 验证用户发起的删除请求在 30 天内清除向量、元数据、缓存副本和派生索引。
 #8.3.3    等级: 2    角色: D
 验证逻辑删除在硬件支持的情况下是否随之对存储块进行加密擦除；如果硬件不支持，则通过密钥保管库中的密钥销毁来实现。
 #8.3.4    等级: 3    角色: D/V
 验证在过期后不到 500 毫秒内，已过期的向量是否会被排除在最近邻搜索结果之外。

---

### C8.4 防止嵌入反演与信息泄露

最近的防御措施—噪声叠加、投影网络、隐私神经元扰动，以及应用层加密—可以将令牌级反演率降低到5%以下。

 #8.4.1    等级: 1    角色: V
 请核实是否存在覆盖反演攻击、成员推断攻击和属性推断攻击的正式威胁模型，并且每年对其进行审查。
 #8.4.2    等级: 2    角色: D/V
 验证应用层加密或可搜索加密是否能够防止向量被基础设施管理员或云端工作人员直接读取。
 #8.4.3    等级: 3    角色: V
 验证防御参数（ε 对 DP，噪声 σ，投影秩 k）在隐私 ≥ 99 % 的令牌保护和效用 ≤ 3 % 的精度损失之间达到平衡。
 #8.4.4    等级: 3    角色: D/V
 请验证在模型更新的发布门控中，是否包含对模型反演攻击的鲁棒性指标，并已定义回归预算。

---

### C8.5 作用域 强制 针对 用户特定 内存

跨租户泄漏仍然是 RAG 风险中的主要风险之一： 未正确过滤的相似性查询可能暴露另一位客户的私有文档。

 #8.5.1    等级: 1    角色: D/V
 请验证每个检索查询在传递给 LLM 提示之前，是否已按租户/用户 ID 进行事后过滤。
 #8.5.2    等级: 1    角色: D
 验证集合名称或带命名空间的ID是否按每个用户或租户进行加盐，以使跨作用域的向量不会发生碰撞。
 #8.5.3    等级: 2    角色: D/V
 验证在可配置的距离阈值之上但超出调用方的范围的相似性结果将被丢弃并触发安全警报。
 #8.5.4    等级: 2    角色: V
 验证多租户压力测试是否能够模拟对抗性查询，试图检索超出范围的文档，并证明零泄漏。
 #8.5.5    等级: 3    角色: D/V
 验证每个租户的加密密钥是否已分离，以确保即使物理存储被共享，也能实现密码学隔离。

---

### C8.6 高级内存系统安全

针对复杂内存架构的安全控制，包括事件记忆、语义记忆和工作记忆，并具备特定的隔离和验证要求。

 #8.6.1    等级: 1    角色: D/V
 验证不同的记忆类型（事件记忆、语义记忆、工作记忆）是否具备彼此隔离的安全上下文、基于角色的访问控制、独立的加密密钥，以及针对每种记忆类型的文档化访问模式。
 #8.6.2    等级: 2    角色: D/V
 验证记忆巩固过程是否包含安全性验证，以在存储之前通过内容净化、来源验证和完整性检查来防止恶意记忆的注入。
 #8.6.3    等级: 2    角色: D/V
 验证记忆检索查询是否已经过验证并净化，以防止通过查询模式分析、访问控制执行和结果过滤提取未授权信息。
 #8.6.4    等级: 3    角色: D/V
 验证内存擦除机制是否能够在具备密码学擦除保证的前提下安全删除敏感信息，方法包括使用密钥删除、多次覆盖，或带有验证证书的基于硬件的安全删除。
 #8.6.5    等级: 3    角色: D/V
 验证内存系统的完整性是否持续受到监控，以防止未经授权的修改或损坏，监控方式包括校验和、审计日志，以及在内存内容超出正常操作范围时触发的自动警报。

---

### 参考文献

Vector database security: Pinecone – IronCore Labs
Securing the Backbone of AI: Safeguarding Vector Databases and Embeddings – Privacera
Enhancing Data Security with RBAC of Qdrant Vector Database – AI Advances
Mitigating Privacy Risks in LLM Embeddings from Embedding Inversion – arXiv
DPPN: Detecting and Perturbing Privacy-Sensitive Neurons – OpenReview
Art. 17 GDPR – Right to Erasure
Sensitive Data in Text Embeddings Is Recoverable – Tonic.ai
PII Identification and Removal – NVIDIA NeMo Docs
De-identifying Sensitive Data – Google Cloud DLP
Remove PII from Conversations Using Sensitive Information Filters – AWS Bedrock Guardrails
Think Your RAG Is Secure? Think Again – Medium
Design a Secure Multitenant RAG Inferencing Solution – Microsoft Learn
Best Practices for Multi-Tenancy RAG with Milvus – Milvus Blog

## 9 自主编排与代理行动安全

### 控制目标

确保自治或多智能体 AI 系统仅能执行那些明确、经认证、可审计且在受限成本和风险阈值内的操作。这有助于防范以下威胁：自治系统妥协、工具滥用、智能体循环检测、通信劫持、身份伪造、群体操控以及意图操纵。

---

### 9.1 智能体任务规划与递归预算

对递归计划进行节流，并在特权操作时强制设立人工审查点。

 #9.1.1    等级: 1    角色: D/V
 验证最大递归深度、广度、实际用时、令牌以及每次代理执行的货币成本是否集中配置并受版本控制。
 #9.1.2    等级: 1    角色: D/V
 验证特权或不可逆操作（例如代码提交、资金转账）在执行前是否需要通过可审计的渠道获得明确的人类批准。
 #9.1.3    等级: 2    角色: D
 验证实时资源监控在任意预算阈值被超出时，是否会触发断路器中断，从而停止进一步的任务扩展。
 #9.1.4    等级: 2    角色: D/V
 验证断路器事件是否已被记录，包含代理ID、触发条件和捕获的计划状态，以供取证审查。
 #9.1.5    等级: 3    角色: V
 验证安全测试覆盖预算耗尽场景和失控计划场景，并确认在不丢失数据的前提下实现安全中止。
 #9.1.6    等级: 3    角色: D
 验证预算策略是否以策略即代码的形式表达，并在 CI/CD 中强制执行，以阻止配置漂移。

---

### 9.2 工具插件沙箱化

将工具交互隔离，以防止未授权的系统访问或代码执行。

 #9.2.1    等级: 1    角色: D/V
 验证每个工具/插件是否在操作系统级、容器级或 WASM 级沙箱中执行，并具备最小权限的文件系统、网络和系统调用策略。
 #9.2.2    等级: 1    角色: D/V
 验证沙箱资源配额（CPU、内存、磁盘、网络出站流量）以及执行超时是否被强制执行并被记录。
 #9.2.3    等级: 2    角色: D/V
 验证工具二进制文件或描述符是否已数字签名；在加载之前对签名进行验证。
 #9.2.4    等级: 2    角色: V
 验证沙箱遥测是否流向 SIEM；异常（例如，尝试的出站连接）会触发告警。
 #9.2.5    等级: 3    角色: V
 请确保高风险插件在生产部署之前经过安全评审和渗透测试。
 #9.2.6    等级: 3    角色: D/V
 请确保沙箱逃逸尝试会被自动阻止，且有问题的插件在调查期间被隔离。

---

### 9.3 自主循环与成本界限

检测并阻止失控的代理之间的递归以及成本暴涨。

 #9.3.1    等级: 1    角色: D/V
 验证 代理之间的调用 是否 包含 跳数限制（hop-limit）或 TTL，运行时 会 对其 递减 并 强制 执行。
 #9.3.2    等级: 2    角色: D
 验证智能体是否维护唯一的调用图 ID，以便检测自调用或循环模式。
 #9.3.3    等级: 2    角色: D/V
 验证对每个请求链是否跟踪累计的计算单元和消耗计数器；超过上限将中止该链。
 #9.3.4    等级: 3    角色: V
 验证形式化分析或模型检测是否证明了智能体协议中不存在无界递归。
 #9.3.5    等级: 3    角色: D
 验证循环中止事件是否会生成警报，并将数据用于持续改进的度量指标。

---

### 9.4 协议级滥用防护

在代理与外部系统之间建立安全通信通道，以防止劫持或篡改。

 #9.4.1    等级: 1    角色: D/V
 请验证所有 agent-to-tool 和 agent-to-agent 消息是否经过身份验证（例如，双向 TLS 或 JWT），并且是否已实现端到端加密。
 #9.4.2    等级: 1    角色: D
 请确保模式被严格验证；未知字段或格式错误的消息将被拒绝。
 #9.4.3    等级: 2    角色: D/V
 请确保完整性校验（MACs 或数字签名）覆盖整个消息有效载荷，包括工具参数。
 #9.4.4    等级: 2    角色: D
 验证在协议层是否实现了防重放（nonce 或时间戳窗口）。
 #9.4.5    等级: 3    角色: V
 验证协议实现是否经过模糊测试和静态分析，以发现注入或反序列化漏洞。

---

### 9.5 代理身份 & 篡改证据

确保行动可追溯且修改可检测。

 #9.5.1    等级: 1    角色: D/V
 验证每个代理实例是否具备唯一的密码学身份（密钥对或硬件-rooted凭证）。
 #9.5.2    等级: 2    角色: D/V
 验证所有代理操作均已签名并带有时间戳；日志应包含用于不可抵赖性的签名。
 #9.5.3    等级: 2    角色: V
 验证防篡改日志是否存储在追加写入介质或一次性写入介质上。
 #9.5.4    等级: 3    角色: D
 验证身份密钥是否按既定时间表轮换，以及在出现妥协迹象时轮换。
 #9.5.5    等级: 3    角色: D/V
 验证伪装攻击或密钥冲突尝试是否会触发对受影响代理的立即隔离。

---

### 9.6 多智能体蜂群风险降低

通过隔离和形式化安全建模来缓解集体行为风险。

 #9.6.1    等级: 1    角色: D/V
 验证在不同安全域中运行的代理是否在隔离的运行时沙箱或网络分段中执行。
 #9.6.2    等级: 3    角色: V
 在部署之前，确保对群体行为进行了建模并经过形式化验证，以确保其具备活性和安全性。
 #9.6.3    等级: 3    角色: D
 验证运行时监控是否能够检测到涌现的不安全模式（例如振荡、死锁），并启动纠正措施。

---

### 9.7 用户 & 工具 身份验证 / 授权

为每个代理触发的操作实现健壮的访问控制。

 #9.7.1    等级: 1    角色: D/V
 验证代理是否以一级主体身份对下游系统进行身份验证，并且从不重用终端用户凭据。
 #9.7.2    等级: 2    角色: D
 验证细粒度授权策略是否限制代理可以调用哪些工具，以及可以提供哪些参数。
 #9.7.3    等级: 2    角色: V
 验证权限检查在每次调用时都会重新评估（持续授权），而不仅在会话开始时。
 #9.7.4    等级: 3    角色: D
 验证委派权限是否会自动过期，并在超时或作用域变更后需要重新授权。

---

### 9.8 代理-代理之间的通信安全

对所有代理之间的消息进行加密并进行完整性保护，以防止窃听和篡改。

 #9.8.1    等级: 1    角色: D/V
 验证代理通道是否必须使用双向认证和具备完美前向保密性的加密（例如 TLS 1.3）。
 #9.8.2    等级: 1    角色: D
 在处理之前，确保消息的完整性和来源已被验证；若验证失败，将触发警报并丢弃该消息。
 #9.8.3    等级: 2    角色: D/V
 验证通信元数据（时间戳、序列号）是否被记录，以支持取证重建。
 #9.8.4    等级: 3    角色: V
 验证形式化验证或模型检查是否能够确认协议状态机不会被驱动进入不安全状态。

---

### 9.9 意图验证 与 约束执行

验证代理行动是否与用户所述的意图和系统约束一致。

 #9.9.1    等级: 1    角色: D
 验证执行前的约束求解器是否将拟议的行动与硬编码的安全与策略规则进行核对。
 #9.9.2    等级: 2    角色: D/V
 请确认高影响操作（金融相关、具备破坏性、隐私敏感）是否需要来自发起用户的明确意图确认。
 #9.9.3    等级: 2    角色: V
 验证后置条件以确保已完成的操作实现了预期效果且无副作用；若存在差异，则触发回滚。
 #9.9.4    等级: 3    角色: V
 验证形式化方法（例如模型检查、定理证明）或基于属性的测试是否能够证明智能体计划满足所有声明的约束。
 #9.9.5    等级: 3    角色: D
 验证意图不匹配或约束违规事件是否推动持续改进循环与威胁情报共享。

---

### 9.10 智能体 推理 策略 安全

安全地选择并执行包括 ReAct、Chain-of-Thought 和 Tree-of-Thoughts 在内的不同推理策略。

 #9.10.1    等级: 1    角色: D/V
 验证推理策略选择是否使用确定性标准（输入复杂度、任务类型、安全上下文），并且在相同安全上下文中，相同输入会产生相同的策略选择。
 #9.10.2    等级: 1    角色: D/V
 请验证每种推理策略（ReAct、Chain-of-Thought、Tree-of-Thoughts）是否具备专用的输入验证、输出净化，以及针对其认知方法的执行时间限制。
 #9.10.3    等级: 2    角色: D/V
 验证推理策略转换是否被完整记录，包含输入特征、选择标准取值和执行元数据，以便进行审计轨迹重建。
 #9.10.4    等级: 2    角色: D/V
 请验证树状推理是否包含在检测到策略违规、资源限制或安全边界时终止探索的分支剪枝机制。
 #9.10.5    等级: 2    角色: D/V
 验证 ReAct（Reason-Act-Observe）循环在每个阶段是否包含验证检查点：推理步骤验证、行动授权，以及在继续之前进行的观测净化。
 #9.10.6    等级: 3    角色: D/V
 验证推理策略的性能指标（执行时间、资源使用、输出质量）在偏离配置阈值时，是否通过自动化警报进行监控。
 #9.10.7    等级: 3    角色: D/V
 验证将多种策略结合在一起的混合推理方法在不绕过任何安全控制的前提下，是否能够保持所有组成策略的输入验证和输出约束。
 #9.10.8    等级: 3    角色: D/V
 验证推理策略的安全性测试是否包括对格式错误输入的模糊测试、旨在强制策略切换的对抗性提示，以及对每种认知方法的边界条件测试。

---

### 9.11 代理生命周期状态管理 与 安全

具备加密审计跟踪和明确定义的恢复程序的安全代理初始化、状态转换和终止。

 #9.11.1    等级: 1    角色: D/V
 验证代理初始化是否包含基于硬件的凭证进行的加密身份建立，以及包含代理 ID、时间戳、配置哈希值和初始化参数的不可变启动审计日志。
 #9.11.2    等级: 2    角色: D/V
 验证代理状态转换是否经过密码学签名、带有时间戳，并记录完整的上下文信息，包括触发事件、前一状态哈希、新状态哈希，以及所执行的安全性验证。
 #9.11.3    等级: 2    角色: D/V
 核实代理关停程序是否包括通过密码擦除或多次覆写进行的安全内存擦除、凭据吊销并通知证书颁发机构，以及生成防篡改的终止证书。
 #9.11.4    等级: 3    角色: D/V
 验证代理恢复机制是否通过使用加密校验和（至少为 SHA-256）来验证状态完整性，并在检测到损坏时回滚到已知良好状态，同时具备自动警报和人工审批要求。
 #9.11.5    等级: 3    角色: D/V
 验证代理持久化机制是否使用对每个代理的 AES-256 密钥对敏感状态数据进行加密，并在可配置的时间表上实现安全密钥轮换（最大 90 天），且实现零停机部署。

---

### 9.12 工具集成安全框架

针对动态工具加载、执行与结果验证的安全控制，包含已定义的风险评估与批准流程。

 #9.12.1    等级: 1    角色: D/V
 请验证工具描述符是否包含安全元数据，这些元数据应指定所需权限（读取/写入/执行）、风险等级（低/中/高）、资源限制（CPU、内存、网络），以及在工具清单中记录的验证要求。
 #9.12.2    等级: 1    角色: D/V
 在与超时限制和错误处理流程集成之前，请验证工具执行结果是否符合预期的模式（JSON Schema、XML Schema）及安全策略（输出净化、数据分类）。
 #9.12.3    等级: 2    角色: D/V
 验证工具交互日志是否包含详细的安全上下文信息，包括特权使用、数据访问模式、执行时间、资源消耗和返回码，并实现用于 SIEM 集成的结构化日志记录。
 #9.12.4    等级: 2    角色: D/V
 验证动态工具加载机制是否使用公钥基础设施验证数字签名，并实现具备沙箱隔离和执行前权限验证的安全加载协议。
 #9.12.5    等级: 3    角色: D/V
 验证新版本是否会自动触发工具安全评估，且包含静态分析、动态测试，以及安全团队评审等强制性审批环节，并提供已文档化的批准标准和 SLA 要求。

---

#### 参考文献

MITRE ATLAS tactics ML09
Circuit-breaker research for AI agents — Zou et al., 2024
Trend Micro analysis of sandbox escapes in AI agents — Park, 2025
Auth0 guidance on human-in-the-loop authorization for agents — Martinez, 2025
Medium deep-dive on MCP & A2A protocol hijacking — ForAISec, 2025
Rapid7 fundamentals on spoofing attack prevention — 2024
Imperial College verification of swarm systems — Lomuscio et al.
NIST AI Risk Management Framework 1.0, 2023
WIRED security briefing on encryption best practices, 2024
OWASP Top 10 for LLM Applications, 2025
Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS
[How Is LLM Reasoning Distracted by Irrelevant Context?
An Analysis Using a Controlled Benchmark](https://www.arxiv.org/pdf/2505.18761)
Large Language Model Sentinel: LLM Agent for Adversarial Purification
Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents

## 10 对抗鲁棒性 与 隐私防御

### 控制目标

确保 AI 模型在面对规避、推断、提取或中毒攻击时，仍然保持可靠，具备隐私保护能力并具备抗滥用能力。

---

### 10.1 模型对齐与安全

防范有害或违反政策的输出。

 #10.1.1    等级: 1    角色: D/V
 请验证对齐测试套件（红队提示、越狱探针、不允许的内容）是否已进行版本控制，并在每次模型发布时运行。
 #10.1.2    等级: 1    角色: D
 请验证拒绝和安全完成的护栏是否已生效。
 #10.1.3    等级: 2    角色: D/V
 验证自动评估器是否能够衡量有害内容的比率，并对超出设定阈值的回归进行标记。
 #10.1.4    等级: 2    角色: D
 验证对抗越狱训练是否有文档记录且可复现。
 #10.1.5    等级: 3    角色: V
 验证正式的政策合规证明或经认证的监控是否覆盖关键领域。

---

### 10.2 对抗性-示例 加固

提高对被操纵输入的鲁棒性。对抗性训练和基准评分是当前的最佳实践。

 #10.2.1    等级: 1    角色: D
 验证项目代码库中是否包含具有可复现随机种子的对抗训练配置。
 #10.2.2    等级: 2    角色: D/V
 验证对抗样本检测在生产管线中是否会触发阻断告警。
 #10.2.4    等级: 3    角色: V
 验证认证‑鲁棒性证明或区间界限证书至少覆盖最关键的前几类。
 #10.2.5    等级: 3    角色: V
 验证回归测试使用自适应攻击来确认没有可测量的鲁棒性损失。

---

### 10.3 成员推断缓解措施

限制判断某条记录是否出现在训练数据中的能力。 差分隐私和置信度分数屏蔽仍然是已知的最有效防御措施。

 #10.3.1    等级: 1    角色: D
 验证对每个查询的熵正则化或温度缩放是否能降低过度自信的预测。
 #10.3.2    等级: 2    角色: D
 验证 训练 是否 采用 ε-有界的 差分隐私优化 用于 敏感 数据集。
 #10.3.3    等级: 2    角色: V
 验证攻击仿真（影子模型或黑盒）在留出数据上的 AUC 值 ≤ 0.60。

---

### 10.4 模型-反演抵抗性

防止对私有属性的重建。最近的综述强调输出截断和差分隐私（DP）保证作为实际防御措施。

 #10.4.1    等级: 1    角色: D
 验证敏感属性从不直接输出；如有需要，请使用桶化或单向变换。
 #10.4.2    等级: 1    角色: D/V
 验证查询速率限制是否对来自同一主体的重复自适应查询进行限流。
 #10.4.3    等级: 2    角色: D
 请验证模型是否在使用隐私保护噪声进行训练。

---

### 10.5 模型提取防御

检测并遏制未授权的克隆。建议采用水印技术和查询模式分析。

 #10.5.1    等级: 1    角色: D
 验证推理网关是否对全局及按每个 API 密钥的速率限制进行了与模型记忆阈值相匹配的调优。
 #10.5.2    等级: 2    角色: D/V
 验证查询熵和输入多样性统计数据是否为自动化提取检测器提供输入。
 #10.5.3    等级: 2    角色: V
 验证脆性水印或概率性水印在对疑似克隆进行不超过 1 000 次查询时，其 p 值小于 0.01。
 #10.5.4    等级: 3    角色: D
 核实水印密钥和触发集是否存储在 hardware-security-module 中，并每年轮换。
 #10.5.5    等级: 3    角色: V
 验证提取警报事件是否包含违规查询，并与事件响应剧本集成。

---

### 10.6 推理-时间 污染-数据 检测

识别并中和带有后门的或被污染的输入。

 #10.6.1    等级: 1    角色: D
 在模型推理之前，验证输入是否经过异常检测器（例如 STRIP、一致性评分）。
 #10.6.2    等级: 1    角色: V
 验证探测器阈值在干净/被污染的验证集上进行调优，以实现小于 5% 的误报率。
 #10.6.3    等级: 2    角色: D
 验证被标记为污染的输入是否会触发软阻塞和人工审核流程。
 #10.6.4    等级: 2    角色: V
 验证检测器是否已针对自适应、无触发器的后门攻击进行压力测试。
 #10.6.5    等级: 3    角色: D
 验证检测有效性指标是否已被记录，并以最新的威胁情报定期重新评估。

---

### 10.7 动态安全策略自适应

基于威胁情报和行为分析的实时-安全策略更新。

 #10.7.1    等级: 1    角色: D/V
 验证安全策略是否可以在不重启代理的情况下动态更新，同时保持策略版本的完整性。
 #10.7.2    等级: 2    角色: D/V
 验证策略更新是否由授权的安全人员进行密码学签名，并在应用之前进行验证。
 #10.7.3    等级: 2    角色: D/V
 验证动态策略变更是否被完整记录在审计跟踪中，包括理由说明、批准链和回滚程序。
 #10.7.4    等级: 3    角色: D/V
 验证自适应安全机制是否根据风险上下文和行为模式调整威胁检测的灵敏度。
 #10.7.5    等级: 3    角色: D/V
 验证策略自适应决策是否可解释，并包含供安全团队审核的证据链。

---

### 10.8 基于反射的安全分析

通过智能体的自我反省与元认知分析进行安全验证。

 #10.8.1    等级: 1    角色: D/V
 验证智能体的反思机制是否包含以安全为重点的对决策和行动的自我评估。
 #10.8.2    等级: 2    角色: D/V
 验证反思输出是否经过验证，以防止对抗性输入对自我评估机制的操纵。
 #10.8.3    等级: 2    角色: D/V
 验证元认知安全分析是否能够在智能代理的推理过程中识别潜在的偏见、操纵或妥协。
 #10.8.4    等级: 3    角色: D/V
 验证基于反射的安全警告是否会触发增强监控和潜在的人为干预工作流。
 #10.8.5    等级: 3    角色: D/V
 验证从安全反思中进行的持续学习是否在提高威胁检测的同时不损害合法功能。

---

### 10.9 进化 与 自我提升 安全

具备自我修改与进化能力的智能体系统的安全控制。

 #10.9.1    等级: 1    角色: D/V
 验证自我修改能力仅限于指定的安全区域，并设有形式化验证边界。
 #10.9.2    等级: 2    角色: D/V
 在实施之前，确保演进提案经过安全影响评估。
 #10.9.3    等级: 2    角色: D/V
 验证自我改进机制是否包含带有完整性验证的回滚能力。
 #10.9.4    等级: 3    角色: D/V
 验证元学习的安全性是否能够防止对改进算法的对抗性操纵。
 #10.9.5    等级: 3    角色: D/V
 验证递归自我改进是否被形式化的安全约束所约束，并给出收敛性的数学证明。

---

#### 参考文献

MITRE ATLAS adversary tactics for ML
NIST AI Risk Management Framework 1.0, 2023
OWASP Top 10 for LLM Applications, 2025
Adversarial Training: A Survey — Zhao et al., 2024
RobustBench adversarial-robustness benchmark
Membership-Inference & Model-Inversion Risk Survey, 2025
PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023
Model-Inversion Attacks & Defenses Survey — AI Review, 2025
Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024
Fragile Model Watermarking Survey — 2025
Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025
BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024

## 11 隐私保护与个人数据管理

### 控制目标

在整个 AI 生命周期中保持严格的隐私保障—数据收集、训练、推理和事件响应—以确保个人数据仅在获得明确同意、最小必要范围、可证明的删除以及正式的隐私保障条件下被处理。

---

### 11.1 匿名化 与 数据最小化

 #11.1.1    等级: 1    角色: D/V
 验证直接标识符和准识别符是否已被移除并进行哈希处理。
 #11.1.2    等级: 2    角色: D/V
 验证自动审计是否衡量 k-匿名性/l-多样性，并在阈值低于策略规定时发出警报。
 #11.1.3    等级: 2    角色: V
 验证模型特征重要性报告，证明不存在超出 ε = 0.01 的互信息的标识符泄露。
 #11.1.4    等级: 3    角色: V
 验证形式证明或合成数据认证在连接攻击下也能显示再识别风险 ≤ 0.05。

---

### 11.2 被遗忘权 & 删除强制执行

 #11.2.1    等级: 1    角色: D/V
 验证 data-subject 删除请求是否在少于 30 天的服务水平协议内传播至原始数据集、检查点、嵌入、日志和备份。
 #11.2.2    等级: 2    角色: D
 验证以下内容：“machine-unlearning” 例程通过实际重新训练，或使用经过认证的遗忘算法来近似移除。
 #11.2.3    等级: 2    角色: V
 验证影子模型评估在完成去学习后证明被遗忘的记录对输出的影响小于1%
 #11.2.4    等级: 3    角色: V
 验证删除事件是否以不可变的方式记录，并可供监管机构审计。

---

### 11.3 差分-隐私保护措施

 #11.3.1    等级: 2    角色: D/V
 验证隐私损失计算仪表板在累计 ε 超过策略阈值时是否会发出警报。
 #11.3.2    等级: 2    角色: V
 验证黑盒-隐私审计的 ε̂ 是否在声明值的 10% 内。
 #11.3.3    等级: 3    角色: V
 验证形式化证明是否覆盖所有训练后微调和嵌入。

---

### 11.4 目的限定与范围蔓延保护

 #11.4.1    等级: 1    角色: D
 验证每个数据集和模型检查点是否携带与原始同意保持一致的机器可读用途标签。
 #11.4.2    等级: 1    角色: D/V
 验证运行时监控是否能够检测到与所声明目的不一致的查询，并触发软拒绝。
 #11.4.3    等级: 3    角色: D
 验证策略即代码的门控是否会在未进行 DPIA 审查的情况下阻止将模型重新部署到新领域。
 #11.4.4    等级: 3    角色: V
 验证形式化可追溯性证明，确保每个个人数据的生命周期保持在经同意的范围内。

---

### 11.5 同意管理与合法基础-跟踪

 #11.5.1    等级: 1    角色: D/V
 验证同意管理平台（CMP）是否为每个数据主体记录了同意状态、处理目的和保留期限。
 #11.5.2    等级: 2    角色: D
 验证 API 是否暴露同意令牌；模型在推断之前必须验证令牌的作用域。
 #11.5.3    等级: 2    角色: D/V
 验证被拒绝或撤回的同意是否会在24小时内中止处理流水线。

---

### 11.6 带有隐私控制的联邦学习

 #11.6.1    等级: 1    角色: D
 请验证客户端更新在聚合之前是否采用本地差分隐私噪声添加。
 #11.6.2    等级: 2    角色: D/V
 验证训练指标具有差分隐私保护，并且不会泄露单个客户端的损失。
 #11.6.3    等级: 2    角色: V
 请验证是否已启用对投毒攻击具有鲁棒性的聚合（例如 Krum/Trimmed-Mean）。
 #11.6.4    等级: 3    角色: V
 验证形式证明表明，在总体 ε 预算下，效用损失小于 5。

---

#### 参考文献

GDPR & AI Compliance Best Practices
EU Parliament Study on GDPR & AI, 2020
ISO 31700-1:2023 — Privacy by Design for Consumer Products
NIST Privacy Framework 1.1 (2025 Draft)
Machine Unlearning: Right-to-Be-Forgotten Techniques
A Survey of Machine Unlearning, 2024
Auditing DP-SGD — ArXiv 2024
DP-SGD Explained — PyTorch Blog
Purpose-Limitation for AI — IJLIT 2025
Data-Protection Considerations for AI — URM Consulting
Top Consent-Management Platforms, 2025
Secure Aggregation in DP Federated Learning — ArXiv 2024

## C12 监控、日志记录与异常检测

### 控制目标

本节提供关于对模型及其他人工智能组件所看到、所执行的操作及返回的结果的实时性与取证可视性的要求，以便检测威胁、分诊并从中学习。

### C12.1 请求与响应日志记录

 #12.1.1    等级: 1    角色: D/V
 请验证所有用户提示和模型响应是否已经被记录，并附带适当的元数据（例如时间戳、用户ID、会话ID、模型版本）。
 #12.1.2    等级: 1    角色: D/V
 验证日志是否存储在安全、受访问控制的存储库中，并具备适当的保留策略和备份程序。
 #12.1.3    等级: 1    角色: D/V
 验证日志存储系统是否在静态状态下对数据进行加密，以及在传输过程中对数据进行加密，以保护日志中包含的敏感信息。
 #12.1.4    等级: 1    角色: D/V
 验证在日志记录之前，提示和输出中的敏感数据是否已自动脱敏或屏蔽，并提供可配置的脱敏规则，适用于 PII、凭据和专有信息。
 #12.1.5    等级: 2    角色: D/V
 请验证政策决策和安全过滤操作是否被记录在日志中，以便对内容审核系统进行审计和调试。
 #12.1.6    等级: 2    角色: D/V
 验证日志完整性是否通过数字签名或只写存储来保护。

---

### C12.2 滥用检测与告警

 #12.2.1    等级: 1    角色: D/V
 验证系统是否能够检测并对已知的越狱模式、提示注入尝试和对抗性输入发出警报，采用基于签名的检测方法。
 #12.2.2    等级: 1    角色: D/V
 验证系统是否与现有的安全信息与事件管理（SIEM）平台进行集成，并使用标准日志格式和协议。
 #12.2.3    等级: 2    角色: D/V
 验证增强的安全事件是否包含与人工智能相关的上下文，例如模型标识符、置信度分数以及安全过滤器的决策。
 #12.2.4    等级: 2    角色: D/V
 验证行为异常检测是否能够识别异常对话模式、过度重试尝试或系统性探测行为。
 #12.2.5    等级: 2    角色: D/V
 验证实时告警机制在检测到潜在的策略违规或攻击企图时，是否会通知安全团队。
 #12.2.6    等级: 2    角色: D/V
 请验证是否已包含自定义规则，以检测针对人工智能的特定威胁模式，包括协调的越狱尝试、提示注入活动和模型提取攻击。
 #12.2.7    等级: 3    角色: D/V
 验证自动化的事件响应工作流程是否能够隔离被妥协的模型、阻止恶意用户，并升级关键安全事件。

---

### C12.3 模型漂移检测

 #12.3.1    等级: 1    角色: D/V
 验证系统是否能够在不同模型版本和时间段内跟踪基本性能指标，例如准确性、置信度分数、延迟和错误率。
 #12.3.2    等级: 2    角色: D/V
 验证在性能指标超过预定义的降级阈值或相对于基线显著偏离时，自动告警是否触发。
 #12.3.3    等级: 2    角色: D/V
 验证幻觉检测监测器在模型输出包含事实性错误、前后不一致或捏造信息时，能够识别并标记这些情况。

---

### C12.4 性能与行为遥测

 #12.4.1    等级: 1    角色: D/V
 验证包括请求延迟、token 消耗、内存使用和吞吐量在内的运维指标是否被持续收集和监控。
 #12.4.2    等级: 1    角色: D/V
 验证是否对成功率和失败率进行跟踪，并按错误类型及其根本原因进行分类。
 #12.4.3    等级: 2    角色: D/V
 验证资源利用监控是否包含 GPU/CPU 使用情况、内存消耗和存储需求，并对阈值突破进行告警。

---

### C12.5 人工智能事件响应计划与执行

 #12.5.1    等级: 1    角色: D/V
 确保事件响应计划专门覆盖与 AI 相关的安全事件，包括模型被入侵、数据投毒和对抗性攻击。
 #12.5.2    等级: 2    角色: D/V
 确保事件响应团队具备使用 AI 专用取证工具和相关专业知识，以调查模型行为和攻击向量。
 #12.5.3    等级: 3    角色: D/V
 验证事后分析是否包含模型重新训练的考量因素、安全过滤器更新，以及将经验教训整合到安全控制中。

---

### C12.5 人工智能 性能下降 检测

监控并检测 AI 模型性能与质量随时间的下降。

 #12.5.1    等级: 1    角色: D/V
 验证模型的准确率、精确度、召回率和 F1 分数是否持续监控，并与基线阈值进行比较。
 #12.5.2    等级: 1    角色: D/V
 验证数据漂移检测是否监控可能影响模型性能的输入分布变化。
 #12.5.3    等级: 2    角色: D/V
 验证概念漂移检测是否能够识别输入与期望输出之间关系的变化。
 #12.5.4    等级: 2    角色: D/V
 验证性能下降是否会触发自动告警并启动模型重新训练或替换工作流。
 #12.5.5    等级: 3    角色: V
 验证性能下降根因分析是否将性能下降与数据变更、基础设施问题或外部因素相关联。

---

### C12.6 有向无环图可视化 & 工作流安全

保护工作流可视化系统免受信息泄露和篡改攻击。

 #12.6.1    等级: 1    角色: D/V
 请确认对 DAG 可视化数据已进行清洗，以在存储或传输之前移除敏感信息。
 #12.6.2    等级: 1    角色: D/V
 请确认工作流可视化访问控制是否仅允许已授权的用户查看智能体的决策路径和推理轨迹。
 #12.6.3    等级: 2    角色: D/V
 验证 DAG 数据的完整性是否通过数字签名和防篡改存储机制得到保护。
 #12.6.4    等级: 2    角色: D/V
 验证工作流可视化系统是否实现输入验证，以防止通过精心构造的节点数据或边数据进行的注入攻击。
 #12.6.5    等级: 3    角色: D/V
 验证实时 DAG（有向无环图）更新是否限流并经过校验，以防止对可视化系统的拒绝服务攻击。

---

### C12.7 主动安全行为监控

通过对代理行为的主动分析实现对安全威胁的检测与防护。

 #12.7.1    等级: 1    角色: D/V
 在执行之前，对主动代理行为进行安全性验证，并与风险评估集成。
 #12.7.2    等级: 2    角色: D/V
 请验证自主行动的触发条件是否包括安全上下文评估和威胁态势评估。
 #12.7.3    等级: 2    角色: D/V
 验证主动行为模式是否已被分析，以评估潜在的安全影响和意外后果。
 #12.7.4    等级: 3    角色: D/V
 请验证对安全至关重要的主动措施是否需要明确的审批链并具备审计日志。
 #12.7.5    等级: 3    角色: D/V
 验证行为异常检测是否能够识别主动代理模式中的偏离，这些偏离可能表示被妥协。

---

### 参考文献

NIST AI Risk Management Framework 1.0 - Manage 4.1 and 4.3
ISO/IEC 42001:2023 — AI Management Systems Requirements - Annex B 6.2.6
EU AI Act — Article 12, 13, 16 and 19 on Logging and Record-keeping

## C13 人工监督、问责与治理

### 控制目标

本章提供在人工智能系统中维持人类监督与明确的问责链的要求，确保在整个人工智能生命周期内实现可解释性、透明度和伦理治理。

---

### C13.1 紧急停止开关与覆盖机制

在检测到 AI 系统存在不安全行为时，提供关机或回滚的路径。

 #13.1.1    等级: 1    角色: D/V
 验证是否存在手动紧急停止开关机制，以便立即中止 AI 模型的推理和输出。
 #13.1.2    等级: 1    角色: D
 验证覆写控制是否仅对经授权人员开放。
 #13.1.3    等级: 3    角色: D/V
 验证回滚过程能否回退到先前的模型版本或安全模式下的运行状态。
 #13.1.4    等级: 3    角色: V
 请确保覆盖机制经过定期测试。

---

### C13.2 人类-在-环 决策检查点

当风险水平超过预设阈值时，需要人工批准。

 #13.2.1    等级: 1    角色: D/V
 验证高风险的人工智能决策在执行之前需要获得明确的人类批准。
 #13.2.2    等级: 1    角色: D
 验证风险阈值是否被明确定义，并自动触发人工审核工作流。
 #13.2.3    等级: 2    角色: D
 核实在时效性决策中，当无法在规定的时间框架内获得人工批准时，是否存在回退机制。
 #13.2.4    等级: 3    角色: D/V
 验证升级程序是否为不同的决策类型或风险类别定义了清晰的授权级别（如适用）。

---

### C13.3 职责链与可审计性

记录操作员的操作和模型决策。

 #13.3.1    等级: 1    角色: D/V
 请验证所有 AI 系统决策和人工干预是否被记录，且记录包含时间戳、用户身份和决策依据。
 #13.3.2    等级: 2    角色: D
 验证审计日志不可被篡改，并包含完整性校验机制。

---

### C13.4 可解释-AI 技术

表面特征重要性、反事实以及局部解释。

 #13.4.1    等级: 1    角色: D/V
 验证人工智能系统是否能够以人类可读的格式为其决策提供基本解释。
 #13.4.2    等级: 2    角色: V
 验证解释质量是否已通过人工评估研究和指标进行验证。
 #13.4.3    等级: 3    角色: D/V
 请确认在关键决策中，特征重要性分数或归因方法（如 SHAP、LIME 等）是否可用。
 #13.4.4    等级: 3    角色: V
 验证反事实解释是否展示了输入如何被修改以改变结果（如适用于该用例和领域）。

---

### C13.5 模型卡与使用披露

为预期用途、性能指标和伦理考量维护模型卡。

 #13.5.1    等级: 1    角色: D
 确保模型卡记录了预期的使用场景、局限性以及已知的失效模式。
 #13.5.2    等级: 1    角色: D/V
 核实在不同适用场景中的性能指标是否已披露。
 #13.5.3    等级: 2    角色: D
 确保伦理考量、偏见评估、公平性评估、训练数据特征以及已知的训练数据局限性被记录并定期更新。
 #13.5.4    等级: 2    角色: D/V
 验证模型卡在整个模型生命周期内是否实现版本控制并得到维护，并具备变更跟踪。

---

### C13.6 不确定性量化

在回答中传递置信度分数或熵测量。

 #13.6.1    等级: 1    角色: D
 验证 AI 系统 在 输出 中 是否 提供 置信度 分数 或 不确定性 度量。
 #13.6.2    等级: 2    角色: D/V
 验证不确定性阈值是否会触发额外的人工审核或替代决策路径。
 #13.6.3    等级: 2    角色: V
 验证不确定性量化方法是否已针对地面真值数据进行校准和验证。
 #13.6.4    等级: 3    角色: D/V
 验证在多步人工智能工作流中是否保持了不确定性传播。

---

### C13.7 面向用户的透明度报告

就事件、漂移和数据使用情况进行定期披露。

 #13.7.1    等级: 1    角色: D/V
 核实数据使用政策和用户同意管理做法是否已向利益相关者清晰传达。
 #13.7.2    等级: 2    角色: D/V
 确保 AI 影响评估已进行，并将结果纳入报告中。
 #13.7.3    等级: 2    角色: D/V
 核实定期发布的透明度报告是否在合理细节范围内披露人工智能事件和运营指标。

#### 参考文献

EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
ISO/IEC 42001:2023 — AI Management Systems Requirements
NIST AI Risk Management Framework 1.0
NIST SP 800-53 Revision 5 — Security and Privacy Controls
A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)
Model Cards for Model Reporting (Mitchell et al., 2018)
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)
ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods
IEEE 7001-2021 — Transparency of Autonomous Systems
GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)
Human Oversight under Article 14 of the EU AI Act (Fink, 2025)

## 附录 A：术语表

This 全面的术语表提供了在 AISVS 中使用的关键 AI、ML 和安全术语的定义，以确保清晰度和共同理解。

对抗样本：一种经过精心设计的输入，旨在使人工智能模型犯错，通常通过添加人眼几乎察觉不到的微小扰动来实现。
​
对抗鲁棒性——在人工智能领域，对抗鲁棒性指的是模型在保持性能的同时，抵御被故意设计的恶意输入所迷惑或操控的能力，这些输入旨在导致错误。
​
智能体 – AI代理是一类使用 AI 的软件系统，用于代表用户追求目标并完成任务。它们具备推理、规划和记忆能力，并具有一定程度的自治性，能够做出决策、学习和适应。
​
具代理性的 AI：能够在一定程度上自主运作以实现目标的 AI 系统，通常在没有直接人类干预的情况下做出决策并采取行动。
​
基于属性的访问控制（ABAC）：一种访问控制范式，其授权决策基于用户、资源、操作和环境的属性，在查询时进行评估。
​
后门攻击：一种数据投毒攻击类型，其中模型在遇到某些触发器时被训练以特定方式响应，而在其他情况下保持正常行为。
​
偏见：在人工智能模型输出中的系统性错误，可能在特定群体或特定情境下导致不公平或带有歧视性的结果。
​
偏见利用：一种利用 AI 模型已知偏见来操纵输出或结果的攻击技术。
​
Cedar: 亚马逊的策略语言与引擎，用于在 AI 系统中实现基于属性的访问控制（ABAC）的细粒度权限。
​
思维链：一种通过在给出最终答案之前生成中间推理步骤来提高语言模型推理能力的技术。
​
断路器：在特定风险阈值超过时，自动暂停人工智能系统运行的机制。
​
数据泄露：通过 AI 模型的输出或行为对敏感信息的无意暴露。
​
数据投毒：故意篡改训练数据以破坏模型的完整性，通常用于安装后门或降低性能。
​
差分隐私 – 差分隐私是一种在数学上严格的框架，用于在发布数据集的统计信息时保护个体数据主体的隐私。它使数据持有者能够在分享群体的聚合模式的同时，限制关于特定个人泄露的信息。
​
嵌入：对数据（文本、图像等）的稠密向量表示，在高维空间中捕捉语义含义。
​
可解释性 – 人工智能中的可解释性是指一个人工智能系统能够提供人类可理解的理由来解释其决策和预测，并揭示其内部工作原理。
​
可解释的人工智能（XAI）：通过各种技术和框架，使 AI 系统能够为其决策和行为提供人类可理解的解释。
​
联邦学习：一种机器学习方法，在多台去中心化设备上对模型进行训练，这些设备各自持有本地数据样本，而不直接交换数据。
​
防护栏：为防止 AI 系统产生有害、带偏见或其他不良输出而实施的约束。
​
幻觉 – AI 幻觉指的是一种现象：AI 模型生成的信息并非基于其训练数据或客观现实，且可能是错误的或具有误导性的。
​
Human-in-the-Loop (HITL): 设计成在关键决策点需要人类监督、验证或干预的系统。
​
基础设施即代码（IaC）：通过代码对基础设施进行管理和配置，而非手动流程，从而实现安全扫描和一致的部署。
​
越狱：用于绕过人工智能系统中的安全护栏的技术，尤其是在大型语言模型中，以生成被禁止的内容。
​
最小权限原则：指仅向用户和进程授予完成任务所需的最小访问权限的安全原则。
​
LIME（Local Interpretable Model-agnostic Explanations）：一种通过在局部使用一个可解释的模型来近似任意机器学习分类器的预测并解释这些预测的技术。
​
成员推断攻击：一种旨在确定某一特定数据点是否被用于训练机器学习模型的攻击。
​
MITRE ATLAS： 面向人工智能系统的对抗性威胁态势； 一个关于针对人工智能系统的对抗性战术和技术的知识库。
​
模型卡 – 模型卡是一份关于人工智能模型的性能、局限性、预期用途以及伦理考量的标准化信息的文档，旨在促进透明度和负责任的人工智能发展。
​
模型提取攻击：一种攻击方式，攻击者通过反复查询目标模型，在未获授权的情况下创建一个功能上相似的副本。
​
模型反演：一种试图通过分析模型输出来重建训练数据的攻击。
​
模型生命周期管理 – AI 模型生命周期管理 是对 AI 模型存在的各个阶段进行监管的过程，包括其设计、开发、部署、监控、维护，以及最终的退役，以确保它保持有效并与目标保持一致。
​
模型中毒攻击：在训练过程中直接将漏洞或后门引入模型。
​
模型窃取/盗用：通过反复查询提取专有模型的副本或近似模型。
​
多智能体系统：由多个相互作用的智能体组成的系统，每个智能体可能具有不同的能力和目标。
​
OPA（Open Policy Agent）：一个开源的策略引擎，能够在整个技术栈中实现统一的策略执行。
​
隐私保护的机器学习（PPML）：在保护训练数据隐私的同时，用于训练和部署机器学习模型的技术与方法。
​
提示注入攻击：一种通过在输入中嵌入恶意指令来使模型偏离其预期行为的攻击。
​
RAG（检索增强生成）: 一种通过在生成响应之前从外部知识源检索相关信息来提升大型语言模型的技术。
​
红队演练：通过模拟对抗性攻击来主动测试 AI 系统以识别漏洞的做法。
​
SBOM（软件物料清单）：一种正式记录，包含用于构建软件或人工智能模型的各种组件的详细信息及其供应链关系。
​
SHAP（SHapley Additive exPlanations）：一种博弈论方法，用于通过计算每个特征对预测结果的贡献来解释任意机器学习模型的输出。
​
供应链攻击：通过攻击供应链中安全性较低的环节来妥协系统，例如第三方库、数据集或预训练模型。
​
迁移学习：一种技术，在一个任务上开发的模型被重新用作另一个任务的起点。
​
向量数据库：一种专门设计用于存储高维向量（嵌入向量）并执行高效相似性搜索的数据库。
​
漏洞扫描：用于识别软件组件中已知安全漏洞的自动化工具，包括 AI 框架及其依赖项。
​
水印技术：在 AI 生成的内容中嵌入不可察觉的标记，以追踪其来源或检测是否由 AI 生成。
​
零日漏洞：在开发者创建并部署补丁之前，攻击者可以利用的此前未知的漏洞。

## 附录 B：参考文献

### TODO

## 附录 C: 人工智能 安全治理与文档

### 目标

本附录提供基础性要求，旨在建立组织结构、政策与流程，以在整个系统生命周期内治理人工智能安全。

---

### AC.1 人工智能 风险 管理 框架 采用

提供一个正式框架，用于在整个系统生命周期中识别、评估和降低 AI‑相关的风险。

 #AC.1.1    等级: 1    角色: D/V
 核实 AI‑专用的风险评估方法是否已文档化并实施。
 #AC.1.2    等级: 2    角色: D
 确保在 AI 生命周期的关键节点以及在重大变更之前进行风险评估。
 #AC.1.3    等级: 3    角色: D/V
 验证风险管理框架是否与公认的标准保持一致（例如 NIST AI RMF）。

---

### AC.2 人工智能安全政策与程序

为安全的人工智能开发、部署和运行制定并执行组织标准。

 #AC.2.1    等级: 1    角色: D/V
 核实是否存在已记录的 AI 安全策略。
 #AC.2.2    等级: 2    角色: D
 请核实：政策是否至少每年审查并更新一次，以及在重大威胁-态势变化后进行更新。
 #AC.2.3    等级: 3    角色: D/V
 验证政策是否覆盖所有 AISVS 类别及适用的监管要求。

---

### AC.3 AI 安全的角色与职责

在整个组织中建立对人工智能安全的明确问责制。

 #AC.3.1    等级: 1    角色: D/V
 验证人工智能安全角色与职责是否已记录。
 #AC.3.2    等级: 2    角色: D
 核实负责人员是否具备适当的安全专业知识。
 #AC.3.3    等级: 3    角色: D/V
 请验证是否已为高‑风险人工智能系统建立人工智能伦理委员会或治理委员会。

---

### AC.4 伦理人工智能指南的执行

确保人工智能系统按照既定伦理原则运行。

 #AC.4.1    等级: 1    角色: D/V
 核实是否存在用于人工智能开发与部署的伦理准则。
 #AC.4.2    等级: 2    角色: D
 确保已建立用于检测和报告伦理违规行为的机制。
 #AC.4.3    等级: 3    角色: D/V
 确保对已部署的人工智能系统进行定期伦理审查。

---

### AC.5 人工智能监管合规监测

持续关注并遵守不断变化的人工智能监管规定。

 #AC.5.1    等级: 1    角色: D/V
 核实是否存在用于识别适用人工智能法规的流程。
 #AC.5.2    等级: 2    角色: D
 验证是否已对所有监管要求进行合规评估。
 #AC.5.3    等级: 3    角色: D/V
 验证监管变更是否会促使 AI 系统进行及时的审查和更新。

### AC.6 训练数据治理、文档与流程

 #1.1.2    等级: 1    角色: D/V
 仅允许经过质量、代表性、伦理来源与许可合规性审核的数据集，从而降低数据投毒、嵌入式偏见和知识产权侵权的风险。
 #1.1.5    等级: 2    角色: D/V
 通过评审者的交叉核对或达成共识来确保标注质量。
 #1.1.6    等级: 2    角色: D/V
 请核实对于重要的训练数据集，是否已经建立并维护了“data cards”或“datasheets for datasets”，并详细描述特征、动机、组成、收集过程、预处理，以及推荐/不推荐的使用。
 #1.3.2    等级: 2    角色: D/V
 验证已识别的偏见是否通过已记录的策略得到缓解，例如再平衡、有针对性的数据增强、算法调整（例如预处理、处理中、后处理技术）或重新加权，并评估缓解对公平性和整体模型性能的影响。
 #1.3.3    等级: 2    角色: D/V
 确保对训练后的公平性指标进行评估并记录。
 #1.3.4    等级: 3    角色: D/V
 验证生命周期偏差管理策略是否已分配所有者和审查节奏。
 #1.4.1    等级: 2    角色: D/V
 验证通过清晰的准则、评审者交叉核对、共识机制（例如监测评注者之间的一致性）以及解决分歧的已定义流程来确保标注/注释质量。
 #1.4.4    等级: 3    角色: D/V
 验证对安全性、安保或公平至关重要的标签（例如识别有害内容、关键医学发现）是否获得强制性的独立双重审核或等效的稳健验证。
 #1.4.6    等级: 2    角色: D/V
 验证标注指南和说明是否全面、具备版本控制，并经过同行评审。
 #1.4.6    等级: 2    角色: D/V
 请验证标签的数据模式是否已清晰定义，并且已进行版本控制。
 #1.3.1    等级: 1    角色: D/V
 验证数据集是否对代表性不平衡和潜在偏见进行评估，覆盖受法律保护的属性（例如种族、性别、年龄）以及与模型应用领域相关的其他伦理敏感特征（例如社会经济地位、地理位置）。
 #1.5.3    等级: 2    角色: V
 验证由领域专家进行的手动抽样检查覆盖一个统计上显著的样本量（例如 ≥1% 或 1,000 个样本，以较大者为准，或按风险评估确定），以识别自动化未能发现的微妙质量问题。
 #1.8.4    等级: 2    角色: D/V
 核实外包或众包的标注工作流程是否包含技术/程序性保障措施，以确保数据机密性、完整性、标签质量，并防止数据泄漏。
 #1.5.4    等级: 2    角色: D/V
 验证是否已将缓解步骤附加到溯源记录中。
 #1.6.2    等级: 2    角色: D/V
 核实标记的样本在训练前会触发人工审核。
 #1.6.3    等级: 2    角色: V
 验证结果是否被纳入模型的安全档案，并为持续的威胁情报提供信息。
 #1.6.4    等级: 3    角色: D/V
 验证检测逻辑是否已用新的威胁情报刷新。
 #1.6.5    等级: 3    角色: D/V
 验证在线学习流水线是否监控分布漂移。
 #1.7.1    等级: 1    角色: D/V
 验证训练数据删除工作流是否能彻底清除原始数据和派生数据，并评估对模型的影响；如有必要，对受影响的模型进行重新训练或重新校准以解决该影响。
 #1.7.2    等级: 2    角色: D
 核实是否已建立机制以跟踪并尊重用于训练的数据的用户同意范围和状态（包括撤回），并确保在将数据纳入新的训练过程或重大模型更新之前对同意进行验证。
 #1.7.3    等级: 2    角色: V
 核实工作流每年进行测试并被记录。
 #1.8.1    等级: 2    角色: D/V
 请确保第三方数据供应商（包括提供预训练模型和外部数据集的供应商）在其数据或模型被整合之前，已进行安全性、隐私、伦理采购和数据质量的尽职调查。
 #1.8.2    等级: 1    角色: D
 验证外部传输是否使用 TLS/认证与完整性校验。
 #1.8.3    等级: 2    角色: D/V
 在将其用于敏感应用之前，请确保对高风险数据源（例如来源不明的开源数据集、未经审核的供应商）进行加强审查，例如进行沙箱分析、广泛的质量与偏见检查，以及有针对性的投毒检测。
 #1.8.4    等级: 3    角色: D/V
 验证来自第三方的预训练模型在微调或部署之前，是否对嵌入式偏见、潜在后门、架构的完整性，以及原始训练数据来源进行评估。
 #1.5.3    等级: 2    角色: D/V
 请验证在使用对抗性训练时，对抗性数据集的生成、管理和版本控制应有文档记录并受控。
 #1.5.3    等级: 3    角色: D/V
 验证对抗鲁棒性训练对模型性能（在干净输入和对抗性输入两种情况下）以及公平性指标的影响是否得到评估、记录并监控。
 #1.5.4    等级: 3    角色: D/V
 确保对抗性训练与鲁棒性的策略得到定期审查并更新，以应对日益演变的对抗性攻击技术。
 #1.4.2    等级: 2    角色: D/V
 验证失败的数据集是否已被隔离并具备审计跟踪。
 #1.4.3    等级: 2    角色: D/V
 验证质量门控是否会阻止质量较差的数据集，除非已批准的例外。
 #1.11.2    等级: 2    角色: D/V
 验证生成过程、参数以及对合成数据的预期用途是否已被记录。
 #1.11.3    等级: 2    角色: D/V
 请在用于训练之前核实合成数据是否已就偏见、隐私泄露和表征问题进行了风险评估。
 #1.12.3    等级: 2    角色: D/V
 请验证是否为可疑访问事件生成告警并及时进行调查。
 #1.13.1    等级: 1    角色: D/V
 确保所有训练数据集都定义了显式的保留期限。
 #1.13.2    等级: 2    角色: D/V
 验证数据集在其生命周期结束时，是否会自动到期、被删除，或被审核以决定是否删除。
 #1.13.3    等级: 2    角色: D/V
 验证数据的保留和删除操作是否已被记录，并且可审计。
 #1.14.1    等级: 2    角色: D/V
 核实所有数据集的数据驻留和跨境传输要求是否已被识别并执行。
 #1.14.2    等级: 2    角色: D/V
 核实在数据处理过程中是否已识别并落实行业特定法规（例如医疗保健、金融等）。
 #1.14.3    等级: 2    角色: D/V
 核实对相关隐私法（例如 GDPR、CCPA）的合规性是否已文档化并定期审查。
 #1.16.1    等级: 2    角色: D/V
 确认存在能够响应数据主体关于访问、更正、限制或异议的请求的机制。
 #1.16.2    等级: 2    角色: D/V
 核实请求是否在法定时限内被记录、跟踪并完成。
 #1.16.3    等级: 2    角色: D/V
 请核实数据主体权利相关流程是否已定期进行测试和评审，以确保其有效性。
 #1.17.1    等级: 2    角色: D/V
 请确保在更新或替换数据集版本之前进行影响分析，涵盖模型性能、公平性和合规性。
 #1.17.2    等级: 2    角色: D/V
 核实影响分析的结果是否已被相关利益相关者记录并审核。
 #1.17.3    等级: 2    角色: D/V
 核实是否存在回滚计划，以防新版本引入不可接受的风险或回归。
 #1.18.1    等级: 2    角色: D/V
 请核实参与数据标注的所有人员均已完成背景调查并接受数据安全与隐私培训。
 #1.18.2    等级: 2    角色: D/V
 核实所有标注人员是否已签署保密协议和不披露协议。
 #1.18.3    等级: 2    角色: D/V
 验证标注平台是否强制执行访问控制并监控内部威胁。

#### 参考文献

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
EU Artificial Intelligence Act — Regulation (EU) 2024/1689
ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods

## 附录 D： AI辅助的安全编码治理与验证

### 目标

本章定义了在软件开发过程中安全且高效使用 AI 辅助编码工具所需的基线组织控制，确保在整个软件开发生命周期（SDLC）中实现安全性与可追溯性。

---

### AD.1 AI-辅助 安全‑编码 工作流程

在不削弱现有安全审查点的前提下，将人工智能工具整合到本组织的安全‑软件‑开发生命周期（SSDLC）中。

 #AD.1.1    等级: 1    角色: D/V
 验证文档化的工作流程是否描述了 AI 工具在何时以及如何生成、重构或审查代码。
 #AD.1.2    等级: 2    角色: D
 验证工作流是否映射到每个SSDLC阶段（设计、实现、代码审查、测试、部署）。
 #AD.1.3    等级: 3    角色: D/V
 验证是否在 AI‑生成的代码上收集度量指标（例如漏洞密度、mean‑time‑to‑detect），并将其与仅由人类产生的基线进行比较。

---

### AD.2 AI 工具资格与威胁建模

在采用之前，确保对 AI 编程工具进行安全能力、风险和供应‑链影响方面的评估。

 #AD.2.1    等级: 1    角色: D/V
 验证每个AI工具的威胁模型是否能够识别滥用、模型‑反演、数据泄露和依赖链风险。
 #AD.2.2    等级: 2    角色: D
 请确认工具评估包括对任何本地组件的静态/动态分析，以及对 SaaS 端点的评估（TLS、身份验证/授权、日志记录）。
 #AD.2.3    等级: 3    角色: D/V
 验证评估是否遵循公认的框架，并在重大版本变更后重新执行 re‑performed。

---

### AD.3 安全提示与上下文管理

在为 AI 模型构建提示或上下文时，防止机密信息、专有代码和个人数据泄露。

 #AD.3.1    等级: 1    角色: D/V
 核实书面指引是否禁止在提示中发送机密信息、凭据或机密数据。
 #AD.3.2    等级: 2    角色: D
 验证技术控制（客户端脱敏、经批准的上下文过滤器）是否能自动去除敏感痕迹。
 #AD.3.3    等级: 3    角色: D/V
 请验证提示和响应是否已进行令牌化，在传输过程中和静态存储时是否已加密，以及保留期限是否符合数据‑分类政策。

---

### AD.4 AI‑生成的 代码 的 验证

在代码合并或部署之前，检测并修复由 AI 输出引入的漏洞。

 #AD.4.1    等级: 1    角色: D/V
 确保 AI‑生成的代码始终经过人工代码审查。
 #AD.4.2    等级: 2    角色: D
 验证在每个包含 AI‑生成的代码的拉取请求上，自动化扫描工具（SAST/IAST/DAST）是否运行，并在关键发现时阻止合并。
 #AD.4.3    等级: 3    角色: D/V
 验证差分模糊测试或基于属性‑的测试是否能证明安全‑关键行为（例如输入验证、授权逻辑）。

---

### AD.5 代码建议的可解释性与可追溯性

向审计人员和开发人员提供洞察，以了解为什么提出该建议，以及它是如何演变的。

 #AD.5.1    等级: 1    角色: D/V
 验证提示/响应对是否已记录并附有提交ID。
 #AD.5.2    等级: 2    角色: D
 验证开发者是否能够公开用于支持某个建议的模型引文（训练片段、文档）。
 #AD.5.3    等级: 3    角色: D/V
 验证可解释性报告是否与设计工件一同存放，并在安全评审中被引用，符合 ISO/IEC 42001 的可追溯性原则。

---

### AD.6 持续反馈与模型微调

随着时间的推移，提升模型的安全性能，同时防止负向漂移。

 #AD.6.1    等级: 1    角色: D/V
 验证开发人员是否能够标记不安全或不合规的建议，并对这些标记进行跟踪。
 #AD.6.2    等级: 2    角色: D
 验证聚合反馈是否用于定期微‑调或检索‑增强生成，并使用经过审核的安全‑编码语料库（例如 OWASP 速查表）。
 #AD.6.3    等级: 3    角色: D/V
 确保闭环评估框架在每次 fine‑tune 之后执行回归测试； 在部署之前，安全指标必须达到或超过先前的基线。

---

#### 参考文献

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
OWASP Secure Coding Practices — Quick Reference Guide

## 附录 E: 示例工具和框架

### 目标

本章提供用于实现或满足特定 AISVS 要求的工具和框架示例。这些不得被视为 AISVS 团队或 OWASP GenAI 安全项目的建议或背书。

---

### AE.1 训练数据治理与偏见管理

用于数据分析、治理和偏差管理的工具。

 #AE.1.1    章节: 1.1
 数据清单管理工具：类似的数据清单管理工具，如...
 #AE.1.2    章节: 1.2
 传输中的加密 使用 TLS 来保护基于 HTTPS 的应用程序，工具包括 OpenSSL 和 Python 的`ssl` 库。

---

### AE.2 用户输入验证

用于处理和验证用户输入的工具链

 #AE.2.1    章节: 2.1
 提示注入防御工具：使用像 NVIDIA 的 NeMo 或 Guardrails AI 这样的护栏工具。

---

