# נספח א: מילון מונחים

מונחים מקיפים אלה מספקים הגדרות למונחים מרכזיים בתחום ה-AI, ML והאבטחה המשמשים לאורך כל AISVS כדי להבטיח בהירות והבנה משותפת.

* דוגמה עוינת: קלט שנוצר במכוון כדי לגרום למודל בינה מלאכותית לטעות, לעיתים על ידי הוספת שינויים עדינים שלא ניתנים לתפיסה על ידי בני אדם.
  ​
* קשיחות נגדית – קשיחות נגדית בבינה מלאכותית מתייחסת ליכולת של מודל לשמור על ביצועיו ולהתנגד להטעיה או למניפולציה באמצעות קלטים זדוניים ומתוכננים במכוון לגרום לשגיאות.
  ​
* סוכן – סוכני AI הם מערכות תוכנה שמשתמשות ב-AI כדי להשיג מטרות ולבצע משימות בשם המשתמשים. הם מפגינים יכולות חשיבה, תכנון וזיכרון ויש להם רמה של אוטונומיה לקבלת החלטות, למידה והסתגלות.
  ​
* AI סוכני: מערכות בינה מלאכותית היכולות לפעול במידת אוטונומיה מסוימת כדי להשיג מטרות, לעיתים מקבלות החלטות ונוקטות פעולות ללא התערבות אנושית ישירה.
  ​
* בקרת גישה מבוססת תכונות (ABAC): פרדיגמת בקרת גישה שבה החלטות הרשאה מבוססות על תכונות של המשתמש, המשאב, הפעולה והסביבה, המוערכות בזמן השאילתה.
  ​
* מתקפת דלת אחורית: סוג של מתקפת הרעלת נתונים שבה המודל מאומן להגיב בצורה מסוימת לגירויים מסוימים בעוד שהוא מתנהג בצורה רגילה אחרת.
  ​
* הטיה: שגיאות שיטתיות בתוצאות של מודלים של בינה מלאכותית שיכולות להוביל לתוצאות לא הוגנות או מפלות עבור קבוצות מסוימות או בהקשרים ספציפיים.
  ​
* ניצול הטיה: טכניקת התקפה הנצלנית הטיות ידועות במודלים של AI כדי למניפול פלטים או תוצאות.
  ​
* Cedar: שפת המדיניות והמנוע של אמזון להרשאות מדויקות המשמשים ליישום ABAC במערכות בינה מלאכותית.
  ​
* שרשרת מחשבה: טכניקה לשיפור ההסקה במודלים לשוניים על ידי יצירת שלבי הסקה ביניים לפני הפקת התשובה הסופית.
  ​
* מפסקי מעגל: מנגנונים שמפסיקים אוטומטית את פעולות מערכת ה-AI כאשר נחרגים ספי סיכון מסוימים.
  ​
* דליפת מידע: חשיפה בלתי מכוונת של מידע רגיש דרך פלטי מודל בינה מלאכותית או התנהגותו.
  ​
* רעלת נתונים: שיבוש מכוון של נתוני האימון במטרה לפגוע בשלמות המודל, לעיתים להתקנת דלתות אחוריות או להורדת הביצועים.
  ​
* פרטיות דיפרנציאלית – פרטיות דיפרנציאלית היא מסגרת מתמטית מדויקת לפרסום מידע סטטיסטי אודות מערכי נתונים תוך הגנה על פרטיותם של נבדקים בודדים. היא מאפשרת למחזיק הנתונים לשתף דפוסים מצטברים של הקבוצה בזמן שמגבילה את המידע שנחשף על יחידים ספציפיים.
  ​
* הטמעות: ייצוגים וקטוריים צפופים של נתונים (טקסט, תמונות וכו') המסוגלים ללכוד משמעות סמנטית במרחב רב-ממדי.
  ​
* בהירות – בהירות ב-AI היא היכולת של מערכת AI לספק סיבות ברורות ומובנות לבני אדם להחלטות ולתחזיות שלה, ולתת תובנות לגבי האופן שבו היא פועלת פנימית.
  ​
* בינה מלאכותית מוסברת (XAI): מערכות בינה מלאכותית שמיועדות לספק הסברים שניתנים להבנה על ידי בני אדם עבור החלטותיהן והתנהגויותיהן באמצעות טכניקות ומסגרות שונות.
  ​
* למידה פדרטיבית: גישה ללמידת מכונה שבה מאמנים מודלים על פני מספר מכשירים מבוזרים המכילים דגימות נתונים מקומיות, מבלי להחליף את הנתונים עצמם.
  ​
* מסגרות בטיחות: מגבלות המיושמות כדי למנוע ממערכות AI להפיק תוצאות מזיקות, מוטות או לא רצויות אחרת.
  ​
* הזיה – הזיה של בינה מלאכותית מתייחסת לתופעה שבה מודל בינה מלאכותית מייצר מידע שגוי או מטעה שאינו מבוסס על נתוני האימון שלו או על המציאות העובדתית.
  ​
* אדם בלולאה (HITL): מערכות שנועדו לדרוש פיקוח, אימות או התערבות של אדם בנקודות החלטה קריטיות.
  ​
* תשתית כקוד (IaC): ניהול והקצאת תשתיות באמצעות קוד במקום תהליכים ידניים, מה שמאפשר סריקת אבטחה ופריסות עקביות.
  ​
* ג'יילברייק: טכניקות המשמשות לעקיפת גדרות בטיחות במערכות בינה מלאכותית, במיוחד במודלים גדולים של שפה, כדי להפיק תוכן אסור.
  ​
* הרשאת מינימום: עיקרון אבטחה של הענקת זכויות גישה מינימליות הכרחיות בלבד למשתמשים ולתהליכים.
  ​
* LIME (הסברים מקומיים מובנים המותאמים למודל): טכניקה המסבירה את תחזיותיו של כל מסווג במכונת למידה על ידי קירוב מקומי באמצעות מודל מובן.
  ​
* התקפת אינפרנציה של חברות: התקפה שמטרתה לקבוע האם נקודת נתונים ספציפית שומשה לאימון מודל למידת מכונה.
  ​
* MITRE ATLAS: נוף האיומים האדברסאריאלי למערכות בינה מלאכותית; בסיס ידע של טקטיקות וטכניקות אדברסאריאליות נגד מערכות בינה מלאכותית.
  ​
* כרטיס דגם – כרטיס דגם הוא מסמך המספק מידע סטנדרטי על ביצועי דגם בינה מלאכותית, מגבלותיו, השימושים המתוכננים וההיבטים האתיים במטרה לקדם שקיפות ופיתוח אחראי של בינה מלאכותית.
  ​
* חילוץ מודל: מתקפה שבה מתקדמת שואל repeatedly את מודל היעד כדי ליצור עותק פונקציונלי דומה ללא אישור.
  ​
* היפוך מודל: מתקפה שמנסה לשחזר נתוני אימון על ידי ניתוח פלטי המודל.
  ​
* ניהול מחזור החיים של המודל – ניהול מחזור החיים של מודל AI הוא התהליך של השגחה על כל שלבי קיומו של מודל AI, כולל התכנון, הפיתוח, הפריסה, המעקב, התחזוקה והפסקת השימוש בסופו של דבר, כדי להבטיח שהוא יישאר אפקטיבי ומותאם למטרות.
  ​
* הרעלת מודל: הכנסת פרצות אבטחה או דלתות אחוריות ישירות לתוך מודל במהלך תהליך האימון.
  ​
* גניבת/העתקת מודל: הפקת עותק או קירוב של מודל קנייני באמצעות שאילתות חוזרות ונשנות.
  ​
* מערכת רב-סוכנית: מערכת המורכבת ממספר סוכני AI הפועלים באינטראקציה, שלכל אחד מהם יכולות ומטרות שונות באופן פוטנציאלי.
  ​
* OPA (Open Policy Agent): מנוע מדיניות קוד פתוח שמאפשר אכיפה מאוחדת של מדיניות בכל שכבות המערכת.
  ​
* למידת מכונה שומרת על פרטיות (PPML): טכניקות ושיטות לאימון והטמעה של מודלים של למידת מכונה תוך הגנה על פרטיות נתוני האימון.
  ​
* הזרקת פרומפט: מתקפה שבה הוראות זדוניות משתלבות בקלטים כדי לעקוף את ההתנהגות המיועדת של המודל.
  ​
* RAG (הפקה משודרגת באמצעות אחזור): טכניקה המשפרת מודלים גדולים של שפה על ידי אחזור מידע רלוונטי ממקורות ידע חיצוניים לפני יצירת תגובה.
  ​
* רד-טים: הפרקטיקה של בדיקה פעילה של מערכות בינה מלאכותית על ידי סימולציה של מתקפות עוינות לזיהוי נקודות תורפה.
  ​
* SBOM (חשבון חומרים של תוכנה): רשומה פורמלית המכילה את הפרטים והקשרים בשרשרת האספקה של רכיבים שונים המשמשים בבניית תוכנה או מודלי AI.
  ​
* SHAP (הסברים אדיטיביים של שפלי): גישה תיאורטית משחקים להסברת הפלט של כל מודל למידת מכונה על ידי חישוב התרומה של כל תכונה לחיזוי.
  ​
* מתקפת שרשרת אספקה: פגיעה במערכת על ידי מיקוד באלמנטים פחות מאובטחים בשרשרת האספקה שלה, כגון ספריות צד שלישי, מערכי נתונים או מודלים מאומנים מראש.
  ​
* למידת העברה: טכניקה שבה מודל שפותח למשימה אחת משמש כנקודת התחלה למודל למשימה שנייה.
  ​
* מאגר וקטורים: מאגר נתונים ייעודי שנועד לאחסן וקטורים בעלי ממדים גבוהים (השתקפויות) ולבצע חיפושים יעילים של דמיון.
  ​
* סריקת פגיעויות: כלים אוטומטיים שמזהים פגיעויות אבטחה מוכרות ברכיבי תוכנה, כולל מסגרות AI ותלויות.
  ​
* סימון מים: טכניקות להטמעת סימנים בלתי נראים בתוכן שנוצר על ידי AI למעקב אחר מקורו או לזיהוי יצירת AI.
  ​
* פגיעות אפס-יום: פגיעות שטרם הייתה ידועה שתקפידי התקפה יכולים לנצל לפני שמפתחים יוצרים ומוציאים תיקון.

