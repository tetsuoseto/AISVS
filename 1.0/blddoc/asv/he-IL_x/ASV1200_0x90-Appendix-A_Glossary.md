# נספח א: מילון מונחים

>מילון מקיף זה מספק הגדרות למונחי מפתח בינה מלאכותית, למידת מכונה ואבטחה המשמשים בכל ה-AISVS כדי להבטיח בהירות והבנה משותפת.

* דוגמה עוינת: קלט שנוצר במכוון כדי לגרום למודל בינה מלאכותית לטעות, לעיתים על ידי הוספת שיבושים עדינים שאינם ניתנים לתפיסה על ידי בני אדם.
  ​
* עמידות מול התקפות עוינות – עמידות עוינת בבינה מלאכותית מתייחסת ליכולת של מודל לשמור על ביצועיו ולהמנע מלהיות מטעה או מנוצל על ידי קלטים זדוניים המיועדים לגרום לשגיאות.
  ​
* סוכן – סוכני AI הם מערכות תוכנה המשתמשות בבינה מלאכותית למען השגת מטרות וביצוע משימות מטעם המשתמשים. הם מציגים יכולות של היגיון, תכנון וזיכרון ויש להם דרגת אוטונומיה לקבלת החלטות, ללמוד ולהתאים את עצמם.
  ​
* AI סוכני: מערכות בינה מלאכותית שיכולות לפעול עם מידה מסוימת של אוטונומיה כדי להשיג מטרות, לעיתים קרובות מקבלות החלטות ופועלות ללא התערבות ישירה של בני אדם.
  ​
* בקרת גישה מבוססת תכונות (ABAC): פרדיגמת בקרת גישה שבה החלטות האישור מבוססות על תכונות של המשתמש, המשאב, הפעולה והסביבה, ומוערכות בזמן השאילתה.
  ​
* מתקפת דלת אחורית: סוג של מתקפת רעלת נתונים שבה המודל מאומן להגיב באופן ספציפי לגירויים מסוימים בעוד שהוא מתפקד כרגיל במצבים אחרים.
  ​
* הטיה: שגיאות שיטתיות בתפוקות של מודלי בינה מלאכותית שיכולות להוביל לתוצאות בלתי הוגנות או מופלות לרעה עבור קבוצות מסוימות או בהקשרים ספציפיים.
  ​
* ניצול הטיה: טכניקת התקפה שניצלת מהטיות ידועות במודלים של בינה מלאכותית כדי למנף פלטים או תוצאות.
  ​
* Cedar: שפת המדיניות והמנוע של אמזון להרשאות מדויקות המשמשים ליישום ABAC במערכות AI.
  ​
* שרשרת מחשבה: טכניקה לשיפור החשיבה במודלי שפה על ידי יצירת שלבים ביניים של חשיבה לפני הפקת תשובה סופית.
  ​
* מפסקי מעגל: מנגנונים שעוצרים אוטומטית פעולות של מערכת בינה מלאכותית כאשר חורגים מרמות סיכון ספציפיות.
  ​
* דליפת נתונים: חשיפת מידע רגיש לא מכוונת דרך פלט או התנהגות של מודל בינה מלאכותית.
  ​
* הרעלת נתונים: השחתה מכוונת של נתוני אימון כדי לפגוע בשלמות המודל, לעיתים להתקין דלתות אחוריות או להוריד את הביצועים.
  ​
* פרטיות דיפרנציאלית – פרטיות דיפרנציאלית היא מסגרת מתמטית מחמירה לשחרור מידע סטטיסטי על מערכי נתונים תוך שמירה על פרטיותם של יחידים. היא מאפשרת לבעל הנתונים לשתף דפוסים מצטברים של הקבוצה תוך הגבלת המידע שנחשף על פרטים ספציפיים.
  ​
* הטמעות: ייצוגים בצורת וקטורים צפופים של נתונים (טקסט, תמונות, וכו') שמלכדים משמעות סמנטית במרחב רב-ממדי.
  ​
* הסברתיות – הסברתיות בבינה מלאכותית היא היכולת של מערכת בינה מלאכותית לספק הסברים ברורים להבנה אנושית לגבי החלטותיה ותחזיותיה, ומציעה תובנות לגבי התפקודים הפנימיים שלה.
  ​
* בינה מלאכותית להסבר (XAI): מערכות בינה מלאכותית שתוכננו לספק הסברים מובנים לבני אדם עבור ההחלטות וההתנהגויות שלהן באמצעות טכניקות ומסגרות שונות.
  ​
* למידה מבוזרת: גישת למידת מכונה שבה מודלים מתאמנים על פני מספר מכשירים מבוזרים המחזיקים דגימות נתונים מקומיות, מבלי להחליף את הנתונים עצמם.
  ​
* הגנות: מגבלות המיושמות למניעת מערכות בינה מלאכותית מלהפיק תוצרים מזיקים, מוטים או בלתי רצויים אחרים.
  ​
* הזיה – הזיה של בינה מלאכותית מתייחסת לתופעה שבה מודל בינה מלאכותית מייצר מידע שגוי או מטעה שאינו מבוסס על נתוני האימון שלו או על המציאות העובדתית.
  ​
* האדם-בתוך-הלופ (HITL): מערכות שעוצבו לדרוש פיקוח, אימות או התערבות אנושית בנקודות החלטה קריטיות.
  ​
* תשתית כקוד (IaC): ניהול ואספקת תשתית באמצעות קוד במקום תהליכים ידניים, המאפשר סריקת אבטחה ופריסות עקביות.
  ​
* פריצת כלא: טכניקות המשמשות לעקיפת אמצעי הבטיחות במערכות בינה מלאכותית, במיוחד במודלים גדולים של שפה, כדי להפיק תוכן אסור.
  ​
* הרשאת מינימום: עקרון אבטחה של מתן רק את זכויות הגישה המינימליות הנדרשות למשתמשים ולתהליכים.
  ​
* LIME (הסברים מקומיים בלתי תלויים בדגם): טכניקה להסברת תחזיות של כל מסווג למידת מכונה על ידי קירוב מקומי שלו באמצעות דגם מובן ובריר.
  ​
* התקפת הסקת חברות: התקפה שמטרתה לקבוע האם נקודת נתונים ספציפית שומשה לאימון מודל למידת מכונה.
  ​
* MITRE ATLAS: נוף האיומים האדברסראליים למערכות בינה מלאכותית; בסיס ידע של טקטיקות וטכניקות אדברסראליות נגד מערכות בינה מלאכותית.
  ​
* כרטיס דגם – כרטיס דגם הוא מסמך המספק מידע סטנדרטי לגבי ביצועי מודל בינה מלאכותית, מגבלותיו, השימושים המיועדים לו, ושיקולים אתיים למטרת קידום שקיפות ופיתוח אחראי של בינה מלאכותית.
  ​
* חילוץ מודל: מתקפה שבה תוקף שואל את המודל המטרה שוב ושוב כדי ליצור עותק פונקציונלי דומה ללא הרשאה.
  ​
* היפוך מודל: מתקפה שמנסה לשחזר את נתוני האימון על ידי ניתוח פלטי המודל.
  ​
* ניהול מחזור חיים של מודל – ניהול מחזור החיים של מודל AI הוא התהליך של פיקוח על כל שלבי קיומו של מודל ה-AI, כולל העיצוב, הפיתוח, הפריסה, המעקב, התחזוקה והפסקתו הסופית, על מנת להבטיח שהוא נשאר יעיל ומתואם עם המטרות.
  ​
* הרעלת מודל: הכנסת חולשות או דלתות אחוריות ישירות לתוך מודל במהלך תהליך האימון.
  ​
* גניבת/העתקת מודל: הפקת עותק או קירוב של מודל קנייני באמצעות שאילתות חוזרות.
  ​
* מערכת רב-סוכנית: מערכת המורכבת ממספר סוכני בינה מלאכותית המתפקדים במקביל, שלכל אחד מהם יכולות ומטרות שונות פוטנציאלית.
  ​
* OPA (Open Policy Agent): מנוע מדיניות קוד פתוח שמאפשר אכיפה מאוחדת של מדיניות בכל השכבות.
  ​
* למידת מכונה לשמירת פרטיות (PPML): טכניקות ושיטות לאימון ופריסת מודלים של למידת מכונה תוך שמירה על פרטיות נתוני האימון.
  ​
* הזרקת פרומפט: התקפה שבה הוראות זדוניות מוטמעות בקלטים כדי לעקוף את ההתנהגות המיועדת של המודל.
  ​
* RAG (ייצור משופר באמצעות שליפה): טכניקה המשפרת מודלים לשוניים גדולים על ידי שליפת מידע רלוונטי ממקורות ידע חיצוניים לפני יצירת תגובה.
  ​
* Red-Teaming: הפרקטיקה של בדיקה פעילה של מערכות AI על ידי סימולציה של מתקפות עוינות לזיהוי פגיעות.
  ​
* רשימת חומרים לתוכנה (SBOM): רישום רשמי המכיל את הפרטים והקשרים בשרשרת האספקה של רכיבים שונים המשמשים בבניית תוכנה או מודלי בינה מלאכותית.
  ​
* SHAP (הסברים אדיטיביים של שפלי): גישה תאורטית-משחקית להסבר פלט של כל מודל למידת מכונה באמצעות חישוב התרומה של כל תכונה לניבוי.
  ​
* מתקפת שרשרת אספקה: פגיעה במערכת על ידי מיקוד ברכיבים הפחות מאובטחים בשרשרת האספקה שלה, כגון ספריות צד שלישי, מערכי נתונים או דגמים מאומנים מראש.
  ​
* למידת העברה: טכניקה שבה מודל שפותח עבור משימה אחת משמש מחדש כנקודת התחלה למודל במשימה שנייה.
  ​
* מאגר נתונים וקטורי: מאגר נתונים מיוחד שנועד לאחסן וקטורים בממדים גבוהים (הטמעות) ולבצע חיפושי דמיון יעילים.
  ​
* סריקת פגיעויות: כלים אוטומטיים שמזהים פגיעויות אבטחה ידועות ברכיבי תוכנה, כולל מסגרות AI ותלויות.
  ​
* סימון מים: טכניקות להטמעת סמנים בלתי נראים בתוכן שנוצר על ידי AI כדי לעקוב אחר המקור שלו או לזהות יצירה על ידי AI.
  ​
* פגיעות יום-אפס: פגיעות שטרם הייתה ידועה שפורצים יכולים לנצל לפני שמפתחים יוצרים ומפיצים תיקון.

