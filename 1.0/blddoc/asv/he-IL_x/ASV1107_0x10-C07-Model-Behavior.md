# דגם C7 התנהגות, שליטה ביציאה והבטחת בטיחות

## מטרת בקרה

פלטי המודל חייבים להיות מבניים, אמינים, בטוחים, ניתנים להסבר ומפוקחים ברצף בסביבת הייצור. כך ניתן להפחית הזיות, דליפות פרטיות, תוכן מזיק ופעולות בלתי מבוקרות, תוך הגברת אמון המשתמש ועמידה בדרישות רגולטוריות.

---

## C7.1 אכיפת פורמט הפלט

סכמות קשוחות, דיקוד מוגבל ואימות בתהליכים הבאים מונעים תוכן פגום או זדוני לפני שהוא מתפשט.

|   #   | תיאור                                                                                                                           | רמה | תפקיד |
| :---: | ------------------------------------------------------------------------------------------------------------------------------- | :-: | :---: |
| 7.1.1 | וודא שסכימות תגובה (למשל, JSON Schema) מסופקים בהנחיית המערכת וכל פלט נבדק אוטומטית; פלטים שאינם תואמים מפעילים תיקון או דחייה. |  1  |  D/V  |
| 7.1.2 | וודא שפענוח במגבלות (stop tokens, regex, max-tokens) מופעל כדי למנוע הצפת זיכרון או תעלות צדדיות של הזרקת פרומפט.               |  1  |  D/V  |
| 7.1.3 | וודא שרכיבים בהמשך התהליך מתייחסים לפלטים כלא מהימנים ומבצעים אימות שלהם מול סכימות או דה-סיריאליזרים בטוחים מהזרקה.            |  2  |  D/V  |
| 7.1.4 | וודא כי אירועי פלט שגוי מתועדים, מוגבלים בקצב, ומוצגים למעקב.                                                                   |  3  |   V   |

---

## C7.2 זיהוי ובלימת הזיות

אומדן אי-ודאות ואסטרטגיות גיבוי מצמצמים תשובות מומצאות.

|   #   | תיאור                                                                                                                        | רמה | תפקיד |
| :---: | ---------------------------------------------------------------------------------------------------------------------------- | :-: | :---: |
| 7.2.1 | ודא כי הסתברויות הלוג-ברמת הטוקן, עקביות עצמית באנסמבל, או גלאי הזיות מיושרים מעניקים ניקוד ביטחון לכל תשובה.                |  1  |  D/V  |
| 7.2.2 | וודא כי תגובות מתחת לסף ביטחון ניתן להתאמה מפעילות זרמי עבודה חלופיים (למשל, הפקה מוגברת משחזורים, מודל משני, או סקירת אדם). |  1  |  D/V  |
| 7.2.3 | אמתו שמקרי ההזיה מתויגים עם מטא-נתוני סיבת שורש ומוזנים לצינורות הניתוח שלאחר המוות ולדיוקים מחדש.                           |  2  |  D/V  |
| 7.2.4 | ודא כי הספים והגלאים מעודכנים מחדש לאחר עדכונים משמעותיים במודל או בבסיס הידע.                                               |  3  |  D/V  |
| 7.2.5 | אמת שהוויזואליזציות בלוח הבקרה עוקבות אחרי שיעורי ההזיות.                                                                    |  3  |   V   |

---

## C7.3 סינון בטיחות ופרטיות בפלט

מסנני מדיניות וכיסוי צוות אדום מגנים על משתמשים ועל נתונים סודיים.

|   #   | תיאור                                                                                                            | רמה | תפקיד |
| :---: | ---------------------------------------------------------------------------------------------------------------- | :-: | :---: |
| 7.3.1 | אמת שהמסננים לפני ואחרי ההפקה חוסמים תוכן של שנאה, הטרדה, פגיעה עצמית, קיצוניות ותוכן מיני מפורש בהתאם למדיניות. |  1  |  D/V  |
| 7.3.2 | אמתו כי זיהוי PII/PCI והסרה אוטומטית מתבצעים בכל תגובה; הפרות גורמות להתרעה על אירוע פרטיות.                     |  1  |  D/V  |
| 7.3.3 | וודא שתוויות סודיות (לדוגמה, סודות מסחריים) מתפשטות בין מודאליות שונות כדי למנוע דליפה בטקסט, תמונות או קוד.     |  2  |   D   |
| 7.3.4 | אמת כי ניסיונות עקיפת סינון או סיווגים בסיכון גבוה דורשים אישור משני או אימות משתמש חוזר.                        |  3  |  D/V  |
| 7.3.5 | אמת שהספי הסינון משקפים את תחומי השיפוט החוקיים ואת ההקשר של גיל/תפקיד המשתמש.                                   |  3  |  D/V  |

---

## C7.4 הגבלת פלט ופעולה

מגבלות קצב ושערי אישור מונעים ניצול לרעה ואוטונומיה מופרזת.

|   #   | תיאור                                                                                                                  | רמה | תפקיד |
| :---: | ---------------------------------------------------------------------------------------------------------------------- | :-: | :---: |
| 7.4.1 | אמת כי המכסים לפי משתמש ולפי מפתח API מגבילים בקשות, אסימונים ועלות עם חזרה אקספוננציאלית במקרים של שגיאות 429.        |  1  |   D   |
| 7.4.2 | אמת שפעולות עם הרשאות גבוהות (כתיבת קבצים, ביצוע קוד, קריאות רשת) דורשות אישור מבוסס מדיניות או מעורבות אנושית בתהליך. |  1  |  D/V  |
| 7.4.3 | אשרו כי בדיקות עקביות רב-מודליות מבטיחות שהתמונות, הקוד והטקסט שנוצרו עבור אותו בקשה לא יכולים לשמש להברחת תוכן זדוני. |  2  |  D/V  |
| 7.4.4 | וודא כי עומק ההסמכה של הסוכן, גבולות הרקורסיה ורשימות הכלים המורשים מוגדרים במפורש.                                    |  2  |   D   |
| 7.4.5 | אמת כי הפרת מגבלות מפיקה אירועי אבטחה מובנים לצריכת SIEM.                                                              |  3  |   V   |

---

## C7.5 הסברת פלט

אותות שקופים משפרים את אמון המשתמש ואת תיקון הבאגים הפנימי.

|   #   | תיאור                                                                                                  | רמה | תפקיד |
| :---: | ------------------------------------------------------------------------------------------------------ | :-: | :---: |
| 7.5.1 | אשר כי ציוני הביטחון המוצגים למשתמש או תקצירי הסיבות הקצרות מוצגים כאשר הערכת הסיכון מראה שהם מתאימים. |  2  |  D/V  |
| 7.5.2 | ודא שההסברים שנוצרו נמנעים מחשיפת פקודות מערכת רגישות או נתונים קנייניים.                              |  2  |  D/V  |
| 7.5.3 | אמתו שהמערכת לוכדת הסתברויות לוג ברמת הטוקן או מפות תשומת לב ושומרת אותן לביקורת מורשית.               |  3  |   D   |
| 7.5.4 | אמת כי ארטיפקטים של הסברתיות מנוהלים בגרסאות יחד עם שחרורי המודל לצורך יכולת ביקורת.                   |  3  |   V   |

---

## C7.6 אינטגרציית ניטור

התצפית בזמן אמת סוגרת את המעגל בין פיתוח לייצור.

|   #   | תיאור                                                                                                                   | רמה | תפקיד |
| :---: | ----------------------------------------------------------------------------------------------------------------------- | :-: | :---: |
| 7.6.1 | אמת שהמדדים (הפרות סכימה, שיעור הזיות, רעילות, דליפות מידע אישי מזהה, זמן השהייה, עלות) מוזרמים לפלטפורמת ניטור מרכזית. |  1  |   D   |
| 7.6.2 | וידא שהספים לאזעקה מוגדרים עבור כל מדד בטיחות, עם מסלולי הסלמה לזמינות בתור.                                            |  1  |   V   |
| 7.6.3 | אמת שדוחות הבקרה מקשרים אנומליות ביציאה עם גרסת/דגם המודל, דגל תכונה, ושינויים בנתונים מהמקור העליון.                   |  2  |   V   |
| 7.6.4 | אמת כי נתוני המעקב מוזנים חזרה לתהליך אימון מחדש, כוונון עדין, או עדכוני כללים במסגרת תיעודית של תהליך MLOps.           |  2  |  D/V  |
| 7.6.5 | וודא כי צינורות הניטור נבדקו לפריצות ומנותבים באמצעות בקרת גישה כדי למנוע דליפה של יומנים רגישים.                       |  3  |   V   |

---

## 7.7 אמצעי זהירות למדיה גנרטיבית

וודאו שמערכות AI אינן מייצרות תכני מדיה לא חוקיים, מזיקים או שאינם מורשים על ידי אכיפת מגבלות מדיניות, אימות פלט ועקבות מעקב.

|   #   | תיאור                                                                                                                                   | רמה | תפקיד |
| :---: | --------------------------------------------------------------------------------------------------------------------------------------- | :-: | :---: |
| 7.7.1 | אמת שהוראות המערכת וההנחיות למשתמש אוסרות במפורש על יצירת מדיה מזויפת עמוקה בלתי חוקית, מזיקה או ללא הסכמה (למשל, תמונה, וידאו, אודיו). |  1  |  D/V  |
| 7.7.2 | אמתו שההנחיות מסוננות מניסיונות לייצור חיקויים, דיפפייקים מיניים מפורשים, או מדיה המתארת יחידים אמיתיים ללא הסכמתם.                     |  2  |  D/V  |
| 7.7.3 | אמתו שהמערכת משתמשת בהאשטינג פרספטואלי, זיהוי סימן מים, או טביעת אצבע כדי למנוע שכפול לא מורשה של מדיה עם זכויות יוצרים.                |  2  |   V   |
| 7.7.4 | אמת שכל המדיה שנוצרת חתומה קריפטוגרפית, מסומנת במים, או מוטמעת עם מטא-נתוני מקור עמידים לזיופים למטרות מעקב בהמשך.                      |  3  |  D/V  |
| 7.7.5 | וודא שניסיונות עקיפת המערכת (למשל, הטעיית הפרומפט, סלנג, ניסוח עוין) מזוהים, מתועדים, ומוגבלים בקצב; התעללות חוזרת מוצגת למערכות המעקב. |  3  |   V   |

## ביבליוגרפיה

* [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)
* [ISO/IEC 42001:2023 – AI Management System](https://www.iso.org/obp/ui/en/)
* [OWASP Top-10 for Large Language Model Applications (2025)](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Improper Output Handling – OWASP LLM05:2025](https://genai.owasp.org/llmrisk/llm052025-improper-output-handling/)
* [Practical Techniques to Constrain LLM Output](https://mychen76.medium.com/practical-techniques-to-constraint-llm-output-in-json-format-e3e72396c670)
* [Dataiku – Structured Text Generation Guide](https://blog.dataiku.com/your-guide-to-structured-text-generation)
* [VL-Uncertainty: Detecting Hallucinations](https://arxiv.org/abs/2411.11919)
* [HaDeMiF: Hallucination Detection & Mitigation](https://openreview.net/forum?id=VwOYxPScxB)
* [Building Confidence in LLM Outputs](https://www.alkymi.io/data-science-room/building-confidence-in-llm-outputs)
* [Explainable AI & LLMs](https://duncsand.medium.com/explainable-ai-140912d31b3b)
* [LLM Red-Teaming Guide](https://www.confident-ai.com/blog/red-teaming-llms-a-step-by-step-guide)
* [Sensitive Information Disclosure in LLMs](https://virtualcyberlabs.com/llm-sensitive-information-disclosure/)
* [LangChain – Chat Model Rate Limiting](https://python.langchain.com/docs/how_to/chat_model_rate_limiting/)
* [OpenAI Rate-Limit & Exponential Back-off](https://hackernoon.com/openais-rate-limit-a-guide-to-exponential-backoff-for-llm-evaluation)
* [Arize AI – LLM Observability Platform](https://arize.com/)

