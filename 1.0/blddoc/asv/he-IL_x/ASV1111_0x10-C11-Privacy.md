# 11 הגנת פרטיות וניהול נתונים אישיים

## מטרת בקרה

שמור על הבטחות פרטיות קפדניות לאורך כל מחזור חיי ה-AI — איסוף, אימון, הסקה, ותגובה לאירועים — כך שנתונים אישיים יעובדו רק עם הסכמה ברורה, היקף מינימלי נחוץ, מחיקה מוכחת, ואישורים פורמליים של פרטיות.

---

## 11.1 אנונימיזציה ומזעור נתונים

|   #    | תיאור                                                                                                            | רמה | תפקיד |
| :----: | ---------------------------------------------------------------------------------------------------------------- | :-: | :---: |
| 11.1.1 | וודא שמזהים ישירים וכמו-מזהים הוסרו או הושתו בהם פעולת גיבוב.                                                    |  1  |  D/V  |
| 11.1.2 | לאמת כי ביקורות אוטומטיות מודדות k-אנונימיות/l-גיוון ומתריעות כאשר הספים יורדים מתחת למדיניות.                   |  2  |  D/V  |
| 11.1.3 | וודא שדוחות חשיבות התכונות של המודל מראים שאין דליפה של מזהים מעבר ל-ε = 0.01 של מידע הדדי.                      |  2  |   V   |
| 11.1.4 | ודא כי הוכחות פורמליות או הסמכות של נתונים סינתטיים מראות שסיכון לזיהוי מחודש הוא ≤ 0.05 אפילו תחת התקפות קישור. |  3  |   V   |

---

## 11.2 זכות הנשכח ואכיפת מחיקה

|   #    | תיאור                                                                                                                                                 | רמה | תפקיד |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :---: |
| 11.2.1 | אמת שהבקשות למחיקת נושא-נתונים מתפשטות למערכי הנתונים הגולמיים, נקודות הביקורת, ההטמעות, היומנים, והגיבויים במסגרת הסכמי רמת שירות של פחות מ-30 ימים. |  1  |  D/V  |
| 11.2.2 | אמת שגרימות "שכחת מכונה" מאמנות מחדש פיזית או מבצעות הסרה מקורבת באמצעות אלגוריתמי שכחה מוכחים.                                                       |  2  |   D   |
| 11.2.3 | אמת שהערכת מודל-הצל מאשרת כי רשומות שנשכחו משפיעות על פחות מ-1% מהתוצאות לאחר תהליך השכחה.                                                            |  2  |   V   |
| 11.2.4 | אשר כי אירועי מחיקה מתועדים באופן בלתי ניתן לשינוי וניתנים לביקורת עבור רגולטורים.                                                                    |  3  |   V   |

---

## 11.3 אמצעי הגנה על פרטיות דיפרנציאלית

|   #    | תיאור                                                                                         | רמה | תפקיד |
| :----: | --------------------------------------------------------------------------------------------- | :-: | :---: |
| 11.3.1 | אמתו כי לוחות מעקב על איבוד הפרטיות מייצרים התראות כאשר הסכום המצטבר של ε חורג מהסף המדיניות. |  2  |  D/V  |
| 11.3.2 | אמת שבדיקות פרטיות בקצה-שחור מעריכות את ε̂ בטווח של 10% מערך המוצהר.                          |  2  |   V   |
| 11.3.3 | וידא שההוכחות הרשמיות מכסות את כל ההתאמות העדינות וההטמעות לאחר האימון.                       |  3  |   V   |

---

## 11.4 הגבלת מטרה והגנה מפני התפשטות תחום

|   #    | תיאור                                                                                                     | רמה | תפקיד |
| :----: | --------------------------------------------------------------------------------------------------------- | :-: | :---: |
| 11.4.1 | ודא שכל מערך נתונים וכל נקודת ביקורת של מודל נושאים תג תכלית קריא על ידי מכונה שמתיישב עם ההסכמה המקורית. |  1  |   D   |
| 11.4.2 | אמת כי מנטרי זמן ריצה מזהים שאילתות שאינן תואמות את המטרה המוצהרת ומפעילים סירוב רך.                      |  1  |  D/V  |
| 11.4.3 | וודא כי שערי מדיניות-כשירות חוסמים פריסת מודלים מחדש לתחומים חדשים ללא סקירת DPIA.                        |  3  |   D   |
| 11.4.4 | וודא שהוכחות מעקב פורמליות מראות שכל מחזור חיי הנתונים האישיים נשאר בטווח הסכמת המשתמש.                   |  3  |   V   |

---

## 11.5 ניהול הסכמה ומעקב על בסיס חוקי

|   #    | תיאור                                                                                              | רמה | תפקיד |
| :----: | -------------------------------------------------------------------------------------------------- | :-: | :---: |
| 11.5.1 | אמת שפלטפורמת ניהול הסכמה (CMP) מתעדת את מצב ההסכמה, את המטרות ואת תקופת השימור עבור כל נתון-נושא. |  1  |  D/V  |
| 11.5.2 | וודא כי ממשקי ה-API חושפים אסימוני הסכמה; על המודלים לאמת את תחום האסימון לפני ביצוע המסקנות.      |  2  |   D   |
| 11.5.3 | וודא כי הסכמה נדחתה או נסוגה עוצרת את צינורות העיבוד בתוך 24 שעות.                                 |  2  |  D/V  |

---

## 11.6 למידה מפוזרת עם בקרות פרטיות

|   #    | תיאור                                                                                 | רמה | תפקיד |
| :----: | ------------------------------------------------------------------------------------- | :-: | :---: |
| 11.6.1 | אמת כי עדכוני הלקוח משתמשים בהוספת רעש פרטיות דיפרנציאלית מקומית לפני האגרגציה.       |  1  |   D   |
| 11.6.2 | אשר כי מדדי האימון פרטיים בצורה דיפרנציאלית ולעולם אינם חושפים את אובדן הלקוח היחידי. |  2  |  D/V  |
| 11.6.3 | וודא שסיכום עמיד להרעלה (למשל, Krum/Trimmed-Mean) מופעל.                              |  2  |   V   |
| 11.6.4 | אמת שההוכחות הפורמליות מראות תקציב ε כולל עם פחות מ-5 איבוד תועלת.                    |  3  |   V   |

---

### ביבליוגרפיה

* [GDPR & AI Compliance Best Practices](https://www.exabeam.com/explainers/gdpr-compliance/the-intersection-of-gdpr-and-ai-and-6-compliance-best-practices/)
* [EU Parliament Study on GDPR & AI, 2020](https://www.europarl.europa.eu/RegData/etudes/STUD/2020/641530/EPRS_STU%282020%29641530_EN.pdf)
* [ISO 31700-1:2023 — Privacy by Design for Consumer Products](https://www.iso.org/standard/84977.html)
* [NIST Privacy Framework 1.1 (2025 Draft)](https://www.nist.gov/privacy-framework)
* [Machine Unlearning: Right-to-Be-Forgotten Techniques](https://www.kaggle.com/code/tamlhp/machine-unlearning-the-right-to-be-forgotten)
* [A Survey of Machine Unlearning, 2024](https://arxiv.org/html/2209.02299v6)
* [Auditing DP-SGD — ArXiv 2024](https://arxiv.org/html/2405.14106v4)
* [DP-SGD Explained — PyTorch Blog](https://medium.com/pytorch/differential-privacy-series-part-1-dp-sgd-algorithm-explained-12512c3959a3)
* [Purpose-Limitation for AI — IJLIT 2025](https://academic.oup.com/ijlit/article/doi/10.1093/ijlit/eaaf003/8121663)
* [Data-Protection Considerations for AI — URM Consulting](https://www.urmconsulting.com/blog/data-protection-considerations-for-artificial-intelligence-ai)
* [Top Consent-Management Platforms, 2025](https://www.enzuzo.com/blog/best-consent-management-platforms)
* [Secure Aggregation in DP Federated Learning — ArXiv 2024](https://arxiv.org/abs/2407.19286)

