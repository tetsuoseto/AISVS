# 11 הגנת פרטיות וניהול נתונים אישיים

## מטרת הבקרה

הקפידו על הבטחות פרטיות נוקשות לאורך כל מחזור החיים של הבינה המלאכותית—איסוף, אימון, הסקה, ותגובה לאירועים—כך שהנתונים האישיים יעובדו רק בהסכמה ברורה, בהיקף המינימלי הנדרש, עם מחיקה שניתן לאמת אותה, והבטחות פרטיות פורמליות.

---

## 11.1 אנונימיזציה & מינימיזציה של נתונים

|   #    | תיאור                                                                                                         | רמה | תפקיד |
| :----: | ------------------------------------------------------------------------------------------------------------- | :-: | :---: |
| 11.1.1 | ודא שמזהים ישירים וכמעט-זהויות הוסרו והועברו ל-hash.                                                          |  1  |  D/V  |
| 11.1.2 | ודא כי ביקורות אוטומטיות מודדות את k-anonymity ואת l-diversity, ומתריעות כאשר הספים יורדים מתחת למדיניות.     |  2  |  D/V  |
| 11.1.3 | ודא שדוחות חשיבות התכונות של המודל מוכיחים שאין דליפה של מזהים מעבר ל-ε = 0.01 של מידע הדדי.                  |  2  |   V   |
| 11.1.4 | ודא כי הוכחות פורמליות או אישור נתונים סינתטיים מראות כי סיכון הזיהוי מחדש הוא ≤ 0.05 אפילו תחת התקפות קישור. |  3  |   V   |

---

## 11.2 אכיפת זכות השכחה ומחיקה

|   #    | תיאור                                                                                                                                        | רמה | תפקיד |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :---: |
| 11.2.1 | ודא כי בקשות מחיקת נתוני המשתמש מתפשטות לסטים נתונים גולמיים, נקודות שמירה, הטמות, יומנים וגיבויים במסגרת הסכמי רמת שירות של פחות מ-30 ימים. |  1  |  D/V  |
| 11.2.2 | ודא ש"שגרות 'machine-unlearning' מאמנות מחדש באופן פיזי או להדמיית הסרה באמצעות אלגוריתמים מאומתים ל-unlearning.                             |  2  |   D   |
| 11.2.3 | ודא כי הערכת מודל-צל מוכיחה כי נתונים שנשכחו משפיעים על פחות מ-1% מהפלטים לאחר הסרת הלמידה.                                                  |  2  |   V   |
| 11.2.4 | ודא שאירועי מחיקה מתועדים בצורה שאינה ניתנת לשינוי וניתנים לביקורת עבור רגולטורים.                                                           |  3  |   V   |

---

## 11.3 הגנות פרטיות דיפרנציאליות

|   #    | תיאור                                                                                     | רמה | תפקיד |
| :----: | ----------------------------------------------------------------------------------------- | :-: | :---: |
| 11.3.1 | ודא כי לוחות הבקרה של חשבון אובדן פרטיות מתריעים כאשר ההצטברות ε עולה על גבולות המדיניות. |  2  |  D/V  |
| 11.3.2 | ודא כי בדיקות פרטיות מסוג קופסה שחורה מעריכות את ε̂ בתוך 10% מהערך המוצהר.                |  2  |   V   |
| 11.3.3 | ודא שהוכחות פורמליות מכסות את כל הכיוונונים שלאחר אימון ואת ההטמעות.                      |  3  |   V   |

---

## 11.4 הגבלת-מטרות והגנה מפני הרחבת-היקף

|   #    | תיאור                                                                                                          | רמה | תפקיד |
| :----: | -------------------------------------------------------------------------------------------------------------- | :-: | :---: |
| 11.4.1 | ודא שכל סט נתונים וכל נקודת שמירה של המודל נושאים תגי תכלית שניתנים לקריאה על ידי מכונה בהתאמה להסכמה המקורית. |  1  |   D   |
| 11.4.2 | ודא שמנטרי זמן הריצה מזהים שאילתות שאינן תואמות למטרה המוצהרת ומפעילים סירוב עדין.                             |  1  |  D/V  |
| 11.4.3 | ודא כי שערי מדיניות-כקוד חוסמים פריסת מודלים מחדש לתחומים חדשים ללא סקירת DPIA.                                |  3  |   D   |
| 11.4.4 | ודא כי הוכחות עקיבות פורמליות מראות כי כל מחזור החיים של נתונים אישיים נשאר במסגרת ההסכמה.                     |  3  |   V   |

---

## 11.5 ניהול הסכמות ומעקב על בסיס-חוקי

|   #    | תיאור                                                                                                         | רמה | תפקיד |
| :----: | ------------------------------------------------------------------------------------------------------------- | :-: | :---: |
| 11.5.1 | ודא כי פלטפורמת ניהול הסכמה (CMP) רושמת את מצב ההסכמה, את מטרת העיבוד, ואת משך שמירת הנתונים לכל נושא נתונים. |  1  |  D/V  |
| 11.5.2 | ודא שממשקי API חושפים אסימוני הסכמה; על המודלים לאמת את היקף ההרשאות של הטוקן לפני ביצוע ההסקה.               |  2  |   D   |
| 11.5.3 | ודא כי הסכמה שנדחתה או שהוסרה משתקת את תהליכי העיבוד בתוך 24 שעות.                                            |  2  |  D/V  |

---

## 11.6 למידה מבוזרת עם בקרות פרטיות

|   #    | תיאור                                                                            | רמה | תפקיד |
| :----: | -------------------------------------------------------------------------------- | :-: | :---: |
| 11.6.1 | וודא כי עדכוני הלקוח משתמשים בהוספת רעש פרטיות דיפרנציאלית מקומית לפני האגרגציה. |  1  |   D   |
| 11.6.2 | ודא שמדדי האימון הם פרטיים דיפרנציאליים ולא חושפים את אובדן הלקוח היחיד.         |  2  |  D/V  |
| 11.6.3 | ודא שאגרגציה עמידה לזיהום נתונים (למשל, Krum/Trimmed-Mean) מופעלת.               |  2  |   V   |
| 11.6.4 | ודא כי הוכחות פורמליות מדגימות את התקציב הכולל של ε עם אובדן תועלת קטן מ-5.      |  3  |   V   |

---

### הפניות

* [GDPR & AI Compliance Best Practices](https://www.exabeam.com/explainers/gdpr-compliance/the-intersection-of-gdpr-and-ai-and-6-compliance-best-practices/)
* [EU Parliament Study on GDPR & AI, 2020](https://www.europarl.europa.eu/RegData/etudes/STUD/2020/641530/EPRS_STU%282020%29641530_EN.pdf)
* [ISO 31700-1:2023 — Privacy by Design for Consumer Products](https://www.iso.org/standard/84977.html)
* [NIST Privacy Framework 1.1 (2025 Draft)](https://www.nist.gov/privacy-framework)
* [Machine Unlearning: Right-to-Be-Forgotten Techniques](https://www.kaggle.com/code/tamlhp/machine-unlearning-the-right-to-be-forgotten)
* [A Survey of Machine Unlearning, 2024](https://arxiv.org/html/2209.02299v6)
* [Auditing DP-SGD — ArXiv 2024](https://arxiv.org/html/2405.14106v4)
* [DP-SGD Explained — PyTorch Blog](https://medium.com/pytorch/differential-privacy-series-part-1-dp-sgd-algorithm-explained-12512c3959a3)
* [Purpose-Limitation for AI — IJLIT 2025](https://academic.oup.com/ijlit/article/doi/10.1093/ijlit/eaaf003/8121663)
* [Data-Protection Considerations for AI — URM Consulting](https://www.urmconsulting.com/blog/data-protection-considerations-for-artificial-intelligence-ai)
* [Top Consent-Management Platforms, 2025](https://www.enzuzo.com/blog/best-consent-management-platforms)
* [Secure Aggregation in DP Federated Learning — ArXiv 2024](https://arxiv.org/abs/2407.19286)

