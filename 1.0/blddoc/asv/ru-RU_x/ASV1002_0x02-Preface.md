# Предисловие

Добро пожаловать в Стандарт проверки безопасности искусственного интеллекта (AISVS) версии 1.0!

## Введение

Основана в 2025 году благодаря совместным усилиям сообщества, AISVS определяет требования к безопасности, которые следует учитывать при проектировании, разработке, развертывании и эксплуатации современных моделей ИИ, пайплайнов и сервисов на базе ИИ.

AISVS v1.0 представляет собой объединённую работу руководителей проекта, рабочей группы и более широкого сообщества участников, направленную на создание прагматичной и тестируемой основы для обеспечения безопасности систем искусственного интеллекта.

Наша цель в этом выпуске — сделать AISVS простым в внедрении, при этом сохранив строгий фокус на определённом объёме работ и учитывая быстро развивающийся ландшафт рисков, характерный для искусственного интеллекта.

## Ключевые цели AISVS версии 1.0

Версия 1.0 будет создана с несколькими руководящими принципами.

### Чётко‑определённый объём

Каждое требование должно соответствовать названию и миссии AISVS:

* Искусственный интеллект – Контроли работают на уровне AI/ML (данные, модель, пайплайн или вывод) и находятся в зоне ответственности специалистов по ИИ.
* Безопасность – требования напрямую снижают выявленные риски информационной безопасности, конфиденциальности и безопасности.
* Верификация – язык написан так, чтобы соответствие могло быть объективно подтверждено.
* Стандарт – Разделы следуют единой структуре и единой терминологии, чтобы образовать целостный справочник.
  ​
---

Следуя AISVS, организации могут систематически оценивать и укреплять уровень безопасности своих решений на базе ИИ, способствуя формированию культуры безопасной разработки ИИ.

