# Предисловие

Добро пожаловать в стандарт проверки безопасности искусственного интеллекта (AISVS) версии 1.0!

## Введение

Основанная в 2025 году в результате совместных усилий сообщества, AISVS определяет требования безопасности, которые необходимо учитывать при проектировании, разработке, внедрении и эксплуатации современных моделей искусственного интеллекта, конвейеров и сервисов с поддержкой ИИ.

AISVS v1.0 представляет собой совместную работу руководителей проекта, рабочей группы и более широкой общины участников, направленную на создание прагматичной и проверяемой базовой линии для обеспечения безопасности AI-систем.

Наша цель с этим выпуском — сделать AISVS простым для внедрения, при этом сохраняя строгий фокус на его определённом объёме и учитывая быстро меняющийся ландшафт рисков, уникальный для ИИ.

## Ключевые задачи для AISVS версии 1.0

Версия 1.0 будет создана на основе нескольких основных принципов.

### Четко определенный объем работ

Каждое требование должно соответствовать названию и миссии AISVS:

* Искусственный интеллект – Контроли работают на уровне ИИ/МО (данные, модель, конвейер или вывод) и являются ответственностью специалистов по ИИ.
* Безопасность – требования непосредственно устраняют выявленные риски для безопасности, конфиденциальности или безопасности.
* Верификация – язык написан таким образом, чтобы соответствие могло быть объективно проверено.
* Стандарт – Разделы следуют последовательной структуре и терминологии для создания связного справочного материала.
  ​
---

Следуя AISVS, организации могут систематически оценивать и укреплять безопасность своих AI-решений, способствуя развитию культуры безопасной инженерии AI.

