# Предисловие

Добро пожаловать в Стандарт проверки безопасности искусственного интеллекта (AISVS) версии 1.0!

## Введение

Созданная в 2025 году в результате совместных усилий сообщества, AISVS определяет требования к безопасности, которые необходимо учитывать при проектировании, разработке, развертывании и эксплуатации современных моделей ИИ, конвейеров и сервисов на базе ИИ.

AISVS v1.0 представляет собой совместную работу руководителей проекта, рабочей группы и более широкой общественности, направленную на создание прагматичной, проверяемой основы для обеспечения безопасности систем искусственного интеллекта.

Наша цель с этим выпуском — сделать AISVS простым для внедрения, при этом сохраняя строгую фокусировку на его определённом назначении и учитывая быстро меняющийся ландшафт рисков, уникальных для ИИ.

## Ключевые цели версии AISVS 1.0

Версия 1.0 будет создана с несколькими основными принципами.

### Четко определенный объем работ

Каждое требование должно соответствовать названию и миссии AISVS:

* Искусственный интеллект – Контроли работают на уровне ИИ/МО (данные, модель, конвейер или вывод) и являются ответственностью специалистов по ИИ.
* Безопасность – Требования непосредственно устраняют выявленные риски безопасности, конфиденциальности или безопасности эксплуатации.
* Верификация – язык написан так, чтобы соответствие можно было объективно проверить.
* Стандарт – разделы следуют последовательной структуре и терминологии для формирования согласованного справочного материала.
  ​
---

Следуя AISVS, организации могут систематически оценивать и укреплять уровень безопасности своих решений на базе ИИ, способствуя формированию культуры безопасной инженерии ИИ.

