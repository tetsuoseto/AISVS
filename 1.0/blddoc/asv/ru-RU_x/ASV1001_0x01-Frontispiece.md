# Титульный лист

## О стандарте

Стандарт проверки безопасности искусственного интеллекта (AISVS) — это каталожный сборник требований безопасности, созданный сообществом, который специалисты по данным, инженеры MLOps, архитекторы программного обеспечения, разработчики, тестировщики, специалисты по безопасности, поставщики инструментов, регуляторы и потребители могут использовать для проектирования, создания, тестирования и проверки надежных систем и приложений с поддержкой ИИ. Он обеспечивает общий язык для определения мер безопасности на протяжении всего жизненного цикла ИИ — от сбора данных и разработки моделей до развертывания и постоянного мониторинга — чтобы организации могли оценивать и повышать устойчивость, конфиденциальность и безопасность своих ИИ-решений.

## Авторские права и лицензия

Версия 0.1 (Первый публичный черновик - В процессе разработки), 2025  

![license](../images/license.png)

Авторские права © 2025 Проект AISVS.  

Выпущено под лицензией [Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
Для любого повторного использования или распространения вы должны четко сообщать другим условия лицензии этой работы.

## Руководители проекта

|             |                        |
| ----------- | ---------------------- |
| Джим Манико | Арас «Русс» Мемисязичи |

## Участники и рецензенты

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS — это совершенно новый стандарт, созданный специально для решения уникальных задач безопасности систем искусственного интеллекта. Хотя он черпает вдохновение из более общих лучших практик безопасности, каждое требование в AISVS разработано с нуля с учетом угроз, характерных для ИИ, и направлено на помощь организациям в создании более безопасных и устойчивых ИИ-решений.

