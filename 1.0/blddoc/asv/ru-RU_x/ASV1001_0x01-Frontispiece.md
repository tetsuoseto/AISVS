# фронтиспис

## Об стандарте

Стандарт проверки безопасности искусственного интеллекта (AISVS) — это каталог требований к безопасности, формируемый сообществом, который специалисты по данным, инженеры MLOps, архитекторы ПО, разработчики, тестировщики, специалисты по безопасности, поставщики инструментов, регуляторы и потребители могут использовать для разработки, построения, тестирования и проверки надежности систем и приложений с использованием искусственного интеллекта. Он обеспечивает единый язык для определения мер безопасности на всём жизненном цикле ИИ — от сбора данных и разработки моделей до развёртывания и постоянного мониторинга — чтобы организации могли измерять и повышать устойчивость, конфиденциальность и безопасность своих решений на базе искусственного интеллекта.

## Авторское право и лицензия

Версия 0.1 (Первый публичный черновик - В процессе разработки), 2025  

![license](../images/license.png)

Авторское право © 2025 The AISVS Project.  

Выпущено под [Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
Для любого повторного использования или распространения вы должны явно сообщать условия лицензии на данную работу другим лицам.

## Руководители проектов

|             |                         |
| ----------- | ----------------------- |
| Джим Манико | Арас «Russ» Memisyazici |

## Соавторы и рецензенты

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS — совершенно новый стандарт, созданный специально для решения уникальных проблем безопасности систем искусственного интеллекта. Хотя он черпает вдохновение из более широких практик обеспечения безопасности, каждое требование AISVS разработано с нуля, чтобы отражать ландшафт угроз в области искусственного интеллекта и помогать организациям создавать более безопасные и устойчивые решения на базе ИИ.

