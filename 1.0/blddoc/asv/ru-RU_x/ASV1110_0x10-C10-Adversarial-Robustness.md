# 10 Адвесариальная стойкость и защита конфиденциальности

## Цель контроля

Обеспечьте, чтобы модели ИИ оставались надежными, сохраняющими конфиденциальность и устойчивыми к злоупотреблениям при столкновении с атаками уклонения, вывода, извлечения или отравления.

---

## 10.1 Выровненность модели и безопасность

Защищайте от вредоносных или нарушающих политику результатов.

|   #    | Описание                                                                                                                                                                                      | Уровень | Роль |
| :----: | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :--: |
| 10.1.1 | Убедитесь, что набор тестов на согласованность (промпты red-team, методы обхода ограничений, запрещённый контент) находится под версионным контролем и запускается при каждом выпуске модели. |    1    | D/V  |
| 10.1.2 | Убедитесь, что механизмы отказа и безопасного завершения работы защитных барьеров применяются.                                                                                                |    1    |  D   |
| 10.1.3 | Проверьте, что автоматический оцениватель измеряет уровень вредоносного контента и отмечает регрессии, превышающие установленный порог.                                                       |    2    | D/V  |
| 10.1.4 | Убедитесь, что обучение против обхода защиты задокументировано и может быть воспроизведено.                                                                                                   |    2    |  D   |
| 10.1.5 | Проверьте, что формальные доказательства соответствия политике или сертифицированный мониторинг охватывают критические области.                                                               |    3    |  V   |

---

## 10.2 Укрепление против примеров с враждебными атаками

Повысить устойчивость к манипулируемым входным данным. Надежное обучение с противодействием и оценка по эталонным тестам являются текущей лучшей практикой.

|   #    | Описание                                                                                                                                     | Уровень | Роль |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :--: |
| 10.2.1 | Проверьте, что репозитории проектов включают конфигурации adversarial-training с воспроизводимыми seed.                                      |    1    |  D   |
| 10.2.2 | Проверьте, что обнаружение атакующих примеров вызывает блокирующие оповещения в производственных конвейерах.                                 |    2    | D/V  |
| 10.2.4 | Проверьте, что доказательства сертифицированной устойчивости или сертификаты с интервалами охватывают как минимум наиболее критичные классы. |    3    |  V   |
| 10.2.5 | Проверьте, что регрессионные тесты используют адаптивные атаки для подтверждения отсутствия измеримой потери устойчивости.                   |    3    |  V   |

---

## 10.3 Смягчение последствий вывода членства

Ограничьте возможность определить, была ли запись в обучающих данных. Дифференциальная конфиденциальность и маскирование оценок уверенности остаются наиболее эффективными известными средствами защиты.

|   #    | Описание                                                                                                                            | Уровень | Роль |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------- | :-----: | :--: |
| 10.3.1 | Проверьте, что регуляризация энтропии для каждого запроса или масштабирование температуры уменьшает излишне уверенные предсказания. |    1    |  D   |
| 10.3.2 | Проверьте, что обучение использует ε-ограниченную дифференциально-приватную оптимизацию для чувствительных наборов данных.          |    2    |  D   |
| 10.3.3 | Проверьте, что симуляции атак (shadow-модель или black-box) показывают AUC атаки ≤ 0.60 на отложенных данных.                       |    2    |  V   |

---

## 10.4 Сопротивление инверсии модели

Предотвратить восстановление приватных атрибутов. Последние исследования подчеркивают усечение вывода и гарантии дифференциальной приватности как практические меры защиты.

|   #    | Описание                                                                                                                                             | Уровень | Роль |
| :----: | ---------------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :--: |
| 10.4.1 | Проверьте, что чувствительные атрибуты никогда не выводятся напрямую; там, где это необходимо, используйте корзины или односторонние преобразования. |    1    |  D   |
| 10.4.2 | Проверьте, что ограничения по частоте запросов ограничивают повторяющиеся адаптивные запросы от одного и того же субъекта.                           |    1    | D/V  |
| 10.4.3 | Проверьте, что модель обучена с использованием шума, сохраняющего конфиденциальность.                                                                |    2    |  D   |

---

## 10.5 Защита от извлечения модели

Обнаружение и предотвращение несанкционированного клонирования. Рекомендуются методы цифрового водяного знака и анализ паттернов запросов.

|   #    | Описание                                                                                                                                                                             | Уровень | Роль |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :-----: | :--: |
| 10.5.1 | Проверьте, что шлюзы вывода обеспечивают соблюдение глобальных и индивидуальных для каждого API-ключа ограничений скорости, настроенных в соответствии с порогом запоминания модели. |    1    |  D   |
| 10.5.2 | Проверьте, что статистика энтропии запросов и множественности входных данных подается в детектор автоматического извлечения.                                                         |    2    | D/V  |
| 10.5.3 | Проверьте, что хрупкие или вероятностные водяные знаки могут быть доказаны с p < 0.01 при ≤ 1 000 запросах к подозреваемому клону.                                                   |    2    |  V   |
| 10.5.4 | Проверьте, что ключи водяных знаков и наборы триггеров хранятся в модуле аппаратной безопасности и обновляются ежегодно.                                                             |    3    |  D   |
| 10.5.5 | Проверьте, что события extraction-alert включают нарушающие запросы и интегрированы с планами реагирования на инциденты.                                                             |    3    |  V   |

---

## 10.6 Обнаружение отравленных данных во время инференса

Идентифицировать и нейтрализовать внедренные или отравленные входные данные.

|   #    | Описание                                                                                                                                                    | Уровень | Роль |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :--: |
| 10.6.1 | Проверьте, что входные данные проходят через детектор аномалий (например, STRIP, оценка согласованности) перед выполнением вывода модели.                   |    1    |  D   |
| 10.6.2 | Проверьте, что пороги детектора настроены на чистых/заражённых валидационных наборах для достижения уровня ложных срабатываний менее 5%.                    |    1    |  V   |
| 10.6.3 | Проверьте, что входные данные, помеченные как заражённые, вызывают срабатывание мягкой блокировки и процессы проверки человеком.                            |    2    |  D   |
| 10.6.4 | Проверьте, что детекторы подвергаются стресс-тестированию с адаптивными, безтриггерными атаками типа «задняя дверь».                                        |    2    |  V   |
| 10.6.5 | Проверьте, что метрики эффективности обнаружения фиксируются и периодически переоцениваются с использованием актуальной информационной разведки по угрозам. |    3    |  D   |

---

## 10.7 Динамическая адаптация политики безопасности

Обновления политики безопасности в реальном времени на основе разведданных о угрозах и поведенческого анализа.

|   #    | Описание                                                                                                                                                    | Уровень | Роль |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :--: |
| 10.7.1 | Проверьте, что политики безопасности могут обновляться динамически без перезапуска агента, при этом сохраняется целостность версии политики.                |    1    | D/V  |
| 10.7.2 | Проверяйте, что обновления политик криптографически подписаны уполномоченными сотрудниками службы безопасности и подтверждены перед применением.            |    2    | D/V  |
| 10.7.3 | Проверьте, что динамические изменения политики регистрируются с полными аудиторскими записями, включая обоснование, цепочки утверждения и процедуры отката. |    2    | D/V  |
| 10.7.4 | Проверьте, что адаптивные механизмы безопасности регулируют чувствительность обнаружения угроз на основе контекста риска и поведенческих моделей.           |    3    | D/V  |
| 10.7.5 | Проверьте, чтобы решения по адаптации политики были объяснимыми и включали следы доказательств для проверки командой безопасности.                          |    3    | D/V  |

---

## 10.8 Анализ безопасности на основе рефлексии

Проверка безопасности через самоанализ агента и метакогнитивный анализ.

|   #    | Описание                                                                                                                                              | Уровень | Роль |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :--: |
| 10.8.1 | Проверьте, что механизмы рефлексии агента включают самооценку решений и действий с упором на безопасность.                                            |    1    | D/V  |
| 10.8.2 | Проверьте, что выходные данные рефлексии проходят проверку для предотвращения манипуляций механизмами самооценки с помощью враждебных входных данных. |    2    | D/V  |
| 10.8.3 | Проверьте, что метакогнитивный анализ безопасности выявляет потенциальные предвзятости, манипуляции или компрометации в процессах рассуждения агента. |    2    | D/V  |
| 10.8.4 | Проверьте, что предупреждения о безопасности на основе рефлексии вызывают усиленный мониторинг и возможные рабочие процессы с участием человека.      |    3    | D/V  |
| 10.8.5 | Подтвердите, что непрерывное обучение на основе анализа безопасности улучшает обнаружение угроз без ухудшения легитимной функциональности.            |    3    | D/V  |

---

## 10.9 Безопасность эволюции и самоусовершенствования

Меры безопасности для агентных систем, способных к самomodификации и эволюции.

|   #    | Описание                                                                                                                                            | Уровень | Роль |
| :----: | --------------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :--: |
| 10.9.1 | Убедитесь, что возможности самомодификации ограничены назначенными безопасными зонами с формальными границами верификации.                          |    1    | D/V  |
| 10.9.2 | Проверьте, что предложения по эволюции проходят оценку влияния на безопасность перед внедрением.                                                    |    2    | D/V  |
| 10.9.3 | Убедитесь, что механизмы самосовершенствования включают возможности отката с проверкой целостности.                                                 |    2    | D/V  |
| 10.9.4 | Проверьте, что безопасность мета-обучения предотвращает враждебное воздействие на алгоритмы улучшения.                                              |    3    | D/V  |
| 10.9.5 | Подтвердите, что рекурсивное самосовершенствование ограничено формальными ограничениями безопасности с математическими доказательствами сходимости. |    3    | D/V  |

---

### Ссылки

* [MITRE ATLAS adversary tactics for ML](https://atlas.mitre.org/)
* [NIST AI Risk Management Framework 1.0, 2023](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [OWASP Top 10 for LLM Applications, 2025](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Adversarial Training: A Survey — Zhao et al., 2024](https://arxiv.org/abs/2410.15042)
* [RobustBench adversarial-robustness benchmark](https://robustbench.github.io/)
* [Membership-Inference & Model-Inversion Risk Survey, 2025](https://www.sciencedirect.com/science/article/abs/pii/S0950705125003867)
* [PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023](https://ojs.aaai.org/index.php/AAAI/article/view/26289)
* [Model-Inversion Attacks & Defenses Survey — AI Review, 2025](https://link.springer.com/article/10.1007/s10462-025-11248-0)
* [Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024](https://doi.org/10.1109/TDSC.2023.3261327)
* [Fragile Model Watermarking Survey — 2025](https://www.sciencedirect.com/science/article/abs/pii/S0165168425002026)
* [Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025](https://arxiv.org/abs/2503.22759)
* [BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024](https://arxiv.org/abs/2405.15269)

