# 10 Адверсариальная устойчивость и защита конфиденциальности

## Контрольная цель

Обеспечьте, чтобы модели ИИ оставались надежными, сохраняли конфиденциальность и были устойчивыми к злоупотреблениям при столкновении с атаками обхода, инференса, извлечения или отравления.

---

## 10.1 Выравнивание модели и безопасность

Предотвращайте вредные или нарушающие политику выходы.

|   #    | Описание                                                                                                                                                                                         | Уровень | Роль |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :-----: | :--: |
| 10.1.1 | Убедитесь, что набор тестов на выравнивание (промпты красной команды, пробы обхода ограничений, запрещённый контент) находится под версионным контролем и выполняется при каждом выпуске модели. |    1    | D/V  |
| 10.1.2 | Проверьте, что применяются правила отказа и безопасного завершения.                                                                                                                              |    1    |  D   |
| 10.1.3 | Проверьте, что автоматизированный оцениватель измеряет уровень вредоносного контента и помечает регрессии, выходящие за заданный порог.                                                          |    2    | D/V  |
| 10.1.4 | Проверьте, что обучение по противодействию джейлбрейку задокументировано и воспроизводимо.                                                                                                       |    2    |  D   |
| 10.1.5 | Проверьте, что формальные доказательства соответствия политике или сертифицированный мониторинг охватывают критические области.                                                                  |    3    |  V   |

---

## 10.2 Укрепление против враждебных примеров

Повышайте устойчивость к манипулируемым входам. Устойчивое адверсариальное-обучение и оценка по бенчмарку — на данный момент лучшая практика.

|   #    | Описание                                                                                                                                          | Уровень | Роль |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :--: |
| 10.2.1 | Проверьте, что в репозиториях проектов присутствуют конфигурации обучения противодействию с воспроизводимыми семенами.                            |    1    |  D   |
| 10.2.2 | Проверьте, что обнаружение враждебных примеров генерирует блокирующие оповещения в производственных пайплайнах.                                   |    2    | D/V  |
| 10.2.4 | Проверьте, что доказательства сертифицированной‑устойчивости или интервальные сертификаты охватывают по крайней мере наиболее критические классы. |    3    |  V   |
| 10.2.5 | Проверьте, что регрессионные тесты используют адаптивные атаки, чтобы подтвердить отсутствие измеримой потери устойчивости.                       |    3    |  V   |

---

## 10.3 Защита от инференции по принадлежности к обучающему набору

Ограничьте возможность определить, была ли запись в обучающих данных. Дифференциальная приватность и маскирование оценки уверенности остаются самыми эффективными известными мерами защиты.

|   #    | Описание                                                                                                                            | Уровень | Роль |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------- | :-----: | :--: |
| 10.3.1 | Убедитесь, что регуляризация энтропии на уровне запроса или масштабирование по температуре снижают излишне уверенные предсказания.  |    1    |  D   |
| 10.3.2 | Проверьте, что обучение выполняет оптимизацию с ε-ограниченной дифференциальной приватностью для чувствительных наборов данных.     |    2    |  D   |
| 10.3.3 | Убедитесь, что симуляции атак (теневая модель или модель с черным ящиком) показывают AUC атаки ≤ 0.60 на отложенной выборке данных. |    2    |  V   |

---

## 10.4 Устойчивость к Model-Inversion

Предотвращение восстановления приватных атрибутов. Недавние обзоры подчеркивают обрезку вывода и гарантии DP как практические меры защиты.

|   #    | Описание                                                                                                                                                   | Уровень | Роль |
| :----: | ---------------------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :--: |
| 10.4.1 | Проверьте, что чувствительные атрибуты никогда не выводятся напрямую; при необходимости используйте разбиение на корзины или односторонние преобразования. |    1    |  D   |
| 10.4.2 | Убедитесь, что ограничения частоты запросов ограничивают повторяющиеся адаптивные запросы от одного и того же принципала.                                  |    1    | D/V  |
| 10.4.3 | Проверьте, что модель обучена с использованием шума, обеспечивающего конфиденциальность.                                                                   |    2    |  D   |

---

## 10.5 Защита от извлечения модели

Обнаружение и предотвращение несанкционированного клонирования. Рекомендуется применение водяных знаков и анализ шаблонов запросов.

|   #    | Описание                                                                                                                                                        | Уровень | Роль |
| :----: | --------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :--: |
| 10.5.1 | Проверьте, что шлюзы инференса обеспечивают соблюдение как глобальных, так и лимитов скорости, настроенных под порог запоминания модели, для каждого API-ключа. |    1    |  D   |
| 10.5.2 | Проверьте, что query-entropy и input-plurality statistics подают данные на вход автоматизированному детектору извлечения.                                       |    2    | D/V  |
| 10.5.3 | Убедитесь, что хрупкие или вероятностные водяные знаки можно доказать с p < 0.01 при ≤ 1 000 запросах против предполагаемого клона.                             |    2    |  V   |
| 10.5.4 | Проверьте, что ключи водяных знаков и наборы триггеров хранятся в аппаратном модуле защиты ключей и обновляются ежегодно.                                       |    3    |  D   |
| 10.5.5 | Убедитесь, что события extraction-alert включают злоумышленные запросы и интегрированы в плейбуки реагирования на инциденты.                                    |    3    |  V   |

---

## 10.6 Обнаружение отравленных-данных на этапе инференса

Идентифицировать и нейтрализовать входные данные с бэкдором или отравленные входные данные.

|   #    | Описание                                                                                                                                                       | Уровень | Роль |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :--: |
| 10.6.1 | Проверьте, что входные данные проходят через детектор аномалий (например, STRIP, оценка согласованности) перед инференсом модели.                              |    1    |  D   |
| 10.6.2 | Убедитесь, что пороги детектора откалиброваны на чистых и отравленных валидационных наборах данных, чтобы обеспечить менее 5% ложноположительных срабатываний. |    1    |  V   |
| 10.6.3 | Проверьте, что помеченные как отравленные входные данные вызывают мягкую блокировку и процессы ручной проверки.                                                |    2    |  D   |
| 10.6.4 | Убедитесь, что детекторы подвергаются стресс-тестированию с адаптивными бэкдор-атаками без триггера.                                                           |    2    |  V   |
| 10.6.5 | Убедитесь, что метрики эффективности обнаружения логируются и периодически повторно оцениваются с использованием свежих разведданных об угрозах.               |    3    |  D   |

---

## 10.7 Динамическая адаптация политики безопасности

Обновления политики безопасности в реальном времени на основе разведки угроз и поведенческого анализа.

|   #    | Описание                                                                                                                                                    | Уровень | Роль |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :--: |
| 10.7.1 | Убедитесь, что политики безопасности могут обновляться динамически без перезапуска агента, сохраняя целостность версии политики.                            |    1    | D/V  |
| 10.7.2 | Убедитесь, что обновления политики криптографически подписаны уполномоченными сотрудниками службы безопасности и валидируются перед применением.            |    2    | D/V  |
| 10.7.3 | Убедитесь, что динамические изменения политики регистрируются с полными журналами аудита, включая обоснование, цепочки согласования и процедуры отката.     |    2    | D/V  |
| 10.7.4 | Убедитесь, что адаптивные механизмы безопасности настраивают чувствительность обнаружения угроз в зависимости от контекста риска и поведенческих паттернов. |    3    | D/V  |
| 10.7.5 | Проверьте, что решения по адаптации политики объяснимы и содержат следы аудита для рассмотрения командой безопасности.                                      |    3    | D/V  |

---

## 10.8 Анализ безопасности на основе рефлексии

Проверка безопасности через саморазмышление агента и метакогнитивный анализ.

|   #    | Описание                                                                                                                                                        | Уровень | Роль |
| :----: | --------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :--: |
| 10.8.1 | Проверьте, что механизмы рефлексии агентов включают самооценку решений и действий, ориентированную на безопасность.                                             |    1    | D/V  |
| 10.8.2 | Проверьте, что выходы саморефлексии валидируются, чтобы предотвратить манипулирование механизмами самооценки вредоносными входными данными.                     |    2    | D/V  |
| 10.8.3 | Проверьте, что метакогнитивный анализ безопасности выявляет возможную предвзятость, манипуляцию или компрометацию в процессах рассуждений агента.               |    2    | D/V  |
| 10.8.4 | Убедитесь, что предупреждения о безопасности на основе рефлексии запускают усиленный мониторинг и потенциальные потоки работ, требующие вмешательства человека. |    3    | D/V  |
| 10.8.5 | Проверьте, что непрерывное обучение на основе размышлений о безопасности улучшает обнаружение угроз, не ухудшая законную функциональность.                      |    3    | D/V  |

---

## 10.9 Эволюция и самосовершенствование безопасности

Средства обеспечения безопасности для агентских систем, способных к самосовершенствованию и эволюции.

|   #    | Описание                                                                                                                                             | Уровень | Роль |
| :----: | ---------------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :--: |
| 10.9.1 | Проверьте, что возможности самоизменения ограничены отведёнными безопасными областями в рамках формальной верификации.                               |    1    | D/V  |
| 10.9.2 | Убедитесь, что предложения по эволюции проходят оценку влияния на безопасность до внедрения.                                                         |    2    | D/V  |
| 10.9.3 | Убедитесь, что механизмы самоулучшения включают возможности отката с проверкой целостности.                                                          |    2    | D/V  |
| 10.9.4 | Проверьте, что безопасность мета-обучения предотвращает враждебную манипуляцию алгоритмами улучшения.                                                |    3    | D/V  |
| 10.9.5 | Проверьте, что рекурсивное самосовершенствование ограничено формальными ограничениями безопасности и имеет математические доказательства сходимости. |    3    | D/V  |

---

### Список литературы

* [MITRE ATLAS adversary tactics for ML](https://atlas.mitre.org/)
* [NIST AI Risk Management Framework 1.0, 2023](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [OWASP Top 10 for LLM Applications, 2025](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Adversarial Training: A Survey — Zhao et al., 2024](https://arxiv.org/abs/2410.15042)
* [RobustBench adversarial-robustness benchmark](https://robustbench.github.io/)
* [Membership-Inference & Model-Inversion Risk Survey, 2025](https://www.sciencedirect.com/science/article/abs/pii/S0950705125003867)
* [PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023](https://ojs.aaai.org/index.php/AAAI/article/view/26289)
* [Model-Inversion Attacks & Defenses Survey — AI Review, 2025](https://link.springer.com/article/10.1007/s10462-025-11248-0)
* [Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024](https://doi.org/10.1109/TDSC.2023.3261327)
* [Fragile Model Watermarking Survey — 2025](https://www.sciencedirect.com/science/article/abs/pii/S0165168425002026)
* [Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025](https://arxiv.org/abs/2503.22759)
* [BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024](https://arxiv.org/abs/2405.15269)

