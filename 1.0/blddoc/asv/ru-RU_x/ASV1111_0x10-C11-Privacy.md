# 11 Защита конфиденциальности и управление персональными данными

## Цель контроля

Обеспечьте строгие гарантии конфиденциальности на протяжении всего жизненного цикла ИИ — сбор, обучение, вывод и реагирование на инциденты — чтобы персональные данные обрабатывались только с четким согласием, в минимально необходимом объеме, с подтверждаемым удалением и формальными гарантиями конфиденциальности.

---

## 11.1 Анонимизация и минимизация данных

|   #    | Описание                                                                                                                                                                               | Уровень | Роль |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :--: |
| 11.1.1 | Убедитесь, что прямые и квази-идентификаторы удалены или захешированы.                                                                                                                 |    1    | D/V  |
| 11.1.2 | Проверьте, что автоматизированные аудиты измеряют k-анонимность/l-разнообразие и выдают предупреждение, когда показатели опускаются ниже установленных политикой порогов.              |    2    | D/V  |
| 11.1.3 | Проверьте, что отчёты о важности признаков модели доказывают отсутствие утечки идентификаторов при взаимной информации не более ε = 0.01.                                              |    2    |  V   |
| 11.1.4 | Убедитесь, что формальные доказательства или сертификация на основе синтетических данных показывают риск повторной идентификации ≤ 0.05 даже при атаках с использованием связи данных. |    3    |  V   |

---

## 11.2 Право на забвение и обеспечение удаления

|   #    | Описание                                                                                                                                                                                                                | Уровень | Роль |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :--: |
| 11.2.1 | Проверьте, что запросы на удаление данных субъекта распространяются на необработанные наборы данных, контрольные точки, эмбеддинги, журналы и резервные копии в рамках соглашений об уровне обслуживания менее 30 дней. |    1    | D/V  |
| 11.2.2 | Проверьте, что процедуры "машинного разучивания" физически переобучают или приближенно удаляют данные с использованием сертифицированных алгоритмов разучивания.                                                        |    2    |  D   |
| 11.2.3 | Проверьте, что оценка теневой модели доказывает, что забытые записи влияют на менее чем 1% выходных данных после процесса удаления знаний.                                                                              |    2    |  V   |
| 11.2.4 | Убедитесь, что события удаления записываются неизменно и могут быть аудированы для регуляторов.                                                                                                                         |    3    |  V   |

---

## 11.3 Механизмы обеспечения дифференциальной приватности

|   #    | Описание                                                                                                                                        | Уровень | Роль |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :--: |
| 11.3.1 | Проверьте, что панели учета потерь конфиденциальности предупреждают, когда кумулятивное значение ε превышает установленные политические пороги. |    2    | D/V  |
| 11.3.2 | Проверьте, что аудиты конфиденциальности с использованием черного ящика оценивают ε̂ с точностью до 10% от заявленного значения.                |    2    |  V   |
| 11.3.3 | Проверьте, что формальные доказательства охватывают все дообучения и встраивания после обучения.                                                |    3    |  V   |

---

## 11.4 Ограничение целей и защита от расширения сферы применения

|   #    | Описание                                                                                                                                                   | Уровень | Роль |
| :----: | ---------------------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :--: |
| 11.4.1 | Убедитесь, что каждый набор данных и контрольная точка модели имеют машинно-читаемый тег назначения, соответствующий первоначальному согласию.             |    1    |  D   |
| 11.4.2 | Проверьте, что мониторинг времени выполнения обнаруживает запросы, не соответствующие заявленной цели, и вызывает мягкий отказ.                            |    1    | D/V  |
| 11.4.3 | Проверьте, что механизмы policy-as-code блокируют повторное развёртывание моделей в новых доменах без проведения обзора DPIA.                              |    3    |  D   |
| 11.4.4 | Подтвердите, что формальные доказательства трассируемости показывают, что весь жизненный цикл персональных данных остается в рамках согласованного объема. |    3    |  V   |

---

## 11.5 Управление согласием и отслеживание на законных основаниях

|   #    | Описание                                                                                                                                                             | Уровень | Роль |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :--: |
| 11.5.1 | Проверьте, что платформа управления согласием (Consent-Management Platform, CMP) фиксирует статус согласия, цель и срок хранения данных для каждого субъекта данных. |    1    | D/V  |
| 11.5.2 | Убедитесь, что API предоставляют токены согласия; модели должны проверять область действия токена перед выполнением инференса.                                       |    2    |  D   |
| 11.5.3 | Убедитесь, что отказ или отзыв согласия приостанавливает обработку данных в течение 24 часов.                                                                        |    2    | D/V  |

---

## 11.6 Федеративное обучение с контролем конфиденциальности

|   #    | Описание                                                                                                                     | Уровень | Роль |
| :----: | ---------------------------------------------------------------------------------------------------------------------------- | :-----: | :--: |
| 11.6.1 | Проверьте, что обновления клиента используют добавление шума с локальной дифференциальной приватностью перед агрегированием. |    1    |  D   |
| 11.6.2 | Проверьте, что метрики обучения являются дифференциально приватными и никогда не раскрывают потери отдельного клиента.       |    2    | D/V  |
| 11.6.3 | Убедитесь, что включена агрегация, устойчивая к отравлению (например, Krum/Trimmed-Mean).                                    |    2    |  V   |
| 11.6.4 | Проверьте, что формальные доказательства демонстрируют общий бюджет ε с потерей полезности менее 5.                          |    3    |  V   |

---

### Ссылки

* [GDPR & AI Compliance Best Practices](https://www.exabeam.com/explainers/gdpr-compliance/the-intersection-of-gdpr-and-ai-and-6-compliance-best-practices/)
* [EU Parliament Study on GDPR & AI, 2020](https://www.europarl.europa.eu/RegData/etudes/STUD/2020/641530/EPRS_STU%282020%29641530_EN.pdf)
* [ISO 31700-1:2023 — Privacy by Design for Consumer Products](https://www.iso.org/standard/84977.html)
* [NIST Privacy Framework 1.1 (2025 Draft)](https://www.nist.gov/privacy-framework)
* [Machine Unlearning: Right-to-Be-Forgotten Techniques](https://www.kaggle.com/code/tamlhp/machine-unlearning-the-right-to-be-forgotten)
* [A Survey of Machine Unlearning, 2024](https://arxiv.org/html/2209.02299v6)
* [Auditing DP-SGD — ArXiv 2024](https://arxiv.org/html/2405.14106v4)
* [DP-SGD Explained — PyTorch Blog](https://medium.com/pytorch/differential-privacy-series-part-1-dp-sgd-algorithm-explained-12512c3959a3)
* [Purpose-Limitation for AI — IJLIT 2025](https://academic.oup.com/ijlit/article/doi/10.1093/ijlit/eaaf003/8121663)
* [Data-Protection Considerations for AI — URM Consulting](https://www.urmconsulting.com/blog/data-protection-considerations-for-artificial-intelligence-ai)
* [Top Consent-Management Platforms, 2025](https://www.enzuzo.com/blog/best-consent-management-platforms)
* [Secure Aggregation in DP Federated Learning — ArXiv 2024](https://arxiv.org/abs/2407.19286)

