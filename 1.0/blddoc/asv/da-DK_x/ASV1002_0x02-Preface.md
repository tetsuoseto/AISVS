# Forord

Velkommen til Artificial Intelligence Security Verification Standard (AISVS) version 1.0!

## Introduktion

Etableret i 2025 gennem en samarbejdende fællesskabsindsats definerer AISVS de sikkerhedskrav, der skal overvejes ved design, udvikling, udrulning og drift af moderne AI-modeller, pipelines og AI-aktiverede tjenester.

AISVS v1.0 repræsenterer det samlede arbejde fra dets projektledere, arbejdsgruppe og bredere samfundsbidragydere for at skabe en pragmatisk, testbar baseline for sikring af AI-systemer.

Vores mål med denne udgivelse er at gøre AISVS let at tage i brug, samtidig med at vi forbliver laserskarpt fokuserede på dets definerede omfang og adresserer det hurtigt udviklende risikobillede, der er unikt for AI.

## Nøglemål for AISVS Version 1.0

Version 1.0 vil blive oprettet med flere vejledende principper.

### Veldefineret omfang

Hver krav skal stemme overens med AISVS’s navn og mission:

* Kunstig intelligens – Kontroller fungerer på AI/ML-laget (data, model, pipeline eller inferens) og er ansvaret for AI-praktikere.
* Sikkerhed – Kravene afhjælper direkte identificerede sikkerheds-, privatlivs- eller sikkerhedsrisici.
* Verifikation – Sproget er skrevet, så overensstemmelse kan valideres objektivt.
* Standard – Sektioner følger en konsekvent struktur og terminologi for at danne en sammenhængende reference.
  ​
---

Ved at følge AISVS kan organisationer systematisk evaluere og styrke sikkerhedspositionen for deres AI-løsninger og fremme en kultur for sikker AI-udvikling.

