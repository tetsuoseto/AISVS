# Forsideillustration

## Om standarden

Artificial Intelligence Security Verification Standard (AISVS) er en fællesskabsdrevet katalog over sikkerhedskrav, som dataforskere, MLOps-ingeniører, softwarearkitekter, udviklere, testere, sikkerhedsprofessionelle, leverandører af værktøjer, regulatorer og forbrugere kan bruge til at designe, udvikle, teste og verificere pålidelige AI-drevne systemer og applikationer. Det giver et fælles sprog til at specificere sikkerhedskontroller på tværs af AI-livscyklussen—fra dataindsamling og modeludvikling til implementering og løbende overvågning—så organisationer kan måle og forbedre modstandsdygtigheden, privatlivets fred og sikkerheden i deres AI-løsninger.

## Ophavsret og Licens

Version 0.1 (Første offentlige udkast - Under udarbejdelse), 2025  

![license](../images/license.png)

Copyright © 2025 The AISVS Project.  

Udgivet under the[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
For enhver genbrug eller distribution skal du tydeligt formidle licensbetingelserne for dette arbejde til andre.

## Projektledere

|            |                         |
| ---------- | ----------------------- |
| Jim Manico | Aras “Russ” Memisyazici |

## Bidragydere og anmeldere

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS er en helt ny standard, skabt specifikt til at håndtere de unikke sikkerhedsudfordringer i kunstige intelligenssystemer. Selvom den henter inspiration fra mere generelle sikkerhedsbedste praksis, er hvert krav i AISVS udviklet fra bunden for at afspejle trusselslandskabet inden for AI og hjælpe organisationer med at bygge sikrere, mere modstandsdygtige AI-løsninger.

