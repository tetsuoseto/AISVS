# Phụ lục A: Danh mục thuật ngữ

>This bảng chú giải toàn diện này cung cấp định nghĩa cho các thuật ngữ chủ chốt về AI, ML và an ninh được sử dụng xuyên suốt AISVS để đảm bảo sự rõ ràng và hiểu biết chung.

* Ví dụ đối kháng: Một đầu vào được thiết kế có chủ đích để làm cho một mô hình AI mắc lỗi, thường bằng cách thêm các biến đổi tinh vi mà con người khó nhận thấy.
  ​
* Adversarial Robustness – Độ bền adversarial trong AI đề cập đến khả năng của một mô hình duy trì hiệu suất và kháng lại việc bị lừa hoặc bị thao túng bởi các đầu vào được thiết kế có chủ ý, độc hại nhằm gây ra lỗi.
  ​
* Tác nhân AI – Các tác nhân AI là các hệ thống phần mềm sử dụng AI để theo đuổi mục tiêu và thực hiện các nhiệm vụ thay cho người dùng. Chúng thể hiện khả năng suy luận, lập kế hoạch và trí nhớ, và có một mức độ tự chủ để đưa ra quyết định, học hỏi và thích nghi.
  ​
* AI có tính chủ động: Các hệ thống AI có thể vận hành ở mức độ tự chủ nhất định để đạt được mục tiêu, thường đưa ra quyết định và thực hiện hành động mà không có sự can thiệp trực tiếp của con người.
  ​
* Kiểm soát truy cập dựa trên thuộc tính (ABAC): một mô hình kiểm soát truy cập trong đó quyết định cấp phép dựa trên các thuộc tính của người dùng, tài nguyên, hành động và môi trường, được đánh giá tại thời điểm truy vấn.
  ​
* Cuộc tấn công cửa hậu: Một loại tấn công đầu độc dữ liệu trong đó mô hình được huấn luyện để phản hồi theo một cách cụ thể đối với các kích hoạt nhất định trong khi hoạt động bình thường ở các trường hợp khác.
  ​
* Độ lệch: Các sai số có hệ thống trong đầu ra của mô hình trí tuệ nhân tạo (AI) có thể dẫn đến kết quả không công bằng hoặc mang tính phân biệt đối xử đối với một số nhóm hoặc trong các ngữ cảnh cụ thể.
  ​
* Khai thác thiên lệch: Một kỹ thuật tấn công tận dụng các thiên lệch được biết đến trong các mô hình AI để thao tác đầu ra hoặc kết quả.
  ​
* Cedar: ngôn ngữ chính sách và động cơ thực thi của Amazon cho quyền truy cập chi tiết được sử dụng để triển khai ABAC cho hệ thống AI.
  ​
* Chuỗi tư duy: một kỹ thuật nhằm cải thiện khả năng suy luận ở các mô hình ngôn ngữ bằng cách tạo ra các bước suy luận trung gian trước khi đưa ra câu trả lời cuối cùng.
  ​
* Cầu dao ngắt mạch: Các cơ chế tự động ngừng hoạt động của hệ thống AI khi ngưỡng rủi ro cụ thể bị vượt quá.
  ​
* Rò rỉ dữ liệu: Việc phơi bày ngoài ý muốn thông tin nhạy cảm thông qua đầu ra của mô hình AI hoặc hành vi.
  ​
* Đầu độc dữ liệu: Việc cố ý làm hỏng dữ liệu huấn luyện để làm suy yếu tính toàn vẹn của mô hình, thường nhằm cài đặt cổng sau hoặc làm giảm hiệu suất.
  ​
* Riêng tư vi phân – Riêng tư vi phân là một khuôn khổ toán học nghiêm ngặt để công bố thông tin thống kê về các tập dữ liệu đồng thời bảo vệ quyền riêng tư của các chủ thể dữ liệu cá nhân. Nó cho phép người nắm giữ dữ liệu chia sẻ các mẫu tổng hợp của nhóm trong khi giới hạn thông tin bị rò rỉ về từng cá nhân cụ thể.
  ​
* Nhúng: Các biểu diễn vectơ đặc của dữ liệu (văn bản, hình ảnh, v.v.) nắm bắt ý nghĩa ngữ nghĩa trong một không gian có nhiều chiều.
  ​
* Khả năng giải thích – Khả năng giải thích trong trí tuệ nhân tạo là khả năng của một hệ thống trí tuệ nhân tạo cung cấp các lý do có thể hiểu được bởi con người cho các quyết định và dự đoán của nó, đồng thời cung cấp cái nhìn sâu sắc về cách nó hoạt động nội tại.
  ​
* Trí tuệ nhân tạo có thể giải thích (XAI): Các hệ thống trí tuệ nhân tạo được thiết kế để cung cấp các lời giải thích dễ hiểu cho các quyết định và hành vi của chúng thông qua nhiều kỹ thuật và khuôn khổ khác nhau.
  ​
* Học liên kết phân tán: một phương pháp học máy trong đó các mô hình được huấn luyện trên nhiều thiết bị phi tập trung khác nhau chứa các mẫu dữ liệu cục bộ, mà không trao đổi dữ liệu với nhau.
  ​
* Rào chắn: Các ràng buộc được triển khai để ngăn các hệ thống trí tuệ nhân tạo (AI) sinh ra các đầu ra gây hại, thiên vị hoặc không mong muốn khác.
  ​
* Ảo giác – Ảo giác AI đề cập đến một hiện tượng mà một mô hình AI tạo ra thông tin không chính xác hoặc gây hiểu lầm, không dựa trên dữ liệu huấn luyện hoặc thực tế.
  ​
* Con người ở vòng lặp (HITL): Các hệ thống được thiết kế để yêu cầu sự giám sát, xác minh hoặc can thiệp của con người tại các điểm quyết định quan trọng.
  ​
* Cơ sở hạ tầng dưới dạng mã (IaC): Quản lý và cấp phát cơ sở hạ tầng thông qua mã thay vì các quy trình thủ công, cho phép quét bảo mật và triển khai nhất quán.
  ​
* Phá khóa: Các kỹ thuật được sử dụng để vượt qua các rào chắn an toàn trong hệ thống AI, đặc biệt là trong các mô hình ngôn ngữ lớn, nhằm tạo ra nội dung bị cấm.
  ​
* Nguyên tắc tối thiểu quyền truy cập: là nguyên tắc bảo mật cấp phát đúng các quyền truy cập tối thiểu cần thiết cho người dùng và các tiến trình.
  ​
* LIME (Local Interpretable Model-agnostic Explanations): Một kỹ thuật để giải thích các dự đoán của bất kỳ bộ phân loại học máy nào bằng cách xấp xỉ nó ở phạm vi cục bộ bằng một mô hình có thể giải thích được.
  ​
* Tấn công suy luận thành viên: Một cuộc tấn công nhằm xác định xem một điểm dữ liệu cụ thể có được sử dụng để huấn luyện một mô hình học máy hay không.
  ​
* MITRE ATLAS: Cảnh đe dọa đối kháng cho Artificial-Intelligence Systems; một cơ sở tri thức về các chiến thuật và kỹ thuật đối kháng nhắm vào AI systems.
  ​
* Model Card – Thẻ mô hình là một tài liệu cung cấp thông tin chuẩn hóa về hiệu suất, giới hạn, mục đích sử dụng và những cân nhắc đạo đức của một mô hình AI nhằm thúc đẩy tính minh bạch và phát triển AI có trách nhiệm.
  ​
* Trích xuất mô hình: một cuộc tấn công trong đó kẻ tấn công liên tục truy vấn một mô hình mục tiêu để tạo ra một bản sao có chức năng tương tự mà không được phép.
  ​
* Đảo ngược mô hình: một cuộc tấn công nhằm khôi phục dữ liệu huấn luyện bằng cách phân tích đầu ra của mô hình.
  ​
* Quản lý vòng đời mô hình – Quản lý vòng đời mô hình AI là quá trình giám sát tất cả các giai đoạn tồn tại của một mô hình AI, bao gồm thiết kế, phát triển, triển khai, giám sát, bảo trì và sự nghỉ hưu cuối cùng, nhằm đảm bảo nó vẫn hoạt động hiệu quả và phù hợp với mục tiêu.
  ​
* Đầu độc mô hình: Tạo ra các lỗ hổng hoặc cửa hậu trực tiếp vào một mô hình trong quá trình huấn luyện.
  ​
* Đánh cắp mô hình: Lấy sao chép hoặc ước lượng của một mô hình độc quyền thông qua các truy vấn lặp lại.
  ​
* Hệ thống đa tác nhân: một hệ thống được tạo thành từ nhiều tác nhân AI tương tác với nhau, mỗi tác nhân có thể có các khả năng và mục tiêu khác nhau.
  ​
* OPA (Open Policy Agent): một động cơ thực thi chính sách nguồn mở cho phép thực thi chính sách thống nhất trên toàn bộ ngăn xếp.
  ​
* Học máy bảo vệ quyền riêng tư (PPML): Các kỹ thuật và phương pháp để huấn luyện và triển khai các mô hình học máy trong khi bảo vệ quyền riêng tư của dữ liệu huấn luyện.
  ​
* Tiêm prompt: Một cuộc tấn công trong đó các chỉ dẫn độc hại được nhúng vào đầu vào để vượt qua hành vi được dự định của mô hình.
  ​
* RAG (Retrieval-Augmented Generation): một kỹ thuật nâng cao các mô hình ngôn ngữ lớn bằng cách truy xuất thông tin liên quan từ các nguồn kiến thức bên ngoài trước khi tạo ra một câu trả lời.
  ​
* Đội đỏ (Red-Teaming): Là thực hành kiểm thử tích cực các hệ thống AI bằng cách mô phỏng các cuộc tấn công có chủ ý nhằm xác định các lỗ hổng.
  ​
* SBOM (Danh sách thành phần phần mềm): Một hồ sơ chính thức chứa chi tiết và mối quan hệ chuỗi cung ứng của các thành phần khác nhau được sử dụng để xây dựng phần mềm hoặc các mô hình AI.
  ​
* SHAP (SHapley Additive exPlanations): Một phương pháp dựa trên lý thuyết trò chơi để giải thích đầu ra của bất kỳ mô hình học máy nào bằng cách tính đóng góp của từng đặc trưng cho dự đoán.
  ​
* Tấn công chuỗi cung ứng: Xâm phạm một hệ thống bằng cách nhắm vào các thành phần ít an toàn hơn trong chuỗi cung ứng của nó, chẳng hạn như thư viện bên thứ ba, tập dữ liệu, hoặc các mô hình được huấn luyện trước.
  ​
* Học chuyển giao: Một kỹ thuật trong đó một mô hình được phát triển cho một nhiệm vụ ban đầu được tái sử dụng làm điểm khởi đầu cho một mô hình cho một nhiệm vụ thứ hai.
  ​
* Cơ sở dữ liệu vector: Một cơ sở dữ liệu chuyên dụng được thiết kế để lưu trữ các vector có nhiều chiều (vector nhúng) và thực hiện các phép tìm kiếm theo độ tương đồng một cách hiệu quả.
  ​
* Quét lỗ hổng bảo mật: Các công cụ tự động xác định các lỗ hổng bảo mật đã biết trong các thành phần phần mềm, bao gồm khung AI và các phụ thuộc.
  ​
* Dấu nước: Các kỹ thuật nhúng dấu nước vô hình vào nội dung do AI tạo ra nhằm theo dõi nguồn gốc hoặc phát hiện nội dung được AI tạo ra.
  ​
* Zero-Day Vulnerability: Một lỗ hổng chưa được biết đến trước đó mà kẻ tấn công có thể khai thác trước khi nhà phát triển tạo và triển khai bản vá.

