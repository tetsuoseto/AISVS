# Phụ lục A: Bảng chú giải thuật ngữ

Bảng thuật ngữ toàn diện này cung cấp các định nghĩa về các thuật ngữ chính trong AI, ML và bảo mật được sử dụng trong toàn bộ AISVS để đảm bảo sự rõ ràng và hiểu biết chung.

* Ví dụ đối nghịch: Một đầu vào được tạo ra cố ý để khiến mô hình AI mắc lỗi, thường bằng cách thêm các nhiễu nhỏ tinh vi mà con người không thể nhận thấy.
  ​
* Độ bền vững chống đối – Độ bền vững chống đối trong AI đề cập đến khả năng của một mô hình duy trì hiệu suất và chống lại việc bị lừa hoặc thao túng bởi các đầu vào độc hại được tạo ra có chủ ý nhằm gây ra lỗi.
  ​
* Agent – Các tác nhân AI là các hệ thống phần mềm sử dụng AI để theo đuổi mục tiêu và hoàn thành các nhiệm vụ thay mặt người dùng. Chúng thể hiện khả năng suy luận, lập kế hoạch và nhớ, đồng thời có mức độ tự chủ để đưa ra quyết định, học hỏi và thích nghi.
  ​
* AI tác nhân: Các hệ thống AI có thể hoạt động với một mức độ tự chủ nhất định để đạt được mục tiêu, thường đưa ra quyết định và thực hiện hành động mà không cần sự can thiệp trực tiếp của con người.
  ​
* Kiểm soát truy cập dựa trên thuộc tính (ABAC): Một mô hình kiểm soát truy cập trong đó các quyết định ủy quyền dựa trên thuộc tính của người dùng, tài nguyên, hành động và môi trường, được đánh giá tại thời điểm truy vấn.
  ​
* Tấn công Cửa hậu: Một loại tấn công đầu độc dữ liệu trong đó mô hình được huấn luyện để phản hồi theo một cách cụ thể đối với các kích hoạt nhất định trong khi hành xử bình thường trong các trường hợp khác.
  ​
* Thiên lệch: Lỗi hệ thống trong đầu ra của mô hình AI có thể dẫn đến kết quả không công bằng hoặc phân biệt đối xử đối với một số nhóm hoặc trong các bối cảnh cụ thể.
  ​
* Khai thác Định kiến: Một kỹ thuật tấn công tận dụng các định kiến đã biết trong các mô hình AI để thao túng đầu ra hoặc kết quả.
  ​
* Cedar: Ngôn ngữ chính sách và công cụ của Amazon để cấp quyền chi tiết được sử dụng trong việc triển khai ABAC cho các hệ thống AI.
  ​
* Chuỗi Tư duy: Một kỹ thuật để cải thiện khả năng suy luận trong các mô hình ngôn ngữ bằng cách tạo ra các bước suy luận trung gian trước khi đưa ra câu trả lời cuối cùng.
  ​
* Cầu dao tự động: Cơ chế tự động dừng hoạt động của hệ thống AI khi vượt quá ngưỡng rủi ro nhất định.
  ​
* Rò rỉ dữ liệu: Tiếp xúc không mong muốn của thông tin nhạy cảm thông qua các kết quả hoặc hành vi của mô hình AI.
  ​
* Đầu độc dữ liệu: Việc cố ý làm hỏng dữ liệu huấn luyện nhằm làm suy yếu tính toàn vẹn của mô hình, thường để cài đặt cửa hậu hoặc làm giảm hiệu suất.
  ​
* Bảo mật vi phân – Bảo mật vi phân là một khuôn khổ toán học nghiêm ngặt để công bố thông tin thống kê về các tập dữ liệu trong khi bảo vệ quyền riêng tư của các cá nhân trong dữ liệu. Nó cho phép người giữ dữ liệu chia sẻ các mẫu tổng hợp của nhóm đồng thời hạn chế việc rò rỉ thông tin về các cá nhân cụ thể.
  ​
* Embeddings: Biểu diễn vectơ dày đặc của dữ liệu (văn bản, hình ảnh, v.v.) chứa đựng ý nghĩa ngữ nghĩa trong không gian đa chiều.
  ​
* Khả năng giải thích – Khả năng giải thích trong AI là khả năng của một hệ thống AI để cung cấp các lý do mà con người có thể hiểu được cho các quyết định và dự đoán của nó, cung cấp cái nhìn sâu sắc về cách hoạt động nội bộ của nó.
  ​
* AI giải thích được (XAI): Các hệ thống AI được thiết kế để cung cấp các giải thích dễ hiểu cho con người về các quyết định và hành vi của chúng thông qua nhiều kỹ thuật và khuôn khổ khác nhau.
  ​
* Học Liên Phân Tán: Một phương pháp học máy trong đó các mô hình được đào tạo trên nhiều thiết bị phi tập trung giữ các mẫu dữ liệu cục bộ, mà không trao đổi dữ liệu trực tiếp.
  ​
* Guardrails: Các giới hạn được thực hiện để ngăn các hệ thống AI tạo ra các kết quả đầu ra gây hại, thiên vị hoặc không mong muốn khác.
  ​
* Ảo giác – Ảo giác AI là hiện tượng khi một mô hình AI tạo ra thông tin sai lệch hoặc gây hiểu lầm không dựa trên dữ liệu đào tạo hoặc thực tế khách quan.
  ​
* Con người trong vòng lặp (Human-in-the-Loop - HITL): Các hệ thống được thiết kế để yêu cầu sự giám sát, xác minh hoặc can thiệp của con người tại các điểm quyết định quan trọng.
  ​
* Hạ tầng dưới dạng mã (IaC): Quản lý và cung cấp hạ tầng thông qua mã thay vì các quy trình thủ công, cho phép quét bảo mật và triển khai nhất quán.
  ​
* Jailbreak: Kỹ thuật được sử dụng để vượt qua các rào cản an toàn trong hệ thống AI, đặc biệt là trong các mô hình ngôn ngữ lớn, nhằm tạo ra nội dung bị cấm.
  ​
* Nguyên tắc Quyền ít nhất: Nguyên tắc bảo mật chỉ cấp quyền truy cập tối thiểu cần thiết cho người dùng và các tiến trình.
  ​
* LIME (Giải thích Mô hình Độc lập cục bộ): Một kỹ thuật để giải thích các dự đoán của bất kỳ bộ phân loại học máy nào bằng cách xấp xỉ chúng tại chỗ với một mô hình có thể giải thích được.
  ​
* Tấn công suy luận thành viên: Một cuộc tấn công nhằm xác định liệu một điểm dữ liệu cụ thể có được sử dụng để huấn luyện mô hình học máy hay không.
  ​
* MITRE ATLAS: Cảnh quan mối đe dọa đối kháng cho hệ thống Trí tuệ Nhân tạo; một cơ sở kiến thức về các chiến thuật và kỹ thuật đối kháng chống lại hệ thống AI.
  ​
* Thẻ Mô Hình – Thẻ mô hình là một tài liệu cung cấp thông tin chuẩn hóa về hiệu suất, giới hạn, mục đích sử dụng và các cân nhắc đạo đức của mô hình AI nhằm thúc đẩy sự minh bạch và phát triển AI có trách nhiệm.
  ​
* Trích xuất mô hình: Một cuộc tấn công trong đó kẻ tấn công liên tục truy vấn một mô hình mục tiêu để tạo ra một bản sao có chức năng tương tự mà không được phép.
  ​
* Đảo ngược mô hình: Một cuộc tấn công cố gắng tái tạo dữ liệu huấn luyện bằng cách phân tích kết quả đầu ra của mô hình.
  ​
* Quản lý Vòng đời Mô hình – Quản lý vòng đời mô hình AI là quá trình giám sát tất cả các giai đoạn tồn tại của một mô hình AI, bao gồm thiết kế, phát triển, triển khai, giám sát, bảo trì và cuối cùng là ngừng sử dụng, nhằm đảm bảo mô hình luôn hiệu quả và phù hợp với các mục tiêu đề ra.
  ​
* Đầu độc mô hình: Giới thiệu lỗ hổng hoặc cánh cửa sau trực tiếp vào mô hình trong quá trình huấn luyện.
  ​
* Đánh cắp/Mô hình ăn cắp: Trích xuất một bản sao hoặc bản gần đúng của mô hình độc quyền thông qua các truy vấn lặp đi lặp lại.
  ​
* Hệ thống đa tác nhân: Một hệ thống gồm nhiều tác nhân AI tương tác với nhau, mỗi tác nhân có thể có các khả năng và mục tiêu khác nhau.
  ​
* OPA (Open Policy Agent): Một công cụ chính sách mã nguồn mở cho phép thi hành chính sách thống nhất trên toàn bộ hệ thống.
  ​
* Học Máy Bảo Vệ Quyền Riêng Tư (PPML): Các kỹ thuật và phương pháp để huấn luyện và triển khai mô hình ML đồng thời bảo vệ quyền riêng tư của dữ liệu huấn luyện.
  ​
* Chèn lệnh vào lời nhắc: Một cuộc tấn công trong đó các chỉ dẫn độc hại được nhúng vào đầu vào để ghi đè hành vi dự định của mô hình.
  ​
* RAG (Tạo sinh tăng cường truy xuất): Một kỹ thuật nâng cao các mô hình ngôn ngữ lớn bằng cách truy xuất thông tin liên quan từ các nguồn kiến thức bên ngoài trước khi tạo ra phản hồi.
  ​
* Red-Teaming: Thực hành kiểm thử chủ động các hệ thống AI bằng cách mô phỏng các cuộc tấn công đối kháng nhằm xác định các điểm yếu.
  ​
* SBOM (Danh sách thành phần phần mềm): Một bản ghi chính thức chứa các chi tiết và mối quan hệ chuỗi cung ứng của các thành phần khác nhau được sử dụng trong việc xây dựng phần mềm hoặc mô hình AI.
  ​
* SHAP (Giải thích Cộng thêm Shapley): Một phương pháp lý thuyết trò chơi để giải thích kết quả của bất kỳ mô hình học máy nào bằng cách tính toán đóng góp của mỗi đặc trưng vào dự đoán.
  ​
* Tấn công chuỗi cung ứng: Xâm nhập hệ thống bằng cách nhắm vào các yếu tố bảo mật kém hơn trong chuỗi cung ứng của nó, chẳng hạn như thư viện bên thứ ba, bộ dữ liệu hoặc mô hình đã được huấn luyện sẵn.
  ​
* Học chuyển giao: Một kỹ thuật trong đó một mô hình được phát triển cho một nhiệm vụ được sử dụng lại làm điểm khởi đầu cho một mô hình cho nhiệm vụ thứ hai.
  ​
* Cơ sở dữ liệu vector: Một cơ sở dữ liệu chuyên biệt được thiết kế để lưu trữ các vector đa chiều cao (embedding) và thực hiện các tìm kiếm tương đồng hiệu quả.
  ​
* Quét Lỗ Hổng Bảo Mật: Công cụ tự động xác định các lỗ hổng bảo mật đã biết trong các thành phần phần mềm, bao gồm cả khung AI và các phụ thuộc.
  ​
* Đóng dấu bản quyền: Các kỹ thuật nhúng các dấu hiệu không thể nhận biết vào nội dung do AI tạo ra để theo dõi nguồn gốc hoặc phát hiện nội dung được tạo bởi AI.
  ​
* Lỗ hổng Zero-Day: Một lỗ hổng chưa được biết đến trước đó mà kẻ tấn công có thể khai thác trước khi các nhà phát triển tạo và triển khai bản vá.

