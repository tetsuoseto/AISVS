# Lời tựa

Chào mừng đến với Tiêu chuẩn Xác minh An ninh Trí tuệ Nhân tạo (AISVS) phiên bản 1.0!

## Giới thiệu

Được thành lập vào năm 2025 thông qua nỗ lực hợp tác của cộng đồng, AISVS định nghĩa các yêu cầu bảo mật cần xem xét khi thiết kế, phát triển, triển khai và vận hành các mô hình AI hiện đại, các pipeline AI, và các dịch vụ có AI tích hợp.

AISVS v1.0 đại diện cho sự phối hợp công việc của các lãnh đạo dự án, nhóm làm việc và các đóng góp từ cộng đồng rộng lớn nhằm tạo ra một chuẩn nền thiết thực, có thể kiểm chứng để đảm bảo an toàn cho các hệ thống AI.

Mục tiêu của bản phát hành này là làm cho AISVS dễ tiếp nhận và áp dụng, đồng thời duy trì sự tập trung tuyệt đối vào phạm vi được định nghĩa và đối phó với bối cảnh rủi ro đang diễn biến nhanh, đặc thù của trí tuệ nhân tạo (AI).

## Các mục tiêu chính cho AISVS Phiên bản 1.0

Phiên bản 1.0 sẽ được xây dựng dựa trên một số nguyên tắc chỉ đạo.

### Phạm vi được xác định rõ

Mỗi yêu cầu phải phù hợp với tên và sứ mệnh của AISVS:

* Trí tuệ nhân tạo – Các biện pháp kiểm soát hoạt động ở lớp AI/ML (dữ liệu, mô hình, pipeline hoặc suy diễn) và là trách nhiệm của những người thực hành AI.
* Bảo mật – Yêu cầu trực tiếp giảm thiểu các rủi ro về bảo mật, quyền riêng tư hoặc an toàn đã được xác định.
* Xác minh – Ngôn ngữ được viết sao cho sự tuân thủ có thể được xác thực một cách khách quan.
* Tiêu chuẩn – Các phần tuân theo một cấu trúc và thuật ngữ nhất quán để hình thành một tham chiếu mạch lạc.
  ​
---

Thông qua AISVS, các tổ chức có thể đánh giá một cách có hệ thống và tăng cường trạng thái bảo mật cho các giải pháp AI của họ, từ đó thúc đẩy một văn hóa kỹ thuật AI an toàn.

