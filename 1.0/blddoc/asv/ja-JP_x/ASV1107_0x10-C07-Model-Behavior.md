# C7 モデルの挙動、出力制御と安全性保証

## 統制目標

モデルの出力は、本番環境で構造化され、信頼性が高く、安全で、説明可能で、継続的に監視されなければならない。これにより、幻覚、プライバシー漏洩、有害なコンテンツ、暴走行動を低減し、同時にユーザーの信頼と規制遵守を高める。

---

## C7.1 出力フォーマットの遵守

厳格なスキーマ、制約付きデコード、下流の検証により、形式が不正な内容や悪意のある内容が伝搬する前に停止します。

|   #   | 説明                                                                                    | レベル | 役割  |
| :---: | ------------------------------------------------------------------------------------- | :-: | :-: |
| 7.1.1 | レスポンススキーマ（例：JSONスキーマ）がシステムプロンプトに含まれていることを確認し、すべての出力が自動的に検証されます。準拠していない出力は修正または拒否されます。 |  1  | D/V |
| 7.1.2 | 制約付きデコード（ストップトークン、正規表現、max-tokens）が有効になっていることを検証し、オーバーフローやプロンプトインジェクションによるサイドチャネルを防ぐ。 |  1  | D/V |
| 7.1.3 | 下流のコンポーネントが出力を信頼できないものとして扱い、スキーマに対して検証するか、インジェクション耐性のあるデシリアライザで検証することを確認する。           |  2  | D/V |
| 7.1.4 | 不適切な出力イベントがログに記録され、レート制限され、監視に通知されることを検証する。                                           |  3  |  V  |

---

## C7.2 幻覚検出と対策

不確実性推定とフォールバック戦略は、捏造された回答を抑制する。

|   #   | 説明                                                                           | レベル | 役割  |
| :---: | ---------------------------------------------------------------------------- | :-: | :-: |
| 7.2.1 | トークンレベルの対数確率、アンサンブル自己整合性、またはファインチューニングされた幻覚検出器が各回答に対して信頼度スコアを割り当てていることを検証する。 |  1  | D/V |
| 7.2.2 | 設定可能な信頼度閾値を下回る応答がフォールバックワークフローをトリガーすることを検証します（例：検索補助生成、二次モデル、または人間によるレビュー）。  |  1  | D/V |
| 7.2.3 | 幻覚事象が根本原因メタデータでタグ付けされ、ポストモーテムおよびファインチューニングのパイプラインに投入されることを検証する。              |  2  | D/V |
| 7.2.4 | 主要なモデルまたは知識ベースの更新後に、閾値と検出器が再校正されていることを確認する。                                  |  3  | D/V |
| 7.2.5 | ダッシュボードの可視化が幻覚率を追跡していることを検証してください。                                           |  3  |  V  |

---

## C7.3 出力の安全性とプライバシー保護フィルタリング

ポリシー フィルターとレッドチームのカバレッジは、ユーザーと機密データを保護します。

|   #   | 説明                                                               | レベル | 役割  |
| :---: | ---------------------------------------------------------------- | :-: | :-: |
| 7.3.1 | 生成前および生成後の分類器が、ポリシーに沿って憎悪・嫌がらせ・自傷・過激主義・性的露骨なコンテンツをブロックすることを検証する。 |  1  | D/V |
| 7.3.2 | すべての応答でPII/PCI検出と自動伏字化が実行されることを検証する。違反はプライバシーインシデントを引き起こす。       |  1  | D/V |
| 7.3.3 | 機密性タグ（例：営業秘密）がモダリティ間で伝播することを検証し、テキスト、画像、またはコードにおける漏洩を防ぐ。         |  2  |  D  |
| 7.3.4 | フィルター回避の試みまたは高リスク分類が二次承認またはユーザーの再認証を必要とすることを検証します。               |  3  | D/V |
| 7.3.5 | フィルタリングの閾値が法域およびユーザーの年齢・役割の文脈を反映していることを検証する。                     |  3  | D/V |

---

## C7.4 出力とアクションの制限

レート制限と承認ゲートは、悪用と過度な自律性を防ぎます。

|   #   | 説明                                                                                 | レベル | 役割  |
| :---: | ---------------------------------------------------------------------------------- | :-: | :-: |
| 7.4.1 | 各ユーザーごとおよび APIキーごとのクォータが、429エラー時に指数バックオフを用いて、リクエスト数、トークン数、コストを制限することを検証します。        |  1  |  D  |
| 7.4.2 | 特権操作（ファイルの書き込み、コードの実行、ネットワーク呼び出し）がポリシーに基づく承認または人間の介在を必要とすることを確認してください。             |  1  | D/V |
| 7.4.3 | 同じリクエストに対して生成された画像、コード、およびテキストが、クロスモーダルの整合性チェックによって悪意のある内容をすり抜けて使用されることがないことを検証する。 |  2  | D/V |
| 7.4.4 | エージェント委任の深さ、再帰の上限、および許可されたツールのリストが明示的に設定されていることを確認する。                              |  2  |  D  |
| 7.4.5 | 制限違反がSIEM取り込みのために構造化されたセキュリティイベントを出力することを検証する。                                     |  3  |  V  |

---

## C7.5 出力の説明可能性

透明性のあるシグナルは、ユーザーの信頼と内部デバッグを向上させる。

|   #   | 説明                                                            | レベル | 役割  |
| :---: | ------------------------------------------------------------- | :-: | :-: |
| 7.5.1 | リスク評価が適切と判断された場合に、ユーザーに表示される信頼度スコアや簡易推論の要約が適切に提供されることを検証する。   |  2  | D/V |
| 7.5.2 | 生成された説明が、機密のシステムプロンプトや専有データを開示していないことを確認する。                   |  2  | D/V |
| 7.5.3 | システムがトークンレベルの対数確率またはアテンションマップを取得し、それらを認可済みの監査のために保存することを検証する。 |  3  |  D  |
| 7.5.4 | 監査可能性のために、説明可能性のアーティファクトがモデルのリリースと並行してバージョン管理されていることを確認する。    |  3  |  V  |

---

## C7.6 モニタリング統合

リアルタイムの可観測性は、開発と本番環境の間のループを閉じる。

|   #   | 説明                                                                  | レベル | 役割  |
| :---: | ------------------------------------------------------------------- | :-: | :-: |
| 7.6.1 | メトリクス（スキーマ違反、幻覚率、有害性、PII漏洩、レイテンシ、コスト）が中央監視プラットフォームへ送信されることを検証する。    |  1  |  D  |
| 7.6.2 | 各安全指標について、アラート閾値が定義されていることを確認し、オンコール時のエスカレーション経路を整備する。              |  1  |  V  |
| 7.6.3 | ダッシュボードが、出力の異常とモデル/バージョン、機能フラグ、および上流データの変更と相関していることを確認してください。       |  2  |  V  |
| 7.6.4 | 監視データが文書化されたMLOpsワークフロー内で再訓練、ファインチューニング、またはルール更新へフィードバックされることを検証する。 |  2  | D/V |
| 7.6.5 | 機密ログの漏洩を防ぐため、監視パイプラインがペネトレーションテストを受け、アクセス制御が適切に行われていることを検証する。       |  3  |  V  |

---

## 7.7 生成系メディアの安全対策

AIシステムが違法・有害・または許可されていないメディアコンテンツを生成しないよう、ポリシー制約の適用、出力検証、トレーサビリティの確保を通じて保証する。

|   #   | 説明                                                                                            | レベル | 役割  |
| :---: | --------------------------------------------------------------------------------------------- | :-: | :-: |
| 7.7.1 | システムプロンプトとユーザー指示が、違法・有害・同意を得ていないディープフェイクメディア（例：画像、動画、音声）の生成を明示的に禁止していることを確認してください。            |  1  | D/V |
| 7.7.2 | プロンプトが、なりすましの試み、性的に露骨なディープフェイク、または同意なしに実在の人物を描写する媒体の生成を試みるものをフィルタリングしていることを確認する。              |  2  | D/V |
| 7.7.3 | システムが知覚ハッシュ、透かし検出、またはフィンガープリントを用いて、著作権で保護されたメディアの不正な複製を防止していることを確認してください。                     |  2  |  V  |
| 7.7.4 | 下流のトレーサビリティを確保するために、生成されたすべてのメディアが暗号署名が付与されている、透かしが施されている、または改ざん耐性のある出所メタデータが埋め込まれていることを確認する。 |  3  | D/V |
| 7.7.5 | バイパス試行（例：プロンプトの難読化、スラング、敵対的な表現）が検出され、記録され、レート制限されることを検証する。繰り返される乱用は監視システムに報告される。              |  3  |  V  |

## 参考文献

* [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)
* [ISO/IEC 42001:2023 – AI Management System](https://www.iso.org/obp/ui/en/)
* [OWASP Top-10 for Large Language Model Applications (2025)](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Improper Output Handling – OWASP LLM05:2025](https://genai.owasp.org/llmrisk/llm052025-improper-output-handling/)
* [Practical Techniques to Constrain LLM Output](https://mychen76.medium.com/practical-techniques-to-constraint-llm-output-in-json-format-e3e72396c670)
* [Dataiku – Structured Text Generation Guide](https://blog.dataiku.com/your-guide-to-structured-text-generation)
* [VL-Uncertainty: Detecting Hallucinations](https://arxiv.org/abs/2411.11919)
* [HaDeMiF: Hallucination Detection & Mitigation](https://openreview.net/forum?id=VwOYxPScxB)
* [Building Confidence in LLM Outputs](https://www.alkymi.io/data-science-room/building-confidence-in-llm-outputs)
* [Explainable AI & LLMs](https://duncsand.medium.com/explainable-ai-140912d31b3b)
* [LLM Red-Teaming Guide](https://www.confident-ai.com/blog/red-teaming-llms-a-step-by-step-guide)
* [Sensitive Information Disclosure in LLMs](https://virtualcyberlabs.com/llm-sensitive-information-disclosure/)
* [LangChain – Chat Model Rate Limiting](https://python.langchain.com/docs/how_to/chat_model_rate_limiting/)
* [OpenAI Rate-Limit & Exponential Back-off](https://hackernoon.com/openais-rate-limit-a-guide-to-exponential-backoff-for-llm-evaluation)
* [Arize AI – LLM Observability Platform](https://arize.com/)

