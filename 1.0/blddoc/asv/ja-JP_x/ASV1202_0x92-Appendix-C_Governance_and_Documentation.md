# 付録C: AI セキュリティ ガバナンスとドキュメンテーション

## 目的

この付録は、システムライフサイクル全体にわたるAIセキュリティを管理するための組織構造、方針、およびプロセスを確立するための基礎的要件を提供します。

---

## AC.1 AIリスク管理フレームワークの採用

システムライフサイクル全体にわたり、AI固有のリスクを特定、評価、および軽減するための正式なフレームワークを提供する。

|   #    | 説明                                                    | レベル | 役割  |
| :----: | ----------------------------------------------------- | :-: | :-: |
| AC.1.1 | AI固有のリスク評価方法論が文書化され、実施されていることを確認してください。               |  1  | D/V |
| AC.1.2 | AIライフサイクルの重要なポイントおよび重要な変更の前にリスク評価が実施されていることを確認してください。 |  2  |  D  |
| AC.1.3 | リスク管理フレームワークが確立された基準（例：NIST AI RMF）と一致していることを確認する。    |  3  | D/V |

---

## AC.2 AI セキュリティポリシーと手順

安全なAIの開発、展開、および運用のための組織基準を定義し、それを実施する。

|   #    | 説明                                                       | レベル | 役割  |
| :----: | -------------------------------------------------------- | :-: | :-: |
| AC.2.1 | 文書化されたAIセキュリティポリシーが存在することを確認してください。                      |  1  | D/V |
| AC.2.2 | ポリシーが少なくとも年に一度、および重大な脅威状況の変化後にレビューされ、更新されていることを確認してください。 |  2  |  D  |
| AC.2.3 | ポリシーがすべてのAISVSカテゴリおよび適用される規制要件を網羅していることを確認してください。        |  3  | D/V |

---

## AC.3 AIセキュリティの役割と責任

組織全体でAIセキュリティに対する明確な責任体制を確立する。

|   #    | 説明                                                     | レベル | 役割  |
| :----: | ------------------------------------------------------ | :-: | :-: |
| AC.3.1 | AIセキュリティの役割と責任が文書化されていることを確認してください。                    |  1  | D/V |
| AC.3.2 | 責任者が適切なセキュリティ専門知識を持っていることを確認してください。                    |  2  |  D  |
| AC.3.3 | 高リスクのAIシステムに対して、AI倫理委員会またはガバナンス委員会が設立されていることを確認してください。 |  3  | D/V |

---

## AC.4 倫理的なAIガイドラインの施行

AIシステムが確立された倫理原則に従って運用されることを確保する。

|   #    | 説明                                             | レベル | 役割  |
| :----: | ---------------------------------------------- | :-: | :-: |
| AC.4.1 | AI開発および展開のための倫理ガイドラインが存在することを確認する。             |  1  | D/V |
| AC.4.2 | 倫理違反を検出し報告するための仕組みが整っていることを確認してください。           |  2  |  D  |
| AC.4.3 | 展開されたAIシステムに対して定期的な倫理的レビューが実施されていることを確認してください。 |  3  | D/V |

---

## AC.5 AI規制コンプライアンス監視

進化するAI規制に対する認識と準拠を維持すること。

|   #    | 説明                                     | レベル | 役割  |
| :----: | -------------------------------------- | :-: | :-: |
| AC.5.1 | 適用されるAI規制を特定するためのプロセスが存在することを確認してください。 |  1  | D/V |
| AC.5.2 | すべての規制要件の遵守状況が評価されていることを確認してください。      |  2  |  D  |
| AC.5.3 | 規制の変更がAIシステムの適時なレビューと更新を引き起こすことを確認する。  |  3  | D/V |

## AC.6 トレーニングデータのガバナンス、文書化およびプロセス

|   #    | 説明                                                                                                                                           | レベル | 役割  |        |                                                                         |     |     |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: | ------ | ----------------------------------------------------------------------- | --- | --- |
| 1.1.2  | 品質、代表性、倫理的調達、およびライセンス遵守のために精査されたデータセットのみを許可し、データの汚染、埋め込みバイアス、および知的財産権侵害のリスクを低減することを検証します。                                                    |  1  | D/V |        |                                                                         |     |     |
| 1.1.5  | レビューアーのクロスチェックまたはコンセンサスによってラベリング／アノテーションの品質が確保されていることを確認してください。                                                                              |  2  | D/V |        |                                                                         |     |     |
| 1.1.6  | 重要なトレーニングデータセットについて、「データカード」または「データセット用データシート」が維持されていることを確認し、それらに特性、動機、構成、収集プロセス、前処理、および推奨される／推奨されない使用方法が詳細に記載されていることを確認してください。              |  2  | D/V |        |                                                                         |     |     |
| 1.3.2  | 特定されたバイアスが、再バランス、ターゲットを絞ったデータ増強、アルゴリズム調整（例：前処理、処理中、後処理技術）、または再重み付けなどの文書化された戦略を通じて軽減されていることを検証し、軽減策が公平性およびモデル全体のパフォーマンスに与える影響を評価すること。         |  2  | D/V |        |                                                                         |     |     |
| 1.3.3  | トレーニング後の公平性指標が評価され、文書化されていることを確認してください。                                                                                                      |  2  | D/V |        |                                                                         |     |     |
| 1.3.4  | ライフサイクルバイアスマネジメントポリシーが所有者とレビュー頻度を割り当てていることを確認してください。                                                                                         |  3  | D/V |        |                                                                         |     |     |
| 1.4.1  | ラベリング／アノテーションの品質が、明確なガイドライン、レビュワーによる相互確認、コンセンサスメカニズム（例：アノテーター間の一致を監視すること）、および不一致を解決するための定義されたプロセスを通じて確保されていることを確認してください。                     |  2  | D/V |        |                                                                         |     |     |
| 1.4.4  | 安全性、セキュリティ、または公正性にとって重要なラベル（例：有害なコンテンツの識別、重要な医療所見）が、必須の独立した二重レビューまたは同等の堅牢な検証を受けていることを確認してください。                                               |  3  | D/V |        |                                                                         |     |     |
| 1.4.6  | ラベリングガイドと指示が包括的で、バージョン管理されており、ピアレビューされていることを確認してください。                                                                                        |  2  | D/V |        |                                                                         |     |     |
| 1.4.6  | ラベルのデータスキーマが明確に定義され、バージョン管理されていることを確認してください。                                                                                                 |  2  | D/V |        |                                                                         |     |     |
| 1.3.1  | データセットが、法的に保護された属性（例：人種、性別、年齢）およびモデルの適用領域に関連するその他の倫理的に敏感な特性（例：社会経済的地位、所在地）に関して、表現の不均衡や潜在的なバイアスについてプロファイリングされていることを確認してください。                  |  1  | D/V |        |                                                                         |     |     |
| 1.5.3  | 自動化では検出できない微細な品質問題を特定するために、ドメイン専門家によるマニュアルのスポットチェックが統計的に有意なサンプル（例：1%以上または1,000サンプルのいずれか大きい方、またはリスク評価により決定された量）をカバーしていることを確認する。               |  2  |  V  |        |                                                                         |     |     |
| 1.8.4  | アウトソーシングまたはクラウドソーシングされたラベリングワークフローに、データの機密性、整合性、ラベル品質を確保し、データ漏洩を防止するための技術的および手続き上の安全対策が含まれていることを確認してください。                                    |  2  | D/V |        |                                                                         |     |     |
| 1.5.4  | 修復手順がプロビナンス記録に付加されていることを確認してください。                                                                                                            |  2  | D/V |        |                                                                         |     |     |
| 1.6.2  | フラグが立てられたサンプルがトレーニング前に手動レビューをトリガーすることを確認してください。                                                                                              |  2  | D/V |        |                                                                         |     |     |
| 1.6.3  | 結果がモデルのセキュリティドシエに反映され、継続的な脅威インテリジェンスに通知されることを確認してください。                                                                                       |  2  |  V  |        |                                                                         |     |     |
| 1.6.4  | 検出ロジックが新しい脅威インテリジェンスで更新されていることを確認してください。                                                                                                     |  3  | D/V |        |                                                                         |     |     |
| 1.6.5  | オンライン学習パイプラインが分布の変動を監視していることを検証してください。                                                                                                       |  3  | D/V |        |                                                                         |     |     |
| 1.7.1  | トレーニングデータの削除ワークフローが、一次データおよび派生データを完全に削除し、モデルへの影響を評価していることを確認し、影響を受けたモデルに対して必要に応じて再トレーニングや再調整などの対処が行われていることを評価してください。                         |  1  | D/V |        |                                                                         |     |     |
| 1.7.2  | トレーニングに使用されるデータに対するユーザーの同意（および撤回）の範囲と状況を追跡し尊重するための仕組みが整っていることを確認し、データが新しいトレーニングプロセスや重要なモデル更新に組み込まれる前に同意が検証されていることを確認してください。                  |  2  |  D  |        |                                                                         |     |     |
| 1.7.3  | ワークフローが年に一度テストされ、記録されていることを確認してください。                                                                                                         |  2  |  V  |        |                                                                         |     |     |
| 1.8.1  | 第三者のデータ供給者（事前学習済みモデルの提供者や外部データセットの提供者を含む）が、そのデータやモデルが統合される前に、セキュリティ、プライバシー、倫理的調達、およびデータ品質のデューデリジェンスを受けていることを確認してください。                        |  2  | D/V |        |                                                                         |     |     |
| 1.8.2  | 外部転送がTLS認証および完全性チェックを使用していることを検証してください。                                                                                                      |  1  |  D  |        |                                                                         |     |     |
| 1.8.3  | 高リスクのデータソース（例：出所不明のオープンソースデータセット、未検証のサプライヤー）が、機密性の高いアプリケーションで使用される前に、サンドボックス分析、徹底した品質・バイアスチェック、ターゲットを絞ったポイズニング検出などの強化された精査を受けていることを確認してください。 |  2  | D/V |        |                                                                         |     |     |
| 1.8.4  | 事前学習済みモデルをサードパーティから入手した場合、ファインチューニングや展開の前に、組み込みバイアス、潜在的なバックドア、アーキテクチャの整合性、および元のトレーニングデータの出所について評価されていることを確認してください。                           |  3  | D/V |        |                                                                         |     |     |
| 1.5.3  | 敵対的トレーニングが使用されている場合、敵対的データセットの生成、管理、およびバージョン管理が文書化され、管理されていることを確認してください。                                                                     |  2  | D/V |        |                                                                         |     |     |
| 1.5.3  | 敵対的ロバストネストレーニングがモデルのパフォーマンス（クリーン入力および敵対的入力の両方に対して）および公平性指標に与える影響が評価され、文書化され、監視されていることを確認する。                                                  |  3  | D/V |        |                                                                         |     |     |
| 1.5.4  | 敵対的トレーニングおよびロバストネスの戦略が、進化する敵対的攻撃手法に対抗するために定期的に見直され、更新されていることを確認する。                                                                           |  3  | D/V |        |                                                                         |     |     |
| 1.4.2  | 監査記録を伴って、失敗したデータセットが隔離されていることを確認してください。                                                                                                      |  2  | D/V |        |                                                                         |     |     |
| 1.4.3  | 例外が承認されていない限り、品質ゲートが基準以下のデータセットをブロックすることを確認してください。                                                                                           |  2  | D/V |        |                                                                         |     |     |
| 1.11.2 | 合成データの生成プロセス、パラメータ、および意図された使用目的が文書化されていることを確認してください。                                                                                         |  2  | D/V |        |                                                                         |     |     |
| 1.11.3 | 合成データをトレーニングに使用する前に、バイアス、プライバシー漏洩、および表現上の問題に関してリスク評価が行われていることを確認してください。                                                                      |  2  | D/V | 1.12.2 | アクセスログが定期的に確認され、大量のエクスポートや新しい場所からのアクセスなどの異常なパターンがないか検証されていることを確認してください。 | 2   | D/V |
| 1.12.3 | 疑わしいアクセスイベントに対してアラートが生成され、迅速に調査されていることを確認してください。                                                                                             |  2  | D/V |        |                                                                         |     |     |
| 1.13.1 | すべてのトレーニングデータセットに対して明示的な保持期間が定義されていることを確認してください。                                                                                             |  1  | D/V |        |                                                                         |     |     |
| 1.13.2 | データセットがライフサイクルの終了時に自動的に期限切れ、削除、または削除のためにレビューされることを確認してください。                                                                                  |  2  | D/V |        |                                                                         |     |     |
| 1.13.3 | 保持および削除の操作が記録され、監査可能であることを確認してください。                                                                                                          |  2  | D/V |        |                                                                         |     |     |
| 1.14.1 | すべてのデータセットに対して、データ居住地および国境を越えた転送の要件が特定され、適用されていることを確認してください。                                                                                 |  2  | D/V |        |                                                                         |     |     |
| 1.14.2 | データ処理において、業界別規制（例：医療、金融）が特定され、対応されていることを確認してください。                                                                                            |  2  | D/V |        |                                                                         |     |     |
| 1.14.3 | 関連するプライバシー法（例：GDPR、CCPA）への準拠が文書化され、定期的にレビューされていることを確認してください。                                                                                 |  2  | D/V |        |                                                                         |     |     |
| 1.16.1 | データ主体からのアクセス、訂正、制限、または異議申し立ての要求に対応するためのメカニズムが存在することを確認してください。                                                                                |  2  | D/V |        |                                                                         |     |     |
| 1.16.2 | リクエストが法的に定められた期限内に記録され、追跡され、履行されていることを確認してください。                                                                                              |  2  | D/V |        |                                                                         |     |     |
| 1.16.3 | データ主体の権利に関するプロセスが効果的であることを検証し、定期的にテストおよび見直しが行われていることを確認してください。                                                                               |  2  | D/V |        |                                                                         |     |     |
| 1.17.1 | データセットのバージョンを更新または置き換える前に、モデルのパフォーマンス、公平性、およびコンプライアンスを対象とした影響分析が実施されていることを確認してください。                                                          |  2  | D/V |        |                                                                         |     |     |
| 1.17.2 | 影響分析の結果が文書化され、関連する利害関係者によってレビューされていることを確認する。                                                                                                 |  2  | D/V |        |                                                                         |     |     |
| 1.17.3 | 新しいバージョンが受け入れられないリスクや回帰をもたらす場合に備え、ロールバック計画が存在することを確認してください。                                                                                  |  2  | D/V |        |                                                                         |     |     |
| 1.18.1 | データ注釈に関与するすべての担当者が、身元調査を受け、データのセキュリティとプライバシーに関する訓練を受けていることを確認してください。                                                                         |  2  | D/V |        |                                                                         |     |     |
| 1.18.2 | すべてのアノテーション担当者が機密保持および非開示契約書に署名していることを確認してください。                                                                                              |  2  | D/V |        |                                                                         |     |     |
| 1.18.3 | アノテーションプラットフォームがアクセス制御を実施し、内部脅威を監視していることを確認してください。                                                                                           |  2  | D/V |        |                                                                         |     |     |

### 参考文献

* [NIST AI Risk Management Framework 1.0](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [ISO/IEC 42001:2023 — AI Management Systems Requirements](https://www.iso.org/standard/81230.html)
* [ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management](https://www.iso.org/standard/77304.html)
* [EU Artificial Intelligence Act — Regulation (EU) 2024/1689](https://eur-lex.europa.eu/eli/reg/2024/1689/oj)
* [ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods](https://www.iso.org/standard/79804.html)

