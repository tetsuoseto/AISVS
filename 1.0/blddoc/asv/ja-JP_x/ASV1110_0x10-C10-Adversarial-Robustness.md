# 10 敵対的頑健性とプライバシー防御

## 制御目標

AIモデルが回避、推論、抽出、または汚染攻撃に直面した際にも、信頼性が高く、プライバシーを保護し、悪用に強い状態を維持することを保証してください。

---

## 10.1 モデルの整合性と安全性

有害またはポリシー違反の出力に対して防御する。

|   #    | 説明                                                                                             | レベル | 役割  |
| :----: | ---------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.1.1 | アライメントテストスイート（レッドチームプロンプト、ジェイルブレイクプローブ、不許可コンテンツ）がバージョン管理されており、すべてのモデルリリース時に実行されていることを確認してください。 |  1  | D/V |
| 10.1.2 | 拒否と安全完了のガードレールが適用されていることを確認してください。                                                             |  1  |  D  |
| 10.1.3 | 自動評価者が有害コンテンツ率を測定し、設定されたしきい値を超える回帰をフラグ付けすることを確認します。                                            |  2  | D/V |
| 10.1.4 | カウンタージェイルブレイクトレーニングが文書化され、再現可能であることを確認してください。                                                  |  2  |  D  |
| 10.1.5 | 正式なポリシー遵守証明または認定監視が重要な領域をカバーしていることを確認してください。                                                   |  3  |  V  |

---

## 10.2 敵対的サンプル耐性強化

操作された入力に対する耐性を高める。堅牢な敵対的トレーニングとベンチマーク評価が現時点での最良の実践方法である。

|   #    | 説明                                                             | レベル | 役割  |
| :----: | -------------------------------------------------------------- | :-: | :-: |
| 10.2.1 | プロジェクトのリポジトリに再現可能なシードを用いた敵対的トレーニングの設定が含まれていることを確認してください。       |  1  |  D  |
| 10.2.2 | 対抗例検出が本番パイプラインでブロッキングアラートを発生させることを確認してください。                    |  2  | D/V |
| 10.2.4 | 認証されたロバストネスの証明または区間境界の証明書が、少なくとも最も重要な上位クラスをカバーしていることを検証してください。 |  3  |  V  |
| 10.2.5 | 回帰テストが適応型攻撃を使用して、測定可能なロバストネスの低下がないことを確認していることを検証してください。        |  3  |  V  |

---

## 10.3 メンバーシップ推論の緩和

レコードがトレーニングデータに含まれていたかどうかを判断する能力を制限します。差分プライバシーと信頼度スコアのマスキングが、現在知られている最も効果的な防御手段であり続けています。

|   #    | 説明                                                                  | レベル | 役割  |
| :----: | ------------------------------------------------------------------- | :-: | :-: |
| 10.3.1 | 各クエリごとのエントロピー正則化または温度スケーリングが過剰に自信を持った予測を抑制することを検証する。                |  1  |  D  |
| 10.3.2 | トレーニングがセンシティブなデータセットに対して ε-バウンド差分プライバシー最適化を採用していることを検証してください。       |  2  |  D  |
| 10.3.3 | 攻撃シミュレーション（シャドウモデルまたはブラックボックス）が保留データに対して攻撃AUC ≤ 0.60であることを確認してください。 |  2  |  V  |

---

## 10.4 モデル反転耐性

プライベート属性の再構築を防止します。最近の調査では、出力の切り捨てとDP保証が実用的な防御策として強調されています。

|   #    | 説明                                                     | レベル | 役割  |
| :----: | ------------------------------------------------------ | :-: | :-: |
| 10.4.1 | 機微な属性が直接出力されないことを確認してください。必要に応じて、バケットや一方向変換を使用してください。  |  1  |  D  |
| 10.4.2 | 同じプリンシパルからの繰り返される適応クエリがクエリレート制限によって制御されていることを検証してください。 |  1  | D/V |
| 10.4.3 | モデルがプライバシー保護のためのノイズを使用してトレーニングされていることを確認してください。        |  2  |  D  |

---

## 10.5 モデル抽出防御

不正なクローンを検出し防止します。ウォーターマーキングとクエリパターン解析が推奨されます。

|   #    | 説明                                                                             | レベル | 役割  |
| :----: | ------------------------------------------------------------------------------ | :-: | :-: |
| 10.5.1 | 推論ゲートウェイが、モデルの記憶閾値に調整されたグローバルおよびAPIキーごとのレート制限を適用していることを検証してください。               |  1  |  D  |
| 10.5.2 | クエリエントロピーおよび入力複数性の統計情報が自動抽出検出器に供給されていることを検証してください。                             |  2  | D/V |
| 10.5.3 | 壊れやすいまたは確率的なウォーターマークが、疑わしいクローンに対して1,000回以下のクエリでp < 0.01の有意水準で証明できることを検証してください。 |  2  |  V  |
| 10.5.4 | ウォーターマークキーとトリガーセットがハードウェアセキュリティモジュールに保存され、毎年ローテーションされていることを検証してください。           |  3  |  D  |
| 10.5.5 | 抽出アラートイベントに違反クエリが含まれていることを確認し、それらがインシデント対応プレイブックに統合されていることを検証してください。           |  3  |  V  |

---

## 10.6 推論時の毒データ検出

バックドアや毒入り入力を検出して無効化します。

|   #    | 説明                                                              | レベル | 役割  |
| :----: | --------------------------------------------------------------- | :-: | :-: |
| 10.6.1 | モデル推論の前に、入力が異常検出器（例えば、STRIP、整合性スコアリング）を通過することを検証してください。         |  1  |  D  |
| 10.6.2 | 検出器の閾値が、クリーンおよび毒入りの検証セットで調整され、誤検出率が5％未満になるように確認してください。          |  1  |  V  |
| 10.6.3 | 汚染されたとフラグ付けされた入力が、ソフトブロックおよび人間によるレビューのワークフローをトリガーすることを確認してください。 |  2  |  D  |
| 10.6.4 | 検出器が適応的でトリガーのないバックドア攻撃によりストレステストされていることを検証してください。               |  2  |  V  |
| 10.6.5 | 検出効果の指標が記録され、新しい脅威インテリジェンスで定期的に再評価されていることを確認してください。             |  3  |  D  |

---

## 10.7 動的セキュリティポリシー適応

脅威インテリジェンスと行動分析に基づくリアルタイムのセキュリティポリシー更新。

|   #    | 説明                                                                  | レベル | 役割  |
| :----: | ------------------------------------------------------------------- | :-: | :-: |
| 10.7.1 | エージェントの再起動なしでセキュリティポリシーを動的に更新でき、ポリシーバージョンの整合性が維持されることを検証してください。     |  1  | D/V |
| 10.7.2 | ポリシーの更新が認可されたセキュリティ担当者によって暗号的に署名され、適用前に検証されていることを確認してください。          |  2  | D/V |
| 10.7.3 | 動的ポリシー変更が、正当な理由、承認チェーン、およびロールバック手順を含む完全な監査記録とともに記録されていることを確認してください。 |  2  | D/V |
| 10.7.4 | 適応型セキュリティメカニズムが、リスクのコンテキストおよび行動パターンに基づいて脅威検出の感度を調整することを検証してください。    |  3  | D/V |
| 10.7.5 | ポリシー適応の判断が説明可能であり、セキュリティチームのレビューのために証拠の追跡が含まれていることを確認してください。        |  3  | D/V |

---

## 10.8 リフレクションベースのセキュリティ分析

エージェントの自己反省とメタ認知分析によるセキュリティ検証。

|   #    | 説明                                                                 | レベル | 役割  |
| :----: | ------------------------------------------------------------------ | :-: | :-: |
| 10.8.1 | エージェントのリフレクションメカニズムが、意思決定と行動に関するセキュリティ重視の自己評価を含んでいることを検証してください。    |  1  | D/V |
| 10.8.2 | 自己評価メカニズムの操作を防ぐために、反射出力が検証されていることを確認してください。                        |  2  | D/V |
| 10.8.3 | メタ認知的セキュリティ分析が、エージェントの推論プロセスにおける潜在的なバイアス、操作、または妥協を特定することを検証してください。 |  2  | D/V |
| 10.8.4 | リフレクションベースのセキュリティ警告が強化された監視および潜在的な人間の介入ワークフローをトリガーすることを確認してください。   |  3  | D/V |
| 10.8.5 | 継続的な学習がセキュリティの振り返りからの脅威検知を向上させつつ、正当な機能を劣化させないことを検証する。              |  3  | D/V |

---

## 10.9 進化と自己改善のセキュリティ

自己修正と進化が可能なエージェントシステムのためのセキュリティ制御。

|   #    | 説明                                              | レベル | 役割  |
| :----: | ----------------------------------------------- | :-: | :-: |
| 10.9.1 | 自己修正機能が正式な検証境界を持つ指定された安全な領域に制限されていることを確認してください。 |  1  | D/V |
| 10.9.2 | 進化提案が実装される前にセキュリティ影響評価を受けることを確認してください。          |  2  | D/V |
| 10.9.3 | 自己改善メカニズムに、整合性検証を伴うロールバック機能が含まれていることを確認してください。  |  2  | D/V |
| 10.9.4 | メタラーニングのセキュリティが改善アルゴリズムの敵対的操作を防止することを検証する。      |  3  | D/V |
| 10.9.5 | 再帰的自己改善が数学的な収束証明により形式的な安全制約によって制限されていることを検証する。  |  3  | D/V |

---

### 参考文献

* [MITRE ATLAS adversary tactics for ML](https://atlas.mitre.org/)
* [NIST AI Risk Management Framework 1.0, 2023](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [OWASP Top 10 for LLM Applications, 2025](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Adversarial Training: A Survey — Zhao et al., 2024](https://arxiv.org/abs/2410.15042)
* [RobustBench adversarial-robustness benchmark](https://robustbench.github.io/)
* [Membership-Inference & Model-Inversion Risk Survey, 2025](https://www.sciencedirect.com/science/article/abs/pii/S0950705125003867)
* [PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023](https://ojs.aaai.org/index.php/AAAI/article/view/26289)
* [Model-Inversion Attacks & Defenses Survey — AI Review, 2025](https://link.springer.com/article/10.1007/s10462-025-11248-0)
* [Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024](https://doi.org/10.1109/TDSC.2023.3261327)
* [Fragile Model Watermarking Survey — 2025](https://www.sciencedirect.com/science/article/abs/pii/S0165168425002026)
* [Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025](https://arxiv.org/abs/2503.22759)
* [BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024](https://arxiv.org/abs/2405.15269)

