# 序文

人工知能セキュリティ検証基準（AISVS）バージョン1.0へようこそ！

## はじめに

AISVSは2025年に共同コミュニティの取り組みとして設立され、最新のAIモデル、パイプライン、AI対応サービスの設計、開発、展開、および運用時に考慮すべきセキュリティ要件を定義しています。

AISVS v1.0は、AIシステムのセキュリティを確保するための実用的でテスト可能な基準を作成するために、プロジェクトリード、作業グループ、および広範なコミュニティ貢献者の協働による成果を表しています。

このリリースの目的は、AISVSを簡単に導入できるようにするとともに、その定義された範囲に厳密に集中し、AI特有の急速に変化するリスク環境に対応することです。

## AISVS バージョン1.0の主な目的

バージョン1.0は、いくつかの指針となる原則に基づいて作成されます。

### 明確に定義された範囲

各要件はAISVSの名称と使命に沿っている必要があります：

* 人工知能 – コントロールはAI/MLレイヤー（データ、モデル、パイプライン、または推論）で動作し、AI実務者の責任です。
* セキュリティ – 要件は特定されたセキュリティ、プライバシー、または安全リスクを直接的に軽減します。
* 検証 – 言語は準拠性を客観的に検証できるように記述されています。
* 標準 – セクションは一貫した構造と用語を用いて、一貫性のある参照を形成します。
  ​
---

AISVSに従うことで、組織はAIソリューションのセキュリティ体制を体系的に評価・強化し、安全なAIエンジニアリングの文化を促進することができます。

