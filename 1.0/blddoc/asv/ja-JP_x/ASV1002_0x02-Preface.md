# 序文

人工知能セキュリティ検証標準（AISVS）バージョン1.0へようこそ！

## はじめに

2025年に共同コミュニティの取り組みにより設立されたAISVSは、最新のAIモデル、パイプライン、およびAI対応サービスの設計、開発、展開、および運用時に考慮すべきセキュリティ要件を定義しています。

AISVS v1.0は、プロジェクトリーダー、作業グループ、および広範なコミュニティ貢献者の協力による総合的な成果であり、AIシステムのセキュリティを確保するための実践的で検証可能な基準を提供します。

このリリースの目標は、AISVSを導入しやすくするとともに、その定義された範囲に厳密に集中し、AIに特有の急速に変化するリスク環境に対応することです。

## AISVS バージョン 1.0 の主要目標

バージョン1.0は、いくつかの指導原則に基づいて作成されます。

### 明確に定義された範囲

各要件はAISVSの名称と使命に沿っていなければなりません：

* 人工知能 – 制御はAI/MLレイヤー（データ、モデル、パイプライン、または推論）で動作し、AI実務者の責任となります。
* セキュリティ – 要件は特定されたセキュリティ、プライバシー、または安全リスクを直接緩和します。
* 検証 – 言語は適合性が客観的に検証できるように記述されている。
* 標準 – セクションは一貫した構造と用語を用いて、一貫性のあるリファレンスを形成します。
  ​
---

AISVSに従うことで、組織はAIソリューションのセキュリティ体制を体系的に評価・強化し、安全なAIエンジニアリングの文化を促進できます。

