# 序文

人工知能セキュリティ検証標準（AISVS）バージョン1.0へようこそ！

## はじめに

2025年に共同コミュニティの努力によって設立されたAISVSは、現代のAIモデル、パイプライン、およびAI対応サービスの設計、開発、展開、および運用時に考慮すべきセキュリティ要件を定義します。

AISVS v1.0は、プロジェクトリーダー、作業グループ、および広範なコミュニティ寄稿者による共同作業の成果であり、AIシステムの安全性を確保するための実用的かつテスト可能なベースラインを提供します。

このリリースの目標は、AISVSを簡単に導入できるようにするとともに、その定義された範囲にレーザーフォーカスを当て、AI特有の急速に変化するリスク環境に対応することです。

## AISVSバージョン1.0の主な目標

バージョン1.0は、いくつかの指針となる原則に基づいて作成されます。

### 明確に定義されたスコープ

各要件はAISVSの名称と使命に沿っている必要があります:

* 人工知能 – コントロールはAI/MLレイヤー（データ、モデル、パイプライン、または推論）で動作し、AI実践者の責任です。
* セキュリティ – 要件は、特定されたセキュリティ、プライバシー、または安全性のリスクを直接軽減します。
* 検証 – 言語は適合性を客観的に検証できるように記述されています。
* 標準 – セクションは一貫した構造と用語を用いて、一貫性のある参照を形成します。
  ​
---

AISVSに従うことで、組織はAIソリューションのセキュリティ体制を体系的に評価・強化し、安全なAIエンジニアリングの文化を促進することができます。

