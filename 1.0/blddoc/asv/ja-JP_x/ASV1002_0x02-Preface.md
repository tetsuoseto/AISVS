# 序文

人工知能セキュリティ検証標準（AISVS）バージョン 1.0へようこそ！

## はじめに

協働コミュニティの取り組みを通じて2025年に設立された AISVS は、最新の AI モデル、パイプライン、および AI‑対応サービスを設計・開発・展開・運用する際に検討すべきセキュリティ要件を定義します。

AISVS v1.0 は、プロジェクトリード、ワーキンググループ、およびより広いコミュニティの貢献者の共同作業を結集した成果を表しており、AIシステムの安全性を確保するための実用的で検証可能なベースラインを作成することを目的としています。

このリリースの目的は、AISVSの導入を容易にする一方で、定義された範囲に厳密に焦点を合わせ、AI特有の急速に変化するリスク環境に対処することです。

## AISVS バージョン 1.0 の主要な目的

バージョン 1.0 は、いくつかの指針となる原則とともに作成されます。

### 明確に定義されたスコープ

各要件は AISVS の名称と使命に沿う必要があります：

* 人工知能 – コントロールは AI/ML レイヤー（データ、モデル、パイプライン、推論）で機能し、AI実践者の責任です。
* セキュリティ – 要求事項は、特定されたセキュリティ、プライバシー、または安全性のリスクを直接軽減します。
* 検証 – 準拠性が客観的に検証できるように、言語は記述されています。
* 標準 – セクションは一貫した構造と用語に従い、整合性のある参照を形成します。
  ​
---

AISVSに従うことで、組織はAIソリューションのセキュリティ体制を体系的に評価・強化し、セキュアなAIエンジニアリングの文化を醸成します。

