# まえがき

人工知能セキュリティ検証標準（AISVS）バージョン1.0へようこそ！

## はじめに

2025年に共同コミュニティの努力によって設立されたAISVSは、現代のAIモデル、パイプライン、AI対応サービスを設計、開発、展開、運用する際に考慮すべきセキュリティ要件を定義しています。

AISVS v1.0は、プロジェクトリーダー、ワーキンググループ、およびより広範なコミュニティの貢献者たちの共同作業の成果を表しており、AIシステムのセキュリティを確保するための現実的で検証可能な基準を提供しています。

このリリースの目標は、AISVSを簡単に導入できるようにしつつ、その定義された範囲に厳密に集中し、AI固有の急速に進化するリスク環境に対応することです。

## AISVS バージョン 1.0 の主要目標

バージョン1.0は、いくつかの指針となる原則に基づいて作成されます。

### 明確に定義されたスコープ

各要件はAISVSの名称および使命に沿っている必要があります：

* 人工知能 – コントロールはAI/MLレイヤー（データ、モデル、パイプライン、または推論）で動作し、AI実践者の責任です。
* セキュリティ – 要件は特定されたセキュリティ、プライバシー、または安全リスクを直接的に軽減するものです。
* 検証 – 言語は客観的に適合性を検証できるように記述されている。
* 標準 – セクションは一貫した構造と用語を用いて、一貫性のある参照を形成します。
  ​
---

AISVS に従うことで、組織は自社の AI ソリューションのセキュリティ体制を体系的に評価・強化し、安全な AI エンジニアリングの文化を育成することができます。

