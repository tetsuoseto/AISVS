# まえがき

人工知能セキュリティ検証標準（AISVS）バージョン1.0へようこそ！

## はじめに

2025年に共同コミュニティの取り組みにより設立されたAISVSは、最新のAIモデル、パイプライン、およびAI対応サービスの設計、開発、展開、運用時に考慮すべきセキュリティ要件を定義しています。

AISVS v1.0は、そのプロジェクトリード、作業部会、および広範なコミュニティ貢献者の共同作業により、AIシステムのセキュリティを確保するための実用的で検証可能なベースラインを提供します。

このリリースの目的は、AISVSを簡単に導入できるようにしつつ、その定義された範囲に的を絞り、AI特有の急速に進化するリスク環境に対応することです。

## AISVS バージョン 1.0 の主要目標

バージョン 1.0 は、いくつかの指導原則に基づいて作成されます。

### 明確に定義されたスコープ

各要件はAISVSの名称と使命に沿っている必要があります：

* 人工知能 – コントロールはAI/MLレイヤー（データ、モデル、パイプライン、または推論）で機能し、AI実務者の責任です。
* セキュリティ – 要件は、特定されたセキュリティ、プライバシー、または安全リスクを直接軽減します。
* 検証 – 言語は適合性を客観的に検証できるように記述されています。
* 標準 – セクションは一貫した構造と用語を用いて、整合性のある参照を形成します。
  ​
---

AISVSに従うことで、組織はAIソリューションのセキュリティ体制を体系的に評価・強化し、安全なAIエンジニアリングの文化を醸成することができます。

