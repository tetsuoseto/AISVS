# C6 モデル、フレームワーク、データのサプライチェーンセキュリティ

## 統制目標

AI サプライ‑チェーン攻撃は、サードパーティ‑モデル、フレームワーク、またはデータセットを利用して、バックドア、バイアス、または悪用可能なコードを埋め込む。これらの管理措置は、エンド‑ツーエンドの出所情報、脆弱性管理、監視を提供し、全体のモデルライフサイクルを保護するためのものです。

---

## C6.1 事前学習済みモデルの検証と出所

ファインチューニングやデプロイメントを行う前に、サードパーティ‑製モデルの出所、ライセンス、隠れた挙動を評価し、認証する。

|   #   | 説明                                                                       | レベル | 役割  |
| :---: | ------------------------------------------------------------------------ | :-: | :-: |
| 6.1.1 | すべてのサードパーティ製モデルアーティファクトには、ソースリポジトリとコミットハッシュを識別する署名付きの出所記録が含まれていることを検証する。 |  1  | D/V |
| 6.1.2 | インポート前に、モデルが自動ツールを用いて悪意のあるレイヤーまたはトロイの木馬のトリガーを検査されていることを確認してください。         |  1  | D/V |
| 6.1.3 | 転移‑学習によるファインチューニングが、隠れた挙動を検出するための敵対的評価をクリアすることを検証する。                     |  2  |  D  |
| 6.1.4 | ML-BOMエントリに、モデルライセンス、輸出管理タグ、およびデータ起源に関する記述が記録されていることを確認してください。           |  2  |  V  |
| 6.1.5 | 高‑リスクモデル（公開された重み、未検証の作成者）が、人間の審査とサイン‑オフが完了するまで隔離された状態のままであることを確認してください。  |  3  | D/V |

---

## C6.2 フレームワークとライブラリのスキャン

実行時スタックを安全に保つため、MLフレームワークとライブラリを継続的にスキャンし、CVEと悪意のあるコードを検出します。

|   #   | 説明                                                         | レベル | 役割  |
| :---: | ---------------------------------------------------------- | :-: | :-: |
| 6.2.1 | CIパイプラインがAIフレームワークおよび重要ライブラリに対して依存関係スキャナーを実行していることを検証する。   |  1  | D/V |
| 6.2.2 | 重大な脆弱性（CVSS ≥ 7.0）が本番イメージへの昇格をブロックすることを確認する。               |  1  | D/V |
| 6.2.3 | フォーク済みまたはベンダー提供の機械学習ライブラリで静的コード解析が実行されることを検証する。            |  2  |  D  |
| 6.2.4 | フレームワークのアップグレード提案に、公開CVEフィードを参照したセキュリティ影響評価が含まれていることを検証する。 |  2  |  V  |
| 6.2.5 | 署名済み SBOM から逸脱する予期せぬ動的ライブラリのロードに対して、実行時センサーが警告することを検証する。   |  3  |  V  |

---

## C6.3 依存関係のピン留めと検証

すべての依存関係を不変ダイジェストに固定し、ビルドを再現可能にして、同一かつ改ざんされていないアーティファクトを保証する。

|   #   | 説明                                                         | レベル | 役割  |
| :---: | ---------------------------------------------------------- | :-: | :-: |
| 6.3.1 | すべてのパッケージマネージャがロックファイルを介してバージョン固定を強制していることを検証する。           |  1  | D/V |
| 6.3.2 | コンテナ参照において不変ダイジェストが可変タグの代わりに使用されていることを検証する。                |  1  | D/V |
| 6.3.3 | 再現性ビルドの検証が、CI の実行間でハッシュ値を比較し、同一の出力を保証していることを確認する。          |  2  |  D  |
| 6.3.4 | ビルドのアテステーションが監査証跡性のために18か月間保存されていることを確認してください。             |  2  |  V  |
| 6.3.5 | 期限切れの依存関係が、ピン留めされたバージョンを更新する自動PRをトリガーするか、あるいはフォークするかを検証する。 |  3  |  D  |

---

## C6.4 信頼済みソースの適用

成果物のダウンロードは、暗号学的に検証済みの組織‑承認済みのソースからのみ許可し、それ以外はすべてブロックします。

|   #   | 説明                                                                     | レベル | 役割  |
| :---: | ---------------------------------------------------------------------- | :-: | :-: |
| 6.4.1 | モデルの重み、データセット、およびコンテナは、承認済みのドメインまたは内部レジストリからのみダウンロードされることを確認してください。    |  1  | D/V |
| 6.4.2 | アーティファクトがローカルにキャッシュされる前に、Sigstore/Cosign の署名が発行者の身元を検証していることを確認する。     |  1  | D/V |
| 6.4.3 | エグレスプロキシが認証されていないアーティファクトのダウンロードをブロックし、trusted‑sourceポリシーを適用することを検証する。 |  2  |  D  |
| 6.4.4 | リポジトリの許可リストが四半期ごとに見直され、各エントリごとにビジネス上の正当性を示す証拠があることを確認する。               |  2  |  V  |
| 6.4.5 | ポリシー違反が成果物の検疫と、依存するパイプライン実行のロールバックを引き起こすことを検証する。                       |  3  |  V  |

---

## C6.5 第三者データセットリスク評価

外部データセットをデータポイズニング、バイアス、法的遵守の観点から評価し、それらのライフサイクル全体を通じて監視する。

|   #   | 説明                                                          | レベル | 役割  |
| :---: | ----------------------------------------------------------- | :-: | :-: |
| 6.5.1 | 外部データセットがデータ汚染リスクのスコアリングを受けることを検証する（例：データ指紋付け、外れ値検出）。       |  1  | D/V |
| 6.5.2 | データセットが承認される前に、バイアス指標（デモグラフィック・パリティ、機会均等）が計算されることを検証する。     |  1  |  D  |
| 6.5.3 | データセットの出所情報とライセンス条件が ML‑BOM エントリに記録されていることを検証してください。        |  2  |  V  |
| 6.5.4 | ホストされたデータセットにおける定期的な監視が、データドリフトまたは破損を検出することを検証する。           |  2  |  V  |
| 6.5.5 | トレーニング前に自動データクリーニングを用いて、禁止されたコンテンツ（著作権、PII）が除去されていることを検証する。 |  3  |  D  |

---

## C6.6 サプライチェーン攻撃の監視

CVEフィード、監査ログ分析、レッドチーム演習を通じてサプライチェーンの脅威を早期に検出する。

|   #   | 説明                                                                         | レベル | 役割  |
| :---: | -------------------------------------------------------------------------- | :-: | :-: |
| 6.6.1 | CI/CD の監査ログが SIEM の検出機能に送られ、異常なパッケージのプルや改ざんされたビルド手順を検知できることを検証する。          |  1  |  V  |
| 6.6.2 | インシデント対応プレイブックに、侵害されたモデルまたはライブラリのロールバック手順が含まれていることを確認する。                   |  2  |  D  |
| 6.6.3 | アラートのトリアージにおいて、脅威インテリジェンス強化タグが ML‑専用指標をタグ付けしていることを検証する（例：モデル‑ポイズニング IoCs）。 |  3  |  V  |

---

## C6.7 モデル成果物用の ML‑BOM

デプロイ時にコンポーネントの完全性を検証できるよう、詳細な ML専用SBOM（ML‑BOM）を生成して署名してください。

|   #   | 説明                                                                          | レベル | 役割  |
| :---: | --------------------------------------------------------------------------- | :-: | :-: |
| 6.7.1 | すべてのモデルアーティファクトが、データセット、重み、ハイパーパラメータ、ライセンスを列挙したML‑BOMを公開していることを確認してください。    |  1  | D/V |
| 6.7.2 | CIでML‑BOMの生成とCosign署名を自動化し、マージに必須であることを検証する。                                |  1  | D/V |
| 6.7.3 | ML‑BOM の完全性チェックが、いずれかのコンポーネントのメタデータ（ハッシュ、ライセンス）が欠落している場合にビルドを失敗させることを検証します。 |  2  |  D  |
| 6.7.4 | デプロイ時にインポートされたモデルを検証するため、下流の利用者が API を介して ML-BOMs を照会できることを検証する。            |  2  |  V  |
| 6.7.5 | ML‑BOMs がバージョン管理され、差分が取られていることを検証し、不正な変更を検出する。                              |  3  |  V  |

---

## 参考文献

* [ML Supply Chain Compromise – MITRE ATLAS](https://misp-galaxy.org/mitre-atlas-attack-pattern/)
* [Supply‑chain Levels for Software Artifacts (SLSA)](https://slsa.dev/)
* [CycloneDX – Machine Learning Bill of Materials](https://cyclonedx.org/capabilities/mlbom/)
* [What is Data Poisoning? – SentinelOne](https://www.sentinelone.com/cybersecurity-101/cybersecurity/data-poisoning/)
* [Transfer Learning Attack – OWASP ML Security Top 10](https://owasp.org/www-project-machine-learning-security-top-10/docs/ML07_2023-Transfer_Learning_Attack)
* [AI Data Security Best Practices – CISA](https://www.cisa.gov/news-events/cybersecurity-advisories/aa25-142a)
* [Secure CI/CD Supply Chain – Sumo Logic](https://www.sumologic.com/blog/secure-azure-devops-github-supply-chain-attacks)
* [AI & Transparency: Protect ML Models – ReversingLabs](https://www.reversinglabs.com/blog/ai-and-transparency-how-ml-model-creators-can-protect-against-supply-chain-attacks)
* [SBOM Overview – CISA](https://www.cisa.gov/sbom)
* [Training Data Poisoning Guide – Lakera.ai](https://www.lakera.ai/blog/training-data-poisoning)
* [Dependency Pinning for Reproducible Python – Medium](https://medium.com/data-science-collective/guarantee-a-locked-reproducible-environment-with-every-python-run-c0e2bf19fb53)

