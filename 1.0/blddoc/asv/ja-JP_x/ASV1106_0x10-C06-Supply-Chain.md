# C6 モデル、フレームワーク、およびデータのサプライチェーンセキュリティ

## 管理目標

AIサプライチェーン攻撃は、サードパーティのモデル、フレームワーク、またはデータセットを悪用してバックドア、バイアス、または悪用可能なコードを埋め込みます。これらのコントロールは、エンドツーエンドの出所管理、脆弱性管理、およびモニタリングを提供し、モデルのライフサイクル全体を保護します。

---

## C6.1 事前学習済みモデルの審査と出所確認

ファインチューニングや展開の前に、サードパーティモデルの出所、ライセンス、および隠れた挙動を評価・認証してください。

|   #   | 説明                                                                          | レベル | 役割  |
| :---: | --------------------------------------------------------------------------- | :-: | :-: |
| 6.1.1 | すべてのサードパーティモデルアーティファクトが、ソースリポジトリおよびコミットハッシュを特定する署名付きの出所記録を含んでいることを確認してください。 |  1  | D/V |
| 6.1.2 | モデルがインポートされる前に、自動化ツールを使用して悪意のあるレイヤーやトロイの木馬トリガーがスキャンされていることを確認してください。        |  1  | D/V |
| 6.1.3 | 転移学習のファインチューニングが、隠れた挙動を検出するための敵対的評価に合格することを検証してください。                        |  2  |  D  |
| 6.1.4 | モデルライセンス、輸出管理タグ、およびデータ起源の記載がML-BOMエントリに記録されていることを確認してください。                  |  2  |  V  |
| 6.1.5 | 高リスクモデル（公開されアップロードされた重み、未検証の作成者）が人間のレビューと承認があるまで隔離されたままであることを確認してください。      |  3  | D/V |

---

## C6.2 フレームワークおよびライブラリのスキャン

ランタイムスタックのセキュリティを維持するために、MLフレームワークやライブラリを継続的にスキャンして、CVEや悪意のあるコードを検出します。

|   #   | 説明                                                                | レベル | 役割  |
| :---: | ----------------------------------------------------------------- | :-: | :-: |
| 6.2.1 | CIパイプラインがAIフレームワークおよび重要なライブラリに対して依存関係スキャナーを実行していることを確認してください。     |  1  | D/V |
| 6.2.2 | 重大な脆弱性（CVSS ≥ 7.0）が、本番用イメージへの昇格をブロックすることを確認してください。                |  1  | D/V |
| 6.2.3 | フォークされたまたはベンダーされたMLライブラリで静的コード解析が実行されていることを確認してください。              |  2  |  D  |
| 6.2.4 | フレームワークのアップグレード提案には、公開CVEフィードを参照したセキュリティ影響評価が含まれていることを確認してください。   |  2  |  V  |
| 6.2.5 | 署名されたSBOMから逸脱する予期しない動的ライブラリのロードに対して、ランタイムセンサーがアラートを出すことを検証してください。 |  3  |  V  |

---

## C6.3 依存関係の固定および検証

すべての依存関係を不変のダイジェストに固定し、ビルドを再現して、同一で改ざんされていないアーティファクトを保証します。

|   #   | 説明                                                           | レベル | 役割  |
| :---: | ------------------------------------------------------------ | :-: | :-: |
| 6.3.1 | すべてのパッケージマネージャーがロックファイルを通じてバージョンピンニングを強制していることを確認してください。     |  1  | D/V |
| 6.3.2 | コンテナ参照において、変更可能なタグの代わりに不変のダイジェストが使用されていることを検証します。            |  1  | D/V |
| 6.3.3 | 再現可能ビルドのチェックが、CI実行間でハッシュを比較して同一の出力を保証することを検証してください。          |  2  |  D  |
| 6.3.4 | 監査の追跡可能性のために、ビルド証明書が18ヶ月間保存されていることを確認してください。                 |  2  |  V  |
| 6.3.5 | 期限切れの依存関係が、自動的にPRをトリガーしてピン留めされたバージョンを更新またはフォークすることを確認してください。 |  3  |  D  |

---

## C6.4 信頼できるソースの強制

アーティファクトのダウンロードは、暗号学的に検証され、組織が承認したソースからのみ許可し、それ以外はすべてブロックします。

|   #   | 説明                                                                    | レベル | 役割  |
| :---: | --------------------------------------------------------------------- | :-: | :-: |
| 6.4.1 | モデルの重み、データセット、およびコンテナが、承認されたドメインまたは内部レジストリからのみダウンロードされていることを確認してください。 |  1  | D/V |
| 6.4.2 | Sigstore/Cosignの署名が、アーティファクトがローカルにキャッシュされる前に公開者の身元を検証することを確認してください。   |  1  | D/V |
| 6.4.3 | アウトバウンドプロキシが未認証のアーティファクトダウンロードをブロックし、信頼済みソースポリシーを強制していることを検証してください。   |  2  |  D  |
| 6.4.4 | リポジトリの許可リストが四半期ごとにレビューされ、各エントリに対するビジネス上の正当性の証拠があることを確認してください。         |  2  |  V  |
| 6.4.5 | ポリシー違反がアーティファクトの隔離と依存パイプライン実行のロールバックを引き起こすことを検証してください。                |  3  |  V  |

---

## C6.5 サードパーティデータセットのリスク評価

外部データセットを毒性、バイアス、および法的遵守の観点から評価し、そのライフサイクル全体を通じて監視します。

|   #   | 説明                                                                  | レベル | 役割  |
| :---: | ------------------------------------------------------------------- | :-: | :-: |
| 6.5.1 | 外部データセットがポイズニングリスクスコアリング（例：データフィンガープリンティング、異常値検出）を受けていることを確認してください。 |  1  | D/V |
| 6.5.2 | バイアスメトリクス（人口統計的公平性、均等機会）がデータセット承認前に計算されていることを確認してください。              |  1  |  D  |
| 6.5.3 | データセットの出所およびライセンス条件がML-BOMエントリに記録されていることを確認してください。                  |  2  |  V  |
| 6.5.4 | ホストされたデータセットにおけるドリフトや破損を検出するために定期的な監視が行われていることを確認してください。            |  2  |  V  |
| 6.5.5 | トレーニング前に、自動スクラビングによって許可されていないコンテンツ（著作権、個人識別情報）が削除されていることを確認してください。  |  3  |  D  |

---

## C6.6 サプライチェーン攻撃モニタリング

CVEフィード、監査ログ分析、およびレッドチームシミュレーションを通じて、サプライチェーンの脅威を早期に検出します。

|   #   | 説明                                                                    | レベル | 役割  |
| :---: | --------------------------------------------------------------------- | :-: | :-: |
| 6.6.1 | CI/CDの監査ログが、異常なパッケージプルや改ざんされたビルドステップに関するSIEM検出にストリームされていることを確認してください。 |  1  |  V  |
| 6.6.2 | インシデント対応プレイブックに、侵害されたモデルやライブラリのロールバック手順が含まれていることを確認してください。            |  2  |  D  |
| 6.6.3 | アラートトリアージにおいて、脅威インテリジェンス強化がML特有の指標（例：モデル汚染IoC）にタグ付けされていることを検証します。     |  3  |  V  |

---

## C6.7 モデルアーティファクトのML‑BOM

詳細なML特化型SBOM（ML-BOM）を生成および署名し、下流の利用者がデプロイ時にコンポーネントの整合性を検証できるようにします。

|   #   | 説明                                                                            | レベル | 役割  |
| :---: | ----------------------------------------------------------------------------- | :-: | :-: |
| 6.7.1 | すべてのモデルアーティファクトが、データセット、重み、ハイパーパラメータ、およびライセンスをリスト化したML-BOMを公開していることを確認してください。 |  1  | D/V |
| 6.7.2 | ML-BOMの生成とCosign署名がCIで自動化されており、マージに必須であることを確認してください。                          |  1  | D/V |
| 6.7.3 | ML‑BOMの完全性チェックが、コンポーネントのメタデータ（ハッシュ、ライセンス）が欠落している場合にビルドを失敗させることを検証してください。      |  2  |  D  |
| 6.7.4 | 下流の利用者がAPIを介してML-BOMを照会し、デプロイ時にインポートされたモデルを検証できることを確認する。                      |  2  |  V  |
| 6.7.5 | ML-BOMがバージョン管理されており、無許可の変更を検出するために差分が取られていることを確認してください。                       |  3  |  V  |

---

## 参考文献

* [ML Supply Chain Compromise – MITRE ATLAS](https://misp-galaxy.org/mitre-atlas-attack-pattern/)
* [Supply‑chain Levels for Software Artifacts (SLSA)](https://slsa.dev/)
* [CycloneDX – Machine Learning Bill of Materials](https://cyclonedx.org/capabilities/mlbom/)
* [What is Data Poisoning? – SentinelOne](https://www.sentinelone.com/cybersecurity-101/cybersecurity/data-poisoning/)
* [Transfer Learning Attack – OWASP ML Security Top 10](https://owasp.org/www-project-machine-learning-security-top-10/docs/ML07_2023-Transfer_Learning_Attack)
* [AI Data Security Best Practices – CISA](https://www.cisa.gov/news-events/cybersecurity-advisories/aa25-142a)
* [Secure CI/CD Supply Chain – Sumo Logic](https://www.sumologic.com/blog/secure-azure-devops-github-supply-chain-attacks)
* [AI & Transparency: Protect ML Models – ReversingLabs](https://www.reversinglabs.com/blog/ai-and-transparency-how-ml-model-creators-can-protect-against-supply-chain-attacks)
* [SBOM Overview – CISA](https://www.cisa.gov/sbom)
* [Training Data Poisoning Guide – Lakera.ai](https://www.lakera.ai/blog/training-data-poisoning)
* [Dependency Pinning for Reproducible Python – Medium](https://medium.com/data-science-collective/guarantee-a-locked-reproducible-environment-with-every-python-run-c0e2bf19fb53)

