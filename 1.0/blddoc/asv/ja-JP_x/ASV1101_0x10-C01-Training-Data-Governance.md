# C1 訓練データ ガバナンス & バイアス管理

## 統制目標

トレーニングデータは、出所の追跡性を保ちつつ、適切に取得・取り扱い・維持され、セキュリティ、品質、そして公正性を確保した状態で管理されなければなりません。これを実践することで法的義務を果たし、トレーニング中に生じるバイアス、データポイズニング、プライバシー侵害のリスクを低減し、それがAIライフサイクル全体に影響を及ぼす可能性を抑えることにつながります。

---

## C1.1 トレーニングデータの出所

すべてのデータセットの検証可能な在庫を維持し、信頼できるソースのみを受け入れ、監査可能性のためにすべての変更を記録する。

|   #   | 説明                                                                                | レベル | 役割  |
| :---: | --------------------------------------------------------------------------------- | :-: | :-: |
| 1.1.1 | すべての学習データソースに関する出所、管理者/所有者、ライセンス、収集方法、利用目的の制約、および処理履歴を含む最新のインベントリが維持されていることを確認する。 |  1  | D/V |
| 1.1.2 | 訓練データの処理が不要な特徴量、属性、またはフィールドを除外していることを検証する（例：未使用のメタデータ、機微な個人識別情報（PII）、漏洩したテストデータ）。 |  1  | D/V |
| 1.1.3 | すべてのデータセットの変更が、ログに記録された承認ワークフローの対象となることを検証してください。                                 |  2  | D/V |
| 1.1.4 | 可能な場合には、データセットまたはそのサブセットに水印が付与されていること、または指紋付けがされていることを確認する。                       |  3  | D/V |

---

## C1.2 トレーニングデータのセキュリティと完全性

トレーニングデータへのアクセスを制限し、保管時および転送時に暗号化し、その完全性を検証して改ざん、盗難、またはデータポイズニングを防ぐ。

|   #   | 説明                                                                               | レベル | 役割  |
| :---: | -------------------------------------------------------------------------------- | :-: | :-: |
| 1.2.1 | アクセス制御がトレーニングデータの保存とパイプラインを保護していることを検証してください。                                    |  1  | D/V |
| 1.2.2 | トレーニングデータへのすべてのアクセスが記録されていることを検証し、記録にはユーザー、時刻、アクションを含める。                         |  2  | D/V |
| 1.2.3 | トレーニングデータセットが転送中および保存時に、業界標準の暗号化アルゴリズムと鍵管理の手法を用いて暗号化されていることを検証する。                |  2  | D/V |
| 1.2.4 | 訓練データの保存および転送中にデータの完全性を確保するために、暗号学的ハッシュ値または電子署名が使用されていることを確認してください。              |  2  | D/V |
| 1.2.5 | 自動検出技術が訓練データの不正な変更または汚染を防ぐために適用されていることを確認する。                                     |  2  | D/V |
| 1.2.6 | 不要になった訓練データが安全に削除または匿名化されていることを検証する。                                             |  2  | D/V |
| 1.2.7 | すべてのトレーニングデータセットのバージョンが一意に識別され、不変に保存され、監査可能であることを確認し、ロールバックおよびフォレンジック分析をサポートします。 |  3  | D/V |

---

## C1.3 訓練データのラベリング品質、完全性、およびセキュリティ

ラベルを保護し、重要データには技術的審査を要求する。

|   #   | 説明                                                                                         | レベル | 役割  |
| :---: | ------------------------------------------------------------------------------------------ | :-: | :-: |
| 1.3.1 | ラベルアーティファクトに対して、暗号ハッシュまたはデジタル署名が適用されていることを検証し、それらの整合性と真正性を保証します。                           |  2  | D/V |
| 1.3.2 | ラベリング用のインターフェースとプラットフォームが強力なアクセス制御を実施し、すべてのラベリング活動の改ざん検知可能な監査ログを維持し、不正な変更を防止することを検証してください。 |  2  | D/V |
| 1.3.3 | ラベルに含まれる機微情報が、データフィールドレベルで静止時および転送時に伏字化、匿名化、または暗号化されていることを検証する。                            |  3  | D/V |

---

## C1.4 トレーニングデータの品質とセキュリティ保証

データセットの信頼性を保証するために、自動検証、手動のスポットチェック、および記録済みの是正措置を組み合わせる。

|   #   | 説明                                                                                                                                                                  | レベル | 役割  |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 1.4.1 | すべての取り込み処理または重要なデータ変換において、自動化されたテストがフォーマットエラーおよび NULL 値を検出することを検証する。                                                                                                |  1  |  D  |
| 1.4.2 | LLMのトレーニングおよびファインチューニングパイプラインが、毒化検知 & データ整合性検証（例：統計的方法、外れ値検出、埋め込み分析）を実装し、潜在的な毒化攻撃（例：ラベル反転、バックドアトリガーの挿入、役割切替コマンド、影響力のあるインスタンス攻撃）またはトレーニングデータの意図しないデータ破損を特定することを検証する。 |  2  | D/V |
| 1.4.3 | リスク評価に基づき、敵対的訓練（生成された敵対的サンプルを使用）、摂動入力によるデータ拡張、またはロバスト最適化手法といった適切な防御策が、関連するモデルに対して実装・調整されていることを検証する。                                                                 |  3  | D/V |
| 1.4.4 | 自動的に生成されたラベルが、幻覚を起こしたもの、誤解を招くもの、または低信頼度のラベルを検出するために、信頼度閾値と一貫性検証の対象となることを確認する。                                                                                       |  2  | D/V |
| 1.4.5 | 自動テストが、データの取り込みのたび、または重要なデータ変換時におけるラベルの偏りを検出することを検証してください。                                                                                                          |  3  |  D  |

---

## C1.5 データ系譜とトレーサビリティ

各データポイントがソースからモデル入力に至るまでの全経路を追跡し、監査可能性とインシデント対応のために使用します。

|   #   | 説明                                                                                                          | レベル | 役割  |
| :---: | ----------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 1.5.1 | 各データポイントの系譜情報が、すべての変換、データ拡張、および結合を含めて記録され、再構築できることを確認する。                                                    |  2  | D/V |
| 1.5.2 | 系譜レコードが不可変であり、安全に保管され、監査のためにアクセス可能であることを検証する。                                                               |  2  | D/V |
| 1.5.3 | プライバシー保護技術または生成的手法によって生成された合成データを対象に、系統追跡が適用されていることを検証し、パイプライン全体を通じてすべての合成データが明確にラベル付けされ、実データと区別できることを確認する。 |  2  | D/V |

---

## 参考文献

* [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)
* [EU AI Act – Article 10: Data & Data Governance](https://artificialintelligenceact.eu/article/10/)
* [MITRE ATLAS: Adversary Tactics for AI](https://atlas.mitre.org/)
* [Survey of ML Bias Mitigation Techniques – MDPI](https://www.mdpi.com/2673-6470/4/1/1)
* [Data Provenance & Lineage Best Practices – Nightfall AI](https://www.nightfall.ai/ai-security-101/data-provenance-and-lineage)
* [Data Labeling Quality Standards – LabelYourData](https://labelyourdata.com/articles/data-labeling-quality-and-how-to-measure-it)
* [Training Data Poisoning Guide – Lakera.ai](https://www.lakera.ai/blog/training-data-poisoning)
* [CISA Advisory: Securing Data for AI Systems](https://www.cisa.gov/news-events/cybersecurity-advisories/aa25-142a)
* [ISO/IEC 23053: AI Management Systems Framework](https://www.iso.org/sectors/it-technologies/ai)
* [IBM: What is AI Governance?](https://www.ibm.com/think/topics/ai-governance)
* [Google AI Principles](https://ai.google/principles/)
* [GDPR & AI Training Data – DataProtectionReport](https://www.dataprotectionreport.com/2024/08/recent-regulatory-developments-in-training-artificial-intelligence-ai-models-under-the-gdpr/)
* [Supply-Chain Security for AI Data – AppSOC](https://www.appsoc.com/blog/ai-is-the-new-frontier-of-supply-chain-security)
* [OpenAI Privacy Center – Data Deletion Controls](https://privacy.openai.com/policies?modal=take-control)
* [Adversarial ML Dataset – Kaggle](https://www.kaggle.com/datasets/cnrieiit/adversarial-machine-learning-dataset)

