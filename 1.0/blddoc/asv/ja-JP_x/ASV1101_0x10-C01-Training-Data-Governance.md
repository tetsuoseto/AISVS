# C1 トレーニングデータガバナンスとバイアスマネジメント

## 管理目標

トレーニングデータは、出所、セキュリティ、品質、公平性を保持する方法で調達、取り扱い、維持されなければなりません。これを行うことで法的義務を果たし、トレーニング中に発生し得るバイアス、ポイズニング、プライバシー侵害のリスクを軽減し、AIのライフサイクル全体に影響を与える可能性を減らします。

---

## C1.1 トレーニングデータの由来

すべてのデータセットの検証可能なインベントリを維持し、信頼できるソースのみを受け入れ、監査可能性のためにすべての変更を記録してください。

|   #   | 説明                                                                                          | レベル | 役割  |
| :---: | ------------------------------------------------------------------------------------------- | :-: | :-: |
| 1.1.1 | すべてのトレーニングデータソース（出所、管理者／所有者、ライセンス、収集方法、意図された使用制約、および処理履歴）について、最新のインベントリが維持されていることを確認してください。 |  1  | D/V |
| 1.1.2 | トレーニングデータの処理が、不必要な特徴、属性、またはフィールド（例：未使用のメタデータ、機微な個人識別情報（PII）、漏洩したテストデータ）を除外していることを確認してください。  |  1  | D/V |
| 1.1.3 | すべてのデータセットの変更が記録された承認ワークフローの対象となっていることを確認してください。                                            |  2  | D/V |
| 1.1.4 | 可能な場合は、データセットまたはサブセットに透かしやフィンガープリントが施されていることを確認してください。                                      |  3  | D/V |

---

## C1.2 トレーニングデータのセキュリティと完全性

トレーニングデータへのアクセスを制限し、保存時および転送時に暗号化し、改ざん、盗難、またはデータポイズニングを防ぐためにその整合性を検証します。

|   #   | 説明                                                                                      | レベル | 役割  |
| :---: | --------------------------------------------------------------------------------------- | :-: | :-: |
| 1.2.1 | トレーニングデータの保存およびパイプラインがアクセス制御によって保護されていることを確認してください。                                     |  1  | D/V |
| 1.2.2 | トレーニングデータへのすべてのアクセスが記録されていることを確認してください。記録には、ユーザー、時間、および操作が含まれる必要があります。                  |  2  | D/V |
| 1.2.3 | トレーニングデータセットが、業界標準の暗号アルゴリズムおよび鍵管理手法を用いて、転送中および保存中に暗号化されていることを検証してください。                  |  2  | D/V |
| 1.2.4 | トレーニングデータの保存および転送時にデータの完全性を確保するために、暗号化ハッシュまたはデジタル署名が使用されていることを確認してください。                 |  2  | D/V |
| 1.2.5 | トレーニングデータの不正な改変や破損を防ぐために、自動検出技術が適用されていることを確認してください。                                     |  2  | D/V |
| 1.2.6 | 古いトレーニングデータが安全に消去または匿名化されていることを確認してください。                                                |  2  | D/V |
| 1.2.7 | すべてのトレーニングデータセットのバージョンが一意に識別され、不変的に保存され、ロールバックおよびフォレンジック分析をサポートするために監査可能であることを検証してください。 |  3  | D/V |

---

## C1.3 トレーニングデータのラベリング品質、整合性、およびセキュリティ

重要なデータに対してはラベルを保護し、技術的なレビューを必須としてください。

|   #   | 説明                                                                                            | レベル | 役割  |
| :---: | --------------------------------------------------------------------------------------------- | :-: | :-: |
| 1.3.1 | 暗号学的ハッシュまたはデジタル署名がラベルアーティファクトに適用されていることを確認し、その完全性と真正性を保証します。                                  |  2  | D/V |
| 1.3.2 | ラベリングインターフェースおよびプラットフォームが強力なアクセス制御を実施し、すべてのラベリング活動の改ざん検知可能な監査ログを保持し、不正な改変から保護していることを確認してください。 |  2  | D/V |
| 1.3.3 | ラベル内の機密情報が、保存時および転送時のデータフィールドレベルで消去、匿名化、または暗号化されていることを検証してください。                               |  3  | D/V |

---

## C1.4 トレーニングデータの品質とセキュリティ保証

自動化された検証、手動のスポットチェック、および記録された修正を組み合わせて、データセットの信頼性を保証します。

|   #   | 説明                                                                                                                                                                                  | レベル | 役割  |
| :---: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 1.4.1 | 自動化テストが、すべての取り込みまたは重要なデータ変換時にフォーマットエラーおよびnull値を検出することを確認してください。                                                                                                                     |  1  |  D  |
| 1.4.2 | LLMのトレーニングおよびファインチューニングパイプラインが、潜在的なポイズニング攻撃（例：ラベルの反転、バックドアトリガーの挿入、役割切り替えコマンド、影響力のあるインスタンス攻撃）やトレーニングデータの意図しない破損を検出するために、ポイズニング検出およびデータ整合性検証（例：統計的方法、異常値検出、埋め込み分析）を実装していることを確認してください。 |  2  | D/V |
| 1.4.3 | 適切な防御策（生成された敵対的事例を使用した敵対的トレーニング、摂動入力を用いたデータ拡張、またはロバスト最適化技術など）が、リスク評価に基づいて関連モデルに実装され、調整されていることを確認してください。                                                                             |  3  | D/V |
| 1.4.4 | 自動生成されたラベル（例：LLMや弱い監督によるもの）が、幻覚的、誤解を招く、または低信頼度のラベルを検出するために信頼度の閾値および一貫性チェックの対象となっていることを確認してください。                                                                                     |  2  | D/V |
| 1.4.5 | 自動化テストが、すべてのデータ取り込みや重要なデータ変換時にラベルのずれを検出することを確認してください。                                                                                                                               |  3  |  D  |

---

## C1.5 データ系譜とトレーサビリティ

監査可能性とインシデント対応のために、各データポイントの全行程をソースからモデル入力まで追跡してください。

|   #   | 説明                                                                                                          | レベル | 役割  |
| :---: | ----------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 1.5.1 | 各データポイントの系譜が、すべての変換、拡張、およびマージを含めて記録されており、再構築可能であることを確認してください。                                               |  2  | D/V |
| 1.5.2 | 系譜記録が不変であり、安全に保存されていて、監査のためにアクセス可能であることを検証してください。                                                           |  2  | D/V |
| 1.5.3 | 系統全体を通じて、プライバシー保護技術や生成技術を用いて生成された合成データについて系譜追跡が行われていることを確認し、すべての合成データが明確にラベル付けされ、本物のデータと区別可能であることを保証してください。 |  2  | D/V |

---

## 参考文献

* [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)
* [EU AI Act – Article 10: Data & Data Governance](https://artificialintelligenceact.eu/article/10/)
* [MITRE ATLAS: Adversary Tactics for AI](https://atlas.mitre.org/)
* [Survey of ML Bias Mitigation Techniques – MDPI](https://www.mdpi.com/2673-6470/4/1/1)
* [Data Provenance & Lineage Best Practices – Nightfall AI](https://www.nightfall.ai/ai-security-101/data-provenance-and-lineage)
* [Data Labeling Quality Standards – LabelYourData](https://labelyourdata.com/articles/data-labeling-quality-and-how-to-measure-it)
* [Training Data Poisoning Guide – Lakera.ai](https://www.lakera.ai/blog/training-data-poisoning)
* [CISA Advisory: Securing Data for AI Systems](https://www.cisa.gov/news-events/cybersecurity-advisories/aa25-142a)
* [ISO/IEC 23053: AI Management Systems Framework](https://www.iso.org/sectors/it-technologies/ai)
* [IBM: What is AI Governance?](https://www.ibm.com/think/topics/ai-governance)
* [Google AI Principles](https://ai.google/principles/)
* [GDPR & AI Training Data – DataProtectionReport](https://www.dataprotectionreport.com/2024/08/recent-regulatory-developments-in-training-artificial-intelligence-ai-models-under-the-gdpr/)
* [Supply-Chain Security for AI Data – AppSOC](https://www.appsoc.com/blog/ai-is-the-new-frontier-of-supply-chain-security)
* [OpenAI Privacy Center – Data Deletion Controls](https://privacy.openai.com/policies?modal=take-control)
* [Adversarial ML Dataset – Kaggle](https://www.kaggle.com/datasets/cnrieiit/adversarial-machine-learning-dataset)

