# Voorplaat

## Over de standaard

De Standaard voor Beveiligingsverificatie van Kunstmatige Intelligentie (AISVS) is een door de gemeenschap aangedreven catalogus met beveiligingsvereisten die datawetenschappers, MLOps-engineers, softwarearchitecten, ontwikkelaars, testers, beveiligingsprofessionals, toolleveranciers, regelgevers en consumenten kunnen gebruiken om betrouwbare AI‑ondersteunde systemen en toepassingen te ontwerpen, bouwen, testen en verifiëren. Het biedt een gemeenschappelijke taal voor het specificeren van beveiligingscontroles gedurende de AI‑levenscyclus—van gegevensverzameling en modelontwikkeling tot implementatie en voortdurende bewaking—zodat organisaties de weerbaarheid, privacy en veiligheid van hun AI‑oplossingen kunnen meten en verbeteren.

## Auteursrecht en Licentie

Versie 0.1 (Eerste openbare conceptversie - Werk in uitvoering), 2025  

![license](../images/license.png)

Auteursrecht © 2025 The AISVS Project.  

Vrijgegeven onder de[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
Voor elk hergebruik of distributie moet u de licentievoorwaarden van dit werk duidelijk aan anderen bekendmaken.

## Projectleiders

|            |                         |
| ---------- | ----------------------- |
| Jim Manico | Aras “Russ” Memisyazici |

## Bijdragers en Beoordelaars

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS is een gloednieuwe standaard die speciaal is ontwikkeld om de unieke beveiligingsuitdagingen van kunstmatige-intelligentiesystemen aan te pakken. Hoewel het inspiratie haalt uit bredere beveiligingspraktijken, is elke eis in AISVS vanaf de grond opgebouwd om het AI-bedreigingslandschap te weerspiegelen en organisaties te helpen veiligere, veerkrachtigere AI-oplossingen te bouwen.

