# Voorplat

## Over de norm

De Artificial Intelligence Security Verification Standard (AISVS) is een door de gemeenschap aangedreven catalogus van beveiligingseisen die datawetenschappers, MLOps-engineers, softwarearchitecten, ontwikkelaars, testers, beveiligingsprofessionals, toolleveranciers, regelgevers en gebruikers kunnen gebruiken om betrouwbare AI-gestuurde systemen en toepassingen te ontwerpen, bouwen, testen en verifiëren. Het biedt een gemeenschappelijke taal voor het specificeren van beveiligingscontroles gedurende de volledige AI-levenscyclus—from het verzamelen van data en modelontwikkeling tot implementatie en voortdurende monitoring—zodat organisaties de veerkracht, privacy en veiligheid van hun AI-oplossingen kunnen meten en verbeteren.

## Auteursrecht en Licentie

Versie 0.1 (Eerste Openbare Concept - Werk In Uitvoering), 2025  

![license](../images/license.png)

Copyright © 2025 Het AISVS-project.  

Uitgegeven onder de[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
Voor hergebruik of distributie moet u de licentievoorwaarden van dit werk duidelijk aan anderen communiceren.

## Projectleiders

|            |                         |
| ---------- | ----------------------- |
| Jim Manico | Aras “Russ” Memisyazici |

## Bijdragers en beoordelaars

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS is een gloednieuwe standaard die specifiek is ontwikkeld om de unieke beveiligingsuitdagingen van kunstmatige-intelligentiesystemen aan te pakken. Hoewel het inspiratie haalt uit bredere beveiligingsbest practices, is elke eis in AISVS vanaf de basis ontwikkeld om het dreigingslandschap van AI weer te geven en organisaties te helpen bij het bouwen van veiligere, veerkrachtigere AI-oplossingen.

