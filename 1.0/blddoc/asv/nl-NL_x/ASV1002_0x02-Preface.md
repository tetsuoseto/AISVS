# Voorwoord

Welkom bij de Artificial Intelligence Security Verification Standard (AISVS) versie 1.0!

## Inleiding

Opgericht in 2025 door een gezamenlijke inspanning van de gemeenschap, definieert AISVS de beveiligingseisen waarmee rekening moet worden gehouden bij het ontwerpen, ontwikkelen, implementeren en exploiteren van moderne AI-modellen, pijplijnen en AI-gestuurde diensten.

AISVS v1.0 vertegenwoordigt het gezamenlijke werk van de projectleiders, de werkgroep en bredere gemeenschapsbijdragers om een pragmatische, toetsbare basislijn voor het beveiligen van AI-systemen te produceren.

Ons doel met deze release is om AISVS gemakkelijk te maken om te adopteren, terwijl we ons scherp richten op de gedefinieerde scope en het snel veranderende risico landschap dat uniek is voor AI aanpakken.

## Belangrijkste doelstellingen voor AISVS Versie 1.0

Versie 1.0 zal worden gemaakt met verschillende leidende principes.

### Duidelijke Afbakening

Elke eis moet in overeenstemming zijn met de naam en missie van AISVS:

* Kunstmatige Intelligentie – Besturingselementen werken op de AI/ML-laag (gegevens, model, pijplijn of inferentie) en vallen onder de verantwoordelijkheid van AI-beoefenaars.
* Beveiliging – Vereisten mitigeren direct de geïdentificeerde beveiligings-, privacy- of veiligheidsrisico’s.
* Verificatie – De taal is zo geschreven dat naleving objectief kan worden geverifieerd.
* Norm – Secties volgen een consistente structuur en terminologie om een samenhangende referentie te vormen.
  ​
---

Door AISVS te volgen, kunnen organisaties systematisch de beveiligingspositie van hun AI-oplossingen evalueren en versterken, en zo een cultuur van veilige AI-engineering bevorderen.

