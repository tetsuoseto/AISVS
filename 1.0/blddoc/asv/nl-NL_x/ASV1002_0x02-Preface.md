# Voorwoord

Welkom bij de Artificial Intelligence Security Verification Standard (AISVS) versie 1.0!

## Inleiding

Opgericht in 2025 door een gezamenlijke inspanning van de gemeenschap, definieert AISVS de beveiligingsvereisten die overwogen moeten worden bij het ontwerpen, ontwikkelen, implementeren en exploiteren van moderne AI‑modellen, pijplijnen en AI‑gestuurde diensten.

AISVS v1.0 vertegenwoordigt het gezamenlijke werk van de projectleiders, de werkgroep en de bredere gemeenschap van bijdragers om een pragmatische, toetsbare basislijn te produceren voor het beveiligen van AI-systemen.

Ons doel met deze release is AISVS eenvoudig in gebruik te nemen, terwijl het haarscherp gericht blijft op de gedefinieerde omvang en inspeelt op het snel evoluerende risicolandschap dat uniek is voor kunstmatige intelligentie.

## Hoofddoelstellingen voor AISVS versie 1.0

Versie 1.0 zal worden opgesteld met verschillende richtinggevende principes.

### Duidelijk‑Gedefinieerde Reikwijdte

Elke vereiste moet overeenkomen met AISVS’s naam en missie:

* Kunstmatige intelligentie – controles werken op de AI/ML-laag (data, model, pijplijn of inferentie) en zijn de verantwoordelijkheid van AI-beoefenaars.
* Beveiliging – Vereisten die rechtstreeks geïdentificeerde beveiligings-, privacy- of veiligheidsrisico's mitigeren.
* Verificatie – De taal is zodanig geschreven dat conformiteit objectief kan worden gevalideerd.
* Standaard – Secties volgen een consistente structuur en terminologie om een samenhangende referentie te vormen.
  ​
---

Door AISVS te volgen, kunnen organisaties systematisch de beveiligingspositie van hun AI-oplossingen evalueren en versterken, waardoor een cultuur van veilige AI-engineering wordt bevorderd.

