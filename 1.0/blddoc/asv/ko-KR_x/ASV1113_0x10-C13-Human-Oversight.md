# C13 인간 감독, 책임 및 거버넌스

## 통제 목표

이 장에서는 AI 시스템에서 인간의 감독 유지와 명확한 책임 체계에 대한 요구사항을 제공하며, AI 생명주기 전반에 걸쳐 설명 가능성, 투명성 및 윤리적 관리가 이루어지도록 보장합니다.

---

## C13.1 킬 스위치 및 오버라이드 메커니즘

AI 시스템의 안전하지 않은 행위가 관찰될 경우 종료 또는 롤백 경로를 제공하십시오.

|   #    | 설명                                                      | 레벨  | 역할  |
| :----: | ------------------------------------------------------- | :-: | :-: |
| 13.1.1 | AI 모델 추론 및 출력을 즉시 중단할 수 있는 수동 킬 스위치 메커니즘이 존재하는지 확인하십시오. |  1  | D/V |
| 13.1.2 | 재정의 제어 장치가 허가된 인원만 접근할 수 있는지 확인하십시오.                    |  1  |  D  |
| 13.1.3 | 롤백 절차가 이전 모델 버전이나 안전 모드 작동으로 되돌릴 수 있는지 확인하십시오.          |  3  | D/V |
| 13.1.4 | 재정의 메커니즘이 정기적으로 테스트되는지 확인하십시오.                          |  3  |  V  |

---

## C13.2 인간 참여 결정 체크포인트

위험 임계값을 초과하는 경우 인간의 승인을 요구합니다.

|   #    | 설명                                                                    | 레벨  | 역할  |
| :----: | --------------------------------------------------------------------- | :-: | :-: |
| 13.2.1 | 고위험 AI 결정은 실행 전에 명시적인 인간 승인을 받아야 함을 확인하십시오.                           |  1  | D/V |
| 13.2.2 | 리스크 임계값이 명확하게 정의되어 있고 자동으로 인간 검토 워크플로우를 트리거하는지 확인하십시오.                |  1  |  D  |
| 13.2.3 | 시간에 민감한 결정이 필요한 시간 내에 인간의 승인을 얻을 수 없을 때 대비한 대체 절차가 있는지 확인하십시오.        |  2  |  D  |
| 13.2.4 | 적용 가능한 경우, 승격 절차가 서로 다른 의사결정 유형 또는 위험 범주에 대해 명확한 권한 수준을 정의하는지 확인하십시오. |  3  | D/V |

---

## C13.3 책임 연쇄 및 감사 가능성

작업자 행동 및 모델 결정을 기록하십시오.

|   #    | 설명                                                            | 레벨  | 역할  |
| :----: | ------------------------------------------------------------- | :-: | :-: |
| 13.3.1 | 모든 AI 시스템 결정과 인간 개입이 타임스탬프, 사용자 신원 및 결정 근거와 함께 기록되었는지 확인하십시오. |  1  | D/V |
| 13.3.2 | 감사 로그가 변조될 수 없으며 무결성 검증 메커니즘을 포함하고 있는지 확인하십시오.                |  2  |  D  |

---

## C13.4 설명 가능한 AI 기법

표면 특징 중요도, 반사실적 설명, 그리고 지역적 설명.

|   #    | 설명                                                                                      | 레벨  | 역할  |
| :----: | --------------------------------------------------------------------------------------- | :-: | :-: |
| 13.4.1 | AI 시스템이 인간이 읽을 수 있는 형식으로 그들의 결정에 대한 기본적인 설명을 제공하는지 확인하십시오.                              |  1  | D/V |
| 13.4.2 | 설명 품질이 인간 평가 연구 및 지표를 통해 검증되었는지 확인하십시오.                                                 |  2  |  V  |
| 13.4.3 | 중요한 결정에 대해 특성 중요도 점수 또는 기여도 방법(SHAP, LIME 등)이 사용 가능한지 확인하십시오.                           |  3  | D/V |
| 13.4.4 | 카운터팩추얼 설명이 입력값을 어떻게 수정하여 결과를 변경할 수 있는지를 보여주는지 확인하십시오. 이는 사용 사례 및 도메인에 적용 가능한 경우에 해당합니다. |  3  |  V  |

---

## C13.5 모델 카드 및 사용 공개사항

모델 카드에 의도된 사용, 성능 지표 및 윤리적 고려 사항을 유지하십시오.

|   #    | 설명                                                                                 | 레벨  | 역할  |
| :----: | ---------------------------------------------------------------------------------- | :-: | :-: |
| 13.5.1 | 모델 카드가 의도된 사용 사례, 한계 및 알려진 실패 모드를 문서화했는지 확인하십시오.                                   |  1  |  D  |
| 13.5.2 | 다양한 적용 가능 사용 사례에 대한 성능 지표가 공개되었는지 확인하십시오.                                          |  1  | D/V |
| 13.5.3 | 윤리적 고려사항, 편향 평가, 공정성 평가, 훈련 데이터 특성, 그리고 알려진 훈련 데이터 한계가 문서화되고 정기적으로 업데이트되는지 확인하십시오. |  2  |  D  |
| 13.5.4 | 모델 카드가 버전 관리되고 변경 추적과 함께 모델 수명 주기 전반에 걸쳐 유지되는지 확인하십시오.                             |  2  | D/V |

---

## C13.6 불확실성 정량화

응답에서 신뢰 점수 또는 엔트로피 측정치를 전파합니다.

|   #    | 설명                                               | 레벨  | 역할  |
| :----: | ------------------------------------------------ | :-: | :-: |
| 13.6.1 | AI 시스템이 출력과 함께 신뢰도 점수 또는 불확실성 측정값을 제공하는지 확인하십시오. |  1  |  D  |
| 13.6.2 | 불확실성 임계값이 추가적인 인간 검토 또는 대체 결정 경로를 유발하는지 확인하십시오.  |  2  | D/V |
| 13.6.3 | 불확실성 정량화 방법이 실제 데이터에 대해 보정되고 검증되었는지 확인하십시오.      |  2  |  V  |
| 13.6.4 | 불확실성 전파가 다단계 AI 워크플로우 전반에 걸쳐 유지되는지 확인하세요.        |  3  | D/V |

---

## C13.7 사용자 대상 투명성 보고서

사건, 드리프트, 데이터 사용에 관한 정기적인 공개를 제공합니다.

|   #    | 설명                                                           | 레벨  | 역할  |
| :----: | ------------------------------------------------------------ | :-: | :-: |
| 13.7.1 | 데이터 사용 정책 및 사용자 동의 관리 관행이 이해관계자에게 명확하게 전달되었는지 확인하십시오.        |  1  | D/V |
| 13.7.2 | AI 영향 평가가 수행되고 그 결과가 보고서에 포함되었는지 확인하십시오.                     |  2  | D/V |
| 13.7.3 | 정기적으로 공개되는 투명성 보고서가 AI 사고 및 운영 지표를 적절한 세부 사항으로 공개하는지 검증하십시오. |  2  | D/V |

### 참고 문헌

* [EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)](https://eur-lex.europa.eu/eli/reg/2024/1689/oj)
* [ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management](https://www.iso.org/standard/77304.html)
* [ISO/IEC 42001:2023 — AI Management Systems Requirements](https://www.iso.org/standard/81230.html)
* [NIST AI Risk Management Framework 1.0](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [NIST SP 800-53 Revision 5 — Security and Privacy Controls](https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-53r5.pdf)
* [A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)](https://arxiv.org/abs/1705.07874)
* [Model Cards for Model Reporting (Mitchell et al., 2018)](https://arxiv.org/abs/1810.03993)
* [Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)](https://arxiv.org/abs/1506.02142)
* [ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods](https://www.iso.org/standard/79804.html)
* [IEEE 7001-2021 — Transparency of Autonomous Systems](https://standards.ieee.org/ieee/7001/6929/)
* [GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)](https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX%3A32016R0679)
* [Human Oversight under Article 14 of the EU AI Act (Fink, 2025)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5147196)

