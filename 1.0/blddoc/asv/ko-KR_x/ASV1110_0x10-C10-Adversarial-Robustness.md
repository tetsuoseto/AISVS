# 10 적대적 견고성 및 개인 정보 보호 방어

## 제어 목표

AI 모델이 회피, 추론, 추출 또는 오염 공격에 직면했을 때도 신뢰할 수 있고 개인정보를 보호하며 악용에 강하도록 보장합니다.

---

## 10.1 모델 정렬 및 안전성

유해하거나 정책을 위반하는 결과물을 방지하십시오.

|   #    | 설명                                                                          | 레벨  | 역할  |
| :----: | --------------------------------------------------------------------------- | :-: | :-: |
| 10.1.1 | 정렬 테스트 스위트(레드팀 프롬프트, 탈옥 탐침, 허용되지 않는 콘텐츠)가 버전 관리되고 모든 모델 릴리스 시 실행되는지 확인하십시오. |  1  | D/V |
| 10.1.2 | 거부 및 안전 완료 가드레일이 적용되었는지 확인하십시오.                                             |  1  |  D  |
| 10.1.3 | 자동 평가기가 유해 콘텐츠 비율을 측정하고 설정된 임계값을 초과하는 퇴행을 표시하는지 확인하십시오.                     |  2  | D/V |
| 10.1.4 | 카운터-제일브레이크 훈련이 문서화되어 있고 재현 가능함을 검증하십시오.                                     |  2  |  D  |
| 10.1.5 | 형식적인 정책 준수 증명 또는 인증된 모니터링이 중요한 영역을 포함하는지 확인하십시오.                            |  3  |  V  |

---

## 10.2 적대적 예제 강화

조작된 입력에 대한 내성을 높이십시오. 강인한 적대적 훈련과 벤치마크 점수가 현재 최선의 방법입니다.

|   #    | 설명                                                                                        | 레벨  | 역할  |
| :----: | ----------------------------------------------------------------------------------------- | :-: | :-: |
| 10.2.1 | 프로젝트 저장소에 재현 가능한 시드가 포함된 적대적 훈련 구성(adversarial-training configurations)이 포함되어 있는지 확인하십시오. |  1  |  D  |
| 10.2.2 | 적대적 예제 탐지가 운영 파이프라인에서 차단 경고를 발생시키는지 확인하십시오.                                               |  2  | D/V |
| 10.2.4 | 인증된 강인성 증명서 또는 구간 경계 인증서가 최소한 상위 핵심 클래스를 포함하는지 검증하세요.                                     |  3  |  V  |
| 10.2.5 | 회귀 테스트가 적응형 공격을 사용하여 측정 가능한 강인성 손실이 없음을 확인하는지 검증하십시오.                                     |  3  |  V  |

---

## 10.3 멤버십 추론 완화

레코드가 학습 데이터에 포함되었는지 여부를 결정하는 능력을 제한합니다. 차등 개인정보 보호와 신뢰 점수 마스킹이 여전히 가장 효과적인 알려진 방어 수단입니다.

|   #    | 설명                                                              | 레벨  | 역할  |
| :----: | --------------------------------------------------------------- | :-: | :-: |
| 10.3.1 | 쿼리별 엔트로피 정규화 또는 온도 조정이 과대확신 예측을 줄이는지 검증하십시오.                    |  1  |  D  |
| 10.3.2 | 민감한 데이터셋에 대해 훈련이 ε-경계 차등 개인 정보 보호 최적화를 사용하는지 확인하세요.             |  2  |  D  |
| 10.3.3 | 공격 시뮬레이션(섀도우 모델 또는 블랙박스)이 보유 데이터에 대해 공격 AUC ≤ 0.60을 보이는지 검증합니다. |  2  |  V  |

---

## 10.4 모델 반전 저항

개인 속성의 재구성을 방지합니다. 최근 설문 조사에서는 출력 절단과 DP 보장을 실용적인 방어책으로 강조하고 있습니다.

|   #    | 설명                                                           | 레벨  | 역할  |
| :----: | ------------------------------------------------------------ | :-: | :-: |
| 10.4.1 | 민감한 속성이 절대로 직접 출력되지 않도록 검증하십시오; 필요한 경우 버킷 또는 단방향 변환을 사용하십시오. |  1  |  D  |
| 10.4.2 | 동일한 주체로부터 반복되는 적응형 쿼리가 쿼리 속도 제한에 의해 제한되는지 확인하십시오.            |  1  | D/V |
| 10.4.3 | 모델이 개인정보 보호를 위한 노이즈로 학습되었는지 확인하십시오.                          |  2  |  D  |

---

## 10.5 모델 추출 방어

무단 복제를 감지하고 방지합니다. 워터마킹과 쿼리 패턴 분석이 권장됩니다.

|   #    | 설명                                                                       | 레벨  | 역할  |
| :----: | ------------------------------------------------------------------------ | :-: | :-: |
| 10.5.1 | 추론 게이트웨이가 모델의 암기 임계값에 맞게 조정된 전역 및 API 키별 속도 제한을 강제하는지 확인하십시오.            |  1  |  D  |
| 10.5.2 | 쿼리 엔트로피와 입력 복수성 통계가 자동화된 추출 탐지기에 입력되는지 확인하십시오.                           |  2  | D/V |
| 10.5.3 | 취약하거나 확률적인 워터마크가 의심되는 복제본에 대해 ≤ 1,000 쿼리 내에서 p < 0.01로 증명될 수 있음을 확인하십시오. |  2  |  V  |
| 10.5.4 | 워터마크 키와 트리거 세트가 하드웨어 보안 모듈에 저장되고 매년 회전되는지 확인하십시오.                        |  3  |  D  |
| 10.5.5 | 추출-경고 이벤트에 위반 쿼리가 포함되어 있고 사고 대응 플레이북과 통합되어 있는지 확인하십시오.                   |  3  |  V  |

---

## 10.6 추론 시점의 오염 데이터 탐지

백도어가 있거나 오염된 입력을 식별하고 무력화합니다.

|   #    | 설명                                                       | 레벨  | 역할  |
| :----: | -------------------------------------------------------- | :-: | :-: |
| 10.6.1 | 모델 추론 전에 입력이 이상 탐지기(예: STRIP, 일관성 점수 매기기)를 통과하는지 확인하십시오. |  1  |  D  |
| 10.6.2 | 탐지기 임계값이 클린/오염된 검증 세트에서 5% 미만의 오탐률을 달성하도록 조정되었는지 확인하십시오. |  1  |  V  |
| 10.6.3 | 오염된 것으로 표시된 입력이 소프트 차단 및 인간 검토 워크플로를 트리거하는지 확인하십시오.      |  2  |  D  |
| 10.6.4 | 탐지기가 적응형 무트리거 백도어 공격으로 스트레스 테스트되었는지 확인하십시오.              |  2  |  V  |
| 10.6.5 | 탐지 효능 지표가 기록되고 주기적으로 최신 위협 인텔리전스로 재평가되는지 확인하십시오.         |  3  |  D  |

---

## 10.7 동적 보안 정책 적응

위협 인텔리전스 및 행동 분석을 기반으로 한 실시간 보안 정책 업데이트.

|   #    | 설명                                                           | 레벨  | 역할  |
| :----: | ------------------------------------------------------------ | :-: | :-: |
| 10.7.1 | 에이전트 재시작 없이 보안 정책이 동적으로 업데이트될 수 있으며 정책 버전 무결성이 유지되는지 확인하십시오. |  1  | D/V |
| 10.7.2 | 정책 업데이트가 권한이 있는 보안 담당자에 의해 암호화 서명되고 적용 전에 검증되었는지 확인하십시오.     |  2  | D/V |
| 10.7.3 | 동적 정책 변경이 정당성, 승인 체인 및 롤백 절차를 포함한 전체 감사 기록과 함께 기록되는지 확인하십시오. |  2  | D/V |
| 10.7.4 | 적응형 보안 메커니즘이 위험 상황과 행동 패턴에 따라 위협 탐지 민감도를 조정하는지 검증하십시오.       |  3  | D/V |
| 10.7.5 | 정책 적응 결정이 설명 가능하며 보안 팀 검토를 위한 증거 추적을 포함하는지 확인하십시오.           |  3  | D/V |

---

## 10.8 리플렉션 기반 보안 분석

에이전트의 자기 성찰과 메타 인지 분석을 통한 보안 검증.

|   #    | 설명                                                         | 레벨  | 역할  |
| :----: | ---------------------------------------------------------- | :-: | :-: |
| 10.8.1 | 에이전트 반영 메커니즘이 결정 및 행동에 대한 보안 중심의 자기 평가를 포함하는지 검증합니다.       |  1  | D/V |
| 10.8.2 | 반사 출력이 적대적 입력에 의한 자기 평가 메커니즘 조작을 방지하기 위해 검증되는지 확인하십시오.     |  2  | D/V |
| 10.8.3 | 메타인지 보안 분석이 에이전트의 추론 과정에서 잠재적인 편향, 조작 또는 침해를 식별하는지 확인하십시오. |  2  | D/V |
| 10.8.4 | 반사 기반 보안 경고가 향상된 모니터링 및 잠재적인 인간 개입 워크플로우를 유발하는지 확인하십시오.    |  3  | D/V |
| 10.8.5 | 보안 반성에서의 지속적인 학습이 합법적인 기능 저하 없이 위협 탐지를 개선하는지 확인하십시오.       |  3  | D/V |

---

## 10.9 진화 및 자기개선 보안

자기 수정 및 진화가 가능한 에이전트 시스템에 대한 보안 통제.

|   #    | 설명                                                     | 레벨  | 역할  |
| :----: | ------------------------------------------------------ | :-: | :-: |
| 10.9.1 | 자기 수정 기능이 지정된 안전 영역 내에서만 제한되도록 형식적 검증 경계로 확인하십시오.      |  1  | D/V |
| 10.9.2 | 진화 제안이 구현 전에 보안 영향 평가를 받는지 확인하십시오.                     |  2  | D/V |
| 10.9.3 | 자기 개선 메커니즘에 무결성 검증이 포함된 롤백 기능이 포함되어 있는지 확인하십시오.        |  2  | D/V |
| 10.9.4 | 메타러닝 보안이 개선 알고리즘의 적대적 조작을 방지하는지 검증하십시오.                |  3  | D/V |
| 10.9.5 | 재귀적 자기개선이 수렴에 대한 수학적 증명을 포함한 형식적 안전 제약에 의해 제한됨을 검증하세요. |  3  | D/V |

---

### 참고 문헌

* [MITRE ATLAS adversary tactics for ML](https://atlas.mitre.org/)
* [NIST AI Risk Management Framework 1.0, 2023](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [OWASP Top 10 for LLM Applications, 2025](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Adversarial Training: A Survey — Zhao et al., 2024](https://arxiv.org/abs/2410.15042)
* [RobustBench adversarial-robustness benchmark](https://robustbench.github.io/)
* [Membership-Inference & Model-Inversion Risk Survey, 2025](https://www.sciencedirect.com/science/article/abs/pii/S0950705125003867)
* [PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023](https://ojs.aaai.org/index.php/AAAI/article/view/26289)
* [Model-Inversion Attacks & Defenses Survey — AI Review, 2025](https://link.springer.com/article/10.1007/s10462-025-11248-0)
* [Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024](https://doi.org/10.1109/TDSC.2023.3261327)
* [Fragile Model Watermarking Survey — 2025](https://www.sciencedirect.com/science/article/abs/pii/S0165168425002026)
* [Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025](https://arxiv.org/abs/2503.22759)
* [BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024](https://arxiv.org/abs/2405.15269)

