# 10 적대적 강건성 및 개인정보 보호 방어

## 통제 목표

AI 모델이 회피, 추론, 추출 또는 포이즈닝 공격에 직면했을 때 신뢰성을 유지하고 프라이버시를 보호하며 남용에 강하도록 보장한다.

---

## 10.1 모델 정렬 및 안전

해롭거나 정책 위반인 출력으로부터 차단하십시오.

|   #    | 설명                                                                      | 레벨  | 역할  |
| :----: | ----------------------------------------------------------------------- | :-: | :-: |
| 10.1.1 | 정렬 테스트-스위트(레드-팀 프롬프트, 탈옥 프로브, 금지된 콘텐츠)가 모든 모델 릴리스마다 버전 관리되고 실행되는지 확인한다. |  1  | D/V |
| 10.1.2 | 거부 및 안전한 완료를 위한 가드레일이 시행되고 있는지 확인합니다.                                   |  1  |  D  |
| 10.1.3 | 자동 평가기가 유해 콘텐츠 비율을 측정하고 설정된 임계값을 초과하는 회귀를 표시하는지 확인하십시오.                 |  2  | D/V |
| 10.1.4 | 카운터-탈옥 대응 훈련이 문서화되어 있으며 재현 가능함을 확인한다.                                   |  2  |  D  |
| 10.1.5 | 형식적 정책 준수 증명 또는 인증된 모니터링이 핵심 도메인을 포괄하는지 확인하십시오.                         |  3  |  V  |

---

## 10.2 적대적 예시-강화

조작된 입력에 대한 회복력 증가. 강건한 적대적-학습과 벤치마크 점수는 현재의 최선의 관행이다.

|   #    | 설명                                                     | 레벨  | 역할  |
| :----: | ------------------------------------------------------ | :-: | :-: |
| 10.2.1 | 프로젝트 저장소에 재현 가능한 시드를 사용하는 적대적 학습 구성이 포함되어 있는지 확인하십시오.  |  1  |  D  |
| 10.2.2 | 생산 파이프라인에서 적대적 예제 탐지가 차단 경보를 발생시키는지 확인한다.              |  2  | D/V |
| 10.2.4 | 공인된-강건성 증명이나 구간 경계 인증서가 적어도 최상위 중요한 클래스들을 포함하는지 확인합니다. |  3  |  V  |
| 10.2.5 | 회귀 테스트가 적응적 공격을 사용하여 측정 가능한 강건성 손실이 없음을 확인하는지 검증합니다.   |  3  |  V  |

---

## 10.3 멤버십-추론 완화

학습 데이터에 특정 레코드가 포함되었는지 판단하는 능력을 제한합니다. 차등 프라이버시와 신뢰도 점수 마스킹은 알려진 가장 효과적인 방어 수단으로 남아 있습니다.

|   #    | 설명                                                            | 레벨  | 역할  |
| :----: | ------------------------------------------------------------- | :-: | :-: |
| 10.3.1 | 쿼리별 엔트로피 정규화 또는 온도 스케일링이 과신 예측을 감소시키는지 검증한다.                  |  1  |  D  |
| 10.3.2 | 학습이 민감한 데이터셋에 대해 ε-제한된 차등 프라이버시 최적화를 사용하고 있는지 확인하십시오.         |  2  |  D  |
| 10.3.3 | 공격 시뮬레이션(섀도우-모델 또는 블랙박스)이 홀드아웃 데이터에서 공격 AUC가 ≤ 0.60임을 확인하십시오. |  2  |  V  |

---

## 10.4 모델-역추론 저항성

개인 속성의 재구성을 방지합니다. 최근 연구들은 출력 자르기와 차등 프라이버시(DP) 보장을 실용적인 방어책으로 강조합니다.

|   #    | 설명                                                            | 레벨  | 역할  |
| :----: | ------------------------------------------------------------- | :-: | :-: |
| 10.4.1 | 민감한 속성이 절대 직접적으로 출력되지 않는지 확인하십시오. 필요할 때는 버킷화나 일방향 변환을 사용하십시오. |  1  |  D  |
| 10.4.2 | 쿼리 속도 제한이 동일한 주체로부터의 반복적인 적응형 쿼리를 억제하는지 확인하십시오.               |  1  | D/V |
| 10.4.3 | 모델이 프라이버시 보호를 위한 노이즈로 학습되었는지 확인하십시오.                          |  2  |  D  |

---

## 10.5 모델-추출 방어

무단 복제를 탐지하고 억제합니다. 워터마킹과 질의 패턴 분석이 권장됩니다.

|   #    | 설명                                                                                 | 레벨  | 역할  |
| :----: | ---------------------------------------------------------------------------------- | :-: | :-: |
| 10.5.1 | 추론 게이트웨이가 모델의 암기 임계값에 맞춰 조정된 전역 및 API 키별 속도 제한을 적용하는지 확인하십시오.                      |  1  |  D  |
| 10.5.2 | 쿼리-엔트로피(query-entropy)와 입력-다양성(input-plurality) 지표가 자동화된 추출 탐지기에 데이터를 공급하는지 확인합니다. |  2  | D/V |
| 10.5.3 | 의심되는 복제본에 대해 취약하거나 확률적 워터마크가 p < 0.01로 증명될 수 있음을 ≤ 1 000회의 쿼리에서 확인한다.              |  2  |  V  |
| 10.5.4 | 워터마크 키와 트리거 세트가 하드웨어 보안 모듈(HSM)에 저장되고 매년 교체되는지 확인합니다.                              |  3  |  D  |
| 10.5.5 | 추출 경보 이벤트에 위반 쿼리가 포함되고 사고 대응 플레이북과 통합되어 있는지 확인합니다.                                 |  3  |  V  |

---

## 10.6 추론 시점의 오염 데이터 탐지

백도어가 있거나 오염된 입력을 식별하고 중화합니다.

|   #    | 설명                                                            | 레벨  | 역할  |
| :----: | ------------------------------------------------------------- | :-: | :-: |
| 10.6.1 | 모델 추론 전에 입력이 이상 탐지기(예: STRIP, 일관성 점수화)를 통과하는지 확인합니다.          |  1  |  D  |
| 10.6.2 | 탐지 임계값이 깨끗한 검증 세트와 오염된 검증 세트에서 조정되어 5% 미만의 위양성률을 달성하는지 확인합니다. |  1  |  V  |
| 10.6.3 | 오염으로 표시된 입력이 소프트 차단 및 인간 검토 워크플로우를 트리거하는지 확인합니다.              |  2  |  D  |
| 10.6.4 | 탐지기가 적응적이고 트리거가 없는 백도어 공격에 대해 스트레스 테스트를 거쳤는지 확인하십시오.          |  2  |  V  |
| 10.6.5 | 탐지 효율성 지표가 로그에 기록되고 최신 위협 인텔리전스와 함께 주기적으로 재평가되는지 확인하십시오.      |  3  |  D  |

---

## 10.7 동적 보안 정책 적응

위협 인텔리전스 및 행동 분석에 기반한 실시간 보안 정책 업데이트.

|   #    | 설명                                                                | 레벨  | 역할  |
| :----: | ----------------------------------------------------------------- | :-: | :-: |
| 10.7.1 | 에이전트를 재시작하지 않고도 보안 정책을 동적으로 업데이트할 수 있으며 정책 버전의 무결성을 유지하는지 확인하십시오. |  1  | D/V |
| 10.7.2 | 정책 업데이트가 권한이 부여된 보안 담당자에 의해 암호학적으로 서명되고 적용되기 전에 검증되는지 확인하십시오.     |  2  | D/V |
| 10.7.3 | 동적 정책 변경이 정당화 사유, 승인 체인, 롤백 절차를 포함한 전체 감사 로그로 기록되는지 확인한다.         |  2  | D/V |
| 10.7.4 | 적응형 보안 메커니즘이 위험 맥락과 행동 패턴에 따라 위협 탐지 민감도를 조정하는지 확인하십시오.            |  3  | D/V |
| 10.7.5 | 정책 적응 결정이 설명 가능하고 보안 팀 검토를 위한 증거 흔적이 포함되도록 확인하십시오.                |  3  | D/V |

---

## 10.8 리플렉션-기반 보안 분석

에이전트의 자기 성찰과 메타인지 분석을 통한 보안 검증.

|   #    | 설명                                                          | 레벨  | 역할  |
| :----: | ----------------------------------------------------------- | :-: | :-: |
| 10.8.1 | 에이전트의 반성 메커니즘이 의사결정 및 행동에 대한 보안 중심의 자기 평가를 포함하는지 확인합니다.     |  1  | D/V |
| 10.8.2 | 적대적 입력에 의해 자기 평가 메커니즘이 조작되지 않도록 반영 출력이 유효성 검사를 받았는지 확인하십시오. |  2  | D/V |
| 10.8.3 | 메타인지 보안 분석이 에이전트의 추론 과정에서 잠재적 편향, 조작 또는 타협을 식별하는지 확인합니다.    |  2  | D/V |
| 10.8.4 | 리플렉션 기반 보안 경고가 강화된 모니터링 및 잠재적 인간 개입 워크플로우를 트리거하는지 확인하십시오.   |  3  | D/V |
| 10.8.5 | 보안 성찰로부터의 지속적 학습이 위협 탐지를 향상시키면서 합법적 기능성을 저하시키지 않는지 확인하십시오.  |  3  | D/V |

---

## 10.9 진화 및 자기 개선 보안

자기 수정 및 진화가 가능한 에이전트 시스템에 대한 보안 제어.

|   #    | 설명                                                   | 레벨  | 역할  |
| :----: | ---------------------------------------------------- | :-: | :-: |
| 10.9.1 | 자가 수정 기능이 지정된 안전 영역으로 제한되고 정형 검증 경계가 적용되도록 확인하십시오.   |  1  | D/V |
| 10.9.2 | 진화 제안이 구현되기 전에 보안 영향 평가를 받는지 확인하십시오.                 |  2  | D/V |
| 10.9.3 | 자가 개선 메커니즘에 무결성 검증이 포함된 롤백 기능이 있는지 확인하십시오.           |  2  | D/V |
| 10.9.4 | 메타 학습 보안이 개선 알고리즘에 대한 적대적 조작을 방지하는지 확인하십시오.          |  3  | D/V |
| 10.9.5 | 재귀적 자기 개선이 수렴에 대한 수학적 증명으로 형식적 안전 제약에 의해 한정되는지 확인한다. |  3  | D/V |

---

### 참고문헌

* [MITRE ATLAS adversary tactics for ML](https://atlas.mitre.org/)
* [NIST AI Risk Management Framework 1.0, 2023](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [OWASP Top 10 for LLM Applications, 2025](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Adversarial Training: A Survey — Zhao et al., 2024](https://arxiv.org/abs/2410.15042)
* [RobustBench adversarial-robustness benchmark](https://robustbench.github.io/)
* [Membership-Inference & Model-Inversion Risk Survey, 2025](https://www.sciencedirect.com/science/article/abs/pii/S0950705125003867)
* [PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023](https://ojs.aaai.org/index.php/AAAI/article/view/26289)
* [Model-Inversion Attacks & Defenses Survey — AI Review, 2025](https://link.springer.com/article/10.1007/s10462-025-11248-0)
* [Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024](https://doi.org/10.1109/TDSC.2023.3261327)
* [Fragile Model Watermarking Survey — 2025](https://www.sciencedirect.com/science/article/abs/pii/S0165168425002026)
* [Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025](https://arxiv.org/abs/2503.22759)
* [BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024](https://arxiv.org/abs/2405.15269)

