# C7 모델 동작, 출력 제어 및 안전 보증

## 통제 목표

모델 출력은 구조화되고, 신뢰할 수 있으며, 안전하고, 설명 가능하며, 프로덕션 환경에서 지속적으로 모니터링되어야 한다. 이를 통해 모델의 환각, 개인정보 유출, 유해한 콘텐츠, 제어를 벗어난 실행을 줄이고, 동시에 사용자 신뢰와 규제 준수를 높일 수 있다.

---

## C7.1 출력 형식 강제

엄격한 스키마, 제약된 디코딩, 그리고 다운스트림 검증은 형태가 잘못되었거나 악의적인 콘텐츠가 확산되기 전에 차단합니다.

|   #   | 설명                                                                                                  | 레벨  | 역할  |
| :---: | --------------------------------------------------------------------------------------------------- | :-: | :-: |
| 7.1.1 | 시스템 프롬프트에 응답 스키마(예: JSON 스키마)가 제공되는지 확인하고, 모든 출력이 자동으로 검증되도록 하십시오. 규격에 맞지 않는 출력은 수정되거나 거부되도록 처리합니다. |  1  | D/V |
| 7.1.2 | 제약된 디코딩(중지 토큰, 정규식, max-tokens)이 활성화되어 오버플로우나 프롬프트 주입 사이드 채널을 방지하는지 확인하십시오.                         |  1  | D/V |
| 7.1.3 | 하류 구성요소가 출력값을 신뢰할 수 없는 것으로 간주하고, 스키마나 주입에 안전한 역직렬화 도구로 검증하는지 확인합니다.                                 |  2  | D/V |
| 7.1.4 | 부적절한 출력 이벤트가 로그에 기록되고, 레이트 제한이 적용되며, 모니터링에 노출되는지 확인합니다.                                             |  3  |  V  |

---

## C7.2 환각 탐지 및 완화

불확실성 추정 및 대체 전략은 허위 답변을 억제한다.

|   #   | 설명                                                                              | 레벨  | 역할  |
| :---: | ------------------------------------------------------------------------------- | :-: | :-: |
| 7.2.1 | 토큰 수준 로그 확률, 앙상블 자기 일관성, 또는 미세 조정된 환각 탐지기가 각 답변에 신뢰도 점수를 할당하는지 확인한다.            |  1  | D/V |
| 7.2.2 | 구성 가능한 신뢰도 임계값 미만의 응답이 대체 워크플로우를 트리거하는지 확인합니다(예: 검색 기반 증강 생성, 보조 모델, 또는 인간 검토). |  1  | D/V |
| 7.2.3 | 환각 사례들이 근본 원인 메타데이터로 태그되고 포스트모템 및 파인튜닝 파이프라인으로 전달되는지 확인합니다.                     |  2  | D/V |
| 7.2.4 | 주요 모델 또는 지식 기반 업데이트 이후 임계값들과 탐지기들이 재보정되는지 확인하십시오.                               |  3  | D/V |
| 7.2.5 | 대시보드 시각화가 환각률을 추적하는지 확인하십시오.                                                    |  3  |  V  |

---

## C7.3 출력 안전성 및 개인정보 보호 필터링

정책 필터와 레드팀의 커버리지는 사용자와 기밀 데이터를 보호합니다.

|   #   | 설명                                                                            | 레벨  | 역할  |
| :---: | ----------------------------------------------------------------------------- | :-: | :-: |
| 7.3.1 | 생성 전 및 생성 후 분류기가 정책에 부합하도록 혐오 발언, 괴롭힘, 자해, 극단주의 및 성적으로 노골적인 콘텐츠를 차단하는지 확인합니다. |  1  | D/V |
| 7.3.2 | 모든 응답에서 PII/PCI 탐지와 자동 비식별 처리가 실행되는지 확인하고, 위반 시 개인정보 사고가 발생합니다.               |  1  | D/V |
| 7.3.3 | 기밀 태그(예: 영업비밀)가 텍스트, 이미지 또는 코드와 같은 모달리티 간에 전파되어 누출을 방지하는지 확인합니다.              |  2  |  D  |
| 7.3.4 | 필터 우회 시도 또는 고위험 분류가 2차 승인이나 사용자 재인증이 필요한지 확인합니다.                              |  3  | D/V |
| 7.3.5 | 필터링 임계값이 법적 관할권 및 사용자 연령/역할 맥락을 반영하는지 확인하십시오.                                 |  3  | D/V |

---

## C7.4 출력 및 동작 제한

요청 속도 제한과 승인 게이트가 남용과 과도한 자율성을 방지합니다.

|   #   | 설명                                                                        | 레벨  | 역할  |
| :---: | ------------------------------------------------------------------------- | :-: | :-: |
| 7.4.1 | 사용자별 및 API 키별 할당량이 429 오류에서 지수 백오프를 적용하여 요청 수, 토큰 수, 비용을 제한하는지 확인하십시오.    |  1  |  D  |
| 7.4.2 | 특권 작업(파일 쓰기, 코드 실행, 네트워크 호출)이 정책 기반 승인 또는 인간의 개입이 필요한지 확인하십시오.            |  1  | D/V |
| 7.4.3 | 동일한 요청으로 생성된 이미지, 코드, 텍스트가 악성 콘텐츠를 은닉하는 데 사용될 수 없도록 교차 모달 일관성 검사를 확인하십시오. |  2  | D/V |
| 7.4.4 | 에이전트 위임 깊이, 재귀 한도 및 허용 도구 목록이 명시적으로 구성되어 있는지 확인합니다.                       |  2  |  D  |
| 7.4.5 | 제한 위반이 SIEM 수집을 위해 구조화된 보안 이벤트를 방출하는지 확인합니다.                              |  3  |  V  |

---

## C7.5 출력 설명 가능성

투명한 신호는 사용자 신뢰와 내부 디버깅을 향상시킵니다.

|   #   | 설명                                                               | 레벨  | 역할  |
| :---: | ---------------------------------------------------------------- | :-: | :-: |
| 7.5.1 | 위험 평가가 적절하다고 판단될 때 사용자에게 표시되는 신뢰도 점수 또는 간략한 추론 요약이 노출되는지 확인하십시오. |  2  | D/V |
| 7.5.2 | 생성된 설명이 민감한 시스템 프롬프트나 독점 데이터를 노출하지 않는지 확인하십시오.                   |  2  | D/V |
| 7.5.3 | 시스템이 토큰 수준의 로그 확률이나 어텐션 맵을 캡처하고 인가된 열람을 위해 이를 저장하는지 확인하십시오.      |  3  |  D  |
| 7.5.4 | 설명 가능성 산출물이 모델 릴리스와 함께 버전 관리되는지 확인하십시오.                          |  3  |  V  |

---

## C7.6 모니터링 통합

실시간 관측성은 개발과 운영 간의 피드백 루프를 닫습니다.

|   #   | 설명                                                                           | 레벨  | 역할  |
| :---: | ---------------------------------------------------------------------------- | :-: | :-: |
| 7.6.1 | 다음 메트릭이 중앙 모니터링 플랫폼으로 스트리밍되는지 확인하십시오: (스키마 위반, 환각률, 유해성, PII 누출, 지연 시간, 비용). |  1  |  D  |
| 7.6.2 | 각 안전성 지표에 대해 경보 임계값이 정의되어 있는지 확인하고, 당직 에스컬레이션 경로가 마련되어 있는지 확인합니다.            |  1  |  V  |
| 7.6.3 | 대시보드들이 출력 이상과 모델/버전, 피처 플래그 및 상류 데이터 변경 간의 상관관계가 있는지 확인합니다.                  |  2  |  V  |
| 7.6.4 | 문서화된 MLOps 워크플로우 내에서 모니터링 데이터가 재학습, 미세 조정 또는 규칙 업데이트로 피드백되는지 확인한다.           |  2  | D/V |
| 7.6.5 | 민감한 로그의 누출을 방지하기 위해 모니터링 파이프라인이 침투 테스트를 거쳤고 접근 제어가 적용되어 있는지 확인합니다.           |  3  |  V  |

---

## 7.7 생성형 미디어 안전 대책

AI 시스템이 정책 제약을 적용하고 출력 검증 및 추적 가능성을 통해 불법적이거나 해롭거나 무단 미디어 콘텐츠를 생성하지 않도록 보장한다.

|   #   | 설명                                                                                               | 레벨  | 역할  |
| :---: | ------------------------------------------------------------------------------------------------ | :-: | :-: |
| 7.7.1 | 시스템 프롬프트와 사용자 지침이 불법적이거나 해롭거나 합의 없이 생성된 딥페이크 미디어(예: 이미지, 비디오, 오디오)의 생성을 명시적으로 금지하는지 확인합니다.       |  1  | D/V |
| 7.7.2 | 프롬프트가 모방 행위, 성적으로 노골적인 딥페이크, 또는 합의 없이 실존 인물을 묘사하는 미디어를 생성하려는 시도를 차단하도록 필터링되는지 확인하십시오.            |  2  | D/V |
| 7.7.3 | 시스템이 저작권이 있는 미디어의 무단 복제를 방지하기 위해 지각 해싱, 워터마크 탐지 또는 지문 추출을 사용하는지 확인하십시오.                          |  2  |  V  |
| 7.7.4 | 모든 생성 미디어가 암호학적으로 서명되었거나, 워터마크가 삽입되었거나, 변조 방지 기능이 있는 출처 메타데이터로 내장되어 다운스트림 추적 가능하도록 되어 있는지 확인합니다. |  3  | D/V |
| 7.7.5 | 우회 시도(예: 프롬프트 은폐, 은어, 적대적 어법)가 탐지되고 로깅되며 속도 제한이 적용되는지 확인하고, 반복적 악용이 모니터링 시스템에 노출되는지 확인합니다.       |  3  |  V  |

## 참고문헌

* [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)
* [ISO/IEC 42001:2023 – AI Management System](https://www.iso.org/obp/ui/en/)
* [OWASP Top-10 for Large Language Model Applications (2025)](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Improper Output Handling – OWASP LLM05:2025](https://genai.owasp.org/llmrisk/llm052025-improper-output-handling/)
* [Practical Techniques to Constrain LLM Output](https://mychen76.medium.com/practical-techniques-to-constraint-llm-output-in-json-format-e3e72396c670)
* [Dataiku – Structured Text Generation Guide](https://blog.dataiku.com/your-guide-to-structured-text-generation)
* [VL-Uncertainty: Detecting Hallucinations](https://arxiv.org/abs/2411.11919)
* [HaDeMiF: Hallucination Detection & Mitigation](https://openreview.net/forum?id=VwOYxPScxB)
* [Building Confidence in LLM Outputs](https://www.alkymi.io/data-science-room/building-confidence-in-llm-outputs)
* [Explainable AI & LLMs](https://duncsand.medium.com/explainable-ai-140912d31b3b)
* [LLM Red-Teaming Guide](https://www.confident-ai.com/blog/red-teaming-llms-a-step-by-step-guide)
* [Sensitive Information Disclosure in LLMs](https://virtualcyberlabs.com/llm-sensitive-information-disclosure/)
* [LangChain – Chat Model Rate Limiting](https://python.langchain.com/docs/how_to/chat_model_rate_limiting/)
* [OpenAI Rate-Limit & Exponential Back-off](https://hackernoon.com/openais-rate-limit-a-guide-to-exponential-backoff-for-llm-evaluation)
* [Arize AI – LLM Observability Platform](https://arize.com/)

