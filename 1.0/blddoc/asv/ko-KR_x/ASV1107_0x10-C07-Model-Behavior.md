# C7 모델 행동, 출력 제어 및 안전 보장

## 통제 목표

모델 출력은 구조적이고 신뢰할 수 있으며 안전하고 설명 가능하며 생산 환경에서 지속적으로 모니터링되어야 합니다. 이렇게 하면 환각 현상, 개인정보 유출, 유해한 콘텐츠 및 통제 불능 행동이 줄어들고 사용자 신뢰와 규제 준수가 향상됩니다.

---

## C7.1 출력 형식 강제 적용

엄격한 스키마, 제한된 디코딩 및 후속 검증은 잘못된 형식이나 악성 콘텐츠가 확산되기 전에 차단합니다.

|   #   | 설명                                                                                           | 레벨  | 역할  |
| :---: | -------------------------------------------------------------------------------------------- | :-: | :-: |
| 7.1.1 | 응답 스키마(예: JSON 스키마)가 시스템 프롬프트에 제공되고 모든 출력이 자동으로 검증되는지 확인하십시오. 규격에 맞지 않는 출력은 수리 또는 거부를 유발합니다. |  1  | D/V |
| 7.1.2 | 오버플로우 또는 프롬프트 인젝션 부채널을 방지하기 위해 제약된 디코딩(중지 토큰, 정규식, 최대 토큰)이 활성화되어 있는지 확인하십시오.                 |  1  | D/V |
| 7.1.3 | 하류 구성 요소가 출력을 신뢰할 수 없는 것으로 처리하고 스키마 또는 인젝션에 안전한 역직렬 변환기를 사용하여 검증하는지 확인하십시오.                  |  2  | D/V |
| 7.1.4 | 부적절한 출력 이벤트가 기록되고, 속도 제한되며, 모니터링에 노출되는지 확인하십시오.                                              |  3  |  V  |

---

## C7.2 환각 탐지 및 완화

불확실성 추정과 폴백 전략은 조작된 답변을 억제합니다.

|   #   | 설명                                                                           | 레벨  | 역할  |
| :---: | ---------------------------------------------------------------------------- | :-: | :-: |
| 7.2.1 | 토큰 수준 로그 확률, 앙상블 자기 일관성 또는 미세 조정된 환각 탐지기가 각 답변에 신뢰도 점수를 할당하는지 확인하십시오.        |  1  | D/V |
| 7.2.2 | 구성 가능한 신뢰도 임계값 이하의 응답이 대체 워크플로우(예: 검색 확대 생성, 보조 모델 또는 인간 검토)를 트리거하는지 확인하십시오. |  1  | D/V |
| 7.2.3 | 환각 발생 사례가 근본 원인 메타데이터로 태그되고 사후 분석 및 미세 조정 파이프라인에 전달되는지 확인하십시오.               |  2  | D/V |
| 7.2.4 | 주요 모델 또는 지식 기반 업데이트 후에 임계값과 탐지기가 재보정되었는지 확인하십시오.                             |  3  | D/V |
| 7.2.5 | 대시보드 시각화가 환각률을 추적하는지 확인하세요.                                                  |  3  |  V  |

---

## C7.3 출력 안전성 및 개인정보 보호 필터링

정책 필터 및 레드팀 커버리지는 사용자와 기밀 데이터를 보호합니다.

|   #   | 설명                                                                        | 레벨  | 역할  |
| :---: | ------------------------------------------------------------------------- | :-: | :-: |
| 7.3.1 | 정책에 부합하는 증오, 괴롭힘, 자해, 극단주의 및 성적으로 노골적인 콘텐츠를 사전 및 사후 생성 분류기가 차단하는지 확인하십시오. |  1  | D/V |
| 7.3.2 | PII/PCI 감지 및 자동 삭제가 모든 응답에서 실행되는지 확인하십시오; 위반 시 개인정보 사고가 발생합니다.            |  1  | D/V |
| 7.3.3 | 기밀성 태그(예: 영업 비밀)가 텍스트, 이미지 또는 코드에서 누출을 방지하기 위해 여러 양식에 걸쳐 전파되는지 확인하십시오.    |  2  |  D  |
| 7.3.4 | 필터 우회 시도 또는 고위험 분류가 2차 승인 또는 사용자 재인증을 요구하는지 확인하십시오.                       |  3  | D/V |
| 7.3.5 | 필터링 임계값이 법적 관할 구역 및 사용자 연령/역할 컨텍스트를 반영하는지 확인하십시오.                         |  3  | D/V |

---

## C7.4 출력 및 동작 제한

비율 제한과 승인 게이트는 남용과 과도한 자율성을 방지합니다.

|   #   | 설명                                                                                 | 레벨  | 역할  |
| :---: | ---------------------------------------------------------------------------------- | :-: | :-: |
| 7.4.1 | 사용자별 및 API 키별 할당량이 429 오류에 대해 지수적 백오프로 요청 수, 토큰 수 및 비용을 제한하는지 확인하세요.               |  1  |  D  |
| 7.4.2 | 특권 작업(파일 쓰기, 코드 실행, 네트워크 호출 등)이 정책 기반 승인 또는 인간 개입을 필요로 하는지 확인하십시오.                 |  1  | D/V |
| 7.4.3 | 교차 모달 일관성 검사가 동일한 요청에 대해 생성된 이미지, 코드 및 텍스트가 악성 콘텐츠를 밀수하는 데 사용될 수 없도록 보장하는지 확인하십시오. |  2  | D/V |
| 7.4.4 | 에이전트 위임 깊이, 재귀 한도 및 허용된 도구 목록이 명시적으로 구성되었는지 확인하십시오.                                |  2  |  D  |
| 7.4.5 | 한도를 초과하는 경우 SIEM 수집을 위한 구조화된 보안 이벤트가 발생하는지 확인하십시오.                                 |  3  |  V  |

---

## C7.5 출력 설명 가능성

투명한 신호는 사용자 신뢰와 내부 디버깅을 향상시킵니다.

|   #   | 설명                                                                 | 레벨  | 역할  |
| :---: | ------------------------------------------------------------------ | :-: | :-: |
| 7.5.1 | 사용자에게 노출되는 신뢰도 점수 또는 간단한 추론 요약이 위험 평가 결과 적절하다고 판단될 때 제공되는지 확인하십시오. |  2  | D/V |
| 7.5.2 | 생성된 설명이 민감한 시스템 프롬프트나 독점 데이터를 노출하지 않는지 확인하십시오.                     |  2  | D/V |
| 7.5.3 | 시스템이 토큰 수준의 로그 확률 또는 어텐션 맵을 캡처하고 이를 권한 있는 검사를 위해 저장하는지 확인하십시오.     |  3  |  D  |
| 7.5.4 | 설명 가능성 산출물이 감사 가능성을 위해 모델 릴리스와 함께 버전 관리되는지 확인하십시오.                 |  3  |  V  |

---

## C7.6 모니터링 통합

실시간 가시성은 개발과 운영 간의 연결 고리를 완성합니다.

|   #   | 설명                                                                       | 레벨  | 역할  |
| :---: | ------------------------------------------------------------------------ | :-: | :-: |
| 7.6.1 | 메트릭(스키마 위반, 환각 비율, 독성, PII 누출, 지연 시간, 비용)이 중앙 모니터링 플랫폼으로 스트리밍되는지 확인하십시오. |  1  |  D  |
| 7.6.2 | 각 안전 지표에 대해 경보 임계값이 정의되어 있으며, 호출 시 에스컬레이션 경로가 설정되어 있는지 검증합니다.            |  1  |  V  |
| 7.6.3 | 대시보드가 출력 이상을 모델/버전, 기능 플래그, 상위 데이터 변경 사항과 연관시키는지 확인합니다.                  |  2  |  V  |
| 7.6.4 | 모니터링 데이터가 문서화된 MLOps 워크플로 내에서 재학습, 미세조정 또는 규칙 업데이트에 다시 피드백되는지 확인하십시오.    |  2  | D/V |
| 7.6.5 | 민감한 로그 유출을 방지하기 위해 모니터링 파이프라인이 침투 테스트되고 접근 제어가 적용되었는지 확인하십시오.            |  3  |  V  |

---

## 7.7 생성 미디어 안전장치

정책 제약, 출력 검증 및 추적성을 시행하여 AI 시스템이 불법적이거나 유해하거나 무단의 미디어 콘텐츠를 생성하지 않도록 보장합니다.

|   #   | 설명                                                                                                                   | 레벨  | 역할  |
| :---: | -------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 7.7.1 | 시스템 프롬프트 및 사용자 지침이 불법적, 유해하거나 비동의 deepfake 미디어(예: 이미지, 비디오, 오디오)의 생성을 명확히 금지하는지 확인하십시오.                              |  1  | D/V |
| 7.7.2 | 프롬프트가 사칭 생성 시도, 성적으로 노골적인 딥페이크, 또는 동의 없이 실제 개인을 묘사하는 미디어에 대해 필터링되는지 확인하십시오.                                          |  2  | D/V |
| 7.7.3 | 시스템이 무단 복제를 방지하기 위해 지각 해싱(perceptual hashing), 워터마크 감지(watermark detection), 또는 지문 인식(fingerprinting)을 사용하는지 확인하십시오. |  2  |  V  |
| 7.7.4 | 모든 생성된 미디어가 하류 추적 가능성을 위해 암호학적으로 서명되고, 워터마크가 삽입되거나 변조 방지 출처 메타데이터가 내장되어 있는지 확인하십시오.                                  |  3  | D/V |
| 7.7.5 | 우회 시도(예: 프롬프트 난독화, 속어, 적대적 표현)가 감지되고 기록되며 속도 제한이 적용되는지 확인하십시오; 반복적인 남용은 모니터링 시스템에 보고됩니다.                             |  3  |  V  |

## 참고 문헌

* [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)
* [ISO/IEC 42001:2023 – AI Management System](https://www.iso.org/obp/ui/en/)
* [OWASP Top-10 for Large Language Model Applications (2025)](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Improper Output Handling – OWASP LLM05:2025](https://genai.owasp.org/llmrisk/llm052025-improper-output-handling/)
* [Practical Techniques to Constrain LLM Output](https://mychen76.medium.com/practical-techniques-to-constraint-llm-output-in-json-format-e3e72396c670)
* [Dataiku – Structured Text Generation Guide](https://blog.dataiku.com/your-guide-to-structured-text-generation)
* [VL-Uncertainty: Detecting Hallucinations](https://arxiv.org/abs/2411.11919)
* [HaDeMiF: Hallucination Detection & Mitigation](https://openreview.net/forum?id=VwOYxPScxB)
* [Building Confidence in LLM Outputs](https://www.alkymi.io/data-science-room/building-confidence-in-llm-outputs)
* [Explainable AI & LLMs](https://duncsand.medium.com/explainable-ai-140912d31b3b)
* [LLM Red-Teaming Guide](https://www.confident-ai.com/blog/red-teaming-llms-a-step-by-step-guide)
* [Sensitive Information Disclosure in LLMs](https://virtualcyberlabs.com/llm-sensitive-information-disclosure/)
* [LangChain – Chat Model Rate Limiting](https://python.langchain.com/docs/how_to/chat_model_rate_limiting/)
* [OpenAI Rate-Limit & Exponential Back-off](https://hackernoon.com/openais-rate-limit-a-guide-to-exponential-backoff-for-llm-evaluation)
* [Arize AI – LLM Observability Platform](https://arize.com/)

