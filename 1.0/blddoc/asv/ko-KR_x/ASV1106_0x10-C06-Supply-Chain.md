# C6 모델, 프레임워크 및 데이터용 공급망 보안

## 제어 목표

AI 공급망 공격은 서드파티 모델, 프레임워크 또는 데이터셋을 악용하여 백도어, 편향 또는 악용 가능한 코드를 삽입합니다. 이러한 통제는 전체 모델 수명 주기를 보호하기 위해 엔드투엔드 출처, 취약점 관리 및 모니터링을 제공합니다.

---

## C6.1 사전 학습된 모델 검증 및 출처 확인

세부 조정 또는 배포 전에 제3자 모델의 출처, 라이선스 및 숨겨진 동작을 평가하고 인증하십시오.

|   #   | 설명                                                                     | 레벨  | 역할  |
| :---: | ---------------------------------------------------------------------- | :-: | :-: |
| 6.1.1 | 모든 타사 모델 아티팩트에 소스 리포지토리 및 커밋 해시를 식별하는 서명된 출처 기록이 포함되어 있는지 확인하십시오.      |  1  | D/V |
| 6.1.2 | 모델을 가져오기 전에 자동화 도구를 사용하여 악성 계층 또는 트로이 목마 트리거가 있는지 스캔되었는지 확인하십시오.       |  1  | D/V |
| 6.1.3 | 전이 학습 미세 조정이 숨겨진 동작을 탐지하기 위해 적대적 평가를 통과하는지 확인하십시오.                     |  2  |  D  |
| 6.1.4 | 모델 라이선스, 수출 관리 태그 및 데이터 출처 진술이 ML-BOM 항목에 기록되어 있는지 확인하십시오.             |  2  |  V  |
| 6.1.5 | 고위험 모델(공개 업로드된 가중치, 검증되지 않은 제작자)이 인간의 검토 및 승인 전까지 격리 상태를 유지하는지 확인하십시오. |  3  | D/V |

---

## C6.2 프레임워크 및 라이브러리 스캐닝

런타임 스택의 보안을 유지하기 위해 ML 프레임워크와 라이브러리를 지속적으로 CVE 및 악성 코드에 대해 스캔합니다.

|   #   | 설명                                                         | 레벨  | 역할  |
| :---: | ---------------------------------------------------------- | :-: | :-: |
| 6.2.1 | CI 파이프라인에서 AI 프레임워크 및 주요 라이브러리에 대해 종속성 스캐너가 실행되는지 확인하십시오.  |  1  | D/V |
| 6.2.2 | 치명적인 취약점(CVSS ≥ 7.0)이 프로덕션 이미지로 승격되는 것을 차단하는지 확인하세요.       |  1  | D/V |
| 6.2.3 | 포크되거나 벤더링된 ML 라이브러리에서 정적 코드 분석이 실행되는지 확인하십시오.              |  2  |  D  |
| 6.2.4 | 프레임워크 업그레이드 제안서에 공개 CVE 피드를 참조한 보안 영향 평가가 포함되어 있는지 확인하십시오. |  2  |  V  |
| 6.2.5 | 서명된 SBOM에서 벗어난 예상치 못한 동적 라이브러리 로드에 대해 런타임 센서가 경고하는지 확인하세요. |  3  |  V  |

---

## C6.3 의존성 고정 및 검증

모든 종속성을 변경 불가능한 다이제스트로 고정하고 빌드를 재현하여 동일하고 변조되지 않은 산출물을 보장하십시오.

|   #   | 설명                                                    | 레벨  | 역할  |
| :---: | ----------------------------------------------------- | :-: | :-: |
| 6.3.1 | 모든 패키지 관리자가 락파일을 통해 버전 고정을 강제하는지 확인하십시오.              |  1  | D/V |
| 6.3.2 | 컨테이너 참조에서 변경 가능한 태그 대신 변경 불가능한 다이제스트가 사용되었는지 확인하세요.   |  1  | D/V |
| 6.3.3 | 재현 가능한 빌드 검사가 CI 실행 간 해시를 비교하여 동일한 출력을 보장하는지 확인하세요.   |  2  |  D  |
| 6.3.4 | 감사 추적 가능성을 위해 빌드 증명서가 18개월 동안 저장되는지 확인하십시오.           |  2  |  V  |
| 6.3.5 | 만료된 종속성이 고정된 버전을 업데이트하거나 포크하기 위한 자동 PR을 트리거하는지 확인하세요. |  3  |  D  |

---

## C6.4 신뢰할 수 있는 출처 강제 적용

암호학적으로 검증되고 조직에서 승인한 소스에서만 아티팩트 다운로드를 허용하고 나머지는 모두 차단하십시오.

|   #   | 설명                                                                 | 레벨  | 역할  |
| :---: | ------------------------------------------------------------------ | :-: | :-: |
| 6.4.1 | 모델 가중치, 데이터셋 및 컨테이너가 승인된 도메인 또는 내부 레지스트리에서만 다운로드되는지 확인하세요.         |  1  | D/V |
| 6.4.2 | Sigstore/Cosign 서명이 퍼블리셔 신원을 검증한 후에만 아티팩트를 로컬에 캐시하는지 확인하세요.        |  1  | D/V |
| 6.4.3 | 아티팩트 다운로드가 인증되지 않은 경우 출구 프록시가 이를 차단하여 신뢰할 수 있는 출처 정책을 시행하는지 확인합니다. |  2  |  D  |
| 6.4.4 | 저장소 허용 목록이 분기별로 검토되며 각 항목에 대한 비즈니스 정당성 증거가 있는지 확인하십시오.             |  2  |  V  |
| 6.4.5 | 정책 위반이 아티팩트 격리 및 종속 파이프라인 실행 롤백을 유발하는지 확인하세요.                      |  3  |  V  |

---

## C6.5 타사 데이터셋 위험 평가

외부 데이터셋의 중독, 편향 및 법적 준수 여부를 평가하고, 전체 라이프사이클 동안 이를 지속적으로 모니터링합니다.

|   #   | 설명                                                           | 레벨  | 역할  |
| :---: | ------------------------------------------------------------ | :-: | :-: |
| 6.5.1 | 외부 데이터셋이 오염 위험 점수 평가(예: 데이터 지문 검사, 이상치 탐지)를 거치는지 확인하십시오.     |  1  | D/V |
| 6.5.2 | 편향 지표(인구통계학적 균형, 기회 균등)가 데이터셋 승인 전에 계산되었는지 확인하십시오.           |  1  |  D  |
| 6.5.3 | 데이터셋에 대한 출처 및 라이선스 조건이 ML‑BOM 항목에 기록되었는지 확인하십시오.             |  2  |  V  |
| 6.5.4 | 주기적인 모니터링이 호스팅된 데이터셋에서 드리프트 또는 손상을 감지하는지 확인하십시오.             |  2  |  V  |
| 6.5.5 | 학습 전에 자동 스크러빙을 통해 허용되지 않는 콘텐츠(저작권, 개인 식별 정보)가 제거되었는지 확인하십시오. |  3  |  D  |

---

## C6.6 공급망 공격 모니터링

CVE 피드, 감사 로그 분석 및 레드팀 시뮬레이션을 통해 공급망 위협을 조기에 감지하세요.

|   #   | 설명                                                                 | 레벨  | 역할  |
| :---: | ------------------------------------------------------------------ | :-: | :-: |
| 6.6.1 | CI/CD 감사 로그가 이상한 패키지 풀 요청이나 조작된 빌드 단계에 대한 SIEM 탐지로 스트리밍되는지 확인하십시오. |  1  |  V  |
| 6.6.2 | 사고 대응 플레이북에 손상된 모델 또는 라이브러리에 대한 롤백 절차가 포함되어 있는지 확인하십시오.            |  2  |  D  |
| 6.6.3 | 위협 인텔리전스 강화가 경고 분류에서 ML 특정 지표(예: 모델-중독 IoC)를 태그하는지 확인합니다.          |  3  |  V  |

---

## C6.7 모델 아티팩트용 ML-BOM

상세한 ML 전용 SBOM(ML-BOM)을 생성하고 서명하여 하류 사용자가 배포 시 구성 요소 무결성을 검증할 수 있도록 합니다.

|   #   | 설명                                                                  | 레벨  | 역할  |
| :---: | ------------------------------------------------------------------- | :-: | :-: |
| 6.7.1 | 모든 모델 아티팩트가 데이터셋, 가중치, 하이퍼파라미터 및 라이선스를 나열하는 ML-BOM을 게시하는지 확인하세요.    |  1  | D/V |
| 6.7.2 | ML-BOM 생성과 Cosign 서명이 CI에서 자동화되어 있으며 병합 시 필수적인지 확인하십시오.             |  1  | D/V |
| 6.7.3 | ML‑BOM 완전성 검증이 구성 요소 메타데이터(해시, 라이선스)가 누락된 경우 빌드를 실패하도록 하는지 확인하십시오.  |  2  |  D  |
| 6.7.4 | 다운스트림 소비자가 배포 시점에 가져온 모델을 검증하기 위해 API를 통해 ML-BOM을 쿼리할 수 있는지 확인하십시오. |  2  |  V  |
| 6.7.5 | ML-BOM이 버전 관리되고 변경 내역 비교(diff)되어 무단 수정이 감지되는지 확인하십시오.               |  3  |  V  |

---

## 참고 문헌

* [ML Supply Chain Compromise – MITRE ATLAS](https://misp-galaxy.org/mitre-atlas-attack-pattern/)
* [Supply‑chain Levels for Software Artifacts (SLSA)](https://slsa.dev/)
* [CycloneDX – Machine Learning Bill of Materials](https://cyclonedx.org/capabilities/mlbom/)
* [What is Data Poisoning? – SentinelOne](https://www.sentinelone.com/cybersecurity-101/cybersecurity/data-poisoning/)
* [Transfer Learning Attack – OWASP ML Security Top 10](https://owasp.org/www-project-machine-learning-security-top-10/docs/ML07_2023-Transfer_Learning_Attack)
* [AI Data Security Best Practices – CISA](https://www.cisa.gov/news-events/cybersecurity-advisories/aa25-142a)
* [Secure CI/CD Supply Chain – Sumo Logic](https://www.sumologic.com/blog/secure-azure-devops-github-supply-chain-attacks)
* [AI & Transparency: Protect ML Models – ReversingLabs](https://www.reversinglabs.com/blog/ai-and-transparency-how-ml-model-creators-can-protect-against-supply-chain-attacks)
* [SBOM Overview – CISA](https://www.cisa.gov/sbom)
* [Training Data Poisoning Guide – Lakera.ai](https://www.lakera.ai/blog/training-data-poisoning)
* [Dependency Pinning for Reproducible Python – Medium](https://medium.com/data-science-collective/guarantee-a-locked-reproducible-environment-with-every-python-run-c0e2bf19fb53)

