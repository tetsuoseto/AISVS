# 서문

인공지능 보안 검증 표준(AISVS) 버전 1.0에 오신 것을 환영합니다!

## 서론

2025년에 협력적인 커뮤니티의 노력으로 설립되었으며, AISVS는 현대의 AI 모델, 파이프라인, 그리고 AI‑기반 서비스의 설계, 개발, 배포 및 운영 시 고려해야 할 보안 요구사항을 정의한다.

AISVS v1.0은 AI 시스템의 보안을 확보하기 위한 실용적이고 검증 가능한 기본선을 만들기 위한 프로젝트 리더들, 작업 그룹, 그리고 더 넓은 커뮤니티 기여자들의 합동 작업을 나타냅니다.

이번 릴리스의 목표는 AISVS를 채택하기 쉽게 만드는 한편, 정의된 범위에 레이저처럼 집중하고 AI 특유의 급변하는 위험 환경에 대응하는 것입니다.

## AISVS 버전 1.0의 주요 목표

버전 1.0은 여러 가지 지침 원칙들로 만들어질 것이다.

### 명확하게-정의된 범위

각 요건은 AISVS의 이름과 사명에 부합해야 합니다:

* 인공지능 – 제어는 AI/ML 계층(데이터, 모델, 파이프라인 또는 추론)에서 작동하며 AI 실무자들의 책임이다.
* 보안 – 요구사항은 식별된 보안, 개인정보 보호 또는 안전 위험을 직접 완화합니다.
* 검증 – 준수 여부를 객관적으로 검증할 수 있도록 언어가 작성된다.
* 표준 – 섹션은 일관된 구조와 용어를 따라 일관된 참조를 형성합니다.
  ​
---

AISVS를 준수함으로써 조직은 자사의 인공지능 솔루션의 보안 태세를 체계적으로 평가하고 강화할 수 있으며, 안전한 인공지능 엔지니어링 문화를 조성한다.

