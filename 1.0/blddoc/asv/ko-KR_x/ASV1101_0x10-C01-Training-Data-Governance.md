# C1 교육 데이터 거버넌스 및 편향 관리

## 통제 목표

학습 데이터는 출처, 보안, 품질 및 공정성을 보존하는 방식으로 수집, 처리 및 관리되어야 합니다. 이렇게 함으로써 법적 의무를 이행하고, 학습 중에 나타날 수 있는 편향, 오염 또는 개인정보 침해의 위험을 줄여 AI 전체 수명 주기에 영향을 미칠 수 있는 문제를 예방할 수 있습니다.

---

## C1.1 학습 데이터 출처

모든 데이터셋에 대한 검증 가능한 재고를 유지하고, 신뢰할 수 있는 출처만 허용하며, 모든 변경 사항을 감사 가능하도록 기록하십시오.

|   #   | 설명                                                                                                | 레벨  | 역할  |
| :---: | ------------------------------------------------------------------------------------------------- | :-: | :-: |
| 1.1.1 | 모든 학습 데이터 소스(출처, 관리자/소유자, 라이선스, 수집 방법, 의도된 사용 제약 조건 및 처리 이력)에 대한 최신 인벤토리가 유지되고 있는지 확인하십시오.        |  1  | D/V |
| 1.1.2 | 훈련 데이터 처리 과정에서 불필요한 특징, 속성 또는 필드(예: 사용되지 않는 메타데이터, 민감한 개인 식별 정보(PII), 유출된 테스트 데이터)를 제외했는지 확인하십시오. |  1  | D/V |
| 1.1.3 | 모든 데이터셋 변경 사항이 기록된 승인 워크플로우의 적용을 받는지 확인하십시오.                                                      |  2  | D/V |
| 1.1.4 | 가능한 경우 데이터셋 또는 하위 집합에 워터마크나 지문이 포함되어 있는지 확인하십시오.                                                  |  3  | D/V |

---

## C1.2 학습 데이터 보안 및 무결성

학습 데이터에 대한 접근을 제한하고, 데이터를 저장 시와 전송 시에 암호화하며, 변조, 도난 또는 데이터 오염을 방지하기 위해 무결성을 검증하십시오.

|   #   | 설명                                                                              | 레벨  | 역할  |
| :---: | ------------------------------------------------------------------------------- | :-: | :-: |
| 1.2.1 | 접근 제어가 학습 데이터 저장소와 파이프라인을 보호하는지 검증하십시오.                                         |  1  | D/V |
| 1.2.2 | 훈련 데이터에 대한 모든 접근이 사용자, 시간, 동작을 포함하여 기록되었는지 확인하세요.                               |  2  | D/V |
| 1.2.3 | 훈련 데이터셋이 전송 중 및 저장 중에 업계 표준 암호화 알고리즘과 키 관리 관행을 사용하여 암호화되었는지 확인하십시오.             |  2  | D/V |
| 1.2.4 | 학습 데이터 저장 및 전송 중 데이터 무결성을 보장하기 위해 암호화 해시 또는 디지털 서명이 사용되는지 확인하십시오.               |  2  | D/V |
| 1.2.5 | 자동화된 탐지 기술이 훈련 데이터의 무단 수정 또는 손상을 방지하기 위해 적용되었는지 확인하십시오.                         |  2  | D/V |
| 1.2.6 | 구식 훈련 데이터가 안전하게 삭제되거나 익명화되었는지 확인하십시오.                                           |  2  | D/V |
| 1.2.7 | 모든 학습 데이터셋 버전이 고유하게 식별되고, 변경 불가능하게 저장되며, 롤백 및 포렌식 분석을 지원할 수 있도록 감사 가능함을 검증하십시오. |  3  | D/V |

---

## C1.3 훈련 데이터 라벨링 품질, 무결성 및 보안

라벨을 보호하고 중요한 데이터에 대해 기술 검토를 요구하십시오.

|   #   | 설명                                                                                             | 레벨  | 역할  |
| :---: | ---------------------------------------------------------------------------------------------- | :-: | :-: |
| 1.3.1 | 암호화 해시 또는 디지털 서명이 라벨 산출물에 적용되어 그 무결성과 진위를 보장하는지 확인하십시오.                                        |  2  | D/V |
| 1.3.2 | 라벨링 인터페이스와 플랫폼이 강력한 접근 제어를 시행하고, 모든 라벨링 활동에 대해 변조 방지 감 audit 로그를 유지하며, 무단 수정으로부터 보호하는지 확인하십시오. |  2  | D/V |
| 1.3.3 | 라벨의 민감한 정보가 저장 시와 전송 시 데이터 필드 수준에서 삭제, 익명화 또는 암호화되어 있는지 확인하십시오.                                |  3  | D/V |

---

## C1.4 훈련 데이터 품질 및 보안 보장

자동화된 검증, 수동 스팟 검사 및 기록된 수정 조치를 결합하여 데이터셋 신뢰성을 보장합니다.

|   #   | 설명                                                                                                                                                                                 | 레벨  | 역할  |
| :---: | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 1.4.1 | 자동화된 테스트가 모든 수집 또는 중요한 데이터 변환 시 형식 오류 및 널 값을 감지하는지 확인하십시오.                                                                                                                         |  1  |  D  |
| 1.4.2 | LLM 훈련 및 미세 조정 파이프라인이 잠재적인 중독 공격(예: 레이블 뒤집기, 백도어 트리거 삽입, 역할 전환 명령, 영향력 있는 인스턴스 공격) 또는 훈련 데이터의 의도하지 않은 데이터 손상을 식별하기 위해 중독 탐지 및 데이터 무결성 검증(예: 통계적 방법, 이상값 탐지, 임베딩 분석)을 구현하는지 확인하십시오. |  2  | D/V |
| 1.4.3 | 생성된 적대적 예제를 사용한 적대적 학습, 변형된 입력을 사용한 데이터 증강, 또는 강인한 최적화 기법과 같은 적절한 방어 방법이 위험 평가에 따라 관련 모델에 구현되고 조정되었는지 확인하십시오.                                                                      |  3  | D/V |
| 1.4.4 | 자동 생성된 레이블(예: LLM 또는 약한 감독을 통해 생성된 레이블)이 환각, 오도, 또는 낮은 신뢰도의 레이블을 감지하기 위해 신뢰도 임계값 및 일관성 검사에 의해 검증되는지 확인하십시오.                                                                        |  2  | D/V |
| 1.4.5 | 자동화된 테스트가 모든 수집 또는 중요한 데이터 변환 시 라벨 왜곡을 감지하는지 확인하십시오.                                                                                                                               |  3  |  D  |

---

## C1.5 데이터 계보 및 추적성

감사 가능성과 사고 대응을 위해 각 데이터 포인트의 출처부터 모델 입력까지 전체 여정을 추적하십시오.

|   #   | 설명                                                                                                            | 레벨  | 역할  |
| :---: | ------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 1.5.1 | 각 데이터 포인트의 계보(모든 변환, 증강, 병합 포함)가 기록되어 있으며 재구성할 수 있는지 확인하십시오.                                                  |  2  | D/V |
| 1.5.2 | 혈통 기록이 변경 불가능하고, 안전하게 저장되며, 감사를 위해 접근 가능함을 확인하십시오.                                                            |  2  | D/V |
| 1.5.3 | 라인리지 추적이 프라이버시 보호 또는 생성 기법을 통해 생성된 합성 데이터를 포함하는지 확인하고, 모든 합성 데이터가 파이프라인 전반에 걸쳐 명확하게 라벨링되어 실제 데이터와 구분되도록 하십시오. |  2  | D/V |

---

## 참고 문헌

* [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)
* [EU AI Act – Article 10: Data & Data Governance](https://artificialintelligenceact.eu/article/10/)
* [MITRE ATLAS: Adversary Tactics for AI](https://atlas.mitre.org/)
* [Survey of ML Bias Mitigation Techniques – MDPI](https://www.mdpi.com/2673-6470/4/1/1)
* [Data Provenance & Lineage Best Practices – Nightfall AI](https://www.nightfall.ai/ai-security-101/data-provenance-and-lineage)
* [Data Labeling Quality Standards – LabelYourData](https://labelyourdata.com/articles/data-labeling-quality-and-how-to-measure-it)
* [Training Data Poisoning Guide – Lakera.ai](https://www.lakera.ai/blog/training-data-poisoning)
* [CISA Advisory: Securing Data for AI Systems](https://www.cisa.gov/news-events/cybersecurity-advisories/aa25-142a)
* [ISO/IEC 23053: AI Management Systems Framework](https://www.iso.org/sectors/it-technologies/ai)
* [IBM: What is AI Governance?](https://www.ibm.com/think/topics/ai-governance)
* [Google AI Principles](https://ai.google/principles/)
* [GDPR & AI Training Data – DataProtectionReport](https://www.dataprotectionreport.com/2024/08/recent-regulatory-developments-in-training-artificial-intelligence-ai-models-under-the-gdpr/)
* [Supply-Chain Security for AI Data – AppSOC](https://www.appsoc.com/blog/ai-is-the-new-frontier-of-supply-chain-security)
* [OpenAI Privacy Center – Data Deletion Controls](https://privacy.openai.com/policies?modal=take-control)
* [Adversarial ML Dataset – Kaggle](https://www.kaggle.com/datasets/cnrieiit/adversarial-machine-learning-dataset)

