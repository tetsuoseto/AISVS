# C1 학습 데이터 거버넌스 및 편향 관리

## 통제 목표

학습 데이터는 출처를 보존하고 보안, 품질 및 공정성을 유지하는 방식으로 수집, 취급 및 유지 관리되어야 한다. 그렇게 함으로써 법적 의무를 이행하고, 학습 과정에서 나타날 수 있는 편향, 데이터 포이즈닝, 또는 프라이버시 침해의 위험을 줄여 AI 수명주기 전체에 미칠 수 있는 영향을 방지한다.

---

## C1.1 훈련 데이터 출처

모든 데이터셋의 검증 가능한 재고를 유지하고, 신뢰할 수 있는 소스만 수락하며, 감사 가능성을 위해 모든 변경 사항을 기록하십시오.

|   #   | 설명                                                                                            | 레벨  | 역할  |
| :---: | --------------------------------------------------------------------------------------------- | :-: | :-: |
| 1.1.1 | 모든 학습 데이터 소스에 대한 최신 재고 목록(출처, 관리책임자/소유자, 라이선스, 수집 방법, 의도된 사용 제약 및 처리 이력)이 유지되고 있는지 확인합니다.     |  1  | D/V |
| 1.1.2 | 학습 데이터 프로세스가 불필요한 특징, 속성 또는 필드를 제외하는지 확인한다(예: 사용되지 않는 메타데이터, 민감한 개인 식별 정보(PII), 유출된 테스트 데이터). |  1  | D/V |
| 1.1.3 | 모든 데이터셋 변경 사항이 로깅된 승인 워크플로우의 대상이 되도록 확인하십시오.                                                  |  2  | D/V |
| 1.1.4 | 가능한 경우 데이터셋이나 부분집합에 워터마크가 삽입되었거나 지문이 남겨져 있는지 확인합니다.                                           |  3  | D/V |

---

## C1.2 학습 데이터 보안 및 무결성

학습 데이터에 대한 접근을 제한하고, 저장 중과 전송 중에 암호화하며, 무결성을 검증하여 변조, 도난 또는 데이터 오염을 방지합니다.

|   #   | 설명                                                                          | 레벨  | 역할  |
| :---: | --------------------------------------------------------------------------- | :-: | :-: |
| 1.2.1 | 접근 제어가 훈련 데이터 저장소와 파이프라인을 보호하는지 확인하십시오.                                     |  1  | D/V |
| 1.2.2 | 훈련 데이터에 대한 모든 접근이 로깅되는지 확인하고, 사용자, 시간 및 작업을 포함합니다.                          |  2  | D/V |
| 1.2.3 | 학습 데이터 세트가 전송 중 및 저장 중에 암호화되어 있는지 확인하고, 산업 표준 암호화 알고리즘과 키 관리 관행을 사용하십시오.    |  2  | D/V |
| 1.2.4 | 학습 데이터 저장 및 전송 중 데이터 무결성을 보장하기 위해 암호학적 해시나 디지털 서명이 사용되고 있는지 확인합니다.          |  2  | D/V |
| 1.2.5 | 학습 데이터의 무단 수정이나 손상으로부터 보호하기 위해 자동 탐지 기법이 적용되고 있는지 확인합니다.                    |  2  | D/V |
| 1.2.6 | 더 이상 사용되지 않는 학습 데이터가 안전하게 삭제되었거나 익명화되었는지 확인합니다.                             |  2  | D/V |
| 1.2.7 | 모든 학습 데이터셋 버전이 고유하게 식별되고 불변하게 저장되며, 롤백 및 포렌식 분석을 지원하기 위해 감사 추적이 가능하도록 확인한다. |  3  | D/V |

---

## C1.3 학습 데이터 라벨링의 품질, 무결성 및 보안

레이블을 보호하고 중요한 데이터에 대해 기술 검토를 요구합니다.

|   #   | 설명                                                                                          | 레벨  | 역할  |
| :---: | ------------------------------------------------------------------------------------------- | :-: | :-: |
| 1.3.1 | 레이블 산출물에 암호학적 해시나 디지털 서명이 적용되어 무결성과 진정성이 보장되는지 확인합니다.                                       |  2  | D/V |
| 1.3.2 | 레이블링 인터페이스와 플랫폼이 강력한 접근 제어를 시행하고, 모든 레이블링 활동에 대한 변조 방지 감사 로그를 유지하며, 무단 수정으로부터 보호하는지 확인하십시오. |  2  | D/V |
| 1.3.3 | 레이블의 민감한 정보가 저장 상태와 전송 상태에서 데이터 필드 수준으로 가려지거나 익명화되거나 암호화되는지 확인합니다.                          |  3  | D/V |

---

## C1.4 학습 데이터 품질 및 보안 보증

자동 검증, 수동 샘플 점검, 그리고 로그에 기록된 시정 조치를 결합하여 데이터셋의 신뢰성을 보장합니다.

|   #   | 설명                                                                                                                                                                                  | 레벨  | 역할  |
| :---: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 1.4.1 | 모든 데이터 수집 시점 또는 중요한 데이터 변환에서 자동화된 테스트가 형식 오류와 널 값을 포착하는지 확인하십시오.                                                                                                                    |  1  |  D  |
| 1.4.2 | 대형 언어 모델(LLM) 훈련 및 미세 조정 파이프라인이 포이즈닝 탐지와 데이터 무결성 검증을 구현하여(예: 통계적 방법, 이상값 탐지, 임베딩 분석) 잠재적 포이즈닝 공격(예: 라벨 반전, 백도어 트리거 삽입, 역할 전환 명령, 영향력 있는 인스턴스 공격)이나 훈련 데이터의 의도치 않은 손상을 식별하는지 확인하십시오. |  2  | D/V |
| 1.4.3 | 위험 평가를 바탕으로 관련 모델에 대해 생성된 적대적 예시를 사용하는 적대적 학습(adversarial training), 교란된 입력을 이용한 데이터 증강, 또는 강건 최적화 기법과 같은 적절한 방어책이 구현되고 조정되는지 확인합니다.                                                |  3  | D/V |
| 1.4.4 | 자동으로 생성된 라벨(예: LLMs를 통한 라벨링 또는 약한 감독)이 신뢰도 임계값과 일관성 검사를 받도록 하여, 환각되었거나 오도하는 또는 신뢰도가 낮은 라벨을 탐지하는지 확인한다.                                                                              |  2  | D/V |
| 1.4.5 | 모든 데이터 인제스트 과정이나 중요한 데이터 변환에서 자동 테스트가 레이블 편향을 포착하는지 확인하십시오.                                                                                                                         |  3  |  D  |

---

## C1.5 데이터 계보 및 추적성

감사 가능성과 사고 대응을 위해 각 데이터 포인트가 원천에서 모델 입력에 이르는 전체 경로를 추적합니다.

|   #   | 설명                                                                                                                                | 레벨  | 역할  |
| :---: | --------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 1.5.1 | 각 데이터 포인트의 계보가 모든 변환, 데이터 증강 및 병합을 포함하여 기록되고 재구성될 수 있는지 확인합니다.                                                                    |  2  | D/V |
| 1.5.2 | 데이터 계보 기록이 변경 불가하고, 안전하게 저장되며, 감사 용도로 열람 가능함을 확인한다.                                                                               |  2  | D/V |
| 1.5.3 | 프라이버시 보호를 위한 기술 또는 생성적 기법으로 생성된 합성 데이터에 대해 데이터 계보 추적이 적용되는지 확인하고, 파이프라인 전반에 걸쳐 모든 합성 데이터가 명확하게 라벨링되어 실제 데이터와 구별될 수 있도록 하는지 확인합니다. |  2  | D/V |

---

## 참고문헌

* [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)
* [EU AI Act – Article 10: Data & Data Governance](https://artificialintelligenceact.eu/article/10/)
* [MITRE ATLAS: Adversary Tactics for AI](https://atlas.mitre.org/)
* [Survey of ML Bias Mitigation Techniques – MDPI](https://www.mdpi.com/2673-6470/4/1/1)
* [Data Provenance & Lineage Best Practices – Nightfall AI](https://www.nightfall.ai/ai-security-101/data-provenance-and-lineage)
* [Data Labeling Quality Standards – LabelYourData](https://labelyourdata.com/articles/data-labeling-quality-and-how-to-measure-it)
* [Training Data Poisoning Guide – Lakera.ai](https://www.lakera.ai/blog/training-data-poisoning)
* [CISA Advisory: Securing Data for AI Systems](https://www.cisa.gov/news-events/cybersecurity-advisories/aa25-142a)
* [ISO/IEC 23053: AI Management Systems Framework](https://www.iso.org/sectors/it-technologies/ai)
* [IBM: What is AI Governance?](https://www.ibm.com/think/topics/ai-governance)
* [Google AI Principles](https://ai.google/principles/)
* [GDPR & AI Training Data – DataProtectionReport](https://www.dataprotectionreport.com/2024/08/recent-regulatory-developments-in-training-artificial-intelligence-ai-models-under-the-gdpr/)
* [Supply-Chain Security for AI Data – AppSOC](https://www.appsoc.com/blog/ai-is-the-new-frontier-of-supply-chain-security)
* [OpenAI Privacy Center – Data Deletion Controls](https://privacy.openai.com/policies?modal=take-control)
* [Adversarial ML Dataset – Kaggle](https://www.kaggle.com/datasets/cnrieiit/adversarial-machine-learning-dataset)

