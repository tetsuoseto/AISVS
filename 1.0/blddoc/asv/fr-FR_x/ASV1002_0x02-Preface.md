# Préface

Bienvenue dans la norme de vérification de la sécurité de l'intelligence artificielle (AISVS) version 1.0 !

## Introduction

Établi en 2025 grâce à un effort communautaire collaboratif, AISVS définit les exigences de sécurité à prendre en compte lors de la conception, du développement, du déploiement et de l'exploitation des modèles d'IA modernes, des pipelines et des services activés par l'IA.

AISVS v1.0 représente le travail combiné de ses responsables de projet, de son groupe de travail et de ses contributeurs de la communauté élargie pour produire une base pragmatique et testable pour la sécurisation des systèmes d'IA.

Notre objectif avec cette version est de rendre l'adoption de l'AISVS simple tout en restant strictement concentré sur son périmètre défini et en répondant au paysage des risques en rapide évolution propre à l'IA.

## Objectifs clés pour AISVS Version 1.0

La version 1.0 sera créée avec plusieurs principes directeurs.

### Portée bien définie

Chaque exigence doit être alignée avec le nom et la mission d’AISVS :

* Intelligence artificielle – Les contrôles fonctionnent au niveau de la couche IA/ML (données, modèle, pipeline ou inférence) et sont sous la responsabilité des praticiens de l'IA.
* Sécurité – Les exigences atténuent directement les risques identifiés en matière de sécurité, de confidentialité ou de sûreté.
* Vérification – Le langage est rédigé de manière à ce que la conformité puisse être validée objectivement.
* Norme – Les sections suivent une structure et une terminologie cohérentes pour former une référence homogène.
  ​
---

En suivant AISVS, les organisations peuvent évaluer systématiquement et renforcer la posture de sécurité de leurs solutions d’IA, favorisant ainsi une culture d’ingénierie de l’IA sécurisée.

