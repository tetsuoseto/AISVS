# Préface

Bienvenue dans la norme de vérification de la sécurité de l'intelligence artificielle (AISVS) version 1.0 !

## Introduction

Établi en 2025 grâce à un effort communautaire collaboratif, AISVS définit les exigences de sécurité à prendre en compte lors de la conception, du développement, du déploiement et de l’exploitation des modèles d’IA modernes, des pipelines et des services activés par l’IA.

AISVS v1.0 représente le travail combiné de ses chefs de projet, du groupe de travail et des contributeurs de la communauté au sens large pour produire une base pragmatique et testable pour sécuriser les systèmes d'IA.

Notre objectif avec cette version est de rendre AISVS facile à adopter tout en restant parfaitement concentré sur son périmètre défini et en répondant au paysage des risques en rapide évolution propre à l'IA.

## Objectifs clés pour AISVS Version 1.0

La version 1.0 sera créée en suivant plusieurs principes directeurs.

### Portée bien définie

Chaque exigence doit être conforme au nom et à la mission d’AISVS :

* Intelligence Artificielle – Les contrôles fonctionnent au niveau de la couche IA/ML (données, modèle, pipeline ou inférence) et relèvent de la responsabilité des praticiens de l’IA.
* Sécurité – Les exigences atténuent directement les risques identifiés en matière de sécurité, de confidentialité ou de sûreté.
* Vérification – Le langage est rédigé de manière à ce que la conformité puisse être validée objectivement.
* Standard – Les sections suivent une structure et une terminologie cohérentes pour former une référence cohérente.
  ​
---

En suivant AISVS, les organisations peuvent évaluer systématiquement et renforcer la posture de sécurité de leurs solutions d'IA, favorisant ainsi une culture d'ingénierie de l'IA sécurisée.

