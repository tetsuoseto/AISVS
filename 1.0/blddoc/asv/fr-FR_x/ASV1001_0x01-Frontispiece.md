# Frontispice

## À propos de la norme

La norme de vérification de la sécurité de l’intelligence artificielle (AISVS) est un catalogue communautaire de exigences de sécurité que les data scientists, les ingénieurs MLOps, les architectes logiciels, les développeurs, les testeurs, les professionnels de la sécurité, les fournisseurs d’outils, les régulateurs et les consommateurs peuvent utiliser pour concevoir, construire, tester et vérifier des systèmes et applications d’IA fiables. Elle fournit un langage commun pour spécifier les contrôles de sécurité tout au long du cycle de vie de l’IA — de la collecte des données et du développement des modèles jusqu’au déploiement et à la surveillance continue — afin que les organisations puissent mesurer et améliorer la résilience, la confidentialité et la sécurité de leurs solutions d’IA.

## Droits d'auteur et Licence

Version 0.1 (Première ébauche publique - Travail en cours), 2025  

![license](../images/license.png)

Droit d'auteur © 2025 Le Projet AISVS.  

Publié sous la [Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
Pour toute réutilisation ou distribution, vous devez clairement communiquer les termes de la licence de ce travail aux autres.

## Chefs de projet

|            |                         |
| ---------- | ----------------------- |
| Jim Manico | Aras “Russ” Memisyazici |

## Contributeurs et réviseurs

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS est une toute nouvelle norme créée spécifiquement pour répondre aux défis uniques de sécurité des systèmes d'intelligence artificielle. Bien qu'elle s'inspire des meilleures pratiques de sécurité plus générales, chaque exigence de l'AISVS a été développée de zéro afin de refléter le paysage des menaces en IA et d'aider les organisations à concevoir des solutions d'IA plus sûres et plus résilientes.

