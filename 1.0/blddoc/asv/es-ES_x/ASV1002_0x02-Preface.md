# Prefacio

¡Bienvenido al Estándar de Verificación de Seguridad de Inteligencia Artificial (AISVS) versión 1.0!

## Introducción

Establecida en 2025 mediante un esfuerzo comunitario colaborativo, AISVS define los requisitos de seguridad a considerar al diseñar, desarrollar, desplegar y operar modelos de IA modernos, pipelines y servicios habilitados con IA.

AISVS v1.0 representa el trabajo conjunto de sus líderes de proyecto, el grupo de trabajo y colaboradores de la comunidad en general para producir una base pragmática y comprobable para asegurar los sistemas de IA.

Nuestro objetivo con esta versión es hacer que AISVS sea fácil de adoptar, manteniéndonos enfocados con precisión en su alcance definido y abordando el paisaje de riesgos que evoluciona rápidamente y es único para la IA.

## Objetivos clave para AISVS Versión 1.0

La versión 1.0 se creará con varios principios rectores.

### Alcance Bien Definido

Cada requisito debe estar alineado con el nombre y la misión de AISVS:

* Inteligencia Artificial – Los controles operan en la capa de IA/ML (datos, modelo, canalización o inferencia) y son responsabilidad de los practicantes de IA.
* Seguridad – Los requisitos mitiguen directamente los riesgos identificados de seguridad, privacidad o seguridad.
* Verificación: el lenguaje está escrito para que la conformidad pueda validarse objetivamente.
* Estándar: las secciones siguen una estructura y terminología coherentes para formar una referencia consistente.
  ​
---

Al seguir AISVS, las organizaciones pueden evaluar y fortalecer sistemáticamente la postura de seguridad de sus soluciones de IA, fomentando una cultura de ingeniería de IA segura.

