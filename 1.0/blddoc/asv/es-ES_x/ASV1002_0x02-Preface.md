# Prefacio

¡Bienvenido a la Norma de Verificación de Seguridad de la Inteligencia Artificial (AISVS) versión 1.0!

## Introducción

Establecida en 2025 a través de un esfuerzo comunitario colaborativo, AISVS define los requisitos de seguridad que deben considerarse al diseñar, desarrollar, desplegar y operar modelos de IA modernos, flujos de procesamiento y servicios habilitados por IA.

AISVS v1.0 representa el trabajo conjunto de sus líderes de proyecto, del grupo de trabajo y de la comunidad de contribuyentes más amplia para producir una base pragmática y verificable para la seguridad de los sistemas de IA.

Nuestro objetivo con este lanzamiento es que AISVS sea fácil de adoptar, manteniéndonos enfocados en un enfoque láser‑centrado en su alcance definido y abordando el panorama de riesgos, que evoluciona rápidamente y es propio de la IA.

## Objetivos clave para AISVS Versión 1.0

La versión 1.0 se creará con varios principios rectores.

### Alcance bien‑definido

Cada requisito debe estar alineado con el nombre y la misión de AISVS:

* Inteligencia Artificial – los controles operan a nivel de la capa de IA/ML (datos, modelo, pipeline o inferencia) y son responsabilidad de los profesionales de IA.
* Seguridad – Los requisitos mitigan directamente los riesgos identificados de seguridad, privacidad o seguridad.
* Verificación – El lenguaje está escrito de modo que la conformidad pueda validarse de forma objetiva.
* Estándar – Las secciones siguen una estructura y terminología consistentes para formar una referencia coherente.
  ​
---

Al seguir AISVS, las organizaciones pueden evaluar de forma sistemática y fortalecer la postura de seguridad de sus soluciones de IA, fomentando una cultura de ingeniería de IA segura.

