# الملحق أ: مسرد المصطلحات

>يوفر هذا القاموس الشامل تعريفات للمصطلحات الرئيسية في الذكاء الاصطناعي، وتعلم الآلة، والأمن المستخدمة في جميع أنحاء نظام AISVS لضمان الوضوح والفهم المشترك.

* مثال الخصم: إدخال تم تصميمه عمدًا لإجبار نموذج الذكاء الاصطناعي على ارتكاب خطأ، غالبًا عن طريق إضافة تعديلات طفيفة غير مرئية للبشر.
  ​
* المتانة العدائية – تشير المتانة العدائية في الذكاء الاصطناعي إلى قدرة النموذج على الحفاظ على أدائه ومقاومة الخداع أو التلاعب من خلال مدخلات خبيثة مصممة بشكل متعمد لإحداث أخطاء.
  ​
* الوكيل – الوكلاء الذكيون هم أنظمة برمجية تستخدم الذكاء الاصطناعي لتحقيق أهداف وإتمام مهام نيابةً عن المستخدمين. يظهرون القدرة على الاستدلال، والتخطيط، والذاكرة، ولديهم مستوى من الاستقلالية لاتخاذ القرارات والتعلم والتكيف.
  ​
* الذكاء الاصطناعي الوكالي: أنظمة الذكاء الاصطناعي التي يمكنها العمل بدرجة معينة من الاستقلالية لتحقيق الأهداف، غالبًا ما تتخذ قرارات وتتخذ إجراءات دون تدخل بشري مباشر.
  ​
* التحكم في الوصول القائم على السمات (ABAC): نموذج للتحكم في الوصول حيث تستند قرارات التفويض إلى سمات المستخدم، المورد، الإجراء، والبيئة، ويتم تقييمها في وقت الاستعلام.
  ​
* هجوم الباب الخلفي: نوع من هجمات تسميم البيانات حيث يتم تدريب النموذج للاستجابة بطريقة معينة لمثيرات محددة مع التصرف بشكل طبيعي بخلاف ذلك.
  ​
* التحيز: أخطاء منهجية في مخرجات نموذج الذكاء الاصطناعي يمكن أن تؤدي إلى نتائج غير عادلة أو تمييزية لمجموعات معينة أو في سياقات محددة.
  ​
* استغلال التحيز: تقنية هجوم تستغل التحيزات المعروفة في نماذج الذكاء الاصطناعي للتلاعب بالمخرجات أو النتائج.
  ​
* سيدر: لغة سياسة أمازون ومحركها للصلاحيات الدقيقة المستخدمة في تنفيذ التحكم في الوصول المعتمد على السمات (ABAC) لأنظمة الذكاء الاصطناعي.
  ​
* سلسلة التفكير: تقنية لتحسين الاستدلال في نماذج اللغة من خلال إنشاء خطوات استدلال وسيطة قبل إنتاج الإجابة النهائية.
  ​
* قواطع الدائرة: آليات توقف عمليات نظام الذكاء الاصطناعي تلقائيًا عند تجاوز حدود معينة للمخاطر.
  ​
* تسرب البيانات: التعرض غير المقصود للمعلومات الحساسة من خلال مخرجات أو سلوك نموذج الذكاء الاصطناعي.
  ​
* تسميم البيانات: هو الفساد المتعمد لبيانات التدريب بهدف الإضرار بسلامة النموذج، غالبًا لتثبيت أبواب خلفية أو تدهور الأداء.
  ​
* الخصوصية التفاضلية – الخصوصية التفاضلية هي إطار عمل رياضي دقيق لإصدار معلومات إحصائية حول مجموعات البيانات مع حماية خصوصية الأفراد المعنيين بالبيانات. تسمح لحامل البيانات بمشاركة أنماط مجموعية للمجموعة مع تقليل المعلومات التي يتم تسريبها عن أفراد محددين.
  ​
* التضمينات: تمثيلات متجهية كثيفة للبيانات (نصوص، صور، إلخ) تلتقط المعنى الدلالي في فضاء عالي الأبعاد.
  ​
* الشرحية – الشرحية في الذكاء الاصطناعي هي قدرة نظام الذكاء الاصطناعي على تقديم أسباب مفهومة للبشر لقراراته وتوقعاته، مما يوفر رؤى حول كيفية عمله الداخلي.
  ​
* الذكاء الاصطناعي القابل للتفسير (XAI): أنظمة الذكاء الاصطناعي المصممة لتوفير تفسيرات قابلة للفهم البشري لقراراتها وسلوكياتها من خلال تقنيات وأُطُر متنوعة.
  ​
* التعلم الفدرالي: نهج في التعلم الآلي حيث يتم تدريب النماذج عبر عدة أجهزة لا مركزية تحتفظ بعينات بيانات محلية، دون تبادل البيانات نفسها.
  ​
* القيود الأمنية: القيود التي تُنفذ لمنع أنظمة الذكاء الاصطناعي من إنتاج مخرجات ضارة أو متحيزة أو غير مرغوب فيها بأي شكل آخر.
  ​
* الهلاوس – تشير هلاوس الـ AI إلى ظاهرة حيث يقوم نموذج الذكاء الاصطناعي بتوليد معلومات غير صحيحة أو مضللة ليست مستندة إلى بيانات التدريب الخاصة به أو الواقع الفعلي.
  ​
* الإنسان في الحلقة (HITL): أنظمة مصممة لتتطلب إشراف الإنسان، التحقق، أو التدخل في نقاط اتخاذ القرار الحاسمة.
  ​
* البنية التحتية كرمز (IaC): إدارة وتوفير البنية التحتية من خلال الكود بدلاً من العمليات اليدوية، مما يتيح فحص الأمان وعمليات النشر المتسقة.
  ​
* الهروب من القيود: تقنيات تُستخدم لتجاوز ضوابط الأمان في أنظمة الذكاء الاصطناعي، وخاصة في نماذج اللغة الكبيرة، لإنتاج محتوى محظور.
  ​
* الامتياز الأدنى: مبدأ الأمان الذي ينص على منح أقل حقوق وصول ضرورية فقط للمستخدمين والعمليات.
  ​
* LIME (التفسيرات المحلية المستقلة عن النموذج): تقنية لشرح توقعات أي مصنف تعلم آلي عن طريق تقريبها محليًا باستخدام نموذج قابل للتفسير.
  ​
* هجوم استدلال العضوية: هو هجوم يهدف إلى تحديد ما إذا تم استخدام نقطة بيانات محددة لتدريب نموذج التعلم الآلي.
  ​
* MITRE ATLAS: مشهد التهديدات العدائية لأنظمة الذكاء الاصطناعي؛ قاعدة معرفية للتكتيكات والأساليب العدائية ضد أنظمة الذكاء الاصطناعي.
  ​
* بطاقة النموذج – بطاقة النموذج هي وثيقة توفر معلومات معيارية حول أداء نموذج الذكاء الاصطناعي، والقيود، والاستخدامات المقصودة، والاعتبارات الأخلاقية لتعزيز الشفافية والتنمية المسؤولة للذكاء الاصطناعي.
  ​
* استخلاص النموذج: هجوم يقوم فيه الخصم باستمرار استجواب نموذج مستهدف لإنشاء نسخة وظيفية مشابهة بدون إذن.
  ​
* عكس النموذج: هجوم يحاول إعادة بناء بيانات التدريب من خلال تحليل مخرجات النموذج.
  ​
* إدارة دورة حياة النموذج – إدارة دورة حياة نموذج الذكاء الاصطناعي هي عملية الإشراف على جميع مراحل وجود نموذج الذكاء الاصطناعي، بما في ذلك تصميمه، وتطويره، ونشره، ومراقبته، وصيانته، والتقاعد النهائي له، لضمان استمراره في الفعالية والتوافق مع الأهداف.
  ​
* تسميم النموذج: إدخال ثغرات أو أبواب خلفية مباشرة في النموذج أثناء عملية التدريب.
  ​
* سرقة/استنساخ النموذج: استخراج نسخة أو تقريبات لنموذج مملوك من خلال استعلامات متكررة.
  ​
* نظام متعدد الوكلاء: نظام يتكون من عدة عوامل ذكاء اصطناعي تفاعلية، كل منها قد يمتلك قدرات وأهداف مختلفة.
  ​
* OPA (وكيل السياسة المفتوحة): محرك سياسات مفتوح المصدر يتيح تطبيق السياسات بشكل موحد عبر جميع المستويات.
  ​
* التعلم الآلي مع الحفاظ على الخصوصية (PPML): تقنيات وأساليب لتدريب ونشر نماذج التعلم الآلي مع حماية خصوصية بيانات التدريب.
  ​
* حقن المدخلات: هجوم يتم فيه تضمين تعليمات خبيثة في المدخلات لتجاوز سلوك النموذج المقصود.
  ​
* RAG (التوليد المعزز بالاستخراج): تقنية تعزز نماذج اللغة الكبيرة من خلال استرجاع المعلومات ذات الصلة من مصادر المعرفة الخارجية قبل توليد الاستجابة.
  ​
* الهجوم الأحمر: ممارسة اختبار أنظمة الذكاء الاصطناعي بشكل فعّال من خلال محاكاة هجمات معادية لتحديد نقاط الضعف.
  ​
* SBOM (قائمة مكونات البرمجيات): سجل رسمي يحتوي على تفاصيل وعلاقات سلسلة التوريد لمكونات مختلفة تُستخدم في بناء البرمجيات أو نماذج الذكاء الاصطناعي.
  ​
* SHAP (تفسيرات شابلية التضافر): نهج يعتمد على نظرية الألعاب لشرح ناتج أي نموذج تعلم آلي من خلال حساب مساهمة كل ميزة في التنبؤ.
  ​
* هجوم سلسلة التوريد: اختراق نظام عن طريق استهداف العناصر الأقل أمانًا في سلسلة التوريد الخاصة به، مثل مكتبات الطرف الثالث، مجموعات البيانات، أو النماذج المدربة مسبقًا.
  ​
* التعلم الانتقالي: تقنية يتم فيها إعادة استخدام نموذج تم تطويره لمهمة واحدة كنقطة انطلاق لنموذج في مهمة ثانية.
  ​
* قاعدة البيانات الشعاعية: قاعدة بيانات متخصصة مصممة لتخزين المتجهات عالية الأبعاد (التضمينات) وتنفيذ عمليات بحث تشابه فعالة.
  ​
* فحص الثغرات الأمنية: أدوات آلية تحدد الثغرات الأمنية المعروفة في مكونات البرمجيات، بما في ذلك أُطُر العمل للذكاء الاصطناعي والتبعيات.
  ​
* الوسم المائي: تقنيات تضمين علامات غير قابلة للإدراك في المحتوى المُنتج بواسطة الذكاء الاصطناعي لتتبع مصدره أو اكتشاف توليده بواسطة الذكاء الاصطناعي.
  ​
* ثغرة اليوم الصفري: هي ثغرة لم تكن معروفة سابقًا يمكن للمهاجمين استغلالها قبل أن يقوم المطورون بإنشاء ونشر ترقية إصلاحية.

