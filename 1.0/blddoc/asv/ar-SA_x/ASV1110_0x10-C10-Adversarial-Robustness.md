# 10 المتانة ضد الهجمات العدائية والدفاع عن الخصوصية

## هدف الرقابة

تأكد من أن نماذج الذكاء الاصطناعي تظل موثوقة مع الحفاظ على الخصوصية ومقاومة لسوء الاستخدام عند مواجهة هجمات التهرب والاستدلال والاستخراج والتسميم.

---

## 10.1 محاذاة النموذج والسلامة

احذر من المخرجات الضارة أو التي تخالف السياسات.

|   #    | الوصف                                                                                                                                                              | المستوى | الدور |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :-----: | :---: |
| 10.1.1 | تحقق من أن مجموعة اختبارات المحاذاة (موجهات فريق الاختبار الأحمر، استقصاءات فك القيود، المحتوى المحظور) مدارة بنظام التحكم بالإصدارات وتُشغّل مع كل إصدار للنموذج. |    1    |  D/V  |
| 10.1.2 | تحقق من تطبيق قيود الرفض وحواجز الإكمال الآمن.                                                                                                                     |    1    |   D   |
| 10.1.3 | تحقق من أن مُقيِّم آلي يقيس معدل المحتوى الضار ويُعلِم بالتراجعات التي تتجاوز عتبة محددة.                                                                          |    2    |  D/V  |
| 10.1.4 | تحقق من أن تدريب مضاد لكسر الحماية موثق وقابل لإعادة الإنتاج.                                                                                                      |    2    |   D   |
| 10.1.5 | تحقق من أن إثباتات الامتثال الرسمي للسياسات أو المراقبة المعتمدة تغطي المجالات الحرجة.                                                                             |    3    |   V   |

---

## 10.2 تحصين-الأمثلة العدائية

زيادة المرونة أمام المدخلات المعدلة بشكل عدائي. التدريب العدائي القوي وتقييم المعايير المرجعية هما أفضل الممارسات في الوقت الحالي.

|   #    | الوصف                                                                                                  | المستوى | الدور |
| :----: | ------------------------------------------------------------------------------------------------------ | :-----: | :---: |
| 10.2.1 | تحقق من أن مستودعات المشاريع تتضمن إعدادات التدريب ضد الهجمات مع بذور قابلة لإعادة الإنتاج.            |    1    |   D   |
| 10.2.2 | تحقق من أن كشف الأمثلة العدائية يثير تنبيهات الحظر في خطوط الإنتاج.                                    |    2    |  D/V  |
| 10.2.4 | تحقق من أن براهين المتانة المعتمدة أو شهادات الحدود النطاقية تغطي على الأقل أهم الفئات الحرجة.         |    3    |   V   |
| 10.2.5 | تحقق من أن اختبارات الانحدار تستخدم الهجمات التكيفية للتأكد من عدم وجود انخفاض قابل للقياس في المتانة. |    3    |   V   |

---

## 10.3 التخفيف من استنتاج العضوية

تقليل القدرة على تحديد ما إذا كان سجل معين موجوداً في بيانات التدريب. تظل الخصوصية التفاضلية وإخفاء درجات الثقة من أكثر وسائل الدفاع فاعلية المعروفة.

|   #    | الوصف                                                                                                     | المستوى | الدور |
| :----: | --------------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 10.3.1 | تحقق من أن تنظيم الإنتروبيا لكل استعلام أو ضبط درجة الحرارة يقلل من التنبؤات ذات الثقة المفرطة.           |    1    |   D   |
| 10.3.2 | تحقق من أن التدريب يستخدم تحسيناً ذا خصوصية تفاضلية مقيدة بـ ε للبيانات الحساسة.                          |    2    |   D   |
| 10.3.3 | تحقق من أن محاكاة الهجوم (النموذج الظلي أو الصندوق الأسود) تُظهر AUC الهجوم ≤ 0.60 على البيانات المحجوزة. |    2    |   V   |

---

## 10.4 مقاومة استرجاع النموذج

منع إعادة بناء السمات الخاصة. تشير الاستطلاعات الأخيرة إلى اقتطاع الإخراج وضمانات الخصوصية التفاضلية (DP) كإجراءات دفاعية عملية.

|   #    | الوصف                                                                                                             | المستوى | الدور |
| :----: | ----------------------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 10.4.1 | تحقق من أن السمات الحساسة لا تخرج مباشرة مطلقاً؛ عند الحاجة، استخدم التقطيع إلى فئات أو التحويلات أحادية الاتجاه. |    1    |   D   |
| 10.4.2 | تحقق من أن حدود معدل الاستعلامات تُبطئ الاستفسارات التكيفية المتكررة من نفس الجهة المفوَّضة.                      |    1    |  D/V  |
| 10.4.3 | تحقق من أن النموذج مُدرَّب باستخدام ضوضاء تحافظ على الخصوصية.                                                     |    2    |   D   |

---

## 10.5 الدفاع ضد استخراج النموذج

اكتشاف ومنع الاستنساخ غير المصرح به. يوصى بإضافة علامة مائية وتحليل نمط الاستعلام.

|   #    | الوصف                                                                                                               | المستوى | الدور |
| :----: | ------------------------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 10.5.1 | تحقق من أن بوابات الاستدلال تفرض حدود المعدل العالمي وحدود المعدل لكل مفتاح API، مضبوطة وفق عتبة حفظ ذاكرة النموذج. |    1    |   D   |
| 10.5.2 | تحقق من أن إحصاءات إنتروبيا-الاستعلام وتعددية-المدخلات تغذي كاشف استخراج تلقائي.                                    |    2    |  D/V  |
| 10.5.3 | تحقق من أن العلامات المائية الهشة أو الاحتمالية يمكن إثباتها بـ p < 0.01 في ≤ 1 000 استعلام ضد استنساخ مشتبه به     |    2    |   V   |
| 10.5.4 | تحقق من أن مفاتيح العلامة المائية ومجموعات المحفزات مخزنة في وحدة أمان الأجهزة ويتم تدويرها سنويًا.                 |    3    |   D   |
| 10.5.5 | تحقق من أن أحداث التنبيه للاستخراج تتضمن الاستعلامات المسيئة وتتكامل مع خطط استجابة الحوادث.                        |    3    |   V   |

---

## 10.6 كشف البيانات الملوثة أثناء الاستدلال

تحديد وتحييد المدخلات المحتوية على باب خلفي أو المدخلات الملوثة.

|   #    | الوصف                                                                                                           | المستوى | الدور |
| :----: | --------------------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 10.6.1 | تحقق من أن المدخلات تمر عبر كاشف الشذوذ (مثلاً STRIP، وتقييم الاتساق) قبل استدلال النموذج.                      |    1    |   D   |
| 10.6.2 | تحقق من أن عتبات الكشف تم ضبطها على مجموعات التحقق النظيفة/المسمّمة لتحقيق أقل من 5% من الإيجابيات الكاذبة.     |    1    |   V   |
| 10.6.3 | تحقق من أن المدخلات المصنَّفة كمسمَّمة تؤدي إلى تفعيل الحظر الناعم وتدفقات العمل للمراجعة البشرية.              |    2    |   D   |
| 10.6.4 | تحقق من أن الكاشفات يتم إخضاعها لاختبارات الإجهاد باستخدام هجمات باب خلفي تكيفية بدون محفز.                     |    2    |   V   |
| 10.6.5 | تحقق من أن مقاييس فعالية الكشف مُسجَّلة وتُعاد تقييمها بشكل دوري باستخدام معلومات استخبارية حديثة عن التهديدات. |    3    |   D   |

---

## 10.7 التكيف الديناميكي لسياسة الأمن

تحديثات سياسة الأمن في الوقت الفعلي استنادًا إلى استخبارات التهديد والتحليل السلوكي.

|   #    | الوصف                                                                                                              | المستوى | الدور |
| :----: | ------------------------------------------------------------------------------------------------------------------ | :-----: | :---: |
| 10.7.1 | تحقق من أن سياسات الأمان يمكن تحديثها ديناميكياً دون إعادة تشغيل الوكيل مع الحفاظ على تكامل إصدار السياسة.         |    1    |  D/V  |
| 10.7.2 | تحقق من أن تحديثات السياسة موقَّعة رقمياً من قبل موظفين أمنيين مخولين ومُدَقَّقة قبل التطبيق.                      |    2    |  D/V  |
| 10.7.3 | تحقق من أن تغييرات السياسة الديناميكية تُسجل مع سجلات تدقيق كاملة تشمل المبررات وسلاسل الموافقات وإجراءات التراجع. |    2    |  D/V  |
| 10.7.4 | تحقق من أن آليات الأمن التكيفية تضبط حساسية اكتشاف التهديدات استنادًا إلى سياق المخاطر وأنماط السلوك.              |    3    |  D/V  |
| 10.7.5 | تحقق من أن قرارات تكييف السياسة قابلة للتفسير وتتضمن مسارات الأدلة لمراجعة فريق الأمن.                             |    3    |  D/V  |

---

## 10.8 تحليل أمني قائم على الانعكاس

التحقق الأمني من خلال تفكّر الوكيل في ذاته والتحليل الميتا-معرفي.

|   #    | الوصف                                                                                                              | المستوى | الدور |
| :----: | ------------------------------------------------------------------------------------------------------------------ | :-----: | :---: |
| 10.8.1 | تحقق من أن آليات انعكاس الوكيل تتضمن تقييمًا ذاتيًا يركّز على الأمن لقراراته وإجراءاته.                            |    1    |  D/V  |
| 10.8.2 | تحقق من صحة مخرجات الانعكاس لضمان عدم التلاعب بآليات التقييم الذاتي من خلال المدخلات العدائية.                     |    2    |  D/V  |
| 10.8.3 | تحقق من أن تحليل أمان ميتا-معرفي يحدد التحيز المحتمل أو التلاعب أو التعرض للاختراق في عمليات الاستدلال لدى الوكيل. |    2    |  D/V  |
| 10.8.4 | تحقق من أن التحذيرات الأمنية المستندة إلى الانعكاس تُؤدي إلى تفعيل مراقبة مُعزَّزة وتدفقات عمل تدخل بشري محتمل.    |    3    |  D/V  |
| 10.8.5 | تحقق من أن التعلم المستمر من الانعكاسات الأمنية يحسّن اكتشاف التهديدات دون الإضرار بالوظائف المشروعة.              |    3    |  D/V  |

---

## 10.9 أمان التطور والتحسين الذاتي

ضوابط الأمان لأنظمة الوكلاء القادرة على التعديل الذاتي والتطور.

|   #    | الوصف                                                                                       | المستوى | الدور |
| :----: | ------------------------------------------------------------------------------------------- | :-----: | :---: |
| 10.9.1 | تحقق من أن قدرات التعديل الذاتي مقصورة على مناطق آمنة محددة مع حدود التحقق الرسمي.          |    1    |  D/V  |
| 10.9.2 | تحقق من أن مقترحات التطوير تخضع لتقييم أثر الأمن قبل التنفيذ.                               |    2    |  D/V  |
| 10.9.3 | تحقق من أن آليات التحسين الذاتي تتضمن قدرات التراجع مع التحقق من التكامل.                   |    2    |  D/V  |
| 10.9.4 | تحقق من أن أمان التعلم الميتا يمنع التلاعب العدائي في خوارزميات التحسين.                    |    3    |  D/V  |
| 10.9.5 | تحقق من أن التحسن الذاتي التكراري محدود بقيود السلامة الشكلية مع براهين رياضية على التقارب. |    3    |  D/V  |

---

### المراجع

* [MITRE ATLAS adversary tactics for ML](https://atlas.mitre.org/)
* [NIST AI Risk Management Framework 1.0, 2023](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [OWASP Top 10 for LLM Applications, 2025](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Adversarial Training: A Survey — Zhao et al., 2024](https://arxiv.org/abs/2410.15042)
* [RobustBench adversarial-robustness benchmark](https://robustbench.github.io/)
* [Membership-Inference & Model-Inversion Risk Survey, 2025](https://www.sciencedirect.com/science/article/abs/pii/S0950705125003867)
* [PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023](https://ojs.aaai.org/index.php/AAAI/article/view/26289)
* [Model-Inversion Attacks & Defenses Survey — AI Review, 2025](https://link.springer.com/article/10.1007/s10462-025-11248-0)
* [Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024](https://doi.org/10.1109/TDSC.2023.3261327)
* [Fragile Model Watermarking Survey — 2025](https://www.sciencedirect.com/science/article/abs/pii/S0165168425002026)
* [Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025](https://arxiv.org/abs/2503.22759)
* [BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024](https://arxiv.org/abs/2405.15269)

