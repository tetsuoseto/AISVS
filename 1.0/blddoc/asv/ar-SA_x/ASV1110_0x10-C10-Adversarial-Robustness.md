# 10 الصلابة ضد الهجمات العدائية والدفاع عن الخصوصية

## هدف التحكم

تأكد من بقاء نماذج الذكاء الاصطناعي موثوقة، تحافظ على الخصوصية، ومقاومة لسوء الاستخدام عند مواجهة هجمات التهرب، الاستنتاج، الاستخراج، أو التسميم.

---

## 10.1 محاذاة النموذج والسلامة

الحذر من المخرجات الضارة أو المخالفة للسياسات.

|   #    | الوصف                                                                                                                                                                         | المستوى | الدور |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 10.1.1 | تحقق من أن مجموعة اختبار المحاذاة (موجهات الفريق الأحمر، استقصاءات اختراق السجن، المحتوى الممنوع) تتم إدارتها بنظام التحكم في الإصدارات ويتم تشغيلها على كل إصدار من النموذج. |    1    |  D/V  |
| 10.1.2 | تحقق من تطبيق قواعد الرفض وحماية إكمال المهام بأمان.                                                                                                                          |    1    |   D   |
| 10.1.3 | تحقق من أن المقيم الآلي يقيس معدل المحتوى الضار ويشير إلى التراجع الذي يتجاوز الحد المحدد.                                                                                    |    2    |  D/V  |
| 10.1.4 | تحقق من أن تدريب مكافحة الكسر محمي بشكل موثق وقابل لإعادة الإنتاج.                                                                                                            |    2    |   D   |
| 10.1.5 | تحقق من أن إثباتات الامتثال للسياسات الرسمية أو المراقبة المعتمدة تغطي المجالات الحرجة.                                                                                       |    3    |   V   |

---

## 10.2 تعزيز مقاومة الأمثلة المعادية

زيادة الصلابة ضد المدخلات المُعدّلة. التدريب العدائي القوي وتقييم المعايير هما أفضل الممارسات الحالية.

|   #    | الوصف                                                                                           | المستوى | الدور |
| :----: | ----------------------------------------------------------------------------------------------- | :-----: | :---: |
| 10.2.1 | تحقق من أن مستودعات المشروع تتضمن إعدادات تدريب معاكسة مع بذور قابلة لإعادة الإنتاج.            |    1    |   D   |
| 10.2.2 | تحقق من أن الكشف عن الأمثلة العدائية يثير تنبيهات الحجب في خطوط الإنتاج.                        |    2    |  D/V  |
| 10.2.4 | تحقق من أن إثباتات المتانة المعتمدة أو شهادات حدود الفترات تغطي على الأقل الفئات الحرجة العليا. |    3    |   V   |
| 10.2.5 | تحقق من أن اختبارات الانحدار تستخدم الهجمات التكيفية لتأكيد عدم وجود فقدان ملحوظ في المتانة.    |    3    |   V   |

---

## 10.3 التخفيف من استنتاج العضوية

تقييد القدرة على تحديد ما إذا كانت السجلات موجودة في بيانات التدريب. تظل الخصوصية التفاضلية وإخفاء درجة الثقة أكثر وسائل الدفاع فعالية المعروفة.

|   #    | الوصف                                                                                                                               | المستوى | الدور |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 10.3.1 | تحقق من أن تنظيم الانتروبيا لكل استعلام أو تعديل درجة الحرارة يقلل من التنبؤات المفرطة الثقة.                                       |    1    |   D   |
| 10.3.2 | تحقق من أن التدريب يستخدم تحسين الخصوصية التفاضلية المحصور بـ ε لمجموعات البيانات الحساسة.                                          |    2    |   D   |
| 10.3.3 | تحقق من أن محاكاة الهجوم (نموذج الظل أو الصندوق الأسود) تظهر أن مساحة تحت منحنى الهجوم (AUC) ≤ 0.60 على البيانات المحتجزة للاختبار. |    2    |   V   |

---

## 10.4 مقاومة انقلاب النموذج

منع إعادة بناء السمات الخاصة. تؤكد الدراسات الاستقصائية الحديثة على تقطيع المخرجات وضمانات حماية الخصوصية التفاضلية كدفاعات عملية.

|   #    | الوصف                                                                                                       | المستوى | الدور |
| :----: | ----------------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 10.4.1 | تحقق من أن السمات الحساسة لا تُخرج مباشرة أبدًا؛ وعند الحاجة، استخدم التجميعات أو التحويلات أحادية الاتجاه. |    1    |   D   |
| 10.4.2 | تحقق من أن حدود معدل الاستعلام تحد من تكرار الاستعلامات التكيفية من نفس المستخدم.                           |    1    |  D/V  |
| 10.4.3 | تحقق من أن النموذج تم تدريبه باستخدام ضوضاء تحافظ على الخصوصية.                                             |    2    |   D   |

---

## 10.5 الدفاع ضد استخراج النماذج

كشف وردع النسخ غير المصرح به. يُوصى باستخدام تقنية العلامات المائية وتحليل أنماط الاستعلام.

|   #    | الوصف                                                                                                             | المستوى | الدور |
| :----: | ----------------------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 10.5.1 | تحقق من أن بوابات الاستدلال تفرض حدود معدلات عامة وخاصة بكل مفتاح API مصممة وفقًا لعتبة الحفظ الخاصة بالنموذج.    |    1    |   D   |
| 10.5.2 | تحقق من أن إحصائيات إنتروبيا الاستعلام وتعددية الإدخال تغذي كاشف الاستخراج الآلي.                                 |    2    |  D/V  |
| 10.5.3 | تحقق من أن العلامات المائية الهشة أو الاحتمالية يمكن إثباتها بقيمة p < 0.01 في ≤ 1 000 استعلام ضد نسخة مشتبه بها. |    2    |   V   |
| 10.5.4 | تحقق من أن مفاتيح العلامة المائية ومجموعات التشغيل مخزنة في وحدة أمان الأجهزة ويتم تدويرها سنويًا.                |    3    |   D   |
| 10.5.5 | تحقق من أن أحداث التنبيه الخاصة بالاستخراج تتضمن الاستعلامات المخالفة وأنها مدمجة مع كتيبات استجابة الحوادث.      |    3    |   V   |

---

## 10.6 كشف البيانات المسمومة في وقت الاستنتاج

تحديد المدخلات المزودة بأبواب خلفية أو المسمومة وتحيدها.

|   #    | الوصف                                                                                                | المستوى | الدور |
| :----: | ---------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 10.6.1 | تحقق من أن المدخلات تمر عبر كاشف الشذوذ (مثل STRIP، تقييم الاتساق) قبل استدلال النموذج.              |    1    |   D   |
| 10.6.2 | تأكد من ضبط عتبات الكاشف على مجموعات تحقق نظيفة/مسمومة لتحقيق أقل من 5% من الإيجابيات الكاذبة.       |    1    |   V   |
| 10.6.3 | تحقق من أن المدخلات التي تم تعليمها على أنها ملوثة تُفعّل حظرًا ناعماً وتدفقات عمل للمراجعة البشرية. |    2    |   D   |
| 10.6.4 | تحقق من أن أجهزة الكشف قد خضعت لاختبارات إجهاد باستخدام هجمات خلفية تكيفية دون محرض.                 |    2    |   V   |
| 10.6.5 | تحقق من تسجيل مقاييس فاعلية الكشف وإعادة تقييمها بشكل دوري باستخدام معلومات تهديد حديثة.             |    3    |   D   |

---

## 10.7 التكيف الديناميكي لسياسة الأمان

تحديثات سياسة الأمان في الوقت الحقيقي بناءً على استخبارات التهديدات وتحليل السلوك.

|   #    | الوصف                                                                                                            | المستوى | الدور |
| :----: | ---------------------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 10.7.1 | تحقق من إمكانية تحديث سياسات الأمان ديناميكيًا دون إعادة تشغيل الوكيل مع الحفاظ على سلامة إصدار السياسة.         |    1    |  D/V  |
| 10.7.2 | تحقق من أن تحديثات السياسة موقعة تشفيرياً من قبل موظفي الأمن المخولين وتم التحقق منها قبل التطبيق.               |    2    |  D/V  |
| 10.7.3 | تحقق من أن تغييرات السياسة الديناميكية مسجلة بسجلات تدقيق كاملة تشمل التبرير، وسلاسل الموافقة، وإجراءات التراجع. |    2    |  D/V  |
| 10.7.4 | تحقق من أن آليات الأمان التكيفية تضبط حساسية كشف التهديدات بناءً على سياق المخاطر وأنماط السلوك.                 |    3    |  D/V  |
| 10.7.5 | تحقق من أن قرارات تكييف السياسات قابلة للتفسير وتتضمن مسارات أدلة لمراجعة فريق الأمان.                           |    3    |  D/V  |

---

## 10.8 التحليل الأمني القائم على الانعكاس

التحقق الأمني من خلال التأمل الذاتي للوكيل والتحليل الميتا-معرفي.

|   #    | الوصف                                                                                                                         | المستوى | الدور |
| :----: | ----------------------------------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 10.8.1 | تحقق من أن آليات انعكاس الوكيل تتضمن التقييم الذاتي المركّز على الأمان للقرارات والإجراءات.                                   |    1    |  D/V  |
| 10.8.2 | تحقق من أن مخرجات الانعكاس تم التحقق منها لمنع التلاعب بآليات التقييم الذاتي بواسطة المدخلات العدائية.                        |    2    |  D/V  |
| 10.8.3 | تحقق من أن التحليل الأمني فوق المعرفي يحدد التحيز المحتمل أو التلاعب أو الخطر في عمليات استدلال الوكيل.                       |    2    |  D/V  |
| 10.8.4 | تحقق من أن تحذيرات الأمان القائمة على الانعكاس تؤدي إلى تفعيل المراقبة المعززة وإمكانيات التدخل البشري المحتملة في سير العمل. |    3    |  D/V  |
| 10.8.5 | تحقق من أن التعلم المستمر من الانعكاسات الأمنية يحسن من اكتشاف التهديدات دون التأثير سلباً على الوظائف الشرعية.               |    3    |  D/V  |

---

## 10.9 الأمن والتحسين الذاتي

ضوابط الأمان لأنظمة العملاء القادرة على التعديل الذاتي والتطور.

|   #    | الوصف                                                                                         | المستوى | الدور |
| :----: | --------------------------------------------------------------------------------------------- | :-----: | :---: |
| 10.9.1 | تحقق من أن قدرات التعديل الذاتي مقيدة بالمناطق الآمنة المحددة التي تحتوي على حدود تحقق رسمية. |    1    |  D/V  |
| 10.9.2 | تأكد من خضوع مقترحات التطوير لتقييم تأثير الأمان قبل التنفيذ.                                 |    2    |  D/V  |
| 10.9.3 | تحقق من أن آليات تحسين الذات تتضمن قدرات التراجع مع التحقق من سلامة البيانات.                 |    2    |  D/V  |
| 10.9.4 | تحقق من أن أمان التعلم التعزيزي يمنع التلاعب العدائي بخوارزميات التحسين.                      |    3    |  D/V  |
| 10.9.5 | تحقق من أن التحسن الذاتي التكراري محدود بقيود السلامة الرسمية مع إثباتات رياضية للتقارب.      |    3    |  D/V  |

---

### المراجع

* [MITRE ATLAS adversary tactics for ML](https://atlas.mitre.org/)
* [NIST AI Risk Management Framework 1.0, 2023](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [OWASP Top 10 for LLM Applications, 2025](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Adversarial Training: A Survey — Zhao et al., 2024](https://arxiv.org/abs/2410.15042)
* [RobustBench adversarial-robustness benchmark](https://robustbench.github.io/)
* [Membership-Inference & Model-Inversion Risk Survey, 2025](https://www.sciencedirect.com/science/article/abs/pii/S0950705125003867)
* [PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023](https://ojs.aaai.org/index.php/AAAI/article/view/26289)
* [Model-Inversion Attacks & Defenses Survey — AI Review, 2025](https://link.springer.com/article/10.1007/s10462-025-11248-0)
* [Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024](https://doi.org/10.1109/TDSC.2023.3261327)
* [Fragile Model Watermarking Survey — 2025](https://www.sciencedirect.com/science/article/abs/pii/S0165168425002026)
* [Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025](https://arxiv.org/abs/2503.22759)
* [BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024](https://arxiv.org/abs/2405.15269)

