# 10 المتانة ضد الهجمات العدائية والدفاع عن الخصوصية

## هدف التحكم

ضمان بقاء نماذج الذكاء الاصطناعي موثوقة، ومحافظة على الخصوصية، ومقاومة لسوء الاستخدام عند مواجهة هجمات التهرب، الاستدلال، الاستغلال، أو التسميم.

---

## 10.1 محاذاة النموذج والسلامة

الحماية من المخرجات الضارة أو المخالفة للسياسات.

|   #    | الوصف                                                                                                                                              | المستوى | الدور |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 10.1.1 | تحقق من أن مجموعة اختبار المحاذاة (مطالبات الفريق الأحمر، استكشافات كسر الحماية، المحتوى الممنوع) تحت نظام إصدار ويتم تشغيلها مع كل إصدار للنموذج. |    1    |  D/V  |
| 10.1.2 | التحقق من أن قواعد الرفض والحماية من الإكمال الآمن مطبقة.                                                                                          |    1    |   D   |
| 10.1.3 | تحقق من أن المُقيّم الآلي يقيس معدل المحتوى الضار ويُحدد التراجعات التي تتجاوز العتبة المحددة.                                                     |    2    |  D/V  |
| 10.1.4 | تحقق من توثيق تدريب مكافحة الهروب من الحماية وقابليته للتكرار.                                                                                     |    2    |   D   |
| 10.1.5 | تحقق من أن إثباتات الامتثال للسياسات الرسمية أو المراقبة المعتمدة تغطي النطاقات الحرجة.                                                            |    3    |   V   |

---

## 10.2 تقوية ضد الأمثلة التضليلية

زيادة المرونة تجاه المدخلات المُعدَّلة. التدريب العكسي المتين وتقييم المعايير المرجعية هما أفضل الممارسات الحالية.

|   #    | الوصف                                                                                          | المستوى | الدور |
| :----: | ---------------------------------------------------------------------------------------------- | :-----: | :---: |
| 10.2.1 | تحقق من أن مستودعات المشروع تتضمن تكوينات التدريب العدائية مع بذور قابلة لإعادة الإنتاج.       |    1    |   D   |
| 10.2.2 | تحقق من أن كشف الأمثلة المعادية يرفع تنبيهات الحظر في خطوط الإنتاج.                            |    2    |  D/V  |
| 10.2.4 | تحقق من أن إثباتات المتانة المعتمدة أو شهادات حدود الفاصل تغطي على الأقل الفئات الحرجة العليا. |    3    |   V   |
| 10.2.5 | تحقق من أن اختبارات الانحدار تستخدم هجمات تكيفية لتأكيد عدم وجود فقدان ملحوظ في الصلابة.       |    3    |   V   |

---

## 10.3 التخفيف من استنتاج العضوية

تقييد القدرة على تحديد ما إذا كانت السجلات ضمن بيانات التدريب. تظل الخصوصية التفاضلية وإخفاء درجة الثقة هي أكثر وسائل الدفاع المعروفة فعالية.

|   #    | الوصف                                                                                                                    | المستوى | الدور |
| :----: | ------------------------------------------------------------------------------------------------------------------------ | :-----: | :---: |
| 10.3.1 | تحقق من أن تنظيم الانتروبيا لكل استعلام أو ضبط درجة الحرارة يقلل من التوقعات المفرطة الثقة.                              |    1    |   D   |
| 10.3.2 | تحقق من أن التدريب يستخدم تحسين الخصوصية التفاضلية المحدودة بـ ε للمجموعات البيانية الحساسة.                             |    2    |   D   |
| 10.3.3 | تحقق من أن محاكاة الهجوم (نموذج الظل أو الصندوق الأسود) تُظهر مساحة تحت منحنى الهجوم (AUC) ≤ 0.60 على البيانات المحتجزة. |    2    |   V   |

---

## 10.4 مقاومة انقلاب النموذج

منع إعادة بناء السمات الخاصة. تبرز الدراسات الحديثة تقطيع المخرجات وضمانات الخصوصية التفاضلية كدفاعات عملية.

|   #    | الوصف                                                                                                           | المستوى | الدور |
| :----: | --------------------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 10.4.1 | تحقق من عدم إخراج السمات الحساسة مباشرةً أبدًا؛ وعند الضرورة، استخدم التجميعات أو التحويلات ذات الاتجاه الواحد. |    1    |   D   |
| 10.4.2 | تحقق من أن حدود معدل الاستعلامات تحد من تكرار الاستعلامات التكيفية من نفس الجهة الأساسية.                       |    1    |  D/V  |
| 10.4.3 | تحقق من أن النموذج مدرب باستخدام ضوضاء تحافظ على الخصوصية.                                                      |    2    |   D   |

---

## 10.5 الدفاع ضد استخراج النماذج

كشف وردع الاستنساخ غير المصرح به. يُنصح باستخدام العلامات المائية وتحليل نمط الاستعلام.

|   #    | الوصف                                                                                                          | المستوى | الدور |
| :----: | -------------------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 10.5.1 | تحقق من أن بوابات الاستدلال تفرض حدود معدلات عامة وعلى أساس مفتاح API مُفصلة بما يتناسب مع عتبة تذكر النموذج.  |    1    |   D   |
| 10.5.2 | تحقق من أن إحصائيات إنتروبيا الاستعلام وتعددية الإدخال تغذي كاشف الاستخراج الآلي.                              |    2    |  D/V  |
| 10.5.3 | تحقق من أن العلامات المائية الهشة أو الاحتمالية يمكن إثباتها بقيمة p < 0.01 في ≤ 1 000 استعلام ضد نسخة مشبوهة. |    2    |   V   |
| 10.5.4 | تحقق من أن مفاتيح العلامات المائية ومجموعات المشغلات مخزنة في وحدة أمان الأجهزة ويتم تدويرها سنويًا.           |    3    |   D   |
| 10.5.5 | تأكد من أن أحداث التنبيه بالاستخراج تتضمن الاستعلامات المخالفة وأنها مدمجة مع كتيبات الاستجابة للحوادث.        |    3    |   V   |

---

## 10.6 الكشف عن البيانات الملوثة أثناء وقت الاستدلال

تحديد المدخلات المزودة بأبواب خلفية أو الملوثة وتحييدها.

|   #    | الوصف                                                                                                      | المستوى | الدور |
| :----: | ---------------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 10.6.1 | تحقق من أن المدخلات تمر عبر كاشف الشذوذ (مثل STRIP، تقييم الاتساق) قبل استدلال النموذج.                    |    1    |   D   |
| 10.6.2 | تحقق من ضبط عتبات الكاشف على مجموعات التحقق النظيفة/المسمومة لتحقيق نسبة أقل من 5% من الإيجابيات الخاطئة.  |    1    |   V   |
| 10.6.3 | تحقق من أن المدخلات التي تم اعتبارها ملوثة تؤدي إلى تفعيل الحظر الناعم وسير العمل الخاص بالمراجعة البشرية. |    2    |   D   |
| 10.6.4 | تحقق من أن الكواشف تخضع لاختبارات ضغط باستخدام هجمات خلفية تكيفية بدون مشغّل.                              |    2    |   V   |
| 10.6.5 | تحقق من تسجيل مقاييس فعالية الكشف وإعادة تقييمها بشكل دوري باستخدام معلومات تهديد حديثة.                   |    3    |   D   |

---

## 10.7 التكيف الديناميكي لسياسة الأمان

تحديثات سياسة الأمان في الوقت الحقيقي بناءً على استخبارات التهديدات وتحليل السلوك.

|   #    | الوصف                                                                                                            | المستوى | الدور |
| :----: | ---------------------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 10.7.1 | تحقق من إمكانية تحديث سياسات الأمان ديناميكيًا دون الحاجة لإعادة تشغيل الوكيل مع الحفاظ على سلامة إصدار السياسة. |    1    |  D/V  |
| 10.7.2 | تحقق من أن تحديثات السياسات موقعة تشفيرياً من قبل موظفي الأمن المخولين ويتم التحقق منها قبل التطبيق.             |    2    |  D/V  |
| 10.7.3 | تحقق من تسجيل تغييرات السياسة الديناميكية مع سجلات تدقيق كاملة تشمل التبرير، وسلاسل الموافقة، وإجراءات التراجع.  |    2    |  D/V  |
| 10.7.4 | تحقق من أن آليات الأمان التكيفية تقوم بضبط حساسية اكتشاف التهديدات بناءً على سياق المخاطر وأنماط السلوك.         |    3    |  D/V  |
| 10.7.5 | تحقق من أن قرارات تكيف السياسة قابلة للتفسير وتتضمن أدلة مسارات لمراجعة فريق الأمان.                             |    3    |  D/V  |

---

## 10.8 التحليل الأمني القائم على الانعكاس

التحقق الأمني من خلال التفكير الذاتي للوكيل والتحليل الميتا-معرفي.

|   #    | الوصف                                                                                                             | المستوى | الدور |
| :----: | ----------------------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 10.8.1 | تحقق من أن آليات انعكاس الوكيل تشمل التقييم الذاتي المركَّز على الأمان للقرارات والإجراءات.                       |    1    |  D/V  |
| 10.8.2 | تحقق من أن مخرجات الانعكاس يتم التحقق من صحتها لمنع التلاعب بآليات التقييم الذاتي عبر المدخلات العدائية.          |    2    |  D/V  |
| 10.8.3 | تحقق من أن تحليل الأمان الميتا-معرفي يحدد التحيز المحتمل أو التلاعب أو الاختراق في عمليات تفكير الوكيل.           |    2    |  D/V  |
| 10.8.4 | تحقق من أن تحذيرات الأمان المعتمدة على الانعكاس تؤدي إلى تفعيل المراقبة المعززة وسير العمل المحتمل للتدخل البشري. |    3    |  D/V  |
| 10.8.5 | تحقق من أن التعلم المستمر من المراجعات الأمنية يحسن من اكتشاف التهديدات دون التأثير سلبًا على الوظائف الشرعية.    |    3    |  D/V  |

---

## 10.9 الأمان في التطور والتحسين الذاتي

ضوابط الأمان لأنظمة الوكلاء القادرة على التعديل الذاتي والتطور.

|   #    | الوصف                                                                                     | المستوى | الدور |
| :----: | ----------------------------------------------------------------------------------------- | :-----: | :---: |
| 10.9.1 | تحقق من أن قدرات التعديل الذاتي مقيدة بالمناطق الآمنة المخصصة مع وجود حدود تحقق رسمية.    |    1    |  D/V  |
| 10.9.2 | تحقق من أن مقترحات التطور تخضع لتقييم تأثير الأمان قبل التنفيذ.                           |    2    |  D/V  |
| 10.9.3 | تحقق من أن آليات التحسين الذاتي تشمل قدرات التراجع مع التحقق من السلامة.                  |    2    |  D/V  |
| 10.9.4 | تحقق من أن الأمان في التعلم الفوقي يمنع التلاعب العدائي بخوارزميات التحسين.               |    3    |  D/V  |
| 10.9.5 | تحقق من أن التحسين الذاتي المتكرر محكوم بقيود السلامة الرسمية مع أدلة رياضية على التقارب. |    3    |  D/V  |

---

### المراجع

* [MITRE ATLAS adversary tactics for ML](https://atlas.mitre.org/)
* [NIST AI Risk Management Framework 1.0, 2023](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [OWASP Top 10 for LLM Applications, 2025](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Adversarial Training: A Survey — Zhao et al., 2024](https://arxiv.org/abs/2410.15042)
* [RobustBench adversarial-robustness benchmark](https://robustbench.github.io/)
* [Membership-Inference & Model-Inversion Risk Survey, 2025](https://www.sciencedirect.com/science/article/abs/pii/S0950705125003867)
* [PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023](https://ojs.aaai.org/index.php/AAAI/article/view/26289)
* [Model-Inversion Attacks & Defenses Survey — AI Review, 2025](https://link.springer.com/article/10.1007/s10462-025-11248-0)
* [Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024](https://doi.org/10.1109/TDSC.2023.3261327)
* [Fragile Model Watermarking Survey — 2025](https://www.sciencedirect.com/science/article/abs/pii/S0165168425002026)
* [Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025](https://arxiv.org/abs/2503.22759)
* [BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024](https://arxiv.org/abs/2405.15269)

