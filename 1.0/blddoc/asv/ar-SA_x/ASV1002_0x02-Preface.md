# المقدمة

مرحبًا بكم في معيار التحقق من أمان الذكاء الاصطناعي (AISVS) الإصدار 1.0!

## مقدمة

تأسست AISVS في عام 2025 من خلال جهد مجتمعي تعاوني، وهي تحدد متطلبات الأمان التي يجب مراعاتها عند تصميم وتطوير ونشر وتشغيل نماذج الذكاء الاصطناعي الحديثة، وسلاسل العمليات، والخدمات المدعومة بالذكاء الاصطناعي.

تمثل AISVS v1.0 العمل المشترك لقادة المشروع، ومجموعة العمل، والمساهمين من المجتمع الأوسع لإنتاج معيار عملي وقابل للاختبار لتأمين أنظمة الذكاء الاصطناعي.

هدفنا في هذا الإصدار هو جعل AISVS سهل التبني مع الحفاظ على التركيز الدقيق على نطاقه المحدد ومعالجة المشهد السريع التطور للمخاطر الفريدة المرتبطة بالذكاء الاصطناعي.

## الأهداف الرئيسية لإصدار AISVS 1.0

سيتم إنشاء الإصدار 1.0 مع عدة مبادئ توجيهية.

### نطاق محدد جيدًا

يجب أن يتماشى كل متطلب مع اسم وأهداف AISVS:

* الذكاء الاصطناعي – تعمل الضوابط على طبقة الذكاء الاصطناعي/التعلم الآلي (البيانات، النموذج، خط الأنابيب، أو الاستدلال) وتكون مسؤولية ممارسي الذكاء الاصطناعي.
* الأمن – المتطلبات تقلل مباشرة من المخاطر المحددة المتعلقة بالأمن أو الخصوصية أو السلامة.
* التحقق – اللغة مكتوبة بحيث يمكن التحقق من الامتثال بشكل موضوعي.
* المعيار – تتبع الأقسام هيكلًا ومصطلحات متسقة لتشكيل مرجع متماسك.
  ​
---

من خلال اتباع AISVS، يمكن للمنظمات تقييم وتقوية وضع الأمان لحلول الذكاء الاصطناعي الخاصة بها بشكل منهجي، مما يعزز ثقافة هندسة الذكاء الاصطناعي الآمنة.

