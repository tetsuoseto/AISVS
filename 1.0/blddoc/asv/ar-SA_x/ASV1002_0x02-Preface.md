# المقدمة

مرحبًا بكم في معيار التحقق من أمان الذكاء الاصطناعي (AISVS) الإصدار 1.0!

## مقدمة

تأسست AISVS في عام 2025 من خلال جهد تعاوني مجتمعي، وتحدد متطلبات الأمان التي يجب مراعاتها عند تصميم وتطوير ونشر وتشغيل نماذج الذكاء الاصطناعي الحديثة، وسلاسل العمل، والخدمات المعتمدة على الذكاء الاصطناعي.

يمثل الإصدار AISVS v1.0 العمل المشترك لقادة المشروع، مجموعة العمل، والمساهمين في المجتمع الأوسع من أجل إنتاج معيار عملي وقابل للاختبار لتأمين أنظمة الذكاء الاصطناعي.

هدفنا مع هذا الإصدار هو جعل AISVS سهل الاعتماد مع البقاء مركزين بدقة على نطاقه المحدد ومعالجة مشهد المخاطر سريع التطور الفريد للذكاء الاصطناعي.

## الأهداف الرئيسية لإصدار AISVS 1.0

سيتم إنشاء الإصدار 1.0 مع عدة مبادئ توجيهية.

### نطاق محدد جيدًا

يجب أن يتوافق كل متطلب مع اسم ومهمة AISVS:

* الذكاء الاصطناعي – تعمل الضوابط على طبقة الذكاء الاصطناعي / التعلم الآلي (البيانات، النموذج، خط الأنابيب، أو الاستدلال) وهي مسؤولية ممارسي الذكاء الاصطناعي.
* الأمن – المتطلبات تقلل مباشرة من المخاطر المحددة المتعلقة بالأمن أو الخصوصية أو السلامة.
* التحقق – تُكتب اللغة بحيث يمكن التحقق من التوافق بشكل موضوعي.
* المعيار – تتبع الأقسام بنية ومصطلحات متسقة لتشكيل مرجع مترابط.
  ​
---

من خلال اتباع AISVS، يمكن للمنظمات تقييم وتعزيز موقف الأمان لحلول الذكاء الاصطناعي الخاصة بها بشكل منهجي، مما يعزز ثقافة هندسة الذكاء الاصطناعي الآمنة.

