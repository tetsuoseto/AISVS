# المقدمة

مرحبًا بكم في معيار التحقق من أمان الذكاء الاصطناعي (AISVS) الإصدار 1.0!

## مقدمة

تأسست AISVS في عام 2025 من خلال جهدٍ مجتمعي تعاوني، وتحدد المتطلبات الأمنية التي يجب أخذها بعين الاعتبار عند تصميم وتطوير ونشر وتشغيل نماذج الذكاء الاصطناعي الحديثة، وخطوط أنابيب تعلم الآلة، والخدمات AI‑enabled.

AISVS v1.0 يمثل العمل المجمّع لقادة المشروع، ومجموعة العمل، ومساهمي المجتمع الأوسع لإنتاج خط أساس عملي وقابل للاختبار لضمان أمان أنظمة الذكاء الاصطناعي.

هدفنا من هذا الإصدار هو جعل AISVS سهل التبنّي مع الحفاظ على تركيز حاد على النطاق المحدد له ومعالجة مشهد المخاطر الذي يتطور بسرعة والذي يخص الذكاء الاصطناعي.

## الأهداف الرئيسية لـ AISVS الإصدار 1.0

سيتم إنشاء الإصدار 1.0 مع عدة مبادئ توجيهية.

### نطاق محدد بشكل واضح

يجب أن تتماشى كل متطلب مع اسم AISVS ومهمته:

* الذكاء الاصطناعي – تعمل الضوابط على طبقة AI/ML (البيانات، النموذج، خط الأنابيب، أو الاستدلال)، وهي مسؤولية ممارسي الذكاء الاصطناعي.
* الأمن – المتطلبات تقلل مباشرة من المخاطر المحددة المرتبطة بالأمن والخصوصية أو السلامة.
* التحقق – اللغة مكتوبة بحيث يمكن التحقق من المطابقة بشكل موضوعي.
* المعيار – تتبع الأقسام بنيةً موحّدة ومصطلحاتٍ متسقة لتشكّل مرجعًا متماسكًا.
  ​
---

باتباع AISVS، يمكن للمؤسسات تقييم الوضع الأمني لحلولها في الذكاء الاصطناعي بشكل منهجي وتعزيزه، مما يعزز ثقافة الهندسة الآمنة للذكاء الاصطناعي.

