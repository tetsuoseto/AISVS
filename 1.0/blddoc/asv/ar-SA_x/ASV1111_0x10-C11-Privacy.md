# 11 حماية الخصوصية وإدارة البيانات الشخصية

## هدف الرقابة

احرص على ضمانات الخصوصية الصارمة عبر دورة حياة الذكاء الاصطناعي الكاملة—جمع البيانات والتدريب والاستدلال والاستجابة للحوادث—بحيث تُعالج البيانات الشخصية فقط بموافقة واضحة، وبالحد الأدنى من النطاق اللازم، وبالمحو القابل لإثباته، وبضمانات خصوصية رسمية.

---

## 11.1 إخفاء الهوية وتقليل البيانات الشخصية

|   #    | الوصف                                                                                                              | المستوى | الدور |
| :----: | ------------------------------------------------------------------------------------------------------------------ | :-----: | :---: |
| 11.1.1 | تحقق من إزالة المعرفات المباشرة والمعرفات شبه القابلة للتعرّف، وتطبيق الهاش عليها.                                 |    1    |  D/V  |
| 11.1.2 | تحقق من أن التدقيقات الآلية تقيس k-anonymity و l-diversity وتنبه عندما تنخفض العتبات عن السياسة.                   |    2    |  D/V  |
| 11.1.3 | تحقق من أن تقارير أهمية الميزات في النموذج تثبت عدم وجود تسرب معرف يتجاوز ε = 0.01 من المعلومات المتبادلة.         |    2    |   V   |
| 11.1.4 | تحقق من أن البرهانات الرسمية أو شهادة البيانات الاصطناعية تُظهر أن خطر إعادة التعريف ≤ 0.05 حتى في ظل هجمات الربط. |    3    |   V   |

---

## 11.2 حق النسيان وإنفاذ الحذف

|   #    | الوصف                                                                                                                                                                                  | المستوى | الدور |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 11.2.1 | تحقق من أن طلبات حذف بيانات صاحب البيانات تنتشر إلى مجموعات البيانات الخام، ونقاط حفظ النموذج، والتضمينات، والسجلات، والنسخ الاحتياطية ضمن اتفاقيات مستوى الخدمة التي تقل عن 30 يومًا. |    1    |  D/V  |
| 11.2.2 | تحقق من أن إجراءات "إلغاء تعلم الآلة" تقوم بإعادة تدريبها فعلياً أو تقريب الإزالة باستخدام خوارزميات إلغاء تعلم معتمدة.                                                                |    2    |   D   |
| 11.2.3 | تحقق من أن تقييم النموذج الظلي يثبت أن السجلات المنسية تؤثر على أقل من 1% من المخرجات بعد إلغاء التعلم.                                                                                |    2    |   V   |
| 11.2.4 | التحقق من أن أحداث الحذف مسجلة بشكل غير قابل للتغيير وقابلة للتدقيق من قبل الجهات التنظيمية.                                                                                           |    3    |   V   |

---

## 11.3 تفاضلية-خصوصية إجراءات حماية

|   #    | الوصف                                                                                               | المستوى | الدور |
| :----: | --------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 11.3.1 | تحقق من أن لوحات معلومات محاسبة فقدان الخصوصية تُصدر تنبيهات عندما يتجاوز ε التراكمي عتبات السياسة. |    2    |  D/V  |
| 11.3.2 | تحقق من أن تقدير ε̂ من خلال التدقيقات الخصوصية بنظام صندوق أسود يقع ضمن 10% من القيمة المعلنة.      |    2    |   V   |
| 11.3.3 | تحقق من أن الإثباتات الشكلية تغطي جميع التعديلات الدقيقة بعد التدريب والتضمينات.                    |    3    |   V   |

---

## 11.4 تقييد الغرض وحماية من توسع النطاق

|   #    | الوصف                                                                                                             | المستوى | الدور |
| :----: | ----------------------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 11.4.1 | تحقق من أن كل مجموعة بيانات وكل نقطة حفظ للنموذج تحمل وسم غرض قابل للقراءة آلياً ومتوافقة مع الموافقة الأصلية.    |    1    |   D   |
| 11.4.2 | تحقق من أن مراقبات وقت التشغيل تكشف عن الاستفسارات غير المتوافقة مع الغرض المعلن وتولّد رفضاً ناعماً.             |    1    |  D/V  |
| 11.4.3 | تحقق من أن بوابات السياسة-كود تمنع إعادة نشر النماذج إلى مجالات جديدة دون مراجعة تقييم أثر حماية البيانات (DPIA). |    3    |   D   |
| 11.4.4 | تحقق من أن إثباتات التتبع الرسمية تبين أن كل دورة حياة البيانات الشخصية تظل ضمن نطاق الموافقة الممنوح.            |    3    |   V   |

---

## 11.5 إدارة الموافقات & التتبع على الأساس-القانوني

|   #    | الوصف                                                                                                        | المستوى | الدور |
| :----: | ------------------------------------------------------------------------------------------------------------ | :-----: | :---: |
| 11.5.1 | تحقق من أن منصة إدارة الموافقات (CMP) تسجل حالة الاشتراك والغرض وفترة الاحتفاظ لكل موضوع بيانات.             |    1    |  D/V  |
| 11.5.2 | تحقق من أن واجهات برمجة التطبيقات تكشف عن رموز الموافقة؛ يجب على النماذج التحقق من نطاق الرمز قبل الاستدلال. |    2    |   D   |
| 11.5.3 | تحقق من أن الموافقة المرفوضة أو المسحوبة تتوقف خطوط المعالجة خلال 24 ساعة.                                   |    2    |  D/V  |

---

## 11.6 التعلم الفيدرالي مع ضوابط الخصوصية

|   #    | الوصف                                                                                | المستوى | الدور |
| :----: | ------------------------------------------------------------------------------------ | :-----: | :---: |
| 11.6.1 | تحقق من أن تحديثات العميل تستخدم إضافة ضوضاء الخصوصية التفاضلية المحلية قبل التجميع. |    1    |   D   |
| 11.6.2 | تحقق من أن مقاييس التدريب تتمتع بخصوصية تفاضلية ولا تكشف عن خسارة تخص عميلًا واحدًا. |    2    |  D/V  |
| 11.6.3 | تحقق من أن التجميع المقاوم للتسميم (مثلاً Krum/Trimmed-Mean) مفعل.                   |    2    |   V   |
| 11.6.4 | تحقق من أن البراهين الشكلية تُبيّن أن ميزانية ε الإجمالية مع خسارة المنفعة أقل من 5. |    3    |   V   |

---

### المراجع

* [GDPR & AI Compliance Best Practices](https://www.exabeam.com/explainers/gdpr-compliance/the-intersection-of-gdpr-and-ai-and-6-compliance-best-practices/)
* [EU Parliament Study on GDPR & AI, 2020](https://www.europarl.europa.eu/RegData/etudes/STUD/2020/641530/EPRS_STU%282020%29641530_EN.pdf)
* [ISO 31700-1:2023 — Privacy by Design for Consumer Products](https://www.iso.org/standard/84977.html)
* [NIST Privacy Framework 1.1 (2025 Draft)](https://www.nist.gov/privacy-framework)
* [Machine Unlearning: Right-to-Be-Forgotten Techniques](https://www.kaggle.com/code/tamlhp/machine-unlearning-the-right-to-be-forgotten)
* [A Survey of Machine Unlearning, 2024](https://arxiv.org/html/2209.02299v6)
* [Auditing DP-SGD — ArXiv 2024](https://arxiv.org/html/2405.14106v4)
* [DP-SGD Explained — PyTorch Blog](https://medium.com/pytorch/differential-privacy-series-part-1-dp-sgd-algorithm-explained-12512c3959a3)
* [Purpose-Limitation for AI — IJLIT 2025](https://academic.oup.com/ijlit/article/doi/10.1093/ijlit/eaaf003/8121663)
* [Data-Protection Considerations for AI — URM Consulting](https://www.urmconsulting.com/blog/data-protection-considerations-for-artificial-intelligence-ai)
* [Top Consent-Management Platforms, 2025](https://www.enzuzo.com/blog/best-consent-management-platforms)
* [Secure Aggregation in DP Federated Learning — ArXiv 2024](https://arxiv.org/abs/2407.19286)

