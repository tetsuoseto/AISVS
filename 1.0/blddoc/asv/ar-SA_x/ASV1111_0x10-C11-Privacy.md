# 11 حماية الخصوصية وإدارة البيانات الشخصية

## هدف التحكم

الحفاظ على ضمانات خصوصية صارمة عبر دورة حياة الذكاء الاصطناعي بأكملها—الجمع، التدريب، الاستدلال، والاستجابة للحوادث—بحيث تتم معالجة البيانات الشخصية فقط بموافقة واضحة، ونطاق ضروري أدنى، ومحو قابل للإثبات، وضمانات خصوصية رسمية.

---

## 11.1 إخفاء الهوية وتقليل البيانات

|   #    | الوصف                                                                                                            | المستوى | الدور |
| :----: | ---------------------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 11.1.1 | تحقق من أن المعرفات المباشرة وشبه المعرفات قد أُزيلت أو حُوّلت إلى هاش.                                          |    1    |  D/V  |
| 11.1.2 | تحقق من أن عمليات التدقيق الآلية تقيس التماثل-ك والتنوع-ل وتنبه عند انخفاض القيم عن الحدود المحددة في السياسة.   |    2    |  D/V  |
| 11.1.3 | تحقق من أن تقارير أهمية ميزات النموذج تثبت عدم وجود تسرب معرف يتجاوز ε = 0.01 من المعلومات المشتركة.             |    2    |   V   |
| 11.1.4 | تحقق من أن البراهين الرسمية أو شهادات البيانات التركيبية تظهر أن خطر إعادة التعريف ≤ 0.05 حتى في ظل هجمات الربط. |    3    |   V   |

---

## 11.2 الحق في النسيان وتنفيذ الحذف

|   #    | الوصف                                                                                                                                                                    | المستوى | الدور |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :-----: | :---: |
| 11.2.1 | تحقق من أن طلبات حذف بيانات الموضوع تنتقل إلى مجموعات البيانات الخام، نقاط التحقق، التضمينات، السجلات، والنسخ الاحتياطية ضمن اتفاقيات مستوى الخدمة التي تقل عن 30 يومًا. |    1    |  D/V  |
| 11.2.2 | تحقق من أن إجراءات "نزع التعلم من الآلة" تعيد التدريب فعليًا أو تقرب الإزالة باستخدام خوارزميات نزع التعلم المعتمدة.                                                     |    2    |   D   |
| 11.2.3 | تحقق من أن تقييم نموذج الظل يثبت أن السجلات المنسية تؤثر بأقل من 1% من النتائج بعد عملية النسيان.                                                                        |    2    |   V   |
| 11.2.4 | تحقق من أن أحداث الحذف مُسجلة بشكل ثابت وغير قابلة للتغيير وقابلة للتدقيق للهيئات التنظيمية.                                                                             |    3    |   V   |

---

## 11.3 التدابير الوقائية للخصوصية التفاضلية

|   #    | الوصف                                                                                         | المستوى | الدور |
| :----: | --------------------------------------------------------------------------------------------- | :-----: | :---: |
| 11.3.1 | تحقق من أن لوحات عد خسارة الخصوصية تنبه عند تجاوز قيمة ε التراكمية للحدود المحددة في السياسة. |    2    |  D/V  |
| 11.3.2 | تحقق من أن تدقيقات الخصوصية ذات الصندوق الأسود تقدر ε̂ ضمن 10% من القيمة المعلنة.             |    2    |   V   |
| 11.3.3 | تحقق من أن البراهين الرسمية تغطي جميع عمليات التعديل الدقيق وما بعد التدريب والتضمينات.       |    3    |   V   |

---

## 11.4 تحديد الغرض - الحماية من تحديد الغرض الزائد وزحف نطاق المشروع

|   #    | الوصف                                                                                                                | المستوى | الدور |
| :----: | -------------------------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 11.4.1 | تحقق من أن كل مجموعة بيانات ونقطة فحص النموذج تحمل وسماً للغرض يمكن قراءته آليًا ومتوافقًا مع الموافقة الأصلية.      |    1    |   D   |
| 11.4.2 | تحقق من أن مراقبي وقت التشغيل يكتشفون الاستعلامات غير المتوافقة مع الغرض المعلن ويُطلقون الرفض الناعم.               |    1    |  D/V  |
| 11.4.3 | تحقق من أن بوابات السياسة ككود تمنع إعادة نشر النماذج إلى مجالات جديدة دون مراجعة تقييم تأثير حماية البيانات (DPIA). |    3    |   D   |
| 11.4.4 | تحقق من أن إثباتات التتبع الرسمية تظهر أن دورة حياة كل بيانات شخصية تبقى ضمن نطاق الموافقة المعطاة.                  |    3    |   V   |

---

## 11.5 إدارة الموافقات وتتبع الأساس القانوني

|   #    | الوصف                                                                                                     | المستوى | الدور |
| :----: | --------------------------------------------------------------------------------------------------------- | :-----: | :---: |
| 11.5.1 | تحقق من أن منصة إدارة الموافقة (CMP) تسجل حالة الموافقة، والغرض، وفترة الاحتفاظ لكل موضوع بيانات.         |    1    |  D/V  |
| 11.5.2 | تحقق من أن واجهات برمجة التطبيقات تعرض رموز الموافقة؛ يجب على النماذج التحقق من نطاق الرمز قبل الاستنتاج. |    2    |   D   |
| 11.5.3 | تأكد من أن رفض أو سحب الموافقة يوقف خطوط معالجة البيانات خلال 24 ساعة.                                    |    2    |  D/V  |

---

## 11.6 التعلم الموزع مع ضوابط الخصوصية

|   #    | الوصف                                                                                     | المستوى | الدور |
| :----: | ----------------------------------------------------------------------------------------- | :-----: | :---: |
| 11.6.1 | تحقق من أن تحديثات العميل تستخدم إضافة ضوضاء خصوصية تفريقية محلية قبل التجميع.            |    1    |   D   |
| 11.6.2 | تحقق من أن مقاييس التدريب تتسم بالخصوصية التفاضلية ولا تكشف أبداً عن خسارة عميل واحد فقط. |    2    |  D/V  |
| 11.6.3 | تحقق من تمكين التجميع المقاوم للتسمم (مثل Krum/Trimmed-Mean).                             |    2    |   V   |
| 11.6.4 | تحقق من أن البراهين الرسمية تثبت ميزانية ε الإجمالية مع فقدان فائدة أقل من 5.             |    3    |   V   |

---

### المراجع

* [GDPR & AI Compliance Best Practices](https://www.exabeam.com/explainers/gdpr-compliance/the-intersection-of-gdpr-and-ai-and-6-compliance-best-practices/)
* [EU Parliament Study on GDPR & AI, 2020](https://www.europarl.europa.eu/RegData/etudes/STUD/2020/641530/EPRS_STU%282020%29641530_EN.pdf)
* [ISO 31700-1:2023 — Privacy by Design for Consumer Products](https://www.iso.org/standard/84977.html)
* [NIST Privacy Framework 1.1 (2025 Draft)](https://www.nist.gov/privacy-framework)
* [Machine Unlearning: Right-to-Be-Forgotten Techniques](https://www.kaggle.com/code/tamlhp/machine-unlearning-the-right-to-be-forgotten)
* [A Survey of Machine Unlearning, 2024](https://arxiv.org/html/2209.02299v6)
* [Auditing DP-SGD — ArXiv 2024](https://arxiv.org/html/2405.14106v4)
* [DP-SGD Explained — PyTorch Blog](https://medium.com/pytorch/differential-privacy-series-part-1-dp-sgd-algorithm-explained-12512c3959a3)
* [Purpose-Limitation for AI — IJLIT 2025](https://academic.oup.com/ijlit/article/doi/10.1093/ijlit/eaaf003/8121663)
* [Data-Protection Considerations for AI — URM Consulting](https://www.urmconsulting.com/blog/data-protection-considerations-for-artificial-intelligence-ai)
* [Top Consent-Management Platforms, 2025](https://www.enzuzo.com/blog/best-consent-management-platforms)
* [Secure Aggregation in DP Federated Learning — ArXiv 2024](https://arxiv.org/abs/2407.19286)

