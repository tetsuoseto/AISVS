# الصفحة التقديمية

## عن المعيار

معيار التحقق من أمان الذكاء الاصطناعي (AISVS) هو دليل مجتمعي متكامل لمتطلبات الأمان يمكن لعلماء البيانات، ومهندسي عمليات تعلم الآلة (MLOps)، ومهندسي البرمجيات، والمطورين، والمختبرين، والمتخصصين في الأمان، وبائعي الأدوات، والمنظمين، والمستهلكين استخدامه لتصميم وبناء واختبار والتحقق من أنظمة وتطبيقات الذكاء الاصطناعي الموثوقة. ويوفر لغة مشتركة لتحديد ضوابط الأمان عبر دورة حياة الذكاء الاصطناعي — من جمع البيانات وتطوير النماذج إلى النشر والمراقبة المستمرة — حتى تتمكن المؤسسات من قياس وتحسين مقاومة وخصوصية وسلامة حلول الذكاء الاصطناعي الخاصة بها.

## حقوق النشر والترخيص

الإصدار 0.1 (المسودة العامة الأولى - قيد العمل)، 2025  

![license](../images/license.png)

حقوق النشر © 2025 مشروع AISVS.  

تم الإصدار بموجب [Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
لأي إعادة استخدام أو توزيع، يجب عليك توضيح شروط الترخيص لهذا العمل بوضوح للآخرين.

## قادة المشروع

|            |                        |
| ---------- | ---------------------- |
| جيم مانيكو | أراس "رس" ميميسيازيتشي |

## المساهمون والمراجعون

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS هو معيار جديد تمامًا تم إنشاؤه خصيصًا لمعالجة تحديات الأمان الفريدة لأنظمة الذكاء الاصطناعي. وبينما يستوحي بعض المبادئ من أفضل ممارسات الأمان العامة، فقد تم تطوير كل متطلب في AISVS من الأساس ليعكس مشهد التهديدات المتعلقة بالذكاء الاصطناعي ولمساعدة المؤسسات في بناء حلول ذكاء اصطناعي أكثر أمانًا ومرونة.

