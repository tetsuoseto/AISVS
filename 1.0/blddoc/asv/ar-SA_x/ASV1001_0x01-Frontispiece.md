# الصفحة التمهيدية

## حول المعيار

معيار التحقق من أمان الذكاء الاصطناعي (AISVS) هو كتالوج يديره المجتمع يحتوي على متطلبات الأمان التي يمكن لعلماء البيانات، مهندسي عمليات تعلم الآلة (MLOps)، مهندسي البرمجيات، المطورين، المختبرين، محترفي الأمن، بائعي الأدوات، الجهات التنظيمية، والمستهلكين استخدامها لتصميم، بناء، اختبار، والتحقق من الأنظمة والتطبيقات المعتمدة على الذكاء الاصطناعي الموثوق بها. يوفر هذا المعيار لغة مشتركة لتحديد ضوابط الأمان عبر دورة حياة الذكاء الاصطناعي — بدءًا من جمع البيانات وتطوير النماذج إلى النشر والمراقبة المستمرة — بحيث يمكن للمنظمات قياس وتحسين مرونة الخصوصية وسلامة حلول الذكاء الاصطناعي الخاصة بها.

## حقوق النشر والترخيص

الإصدار 0.1 (المسودة العامة الأولى - قيد العمل)، 2025  

![license](../images/license.png)

حقوق النشر © 2025 مشروع AISVS.  

صدر بموجب ال[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
لأي إعادة استخدام أو توزيع، يجب عليك توصيل شروط الترخيص لهذه العمل بوضوح للآخرين.

## قادة المشروع

|            |                         |
| ---------- | ----------------------- |
| جيم مانيكو | أراس "روس" ميميسيازيتشي |

## المساهمون والمراجعون

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS هو معيار جديد كليًا تم إنشاؤه خصيصًا لمعالجة تحديات الأمن الفريدة لأنظمة الذكاء الاصطناعي. وبينما يستلهم هذا المعيار من أفضل ممارسات الأمن الأوسع نطاقًا، فقد تم تطوير كل متطلب في AISVS من الأساس ليعكس مشهد التهديدات في مجال الذكاء الاصطناعي ولمساعدة المؤسسات على بناء حلول ذكاء اصطناعي أكثر أمانًا ومرونة.

