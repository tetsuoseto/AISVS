# لوحة أمامية

## حول المعيار

معيار أمان التحقق من الذكاء الاصطناعي (AISVS) هو فهرس مدفوع بالمجتمع لمتطلبات الأمان يمكن لعلماء البيانات، ومهندسي MLOps، ومعماريي البرمجيات، والمطورين، والمختبرين، والمتخصصين في الأمن، وبائعي الأدوات، والجهات التنظيمية، والمستهلكين استخدامه لتصميم وبناء واختبار والتحقق من أنظمة وتطبيقات مدعومة بالذكاء الاصطناعي موثوقة. إنه يوفر لغة مشتركة لتحديد ضوابط الأمان عبر دورة حياة الذكاء الاصطناعي—from data collection and model development to deployment and ongoing monitoring—حتى تتمكن المؤسسات من قياس وتحسين المتانة والخصوصية والسلامة لحلولها في مجال الذكاء الاصطناعي.

## حقوق النشر والترخيص

الإصدار 0.1 (المسودة العامة الأولى - قيد التطوير)، 2025  

![license](../images/license.png)

حقوق النشر © 2025 مشروع AISVS  

صدر بموجب[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
لأي إعادة استخدام أو توزيع، يجب عليك توضيح شروط الترخيص الخاصة بهذا العمل للآخرين بوضوح.

## قادة المشروع

|            |                         |
| ---------- | ----------------------- |
| جيم مانيكو | Aras “Russ” Memisyazici |

## المساهمون والمراجعون

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS هو معيار جديد كلياً صُمم خصيصاً لمعالجة التحديات الأمنية الفريدة لأنظمة الذكاء الاصطناعي. بينما يستلهم من أفضل ممارسات الأمن على نطاق أوسع، فقد تم تطوير كل متطلب في AISVS من الأساس ليعكس مشهد التهديدات المرتبطة بالذكاء الاصطناعي ولمساعدة المؤسسات في بناء حلول ذكاء اصطناعي أكثر أماناً ومرونة.

