# الصفحة التمهيدية

## حول المعيار

معيار التحقق من أمان الذكاء الاصطناعي (AISVS) هو كتالوج يقوده المجتمع يحتوي على متطلبات الأمان التي يمكن لعلماء البيانات، ومهندسي MLOps، والمهندسين المعماريين للبرمجيات، والمطورين، والمختبرين، وخبراء الأمان، وبائعي الأدوات، والمنظمين، والمستهلكين استخدامها لتصميم وبناء واختبار والتحقق من أنظمة وتطبيقات الذكاء الاصطناعي الموثوقة. يوفر معيار AISVS لغة مشتركة لتحديد ضوابط الأمان عبر دورة حياة الذكاء الاصطناعي—من جمع البيانات وتطوير النماذج إلى النشر والمراقبة المستمرة—حتى تتمكن المؤسسات من قياس وتحسين مرونة وخصوصية وسلامة حلول الذكاء الاصطناعي لديها.

## حقوق النشر والترخيص

الإصدار 0.1 (المسودة العامة الأولى - العمل جار)، 2025  

![license](../images/license.png)

حقوق الطبع والنشر © 2025 مشروع AISVS.  

تم إصداره تحت[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
لأي إعادة استخدام أو توزيع، يجب عليك توضيح شروط الترخيص لهذا العمل للآخرين بوضوح.

## قادة المشروع

|            |                         |
| ---------- | ----------------------- |
| جيم مانيكو | أراس "روس" ميميسيازيتشي |

## المساهمون والمراجعون

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS هو معيار جديد تمامًا تم إنشاؤه خصيصًا لمعالجة التحديات الأمنية الفريدة لأنظمة الذكاء الاصطناعي. وبينما يستلهم منه الممارسات الأمنية العامة الأفضل، تم تطوير كل متطلب في AISVS من الصفر ليعكس مشهد التهديدات في الذكاء الاصطناعي ولمساعدة المؤسسات على بناء حلول ذكاء اصطناعي أكثر أمانًا ومرونة.

