## 扉絵

### 標準について

人工知能セキュリティ検証標準（AISVS）は、データサイエンティスト、MLOpsエンジニア、ソフトウェアアーキテクト、開発者、テスター、セキュリティ専門家、ツールベンダー、規制当局、そして消費者が、信頼できるAI搭載システムとアプリケーションを設計・構築・テスト・検証するために利用できる、コミュニティ主導のセキュリティ要件カタログです。AIのライフサイクル全体にわたるセキュリティコントロールを指定する共通言語を提供し、データ収集とモデル開発から展開、継続的な監視に至るまで、組織がAIソリューションのレジリエンス、プライバシー、および安全性を測定・改善できるようにします。

### 著作権とライセンス

バージョン 0.1（初公開ドラフト - 作業中）、 2025  

![license](images/license.png)
著作権 © 2025 AISVSプロジェクト.  

以下のライセンスのもとで公開されています  Creative Commons Attribution‑ShareAlike 4.0 International License.
いかなる再利用または配布の場合にも、本作品のライセンス条件を他者に明確に伝える必要があります。

### プロジェクトリーダー

ジム マニコ
アラス 「ラス」 メミスヤジチ

### 貢献者とレビュアー

https://github.com/ottosulin
https://github.com/mbhatt1
https://github.com/vineethsai
https://github.com/cciprofm
https://github.com/deepakrpandey12


---

AISVS は brand‑new の標準として、特に人工知能システムが直面する固有のセキュリティ課題に対処するために作成されました。広範なセキュリティのベストプラクティスから着想を得ている一方で、AISVS の全要件は AI 脅威の状況を反映させるためにゼロから開発されており、組織がより安全で、よりレジリエントな AI ソリューションを構築するのを支援します。

## 序文

人工知能セキュリティ検証標準（AISVS）バージョン 1.0へようこそ！

### はじめに

協働コミュニティの取り組みを通じて2025年に設立された AISVS は、最新の AI モデル、パイプライン、および AI‑対応サービスを設計・開発・展開・運用する際に検討すべきセキュリティ要件を定義します。

AISVS v1.0 は、プロジェクトリード、ワーキンググループ、およびより広いコミュニティの貢献者の共同作業を結集した成果を表しており、AIシステムの安全性を確保するための実用的で検証可能なベースラインを作成することを目的としています。

このリリースの目的は、AISVSの導入を容易にする一方で、定義された範囲に厳密に焦点を合わせ、AI特有の急速に変化するリスク環境に対処することです。

### AISVS バージョン 1.0 の主要な目的

バージョン 1.0 は、いくつかの指針となる原則とともに作成されます。

#### 明確に定義されたスコープ

各要件は AISVS の名称と使命に沿う必要があります：

人工知能 – コントロールは AI/ML レイヤー（データ、モデル、パイプライン、推論）で機能し、AI実践者の責任です。
セキュリティ – 要求事項は、特定されたセキュリティ、プライバシー、または安全性のリスクを直接軽減します。
検証 – 準拠性が客観的に検証できるように、言語は記述されています。
標準 – セクションは一貫した構造と用語に従い、整合性のある参照を形成します。
​
---

AISVSに従うことで、組織はAIソリューションのセキュリティ体制を体系的に評価・強化し、セキュアなAIエンジニアリングの文化を醸成します。

## AISVS の使用

人工知能セキュリティ検証標準（AISVS）は、現代のAIアプリケーションとサービスに対するセキュリティ要件を定義し、アプリケーション開発者が管理できる範囲の側面に焦点を当てます。

AISVSは、AIアプリケーションのセキュリティを開発または評価するすべての人を対象としています。これには、開発者、アーキテクト、セキュリティエンジニア、監査人が含まれます。本章では、AISVSの構造と活用方法を、検証レベルおよび想定されるユースケースを含めて紹介します。

### 人工知能のセキュリティ検証レベル

AISVSは、セキュリティ検証の3つの段階を定義します。各段階は深さと複雑さを加え、組織がAIシステムのリスクレベルに応じてセキュリティ体制を調整できるようにします。

組織は Level 1 から開始し、セキュリティ成熟度と脅威の露出が高まるにつれて、より高いレベルを段階的に採用することができます。

#### レベルの定義

AISVS v1.0 の各要件は、以下のいずれかのレベルに割り当てられます：

 レベル 1 要件

レベル 1 には、最も重要で基盤となるセキュリティ要件が含まれます。これらは、他の前提条件や脆弱性に依存せず、一般的な攻撃を防ぐことに焦点を当てています。レベル 1 のコントロールの多くは、実装が容易であるか、投入する労力を正当化するほど不可欠です。

 レベル 2 の要件

レベル2は、より高度なまたは珍しい攻撃、さらには広範な脅威に対する階層的防御に対応します。これらの要件は、より複雑なロジックを含む場合や、特定の攻撃の前提条件を標的とする場合があります。

 レベル 3 要件

レベル3には、実装が通常より難しい、あるいは適用性が状況依存であるコントロールが含まれます。これらは多くの場合、防御の多層化を実現するメカニズムや、ニッチな、標的型の、または高度に複雑な攻撃に対する緩和策を表します。

#### 役割 (D/V)

各 AISVS 要件は、主要な対象者に従って区分されています：

D – 開発者向けの要件
V – 検証者/監査人向けの要件
D/V – 開発者と検証者の双方に関連する

## C1 訓練データ ガバナンス & バイアス管理

### 統制目標

トレーニングデータは、出所の追跡性を保ちつつ、適切に取得・取り扱い・維持され、セキュリティ、品質、そして公正性を確保した状態で管理されなければなりません。これを実践することで法的義務を果たし、トレーニング中に生じるバイアス、データポイズニング、プライバシー侵害のリスクを低減し、それがAIライフサイクル全体に影響を及ぼす可能性を抑えることにつながります。

---

### C1.1 トレーニングデータの出所

すべてのデータセットの検証可能な在庫を維持し、信頼できるソースのみを受け入れ、監査可能性のためにすべての変更を記録する。

 #1.1.1    レベル: 1    役割: D/V
 すべての学習データソースに関する出所、管理者/所有者、ライセンス、収集方法、利用目的の制約、および処理履歴を含む最新のインベントリが維持されていることを確認する。
 #1.1.2    レベル: 1    役割: D/V
 訓練データの処理が不要な特徴量、属性、またはフィールドを除外していることを検証する（例：未使用のメタデータ、機微な個人識別情報（PII）、漏洩したテストデータ）。
 #1.1.3    レベル: 2    役割: D/V
 すべてのデータセットの変更が、ログに記録された承認ワークフローの対象となることを検証してください。
 #1.1.4    レベル: 3    役割: D/V
 可能な場合には、データセットまたはそのサブセットに水印が付与されていること、または指紋付けがされていることを確認する。

---

### C1.2 トレーニングデータのセキュリティと完全性

トレーニングデータへのアクセスを制限し、保管時および転送時に暗号化し、その完全性を検証して改ざん、盗難、またはデータポイズニングを防ぐ。

 #1.2.1    レベル: 1    役割: D/V
 アクセス制御がトレーニングデータの保存とパイプラインを保護していることを検証してください。
 #1.2.2    レベル: 2    役割: D/V
 トレーニングデータへのすべてのアクセスが記録されていることを検証し、記録にはユーザー、時刻、アクションを含める。
 #1.2.3    レベル: 2    役割: D/V
 トレーニングデータセットが転送中および保存時に、業界標準の暗号化アルゴリズムと鍵管理の手法を用いて暗号化されていることを検証する。
 #1.2.4    レベル: 2    役割: D/V
 訓練データの保存および転送中にデータの完全性を確保するために、暗号学的ハッシュ値または電子署名が使用されていることを確認してください。
 #1.2.5    レベル: 2    役割: D/V
 自動検出技術が訓練データの不正な変更または汚染を防ぐために適用されていることを確認する。
 #1.2.6    レベル: 2    役割: D/V
 不要になった訓練データが安全に削除または匿名化されていることを検証する。
 #1.2.7    レベル: 3    役割: D/V
 すべてのトレーニングデータセットのバージョンが一意に識別され、不変に保存され、監査可能であることを確認し、ロールバックおよびフォレンジック分析をサポートします。

---

### C1.3 訓練データのラベリング品質、完全性、およびセキュリティ

ラベルを保護し、重要データには技術的審査を要求する。

 #1.3.1    レベル: 2    役割: D/V
 ラベルアーティファクトに対して、暗号ハッシュまたはデジタル署名が適用されていることを検証し、それらの整合性と真正性を保証します。
 #1.3.2    レベル: 2    役割: D/V
 ラベリング用のインターフェースとプラットフォームが強力なアクセス制御を実施し、すべてのラベリング活動の改ざん検知可能な監査ログを維持し、不正な変更を防止することを検証してください。
 #1.3.3    レベル: 3    役割: D/V
 ラベルに含まれる機微情報が、データフィールドレベルで静止時および転送時に伏字化、匿名化、または暗号化されていることを検証する。

---

### C1.4 トレーニングデータの品質とセキュリティ保証

データセットの信頼性を保証するために、自動検証、手動のスポットチェック、および記録済みの是正措置を組み合わせる。

 #1.4.1    レベル: 1    役割: D
 すべての取り込み処理または重要なデータ変換において、自動化されたテストがフォーマットエラーおよび NULL 値を検出することを検証する。
 #1.4.2    レベル: 2    役割: D/V
 LLMのトレーニングおよびファインチューニングパイプラインが、毒化検知 & データ整合性検証（例：統計的方法、外れ値検出、埋め込み分析）を実装し、潜在的な毒化攻撃（例：ラベル反転、バックドアトリガーの挿入、役割切替コマンド、影響力のあるインスタンス攻撃）またはトレーニングデータの意図しないデータ破損を特定することを検証する。
 #1.4.3    レベル: 3    役割: D/V
 リスク評価に基づき、敵対的訓練（生成された敵対的サンプルを使用）、摂動入力によるデータ拡張、またはロバスト最適化手法といった適切な防御策が、関連するモデルに対して実装・調整されていることを検証する。
 #1.4.4    レベル: 2    役割: D/V
 自動的に生成されたラベルが、幻覚を起こしたもの、誤解を招くもの、または低信頼度のラベルを検出するために、信頼度閾値と一貫性検証の対象となることを確認する。
 #1.4.5    レベル: 3    役割: D
 自動テストが、データの取り込みのたび、または重要なデータ変換時におけるラベルの偏りを検出することを検証してください。

---

### C1.5 データ系譜とトレーサビリティ

各データポイントがソースからモデル入力に至るまでの全経路を追跡し、監査可能性とインシデント対応のために使用します。

 #1.5.1    レベル: 2    役割: D/V
 各データポイントの系譜情報が、すべての変換、データ拡張、および結合を含めて記録され、再構築できることを確認する。
 #1.5.2    レベル: 2    役割: D/V
 系譜レコードが不可変であり、安全に保管され、監査のためにアクセス可能であることを検証する。
 #1.5.3    レベル: 2    役割: D/V
 プライバシー保護技術または生成的手法によって生成された合成データを対象に、系統追跡が適用されていることを検証し、パイプライン全体を通じてすべての合成データが明確にラベル付けされ、実データと区別できることを確認する。

---

### 参考文献

NIST AI Risk Management Framework
EU AI Act – Article 10: Data & Data Governance
MITRE ATLAS: Adversary Tactics for AI
Survey of ML Bias Mitigation Techniques – MDPI
Data Provenance & Lineage Best Practices – Nightfall AI
Data Labeling Quality Standards – LabelYourData
Training Data Poisoning Guide – Lakera.ai
CISA Advisory: Securing Data for AI Systems
ISO/IEC 23053: AI Management Systems Framework
IBM: What is AI Governance?
Google AI Principles
GDPR & AI Training Data – DataProtectionReport
Supply-Chain Security for AI Data – AppSOC
OpenAI Privacy Center – Data Deletion Controls
Adversarial ML Dataset – Kaggle

## C2 ユーザー入力の検証

### 統制目標

ユーザー入力の堅牢な検証は、AIシステムに対する最も深刻な攻撃のいくつかに対する第一の防御線となる。プロンプトインジェクション攻撃は、システム指示を上書きしたり、機密データを漏洩させたり、モデルを許可されていない挙動へと誘導したりする可能性がある。専用のフィルターや指示階層が整備されていない限り、長大なコンテキストウィンドウを悪用する「マルチショット」ジャイルブレイク攻撃は有効になることが研究で示されている。さらに、同形文字の置換や leetspeak（leet表記）といった微妙な敵対的摂動攻撃は、モデルの判断を黙って変えることがある。

---

### C2.1 プロンプトインジェクション対策

プロンプトインジェクションは、AIシステムにおける主要なリスクの一つです。 この手法に対する防御は、静的パターンフィルタ、動的分類器、および指示階層の遵守の組み合わせを用いて実施されます。

 #2.1.1    レベル: 1    役割: D/V
 ユーザー入力が、継続的に更新される既知のプロンプト注入パターンのライブラリに対して検査・スクリーニングされていることを検証する（ジャイルブレイクキーワード、"ignore previous"、ロールプレイチェーン、間接的なHTML/URL攻撃）。
 #2.1.2    レベル: 1    役割: D/V
 システムが、システムメッセージまたは開発者メッセージがユーザーの指示を上書きする指示階層を厳格に適用し、コンテキストウィンドウの拡張後もそれが維持されることを検証する。
 #2.1.3    レベル: 2    役割: D/V
 すべてのモデルまたはプロンプトテンプレートのリリース前に、敵対的評価テスト（例：レッドチームによる「many-shot」プロンプト）を実行し、成功率の閾値および回帰を自動的にブロックする仕組みを備えていることを確認する。
 #2.1.4    レベル: 2    役割: D
 第三者コンテンツ（ウェブページ、PDF、メール）由来のプロンプトが、メインのプロンプトへ結合される前に、分離された解析コンテキストでサニタイズされていることを検証します。
 #2.1.5    レベル: 3    役割: D/V
 すべてのプロンプトフィルター規則の更新、分類器モデルのバージョン、およびブロックリストの変更がバージョン管理され、監査可能であることを検証する。

---

### C2.2 敵対的-サンプル耐性

自然言語処理（NLP）モデルは、まだ人間には気づかれにくい微妙な文字レベルおよび単語レベルの摂動に対して脆弱であり、そうした摂動が原因でモデルは誤分類しがちです。

 #2.2.1    レベル: 1    役割: D
 基本的な入力正規化手順（Unicode NFC 形式、同形字マッピング、空白のトリミング）がトークン化の前に実行されることを検証する。
 #2.2.2    レベル: 2    役割: D/V
 統計的異常検知が、言語ノームに対して編集距離が異常に大きい入力、過度に繰り返されるトークン、または埋め込み距離が異常な入力をフラグ付けすることを検証する。
 #2.2.3    レベル: 2    役割: D
 推論パイプラインが、高リスクのエンドポイントに対して、任意の敵対的訓練で堅牢化されたモデルバリアントや防御層（例：ランダム化、防御蒸留）をサポートすることを検証してください。
 #2.2.4    レベル: 2    役割: V
 疑われる敵対的入力が隔離され、PII の伏字化後の完全なペイロードを含むログに記録されていることを検証する。
 #2.2.5    レベル: 3    役割: D/V
 頑健性指標（既知の攻撃スイートの成功率）が時間の経過とともに追跡され、回帰がリリースブロッカーを引き起こすことを検証する。

---

### C2.3 スキーマ、型と長さの検証

不正な形式または過大な入力を特徴とするAI攻撃は、解析エラーを引き起こし、フィールド間でプロンプト情報が漏洩し、リソースの枯渇を招くことがあります。  決定論的なツール呼び出しを行う際には、厳格なスキーマ適用も前提条件となります。

 #2.3.1    レベル: 1    役割: D
 すべての API または関数呼び出しエンドポイントが、明示的な入力スキーマ（JSON Schema、Protobuf、またはマルチモーダル相当のもの）を定義し、入力がプロンプトの組み立て前に検証されていることを確認してください。
 #2.3.2    レベル: 1    役割: D/V
 最大トークン数またはバイト数を超える入力は、黙って切り捨てられることなく、安全なエラーで拒否されることを検証してください。
 #2.3.3    レベル: 2    役割: D/V
 サーバーサイドで型チェック（例：数値範囲、列挙値、画像/音声の MIME タイプ）が適用されていることを、クライアント側のコードだけでなく検証してください。
 #2.3.4    レベル: 2    役割: D
 セマンティック検証器（例：JSON Schema）が定数時間で実行されることを検証し、アルゴリズム的DoSを防ぎます。
 #2.3.5    レベル: 3    役割: V
 検証失敗が、機密情報を伏せたペイロードの断片と明確なエラーコードとともにログに記録され、セキュリティ対応のトリアージを支援することを確認する。

---

### C2.4 コンテンツとポリシーの審査

開発者は、構文的に有効だが禁止された内容を要求するプロンプトを検出し（例：違法な指示、ヘイトスピーチ、著作権で保護されたテキストなど）、それらが拡散するのを防ぐことができるべきです。

 #2.4.1    レベル: 1    役割: D
 コンテンツ分類器（ゼロショットまたはファインチューニング済み）が、暴力、自傷行為、ヘイト表現、性的内容、違法リクエストの各カテゴリについて、設定可能な閾値を用いてすべての入力をスコア付けすることを検証してください。
 #2.4.2    レベル: 1    役割: D/V
 ポリシーに違反する入力が標準化された拒否または安全な応答を受け取ることを確認し、それらが下流の LLM 呼び出しへ伝播しないようにする。
 #2.4.3    レベル: 2    役割: D
 スクリーニングモデルまたはルールセットが少なくとも3か月ごとに再訓練/更新され、新たに観測されたジェイルブレイクまたはポリシー回避パターンを取り入れていることを検証する。
 #2.4.4    レベル: 2    役割: D
 リクエスト時に解決される属性ベースのルールを用いて、年齢や地域の法的制約など、ユーザー固有のポリシーが遵守されていることを検証する。
 #2.4.5    レベル: 3    役割: V
 SOC 相関と将来のレッドチーム再現のために、スクリーニングログに分類器の信頼度スコアとポリシーカテゴリタグを含めることを確認してください。

---

### C2.5 入力レート制限と不正利用防止

開発者は、AIシステムに対する悪用、資源の枯渇、および自動化攻撃を防ぐために、入力レートを制限し、異常な使用パターンを検出すべきである。

 #2.5.1    レベル: 1    役割: D/V
 すべての入力エンドポイントにおいて、ユーザーごと、IPごと、APIキーごとに設定されたレート制限が適用されていることを確認してください。
 #2.5.2    レベル: 2    役割: D/V
 バーストと持続的なレート制限がDoS攻撃および総当たり攻撃を防ぐように適切に調整されていることを検証する。
 #2.5.3    レベル: 2    役割: D/V
 異常な利用パターン（例：連続リクエスト、入力過多）が自動ブロックまたはエスカレーションを引き起こすことを検証する。
 #2.5.4    レベル: 3    役割: V
 乱用防止ログが保持され、出現する攻撃パターンを監視・検討していることを確認してください。

---

### C2.6 マルチ-モーダル入力検証

AIシステムは、画像・音声・ファイルなどの非テキスト入力に対して堅牢な検証を実施し、インジェクション攻撃、回避行為、リソースの乱用を防ぐべきです。

 #2.6.1    レベル: 1    役割: D
 処理を開始する前に、すべての非テキスト入力（画像、音声、ファイル）のタイプ、サイズ、およびフォーマットが検証されていることを確認してください。
 #2.6.2    レベル: 2    役割: D/V
 取り込み前に、ファイルがマルウェアおよびステガノグラフィー・ペイロードのスキャンを受けていることを検証する。
 #2.6.3    レベル: 2    役割: D/V
 画像入力および音声入力が、敵対的摂動や既知の攻撃パターンに対して検査されていることを確認してください。
 #2.6.4    レベル: 3    役割: V
 マルチモーダル入力検証の失敗がログに記録され、調査のためのアラートをトリガーすることを検証します。

---

### C2.7 入力の来歴と帰属

AIシステムは、すべてのユーザー入力の出所を監視し、タグ付けすることによって、監査、乱用追跡、およびコンプライアンスを支援すべきである。

 #2.7.1    レベル: 1    役割: D/V
 取り込み時に、すべてのユーザー入力がメタデータ（ユーザーID、セッション、ソース、タイムスタンプ、IPアドレス）でタグ付けされていることを検証してください。
 #2.7.2    レベル: 2    役割: D/V
 すべての処理済み入力について、出所メタデータが保持され、監査可能であることを検証する。
 #2.7.3    レベル: 2    役割: D/V
 異常または信頼できない入力ソースを検出してフラグを立て、強化された審査またはブロックの対象とすることを検証します。

---

### C2.8 リアルタイム適応型脅威検知

開発者は、AI用の高度な脅威検知システムを採用すべきであり、それは新たな攻撃パターンに適応し、コンパイル済みパターンマッチングによるリアルタイムの保護を提供します。

 #2.8.1    レベル: 1    役割: D/V
 脅威検知パターンが、遅延の影響を最小限に抑えた高性能なリアルタイムフィルタリングを実現するために、最適化された正規表現エンジンにコンパイルされていることを検証する。
 #2.8.2    レベル: 1    役割: D/V
 脅威検知システムが、異なる脅威カテゴリごとに別々のパターンライブラリを維持していることを検証する（プロンプトインジェクション、有害なコンテンツ、機微データ、システムコマンド）。
 #2.8.3    レベル: 2    役割: D/V
 適応型脅威検知が、攻撃頻度と成功率に基づいて脅威感度を更新する機械学習モデルを組み込んでいることを検証する。
 #2.8.4    レベル: 2    役割: D/V
 リアルタイムの脅威情報フィードが、新しい攻撃署名とIOCs（Indicators of Compromise）をパターンライブラリに自動的に更新することを検証してください。
 #2.8.5    レベル: 3    役割: D/V
 脅威検出の偽陽性率が継続的に監視され、パターンの特異性が自動的に調整され、正当なユースケースへの干渉を最小化することを確認してください。
 #2.8.6    レベル: 3    役割: D/V
 文脈に基づく脅威分析が、入力元、ユーザーの行動パターン、およびセッション履歴を考慮して検知精度を向上させることを検証してください。
 #2.8.7    レベル: 3    役割: D/V
 脅威検知の性能指標（検出率、処理遅延、リソース利用率）がリアルタイムで監視・最適化されていることを確認してください。

---

### C2.9 マルチ-モーダル セキュリティ検証パイプライン

開発者は、テキスト、画像、音声、およびその他のAI入力モダリティに対して、特定の種類の脅威検知とリソース分離を備えたセキュリティ検証を提供すべきです。

 #2.9.1    レベル: 1    役割: D/V
 各入力モダリティが、文書化された脅威パターンを持つ専用のセキュリティ検証ツールを備え、検出閾値が設定されていることを確認してください（テキスト：プロンプト注入、画像：ステガノグラフィー、音声：スペクトログラム攻撃）。
 #2.9.2    レベル: 2    役割: D/V
 マルチモーダル入力が、各モダリティタイプに固有の定義済みリソース制限（メモリ、CPU、処理時間）を持つ分離されたサンドボックスで処理され、セキュリティポリシーに記載されていることを検証する。
 #2.9.3    レベル: 2    役割: D/V
 クロスモーダル攻撃検出が、複数の入力タイプにまたがる協調攻撃を、相関ルールとアラート生成を用いて識別することを検証する（例：画像内のステガノグラフィーによるペイロードと、テキストのプロンプト挿入を組み合わせたもの）。
 #2.9.4    レベル: 3    役割: D/V
 マルチモーダル検証の失敗が、すべての入力モダリティ、検証結果、脅威スコア、相関分析を含む詳細なログをトリガーし、SIEM統合のための構造化ログ形式で記録されることを検証する。
 #2.9.5    レベル: 3    役割: D/V
 モダリティ別 コンテンツ分類器 が、 文書化 された スケジュール（ 最低でも 四半期ごと） に 従って 更新 され、 新しい 脅威 パターン、 敵対的 サンプル、 および 性能 ベンチマーク が ベースライン 閾値 を 上回る 状態 で 維持 されて いる こと を 検証 する。

---

### 参考文献

LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security
Generative AI's Biggest Security Flaw Is Not Easy to Fix
Many-shot jailbreaking \ Anthropic
$PDF$ OpenAI GPT-4.5 System Card
Notebook for the CheckThat Lab at CLEF 2024
Mitigate jailbreaks and prompt injections – Anthropic
Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis
OWASP Top 10 for LLM Applications 2025 – WorldTech IT
OWASP Machine Learning Security Top Ten
Few words about AI Security – Jussi Metso
How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry
Easily enforcing valid JSON schema following – API
AI Safety + Cybersecurity R\&D Tracker – Fairly AI
Anthropic makes 'jailbreak' advance to stop AI models producing harmful results
Pattern matching filter rules - IBM
Real-time Threat Detection

## C3 モデルライフサイクル管理と変更管理

### 統制目標

AIシステムは、本番環境へ到達する不正または不安全なモデル変更を防ぐ変更管理プロセスを実装しなければならない--この統制は、開発から展開、廃止までのライフサイクル全体を通じてモデルの完全性を保証し、迅速なインシデント対応を可能にし、すべての変更に対する説明責任を維持する。

コアセキュリティ目標: 本番環境へデプロイされるのは、承認済み・検証済みのモデルのみとし、それを実現するのは、完全性・追跡性・回復性を維持する制御されたプロセスを用いることである。

---

### C3.1 モデルの認可と完全性

検証済みの完全性を備えた認可済みモデルのみが本番環境に到達する。

 #3.1.1    レベル: 1    役割: D/V
 デプロイ前に、すべてのモデルアーティファクト（重み、設定、トークナイザ）が認可されたエンティティによって暗号署名されていることを検証してください。
 #3.1.2    レベル: 1    役割: D/V
 デプロイ時にモデルの完全性が検証されることを確認し、署名検証の失敗がモデルの読み込みを妨げることを保証する。
 #3.1.3    レベル: 2    役割: D/V
 モデル由来情報の記録が、承認主体の身元、学習データのハッシュ値、検証テスト結果（合否ステータス付き）、および作成タイムスタンプを含むことを確認する。
 #3.1.4    レベル: 2    役割: D/V
 すべてのモデルアーティファクトがセマンティック・バージョニング（MAJOR.MINOR.PATCH）を使用していることを、各バージョン成分がいつ増分されるかを規定した文書化された基準とともに検証します。
 #3.1.5    レベル: 2    役割: V
 依存関係の追跡が、すべての消費システムを迅速に特定できるリアルタイム在庫情報を維持していることを検証する。

---

### C3.2 モデル検証 & テスト

モデルは、デプロイ前に定義されたセキュリティおよび安全性の検証を必ず通過する必要があります。

 #3.2.1    レベル: 1    役割: D/V
 デプロイ前に、モデルが入力検証、出力のサニタイズ、及び安全性評価を含む自動化されたセキュリティテストを受け、事前に合意された組織の合格/不合格閾値を満たすことを確認する。
 #3.2.2    レベル: 1    役割: D/V
 検証の失敗が、事前に指定された承認権を有する担当者による明示的なオーバーライド承認の後、文書化されたビジネス上の正当化を伴って自動的にモデルのデプロイをブロックすることを確認する。
 #3.2.3    レベル: 2    役割: V
 テスト結果が暗号署名され、検証対象の特定モデルバージョンのハッシュに不変に結びついていることを確認する。
 #3.2.4    レベル: 2    役割: D/V
 緊急展開には、文書化されたセキュリティリスク評価と、事前に指定されたセキュリティ当局からの承認が、事前に合意された時間枠内で求められることを検証する。

---

### C3.3 制御されたデプロイメントとロールバック

モデルのデプロイは、制御され、監視され、元に戻せる必要がある。

 #3.3.1    レベル: 1    役割: D
 本番環境へのデプロイが段階的なロールアウト機構（カナリアリリース、ブルーグリーンデプロイメント）を実装し、事前に合意されたエラー率、レイテンシ閾値、またはセキュリティアラート基準に基づいて自動ロールバックをトリガーする条件を満たしていることを検証する。
 #3.3.2    レベル: 1    役割: D/V
 ロールバック機能が、モデルの完全な状態（重み、設定、依存関係）を原子性を保って復元し、事前に定義された組織の時間枠内で実行されることを検証する。
 #3.3.3    レベル: 2    役割: D/V
 デプロイメントプロセスがデジタル署名を検証し、モデルを起動する前に整合性チェックサムを計算することを確認し、いずれかの不一致がある場合はデプロイを失敗させる。
 #3.3.4    レベル: 2    役割: D/V
 緊急時のモデルシャットダウン機能が、事前に定義された応答時間内に自動サーキットブレーカーまたは手動キルスイッチを介してモデルエンドポイントを無効化できることを検証する。
 #3.3.5    レベル: 2    役割: V
 組織のポリシーに従い、ロールバック成果物（以前のモデルバージョン、設定、依存関係）がインシデント対応のための不変ストレージに保持されていることを検証する。

---

### C3.4 変更の説明責任および監査

すべてのモデルのライフサイクル変更は追跡可能で監査可能でなければならない。

 #3.4.1    レベル: 1    役割: V
 すべてのモデル変更（デプロイ、設定、運用終了）について、タイムスタンプ、認証済み実行者ID、変更タイプ、前後の状態を含む不変の監査記録を生成することを検証してください。
 #3.4.2    レベル: 2    役割: D/V
 監査ログへのアクセスが適切な認可を要することを検証し、すべてのアクセス試行がユーザーIDとタイムスタンプを記録していることを確認してください。
 #3.4.3    レベル: 2    役割: D/V
 デプロイ前に、指定されたレビュアーによる必須のコードレビューと承認を受けた上で、Gitリポジトリにおけるプロンプトテンプレートとシステムメッセージがバージョン管理されていることを検証する。
 #3.4.4    レベル: 2    役割: V
 保持期間内の任意のタイムスタンプに対して、モデル状態を完全に再構築できるよう、監査記録に十分な詳細（モデルハッシュ、設定スナップショット、依存関係のバージョン）が含まれていることを検証する。

---

### C3.5 セキュア開発の実践

モデルの開発と訓練プロセスは、侵害を防ぐために安全な実践に従う必要があります。

 #3.5.1    レベル: 1    役割: D
 モデル開発環境、テスト環境、本番環境が物理的または論理的に分離されていることを確認してください。これらは共有インフラストラクチャを持たず、個別のアクセス制御が適用され、データストアが分離されています。
 #3.5.2    レベル: 1    役割: D
 モデルのトレーニングとファインチューニングが、ネットワークアクセスが制御された隔離環境で実行されることを検証する。
 #3.5.3    レベル: 1    役割: D/V
 モデル開発に使用する前に、トレーニングデータのソースが整合性検査で検証され、信頼できるソースを介して認証され、文書化されたチェーン・オブ・カストディを伴っていることを確認する。
 #3.5.4    レベル: 2    役割: D
 モデル開発成果物（ハイパーパラメータ、トレーニングスクリプト、設定ファイル）がバージョン管理に保存されており、トレーニングに使用する前にピアレビュー承認を必要とすることを確認する。

---

### C3.6 モデルの退役 & デコミッショニング

モデルは、もはや必要がなくなった場合、またはセキュリティ上の問題が特定された場合には、安全に退役させるべきです。

 #3.6.1    レベル: 1    役割: D
 モデルの退役プロセスが依存関係グラフを自動的にスキャンし、モデルの出力を利用するすべてのシステムを特定し、廃止前に事前合意された通知期間を提供することを検証する。
 #3.6.2    レベル: 1    役割: D/V
 退役済みモデルのアーティファクトが、文書化されたデータ保持ポリシーに従って、暗号化消去またはマルチパス上書きによって安全に消去されることを検証し、検証済みの破棄証明書を添付する。
 #3.6.3    レベル: 2    役割: V
 モデルのリタイアイベントが、タイムスタンプと実行者の識別情報を伴ってログに記録されることを確認し、再利用を防ぐためにモデル署名を失効させる。
 #3.6.4    レベル: 2    役割: D/V
 重大なセキュリティ脆弱性が発見された場合には、事前に設定された緊急対応時間枠内で、緊急時のモデル退役がモデルへのアクセスを自動的に無効化できることを、自動化されたキルスイッチを介して検証する。

---

### 参考文献

MLOps Principles
Securing AI/ML Ops – Cisco.com
Audit logs security: cryptographically signed tamper-proof logs
Machine Learning Model Versioning: Top Tools & Best Practices
AI Hygiene Starts with Models and Data Loaders – SEI Blog
How to handle versioning and rollback of a deployed ML model?
Reinforcement fine-tuning – OpenAI API
Auditing Machine Learning models: Governance, Data Security and …
Adversarial Training to Improve Model Robustness
What is AI adversarial robustness? – IBM Research
Exploring Data Provenance: Ensuring Data Integrity and Authenticity
MITRE ATLAS
AWS Prescriptive Guidance – Best practices for retiring applications …

## C4 インフラストラクチャ、構成・デプロイメントのセキュリティ

### 統制目標

AIインフラストラクチャは、権限昇格、サプライチェーンの改ざん、横方向の移動に対して強化されるべきであり、それを実現する手段として、安全な構成、実行時分離、信頼されたデプロイパイプライン、包括的な監視を備える。認可され検証済みのインフラストラクチャ部品と構成のみが、セキュリティ、完全性、監査可能性を維持する統制されたプロセスを通じて本番環境へ到達する。

コアセキュリティ目標：暗号署名済みで脆弱性スキャン済みのインフラストラクチャ構成要素だけが、自動検証パイプラインを通じて本番環境へ到達し、セキュリティポリシーを適用し、不変の監査証跡を維持する。

---

### C4.1 ランタイム環境の分離

カーネルレベルの分離プリミティブと強制アクセス制御を用いて、コンテナの脱出と権限昇格を防止する。

 #4.1.1    レベル: 1    役割: D/V
 すべての AI コンテナの Linux capabilities を削除し、CAP_SETUID、CAP_SETGID、およびセキュリティ基準で文書化された明示的に必要な capabilities のみを残すことを検証する。
 #4.1.2    レベル: 1    役割: D/V
 seccomp プロファイルが、事前承認済みの許可リストに含まれるシステムコールを除き、すべてのシステムコールをブロックすることを検証し、違反が発生した場合にはコンテナを終了し、セキュリティアラートを生成する。
 #4.1.3    レベル: 2    役割: D/V
 AIワークロードが、ルートファイルシステムを読み取り専用に、一時データには tmpfs を使用し、永続データには名前付きボリュームを使用して、noexec のマウントオプションが適用されていることを検証する。
 #4.1.4    レベル: 2    役割: D/V
 eBPF-based ランタイム監視（Falco、Tetragon、または同等のもの）が特権昇格の試行を検出し、組織の対応時間要件を満たす範囲内で不正なプロセスを自動的に終了させることを検証する。
 #4.1.5    レベル: 3    役割: D/V
 高リスクAIワークロードが、Intel TXT、AMD SVM、または専用のベアメタルノードといったハードウェア分離環境で、アテステーション検証を伴って実行されることを検証する。

---

### C4.2 セキュアな ビルド & デプロイ パイプライン

再現可能なビルドと署名済みのアーティファクトを通じて、暗号学的完全性とサプライチェーンのセキュリティを確保する。

 #4.2.1    レベル: 1    役割: D/V
 IaC が毎回のコミット時に tfsec、Checkov、または Terrascan のツールでスキャンされることを検証し、CRITICAL または HIGH の重大度の検出がある場合にはマージをブロックする。
 #4.2.2    レベル: 1    役割: D/V
 コンテナのビルドがビルド間で同一のSHA256ハッシュになるよう再現可能であることを検証し、Sigstoreで署名されたSLSAレベル3の出所証明を生成する。
 #4.2.3    レベル: 2    役割: D/V
 コンテナイメージが CycloneDX または SPDX SBOM を埋め込んでおり、Cosign で署名されていることをレジストリへプッシュする前に検証し、署名されていないイメージはデプロイ時に拒否されるようにする。
 #4.2.4    レベル: 2    役割: D/V
 CI/CDパイプラインが HashiCorp Vault、AWS IAM ロール、または Azure Managed Identity からの OIDC トークンを使用し、その有効期限が組織のセキュリティポリシーの制限を超えないことを検証する。
 #4.2.5    レベル: 2    役割: D/V
 デプロイメントの過程で、コンテナの実行前に Cosign 署名と SLSA プロヴェナンスが検証されることを確認し、検証エラーがデプロイメントを失敗させることを確認する。
 #4.2.6    レベル: 2    役割: D/V
 ビルド環境が、一時的なコンテナまたは VM 上で実行され、永続ストレージを持たず、本番 VPC からネットワーク分離されていることを検証します。

---

### C4.3 ネットワーク セキュリティ & アクセス 制御

デフォルト拒否ポリシーと暗号化された通信を伴うゼロトラスト・ネットワーキングを実装する。

 #4.3.1    レベル: 1    役割: D/V
 Kubernetes の NetworkPolicy（または同等の機能）が、デフォルト拒否の受信・送信を実装し、必要なポート（443、8080 など）に対して明示的な許可ルールを適用していることを検証する。
 #4.3.2    レベル: 1    役割: D/V
 SSH (ポート 22)、RDP (ポート 3389)、およびクラウドメタデータエンドポイント (169.254.169.254) がブロックされているか、または証明書ベースの認証を要求していることを確認してください。
 #4.3.3    レベル: 2    役割: D/V
 アウトバウンドトラフィックが HTTP/HTTPS プロキシ（Squid、Istio、またはクラウド NAT ゲートウェイ）を介してフィルタリングされ、ドメイン許可リストが適用され、ブロックされたリクエストが記録されていることを確認する。
 #4.3.4    レベル: 2    役割: D/V
 サービス間の通信が、組織方針に沿って証明書がローテーションされ、相互TLS認証を使用しており、証明書検証が強制されていることを検証してください（skip-verify フラグは使用されていません）。
 #4.3.5    レベル: 2    役割: D/V
 AIインフラストラクチャが専用のVPCs/VNetsで動作し、直接のインターネットアクセスがないことを確認し、通信はNATゲートウェイまたは踏み台ホストのみを介して行われることを確認してください。

---

### C4.4 秘密情報と暗号鍵の管理

ハードウェアベースのストレージと自動ローテーションを用いて、ゼロトラストアクセスで認証情報を保護する。

 #4.4.1    レベル: 1    役割: D/V
 シークレットが AES-256 による保存時の暗号化を適用した状態で、HashiCorp Vault、AWS Secrets Manager、Azure Key Vault、または Google Secret Manager に保存されていることを検証する。
 #4.4.2    レベル: 1    役割: D/V
 組織の暗号ポリシーに従い、キー回転を行いながら、FIPS 140-2 レベル 2 の HSM（AWS CloudHSM、Azure Dedicated HSM）で暗号鍵が生成されていることを検証してください。
 #4.4.3    レベル: 2    役割: D/V
 シークレットのローテーションが、ダウンタイムゼロのデプロイで自動化され、人員の異動やセキュリティインシデントにより即時にローテーションがトリガーされることを確認してください。
 #4.4.4    レベル: 2    役割: D/V
 コンテナイメージが、APIキー、パスワード、または証明書を含むビルドをブロックするよう、ツール（GitLeaks、TruffleHog、または detect-secrets）でスキャンされていることを検証する。
 #4.4.5    レベル: 2    役割: D/V
 本番環境の機密情報へのアクセスには、ハードウェアトークン（YubiKey、FIDO2）を用いた多要素認証が必要であり、ユーザー識別情報とタイムスタンプを含む改ざん不可の監査ログに記録されることを検証する。
 #4.4.6    レベル: 2    役割: D/V
 シークレットが Kubernetes のシークレット、マウントされたボリューム、または init コンテナを介して注入されることを検証し、環境変数やイメージにシークレットを埋め込まないことを保証する。

---

### C4.5 AI ワークロード サンドボックス化 & 検証

信頼できないAIモデルをセキュアなサンドボックスに分離し、包括的な挙動分析を実施する。

 #4.5.1    レベル: 1    役割: D/V
 外部AIモデルが gVisor、マイクロVM（Firecracker、CrossVM など）、または Docker コンテナ内で --security-opt=no-new-privileges および --read-only フラグを用いて実行されることを検証する。
 #4.5.2    レベル: 1    役割: D/V
 サンドボックス環境でネットワーク接続が一切ないこと（--network=none）または localhost へのアクセスのみを許可し、外部へのすべてのリクエストを iptables ルールでブロックしていることを確認してください。
 #4.5.3    レベル: 2    役割: D/V
 AIモデル検証が自動化されたレッドチームテストを含み、組織が定義したテストカバレッジとバックドア検出のための挙動分析を含むことを確認する。
 #4.5.4    レベル: 2    役割: D/V
 AIモデルが本番環境へデプロイされる前に、そのサンドボックス結果が認可されたセキュリティ担当者によって暗号学的署名され、不変の監査ログに保存されていることを検証する。
 #4.5.5    レベル: 2    役割: D/V
 評価間で、ゴールデンイメージからサンドボックス環境を破棄し再作成するとともに、ファイルシステムとメモリを完全にクリーンアップすることを確認する。

---

### C4.6 インフラストラクチャのセキュリティ監視

自動修復とリアルタイムアラートを備えた、インフラストラクチャの継続的なスキャンと監視。

 #4.6.1    レベル: 1    役割: D/V
 組織のスケジュールに従ってコンテナイメージがスキャンされ、組織のリスク閾値に基づいてデプロイをブロックする CRITICAL な脆弱性が存在することを確認する。
 #4.6.2    レベル: 1    役割: D/V
 組織が定義したコンプライアンス閾値と、失敗したチェックに対する自動修復を用いて、インフラストラクチャが CISベンチマークまたは NIST 800-53 のコントロールを満たすことを検証する。
 #4.6.3    レベル: 2    役割: D/V
 組織のリスク管理のタイムラインに従い、積極的に悪用されている CVE に対して緊急手順を講じ、重大度が高い脆弱性がパッチ適用されていることを検証する。
 #4.6.4    レベル: 2    役割: V
 CEF または STIX/TAXII 形式を用いた自動的な情報付加を伴うセキュリティアラートが、Splunk、Elastic、または Sentinel の SIEM プラットフォームと統合されることを検証する。
 #4.6.5    レベル: 3    役割: V
 インフラストラクチャの指標が監視システム（Prometheus、DataDog）へエクスポートされ、SLAダッシュボードと経営層向けレポート機能を備えていることを検証する。
 #4.6.6    レベル: 2    役割: D/V
 組織の監視要件に基づいて、ツール（Chef InSpec、AWS Config）を用いて構成のドリフトが検出されることを検証し、許可されていない変更に対して自動ロールバックが適用されることを確認する。

---

### C4.7 AI インフラストラクチャ リソース管理

リソース枯渇攻撃を防ぎ、クォータと監視を通じて公平なリソース配分を保証する。

 #4.7.1    レベル: 1    役割: D/V
 GPU/TPUの利用状況を監視し、組織が定義した閾値でアラートがトリガーされることを検証し、容量管理ポリシーに基づいて自動スケーリングまたはロードバランシングを有効化する。
 #4.7.2    レベル: 1    役割: D/V
 AIワークロード指標（推論レイテンシ、スループット、エラー率）が組織のモニタリング要件に従って収集され、インフラ利用状況と相関付けられていることを検証する。
 #4.7.3    レベル: 2    役割: D/V
 Kubernetes の ResourceQuota（または同等の機能）が、組織のリソース配分ポリシーに従って個々のワークロードを制限し、ハードリミットが適用されていることを検証する。
 #4.7.4    レベル: 2    役割: V
 コスト監視が、ワークロード/テナントごとの支出を追跡し、組織の予算閾値に基づくアラートと、予算超過を自動的に抑制する自動化された制御を備えていることを検証する。
 #4.7.5    レベル: 3    役割: V
 容量計画が、組織で定義された予測期間を含む履歴データを使用し、需要パターンに基づくリソースの自動プロビジョニングを行うことを検証する。
 #4.7.6    レベル: 2    役割: D/V
 リソースの枯渇が組織の対応要件に従ってサーキットブレーカーを作動させることを検証し、容量ポリシーに基づくレート制限およびワークロード分離を含める。

---

### C4.8 環境の分離とプロモーション制御

自動化された昇格ゲートとセキュリティ検証を用いて、厳格な環境間の境界を確保する。

 #4.8.1    レベル: 1    役割: D/V
 dev/test/prod 環境が別々の VPCs/VNets で実行され、共有された IAM ロール、セキュリティグループ、またはネットワーク接続がないことを確認してください。
 #4.8.2    レベル: 1    役割: D/V
 環境昇格には、組織で定義された承認権限を有する者の承認と、暗号署名および改ざん不可の監査証跡が必要であることを検証する。
 #4.8.3    レベル: 2    役割: D/V
 本番環境でSSHアクセスをブロックし、デバッグエンドポイントを無効化し、緊急時を除き組織の事前通知要件を満たす変更依頼を求めることを検証する。
 #4.8.4    レベル: 2    役割: D/V
 infrastructure-as-code の変更は、メインブランチへマージする前に、ピアレビューと自動テストおよびセキュリティスキャンを要求することを確認してください。
 #4.8.5    レベル: 2    役割: D/V
 本番以外のデータが、組織のプライバシー要件に従って匿名化されていること、または合成データ生成が行われていること、あるいはPII除去を含む完全なデータマスキングが検証されていることを確認する。
 #4.8.6    レベル: 2    役割: D/V
 昇格ゲートに自動化されたセキュリティテスト（SAST、DAST、コンテナスキャン）を含め、承認を得るための条件としてクリティカルな所見がゼロであることを検証する。

---

### C4.9 インフラストラクチャのバックアップとリカバリ

自動バックアップ、検証済みの復旧手順、および災害復旧機能を通じて、インフラストラクチャのレジリエンスを確保する。

 #4.9.1    レベル: 1    役割: D/V
 インフラ構成が組織のバックアップスケジュールに従ってバックアップされ、地理的に分離された複数のリージョンにおいて3-2-1バックアップ戦略を実装していることを確認します。
 #4.9.2    レベル: 2    役割: D/V
 バックアップシステムが、分離されたネットワーク内で別々の認証情報とエアギャップ式ストレージを用いて動作していることを検証してください。
 #4.9.3    レベル: 2    役割: V
 組織のスケジュールに従い、自動化テストを通じて復旧手順がテストおよび検証されていることを確認し、RTOおよびRPOの目標が組織要件を満たしていることを保証する。
 #4.9.4    レベル: 3    役割: V
 ディザスターリカバリにAI専用の運用手順書が含まれ、モデル重みの復元、GPUクラスターの再構築、サービス依存関係のマッピングをカバーしていることを確認してください。

---

### C4.10 インフラストラクチャのコンプライアンスとガバナンス

継続的な評価、文書化、そして自動化された統制を通じて規制遵守を維持する。

 #4.10.1    レベル: 2    役割: D/V
 組織のスケジュールに沿って、SOC 2、ISO 27001、または FedRAMP の統制に対して、インフラストラクチャのコンプライアンスが自動的な証拠収集とともに評価されていることを検証する。
 #4.10.2    レベル: 2    役割: V
 インフラストラクチャの文書にネットワーク図、データフロー図、脅威モデルが含まれ、組織の変更管理要件に従って更新されていることを確認してください。
 #4.10.3    レベル: 3    役割: D/V
 高リスクの変更について、インフラストラクチャの変更が自動化されたコンプライアンス影響評価を受け、規制承認ワークフローを経由することを検証する。

---

### C4.11 AI ハードウェアのセキュリティ

GPU、TPU、そして専門的なAIアクセラレータを含むAI専用ハードウェアコンポーネントのセキュリティを確保する。

 #4.11.1    レベル: 2    役割: D/V
 AIアクセラレータのファームウェア（GPU BIOS、TPUファームウェア）が暗号署名で検証され、組織のパッチ管理スケジュールに従って更新されていることを確認する。
 #4.11.2    レベル: 2    役割: D/V
 ワークロードを実行する前に、AIアクセラレータの完全性が TPM 2.0、Intel TXT、または AMD SVM を用いたハードウェアアテステーションによって検証されることを確認する。
 #4.11.3    レベル: 2    役割: D/V
 SR-IOV、MIG（Multi-Instance GPU）または同等のハードウェアパーティショニングを用いて、ジョブ間でのメモリサニタイズを行い、GPUメモリがワークロード間で分離されていることを検証する。
 #4.11.4    レベル: 3    役割: V
 AIハードウェアのサプライチェーンが、製造元証明書を用いた出所検証と、改ざん防止梱包の検証を含むことを確認する。
 #4.11.5    レベル: 3    役割: D/V
 HSM（ハードウェアセキュリティモジュール）がAIモデルの重みと暗号鍵をFIPS 140-2レベル3またはCommon Criteria EAL4+認証で保護していることを検証する。

---

### C4.12 エッジ & 分散AIインフラストラクチャ

エッジコンピューティング、フェデレーテッドラーニング、およびマルチサイトアーキテクチャを含むセキュアな分散AIの展開。

 #4.12.1    レベル: 2    役割: D/V
 エッジAIデバイスが中央インフラストラクチャに対して相互TLSを用いて認証することを検証し、デバイス証明書が組織の証明書管理ポリシーに従ってローテーションされること。
 #4.12.2    レベル: 2    役割: D/V
 エッジデバイスが、検証済みの署名を用いたセキュアブートを実装し、ファームウェアのダウングレード攻撃を防ぐロールバック保護を備えていることを検証します。
 #4.12.3    レベル: 3    役割: D/V
 分散型AIの協調が、参加者検証と悪意あるノード検出を備えたビザンチン耐障害性のコンセンサスアルゴリズムを用いていることを検証してください。
 #4.12.4    レベル: 3    役割: D/V
 edge-to-cloud 通信が、帯域幅制御、データ圧縮、および安全なローカルストレージを備えたオフライン動作機能を含むことを確認する。

---

### C4.13 マルチクラウド & ハイブリッド インフラストラクチャのセキュリティ

複数のクラウドプロバイダーとハイブリッドクラウドおよびオンプレミス展開全体にわたって、AIワークロードを安全に保護する。

 #4.13.1    レベル: 2    役割: D/V
 マルチクラウドAIデプロイメントが、クラウド非依存のアイデンティティ・フェデレーション（OIDC、SAML）を、クラウドプロバイダー間で一元化されたポリシー管理とともに使用していることを検証する。
 #4.13.2    レベル: 2    役割: D/V
 複数クラウド間のデータ転送が、顧客管理キーを用いたエンドツーエンド暗号化と、法域ごとに適用・強制されるデータ所在規制を満たしていることを検証してください。
 #4.13.3    レベル: 2    役割: D/V
 ハイブリッドクラウドAIワークロードが、オンプレミスとクラウド環境全体で一貫したセキュリティポリシーを実装し、統合監視とアラート機能を備えていることを検証する。
 #4.13.4    レベル: 3    役割: V
 クラウドベンダーロックイン防止策には、移植性のある infrastructure-as-code、標準化された API、および形式変換ツールを備えたデータエクスポート機能が含まれていることを検証する。
 #4.13.5    レベル: 3    役割: V
 マルチクラウドのコスト最適化が、リソースのスプロールを防ぐセキュリティ制御と、認可されていないクラウド間データ転送に伴う料金を防ぐ対策を含んでいることを確認する。

---

### C4.14 インフラ自動化 & GitOps セキュリティ

AIインフラストラクチャ管理のための、インフラ自動化パイプラインとGitOpsワークフローをセキュアにする。

 #4.14.1    レベル: 2    役割: D/V
 GitOps リポジトリが GPGキーによる署名済みのコミットを要求し、main ブランチへの直接プッシュを防ぐブランチ保護ルールを適用していることを検証する。
 #4.14.2    レベル: 2    役割: D/V
 組織の対応要件に従って不正な変更をトリガーとする、自動的な是正およびロールバック機能を備えたドリフト検出を含むインフラ自動化を検証してください。
 #4.14.3    レベル: 2    役割: D/V
 自動化されたインフラストラクチャのプロビジョニングが、準拠していない構成に対してデプロイをブロックするセキュリティポリシーの検証を含むことを確認する。
 #4.14.4    レベル: 2    役割: D/V
 外部シークレットオペレーター（External Secrets Operator、Bank-Vaults）を通じてインフラ自動化のシークレットが管理され、かつ自動回転が行われていることを検証する。
 #4.14.5    レベル: 3    役割: V
 自己修復可能なインフラストラクチャには、セキュリティイベントの相関と自動化されたインシデント対応および利害関係者通知のワークフローが含まれていることを検証する。

---

### C4.15 量子耐性インフラストラクチャのセキュリティ

量子計算の脅威に備えたAIインフラを、ポスト量子暗号と量子安全プロトコルを用いて整備する。

 #4.15.1    レベル: 3    役割: D/V
 AIインフラストラクチャが、鍵交換とデジタル署名のためにNIST承認済みのポスト量子暗号アルゴリズム（CRYSTALS-Kyber、CRYSTALS-Dilithium、SPHINCS+）を実装していることを検証します。
 #4.15.2    レベル: 3    役割: D/V
 量子鍵配送（QKD）システムが高セキュリティAI通信のために実装され、量子耐性鍵管理プロトコルを用いていることを確認してください。
 #4.15.3    レベル: 3    役割: D/V
 暗号適応性フレームワークが、自動化された証明書と鍵のローテーションを伴い、新しいポスト量子アルゴリズムへの迅速な移行を実現することを検証する。
 #4.15.4    レベル: 3    役割: V
 量子脅威モデリングが、文書化された移行タイムラインとリスク評価を伴って、AIインフラストラクチャの量子攻撃に対する脆弱性を評価していることを確認する。
 #4.15.5    レベル: 3    役割: D/V
 量子移行期間中に、性能監視を伴う古典-量子ハイブリッド暗号システムが多層防御を提供することを検証する。

---

### C4.16 機密計算とセキュアエンクレーブ

ハードウェアベースの信頼できる実行環境と機密計算技術を用いて、AIワークロードとモデルの重みを保護する。

 #4.16.1    レベル: 3    役割: D/V
 機密AIモデルが、暗号化メモリとアテステーション検証を備えた Intel SGX エンクレーブ、AMD SEV-SNP、または ARM TrustZone 内で実行されることを検証する。
 #4.16.2    レベル: 3    役割: D/V
 機密コンテナ（Kata Containers、機密計算を用いた gVisor）により、AI ワークロードをハードウェアによるメモリ暗号化で隔離していることを検証する。
 #4.16.3    レベル: 3    役割: D/V
 リモートアテステーションがエンクレーブの完全性を検証し、AIモデルをロードする前に、実行環境の真正性を暗号的証明として提供することを確認する。
 #4.16.4    レベル: 3    役割: D/V
 機密性の高いAI推論サービスが、封印済みのモデル重みと保護された実行環境を用いた暗号化計算を介して、モデル抽出を防止していることを検証する。
 #4.16.5    レベル: 3    役割: D/V
 信頼済み実行環境のオーケストレーションが、リモート・アテステーションと暗号化通信チャネルを用いて、セキュアなエンクレーブのライフサイクルを管理していることを検証してください。
 #4.16.6    レベル: 3    役割: D/V
 個々のデータセットやモデルパラメータを公開することなく、協調的なAIトレーニングを可能にするSMPCを検証する。

---

### C4.17 ゼロ知識インフラストラクチャ

機微情報を開示せずに、プライバシー保護を実現するAIの検証と認証のためのゼロ知識証明システムを実装する。

 #4.17.1    レベル: 3    役割: D/V
 ゼロ知識証明（ZK-SNARKs、ZK-STARKs）が、モデルの重みやトレーニングデータを公開することなく、AIモデルの完全性とトレーニングの出所を検証することを確認してください。
 #4.17.2    レベル: 3    役割: D/V
 ZKベースの認証システムが、AIサービスに対して身元関連情報を開示することなく、プライバシーを保護したユーザー検証を実現できることを検証する。
 #4.17.3    レベル: 3    役割: D/V
 プライベート・セット・インターセクション（PSI）プロトコルが、個々のデータセットを開示することなく、フェデレーテッドAIのための安全なデータ照合を可能にすることを検証してください。
 #4.17.4    レベル: 3    役割: D/V
 ゼロナレッジきかいがくしゅう（ZKML）システムが、せいかくな AI すいろん を あんごてきしょうめい とともに かのう に することを けんしょう する。
 #4.17.5    レベル: 3    役割: D/V
 ZKロールアップが、バッチ検証と計算オーバーヘッドの削減を伴う、スケーラブルでプライバシー保護されたAIトランザクション処理を提供することを検証してください。

---

### C4.18 サイド-チャネル攻撃の予防

機密情報を漏洩する可能性のあるタイミング、電力、電磁波、キャッシュベースのサイドチャネル攻撃から AI インフラを保護する。

 #4.18.1    レベル: 3    役割: D/V
 AI推論のタイミングが、constant-timeアルゴリズムとパディングを用いて正規化され、タイミングに基づくモデル抽出攻撃を防ぐことを検証します。
 #4.18.2    レベル: 3    役割: D/V
 AIハードウェア向けの電力解析保護に、ノイズ注入、電源ラインフィルタリング、およびランダム化された実行パターンが含まれていることを確認してください。
 #4.18.3    レベル: 3    役割: D/V
 キャッシュベースのサイドチャネル対策がキャッシュ分割、ランダム化、フラッシュ命令を用いて情報漏えいを防ぐことを検証する。
 #4.18.4    レベル: 3    役割: D/V
 電磁放射対策が遮蔽、信号フィルタリング、およびランダム化処理を含み、TEMPEST-style攻撃を防ぐことを検証する。
 #4.18.5    レベル: 3    役割: D/V
 マイクロアーキテクチャのサイドチャネル防御には、推測実行の制御とメモリアクセスパターンの難読化が含まれていることを確認してください。

---

### C4.19 ニューロモルフィックと専門的なAIハードウェアセキュリティ

ニューロモルフィック・チップ、FPGA、カスタムASIC、光学計算システムを含む新興のAIハードウェア・アーキテクチャの安全性を確保する。

 #4.19.1    レベル: 3    役割: D/V
 ニューロモルフィックチップのセキュリティが、スパイクパターン暗号化、シナプス重みの保護、およびハードウェアベースの学習則の検証を含んでいることを確認してください。
 #4.19.2    レベル: 3    役割: D/V
 FPGAベースのAIアクセラレータがビットストリーム暗号化、改ざん防止機構、認証済みの更新を用いたセキュアな設定のロードを実装していることを検証する。
 #4.19.3    レベル: 3    役割: D/V
 カスタムASICセキュリティには、オンチップセキュリティプロセッサ、ハードウェア・ルート・オブ・トラスト、および改ざん検知機能を備えた秘密鍵の安全な格納が含まれていることを検証する。
 #4.19.4    レベル: 3    役割: D/V
 光学計算システムが、量子安全な光学暗号化、セキュアなフォトニックスイッチング、保護された光信号処理を実装していることを検証してください。
 #4.19.5    レベル: 3    役割: D/V
 ハイブリッドアナログ-デジタルAIチップには、セキュアなアナログ演算、保護された重みの格納、および認証済みのアナログ-デジタル変換が含まれていることを検証する。

---

### C4.20 プライバシー保護された計算インフラストラクチャ

AI処理および分析中の機微データを保護するために、プライバシー保護計算を支えるインフラストラクチャの統制を実装する。

 #4.20.1    レベル: 3    役割: D/V
 同型暗号基盤が機密性の高いAIワークロード上で暗号化計算を可能にし、暗号的整合性検証と性能監視を実現することを検証する。
 #4.20.2    レベル: 3    役割: D/V
 アクセスパターンを暗号的に保護することで、クエリパターンを開示せずにデータベース照会を可能にするプライベート情報検索（PIR）システムを検証してください。
 #4.20.3    レベル: 3    役割: D/V
 セキュアなマルチパーティ計算プロトコルは、個々の入力や中間計算を公開することなく、プライバシー保護型のAI推論を実現できることを検証する。
 #4.20.4    レベル: 3    役割: D/V
 プライバシー保護型の鍵管理が、分散鍵生成、閾値暗号、およびハードウェア保護付きの安全な鍵回転を含むことを検証してください。
 #4.20.5    レベル: 3    役割: D/V
 プライバシー保護された計算のパフォーマンスが、バッチ処理、キャッシュ、ハードウェア加速を通じて最適化されていることを、暗号学的セキュリティ保証を維持しながら検証する。

---

### C4.15 エージェント フレームワーク クラウド統合 セキュリティ & ハイブリッド展開

ハイブリッドなオンプレミス／クラウドアーキテクチャを備えたクラウド統合エージェントフレームワークのためのセキュリティ対策。

 #4.15.1    レベル: 1    役割: D/V
 クラウドストレージ統合がエンドツーエンド暗号化を、エージェントが管理する鍵管理とともに採用していることを検証する。
 #4.15.2    レベル: 2    役割: D/V
 ハイブリッド展開のセキュリティ境界が、暗号化された通信チャネルを用いて明確に定義されていることを検証する。
 #4.15.3    レベル: 2    役割: D/V
 クラウドリソースへのアクセスが、継続的な認証を伴うゼロトラスト検証を含んでいることを確認してください。
 #4.15.4    レベル: 3    役割: D/V
 データ居住要件が、ストレージ場所の暗号的証明によって遵守されていることを検証する。
 #4.15.5    レベル: 3    役割: D/V
 クラウドプロバイダのセキュリティ評価がエージェント固有の脅威モデリングとリスク評価を含んでいることを検証する。

---

### 参考文献

NIST Cybersecurity Framework 2.0
CIS Controls v8
OWASP Container Security Verification Standard
Kubernetes Security Best Practices
SLSA Supply Chain Security Framework
NIST SP 800-190: Application Container Security Guide
Cloud Security Alliance: Cloud Controls Matrix
ENISA: Secure Infrastructure Design
NIST SP 800-53: Security Controls for Federal Information Systems
ISO 27001:2022 Information Security Management
NIST AI Risk Management Framework
CIS Kubernetes Benchmark
FIPS 140-2 Security Requirements
NIST SP 800-207: Zero Trust Architecture
IEEE 2857: Privacy Engineering for AI Systems
NIST SP 800-161: Cybersecurity Supply Chain Risk Management
NIST Post-Quantum Cryptography Standards
Intel SGX Developer Guide
AMD SEV-SNP White Paper
ARM TrustZone Technology
ZK-SNARKs: A Gentle Introduction
NIST SP 800-57: Cryptographic Key Management
Side-Channel Attack Countermeasures
Neuromorphic Computing Security Challenges
FPGA Security: Fundamentals, Evaluation, and Countermeasures
Microsoft SEAL: Homomorphic Encryption Library
HElib: Homomorphic Encryption Library
PALISADE Lattice Cryptography Library
Differential Privacy: A Survey of Results
Secure Aggregation for Federated Learning
Private Information Retrieval: Concepts and Constructions

## C5 AI コンポーネントおよびユーザーのアクセス制御とアイデンティティ

### 統制目標

AIシステムにおける効果的なアクセス制御には、堅牢なアイデンティティ管理、文脈認識型認可、そしてゼロトラスト原則に沿った実行時適用が必要です。これらの制御は、人間、サービス、そして自律エージェントが、明示的に許可されたスコープ内でのみモデル、データ、計算資源と相互作用できるようにし、継続的な検証と監査機能を提供します。

---

### C5.1 アイデンティティ管理 & 認証

すべての主体に対して、暗号技術によって裏付けられたアイデンティティを確立し、特権操作には多要素認証を適用する。

 #5.1.1    レベル: 1    役割: D/V
 すべての人間のユーザーとサービスプリンシパルが、集中化された企業アイデンティティプロバイダ（IdP）を介してOIDC/SAMLプロトコルを用いて認証し、一意のアイデンティティとトークンの対応づけを確保することを検証する（共有アカウントや認証情報の共有は不可）。
 #5.1.2    レベル: 1    役割: D/V
 高リスク操作（モデルのデプロイ、重みのエクスポート、トレーニングデータへのアクセス、本番環境の構成変更）が、マルチファクター認証またはセッション再認証を伴うステップアップ認証を必要とすることを検証する。
 #5.1.3    レベル: 2    役割: D
 新規プリンシパルが、NIST 800-63-3 IAL-2または同等の基準に沿った身元確認を受けることを、本番システムへのアクセスを取得する前に確認する。
 #5.1.4    レベル: 2    役割: V
 アクセスレビューが四半期ごとに実施され、休眠アカウントの自動検出、資格情報ローテーションの強制、デプロビジョニング ワークフローの実行を確認します。
 #5.1.5    レベル: 3    役割: D/V
 フェデレーテッドAIエージェントが、署名済みJWTアサーションを介して認証され、最大有効期限が24時間で、起源を示す暗号学的証拠を含むことを検証する。

---

### C5.2 リソース認可と最小権限

すべてのAIリソースに対して、明示的な権限モデルと監査証跡を備えた細粒度のアクセス制御を実装する。

 #5.2.1    レベル: 1    役割: D/V
 すべてのAIリソース（データセット、モデル、エンドポイント、ベクトルコレクション、埋め込みインデックス、計算インスタンス）が、明示的な許可リストとデフォルト拒否ポリシーを備えたロールベースアクセス制御を適用していることを検証してください。
 #5.2.2    レベル: 1    役割: D/V
 デフォルトで最小権限の原則が適用されていることを検証し、サービスアカウントは読み取り専用権限から開始し、書き込みアクセスには文書化されたビジネス上の正当性が必要であることを確認する。
 #5.2.3    レベル: 1    役割: V
 すべてのアクセス制御の変更が承認済みの変更要求に紐づけられ、タイムスタンプ、実行者の識別情報、リソース識別子、および権限の差分を含む不変なログとして記録されていることを検証してください。
 #5.2.4    レベル: 2    役割: D
 データ分類ラベル（PII、PHI、輸出規制対象、企業機密）が、派生リソース（埋め込み表現、プロンプトキャッシュ、モデル出力）へ自動的に伝搬し、一貫したポリシーの適用が行われることを検証する。
 #5.2.5    レベル: 2    役割: D/V
 不正アクセスの試行および権限昇格イベントが、文脈情報を含むメタデータを付与したリアルタイムアラートとしてSIEMシステムへ5分以内に通知されることを検証する。

---

### C5.3 動的ポリシー評価

コンテキスト認識に基づく認可決定のための属性ベースのアクセス制御（ABAC）エンジンを展開し、監査機能を備える。

 #5.3.1    レベル: 1    役割: D/V
 認可決定が専用のポリシーエンジン（OPA、Cedar、または同等のもの）に外部化され、認証済みの API を介してアクセス可能で、暗号技術による整合性保護が提供されていることを検証する。
 #5.3.2    レベル: 1    役割: D/V
 ポリシーが実行時に動的属性を評価することを検証します。これには、ユーザーのクリアランスレベル、リソースの機密性分類、リクエストコンテキスト、テナント分離、時間的制約を含みます。
 #5.3.3    レベル: 2    役割: D
 ポリシー定義がバージョン管理され、査読済みで、CI/CDパイプラインでの自動テストを通じて検証されることを、本番環境へのデプロイ前に確認する。
 #5.3.4    レベル: 2    役割: V
 ポリシー評価結果に構造化された意思決定根拠が含まれていることを検証し、それらが相関分析およびコンプライアンス報告のために SIEM システムへ送信されることを確認する。
 #5.3.5    レベル: 3    役割: D/V
 キャッシュの無効化機能を備えたリソースについて、ポリシーキャッシュの TTL 値が機密性の高いリソースでは最大 5 分、標準リソースでは最大 1 時間を超えないことを検証してください。

---

### C5.4 クエリ-時のセキュリティ適用

データベース層のセキュリティ制御を実装し、強制的なフィルタリングと行レベルのセキュリティポリシーを適用する。

 #5.4.1    レベル: 1    役割: D/V
 すべてのベクトルデータベースおよび SQL クエリに、テナントID、機密性ラベル、ユーザー範囲といった必須のセキュリティフィルターが、アプリケーションコードではなくデータベースエンジンレベルで強制されていることを検証してください。
 #5.4.2    レベル: 1    役割: D/V
 すべてのベクトルデータベース、検索インデックス、およびトレーニングデータセットについて、ポリシー継承を有効にし、行レベルのセキュリティ（RLS）ポリシーおよびフィールドレベルのマスキングが有効になっていることを検証します。
 #5.4.3    レベル: 2    役割: D
 認可評価の失敗が、クエリを直ちに中止し、空の結果セットを返すのではなく、明示的な認可エラーコードを返すことによって、「混同した代理人攻撃」を防ぐことを検証する。
 #5.4.4    レベル: 2    役割: V
 ポリシー評価のレイテンシが継続的に監視され、認可回避を引き起こす可能性のあるタイムアウト条件に対して自動アラートが発されていることを確認する。
 #5.4.5    レベル: 3    役割: D/V
 クエリ再試行メカニズムが、アクティブなユーザー セッション内の動的な権限変更を考慮して、認可ポリシーを再評価することを検証する。

---

### C5.5 出力フィルタリングとデータ損失防止

AI生成コンテンツにおける不正なデータ露出を防ぐための事後処理制御を展開する。

 #5.5.1    レベル: 1    役割: D/V
 推論後のフィルタリング機構が、要求者へコンテンツを提供する前に、許可されていないPII（個人を特定できる情報）、機密情報、および企業秘密データをスキャンして伏せ字にすることを検証する。
 #5.5.2    レベル: 1    役割: D/V
 モデル出力における引用・参照・出典の帰属情報が、呼び出し元の権限と照合して検証され、不正アクセスが検出された場合には削除されることを確認する。
 #5.5.3    レベル: 2    役割: D
 出力形式の制限（サニタイズされたPDFファイル、メタデータを削除した画像、承認済みファイルタイプ）が、ユーザーの権限レベルとデータ分類に基づいて適用されていることを検証する。
 #5.5.4    レベル: 2    役割: V
 伏字化アルゴリズムが決定論的で、バージョン管理されており、監査ログを保持して、コンプライアンス調査および法医学的分析を支援することを確認してください。
 #5.5.5    レベル: 3    役割: V
 高リスクの秘匿化イベントがデータ露出を伴わずに、元の内容の暗号学的ハッシュ値を含む適応型ログを生成することを検証する。

---

### C5.6 マルチテナント分離

共有AIインフラストラクチャにおけるテナント間の暗号的および論理的隔離を確保する。

 #5.6.1    レベル: 1    役割: D/V
 メモリ空間、埋め込みストア、キャッシュエントリ、および一時ファイルが、テナントごとにネームスペースで分離され、テナントの削除またはセッション終了時に安全に消去されることを検証する。
 #5.6.2    レベル: 1    役割: D/V
 すべての API リクエストに、認証済みのテナント識別子が含まれており、それがセッションコンテキストおよびユーザーの権限情報に対して暗号学的に検証されることを確認してください。
 #5.6.3    レベル: 2    役割: D
 サービスメッシュ内およびコンテナオーケストレーションプラットフォーム内で、ネットワークポリシーがテナント間通信に対してデフォルト拒否ルールを実装していることを検証してください。
 #5.6.4    レベル: 3    役割: D
 テナントごとに暗号鍵が一意であることを確認し、顧客管理キー（CMK）をサポートし、テナントデータストア間の暗号学的分離を確保する。

---

### C5.7 自律エージェントの認可

スコープ付き能力トークンと継続的認可を通じて、AIエージェントと自律システムの権限を制御する。

 #5.7.1    レベル: 1    役割: D/V
 自律エージェントが、許可された操作、アクセス可能なリソース、時間的境界、および運用上の制約を明示的に列挙するスコープ付き能力トークンを受け取ることを検証する。
 #5.7.2    レベル: 1    役割: D/V
 高リスク機能（ファイルシステムアクセス、コード実行、外部API呼び出し、金融取引）がデフォルトで無効になっていることを検証し、有効化にはビジネス上の正当な理由を添えた明示的な承認が必要であることを確認する。
 #5.7.3    レベル: 2    役割: D
 能力トークンがユーザーセッションに紐付けられていることを検証し、暗号的整合性保護を含め、オフライン環境で永続化または再利用されないことを保証してください。
 #5.7.4    レベル: 2    役割: V
 エージェント起動アクションが ABAC ポリシーエンジンを介して完全なコンテキスト評価と監査ログを伴う二次認可を受けることを検証します。
 #5.7.5    レベル: 3    役割: V
 エージェントのエラー条件および例外処理に、インシデント分析とフォレンジック調査を支援するための能力の範囲情報を含めることを確認してください。

---

### 参考文献

#### 標準とフレームワーク

NIST SP 800-63-3: Digital Identity Guidelines
Zero Trust Architecture – NIST SP 800-207
OWASP Application Security Verification Standard (AISVS)
​
#### 実装ガイド

Identity and Access Management in the AI Era: 2025 Guide – IDSA
Attribute-Based Access Control with OPA – Permify
How We Designed Cedar to Be Intuitive, Fast, and Safe – AWS
​
#### AI-特化セキュリティ

Row Level Security in Vector DBs for RAG – Bluetuple.ai
Tenant Isolation in Multi-Tenant Systems – WorkOS
Handling AI Agent Permissions – Stytch
OWASP Top 10 for Large Language Model Applications

## C6 モデル、フレームワーク、データのサプライチェーンセキュリティ

### 統制目標

AI サプライ‑チェーン攻撃は、サードパーティ‑モデル、フレームワーク、またはデータセットを利用して、バックドア、バイアス、または悪用可能なコードを埋め込む。これらの管理措置は、エンド‑ツーエンドの出所情報、脆弱性管理、監視を提供し、全体のモデルライフサイクルを保護するためのものです。

---

### C6.1 事前学習済みモデルの検証と出所

ファインチューニングやデプロイメントを行う前に、サードパーティ‑製モデルの出所、ライセンス、隠れた挙動を評価し、認証する。

 #6.1.1    レベル: 1    役割: D/V
 すべてのサードパーティ製モデルアーティファクトには、ソースリポジトリとコミットハッシュを識別する署名付きの出所記録が含まれていることを検証する。
 #6.1.2    レベル: 1    役割: D/V
 インポート前に、モデルが自動ツールを用いて悪意のあるレイヤーまたはトロイの木馬のトリガーを検査されていることを確認してください。
 #6.1.3    レベル: 2    役割: D
 転移‑学習によるファインチューニングが、隠れた挙動を検出するための敵対的評価をクリアすることを検証する。
 #6.1.4    レベル: 2    役割: V
 ML-BOMエントリに、モデルライセンス、輸出管理タグ、およびデータ起源に関する記述が記録されていることを確認してください。
 #6.1.5    レベル: 3    役割: D/V
 高‑リスクモデル（公開された重み、未検証の作成者）が、人間の審査とサイン‑オフが完了するまで隔離された状態のままであることを確認してください。

---

### C6.2 フレームワークとライブラリのスキャン

実行時スタックを安全に保つため、MLフレームワークとライブラリを継続的にスキャンし、CVEと悪意のあるコードを検出します。

 #6.2.1    レベル: 1    役割: D/V
 CIパイプラインがAIフレームワークおよび重要ライブラリに対して依存関係スキャナーを実行していることを検証する。
 #6.2.2    レベル: 1    役割: D/V
 重大な脆弱性（CVSS ≥ 7.0）が本番イメージへの昇格をブロックすることを確認する。
 #6.2.3    レベル: 2    役割: D
 フォーク済みまたはベンダー提供の機械学習ライブラリで静的コード解析が実行されることを検証する。
 #6.2.4    レベル: 2    役割: V
 フレームワークのアップグレード提案に、公開CVEフィードを参照したセキュリティ影響評価が含まれていることを検証する。
 #6.2.5    レベル: 3    役割: V
 署名済み SBOM から逸脱する予期せぬ動的ライブラリのロードに対して、実行時センサーが警告することを検証する。

---

### C6.3 依存関係のピン留めと検証

すべての依存関係を不変ダイジェストに固定し、ビルドを再現可能にして、同一かつ改ざんされていないアーティファクトを保証する。

 #6.3.1    レベル: 1    役割: D/V
 すべてのパッケージマネージャがロックファイルを介してバージョン固定を強制していることを検証する。
 #6.3.2    レベル: 1    役割: D/V
 コンテナ参照において不変ダイジェストが可変タグの代わりに使用されていることを検証する。
 #6.3.3    レベル: 2    役割: D
 再現性ビルドの検証が、CI の実行間でハッシュ値を比較し、同一の出力を保証していることを確認する。
 #6.3.4    レベル: 2    役割: V
 ビルドのアテステーションが監査証跡性のために18か月間保存されていることを確認してください。
 #6.3.5    レベル: 3    役割: D
 期限切れの依存関係が、ピン留めされたバージョンを更新する自動PRをトリガーするか、あるいはフォークするかを検証する。

---

### C6.4 信頼済みソースの適用

成果物のダウンロードは、暗号学的に検証済みの組織‑承認済みのソースからのみ許可し、それ以外はすべてブロックします。

 #6.4.1    レベル: 1    役割: D/V
 モデルの重み、データセット、およびコンテナは、承認済みのドメインまたは内部レジストリからのみダウンロードされることを確認してください。
 #6.4.2    レベル: 1    役割: D/V
 アーティファクトがローカルにキャッシュされる前に、Sigstore/Cosign の署名が発行者の身元を検証していることを確認する。
 #6.4.3    レベル: 2    役割: D
 エグレスプロキシが認証されていないアーティファクトのダウンロードをブロックし、trusted‑sourceポリシーを適用することを検証する。
 #6.4.4    レベル: 2    役割: V
 リポジトリの許可リストが四半期ごとに見直され、各エントリごとにビジネス上の正当性を示す証拠があることを確認する。
 #6.4.5    レベル: 3    役割: V
 ポリシー違反が成果物の検疫と、依存するパイプライン実行のロールバックを引き起こすことを検証する。

---

### C6.5 第三者データセットリスク評価

外部データセットをデータポイズニング、バイアス、法的遵守の観点から評価し、それらのライフサイクル全体を通じて監視する。

 #6.5.1    レベル: 1    役割: D/V
 外部データセットがデータ汚染リスクのスコアリングを受けることを検証する（例：データ指紋付け、外れ値検出）。
 #6.5.2    レベル: 1    役割: D
 データセットが承認される前に、バイアス指標（デモグラフィック・パリティ、機会均等）が計算されることを検証する。
 #6.5.3    レベル: 2    役割: V
 データセットの出所情報とライセンス条件が ML‑BOM エントリに記録されていることを検証してください。
 #6.5.4    レベル: 2    役割: V
 ホストされたデータセットにおける定期的な監視が、データドリフトまたは破損を検出することを検証する。
 #6.5.5    レベル: 3    役割: D
 トレーニング前に自動データクリーニングを用いて、禁止されたコンテンツ（著作権、PII）が除去されていることを検証する。

---

### C6.6 サプライチェーン攻撃の監視

CVEフィード、監査ログ分析、レッドチーム演習を通じてサプライチェーンの脅威を早期に検出する。

 #6.6.1    レベル: 1    役割: V
 CI/CD の監査ログが SIEM の検出機能に送られ、異常なパッケージのプルや改ざんされたビルド手順を検知できることを検証する。
 #6.6.2    レベル: 2    役割: D
 インシデント対応プレイブックに、侵害されたモデルまたはライブラリのロールバック手順が含まれていることを確認する。
 #6.6.3    レベル: 3    役割: V
 アラートのトリアージにおいて、脅威インテリジェンス強化タグが ML‑専用指標をタグ付けしていることを検証する（例：モデル‑ポイズニング IoCs）。

---

### C6.7 モデル成果物用の ML‑BOM

デプロイ時にコンポーネントの完全性を検証できるよう、詳細な ML専用SBOM（ML‑BOM）を生成して署名してください。

 #6.7.1    レベル: 1    役割: D/V
 すべてのモデルアーティファクトが、データセット、重み、ハイパーパラメータ、ライセンスを列挙したML‑BOMを公開していることを確認してください。
 #6.7.2    レベル: 1    役割: D/V
 CIでML‑BOMの生成とCosign署名を自動化し、マージに必須であることを検証する。
 #6.7.3    レベル: 2    役割: D
 ML‑BOM の完全性チェックが、いずれかのコンポーネントのメタデータ（ハッシュ、ライセンス）が欠落している場合にビルドを失敗させることを検証します。
 #6.7.4    レベル: 2    役割: V
 デプロイ時にインポートされたモデルを検証するため、下流の利用者が API を介して ML-BOMs を照会できることを検証する。
 #6.7.5    レベル: 3    役割: V
 ML‑BOMs がバージョン管理され、差分が取られていることを検証し、不正な変更を検出する。

---

### 参考文献

ML Supply Chain Compromise – MITRE ATLAS
Supply‑chain Levels for Software Artifacts (SLSA)
CycloneDX – Machine Learning Bill of Materials
What is Data Poisoning? – SentinelOne
Transfer Learning Attack – OWASP ML Security Top 10
AI Data Security Best Practices – CISA
Secure CI/CD Supply Chain – Sumo Logic
AI & Transparency: Protect ML Models – ReversingLabs
SBOM Overview – CISA
Training Data Poisoning Guide – Lakera.ai
Dependency Pinning for Reproducible Python – Medium

## C7 モデルの挙動、出力制御と安全性保証

### 統制目標

モデルの出力は、本番環境で構造化され、信頼性が高く、安全で、説明可能で、継続的に監視されなければならない。これにより、幻覚、プライバシー漏洩、有害なコンテンツ、暴走行動を低減し、同時にユーザーの信頼と規制遵守を高める。

---

### C7.1 出力フォーマットの遵守

厳格なスキーマ、制約付きデコード、下流の検証により、形式が不正な内容や悪意のある内容が伝搬する前に停止します。

 #7.1.1    レベル: 1    役割: D/V
 レスポンススキーマ（例：JSONスキーマ）がシステムプロンプトに含まれていることを確認し、すべての出力が自動的に検証されます。準拠していない出力は修正または拒否されます。
 #7.1.2    レベル: 1    役割: D/V
 制約付きデコード（ストップトークン、正規表現、max-tokens）が有効になっていることを検証し、オーバーフローやプロンプトインジェクションによるサイドチャネルを防ぐ。
 #7.1.3    レベル: 2    役割: D/V
 下流のコンポーネントが出力を信頼できないものとして扱い、スキーマに対して検証するか、インジェクション耐性のあるデシリアライザで検証することを確認する。
 #7.1.4    レベル: 3    役割: V
 不適切な出力イベントがログに記録され、レート制限され、監視に通知されることを検証する。

---

### C7.2 幻覚検出と対策

不確実性推定とフォールバック戦略は、捏造された回答を抑制する。

 #7.2.1    レベル: 1    役割: D/V
 トークンレベルの対数確率、アンサンブル自己整合性、またはファインチューニングされた幻覚検出器が各回答に対して信頼度スコアを割り当てていることを検証する。
 #7.2.2    レベル: 1    役割: D/V
 設定可能な信頼度閾値を下回る応答がフォールバックワークフローをトリガーすることを検証します（例：検索補助生成、二次モデル、または人間によるレビュー）。
 #7.2.3    レベル: 2    役割: D/V
 幻覚事象が根本原因メタデータでタグ付けされ、ポストモーテムおよびファインチューニングのパイプラインに投入されることを検証する。
 #7.2.4    レベル: 3    役割: D/V
 主要なモデルまたは知識ベースの更新後に、閾値と検出器が再校正されていることを確認する。
 #7.2.5    レベル: 3    役割: V
 ダッシュボードの可視化が幻覚率を追跡していることを検証してください。

---

### C7.3 出力の安全性とプライバシー保護フィルタリング

ポリシー フィルターとレッドチームのカバレッジは、ユーザーと機密データを保護します。

 #7.3.1    レベル: 1    役割: D/V
 生成前および生成後の分類器が、ポリシーに沿って憎悪・嫌がらせ・自傷・過激主義・性的露骨なコンテンツをブロックすることを検証する。
 #7.3.2    レベル: 1    役割: D/V
 すべての応答でPII/PCI検出と自動伏字化が実行されることを検証する。違反はプライバシーインシデントを引き起こす。
 #7.3.3    レベル: 2    役割: D
 機密性タグ（例：営業秘密）がモダリティ間で伝播することを検証し、テキスト、画像、またはコードにおける漏洩を防ぐ。
 #7.3.4    レベル: 3    役割: D/V
 フィルター回避の試みまたは高リスク分類が二次承認またはユーザーの再認証を必要とすることを検証します。
 #7.3.5    レベル: 3    役割: D/V
 フィルタリングの閾値が法域およびユーザーの年齢・役割の文脈を反映していることを検証する。

---

### C7.4 出力とアクションの制限

レート制限と承認ゲートは、悪用と過度な自律性を防ぎます。

 #7.4.1    レベル: 1    役割: D
 各ユーザーごとおよび APIキーごとのクォータが、429エラー時に指数バックオフを用いて、リクエスト数、トークン数、コストを制限することを検証します。
 #7.4.2    レベル: 1    役割: D/V
 特権操作（ファイルの書き込み、コードの実行、ネットワーク呼び出し）がポリシーに基づく承認または人間の介在を必要とすることを確認してください。
 #7.4.3    レベル: 2    役割: D/V
 同じリクエストに対して生成された画像、コード、およびテキストが、クロスモーダルの整合性チェックによって悪意のある内容をすり抜けて使用されることがないことを検証する。
 #7.4.4    レベル: 2    役割: D
 エージェント委任の深さ、再帰の上限、および許可されたツールのリストが明示的に設定されていることを確認する。
 #7.4.5    レベル: 3    役割: V
 制限違反がSIEM取り込みのために構造化されたセキュリティイベントを出力することを検証する。

---

### C7.5 出力の説明可能性

透明性のあるシグナルは、ユーザーの信頼と内部デバッグを向上させる。

 #7.5.1    レベル: 2    役割: D/V
 リスク評価が適切と判断された場合に、ユーザーに表示される信頼度スコアや簡易推論の要約が適切に提供されることを検証する。
 #7.5.2    レベル: 2    役割: D/V
 生成された説明が、機密のシステムプロンプトや専有データを開示していないことを確認する。
 #7.5.3    レベル: 3    役割: D
 システムがトークンレベルの対数確率またはアテンションマップを取得し、それらを認可済みの監査のために保存することを検証する。
 #7.5.4    レベル: 3    役割: V
 監査可能性のために、説明可能性のアーティファクトがモデルのリリースと並行してバージョン管理されていることを確認する。

---

### C7.6 モニタリング統合

リアルタイムの可観測性は、開発と本番環境の間のループを閉じる。

 #7.6.1    レベル: 1    役割: D
 メトリクス（スキーマ違反、幻覚率、有害性、PII漏洩、レイテンシ、コスト）が中央監視プラットフォームへ送信されることを検証する。
 #7.6.2    レベル: 1    役割: V
 各安全指標について、アラート閾値が定義されていることを確認し、オンコール時のエスカレーション経路を整備する。
 #7.6.3    レベル: 2    役割: V
 ダッシュボードが、出力の異常とモデル/バージョン、機能フラグ、および上流データの変更と相関していることを確認してください。
 #7.6.4    レベル: 2    役割: D/V
 監視データが文書化されたMLOpsワークフロー内で再訓練、ファインチューニング、またはルール更新へフィードバックされることを検証する。
 #7.6.5    レベル: 3    役割: V
 機密ログの漏洩を防ぐため、監視パイプラインがペネトレーションテストを受け、アクセス制御が適切に行われていることを検証する。

---

### 7.7 生成系メディアの安全対策

AIシステムが違法・有害・または許可されていないメディアコンテンツを生成しないよう、ポリシー制約の適用、出力検証、トレーサビリティの確保を通じて保証する。

 #7.7.1    レベル: 1    役割: D/V
 システムプロンプトとユーザー指示が、違法・有害・同意を得ていないディープフェイクメディア（例：画像、動画、音声）の生成を明示的に禁止していることを確認してください。
 #7.7.2    レベル: 2    役割: D/V
 プロンプトが、なりすましの試み、性的に露骨なディープフェイク、または同意なしに実在の人物を描写する媒体の生成を試みるものをフィルタリングしていることを確認する。
 #7.7.3    レベル: 2    役割: V
 システムが知覚ハッシュ、透かし検出、またはフィンガープリントを用いて、著作権で保護されたメディアの不正な複製を防止していることを確認してください。
 #7.7.4    レベル: 3    役割: D/V
 下流のトレーサビリティを確保するために、生成されたすべてのメディアが暗号署名が付与されている、透かしが施されている、または改ざん耐性のある出所メタデータが埋め込まれていることを確認する。
 #7.7.5    レベル: 3    役割: V
 バイパス試行（例：プロンプトの難読化、スラング、敵対的な表現）が検出され、記録され、レート制限されることを検証する。繰り返される乱用は監視システムに報告される。

### 参考文献

NIST AI Risk Management Framework
ISO/IEC 42001:2023 – AI Management System
OWASP Top-10 for Large Language Model Applications (2025)
Improper Output Handling – OWASP LLM05:2025
Practical Techniques to Constrain LLM Output
Dataiku – Structured Text Generation Guide
VL-Uncertainty: Detecting Hallucinations
HaDeMiF: Hallucination Detection & Mitigation
Building Confidence in LLM Outputs
Explainable AI & LLMs
LLM Red-Teaming Guide
Sensitive Information Disclosure in LLMs
LangChain – Chat Model Rate Limiting
OpenAI Rate-Limit & Exponential Back-off
Arize AI – LLM Observability Platform

## C8 Memory, 埋め込み表現とベクトルデータベースのセキュリティ

### 統制目標

埋め込みとベクトルストアは、現代のAIシステムの「ライブメモリ」として機能し、絶えずユーザーが提供したデータを受け取り、Retrieval-Augmented Generation（RAG）を介してモデルのコンテキストへ再提示します。統制されていないまま放置すると、このメモリはPIIを漏えいさせたり、同意を侵害したり、元のテキストを再構築するために反転される可能性があります。本統制ファミリーの目的は、メモリパイプラインとベクトルデータベースを堅牢化し、アクセスを最小権限に限定し、埋め込みをプライバシー保護型にし、保存されたベクトルを有効期限切れにするか、必要に応じて取り消し可能にし、個々のユーザーのメモリが別のユーザーのプロンプトや生成結果を汚染しないようにすることです。

---

### C8.1 メモリ & RAG 指標へのアクセス制御

すべてのベクトルコレクションに細粒度のアクセス制御を適用する。

 #8.1.1    レベル: 1    役割: D/V
 テナント、コレクション、またはドキュメントタグごとに、挿入、削除、およびクエリ操作を制限する行/名前空間-レベルのアクセス制御ルールを検証する。
 #8.1.2    レベル: 1    役割: D/V
 APIキーまたはJWTには、コレクションIDやアクション動詞などのスコープ付きクレームが含まれていることを検証し、それらが少なくとも四半期ごとにローテーションされていることを確認する。
 #8.1.3    レベル: 2    役割: D/V
 権限昇格の試行（例：異なるネームスペース間の類似性クエリ）が検出され、5分以内にSIEMへ記録されることを検証する。
 #8.1.4    レベル: 2    役割: D/V
 ベクトルDBの監査ログが、主体識別子、操作、ベクトルID/ネームスペース、類似度閾値、および結果件数を記録していることを確認してください。
 #8.1.5    レベル: 3    役割: V
 エンジンがアップグレードされるたび、または index-sharding ルールが変更される場合には、アクセス決定がバイパス脆弱性に対して検証されていることを確認してください。

---

### C8.2 埋め込みのサニタイズ & 検証

PII（個人を特定できる情報）を事前にスクリーニングし、ベクトル化の前に伏字化／偽名化を行い、必要に応じて埋め込みベクトルを後処理して残留信号を除去する。

 #8.2.1    レベル: 1    役割: D/V
 PIIおよび規制対象データを自動分類器で検出し、埋め込み前にマスク、トークン化、または削除します。
 #8.2.2    レベル: 1    役割: D
 埋め込みパイプラインが、インデックスを汚染する可能性のある実行可能なコードを含む入力や、非UTF-8アーティファクトを含む入力を拒否または検疫することを検証する。
 #8.2.3    レベル: 2    役割: D/V
 文埋め込み表現に対して、既知のPIIトークンのいずれかとの距離が設定可能な閾値を下回る場合に、局所差分プライバシー保護またはメトリック差分プライバシー保護のサニタイズが適用されていることを検証する。
 #8.2.4    レベル: 2    役割: V
 サニタイズの有効性（例：PIIのマスキングの再現率、意味的ドリフト）が少なくとも半年ごとにベンチマークコーパスに対して検証されていることを確認する。
 #8.2.5    レベル: 3    役割: D/V
 サニタイズ設定がバージョン管理されており、変更がピアレビューを受けていることを確認してください。

---

### C8.3 メモリの有効期限、取り消し、削除

GDPR（一般データ保護規則）の「忘れられる権利」および同様の法は適時の削除を要求します。したがって、ベクトルストアはTTL（Time To Live）をはじめ、ハードデリート、そして墓標-化をサポートし、撤回されたベクトルが回復できず、再インデックス化されることを防ぐ必要があります。

 #8.3.1    レベル: 1    役割: D/V
 すべてのベクトルとメタデータレコードが、TTLまたは自動クリーンアップジョブによって遵守される明示的な保持ラベルを携えていることを検証する。
 #8.3.2    レベル: 1    役割: D/V
 ユーザーが開始した削除リクエストが、ベクトル、メタデータ、キャッシュコピー、派生インデックスを30日以内に消去することを検証する。
 #8.3.3    レベル: 2    役割: D
 論理削除の後、ハードウェアが対応していればストレージブロックの暗号的シュレッディングを行い、そうでなければ Key Vault の鍵を破棄することを検証する。
 #8.3.4    レベル: 3    役割: D/V
 有効期限切れのベクトルが、有効期限切れから 500 ms 未満の時間内に最近傍探索の結果から除外されることを検証する。

---

### C8.4 埋め込みの反転と漏洩を防止

最近の防御策—ノイズの重畳、プロジェクションネットワーク、プライバシー-ニューロン摂動、そしてアプリケーション-層の暗号化—は、トークン-レベルの復元率を5%以下に抑えることができる。

 #8.4.1    レベル: 1    役割: V
 公式な脅威モデルが、逆推定攻撃、メンバーシップ推定攻撃、属性推定攻撃を含むものであり、毎年見直されていることを確認する。
 #8.4.2    レベル: 2    役割: D/V
 アプリケーション層の暗号化または検索可能暗号化が、インフラストラクチャの管理者またはクラウド担当者による直接的な読み取りからベクトルを保護していることを検証してください。
 #8.4.3    レベル: 3    役割: V
 防御パラメータ（DP の ε、ノイズ σ、射影階数 k）が、プライバシーを 99 % 以上、トークン保護を維持し、有用性を 3 % 以下の精度低下でバランスさせることを検証する。
 #8.4.4    レベル: 3    役割: D/V
 モデル更新のリリースゲートの一部として、インバージョン耐性指標が含まれていることを検証し、回帰予算を定義する。

---

### C8.5 ユーザー固有メモリのスコープ適用

テナント間の情報流出は依然として RAG の最大級のリスクです：適切にフィルタリングされていない類似クエリは、他の顧客の機密文書を露出させる可能性があります。

 #8.5.1    レベル: 1    役割: D/V
 すべての検索クエリが、LLMプロンプトへ渡される前に、テナントIDおよびユーザーIDで事後フィルタリングされていることを検証する。
 #8.5.2    レベル: 1    役割: D
 コレクション名またはネームスペース付きIDが、ユーザーまたはテナントごとにソルトされていることを検証し、スコープ間でベクトルが衝突しないようにします。
 #8.5.3    レベル: 2    役割: D/V
 呼び出し元の範囲外かつ設定可能な距離閾値を超える類似性結果は破棄され、セキュリティ警告を発することを検証する。
 #8.5.4    レベル: 2    役割: V
 マルチテナント環境におけるストレステストが、範囲外のドキュメントを取得しようとする敵対的なクエリをシミュレートし、情報漏洩ゼロを実証することを検証する。
 #8.5.5    レベル: 3    役割: D/V
 暗号鍵がテナントごとに分離されていることを検証し、物理的なストレージが共有されていても暗号学的分離を保証します。

---

### C8.6 高度な メモリシステム の セキュリティ

エピソード記憶、意味記憶、作業記憶を含む高度なメモリアーキテクチャに対する、特定の隔離および検証要件を備えたセキュリティコントロール。

 #8.6.1    レベル: 1    役割: D/V
 異なるメモリタイプ（エピソード記憶、意味記憶、作業記憶）が、ロールベースのアクセス制御、別個の暗号化鍵、各メモリタイプに対する文書化されたアクセスパターンとともに、隔離されたセキュリティコンテキストを有することを検証する。
 #8.6.2    レベル: 2    役割: D/V
 メモリ統合プロセスには、保存前にコンテンツのサニタイズ、出所検証、整合性チェックを通じて、悪意のあるメモリの注入を防ぐセキュリティ検証が含まれていることを確認してください。
 #8.6.3    レベル: 2    役割: D/V
 不正な情報の抽出を防ぐために、クエリパターン分析、アクセス制御の適用、そして結果のフィルタリングを通じて、メモリ取得クエリが検証され、サニタイズされることを確認する。
 #8.6.4    レベル: 3    役割: D/V
 メモリ消去機構が、鍵削除、複数回の上書き、または検証証明書付きのハードウェアベースのセキュア削除を用いて、機微情報を安全に削除する暗号学的消去保証を満たすことを検証する。
 #8.6.5    レベル: 3    役割: D/V
 メモリシステムの整合性が、許可されていない変更または破損を検出するため、チェックサム、監査ログ、およびメモリ内容が通常の操作範囲外に変更された場合の自動通知を通じて継続的に監視されていることを検証します。

---

### 参考文献

Vector database security: Pinecone – IronCore Labs
Securing the Backbone of AI: Safeguarding Vector Databases and Embeddings – Privacera
Enhancing Data Security with RBAC of Qdrant Vector Database – AI Advances
Mitigating Privacy Risks in LLM Embeddings from Embedding Inversion – arXiv
DPPN: Detecting and Perturbing Privacy-Sensitive Neurons – OpenReview
Art. 17 GDPR – Right to Erasure
Sensitive Data in Text Embeddings Is Recoverable – Tonic.ai
PII Identification and Removal – NVIDIA NeMo Docs
De-identifying Sensitive Data – Google Cloud DLP
Remove PII from Conversations Using Sensitive Information Filters – AWS Bedrock Guardrails
Think Your RAG Is Secure? Think Again – Medium
Design a Secure Multitenant RAG Inferencing Solution – Microsoft Learn
Best Practices for Multi-Tenancy RAG with Milvus – Milvus Blog

## 9 自律オーケストレーションとエージェント的行動のセキュリティ

### 統制目標

自律型またはマルチエージェントAIシステムは、明示的に意図され、認証され、監査可能で、かつ費用とリスクの閾値が制限された範囲内の行動のみを実行できるようにする。これにより、以下の脅威に対して保護します：自律システムの侵害、ツールの不正使用、エージェント・ループ検出、通信の乗っ取り、アイデンティティのなりすまし、群知能の操作、そして意図の改ざん。

---

### 9.1 エージェントのタスク-計画と再帰予算

再帰的な計画を制限し、特権的なアクションには人間のチェックポイントを設ける。

 #9.1.1    レベル: 1    役割: D/V
 最大再帰深度、探索幅、ウォールクロック時間、トークン数、およびエージェント実行あたりの金銭的コストが一元的に設定され、バージョン管理されていることを確認してください。
 #9.1.2    レベル: 1    役割: D/V
 特権的または不可逆的な操作（例：コードのコミット、資金の移動）が、実行前に監査可能なチャネルを介して明示的な人間の承認を必要とすることを検証する。
 #9.1.3    レベル: 2    役割: D
 リアルタイムのリソース監視が、いずれかの予算閾値を超えた場合にサーキットブレーカを作動させ、さらなるタスク拡張を停止することを検証する。
 #9.1.4    レベル: 2    役割: D/V
 フォレンジック調査のため、サーキットブレーカーのイベントが、エージェントID、トリガ条件、取得済みのプラン状態とともに記録されていることを検証してください。
 #9.1.5    レベル: 3    役割: V
 セキュリティテストが予算枯渇および暴走プランのシナリオを網羅していることを検証し、データ損失なしに安全に停止できることを確認する。
 #9.1.6    レベル: 3    役割: D
 予算ポリシーをポリシー・アズ・コードとして表現し、CI/CD で適用・強制されていることを検証して、構成のドリフトをブロックします。

---

### 9.2 ツール プラグイン サンドボックス化

ツールの相互作用を分離し、不正なシステムアクセスやコードの実行を防止する。

 #9.2.1    レベル: 1    役割: D/V
 すべてのツール／プラグインが、OS、コンテナ、または WASM レベルのサンドボックス内で、最小権限のファイルシステム、ネットワーク、およびシステムコール ポリシーを適用して実行されることを検証してください。
 #9.2.2    レベル: 1    役割: D/V
 サンドボックスのリソースクォータ（CPU、メモリ、ディスク、ネットワーク出力）と実行タイムアウトが適用され、ログに記録されていることを確認する。
 #9.2.3    レベル: 2    役割: D/V
 ツールのバイナリまたはディスクリプタがデジタル署名されていることを確認し、読み込み前に署名を検証します。
 #9.2.4    レベル: 2    役割: V
 サンドボックスのテレメトリがSIEMにストリームとして送信されることを検証し、異常（例：外部への接続を試みた場合など）がアラートを発生させることを確認する。
 #9.2.5    レベル: 3    役割: V
 高リスクのプラグインが本番環境へのデプロイ前にセキュリティレビューとペネトレーションテストを受けることを確認してください。
 #9.2.6    レベル: 3    役割: D/V
 サンドボックスからの脱出を試みる行為が自動的にブロックされることを検証し、問題のプラグインが調査中は検疫されることを確認してください。

---

### 9.3 自律ループ & コスト境界

制御不能なエージェント間の再帰とコストの爆発を検出して停止する。

 #9.3.1    レベル: 1    役割: D/V
 エージェント間の呼び出しに、ランタイムがデクリメントして適用を強制するホップ制限または TTL が含まれていることを検証する。
 #9.3.2    レベル: 2    役割: D
 エージェントが自己呼び出しや循環パターンを検出するために、固有の invocation-graph ID を維持していることを検証する。
 #9.3.3    レベル: 2    役割: D/V
 累積コンピュートユニットと消費カウンターがリクエストチェーンごとに追跡されていることを検証する; 制限を超えるとチェーンは中止される。
 #9.3.4    レベル: 3    役割: V
 形式的解析またはモデル検査が、エージェントのプロトコルにおける無限再帰が存在しないことを示すことを検証する。
 #9.3.5    レベル: 3    役割: D
 loop-abort イベントがアラートを生成し、継続的改善の指標に寄与することを検証する。

---

### 9.4 プロトコルレベルの不正利用対策

エージェントと外部システム間の通信チャネルを保護し、乗っ取りや改ざんを防ぐ。

 #9.4.1    レベル: 1    役割: D/V
 すべてのエージェント-ツール間およびエージェント-エージェント間のメッセージが認証されており（例：相互TLS認証またはJWT）、エンドツーエンドで暗号化されていることを確認してください。
 #9.4.2    レベル: 1    役割: D
 スキーマが厳密に検証されていることを確認し、未知のフィールドや形式が不正なメッセージは拒否される。
 #9.4.3    レベル: 2    役割: D/V
 整合性検証（MAC またはデジタル署名）が、ツールのパラメータを含むメッセージ全体のペイロードをカバーしていることを確認する。
 #9.4.4    レベル: 2    役割: D
 プロトコル層でリプレイ防止機構（ノンスまたはタイムスタンプウィンドウ）が適用されていることを検証する。
 #9.4.5    レベル: 3    役割: V
 プロトコル実装がインジェクション脆弱性やデシリアライズ脆弱性に対して、ファジングと静的解析を受けていることを確認する。

---

### 9.5 エージェントの識別と改ざん証跡

行動を帰属可能にし、変更を検出可能にする。

 #9.5.1    レベル: 1    役割: D/V
 各エージェント・インスタンスが固有の暗号的アイデンティティ（鍵ペアまたはハードウェア・ルート認証情報）を有していることを検証してください。
 #9.5.2    レベル: 2    役割: D/V
 すべてのエージェントのアクションが署名され、タイムスタンプが付与されていることを検証してください。ログには否認不能性を確保するための署名が含まれています。
 #9.5.3    レベル: 2    役割: V
 改ざん検知可能なログが、追記専用媒体または書き込み一度きりの媒体に保存されていることを検証する。
 #9.5.4    レベル: 3    役割: D
 アイデンティティ鍵が定義されたスケジュールと侵害の兆候に基づいてローテーションすることを検証する。
 #9.5.5    レベル: 3    役割: D/V
 なりすましまたは鍵の衝突の試みが、影響を受けたエージェントを直ちに隔離するよう誘発することを確認してください。

---

### 9.6 マルチ-エージェント・スウォームのリスク低減

分離と形式的安全モデリングを通じて、集合的行動による危険を軽減する。

 #9.6.1    レベル: 1    役割: D/V
 異なるセキュリティ領域で動作するエージェントが、分離されたランタイムサンドボックスまたはネットワークセグメントで実行されることを検証する。
 #9.6.2    レベル: 3    役割: V
 展開前に、群れの挙動がモデル化され、生存性および安全性について形式的に検証されていることを確認する。
 #9.6.3    レベル: 3    役割: D
 ランタイムモニターが新たに出現する不安全パターン（例：発振、デッドロック）を検出し、是正措置を開始することを検証する。

---

### 9.7 ユーザー & ツール 認証 / 認可

すべてのエージェントによってトリガーされるアクションに対して、堅牢なアクセス制御を実装する。

 #9.7.1    レベル: 1    役割: D/V
 エージェントが下流システムに対してファーストクラスプリンシパルとして認証していることを検証し、エンドユーザーの資格情報を再利用しないことを確認する。
 #9.7.2    レベル: 2    役割: D
 細粒度の認可ポリシーが、エージェントが呼び出せるツールと、エージェントが提供できるパラメータを制限していることを検証する。
 #9.7.3    レベル: 2    役割: V
 各呼び出し時に権限チェックが再評価されること（継続的認可）を検証し、セッション開始時だけでなく毎回実行されることを確認する。
 #9.7.4    レベル: 3    役割: D
 委任された権限が自動的に失効し、タイムアウト後またはスコープ変更後に再同意を求めることを検証します。

---

### 9.8 エージェント間の通信セキュリティ

すべてのエージェント間のメッセージを暗号化し、完全性を確保して、盗聴と改ざんを防止する。

 #9.8.1    レベル: 1    役割: D/V
 エージェントチャネルには、相互認証と完全前方秘匿性を備えた暗号化（例：TLS 1.3）が必須であることを検証する。
 #9.8.2    レベル: 1    役割: D
 処理を行う前に、メッセージの完全性と発信元が検証されていることを確認してください。検証に失敗した場合は、警告を発し、メッセージを破棄します。
 #9.8.3    レベル: 2    役割: D/V
 法医学的再構成を支援するために、通信メタデータ（タイムスタンプ、シーケンス番号）がログに記録されていることを確認する。
 #9.8.4    レベル: 3    役割: V
 形式検証またはモデル検査を用いて、プロトコルの状態機械が不安全な状態へ移行しないことを確認する。

---

### 9.9 インテント検証 & 制約の適用

エージェントの行動が、ユーザーの明示的な意図およびシステム制約に沿っていることを検証する。

 #9.9.1    レベル: 1    役割: D
 実行前の制約ソルバーが、提案された行動をハードコーディングされた安全性およびポリシー規則と照合することを検証する。
 #9.9.2    レベル: 2    役割: D/V
 高影響の操作（金融的影響を伴うもの、破壊的なもの、プライバシーに敏感なもの）には、操作を開始したユーザーからの明示的な意図の確認を必要とすることを検証する。
 #9.9.3    レベル: 2    役割: V
 事後条件の検証により、完了したアクションが意図した効果を副作用なく達成したことを確認する。差異が生じた場合はロールバックを実行する。
 #9.9.4    レベル: 3    役割: V
 形式手法（例：モデル検査、定理証明）または性質ベースのテストを用いて、エージェントの計画が宣言されたすべての制約を満たすことを検証する。
 #9.9.5    レベル: 3    役割: D
 インテント不一致または制約違反のインシデントが、継続的改善サイクルと脅威情報共有を促進することを検証する。

---

### 9.10 エージェント推論戦略とセキュリティ

ReAct、Chain-of-Thought、および Tree-of-Thoughts アプローチを含む、さまざまな推論戦略の安全な選択と実行。

 #9.10.1    レベル: 1    役割: D/V
 推論戦略の選択が決定論的基準（入力の複雑性、タスクの種類、セキュリティコンテキスト）を用いて行われ、同一の入力が同じセキュリティコンテキスト内で同一の戦略選択を生み出すことを検証する。
 #9.10.2    レベル: 1    役割: D/V
 各推論戦略（ReAct、Chain-of-Thought、Tree-of-Thoughts）には、それぞれの認知アプローチに固有の入力検証、出力のサニタイズ、および実行時間制限が備わっていることを検証する。
 #9.10.3    レベル: 2    役割: D/V
 推論戦略の遷移が、監査証跡の再構築のために、入力特性、選択基準値、実行メタデータを含む完全な文脈とともに記録されていることを検証する。
 #9.10.4    レベル: 2    役割: D/V
 Tree-of-Thoughtsの推論が、ポリシー違反、リソース制限、または安全境界が検出されたときに探索を終了する分岐の枝刈り機構を含んでいることを確認する。
 #9.10.5    レベル: 2    役割: D/V
 ReAct（Reason-Act-Observe）サイクルが各フェーズに検証ポイントを含み、先に進む前に推論ステップの検証、アクションの承認、観測のサニタイズが行われることを検証してください。
 #9.10.6    レベル: 3    役割: D/V
 推論戦略のパフォーマンス指標（実行時間、リソース使用量、出力品質）が、設定された閾値を超えた場合に自動アラートで監視されることを検証する。
 #9.10.7    レベル: 3    役割: D/V
 複数の戦略を組み合わせるハイブリッド推論アプローチが、すべての構成戦略の入力検証と出力制約を回避することなく維持していることを検証する。
 #9.10.8    レベル: 3    役割: D/V
 推論戦略のセキュリティテストには、形式が崩れた入力を対象としたファジング、戦略の切替を強制するよう設計された敵対的プロンプト、そして各認知アプローチに対する境界条件テストが含まれていることを検証する。

---

### 9.11 エージェントのライフサイクル状態管理とセキュリティ

セキュアなエージェントの初期化、状態遷移、終了、および暗号化された監査証跡と定義済みの復旧手順。

 #9.11.1    レベル: 1    役割: D/V
 エージェントの初期化が、ハードウェア保護された認証情報を用いた暗号的なアイデンティティの確立を含み、エージェントID、タイムスタンプ、設定ハッシュ、および初期化パラメータを含む不可変の起動監査ログを保持していることを検証してください。
 #9.11.2    レベル: 2    役割: D/V
 エージェントの状態遷移が暗号署名され、タイムスタンプが付与され、トリガーとなるイベント、前状態ハッシュ、新状態ハッシュ、および実施されたセキュリティ検証を含む完全な文脈とともにログに記録されていることを検証する。
 #9.11.3    レベル: 2    役割: D/V
 エージェントのシャットダウン手順が、暗号化消去またはマルチパス上書きを用いた安全なメモリ消去、認証情報の取り消しと認証局への通知、そして改ざん検知機能を備えた終了証明書の発行を含むことを検証してください。
 #9.11.4    レベル: 3    役割: D/V
 エージェント回復機構が、状態の整合性を暗号学的ハッシュ値（SHA-256を最低限とする）を用いて検証し、破損が検出された場合に自動通知と手動承認要件を伴って既知の良好な状態へロールバックすることを検証する。
 #9.11.5    レベル: 3    役割: D/V
 エージェントの永続化メカニズムが機密性の高い状態データをエージェントごとに AES-256 鍵で暗号化し、設定可能なスケジュール（最大 90 日）で安全な鍵回転を実装し、ゼロダウンタイムでのデプロイを実現していることを検証する。

---

### 9.12 ツール統合セキュリティフレームワーク

定義されたリスク評価および承認プロセスを伴う、動的ツールの読み込み、実行、結果検証に対するセキュリティ制御。

 #9.12.1    レベル: 1    役割: D/V
 ツール記述子に、必要な権限（読み取り/書き込み/実行）、リスクレベル（低/中/高）、リソース制限（CPU、メモリ、ネットワーク）を指定するセキュリティメタデータ、およびツールマニフェストに文書化された検証要件が含まれていることを確認する。
 #9.12.2    レベル: 1    役割: D/V
 ツールの実行結果が、想定されるスキーマ（JSON Schema、XML Schema）およびセキュリティポリシー（出力のサニタイズ、データ分類）に対して検証されることを、タイムアウト制限およびエラーハンドリング手順と統合する前に確認してください。
 #9.12.3    レベル: 2    役割: D/V
 SIEM統合のために、ツールの相互作用ログが権限の使用、データアクセスパターン、実行時間、リソース消費量、および戻り値コードを含む詳細なセキュリティコンテキストを構造化ログとして記録していることを確認する。
 #9.12.4    レベル: 2    役割: D/V
 動的ツール読み込み機構が PKI インフラストラクチャを用いてデジタル署名を検証することを確認し、実行前にサンドボックス分離と権限検証を含む安全な読み込みプロトコルを実装する。
 #9.12.5    レベル: 3    役割: D/V
 新しいバージョンに対して、静的解析、動的テスト、セキュリティチームの審査を含む必須の承認ゲートを備えたツールのセキュリティ評価が自動的にトリガーされることを検証し、承認基準およびSLA要件を文書化していることを確認する。

---

#### 参考文献

MITRE ATLAS tactics ML09
Circuit-breaker research for AI agents — Zou et al., 2024
Trend Micro analysis of sandbox escapes in AI agents — Park, 2025
Auth0 guidance on human-in-the-loop authorization for agents — Martinez, 2025
Medium deep-dive on MCP & A2A protocol hijacking — ForAISec, 2025
Rapid7 fundamentals on spoofing attack prevention — 2024
Imperial College verification of swarm systems — Lomuscio et al.
NIST AI Risk Management Framework 1.0, 2023
WIRED security briefing on encryption best practices, 2024
OWASP Top 10 for LLM Applications, 2025
Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS
[How Is LLM Reasoning Distracted by Irrelevant Context?
An Analysis Using a Controlled Benchmark](https://www.arxiv.org/pdf/2505.18761)
Large Language Model Sentinel: LLM Agent for Adversarial Purification
Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents

## 10 敵対的ロバストネス & プライバシー保護

### 統制目標

AIモデルは、回避攻撃、推論攻撃、抽出攻撃、またはポイズニング攻撃に直面しても、信頼性を維持し、プライバシーを保護し、乱用耐性を確保する。

---

### 10.1 モデルのアラインメントと安全性

有害な内容やポリシー違反の出力を防ぐ。

 #10.1.1    レベル: 1    役割: D/V
 アラインメント テスト-スイート（レッドチームのプロンプト、ジャイルブレイク・プローブ、禁止コンテンツ）がバージョン管理下に置かれており、すべてのモデルリリース時に実行されることを検証する。
 #10.1.2    レベル: 1    役割: D
 拒否および安全完了のガードレールが適用されていることを検証する。
 #10.1.3    レベル: 2    役割: D/V
 自動評価システムが有害コンテンツの割合を測定し、設定された閾値を超える回帰を検出してフラグを付けることを検証する。
 #10.1.4    レベル: 2    役割: D
 ジャイルブレイク対策トレーニングが文書化され、再現可能であることを検証する。
 #10.1.5    レベル: 3    役割: V
 形式的なポリシー遵守の証明または認定監視が、重要な領域を網羅していることを検証する。

---

### 10.2 敵対的サンプルの堅牢化

改ざんされた入力に対する耐性を高める。堅牢なアドバーサリアルトレーニングとベンチマーク評価が現在の最良の実践です。

 #10.2.1    レベル: 1    役割: D
 プロジェクトのリポジトリに、再現性のあるシードを用いた敵対的訓練の設定が含まれていることを検証してください。
 #10.2.2    レベル: 2    役割: D/V
 敵対的サンプル検出が本番パイプラインで遮断アラートを発生させることを検証する。
 #10.2.4    レベル: 3    役割: V
 認定済みの頑健性証明または区間境界証明が、少なくとも最重要クラスをカバーしていることを検証する。
 #10.2.5    レベル: 3    役割: V
 回帰テストが適応的攻撃を用いて、測定可能な頑健性の低下がないことを確認する。

---

### 10.3 メンバーシップ-推論 緩和

訓練データに特定のレコードが含まれていたかどうかを判断する能力を制限する。差分プライバシーと信頼度スコアのマスキングは、現時点で知られている防御策の中で最も効果的である。

 #10.3.1    レベル: 1    役割: D
 クエリごとのエントロピー正則化または温度スケーリングが過剰に自信を持つ予測を低減することを検証する。
 #10.3.2    レベル: 2    役割: D
 機微データセットに対して、トレーニングが ε-有界な差分プライベート最適化を採用していることを検証してください。
 #10.3.3    レベル: 2    役割: V
 攻撃シミュレーション（シャドーモデルまたはブラックボックス）が、ホールドアウトデータ上で攻撃AUC ≤ 0.60を示すことを検証してください。

---

### 10.4 モデル-反転耐性

機微属性の再構築を防ぐ。最近の調査は、出力の切り捨てと微分プライバシーの保証を実用的な防御として強調している。

 #10.4.1    レベル: 1    役割: D
 機微属性が直接出力されないことを検証してください。必要に応じて、バケットまたは一方向変換を使用してください。
 #10.4.2    レベル: 1    役割: D/V
 同一のプリンシパルからの繰り返しの適応的クエリがクエリレート制限によって抑制されることを検証する。
 #10.4.3    レベル: 2    役割: D
 モデルがプライバシー保護ノイズを用いて訓練されていることを検証する。

---

### 10.5 モデル抽出防御

無断複製を検出し、抑止します。透かし技術とクエリパターン分析を推奨します。

 #10.5.1    レベル: 1    役割: D
 推論ゲートウェイが、モデルの記憶閾値に合わせて調整されたグローバルおよび APIキーごとのレート制限を適用していることを検証する。
 #10.5.2    レベル: 2    役割: D/V
 クエリ-エントロピーと入力-多様性の統計量が自動抽出検出器に供給されることを検証する。
 #10.5.3    レベル: 2    役割: V
 脆弱な水印または確率的水印が、疑われるクローンに対して、p < 0.01 で ≤ 1 000 回のクエリで証明できることを検証する。
 #10.5.4    レベル: 3    役割: D
 ウォーターマークキーとトリガーセットがハードウェアセキュリティモジュールに格納され、毎年ローテーションされることを確認してください。
 #10.5.5    レベル: 3    役割: V
 抽出アラートイベントに不正なクエリが含まれており、インシデント対応プレイブックと統合されていることを検証してください。

---

### 10.6 推論-時間 汚染-データ 検出

バックドアが仕込まれた入力と汚染された入力を識別し、無害化する。

 #10.6.1    レベル: 1    役割: D
 モデル推論の前に、入力が異常検出器（例：STRIP、consistency-scoring）を通過することを検証する。
 #10.6.2    レベル: 1    役割: V
 検出器の閾値が、クリーン/毒化された検証セット上で調整され、偽陽性を5%未満に抑えることを確認する。
 #10.6.3    レベル: 2    役割: D
 汚染されたとフラグ付けされた入力が、ソフトブロックおよび人間の審査ワークフローをトリガーすることを検証してください。
 #10.6.4    レベル: 2    役割: V
 検出器が適応的なトリガーなしバックドア攻撃に対してストレステストされていることを検証する。
 #10.6.5    レベル: 3    役割: D
 検出有効性指標がログに記録され、最新の脅威インテリジェンスを用いて定期的に再評価されていることを確認してください。

---

### 10.7 動的 セキュリティ ポリシー 適応

脅威情報と行動分析に基づくリアルタイムのセキュリティポリシー更新。

 #10.7.1    レベル: 1    役割: D/V
 エージェントを再起動することなくセキュリティポリシーを動的に更新できることを、ポリシーのバージョン整合性を維持したまま検証する。
 #10.7.2    レベル: 2    役割: D/V
 ポリシー更新が認可されたセキュリティ担当者によって暗号署名され、適用前に検証されることを確認する。
 #10.7.3    レベル: 2    役割: D/V
 動的ポリシー変更が、正当化、承認チェーン、ロールバック手順を含む完全な監査証跡として記録されることを検証する。
 #10.7.4    レベル: 3    役割: D/V
 適応型セキュリティ機構が、リスク文脈と行動パターンに基づいて脅威検知の感度を調整することを検証します。
 #10.7.5    レベル: 3    役割: D/V
 ポリシーの適応決定が説明可能であることを検証し、セキュリティチームの審査のための証跡を含める。

---

### 10.8 リフレクションに基づくセキュリティ分析

エージェントの自己反省とメタ認知分析を通じたセキュリティ検証。

 #10.8.1    レベル: 1    役割: D/V
 エージェントのリフレクション機構が、意思決定と行動に対するセキュリティ重視の自己評価を含んでいることを検証する。
 #10.8.2    レベル: 2    役割: D/V
 リフレクション出力が検証され、敵対的入力による自己評価機構の改ざんを防止することを確認する。
 #10.8.3    レベル: 2    役割: D/V
 メタ認知セキュリティ分析が、エージェントの推論プロセスにおける潜在的なバイアス、操作、または妥協を識別できることを検証する。
 #10.8.4    レベル: 3    役割: D/V
 リフレクションを用いたセキュリティ警告が、強化監視および人手介入の可能性があるワークフローをトリガーすることを検証する。
 #10.8.5    レベル: 3    役割: D/V
 セキュリティに関する洞察からの継続的な学習が、脅威検知を向上させ、正当な機能を低下させないことを検証する。

---

### 10.9 進化 & 自己改善 セキュリティ

自己改変と進化が可能なエージェントシステムのセキュリティ対策

 #10.9.1    レベル: 1    役割: D/V
 自己修正機能が指定された安全領域に限定され、形式検証の境界が適用されていることを検証する。
 #10.9.2    レベル: 2    役割: D/V
 実装前に進化提案がセキュリティ影響評価を受けることを確認する。
 #10.9.3    レベル: 2    役割: D/V
 自己改善メカニズムには、整合性検証を伴うロールバック機能が含まれていることを検証する。
 #10.9.4    レベル: 3    役割: D/V
 メタ学習のセキュリティが、改善アルゴリズムに対する敵対的な改変を防ぐことを検証する。
 #10.9.5    レベル: 3    役割: D/V
 再帰的自己改善が形式的安全性制約によって有界であることを、収束性に関する数学的証明を用いて検証する。

---

#### 参考文献

MITRE ATLAS adversary tactics for ML
NIST AI Risk Management Framework 1.0, 2023
OWASP Top 10 for LLM Applications, 2025
Adversarial Training: A Survey — Zhao et al., 2024
RobustBench adversarial-robustness benchmark
Membership-Inference & Model-Inversion Risk Survey, 2025
PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023
Model-Inversion Attacks & Defenses Survey — AI Review, 2025
Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024
Fragile Model Watermarking Survey — 2025
Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025
BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024

## 11 プライバシー保護と個人データ管理

### 統制目標

AIライフサイクル全体を通じて厳格なプライバシー保証を維持する—収集、訓練、推論、及びインシデント対応—個人データが、明確な同意、必要最小限の範囲、証明可能な消去、そして正式なプライバシー保証という条件のもとでのみ処理されるようにする。

---

### 11.1 匿名化およびデータ最小化

 #11.1.1    レベル: 1    役割: D/V
 直接識別子と準識別子が削除され、ハッシュ化されていることを検証する。
 #11.1.2    レベル: 2    役割: D/V
 自動監査が k-匿名性/l-多様性を測定し、閾値がポリシーを下回った場合に警告することを検証する。
 #11.1.3    レベル: 2    役割: V
 モデルの特徴量重要度レポートが、ε = 0.01 の相互情報量を超える識別子の漏洩がないことを証明していることを確認する。
 #11.1.4    レベル: 3    役割: V
 形式的証明または合成データの認証が、リンク攻撃を受けても再識別リスクが ≤ 0.05 であることを示すことを検証する。

---

### 11.2 忘却権と削除の実施

 #11.2.1    レベル: 1    役割: D/V
 データ主体削除リクエストが、生データセット、チェックポイント、埋め込み、ログ、バックアップに、30日未満のサービスレベル合意の範囲内で反映されることを検証してください。
 #11.2.2    レベル: 2    役割: D
 「machine-unlearning」ルーチンが、認定済みのアンラーニングアルゴリズムを用いて、実際に再訓練を行うか、あるいは削除を近似するかを検証する。
 #11.2.3    レベル: 2    役割: V
 アンラーニング後、シャドーモデル評価が忘却されたレコードが出力に与える影響が1%未満であることを検証する。
 #11.2.4    レベル: 3    役割: V
 削除イベントが改ざん不能に記録され、規制当局が監査できることを検証する。

---

### 11.3 差分-プライバシーの安全対策

 #11.3.1    レベル: 2    役割: D/V
 累積 ε がポリシー閾値を超えたときに、プライバシー損失集計ダッシュボードがアラートを出すことを検証する。
 #11.3.2    レベル: 2    役割: V
 ブラックボックス型のプライバシー監査が ε̂ を宣言値の10%以内に推定することを検証する。
 #11.3.3    レベル: 3    役割: V
 形式的証明が、訓練後のファインチューニングと埋め込みのすべてを網羅していることを確認する。

---

### 11.4 目的の限定とスコープクリープ防止

 #11.4.1    レベル: 1    役割: D
 すべてのデータセットおよびモデルのチェックポイントに、元の同意に沿った機械可読の目的タグが付与されていることを検証する。
 #11.4.2    レベル: 1    役割: D/V
 実行時モニターが、宣言された目的と整合しないクエリを検出し、ソフト拒否を発動することを検証する。
 #11.4.3    レベル: 3    役割: D
 ポリシー・アズ・コードのゲートが、DPIAレビューなしに新しいドメインへのモデルの再デプロイをブロックすることを検証する。
 #11.4.4    レベル: 3    役割: V
 形式的なトレーサビリティ証明が、すべての個人データのライフサイクルが同意された範囲内に留まることを示していることを検証する。

---

### 11.5 同意管理 & Lawful-Basis Tracking

 #11.5.1    レベル: 1    役割: D/V
 同意管理プラットフォーム（CMP）が各データ主体ごとに同意取得状況、目的、保持期間を記録していることを確認する。
 #11.5.2    レベル: 2    役割: D
 API が同意トークンを公開していることを検証する; モデルは推論を行う前にトークンのスコープを検証する必要がある。
 #11.5.3    レベル: 2    役割: D/V
 拒否された または 撤回された 同意 が、24 時間以内 に 処理 パイプライン を 停止 する こと を 検証 してください。

---

### 11.6 プライバシー制御を備えた連合学習

 #11.6.1    レベル: 1    役割: D
 クライアントの更新が集約前に局所差分プライバシー（LDP）ノイズを付加していることを確認する。
 #11.6.2    レベル: 2    役割: D/V
 トレーニング指標が差分プライバシー保護された状態であることを検証し、単一クライアントの損失を決して公開しないことを確認する。
 #11.6.3    レベル: 2    役割: V
 ポイズニング耐性を備えた集約が有効になっていることを確認してください。
 #11.6.4    レベル: 3    役割: V
 形式的証明が、全体の ε 予算を満たすとともに、ユーティリティ損失を 5 未満に抑えることを示していることを検証する。

---

#### 参考文献

GDPR & AI Compliance Best Practices
EU Parliament Study on GDPR & AI, 2020
ISO 31700-1:2023 — Privacy by Design for Consumer Products
NIST Privacy Framework 1.1 (2025 Draft)
Machine Unlearning: Right-to-Be-Forgotten Techniques
A Survey of Machine Unlearning, 2024
Auditing DP-SGD — ArXiv 2024
DP-SGD Explained — PyTorch Blog
Purpose-Limitation for AI — IJLIT 2025
Data-Protection Considerations for AI — URM Consulting
Top Consent-Management Platforms, 2025
Secure Aggregation in DP Federated Learning — ArXiv 2024

## C12 モニタリング, ロギング & 異常検知

### 統制目標

このセクションは、モデルおよび他のAIコンポーネントが何を見て、何をし、何を返すかについて、リアルタイムおよび法医学的な可視性を提供するための要件を示します。これにより、脅威を検知し、トリアージし、そこから学ぶことができるようになります。

### C12.1 リクエストとレスポンスのログ

 #12.1.1    レベル: 1    役割: D/V
 すべてのユーザーのプロンプトとモデルの応答が、適切なメタデータ（例：タイムスタンプ、ユーザーID、セッションID、モデルバージョン）とともにログに記録されていることを検証してください。
 #12.1.2    レベル: 1    役割: D/V
 ログがセキュアでアクセス制御されたリポジトリに保存されており、適切な保持ポリシーとバックアップ手順を備えていることを確認する。
 #12.1.3    レベル: 1    役割: D/V
 ログストレージシステムが静止時および転送中の暗号化を実装して、ログに含まれる機密情報を保護していることを検証する。
 #12.1.4    レベル: 1    役割: D/V
 プロンプトおよび出力内の機微データが、ログに記録される前に自動的に伏字化またはマスキングされることを検証し、PII（個人を特定できる情報）、認証情報、および機密情報に対して設定可能な伏字化ルールを適用する。
 #12.1.5    レベル: 2    役割: D/V
 ポリシー決定と安全フィルタリングのアクションが、コンテンツモデレーションシステムの監査およびデバッグを可能にするのに十分な詳細で記録されていることを検証する。
 #12.1.6    レベル: 2    役割: D/V
 ログの完全性が、例えば暗号署名や書き込み専用ストレージなどによって保護されていることを確認する。

---

### C12.2 乱用検出とアラート通知

 #12.2.1    レベル: 1    役割: D/V
 システムが既知の脱獄パターン、プロンプトインジェクションの試み、および敵対的入力を検知して警告し、署名ベースの検出を用いていることを検証する。
 #12.2.2    レベル: 1    役割: D/V
 システムが既存のセキュリティ情報イベント管理（SIEM）プラットフォームと、標準的なログ形式およびプロトコルを使用して統合されていることを検証します。
 #12.2.3    レベル: 2    役割: D/V
 強化されたセキュリティイベントに、AI特有の文脈として、モデル識別子、信頼度スコア、および安全フィルターの決定が含まれていることを確認してください。
 #12.2.4    レベル: 2    役割: D/V
 行動異常検知が、異常な会話パターン、過度なリトライ試行、または体系的な探査行動を識別することを検証する。
 #12.2.5    レベル: 2    役割: D/V
 潜在的なポリシー違反や攻撃の試みが検出された場合に、リアルタイムのアラート通知機構がセキュリティチームに通知することを検証する。
 #12.2.6    レベル: 2    役割: D/V
 協調的ジャイルブレイク試行、プロンプトインジェクションキャンペーン、モデル抽出攻撃を含むAI特有の脅威パターンを検出するためのカスタムルールが含まれていることを確認してください。
 #12.2.7    レベル: 3    役割: D/V
 自動化されたインシデント対応ワークフローが、侵害されたモデルを隔離し、悪意のあるユーザーをブロックし、重大なセキュリティイベントをエスカレートできることを確認する。

---

### C12.3 モデルドリフト検出

 #12.3.1    レベル: 1    役割: D/V
 システムが、精度、信頼度スコア、レイテンシ、エラーレートといった基本的なパフォーマンス指標を、モデルバージョンおよび時間経過にわたって追跡していることを検証する。
 #12.3.2    レベル: 2    役割: D/V
 性能指標が事前に定義された劣化閾値を超える場合、またはベースラインから大幅に逸脱する場合に、自動アラート通知がトリガーされることを検証する。
 #12.3.3    レベル: 2    役割: D/V
 幻覚検出モニターが、モデルの出力に事実と異なる情報、矛盾する情報、または捏造された情報が含まれる場合を識別してフラグすることを検証する。

---

### C12.4 パフォーマンス & 挙動のテレメトリ

 #12.4.1    レベル: 1    役割: D/V
 リクエストのレイテンシ、トークン消費量、メモリ使用量、スループットを含む運用指標が継続的に収集・監視されていることを検証する。
 #12.4.2    レベル: 1    役割: D/V
 成功率と失敗率が、エラーの種類と根本原因の分類とともに追跡されていることを確認してください。
 #12.4.3    レベル: 2    役割: D/V
 リソース利用状況の監視には、GPU/CPU使用率、メモリ使用量、およびストレージ要件が含まれており、閾値を超えた場合にアラートを発することを確認する。

---

### C12.5 AI インシデント対応計画と実行

 #12.5.1    レベル: 1    役割: D/V
 インシデント対応計画が、AI関連のセキュリティイベントを特に扱い、モデルの侵害、データ汚染、敵対的攻撃を含むことを確認してください。
 #12.5.2    レベル: 2    役割: D/V
 インシデント対応チームが、モデルの挙動と攻撃ベクトルを調査するためのAI専用のフォレンジックツールと専門知識にアクセスできることを検証する。
 #12.5.3    レベル: 3    役割: D/V
 インシデント後の分析に、モデルの再訓練の検討事項、安全フィルターの更新、および得られた教訓をセキュリティコントロールへ統合することを含むことを確認する。

---

### C12.5 AI 性能低下検出

時間の経過とともに、AIモデルの性能と品質の低下を監視し、検出する。

 #12.5.1    レベル: 1    役割: D/V
 モデルの正解率、適合率、再現率、および F1スコアが継続的に監視され、ベースライン閾値と比較されていることを検証する。
 #12.5.2    レベル: 1    役割: D/V
 データドリフト検出が、モデルの性能に影響を与える可能性のある入力分布の変化を監視していることを検証してください。
 #12.5.3    レベル: 2    役割: D/V
 概念ドリフト検出が、入力と期待出力の関係の変化を識別することを検証する。
 #12.5.4    レベル: 2    役割: D/V
 パフォーマンスの低下が自動アラートをトリガーし、モデルの再学習または置換ワークフローを開始することを検証します。
 #12.5.5    レベル: 3    役割: V
 パフォーマンス低下とデータの変更、インフラの問題、外部要因との相関を、劣化の根本原因分析が示していることを検証する。

---

### C12.6 DAG 可視化 & ワークフローのセキュリティ

ワークフローの可視化システムを情報漏洩と改ざん攻撃から保護する。

 #12.6.1    レベル: 1    役割: D/V
 有向非巡回グラフ（DAG）の可視化データが、格納または送信前に機密情報を除去するようにサニタイズされていることを検証する。
 #12.6.2    レベル: 1    役割: D/V
 ワークフローの可視化へのアクセス制御が、認可されたユーザーのみがエージェントの意思決定経路と推論の痕跡を閲覧できることを保証していることを確認してください。
 #12.6.3    レベル: 2    役割: D/V
 DAGデータの整合性が、暗号署名および改ざん検知可能な保存機構によって保護されていることを検証する。
 #12.6.4    レベル: 2    役割: D/V
 ワークフローの可視化システムが、細工されたノードまたはエッジデータを介して発生するインジェクション攻撃を防ぐための入力検証を実装していることを検証する。
 #12.6.5    レベル: 3    役割: D/V
 可視化システムへのDoS攻撃を防ぐため、リアルタイムのDAG（有向非巡回グラフ）更新がレート制限され、検証されていることを確認する。

---

### C12.7 積極的なセキュリティ挙動モニタリング

プロアクティブなエージェントの挙動分析を通じたセキュリティ脅威の検出と予防。

 #12.7.1    レベル: 1    役割: D/V
 実行前に、リスク評価の統合を伴い、プロアクティブなエージェントの挙動がセキュリティ検証済みであることを確認する。
 #12.7.2    レベル: 2    役割: D/V
 自律的イニシアティブのトリガーに、セキュリティコンテキスト評価と脅威動向評価が含まれていることを検証する。
 #12.7.3    レベル: 2    役割: D/V
 プロアクティブな行動パターンが潜在的なセキュリティへの影響と予期せぬ結果について分析されていることを検証する。
 #12.7.4    レベル: 3    役割: D/V
 セキュリティ上重要な予防的アクションが、監査証跡を備えた明示的な承認チェーンを必要とすることを検証する。
 #12.7.5    レベル: 3    役割: D/V
 行動異常検知が、侵害を示す可能性のあるプロアクティブエージェントのパターンの逸脱を検出することを検証してください。

---

### 参考文献

NIST AI Risk Management Framework 1.0 - Manage 4.1 and 4.3
ISO/IEC 42001:2023 — AI Management Systems Requirements - Annex B 6.2.6
EU AI Act — Article 12, 13, 16 and 19 on Logging and Record-keeping

## C13 人間による監督、説明責任、ガバナンス

### 統制目標

本章は、AIシステムにおける人間の監督と明確な説明責任の連鎖を維持するための要件を提供し、AIライフサイクル全体を通じて説明可能性・透明性・倫理的な管理を確保します。

---

### C13.1 キル-スイッチ & オーバーライド機構

AIシステムの安全でない挙動が観測された場合には、シャットダウンまたはロールバックの手順を提供してください。

 #13.1.1    レベル: 1    役割: D/V
 AIモデルの推論および出力を直ちに停止させる手動キルスイッチ機構が存在することを確認してください。
 #13.1.2    レベル: 1    役割: D
 オーバーライド制御 は 認可された 人員 のみ が アクセス できる ことを 確認してください。
 #13.1.3    レベル: 3    役割: D/V
 ロールバック手順が以前のモデルバージョンに戻せること、またはセーフモードでの動作に戻せることを検証する。
 #13.1.4    レベル: 3    役割: V
 オーバーライド機構が定期的にテストされていることを検証する。

---

### C13.2 人間を介在させるループの意思決定チェックポイント

事前に定義されたリスク閾値を超えた場合には、人間の承認を求める。

 #13.2.1    レベル: 1    役割: D/V
 高リスクのAIの判断が実行前に明示的な人間の承認を必要とすることを検証する。
 #13.2.2    レベル: 1    役割: D
 リスク閾値が明確に定義されていることを検証し、それらが自動的に人間による審査ワークフローを起動することを確認する。
 #13.2.3    レベル: 2    役割: D
 人間の承認を所定の時間内に取得できない場合に備え、時間制約のある意思決定にはフォールバック手順があることを検証する。
 #13.2.4    レベル: 3    役割: D/V
 適用可能であれば、エスカレーション手順が異なる意思決定タイプまたはリスクカテゴリごとに明確な権限レベルを定義していることを確認する。

---

### C13.3 責任の連鎖パターン & 監査可能性

オペレーターの操作とモデルの決定をログに記録する。

 #13.3.1    レベル: 1    役割: D/V
 すべてのAIシステムの意思決定と人間の介入が、タイムスタンプ、ユーザー識別情報、および意思決定の根拠とともにログに記録されていることを確認してください。
 #13.3.2    レベル: 2    役割: D
 監査ログが改ざんされていないことを検証し、整合性検証機構を含める。

---

### C13.4 説明可能-AI の手法

表層特徴量の重要性、反事実、および局所的な説明。

 #13.4.1    レベル: 1    役割: D/V
 AIシステムがその決定について、人間が読める形式で基本的な説明を提供することを検証する。
 #13.4.2    レベル: 2    役割: V
 説明の品質が人間による評価研究と指標によって検証されていることを確認する。
 #13.4.3    レベル: 3    役割: D/V
 重要な意思決定に対して、特徴量の重要度スコアまたはアトリビューション手法（SHAP、LIME など）が利用可能であることを検証する。
 #13.4.4    レベル: 3    役割: V
 ユースケースとドメインに適用可能な場合に限り、入力をどのように変更すれば結果を変えられるかを示す反事実説明を検証してください。

---

### C13.5 モデルカードと使用開示

意図した用途、性能指標、倫理的配慮のためにモデルカードを維持する。

 #13.5.1    レベル: 1    役割: D
 モデルカードが、意図された使用事例、制限、および既知の故障モードを文書化していることを検証する。
 #13.5.2    レベル: 1    役割: D/V
 適用可能な各ユースケースにおけるパフォーマンス指標が開示されていることを検証する。
 #13.5.3    レベル: 2    役割: D
 倫理的配慮、バイアス評価、公平性評価、トレーニングデータの特徴、および既知のトレーニングデータの制限が文書化され、定期的に更新されていることを検証する。
 #13.5.4    レベル: 2    役割: D/V
 モデルカードがバージョン管理され、モデルのライフサイクル全体を通じて変更追跡機能とともに維持されることを検証する。

---

### C13.6 不確実性の定量化

応答に信頼度スコアまたはエントロピー指標を伝播させる。

 #13.6.1    レベル: 1    役割: D
 AIシステムが出力とともに信頼度スコアまたは不確実性指標を提供することを検証する。
 #13.6.2    レベル: 2    役割: D/V
 不確実性の閾値が追加の人間による審査または代替的な意思決定経路を引き起こすことを検証する。
 #13.6.3    レベル: 2    役割: V
 不確実性定量化手法が、真値データに対して校正され、検証されていることを確認する。
 #13.6.4    レベル: 3    役割: D/V
 マルチステップのAIワークフローを通じて、不確実性の伝搬が維持されていることを検証する。

---

### C13.7 ユーザー-向け透明性レポート

インシデント、ドリフト、データ使用に関する定期的な開示を提供します。

 #13.7.1    レベル: 1    役割: D/V
 データ利用ポリシーおよびユーザー同意管理の慣行が、利害関係者に対して明確に伝達されていることを検証する。
 #13.7.2    レベル: 2    役割: D/V
 AI影響評価が実施され、結果が報告に含まれていることを確認してください。
 #13.7.3    レベル: 2    役割: D/V
 定期的に公表される透明性レポートが、AIのインシデントと運用指標を適切な程度の詳細で開示していることを検証する。

#### 参考文献

EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
ISO/IEC 42001:2023 — AI Management Systems Requirements
NIST AI Risk Management Framework 1.0
NIST SP 800-53 Revision 5 — Security and Privacy Controls
A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)
Model Cards for Model Reporting (Mitchell et al., 2018)
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)
ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods
IEEE 7001-2021 — Transparency of Autonomous Systems
GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)
Human Oversight under Article 14 of the EU AI Act (Fink, 2025)

## 付録A: 用語集

This この包括的な用語集は、AISVS 全体で使用される主要な人工知能（AI）、機械学習（ML）、およびセキュリティ用語の定義を提供し、明確さと共通理解を確保します。

敵対的サンプル: AIモデルが誤作動するように意図的に作成された入力であり、しばしば人間には知覚できない微小な摂動を加えることによって引き起こされる。
​
敵対的頑健性 – AIにおける敵対的頑健性とは、モデルの性能を維持し、誤作動を引き起こすことを意図して作成された悪意ある入力によってだまされたり操作されたりするのを防ぐ能力を指す。
​
エージェント – AIエージェントは、ユーザーに代わって目標を追求し、タスクを完了させるためにAIを用いたソフトウェアシステムです。彼らは推論、計画、記憶を示し、意思決定を行い、学習し、適応する自律性をある程度持っています。
​
エージェント性を持つAI: 目標を達成するために一定の自律性を持って動作できるAIシステムであり、しばしば人間の直接的な介入なしに意思決定を行い、行動を起こす。
​
属性ベースアクセス制御（ABAC）：ユーザー、リソース、アクション、環境の属性に基づいて認可決定を行い、クエリ時に評価されるアクセス制御のパラダイム。
​
バックドア攻撃: モデルが特定のトリガーに対して特定の応答をするよう訓練され、その他は通常通り動作するデータポイズニング攻撃の一種。
​
バイアス: AIモデルの出力における系統的な偏りは、特定の集団や特定の文脈において不公平または差別的な結果を生じさせる可能性がある。
​
バイアスの悪用: 人工知能モデルに存在する既知のバイアスを利用して、出力や結果を操作する攻撃手法。
​
Cedar: AI システムの ABAC を実装する際に用いられる、細粒度の権限を扱う Amazon のポリシー言語とエンジン。
​
思考の連鎖（Chain of Thought）：言語モデルの推論を改善するための手法で、最終的な回答を生成する前に中間の推論ステップを生成する。
​
サーキットブレーカー: 特定のリスク閾値を超えた場合に、AIシステムの運用を自動的に停止させる仕組み。
​
データ漏洩：AIモデルの出力や挙動を通じた機密情報の意図しない露出。
​
データ汚染: モデルの完全性を損なうために、学習データを意図的に改ざんする行為。多くはバックドアの設置や性能の低下を狙う。
​
差分プライバシーは、データセットに関する統計情報を公開する際に個々のデータ主体のプライバシーを保護する、数学的に厳密な枠組みです。これにより、データ保有者はグループ全体の集計パターンを共有しつつ、特定の個人に関する情報の漏えいを制限できます。
​
埋め込み表現：テキストや画像などのデータを高次元空間で意味を捉える密なベクトル表現。
​
説明可能性 – AIにおける説明可能性は、AIシステムがその意思決定と予測に対して人間が理解できる理由を提供する能力であり、内部動作への洞察を提供します。
​
説明可能な人工知能（XAI）：決定と行動に対して人間が理解できる説明を提供するために、さまざまな技術とフレームワークを用いて設計された人工知能システム。
​
連邦学習（フェデレーテッドラーニング）: ローカルデータサンプルを保持する複数の分散デバイス上で、データ自体を交換することなくモデルを訓練する機械学習のアプローチ。
​
ガードレール: AI システムが有害な、偏った、またはその他望ましくない出力を生成するのを防ぐために実装された制約。
​
幻覚 – AIの幻覚とは、AIモデルが訓練データや事実の現実に基づかない、誤ったまたは誤解を招く情報を生成する現象を指します。
​
ヒューマン・イン・ザ・ループ（HITL）：重要な意思決定のポイントで、人間の監視、検証、または介入を必要とするよう設計されたシステム。
​
Infrastructure as Code (IaC): コードを用いてインフラストラクチャを管理・プロビジョニングすることで、手動プロセスを排除し、セキュリティスキャンを可能にし、一貫したデプロイを実現します。
​
ジャイルブレイク: AIシステムの安全ガードレールを回避するために用いられる手法、特に大規模言語モデルにおいて、禁止コンテンツを生成することを目的とする。
​
最小権限の原則: ユーザーおよびプロセスに対して、必要最小限のアクセス権のみを付与するセキュリティ原則。
​
LIME（局所的に解釈可能なモデル-非依存の説明）: 任意の機械学習分類器の予測を、解釈可能なモデルで局所的に近似することによって説明する手法。
​
メンバーシップ推論攻撃: 特定のデータポイントが機械学習モデルの訓練に使用されたかどうかを判定することを目的とする攻撃。
​
MITRE ATLAS: 人工知能システムに対する敵対的脅威の全体像; 人工知能システムに対する敵対的な戦術と技術の知識ベース。
​
モデルカード – モデルカードとは、AIモデルの性能、制限、意図された用途、倫理的配慮について標準化された情報を提供する文書です。
​
モデル抽出攻撃: 攻撃者が標的モデルに対して繰り返しクエリを送信し、許可なく機能的に類似したコピーを作成する。
​
モデル反転攻撃: モデルの出力を分析して学習データを再構築しようとする攻撃。
​
モデルライフサイクル管理 – AIモデルのライフサイクル管理は、AIモデルの存在における全段階を監督するプロセスであり、設計、開発、デプロイ、監視、保守、そして最終的な退役を含むことで、AIモデルが有効で目的に沿っている状態を維持することを目的とします。
​
モデルポイズニング：トレーニング過程でモデルに直接脆弱性やバックドアを注入すること。
​
モデル盗用：専有モデルのコピーまたは近似を、繰り返しのクエリを通じて抽出すること。
​
マルチエージェントシステム: 複数の相互作用するAIエージェントで構成され、各エージェントは潜在的に異なる能力と目標を持つ。
​
OPA（Open Policy Agent）：スタック全体にわたる統一的なポリシー適用を可能にするオープンソースのポリシーエンジン。
​
プライバシー保護機械学習（PPML）：学習データのプライバシーを保護しながら、機械学習モデルを訓練・展開するための技術と手法。
​
プロンプトインジェクション攻撃: 入力に悪意のある指示が埋め込まれ、モデルの意図した挙動を上書きする攻撃。
​
RAG（Retrieval-Augmented Generation、情報検索を組み込んだ生成）: 応答を生成する前に外部知識ソースから関連情報を取得して大規模言語モデルを強化する技術。
​
レッドチーミング: AIシステムを対象に、敵対的な攻撃をシミュレートして脆弱性を特定するための積極的なテストの実践。
​
SBOM（Software Bill of Materials）: ソフトウェアやAIモデルの構築に使用されるさまざまな部品の詳細とサプライチェーンの関係を含む公式な記録。
​
SHAP（SHapley Additive exPlanations）：予測に対する各特徴量の寄与度を計算することによって、任意の機械学習モデルの出力を説明するゲーム理論的アプローチ。
​
サプライチェーン攻撃: サプライチェーン内の安全性が低い要素を標的とすることでシステムを侵害する行為。例として、サードパーティ製ライブラリ、データセット、または事前学習済みモデルなどが挙げられる。
​
転移学習: あるタスクのために開発されたモデルを、別のタスクのモデルの出発点として再利用する手法。
​
ベクトルデータベース： 高次元ベクトル（埋め込み）を格納し、効率的な類似検索を実行するよう設計された特殊なデータベース。
​
脆弱性スキャン: AIフレームワークや依存関係を含むソフトウェア部品の既知のセキュリティ脆弱性を識別する自動ツール。
​
透かし技術: AI生成コンテンツに知覚できないマーカーを埋め込み、その出所を追跡したりAI生成であることを検出したりする手法。
​
ゼロデイ脆弱性: 開発者がパッチを作成して配布する前に、攻撃者が悪用できる、以前は未知であった脆弱性。

## 付録 B: 参考文献

### TODO

## 付録 C： AIセキュリティ ガバナンスとドキュメンテーション

### 目的

この付録は、システムライフサイクル全体を通じてAIセキュリティを統治するために、組織構造・方針・プロセスを確立する基盤となる要件を提供します。

---

### AC.1 AIリスク管理フレームワークの採用

システムライフサイクル全体を通じて、AI‑特有のリスクを特定・評価・緩和するための正式なフレームワークを提供する。

 #AC.1.1    レベル: 1    役割: D/V
 AI‑専用のリスク評価手法が文書化され、実装されていることを確認する。
 #AC.1.2    レベル: 2    役割: D
 AIライフサイクルの重要なポイントと重大な変更の前に、リスク評価が実施されていることを確認してください。
 #AC.1.3    レベル: 3    役割: D/V
 リスク管理フレームワークが確立された標準（例：NIST AI RMF）に適合していることを検証する。

---

### AC.2 AIセキュリティ方針と手順

安全なAIの開発・展開・運用のための組織標準を定義し、それを遵守させる。

 #AC.2.1    レベル: 1    役割: D/V
 文書化されたAIセキュリティ方針が存在することを確認してください。
 #AC.2.2    レベル: 2    役割: D
 ポリシーが少なくとも年に1回、さらには重大な脅威環境の変化後にも見直され、更新されていることを確認する。
 #AC.2.3    レベル: 3    役割: D/V
 ポリシーが AISVS のすべてのカテゴリおよび適用される規制要件に対応していることを検証してください。

---

### AC.3 AIセキュリティの役割と責任

組織全体におけるAIセキュリティの説明責任を明確にする。

 #AC.3.1    レベル: 1    役割: D/V
 AIセキュリティの役割と責任が文書化されていることを確認する。
 #AC.3.2    レベル: 2    役割: D
 責任者が適切なセキュリティ専門知識を有していることを確認してください。
 #AC.3.3    レベル: 3    役割: D/V
 高リスクのAIシステムのために、AI倫理委員会またはガバナンス委員会が設置されていることを確認する。

---

### AC.4 倫理的AIガイドラインの執行

AIシステムが確立された倫理原則に従って動作するようにする。

 #AC.4.1    レベル: 1    役割: D/V
 AIの開発と展開に関する倫理ガイドラインが存在することを確認する。
 #AC.4.2    レベル: 2    役割: D
 倫理的違反を検出し、報告するための仕組みが整っていることを確認する。
 #AC.4.3    レベル: 3    役割: D/V
 展開済みのAIシステムに対する定期的な倫理審査が実施されていることを確認する。

---

### AC.5 AI 規制 遵守 モニタリング

進化するAI規制を認識し、それらを遵守する。

 #AC.5.1    レベル: 1    役割: D/V
 適用されるAI規制を特定するためのプロセスが存在することを検証する。
 #AC.5.2    レベル: 2    役割: D
 すべての規制要件への適合性が評価されていることを確認してください。
 #AC.5.3    レベル: 3    役割: D/V
 規制の変更がAIシステムの適時なレビューと更新を促すことを検証する。

### AC.6 トレーニングデータのガバナンス、文書化およびプロセス

 #1.1.2    レベル: 1    役割: D/V
 品質、代表性、倫理的調達、およびライセンス遵守を検証済みのデータセットのみが許可されていることを確認し、データポイズニング、潜在的なバイアス、知的財産侵害のリスクを低減します。
 #1.1.5    レベル: 2    役割: D/V
 ラベリング/アノテーションの品質が、レビュアーによるクロスチェックまたは合意によって担保されていることを確認する。
 #1.1.6    レベル: 2    役割: D/V
 重要なトレーニングデータセットについて、「データカード」または「データセット用データシート」が維持されていることを確認し、特徴、動機、構成、収集プロセス、前処理、推奨/非推奨の用途を詳述する。
 #1.3.2    レベル: 2    役割: D/V
 特定されたバイアスが、文書化された戦略（再均衡、標的データ拡張、アルゴリズム調整（例：前処理、学習過程での処理、後処理の技術）、または再重み付け）を通じて緩和されていることを検証し、緩和の影響が公平性と全体的なモデル性能の両方に及ぶことを評価します。
 #1.3.3    レベル: 2    役割: D/V
 訓練後の公平性指標が評価され、文書化されていることを確認する。
 #1.3.4    レベル: 3    役割: D/V
 ライフサイクルのバイアス管理ポリシーが責任者とレビューの頻度を割り当てることを検証する。
 #1.4.1    レベル: 2    役割: D/V
 明確なガイドラインを通じて、レビュアー間のクロスチェック、合意形成メカニズム（例：アノテータ間の一致度の監視）、そして不一致を解消するための定義済みプロセスにより、ラベリング/アノテーション品質が担保されることを検証する。
 #1.4.4    レベル: 3    役割: D/V
 安全性、セキュリティ、または公平性にとって重要なラベルが、必須の独立した二重審査または同等の堅牢な検証を受けることを確認する。
 #1.4.6    レベル: 2    役割: D/V
 ラベリングガイドラインと指示が包括的で、バージョン管理されており、査読済みであることを検証する。
 #1.4.6    レベル: 2    役割: D/V
 ラベルのデータスキーマが明確に定義され、かつバージョン管理されていることを確認してください。
 #1.3.1    レベル: 1    役割: D/V
 データセットが、法的に保護された属性（例：人種、性別、年齢）およびモデルの適用ドメインに関連するその他の倫理的に敏感な特性（例：社会経済的地位、所在地）にわたる代表性の不均衡と潜在的な偏りについてプロファイリングされていることを検証する。
 #1.5.3    レベル: 2    役割: V
 ドメインの専門家による手動のスポットチェックが、統計的に有意な標本数をカバーしていることを検証し、自動化で検出されない微妙な品質問題を特定する。
 #1.8.4    レベル: 2    役割: D/V
 外部委託またはクラウドソーシングによるラベリングワークフローが、データの機密性、完全性、ラベル品質を確保し、データ漏洩を防ぐための技術的および手続き上の保護措置を含んでいることを検証する。
 #1.5.4    レベル: 2    役割: D/V
 是正措置の手順が出所記録に追記されていることを検証する。
 #1.6.2    レベル: 2    役割: D/V
 フラグが付けられたサンプルがトレーニングの前に手動審査を開始することを検証する。
 #1.6.3    レベル: 2    役割: V
 結果がモデルのセキュリティ・ドシエに取り込まれ、継続的な脅威情報に寄与していることを確認する。
 #1.6.4    レベル: 3    役割: D/V
 新しい脅威情報を取り入れて、検出ロジックが更新されていることを検証する。
 #1.6.5    レベル: 3    役割: D/V
 オンライン-learningパイプラインが分布ドリフトを監視していることを検証する。
 #1.7.1    レベル: 1    役割: D/V
 トレーニングデータ削除ワークフローが一次データおよび派生データを完全に削除することを検証し、モデルへの影響を評価し、影響を受けたモデルについても評価が行われ、必要に応じて再訓練または再調整を通じて対処されることを確認する。
 #1.7.2    レベル: 2    役割: D
 データを学習に使用する際、ユーザー同意の範囲と状態（および撤回）を追跡し、尊重する仕組みが整備されていることを確認し、データが新しい学習プロセスまたは重要なモデル更新に組み込まれる前に同意が検証されることを確認してください。
 #1.7.3    レベル: 2    役割: V
 ワークフローが毎年テストされ、監査ログに記録されていることを確認してください。
 #1.8.1    レベル: 2    役割: D/V
 第三者データ供給者（事前学習済みモデルの提供者および外部データセットを含む）が、データまたはモデルが統合される前に、セキュリティ、プライバシー、倫理的調達、データ品質に関するデューデリジェンスを受けていることを確認する。
 #1.8.2    レベル: 1    役割: D
 外部転送がTLS/認証および整合性チェックを使用していることを検証する。
 #1.8.3    レベル: 2    役割: D/V
 センシティブなアプリケーションでの使用前に、高リスクのデータソース（例：出所が不明なオープンソースデータセット、審査を経ていないサプライヤー）が、サンドボックス分析、広範な品質・バイアス検査、そして標的化データ中毒検出といった強化された精査を受けることを確認してください。
 #1.8.4    レベル: 3    役割: D/V
 第三者から取得した事前学習済みモデルが、埋め込みバイアス、潜在的なバックドア、アーキテクチャの完全性、および元の学習データの出所について、ファインチューニング前またはデプロイ前に評価されていることを検証してください。
 #1.5.3    レベル: 2    役割: D/V
 敵対的トレーニングが使用される場合、敵対的データセットの生成、管理、およびバージョン管理が文書化され、統制されていることを検証する。
 #1.5.3    レベル: 3    役割: D/V
 敵対的ロバストネス訓練がモデルの性能（クリーン入力と敵対的入力の両方に対して）および公平性指標に与える影響が、評価され、文書化され、モニタリングされていることを検証する。
 #1.5.4    レベル: 3    役割: D/V
 敵対的訓練と頑健性の戦略が、進化する敵対的攻撃手法に対抗するために、定期的に見直し、更新されていることを検証する。
 #1.4.2    レベル: 2    役割: D/V
 失敗したデータセットが監査証跡付きで隔離されていることを検証する。
 #1.4.3    レベル: 2    役割: D/V
 例外が承認されていない限り、品質ゲートが低品質のデータセットをブロックすることを確認してください。
 #1.11.2    レベル: 2    役割: D/V
 合成データの生成プロセス、パラメータ、および意図された用途が文書化されていることを確認してください。
 #1.11.3    レベル: 2    役割: D/V
 訓練に使用する前に、合成データがバイアス、個人情報漏洩、および表現上の問題についてリスク評価されていることを検証する。
 #1.12.3    レベル: 2    役割: D/V
 疑わしいアクセスイベントに対してアラートが生成され、迅速に調査されることを確認する。
 #1.13.1    レベル: 1    役割: D/V
 すべての訓練データセットについて、明示的な保持期間が定義されていることを確認してください。
 #1.13.2    レベル: 2    役割: D/V
 データセットがライフサイクルの終了時に自動的に有効期限切れになる、削除される、または削除のために審査されることを検証してください。
 #1.13.3    レベル: 2    役割: D/V
 データの保持および削除の操作が記録され、監査可能であることを検証する。
 #1.14.1    レベル: 2    役割: D/V
 すべてのデータセットについて、データ居住要件および越境転送要件が特定され、適用されていることを検証する。
 #1.14.2    レベル: 2    役割: D/V
 データ処理において、医療、金融などの業界別規制が特定され、適切に対処されていることを確認する。
 #1.14.3    レベル: 2    役割: D/V
 関連するプライバシー法（例：GDPR、CCPA）への準拠が文書化され、定期的に見直されていることを確認してください。
 #1.16.1    レベル: 2    役割: D/V
 データ主体のアクセス権、訂正、処理の制限、または異議申立ての要求に対応する仕組みが存在することを確認してください。
 #1.16.2    レベル: 2    役割: D/V
 リクエストが記録され、追跡され、法定期限内に処理されていることを検証する。
 #1.16.3    レベル: 2    役割: D/V
 データ主体の権利に関する手続きが定期的に効果を発揮するよう、テストおよび見直しが行われていることを検証する。
 #1.17.1    レベル: 2    役割: D/V
 データセットのバージョンを更新または置換する前に、影響分析が実施されることを確認し、その分析がモデルの性能、公平性、コンプライアンスを含むものであることを保証する。
 #1.17.2    レベル: 2    役割: D/V
 影響分析の結果が文書化され、関連する利害関係者によってレビューされることを確認する。
 #1.17.3    レベル: 2    役割: D/V
 新しいバージョンが許容できないリスクや回帰をもたらす場合に備えて、ロールバック計画が存在することを確認する。
 #1.18.1    レベル: 2    役割: D/V
 データアノテーションに携わる全ての人員が身元調査を受け、データセキュリティとプライバシーに関する訓練を受けていることを確認してください。
 #1.18.2    レベル: 2    役割: D/V
 すべてのアノテーション担当者が機密保持契約に署名していることを確認してください。
 #1.18.3    レベル: 2    役割: D/V
 アノテーションプラットフォームがアクセス制御を適用し、内部脅威を監視していることを検証する。

#### 参考文献

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
EU Artificial Intelligence Act — Regulation (EU) 2024/1689
ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods

## 付録 D: AIを活用したセキュアコーディングのガバナンスと検証

### 目的

本章は、ソフトウェア開発におけるAIを活用したコーディングツールの安全かつ効果的な利用のための基本的な組織統制を定義し、SDLC全体にわたりセキュリティと追跡可能性を確保します。

---

### AD.1 AI支援の セキュアコーディング ワークフロー

既存のセキュリティゲートを弱体化させることなく、組織の secure‑software‑development ライフサイクル（SSDLC）に AI ツールを統合する。

 #AD.1.1    レベル: 1    役割: D/V
 文書化されたワークフローが、AIツールがいつ・どのようにコードを生成・リファクタリング・レビューできるかを説明していることを確認する。
 #AD.1.2    レベル: 2    役割: D
 ワークフローがSSDLCの各フェーズ（設計、実装、コードレビュー、テスト、デプロイ）に対応していることを検証してください。
 #AD.1.3    レベル: 3    役割: D/V
 AI‑生成コードに対して、脆弱性密度、mean‑time‑to‑detect などの指標が収集され、人間‑のみのベースラインと比較されることを検証する。

---

### AD.2 AIツールの適格性評価と脅威モデリング

AI コーディングツールは、導入前にセキュリティ機能、リスク、サプライ‑チェーンへの影響を評価されるべきです。

 #AD.2.1    レベル: 1    役割: D/V
 各AIツールの脅威モデルが悪用、モデル反転、データ漏洩、および依存関係チェーンのリスクを特定していることを検証する。
 #AD.2.2    レベル: 2    役割: D
 ツール評価が、ローカルコンポーネントの静的・動的解析とSaaSエンドポイントの評価（TLS、認証/認可、ログ記録）を含むことを確認してください。
 #AD.2.3    レベル: 3    役割: D/V
 評価が公認のフレームワークに従っていることを確認し、主要バージョン変更後に再実施されることを確認する。

---

### AD.3 セキュア プロンプト & コンテキスト管理

AIモデルのプロンプトやコンテキストを作成する際に、機密情報、独自コード、個人データの流出を防ぐ。

 #AD.3.1    レベル: 1    役割: D/V
 書面による指針が、プロンプト内で秘密情報、認証情報、または機密データを送信することを禁止していることを確認してください。
 #AD.3.2    レベル: 2    役割: D
 技術的統制（クライアントサイドの伏字化、承認済みのコンテキストフィルター）が機微なアーティファクトを自動的に除去することを検証してください。
 #AD.3.3    レベル: 3    役割: D/V
 プロンプトとレスポンスがトークン化され、通信中および保存時に暗号化され、保持期間がデータ分類ポリシーに準拠していることを検証します。

---

### AD.4 AI‑生成コードの検証

コードがマージまたはデプロイされる前に、AIの出力によって導入された脆弱性を検出し、是正してください。

 #AD.4.1    レベル: 1    役割: D/V
 AIが生成したコードは必ず人間によるコードレビューの対象とされることを検証する。
 #AD.4.2    レベル: 2    役割: D
 AI‑generatedコードを含むすべてのプルリクエストに対して自動スキャナー（SAST/IAST/DAST）が実行され、重大な所見がある場合にはマージをブロックすることを検証してください。
 #AD.4.3    レベル: 3    役割: D/V
 差分ファズテストやプロパティベースのテストが、入力検証や認可ロジックなどのセキュリティ上重要な挙動を証明することを確認する。

---

### AD.5 コード提案の説明可能性と追跡可能性

監査人と開発者に、提案がなぜ出されたのか、そしてそれがどのように進化したのかについて洞察を提供する。

 #AD.5.1    レベル: 1    役割: D/V
 プロンプト/レスポンスのペアがコミットIDとともにログに記録されていることを確認する。
 #AD.5.2    レベル: 2    役割: D
 開発者が提案を裏付けるモデルの出典情報（トレーニングの抜粋、ドキュメント）を提示できることを確認する。
 #AD.5.3    レベル: 3    役割: D/V
 説明可能性レポートが設計成果物とともに保存され、セキュリティレビューで参照されていることを確認し、ISO/IEC 42001の追跡性原則を満たす。

---

### AD.6 継続的なフィードバックとモデルのファインチューニング

時間の経過とともにモデルのセキュリティ性能を向上させつつ、ネガティブ・ドリフトを防ぐ。

 #AD.6.1    レベル: 1    役割: D/V
 開発者が不安全または不適合な提案をフラグ付けできること、そしてフラグが追跡されることを確認します。
 #AD.6.2    レベル: 2    役割: D
 集約されたフィードバックが、定期的なファインチューニングまたは取得型生成に反映されることを、検証済みのセキュア‑コーディングコーパス（例：OWASP Cheat Sheets）を用いて確認する。
 #AD.6.3    レベル: 3    役割: D/V
 各ファインチューニングの後に、クローズドループ評価ハーネスが回帰テストを実行することを確認する。展開前には、セキュリティ指標が以前のベースラインを満たすか、またはそれを上回る必要がある。

---

#### 参考文献

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
OWASP Secure Coding Practices — Quick Reference Guide

## 付録 E: ツールとフレームワークの例

### 目的

本章では、特定の AISVS 要件の実装または達成を支援できるツールとフレームワークの例を提供します。これらは AISVS チームまたは OWASP GenAI Security Project による推奨事項または賛同としてみなされるべきものではありません。

---

### AE.1 訓練データのガバナンス & バイアスの管理

データ分析、データガバナンス、バイアス管理のためのツール群。

 #AE.1.1    セクション: 1.1
 データ在庫ツール: データ在庫管理ツールのような...
 #AE.1.2    セクション: 1.2
 転送中の暗号化 HTTPSベースのアプリケーションには TLS を使用し、OpenSSL のようなツールや Python のツールを用います`ssl` ライブラリ.

---

### AE.2 ユーザー入力検証

ユーザー入力を処理し、検証するツール。

 #AE.2.1    セクション: 2.1
 プロンプトインジェクション防御ツール: NVIDIAの NeMo や Guardrails AI のようなガードレールツールを使用する。

---

