# Frontispicio

## Acerca del Estándar

El Estándar de Verificación de Seguridad de Inteligencia Artificial (AISVS) es un catálogo impulsado por la comunidad de requisitos de seguridad que científicos de datos, ingenieros de MLOps, arquitectos de software, desarrolladores, probadores, profesionales de seguridad, proveedores de herramientas, reguladores y consumidores pueden utilizar para diseñar, construir, probar y verificar sistemas y aplicaciones habilitados para IA confiables. Proporciona un lenguaje común para especificar controles de seguridad a lo largo del ciclo de vida de la IA, desde la recopilación de datos y el desarrollo de modelos hasta el despliegue y el monitoreo continuo, de modo que las organizaciones puedan medir y mejorar la resiliencia, la privacidad y la seguridad de sus soluciones de IA.

## Derechos de autor y licencia

Versión 0.1 (Primer Borrador Público - Trabajo en Progreso), 2025  

![license](../images/license.png)

Copyright © 2025 El Proyecto AISVS.  

Publicado bajo la[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
Para cualquier reutilización o distribución, debe comunicar claramente los términos de la licencia de este trabajo a otros.

## Líderes de Proyecto

|            |                         |
| ---------- | ----------------------- |
| Jim Manico | Aras “Russ” Memisyazici |

## Colaboradores y Revisores

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS es un estándar completamente nuevo creado específicamente para abordar los desafíos únicos de seguridad de los sistemas de inteligencia artificial. Aunque se inspira en las mejores prácticas de seguridad más amplias, cada requisito en AISVS se ha desarrollado desde cero para reflejar el panorama de amenazas de la IA y ayudar a las organizaciones a construir soluciones de IA más seguras y resistentes.

