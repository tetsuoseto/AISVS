# प्रस्तावना

कृत्रिम बुद्धिमत्ता सुरक्षा सत्यापन मानक (AISVS) संस्करण 1.0 में आपका स्वागत है!

## परिचय

2025 में एक सहयोगात्मक सामुदायिक प्रयास के माध्यम से स्थापित, AISVS उन सुरक्षा आवश्यकताओं को परिभाषित करता है जिन्हें आधुनिक AI मॉडल, पाइपलाइनों, और AI-सक्षम सेवाओं को डिज़ाइन, विकसित, तैनात, और संचालित करते समय ध्यान में रखना चाहिए।

AISVS v1.0 इसके परियोजना प्रमुखों, कार्य समूह, और व्यापक समुदाय योगदानकर्ताओं के संयुक्त कार्य का प्रतिनिधित्व करता है ताकि AI सिस्टम्स की सुरक्षा के लिए एक व्यावहारिक, परीक्षण योग्य आधार तैयार किया जा सके।

इस रिलीज़ के साथ हमारा लक्ष्य AISVS को अपनाना आसान बनाना है, साथ ही इसके परिभाषित दायरे पर पूरी तरह ध्यान केंद्रित रखना और AI से संबंधित तेजी से बदलते जोखिम परिदृश्य को संबोधित करना है।

## AISVS संस्करण 1.0 के लिए मुख्य उद्देश्य

संस्करण 1.0 कई मार्गदर्शक सिद्धांतों के साथ बनाया जाएगा।

### स्पष्ट परिभाषित क्षेत्र

प्रत्येक आवश्यकता AISVS के नाम और मिशन के अनुरूप होनी चाहिए:

* कृत्रिम बुद्धिमत्ता – नियंत्रण AI/ML स्तर (डेटा, मॉडल, पाइपलाइन, या अनुमान) पर संचालित होते हैं और AI विशेषज्ञों की जिम्मेदारी होती है।
* सुरक्षा – आवश्यकताएँ सीधे पहचाने गए सुरक्षा, गोपनीयता, या सुरक्षा जोखिमों को कम करती हैं।
* सत्यापन – भाषा इस प्रकार लिखी जाती है कि अनुपालन का वस्तुनिष्ठ रूप से सत्यापन किया जा सके।
* मानक – अनुभाग एक सुसंगत संरचना और शब्दावली का पालन करते हैं ताकि एक संगत संदर्भ बन सके।
  ​
---

AISVS का पालन करके, संगठन अपने AI समाधानों की सुरक्षा स्थिति का व्यवस्थित रूप से मूल्यांकन और मजबूत कर सकते हैं, जिससे सुरक्षित AI इंजीनियरिंग की संस्कृति को बढ़ावा मिलता है।

