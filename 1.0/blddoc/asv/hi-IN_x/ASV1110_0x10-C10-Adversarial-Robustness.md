# 10 प्रतिद्वंद्वी मजबूती और गोपनीयता रक्षा

## नियंत्रण उद्देश्य

सुनिश्चित करें कि AI मॉडल बचाव, निष्कर्षण, निकासी, या विषाक्तता हमलों का सामना करते समय विश्वसनीय, गोपनीयता-संरक्षित, और दुरुपयोग-प्रतिरोधी बने रहें।

---

## 10.1 मॉडल संरेखण और सुरक्षा

हानिकारक या नीति-भंग करने वाले आउटपुट्स के खिलाफ सुरक्षा करें।

|   #    | विवरण                                                                                                                                              | स्तर | भूमिका |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------------- | :--: | :----: |
| 10.1.1 | सुनिश्चित करें कि एक संरेखण परीक्षण-सूट (रेड-टीम प्रॉम्प्ट, जेलब्रेक जांचें, निषिद्ध सामग्री) संस्करण-नियंत्रित हो और हर मॉडल रिलीज़ पर चलाया जाए। |  1   |  D/V   |
| 10.1.2 | सुनिश्चित करें कि अस्वीकृति और सुरक्षित-पूर्ति गार्ड-रेल लागू किए गए हैं।                                                                          |  1   |   D    |
| 10.1.3 | सत्यापित करें कि एक स्वचालित मूल्यांकनकर्ता हानिकारक-सामग्री दर को मापता है और एक निर्धारित सीमा से अधिक होने पर प्रतिगमन को चिन्हित करता है।      |  2   |  D/V   |
| 10.1.4 | सुनिश्चित करें कि काउंटर-जेलब्रेक प्रशिक्षण दस्तावेजीकृत और पुनरुत्पादनीय है।                                                                      |  2   |   D    |
| 10.1.5 | सुनिश्चित करें कि औपचारिक नीति-अनुपालन प्रमाण या प्रमाणित निगरानी महत्वपूर्ण डोमेन को कवर करती हैं।                                                |  3   |   V    |

---

## 10.2 प्रतिद्वंदी-उदाहरण कठोरता बढ़ाना

संशोधित इनपुट के प्रति सहनशीलता बढ़ाएं। मजबूत विरोधी-प्रशिक्षण और मानक मूल्यांकन वर्तमान में सर्वोत्तम अभ्यास हैं।

|   #    | विवरण                                                                                                                          | स्तर | भूमिका |
| :----: | ------------------------------------------------------------------------------------------------------------------------------ | :--: | :----: |
| 10.2.1 | सुनिश्चित करें कि परियोजना रिपॉजिटरीज में पुनरुत्पादन योग्य सीड्स के साथ विरोधी-प्रशिक्षण कॉन्फ़िगरेशन शामिल हैं।              |  1   |   D    |
| 10.2.2 | सुनिश्चित करें कि प्रतिद्वंद्वी-उदाहरण पहचान उत्पादन पाइपलाइनों में अवरोधक अलर्ट उत्पन्न करती है।                              |  2   |  D/V   |
| 10.2.4 | सत्यापित करें कि प्रमाणित-रोबस्टनेस प्रमाण या अंतराल-बाउंड प्रमाणपत्र कम से कम शीर्ष महत्वपूर्ण वर्गों को कवर करते हैं।        |  3   |   V    |
| 10.2.5 | सुनिश्चित करें कि रिग्रेशन परीक्षण अनुकूलन हमलों का उपयोग करते हैं ताकि कोई मापन योग्य मजबूती हानि न हो इसका पुष्टि की जा सके। |  3   |   V    |

---

## 10.3 सदस्यता-सूचना न्यूनीकरण

यह निर्धारित करने की क्षमता को सीमित करें कि कोई रिकॉर्ड प्रशिक्षण डेटा में था या नहीं। विभेदकीय गोपनीयता और विश्वास-स्कोर मास्किंग सबसे प्रभावी ज्ञात सुरक्षा उपाय बने हुए हैं।

|   #    | विवरण                                                                                                         | स्तर | भूमिका |
| :----: | ------------------------------------------------------------------------------------------------------------- | :--: | :----: |
| 10.3.1 | सत्यापित करें कि प्रति-क्वेरी एंट्रॉपी नियमितीकरण या तापमान-स्केलिंग अतिप्रमाणित भविष्यवाणियों को कम करता है। |  1   |   D    |
| 10.3.2 | सुनिश्चित करें कि प्रशिक्षण संवेदनशील डेटा सेट के लिए ε-सीमित विभेदित-गोपनीयता अनुकूलन का उपयोग करता है।      |  2   |   D    |
| 10.3.3 | सुनिश्चित करें कि आक्रमण सिमुलेशन (शैडो-मॉडल या ब्लैक-बॉक्स) होल्ड-आउट डेटा पर आक्रमण AUC ≤ 0.60 दिखाते हैं।  |  2   |   V    |

---

## 10.4 मॉडल-इनवर्शन प्रतिरोध

निजी विशेषताओं के पुनर्निर्माण को रोकें। हाल के सर्वेक्षण आउटपुट ट्रंकशन और DP गारंटियों को व्यावहारिक सुरक्षा उपायों के रूप में जोर देते हैं।

|   #    | विवरण                                                                                                                | स्तर | भूमिका |
| :----: | -------------------------------------------------------------------------------------------------------------------- | :--: | :----: |
| 10.4.1 | सुनिश्चित करें कि संवेदनशील गुण कभी भी सीधे आउटपुट न हों; जहाँ आवश्यक हो, बकेट्स या एक-तरफा रूपांतरों का उपयोग करें। |  1   |   D    |
| 10.4.2 | सुनिश्चित करें कि क्वेरी-रेट सीमा एक ही प्रिंसिपल से बार-बार होने वाली अनुकूली क्वेरियों को धीमा कर देती है।         |  1   |  D/V   |
| 10.4.3 | पुष्टि करें कि मॉडल को प्राइवेसी-प्रिज़र्विंग शोर के साथ प्रशिक्षित किया गया है।                                     |  2   |   D    |

---

## 10.5 मॉडल-अधिग्रहण सुरक्षा

अनधिकृत क्लोनिंग का पता लगाने और उसे रोकने के लिए। वॉटरमार्किंग और क्वेरी-पैटर्न विश्लेषण की सिफारिश की जाती है।

|   #    | विवरण                                                                                                                                        | स्तर | भूमिका |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------- | :--: | :----: |
| 10.5.1 | सुनिश्चित करें कि इनफ़ेरेंस गेटवे मॉडल की मेमोराइज़ेशन थ्रेशोल्ड के अनुसार वैश्विक और प्रति-API-कुंजी दर सीमा को लागू करते हैं।              |  1   |   D    |
| 10.5.2 | सुनिश्चित करें कि query-entropy और input-plurality सांख्यिकी स्वचालित निष्कर्ष निकालने वाले डिटेक्टर को फीड करती हैं।                        |  2   |  D/V   |
| 10.5.3 | सत्यापित करें कि नाजुक या प्रायिकतात्मक वॉटरमार्क्स को संदिग्ध क्लोन के खिलाफ ≤ 1 000 क्वेरीज़ में p < 0.01 के साथ प्रमाणित किया जा सकता है। |  2   |   V    |
| 10.5.4 | पुष्टि करें कि वॉटरमार्क कुंजियाँ और ट्रिगर सेट हार्डवेयर-सिक्योरिटी-मॉड्यूल में संग्रहीत हैं और सालाना घुमाए जाते हैं।                      |  3   |   D    |
| 10.5.5 | पुष्टि करें कि extraction-alert घटनाओं में दोषपूर्ण क्वेरी शामिल हैं और वे incident-response प्लेबुक्स के साथ एकीकृत हैं।                    |  3   |   V    |

---

## 10.6 अनुमान-समय विषाक्त-डेटा पहचान

बैकडोर या विषाक्त इनपुट्स की पहचान करें और उन्हें निष्क्रिय करें।

|   #    | विवरण                                                                                                                                             | स्तर | भूमिका |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------- | :--: | :----: |
| 10.6.1 | सुनिश्चित करें कि मॉडल अनुमान से पहले इनपुट एक अनोमली डिटेक्टर (जैसे, STRIP, कंसिस्टेंसी-स्कोरिंग) से गुजरते हैं।                                 |  1   |   D    |
| 10.6.2 | सुनिश्चित करें कि डिटेक्टर थ्रेशोल्ड्स को साफ/प्रदूषित सत्यापन सेटों पर समायोजित किया गया है ताकि 5% से कम झूठे सकारात्मक परिणाम प्राप्त हो सकें। |  1   |   V    |
| 10.6.3 | सुनिश्चित करें कि विषाक्त के रूप में चिह्नित इनपुट सॉफ्ट-ब्लॉकिंग और मानव समीक्षा वर्कफ़्लोज़ को सक्रिय करें।                                     |  2   |   D    |
| 10.6.4 | सुनिश्चित करें कि डिटेक्टर्स को अनुकूली, ट्रिगरलेस बैकडोर हमलों के साथ तनाव-परीक्षण किया गया है।                                                  |  2   |   V    |
| 10.6.5 | सुनिश्चित करें कि डिटेक्शन एफिशिएंसी मेट्रिक्स लॉग किए गए हैं और इन्हें ताजा खतरा इंटेल के साथ समय-समय पर पुनः मूल्यांकन किया जाता है।            |  3   |   D    |

---

## 10.7 गतिशील सुरक्षा नीति अनुकूलन

धमकी खुफिया और व्यवहार विश्लेषण के आधार पर वास्तविक समय पर सुरक्षा नीति अपडेट।

|   #    | विवरण                                                                                                                                                    | स्तर | भूमिका |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------------------- | :--: | :----: |
| 10.7.1 | सुरक्षा नीतियों को एजेंट पुनः प्रारंभ किए बिना गतिशील रूप से अपडेट किया जा सकता है यह सत्यापित करें, साथ ही नीति संस्करण की अखंडता बनाए रखें।            |  1   |  D/V   |
| 10.7.2 | नीति अद्यतनों को अधिकृत सुरक्षा कर्मचारी द्वारा क्रिप्टोग्राफिक रूप से हस्ताक्षरित किए जाने और लागू करने से पहले मान्य किए जाने की पुष्टि करें।          |  2   |  D/V   |
| 10.7.3 | सुनिश्चित करें कि गतिशील नीति परिवर्तनों को पूर्ण ऑडिट ट्रेल के साथ लॉग किया गया है जिसमें औचित्य, स्वीकृति श्रृंखलाएं, और रोलबैक प्रक्रियाएं शामिल हैं। |  2   |  D/V   |
| 10.7.4 | पुष्ट करें कि अनुकूलन सुरक्षा तंत्र खतरा पहचान संवेदनशीलता को जोखिम संदर्भ और व्यवहारिक पैटर्न के आधार पर समायोजित करते हैं।                             |  3   |  D/V   |
| 10.7.5 | पुनर्नीतिगत अनुकूलन निर्णयों की व्याख्या योग्य हों और सुरक्षा टीम की समीक्षा के लिए साक्ष्य ट्रेल शामिल हों।                                             |  3   |  D/V   |

---

## 10.8 रिफ्लेक्शन-आधारित सुरक्षा विश्लेषण

एजेंट आत्म-चिंतन और मेटा-संज्ञानात्मक विश्लेषण के माध्यम से सुरक्षा मान्यता।

|   #    | विवरण                                                                                                                                          | स्तर | भूमिका |
| :----: | ---------------------------------------------------------------------------------------------------------------------------------------------- | :--: | :----: |
| 10.8.1 | सुनिश्चित करें कि एजेंट रिफ्लेक्शन तंत्र में निर्णयों और कार्यों का सुरक्षा-केंद्रित आत्म-मूल्यांकन शामिल है।                                  |  1   |  D/V   |
| 10.8.2 | पुष्टि करें कि रिफ्लेक्शन आउटपुट्स को सत्यापित किया जाता है ताकि प्रतिद्वंदी इनपुट्स द्वारा स्व-मूल्यांकन तंत्रों में छेड़छाड़ को रोका जा सके। |  2   |  D/V   |
| 10.8.3 | पुष्टि करें कि मेटा-कॉग्निटिव सुरक्षा विश्लेषण एजेंट की तर्क प्रक्रिया में संभावित पक्षपात, हेरफेर, या समझौता पहचानता है।                      |  2   |  D/V   |
| 10.8.4 | सत्यापित करें कि प्रतिबिंब-आधारित सुरक्षा चेतावनियां उन्नत निगरानी और संभावित मानवीय हस्तक्षेप कार्यप्रवाह को ट्रिगर करती हैं।                 |  3   |  D/V   |
| 10.8.5 | सुनिश्चित करें कि सुरक्षा प्रतिबिंबों से निरंतर सीखना खतरों का पता लगाने में सुधार करता है बिना वैध कार्यक्षमता को खराब किए।                   |  3   |  D/V   |

---

## 10.9 विकास और आत्म-सुधार सुरक्षा

स्वयं-संशोधन और विकास करने में सक्षम एजेंट सिस्टम के लिए सुरक्षा नियंत्रण।

|   #    | विवरण                                                                                                                                    | स्तर | भूमिका |
| :----: | ---------------------------------------------------------------------------------------------------------------------------------------- | :--: | :----: |
| 10.9.1 | पुष्टि करें कि स्व-परिवर्तन क्षमताएँ औपचारिक सत्यापन सीमाओं के साथ निर्दिष्ट सुरक्षित क्षेत्रों तक सीमित हैं।                            |  1   |  D/V   |
| 10.9.2 | सुनिश्चित करें कि विकास प्रस्तावों को क्रियान्वयन से पहले सुरक्षा प्रभाव मूल्यांकन से गुजरना पड़ता है।                                   |  2   |  D/V   |
| 10.9.3 | सुनिश्चित करें कि आत्म-सुधार तंत्र में पूर्णता सत्यापन के साथ रोलबैक क्षमताएँ शामिल हों।                                                 |  2   |  D/V   |
| 10.9.4 | सुनिश्चित करें कि मेटा-लर्निंग सुरक्षा सुधार एल्गोरिदम के प्रतिरोधात्मक छेड़छाड़ को रोकती है।                                            |  3   |  D/V   |
| 10.9.5 | सुनिश्चित करें कि पुनरावर्ती स्व-सुधार को औपचारिक सुरक्षा प्रतिबंधों द्वारा सीमित किया गया है, जिसमें अभिसरण के गणितीय प्रमाण शामिल हों। |  3   |  D/V   |

---

### संदर्भ

* [MITRE ATLAS adversary tactics for ML](https://atlas.mitre.org/)
* [NIST AI Risk Management Framework 1.0, 2023](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [OWASP Top 10 for LLM Applications, 2025](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Adversarial Training: A Survey — Zhao et al., 2024](https://arxiv.org/abs/2410.15042)
* [RobustBench adversarial-robustness benchmark](https://robustbench.github.io/)
* [Membership-Inference & Model-Inversion Risk Survey, 2025](https://www.sciencedirect.com/science/article/abs/pii/S0950705125003867)
* [PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023](https://ojs.aaai.org/index.php/AAAI/article/view/26289)
* [Model-Inversion Attacks & Defenses Survey — AI Review, 2025](https://link.springer.com/article/10.1007/s10462-025-11248-0)
* [Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024](https://doi.org/10.1109/TDSC.2023.3261327)
* [Fragile Model Watermarking Survey — 2025](https://www.sciencedirect.com/science/article/abs/pii/S0165168425002026)
* [Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025](https://arxiv.org/abs/2503.22759)
* [BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024](https://arxiv.org/abs/2405.15269)

