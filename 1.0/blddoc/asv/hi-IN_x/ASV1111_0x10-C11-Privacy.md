# 11 गोपनीयता संरक्षण और व्यक्तिगत डेटा प्रबंधन

## नियंत्रण उद्देश्य

पूरे एआई जीवनचक्र—संकलन, प्रशिक्षण, इनफरेंस, और घटना प्रतिक्रिया—के दौरान कठोर गोपनीयता आश्वासनों को बनाए रखें ताकि व्यक्तिगत डेटा केवल स्पष्ट सहमति, आवश्यक न्यूनतम दायरे, प्रमाणित मिटाव, और औपचारिक गोपनीयता गारंटी के साथ ही संसाधित हो।

---

## 11.1 गुमनामीकरण और डेटा न्यूनतमकरण

|   #    | विवरण                                                                                                                               | स्तर | भूमिका |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------- | :--: | :----: |
| 11.1.1 | सत्यापित करें कि प्रत्यक्ष पहचानकर्ता और क्वासी-आइडेंटिफायर्स हटाए गए हैं, हैश किए गए हैं।                                          |  1   |  D/V   |
| 11.1.2 | सत्यापित करें कि स्वचालित ऑडिट्स k-anonymity/l-diversity को मापते हैं और जब ये सीमाएँ नीति से नीचे गिर जाएँ, तब अलर्ट करें।         |  2   |  D/V   |
| 11.1.3 | यह सत्यापित करें कि मॉडल फीचर-इम्पोर्टेंस रिपोर्ट्स ε = 0.01 म्यूचुअल इन्फॉर्मेशन से आगे पहचानकर्ता लीक नहीं दिखाती हैं।            |  2   |   V    |
| 11.1.4 | सत्यापित करें कि औपचारिक प्रमाण या सिंथेटिक-डेटा प्रमाणन पुनः पहचान जोखिम ≤ 0.05 दिखाते हैं, यहां तक कि लिंकिंग आक्रमणों के तहत भी। |  3   |   V    |

---

## 11.2 भुलाए जाने का अधिकार और हटाने का प्रवर्तन

|   #    | विवरण                                                                                                                                                                        | स्तर | भूमिका |
| :----: | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :--: | :----: |
| 11.2.1 | सत्यापित करें कि data-subject हटाने के अनुरोध कच्चे डेटा सेट, चेकपॉइंट्स, एम्बेडिंग्स, लॉग्स और बैकअप तक 30 दिनों से कम SLA (सेवा स्तर समझौते) के भीतर प्रसारित हो जाते हैं। |  1   |  D/V   |
| 11.2.2 | सत्यापित करें कि "machine-unlearning" रूटीन भौतिक रूप से पुनः प्रशिक्षित करते हैं या प्रमाणित अनलर्निंग एल्गोरिदम का उपयोग करके हटाने का अनुमान लगाते हैं।                   |  2   |   D    |
| 11.2.3 | पुष्टि करें कि शैडो-मॉडल मूल्यांकन यह सिद्ध करता है कि भुलाए गए रिकॉर्ड अनलर्निंग के बाद आउटपुट के 1% से कम पर प्रभाव डालते हैं।                                             |  2   |   V    |
| 11.2.4 | सत्यापित करें कि हटाने की घटनाओं को अपरिवर्तनीय रूप से लॉग किया गया है और नियामकों के लिए ऑडिट-योग्य है।                                                                     |  3   |   V    |

---

## 11.3 डिफरेंशियल-गोपनीयता सुरक्षा उपाय

|   #    | विवरण                                                                                                   | स्तर | भूमिका |
| :----: | ------------------------------------------------------------------------------------------------------- | :--: | :----: |
| 11.3.1 | सत्यापित करें कि गोपनीयता-हानि लेखांकन डैशबोर्ड संचयी ε नीति की सीमाओं से अधिक होने पर चेतावनी देता है। |  2   |  D/V   |
| 11.3.2 | सत्यापित करें कि ब्लैक-बॉक्स गोपनीयता ऑडिट ε̂ को घोषित मान के 10% के भीतर अनुमान लगाते हैं।             |  2   |   V    |
| 11.3.3 | सुनिश्चित करें कि औपचारिक प्रमाण सभी पोस्ट-ट्रेनिंग फाइन-ट्यूनों और एम्बेडिंग्स को कवर करते हैं।        |  3   |   V    |

---

## 11.4 उद्देश्य-सीमितीकरण & स्कोप-क्रिप संरक्षण

|   #    | विवरण                                                                                                                            | स्तर | भूमिका |
| :----: | -------------------------------------------------------------------------------------------------------------------------------- | :--: | :----: |
| 11.4.1 | सत्यापित करें कि हर डेटासेट और मॉडल चेकपॉइंट एक मशीन-पठनीय उद्देश्य टैग रखता है जो मूल सहमति के अनुरूप है।                       |  1   |   D    |
| 11.4.2 | सत्यापित करें कि रनटाइम मॉनिटर्स घोषित उद्देश्य के अनुरूप न रहने वाले प्रश्नों का पता लगाते हैं और नरम इनकार को ट्रिगर करते हैं। |  1   |  D/V   |
| 11.4.3 | सत्यापित करें कि नीति-के-कोड गेट्स नए डोमेन में मॉडलों के पुनः-तैनाती को DPIA समीक्षा के बिना रोकते हैं।                         |  3   |   D    |
| 11.4.4 | सत्यापित करें कि औपचारिक ट्रेसबिलिटी प्रमाण यह दिखाते हैं कि हर व्यक्तिगत डेटा जीवनचक्र सहमति के दायरे में बना रहता है।          |  3   |   V    |

---

## 11.5 सहमति प्रबंधन और कानूनी-आधार ट्रैकिंग

|   #    | विवरण                                                                                                                                      | स्तर | भूमिका |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------ | :--: | :----: |
| 11.5.1 | सुनिश्चित करें कि एक अनुमति-प्रबंधन प्लेटफ़ॉर्म (CMP) प्रत्येक डेटा-विषय के अनुसार स्वीकृति-स्थिति, उद्देश्य और धारण अवधि रिकॉर्ड करता है। |  1   |  D/V   |
| 11.5.2 | यह सत्यापित करें कि एपीआईज़ सहमति टोकन उजागर करते हैं; मॉडलों को इनफरेंस से पहले टोकन के स्कोप की वैधता जाँच करनी चाहिए।                   |  2   |   D    |
| 11.5.3 | सत्यापित करें कि अस्वीकृत या वापस ली गई सहमति 24 घंटे के भीतर प्रसंस्करण पाइपलाइनों को रोक देती है.                                        |  2   |  D/V   |

---

## 11.6 फेडरेटेड लर्निंग के साथ गोपनीयता नियंत्रण

|   #    | विवरण                                                                                                         | स्तर | भूमिका |
| :----: | ------------------------------------------------------------------------------------------------------------- | :--: | :----: |
| 11.6.1 | पुष्टि करें कि क्लाइंट अपडेट्स एग्रीगेशन से पहले स्थानीय डिफरेंशियल प्राइवेसी शोर जोड़ते हैं।                 |  1   |   D    |
| 11.6.2 | यह सत्यापित करें कि प्रशिक्षण मेट्रिक्स डिफरेंशिएली प्राइवेट हैं और कभी भी एक-ग्राहक हानि को उजागर नहीं करते। |  2   |  D/V   |
| 11.6.3 | सत्यापित करें कि पॉइज़निंग-प्रतिरोधी समेकन सक्षम है (जैसे Krum/Trimmed-Mean)।                                 |  2   |   V    |
| 11.6.4 | सत्यापित करें कि औपचारिक प्रमाण कुल ε बजट को दर्शाते हैं और 5 से कम उपयोगिता हानि है.                         |  3   |   V    |

---

### संदर्भ

* [GDPR & AI Compliance Best Practices](https://www.exabeam.com/explainers/gdpr-compliance/the-intersection-of-gdpr-and-ai-and-6-compliance-best-practices/)
* [EU Parliament Study on GDPR & AI, 2020](https://www.europarl.europa.eu/RegData/etudes/STUD/2020/641530/EPRS_STU%282020%29641530_EN.pdf)
* [ISO 31700-1:2023 — Privacy by Design for Consumer Products](https://www.iso.org/standard/84977.html)
* [NIST Privacy Framework 1.1 (2025 Draft)](https://www.nist.gov/privacy-framework)
* [Machine Unlearning: Right-to-Be-Forgotten Techniques](https://www.kaggle.com/code/tamlhp/machine-unlearning-the-right-to-be-forgotten)
* [A Survey of Machine Unlearning, 2024](https://arxiv.org/html/2209.02299v6)
* [Auditing DP-SGD — ArXiv 2024](https://arxiv.org/html/2405.14106v4)
* [DP-SGD Explained — PyTorch Blog](https://medium.com/pytorch/differential-privacy-series-part-1-dp-sgd-algorithm-explained-12512c3959a3)
* [Purpose-Limitation for AI — IJLIT 2025](https://academic.oup.com/ijlit/article/doi/10.1093/ijlit/eaaf003/8121663)
* [Data-Protection Considerations for AI — URM Consulting](https://www.urmconsulting.com/blog/data-protection-considerations-for-artificial-intelligence-ai)
* [Top Consent-Management Platforms, 2025](https://www.enzuzo.com/blog/best-consent-management-platforms)
* [Secure Aggregation in DP Federated Learning — ArXiv 2024](https://arxiv.org/abs/2407.19286)

