# C13 मानव पर्यवेक्षण, जवाबदेही और शासन

## नियंत्रण उद्देश्य

यह अध्याय एआई प्रणालियों में मानव निगरानी बनाए रखने और स्पष्ट जवाबदेही की श्रृंखलाओं के लिए आवश्यकताएं प्रदान करता है, ताकि एआई जीवनचक्र के पूरे चरणों के दौरान व्याख्येयता, पारदर्शिता और नैतिक देखरेख सुनिश्चित की जा सके।

---

## C13.1 किल-स्विच और ओवरराइड मैकेनिज़्म

जब एआई सिस्टम के असुरक्षित व्यवहार का पता चले, तब शटडाउन या रोलबैक के मार्ग प्रदान करें।

|   #    | विवरण                                                                                                            | स्तर | भूमिका |
| :----: | ---------------------------------------------------------------------------------------------------------------- | :--: | :----: |
| 13.1.1 | सत्यापित करें कि एक मैनुअल किल-स्विच तंत्र मौजूद है ताकि एआई मॉडल के पूर्वानुमान और आउटपुट को तुरंत रोका जा सके। |  1   |  D/V   |
| 13.1.2 | सत्यापित करें कि ओवरराइड नियंत्रण केवल अधिकृत कर्मियों के लिए पहुँच योग्य हैं।                                   |  1   |   D    |
| 13.1.3 | यह सत्यापित करें कि रोलबैक प्रक्रियाएं पूर्व मॉडल संस्करणों या safe-mode ऑपरेशनों पर लौट सकती हैं।               |  3   |  D/V   |
| 13.1.4 | सुनिश्चित करें कि ओवरराइड तंत्रों का नियमित रूप से परीक्षण किया जाता है।                                         |  3   |   V    |

---

## C13.2 मानव-इन-द-लूप निर्णय चेकप्वाइंट्स

पूर्व निर्धारित जोखिम सीमाओं से ऊपर जाने पर मानव अनुमोदन आवश्यक है।

|   #    | विवरण                                                                                                                                           | स्तर | भूमिका |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------- | :--: | :----: |
| 13.2.1 | यह सत्यापित करें कि उच्च-जोखिम एआई निर्णयों के लिए स्पष्ट मानव अनुमोदन क्रियान्वयन से पहले आवश्यक है।                                           |  1   |  D/V   |
| 13.2.2 | यह सुनिश्चित करें कि जोखिम सीमाएं स्पष्ट रूप से परिभाषित हों और स्वचालित रूप से मानव समीक्षा कार्यप्रवाहों को ट्रिगर करें।                      |  1   |   D    |
| 13.2.3 | यह सुनिश्चित करें कि समय-संवेदनशील निर्णयों के लिए फॉलबैक प्रक्रियाएं हों जब आवश्यक समय-सीमा के भीतर मानवीय अनुमोदन प्राप्त नहीं हो पाता।       |  2   |   D    |
| 13.2.4 | यह सत्यापित करें कि एस्केलेशन प्रक्रियाएं विभिन्न निर्णय प्रकारों या जोखिम वर्गों के लिए स्पष्ट प्राधिकरण स्तर निर्धारित करती हैं, यदि लागू हो। |  3   |  D/V   |

---

## C13.3 जिम्मेदारी की श्रृंखला और ऑडिटेबिलिटी

ऑपरेटर के क्रियाकलाप और मॉडल के निर्णय लॉग करें।

|   #    | विवरण                                                                                                                                         | स्तर | भूमिका |
| :----: | --------------------------------------------------------------------------------------------------------------------------------------------- | :--: | :----: |
| 13.3.1 | सुनिश्चित करें कि सभी एआई सिस्टम के निर्णय और मानवीय हस्तक्षेप समय-चिह्नों, उपयोगकर्ताओं की पहचान, और निर्णय के तर्क के साथ रिकॉर्ड किए जाएँ। |  1   |  D/V   |
| 13.3.2 | यह सत्यापित करें कि ऑडिट लॉग्स बदला नहीं जा सकते और उनमें अखंडता सत्यापन के तंत्र शामिल हों।                                                  |  2   |   D    |

---

## C13.4 व्याख्यात्मक-एआई तकनीकें

सतही विशेषताओं का महत्त्व, काउंटर-फैक्चुअल्स, और स्थानीय स्पष्टीकरण।

|   #    | विवरण                                                                                                                                                      | स्तर | भूमिका |
| :----: | ---------------------------------------------------------------------------------------------------------------------------------------------------------- | :--: | :----: |
| 13.4.1 | सत्यापित करें कि एआई प्रणालियाँ अपने निर्णयों के लिए बुनियादी स्पष्टीकरण मानव-पाठ्य प्रारूप में प्रदान करती हैं।                                           |  1   |  D/V   |
| 13.4.2 | सुनिश्चित करें कि स्पष्टीकरण की गुणवत्ता मानवीय मूल्यांकन अध्ययनों और मीट्रिक्स के माध्यम से सत्यापित होती है।                                             |  2   |   V    |
| 13.4.3 | सत्यापित करें कि महत्वपूर्ण निर्णयों के लिए विशेषताओं के महत्त्व के स्कोर या एट्रिब्यूशन विधियाँ (SHAP, LIME, आदि) उपलब्ध हैं।                             |  3   |  D/V   |
| 13.4.4 | सत्यापित करें कि काउंटरफैक्चुअल स्पष्टीकरण ये दिखाते हैं कि इनपुट कैसे संशोधित किए जा सकते हैं ताकि परिणाम बदले, यदि उपयोग केस और डोमेन के अनुसार लागू हो। |  3   |   V    |

---

## C13.5 मॉडल कार्ड्स और उपयोग खुलासे

उद्देश्यित उपयोग, प्रदर्शन मीट्रिक्स, और नैतिक विचारों के लिए मॉडल कार्ड बनाए रखें।

|   #    | विवरण                                                                                                                                                                                              | स्तर | भूमिका |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :--: | :----: |
| 13.5.1 | सुनिश्चित करें कि मॉडल कार्डों में उद्देश्यित उपयोग के मामले, सीमाएं, और ज्ञात विफलता मोड दर्ज हों।                                                                                                |  1   |   D    |
| 13.5.2 | यह सत्यापित करें कि विभिन्न लागू उपयोग मामलों में प्रदर्शन मीट्रिक्स प्रकाशित किए गए हैं।                                                                                                          |  1   |  D/V   |
| 13.5.3 | यह सुनिश्चित करें कि नैतिक विचार, पूर्वाग्रह मूल्यांकन, निष्पक्षता मूल्यांकन, प्रशिक्षण डेटा की विशेषताएं, और ज्ञात प्रशिक्षण डेटा की सीमाएं दस्तावेजीकृत हैं और नियमित रूप से अपडेट किए जाते हैं। |  2   |   D    |
| 13.5.4 | यह सुनिश्चित करें कि मॉडल कार्ड संस्करण-नियंत्रित हैं और मॉडल जीवनचक्र के दौरान परिवर्तन ट्रैकिंग के साथ बनाए रखे जाते हैं।                                                                        |  2   |  D/V   |

---

## C13.6 अनिश्चितता का मात्रात्मक आकलन

जवाबों में आत्मविश्वास स्कोर या एंट्रॉपी माप प्रसारित करें।

|   #    | विवरण                                                                                                                 | स्तर | भूमिका |
| :----: | --------------------------------------------------------------------------------------------------------------------- | :--: | :----: |
| 13.6.1 | सत्यापित करें कि एआई प्रणालियाँ अपने आउटपुट के साथ कॉन्फिडेन्स स्कोर या अनिश्चितता माप प्रदान करती हैं।               |  1   |   D    |
| 13.6.2 | सत्यापित करें कि अनिश्चितता की सीमाएं अतिरिक्त मानव समीक्षा या वैकल्पिक निर्णय मार्गों को ट्रिगर करती हैं।            |  2   |  D/V   |
| 13.6.3 | यह सत्यापित करें कि अनिश्चितता मात्रांकन की पद्धतियाँ ग्राउंड ट्रुथ डेटा के विरुद्ध कैलिब्रेट और वैलिडेट की जाती हैं। |  2   |   V    |
| 13.6.4 | यह सुनिश्चित करें कि अनिश्चितता का प्रसार बहु-चरण AI वर्कफ़्लोज़ के माध्यम से बनाए रखा गया है।                        |  3   |  D/V   |

---

## C13.7 उपयोगकर्ता-समक्ष पारदर्शिता रिपोर्टें

घटनाओं, ड्रिफ्ट, और डेटा उपयोग पर नियमित प्रकटीकरण दें।

|   #    | विवरण                                                                                                                    | स्तर | भूमिका |
| :----: | ------------------------------------------------------------------------------------------------------------------------ | :--: | :----: |
| 13.7.1 | यह सुनिश्चित करें कि डेटा उपयोग नीतियाँ और उपयोगकर्ता सहमति प्रबंधन की प्रथाएं स्पष्ट रूप से हितधारकों तक संप्रेषित हैं। |  1   |  D/V   |
| 13.7.2 | सुनिश्चित करें कि एआई प्रभाव आकलन किए जाते हैं और परिणाम रिपोर्टिंग में शामिल किए जाते हैं।                              |  2   |  D/V   |
| 13.7.3 | सत्यापित करें कि नियमित रूप से प्रकाशित पारदर्शिता रिपोर्टें एआई घटनाओं और परिचालन मीट्रिक्स का उचित विवरण देती हैं।     |  2   |  D/V   |

### संदर्भ

* [EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)](https://eur-lex.europa.eu/eli/reg/2024/1689/oj)
* [ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management](https://www.iso.org/standard/77304.html)
* [ISO/IEC 42001:2023 — AI Management Systems Requirements](https://www.iso.org/standard/81230.html)
* [NIST AI Risk Management Framework 1.0](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [NIST SP 800-53 Revision 5 — Security and Privacy Controls](https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-53r5.pdf)
* [A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)](https://arxiv.org/abs/1705.07874)
* [Model Cards for Model Reporting (Mitchell et al., 2018)](https://arxiv.org/abs/1810.03993)
* [Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)](https://arxiv.org/abs/1506.02142)
* [ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods](https://www.iso.org/standard/79804.html)
* [IEEE 7001-2021 — Transparency of Autonomous Systems](https://standards.ieee.org/ieee/7001/6929/)
* [GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)](https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX%3A32016R0679)
* [Human Oversight under Article 14 of the EU AI Act (Fink, 2025)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5147196)

