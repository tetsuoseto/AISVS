# Prefácio

Bem-vindo ao Padrão de Verificação de Segurança em Inteligência Artificial (AISVS) versão 1.0!

## Introdução

Estabelecida em 2025 através de um esforço colaborativo da comunidade, a AISVS define os requisitos de segurança a serem considerados ao projetar, desenvolver, implantar e operar modelos de IA modernos, pipelines e serviços habilitados para IA.

AISVS v1.0 representa o trabalho conjunto de seus líderes de projeto, grupo de trabalho e contribuidores da comunidade mais ampla para fornecer uma linha de base pragmática e verificável para garantir a segurança de sistemas de IA.

Nosso objetivo com este lançamento é tornar o AISVS de fácil adoção, mantendo o foco absoluto no escopo definido e abordando o cenário de riscos em rápida evolução, exclusivo da IA.

## Objetivos principais para a versão 1.0 do AISVS

A Versão 1.0 será criada com vários princípios orientadores.

### Escopo Bem‑Definido

Cada requisito deve estar alinhado com o nome e a missão da AISVS:

* Inteligência Artificial – Os controles operam na camada de IA/ML (dados, modelo, pipeline ou inferência) e são de responsabilidade dos profissionais de IA.
* Segurança – Requisitos que mitigam diretamente riscos de segurança, privacidade ou segurança identificados.
* Verificação – A linguagem é escrita de modo que a conformidade possa ser validada de forma objetiva.
* Padrão – Seções seguem uma estrutura e terminologia consistentes para formar uma referência coerente.
  ​
---

Seguindo o AISVS, as organizações podem avaliar e fortalecer de forma sistemática a postura de segurança de suas soluções de IA, promovendo uma cultura de engenharia de IA segura.

