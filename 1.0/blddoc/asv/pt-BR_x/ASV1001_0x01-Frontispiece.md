# Capa

## Sobre o Padrão

O Padrão de Verificação de Segurança de Inteligência Artificial (AISVS) é um catálogo baseado na comunidade de requisitos de segurança que cientistas de dados, engenheiros de MLOps, arquitetos de software, desenvolvedores, testadores, profissionais de segurança, fornecedores de ferramentas, reguladores e consumidores podem usar para projetar, construir, testar e verificar sistemas e aplicações confiáveis habilitados por IA. Ele fornece uma linguagem comum para especificar controles de segurança ao longo do ciclo de vida da IA — desde a coleta de dados e desenvolvimento de modelos até implantação e monitoramento contínuo — para que as organizações possam medir e melhorar a resiliência, privacidade e segurança de suas soluções de IA.

## Direitos Autorais e Licença

Versão 0.1 (Primeiro Rascunho Público - Em Andamento), 2025  

![license](../images/license.png)

Copyright © 2025 O Projeto AISVS.  

Liberado sob a[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
Para qualquer reutilização ou distribuição, você deve comunicar claramente os termos de licença deste trabalho aos outros.

## Líderes de Projeto

|            |                         |
| ---------- | ----------------------- |
| Jim Manico | Aras “Russ” Memisyazici |

## Contribuidores e Revisores

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS é um padrão totalmente novo criado especificamente para enfrentar os desafios de segurança únicos dos sistemas de inteligência artificial. Embora se inspire em melhores práticas gerais de segurança, cada requisito do AISVS foi desenvolvido do zero para refletir o cenário de ameaças da IA e ajudar as organizações a construir soluções de IA mais seguras e resilientes.

