# Frontispício

## Sobre o Padrão

Padrão de Verificação de Segurança de Inteligência Artificial (AISVS) é um catálogo orientado pela comunidade de requisitos de segurança que cientistas de dados, engenheiros de MLOps, arquitetos de software, desenvolvedores, testadores, profissionais de segurança, fornecedores de ferramentas, reguladores e consumidores podem usar para projetar, construir, testar e verificar sistemas e aplicações confiáveis habilitados por IA. Ele oferece uma linguagem comum para especificar controles de segurança ao longo do ciclo de vida da IA—desde a coleta de dados e o desenvolvimento de modelos até a implantação e o monitoramento contínuo—para que as organizações possam medir e melhorar a resiliência, a privacidade e a segurança de suas soluções de IA.

## Direitos Autorais e Licença

Versão 0.1 (Primeiro Rascunho Público - Em Andamento), 2025  

![license](../images/license.png)

Direitos autorais © 2025 The AISVS Project.  

Lançado sob a [Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
Para qualquer reutilização ou distribuição, você deve comunicar claramente os termos de licença desta obra a terceiros.

## Líderes de Projeto

|            |                         |
| ---------- | ----------------------- |
| Jim Manico | Aras “Russ” Memisyazici |

## Contribuidores e Revisores

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS é um padrão totalmente novo criado especificamente para enfrentar os desafios de segurança únicos de sistemas de inteligência artificial. Embora se inspire em melhores práticas de segurança mais amplas, cada requisito no AISVS foi desenvolvido do zero para refletir o cenário de ameaças de IA e ajudar as organizações a construir soluções de IA mais seguras e resilientes.

