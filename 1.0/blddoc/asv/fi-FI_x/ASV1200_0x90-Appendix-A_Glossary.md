# Liite A: Sanasto

Tämä kattava sanasto tarjoaa määritelmiä keskeisille tekoälyn, koneoppimisen ja turvallisuuden termeille, joita käytetään AISVS:n yhteydessä selkeyden ja yhteisen ymmärryksen varmistamiseksi.

* Vastustava esimerkki: Tietoinen syöte, joka on tarkoituksellisesti muokattu saamaan tekoälymalli tekemään virheen, usein lisäämällä hienovaraisia häiriöitä, joita ihmiset eivät huomaa.
  ​
* Vihamielinen kestävyys – Vihamielinen kestävyys tekoälyssä viittaa mallin kykyyn säilyttää suorituskykynsä ja vastustaa tahallisesti suunniteltujen, haitallisten syötteiden aiheuttamaa harhautusta tai manipulointia, jotka on tarkoitettu aiheuttamaan virheitä.
  ​
* Agentti – tekoälyagentit ovat ohjelmistojärjestelmiä, jotka käyttävät tekoälyä tavoitteiden saavuttamiseen ja tehtävien suorittamiseen käyttäjien puolesta. Ne osoittavat päättelykykyä, suunnittelua ja muistia sekä omaavat autonomian tason tehdä päätöksiä, oppia ja sopeutua.
  ​
* Agenttinen tekoäly: tekoälyjärjestelmät, jotka voivat toimia jonkin verran itsenäisesti saavuttaakseen tavoitteita, usein tekemällä päätöksiä ja ryhtymällä toimiin ilman suoraa ihmisen väliintuloa.
  ​
* Attribuuttipohjainen pääsynhallinta (ABAC): Pääsynhallintaparadigma, jossa valtuutuspäätökset perustuvat käyttäjän, resurssin, toiminnon ja ympäristön attribuutteihin, jotka arvioidaan kyselyhetkellä.
  ​
* Takaporttihyökkäys: Tietomyrkytyshyökkäyksen tyyppi, jossa mallia koulutetaan vastaamaan tietyllä tavalla tiettyihin laukaiseviin tekijöihin, mutta käyttäytymään normaalisti muulloin.
  ​
* Vinouma: Järjestelmällisiä virheitä tekoälymallin tuloksissa, jotka voivat johtaa epäoikeudenmukaisiin tai syrjiviin lopputuloksiin tietyille ryhmille tai tietyissä konteksteissa.
  ​
* Harhakäsittelyn hyväksikäyttö: Hyökkäystekniikka, joka hyödyntää tunnettua vinoutuneisuutta tekoälymalleissa manipuloidakseen tuloksia tai lopputuloksia.
  ​
* Cedar: Amazonin politiikan kieli ja moottori hienojakoisten käyttöoikeuksien hallintaan, jota käytetään ABAC:n toteuttamiseen tekoälyjärjestelmissä.
  ​
* Ajatusketju: Tekniikka kielen mallien päättelykyvyn parantamiseksi luomalla välivaiheen päättelyaskeleita ennen lopullisen vastauksen tuottamista.
  ​
* Virtakatkaisijat: Mekanismit, jotka keskeyttävät automaattisesti tekoälyjärjestelmän toiminnot, kun tietyt riskirajat ylitetään.
  ​
* Tietovuoto: Arkaluonteisen tiedon tahaton paljastuminen tekoälymallin tulosteiden tai käyttäytymisen kautta.
  ​
* Datan myrkyttäminen: Harjoitusdatan tahallinen turmelemine mallin eheyden vaarantamiseksi, usein takaovien asentamiseksi tai suorituskyvyn heikentämiseksi.
  ​
* Differential Privacy – Differentielli yksityisyys on matemaattisesti tiukka kehys tilastollisen tiedon julkaisemiseen tietoaineistoista samalla kun suojataan yksittäisten tietueiden yksityisyyttä. Sen avulla tietoja omistava voi jakaa ryhmän yhteenlasketut mallit rajoittaen samalla yksittäisiä henkilöitä koskevan tiedon vuotamista.
  ​
* Upotukset: Tiheät vektoriesitykset datasta (teksti, kuvat jne.), jotka tallentavat semanttisen merkityksen monidimensionaalisessa tilassa.
  ​
* Selitettävyys – Selitettävyys tekoälyssä tarkoittaa tekoälyjärjestelmän kykyä tarjota ihmisille ymmärrettäviä perusteluja tekemilleen päätöksille ja ennusteille sekä antaa näkemyksiä sen sisäisestä toiminnasta.
  ​
* Selitettävä tekoäly (XAI): Tekoälyjärjestelmät, jotka on suunniteltu tarjoamaan ihmisille ymmärrettäviä selityksiä päätöksilleen ja käytökselleen erilaisilla tekniikoilla ja kehikoilla.
  ​
* Federated Learning: Koneoppimisen lähestymistapa, jossa malleja koulutetaan useilla hajautetuilla laitteilla, jotka pitävät hallussaan paikallisia datanäytteitä, ilman että dataa itsessään vaihdetaan.
  ​
* Suojakaiteet: Rajoituksia, jotka on otettu käyttöön estämään tekoälyjärjestelmiä tuottamasta haitallisia, puolueellisia tai muuten ei-toivottuja tuloksia.
  ​
* Hallusinaatio – AI-hallusinaatio viittaa ilmiöön, jossa tekoälymalli tuottaa virheellistä tai harhaanjohtavaa tietoa, joka ei perustu sen koulutusdataan tai tosiasialliseen todellisuuteen.
  ​
* Ihmisen mukanaolo (Human-in-the-Loop, HITL): Järjestelmät, jotka on suunniteltu vaatimaan ihmisen valvontaa, vahvistusta tai puuttumista ratkaisevissa päätöspisteissä.
  ​
* Infrastruktuuri koodina (IaC): Infrastruktuurin hallinta ja käyttöönotto koodin avulla manuaalisten prosessien sijaan, mikä mahdollistaa tietoturvatarkastukset ja yhdenmukaiset käyttöönotot.
  ​
* Jailbreak: Tekniikoita, joita käytetään kiertämään tekoälyjärjestelmien turvallisuusrajoja, erityisesti suurissa kielimalleissa, tuottamaan kiellettyä sisältöä.
  ​
* Vähimmän etuoikeuden periaate: Turvallisuusperiaate, jossa käyttäjille ja prosesseille annetaan vain välttämättömimmät käyttöoikeudet.
  ​
* LIME (Local Interpretable Model-agnostic Explanations): Menetelmä, jolla voidaan selittää minkä tahansa koneoppimisluokittelijan ennusteita likimääräistämällä se paikallisesti tulkittavalla mallilla.
  ​
* Jäsenyyspäätelmähyökkäys: Hyökkäys, jonka tavoitteena on selvittää, käytettiinkö tiettyä datapistettä koneoppimismallin kouluttamiseen.
  ​
* MITRE ATLAS: Vihamielisten uhkien maisema tekoälyjärjestelmille; tietopankki vihamielisistä taktiikoista ja tekniikoista tekoälyjärjestelmiä vastaan.
  ​
* Mallikortti – Mallikortti on dokumentti, joka tarjoaa standardoitua tietoa tekoälymallin suorituskyvystä, rajoituksista, suunnitelluista käyttötarkoituksista ja eettisistä näkökohdista edistääkseen läpinäkyvyyttä ja vastuullista tekoälyn kehitystä.
  ​
* Mallin poiminta: Hyökkäys, jossa hyökkääjä kysyy toistuvasti kohdemallia luodakseen toiminnallisesti vastaavan kopion ilman lupaa.
  ​
* Mallin kääntäminen: Hyökkäys, jossa pyritään rekonstruoimaan koulutusdataa analysoimalla mallin tuottamia tuloksia.
  ​
* Mallin elinkaaren hallinta – AI-mallin elinkaaren hallinta on prosessi, jossa valvotaan kaikkia tekoälymallin olemassaolon vaiheita, mukaan lukien sen suunnittelu, kehitys, käyttöönotto, seuranta, ylläpito ja lopullinen poisto, jotta varmistetaan mallin tehokkuus ja tavoitteiden mukaisuus.
  ​
* Mallin myrkyttäminen: Haavoittuvuuksien tai takaovien lisääminen suoraan malliin koulutusprosessin aikana.
  ​
* Mallin varastaminen/varkaus: Omistusoikeudelliseen malliin perustuvan kopion tai likimääräisen version poimiminen toistuvien kyselyjen kautta.
  ​
* Moniagenttijärjestelmä: Järjestelmä, joka koostuu useista vuorovaikutteisista tekoälyagenttien kokonaisuuksista, joilla kullakin voi olla erilaisia kykyjä ja tavoitteita.
  ​
* OPA (Open Policy Agent): Avoimen lähdekoodin politiikkamoottori, joka mahdollistaa yhtenäisen politiikan noudattamisen koko pinossa.
  ​
* Yksityisyyttä suojaava koneoppiminen (PPML): Menetelmät ja tekniikat koneoppimismallien kouluttamiseen ja käyttöönottoon siten, että koulutusdatan yksityisyys säilyy.
  ​
* Komentointisyrjintä: hyökkäys, jossa haitallisia ohjeita upotetaan syötteisiin mallin tarkoitetun toiminnan ohittamiseksi.
  ​
* RAG (haun tehostama generointi): Tekniikka, joka parantaa suuria kielimalleja hakemalla asiaankuuluvaa tietoa ulkoisista tietolähteistä ennen vastauksen luomista.
  ​
* Red-Teaming: Käytäntö, jossa testataan tekoälyjärjestelmiä aktiivisesti simuloimalla vihamielisiä hyökkäyksiä haavoittuvuuksien tunnistamiseksi.
  ​
* SBOM (Ohjelmistojen materiaaliluettelo): Virallinen tietue, joka sisältää tiedot ja toimitusketjusuhteet erilaisista komponenteista, joita käytetään ohjelmistojen tai tekoälymallien rakentamisessa.
  ​
* SHAP (SHapley Additive exPlanations): Peliteoreettinen lähestymistapa koneoppimismallin tuloksen selittämiseen laskemalla kunkin piirteen osuus ennusteessa.
  ​
* Toimitusketjun hyökkäys: järjestelmän kompromissointi kohdistamalla vähemmän suojattuihin osiin sen toimitusketjussa, kuten kolmannen osapuolen kirjastoihin, tietoaineistoihin tai valmiiksi koulutettuihin malleihin.
  ​
* Siirto-oppiminen: Tekniikka, jossa yhdelle tehtävälle kehitetty malli uudelleenkäytetään lähtökohtana mallille toisessa tehtävässä.
  ​
* Vektoritietokanta: Erityinen tietokanta, joka on suunniteltu tallentamaan korkeulotteisia vektoreita (upotuksia) ja suorittamaan tehokkaita samankaltaisuushakuja.
  ​
* Haavoittuvuusskannaus: Automaattiset työkalut, jotka tunnistavat tunnetut tietoturva-aukot ohjelmistokomponenteissa, mukaan lukien tekoälykehyksiä ja riippuvuuksia.
  ​
* Vesileimaus: Tekniikat näkymättömien tunnisteiden upottamiseksi tekoälyn tuottamaan sisältöön sen alkuperän seuraamiseksi tai tekoälytuotannon havaitsemiseksi.
  ​
* Zero-Day-haavoittuvuus: Aiempia tuntematon haavoittuvuus, jota hyökkääjät voivat käyttää hyväkseen ennen kuin kehittäjät luovat ja ottavat käyttöön korjauksen.

