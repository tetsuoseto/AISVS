# Liite A: Sanasto

>Tämä kattava sanasto sisältää AISVS:ssä käytettyjen keskeisten tekoäly-, koneoppimisen ja turvallisuus-termien määritelmiä varmistaen selkeyden ja yhteisen ymmärryksen.

* Vihamielinen esimerkki: syöte, joka on tarkoituksella laadittu saattamaan tekoälymallin tekemään virheen, usein lisäämällä ihmisten havaittamattomia hienovaraisia perturbaatioita.
  ​
* Hyökkäyskestävyys – Tekoälyssä se tarkoittaa mallin kykyä säilyttää suorituskykynsä ja torjua tarkoituksella suunniteltuja, pahantahtoisia syötteitä, joiden tavoitteena on aiheuttaa virheitä.
  ​
* Agentti – AI-agentit ovat ohjelmistojärjestelmiä, jotka käyttävät tekoälyä tavoitteiden saavuttamiseen ja tehtävien suorittamiseen käyttäjien puolesta. Ne osoittavat päättelyä, suunnittelua ja muistia, ja niillä on autonomia tehdä päätöksiä, oppia ja sopeutua.
  ​
* Agenttinen tekoäly: tekoälyjärjestelmät, jotka voivat toimia jonkin asteisen autonomian avulla tavoitteiden saavuttamiseksi, ja jotka usein tekevät päätöksiä sekä ryhtyvät toimiin ilman suoraa ihmisen puuttumista.
  ​
* Attribuutteihin perustuva pääsynvalvonta (ABAC): pääsynvalvontamalli, jossa valtuutuspäätökset perustuvat käyttäjän, resurssin, toiminnon ja ympäristön attribuuteihin, arvioidaan kyselyaikana.
  ​
* Takaporttihyökkäys: eräänlainen datan myrkytyshyökkäyksen tyyppi, jossa malli opetetaan vastaamaan tietyllä tavalla joillekin laukaisimille, kun se muuten käyttäytyy normaalisti.
  ​
* Vinouma: Järjestelmälliset virheet tekoälymallin tuloksissa, jotka voivat johtaa epäoikeudenmukaisiin tai syrjiviin lopputuloksiin tietyille ryhmille tai tietyissä konteksteissa.
  ​
* Vinouksien hyödyntäminen: Hyökkäystekniikka, joka hyödyntää tekoälymallien tunnettuja vinouksia manipuloidakseen tuloksia tai lopputuloksia.
  ​
* Cedar: Amazonin politiikkakieli ja moottori hienorakeisten käyttöoikeuksien toteuttamiseen ABACin tekoälyjärjestelmissä.
  ​
* Ajatteluketju: Tekniikka, jolla parannetaan kielimallien päättelykykyä tuottamalla välivaiheita ennen lopullisen vastauksen antamista.
  ​
* Katkaisijat: Mekanismit, jotka pysäyttävät tekoälyjärjestelmän toiminnot automaattisesti, kun tietyt riskirajat ylittyvät.
  ​
* Tietovuoto: arkaluonteisten tietojen tahattomasta paljastumisesta AI-mallin tulosteiden tai käyttäytymisen kautta.
  ​
* Datan myrkyttäminen: Koulutusdatan tahallinen vääristely mallin eheyden vaarantamiseksi, usein takaporttien asentamiseen tai suorituskyvyn heikentämiseen.
  ​
* Differentiaalinen yksityisyys – Differentiaalinen yksityisyys on matemaattisesti tiukka kehys tilastollisen tiedon julkaisemiseksi tietoaineistoista samalla suojaten yksittäisten henkilöiden yksityisyyttä. Se mahdollistaa datan omistajan jakaa ryhmän yhdistetyt piirteet samalla rajoittaen sitä, millaista tietoa yksittäisistä henkilöistä vuotaa.
  ​
* Upotukset: Tiheät vektoriedustukset datasta (teksti, kuvat jne.), jotka kuvaavat semanttista merkitystä korkeidimensionaalisessa avaruudessa.
  ​
* Selitettävyyys – Selitettävyyden tekoälyssä on kyky tarjota ihmisille ymmärrettäviä syitä sen päätöksille ja ennusteille, tarjoten näkemyksiä sen sisäisestä toiminnasta.
  ​
* Selitettävä tekoäly (XAI): tekoälyjärjestelmät, jotka on suunniteltu tarjoamaan ihmisille ymmärrettäviä selityksiä niiden päätöksistä ja käyttäytymisestään erilaisten tekniikoiden ja kehyksien kautta.
  ​
* Federated Learning: koneoppimisen lähestymistapa, jossa mallit koulutetaan useiden hajautettujen laitteiden kautta, joilla on paikalliset datanäytteet, ilman että dataa vaihdetaan keskenään.
  ​
* Turvakaiteet: AI-järjestelmien haitallisten, puolueellisten tai muuten epätoivottujen tulosten syntymisen estämiseksi toteutetut rajoitteet.
  ​
* Hallusinaatio – tekoälyhallusinaatio viittaa ilmiöön, jossa tekoälymalli tuottaa virheellistä tai harhaanjohtavaa tietoa, joka ei perustu sen koulutusdataan tai todelliseen faktaan.
  ​
* Ihmisen ohjaama silmukka (HITL): Järjestelmät, jotka on suunniteltu vaatimaan ihmisen valvontaa, varmistusta tai puuttumista kriittisissä päätöksentekopisteissä.
  ​
* Infrastruktuuri koodina (IaC): Infrastruktuurin hallinta ja provisionointi koodin kautta manuaalisten prosessien sijaan, mahdollistaa turvallisuusskannauksen ja johdonmukaiset käyttöönotot.
  ​
* Jailbreak: Tekniikat, joita käytetään kiertämään tekoälyjärjestelmien turvakaiteita, erityisesti suurissa kielimalleissa, jotta voidaan tuottaa kiellettyä sisältöä.
  ​
* Oikeuksien minimoinnin periaate: Turvallisuusperiaate, jossa annetaan vain käyttäjille ja prosesseille tarvittavat minimioikeudet.
  ​
* LIME (Local Interpretable Model-agnostic Explanations): Tekniikka, jolla selitetään minkä tahansa koneoppimisluokittelijan ennusteet lähentämällä sen paikallisesti tulkittavalla mallilla.
  ​
* Jäsenyyden inferenssihyökkäys: hyökkäys, jonka tavoitteena on selvittää, käytettiinkö tietty datapiste kouluttamaan koneoppimismallia.
  ​
* MITRE ATLAS: Vastustajien uhkakartta tekoälyjärjestelmille; tietopankki vastustajien taktiikoista ja tekniikoista tekoälyjärjestelmiä vastaan.
  ​
* Mallikortti – Mallikortti on dokumentti, joka tarjoaa standardoitua tietoa tekoälymallin suorituskyvystä, rajoitteista, käyttötarkoituksista sekä eettisistä näkökohdista läpinäkyvyyden ja vastuullisen tekoälyn kehityksen edistämiseksi.
  ​
* Mallin poimintahyökkäys: Hyökkäys, jossa hyökkääjä toistuvasti tekee kyselyitä kohdemallille luodakseen toiminnallisesti samankaltaisen kopion ilman valtuutusta.
  ​
* Mallin inversiohyökkäys: hyökkäys, jonka tarkoituksena on rekonstruoida koulutusdata analysoimalla mallin tuottamia tuloksia.
  ​
* Model Lifecycle Management – Tekoälymallin elinkaaren hallinta on prosessi, jossa valvotaan kaikkia tekoälymallin olemassaolon vaiheita, mukaan lukien sen suunnittelu, kehittäminen, käyttöönotto, seuranta, ylläpito ja lopullinen eläköityminen, jotta se pysyy tehokkaana ja tavoitteisiin nähden linjassa.
  ​
* Mallin myrkyttäminen: Haavoittuvuuksien tai takaporttien lisääminen suoraan malliin koulutusprosessin aikana.
  ​
* Mallin varastaminen/varkaus: Toistuvien kyselyjen kautta omistetun mallin kopion tai likimääräisen version hankkiminen.
  ​
* Moni-agenttijärjestelmä: Järjestelmä, joka koostuu useista vuorovaikutteisista tekoälyagentteista, joilla on mahdollisesti erilaiset kyvykkyydet ja tavoitteet.
  ​
* OPA (Open Policy Agent): avoimen lähdekoodin politiikan moottori, joka mahdollistaa yhtenäisen politiikan täytäntöönpanon koko pinon läpi.
  ​
* Yksityisyyttä suojaava koneoppiminen (PPML): Tekniikat ja menetelmät, joilla koulutetaan ja otetaan käyttöön ML-malleja samalla kun suojataan koulutusdatan yksityisyyttä.
  ​
* Kehote-injektio: Hyökkäys, jossa haitalliset ohjeet upotetaan syötteisiin, jotta mallin suunniteltu käyttäytyminen ohitetaan.
  ​
* RAG (Retrieval-Augmented Generation): Tekniikka, joka parantaa suuria kielimalleja hakemalla olennaista tietoa ulkoisista tietolähteistä ennen vastauksen tuottamista.
  ​
* Punaisen tiimin testaus: Aktiivisen testaamisen käytäntö tekoälyjärjestelmille simuloimalla vihamielisiä hyökkäyksiä haavoittuvuuksien tunnistamiseksi.
  ​
* SBOM (Software Bill of Materials): Virallinen rekisteri, joka sisältää ohjelmiston tai tekoälymallien rakentamiseen käytettyjen erilaisten komponenttien yksityiskohdat ja toimitusketjun suhteet.
  ​
* SHAP (SHapley Additive exPlanations): Peliteoreettinen lähestymistapa selittää minkä tahansa koneoppimismallin tuloksen laskemalla kunkin ominaisuuden panoksen ennusteeseen.
  ​
* Toimitusketjuhyökkäys: Järjestelmän vahingoittaminen kohdistamalla toimitusketjun heikosti suojattuihin osiin, kuten kolmansien osapuolien kirjastoihin, datasetteihin tai esikoulutetuihin malleihin.
  ​
* Siirtäminen oppimiseen: Tekniikka, jossa yhdelle tehtävälle kehitettyä mallia käytetään lähtökohtana toisen tehtävän mallille.
  ​
* Vektoritietokanta: Erityisesti korkeidimensionaalisten vektoreiden (upotukset) tallentamiseen suunniteltu tietokanta sekä tehokkaiden samankaltaisuushakujen suorittaminen.
  ​
* Haavoittuvuusskannaus: Automaattiset työkalut, jotka tunnistavat tunnettuja turvallisuushaavoittuvuuksia ohjelmistokomponenteissa, mukaan lukien tekoälykehykset ja riippuvuudet.
  ​
* Vesileimaus: Tekniikat, joilla tekoälyn luomalle sisällölle upotetaan huomaamattomia merkkejä sen alkuperän seuraamiseksi tai tekoälyn tuottaman sisällön havaitsemiseksi.
  ​
* Nollapäivähaavoittuvuus: aiemmin tuntematon haavoittuvuus, jota hyökkääjät voivat hyödyntää ennen kuin kehittäjät luovat ja ottavat käyttöön paikkauksen.

