# C2 使用者輸入驗證

## 控制目標

對用戶輸入的強健驗證是對 AI 系統中一些最具破壞性的攻擊的第一道防線。提示注入攻擊可能覆蓋系統指令、洩露敏感資料，或將模型引導至不被允許的行為。除非設置了專用的過濾器與指令層級架構，研究顯示，利用極長的上下文視窗的 "multi-shot" 越獄攻擊將會有效。此外，微妙的對抗性擾動攻擊--例如 homoglyph swaps 或 leetspeak—-可以悄悄改變模型的決策。

---

## C2.1 提示注入防禦

提示注入是 AI 系統面臨的主要風險之一。為對抗這一策略，防禦措施採用靜態模式過濾、動態分類器，以及指令層級的強制執行等組合。

|   #   | 描述                                                                     | 等級  | 角色  |
| :---: | ---------------------------------------------------------------------- | :-: | :-: |
| 2.1.1 | 驗證使用者輸入是否與不斷更新的已知提示注入模式庫進行篩檢（越獄關鍵字、“忽略先前”、“角色扮演鏈條”、以及間接的 HTML/URL 攻擊）。 |  1  | D/V |
| 2.1.2 | 驗證系統是否強制執行指令層級，使系統或開發人員的訊息覆蓋使用者的指示，即使在上下文視窗擴展之後仍然如此。                   |  1  | D/V |
| 2.1.3 | 確保在每次模型或提示模板發布之前，執行對抗性評估測試（例如紅隊的「many-shot」提示），並具備成功率閾值與用於回歸的自動阻塞機制。   |  2  | D/V |
| 2.1.4 | 驗證來自第三方內容（網頁、PDF 文件、電子郵件）的提示，在被串接到主提示之前，已在隔離的解析上下文中進行淨化。               |  2  |  D  |
| 2.1.5 | 確保所有 prompt-filter 規則更新、分類器模型版本以及封鎖清單變更均受版本控制且可審核。                     |  3  | D/V |

---

## C2.2 對抗性樣本魯棒性

自然語言處理（NLP） 模型仍然容易受到微妙的字元層級或單詞層級擾動的影響，這些擾動人類常常忽略，但模型卻傾向於誤判。

|   #   | 描述                                                   | 等級  | 角色  |
| :---: | ---------------------------------------------------- | :-: | :-: |
| 2.2.1 | 驗證在分詞之前是否已執行基本的輸入正規化步驟（Unicode NFC、同形字映射、前後空白字元去除）。  |  1  |  D  |
| 2.2.2 | 驗證統計異常偵測是否會標示與語言規範相比具有異常高的編輯距離、過度重複的詞元，或嵌入距離異常的輸入。   |  2  | D/V |
| 2.2.3 | 驗證推論流程是否支援可選的對抗性訓練增強的模型變體或防禦層（例如，隨機化、防禦性蒸餾）以應對高風險端點。 |  2  |  D  |
| 2.2.4 | 驗證可疑的對抗性輸入是否已被隔離，並在去識別化個人資料之後，完整載荷已被記錄。              |  2  |  V  |
| 2.2.5 | 驗證穩健性指標（已知攻擊套件的成功率）是否隨時間持續追蹤，若出現回歸，則觸發發布阻塞。          |  3  | D/V |

---

## C2.3 模式、型別與長度驗證

AI 攻擊，包含格式錯誤或尺寸過大的輸入，可能導致解析錯誤、跨欄位的提示詞洩漏，以及資源耗盡。  在執行確定性工具呼叫時，嚴格的資料模式驗證也是前提。

|   #   | 描述                                                                         | 等級  | 角色  |
| :---: | -------------------------------------------------------------------------- | :-: | :-: |
| 2.3.1 | 確認每個 API 或函式呼叫端點是否定義了明確的輸入架構（JSON Schema、Protobuf 或多模態等效），並在提示組裝之前對輸入進行驗證。 |  1  |  D  |
| 2.3.2 | 驗證超過最大詞元數或位元組限制的輸入，將被拒絕，並以安全的錯誤訊息回應，且絕不會被悄悄截斷。                             |  1  | D/V |
| 2.3.3 | 請確保型別檢查（例如數值範圍、枚舉值、影像/音訊的 MIME 類型）在伺服器端執行，而不僅僅在客戶端程式碼中。                    |  2  | D/V |
| 2.3.4 | 確保語義驗證器（例如 JSON Schema）在常數時間內執行，以防止演算法性 DoS 攻擊。                            |  2  |  D  |
| 2.3.5 | 確保驗證失敗會被記錄，並以經過遮蔽的有效載荷片段與不含歧義的錯誤碼呈現，以協助安全分流與事件分級。                          |  3  |  V  |

---

## C2.4 內容與政策審查

開發者應能檢測請求包含不允許內容且在語法上有效的提示（例如違法指令、仇恨言論，以及受版權保護的文本），並阻止它們的傳播。

|   #   | 描述                                                         | 等級  | 角色  |
| :---: | ---------------------------------------------------------- | :-: | :-: |
| 2.4.1 | 確保內容分類器（零樣本或微調）對每個輸入在暴力、自我傷害、仇恨、性內容與非法請求等方面進行評分，且具備可配置的閾值。 |  1  |  D  |
| 2.4.2 | 驗證違反政策的輸入將收到標準化的拒絕或安全回覆，以避免它們傳遞至下游的大型語言模型呼叫。               |  1  | D/V |
| 2.4.3 | 請確認篩選模型或規則集合至少每季度重新訓練/更新一次，並納入新近觀察到的越獄或政策繞過模式。             |  2  |  D  |
| 2.4.4 | 驗證篩選是否符合使用者特定政策（年齡、地區法規限制），這些政策透過在請求時解析的屬性為基礎的規則來實現。       |  2  |  D  |
| 2.4.5 | 驗證篩選日誌是否包含分類器的置信度分數和策略類別標籤，以利於 SOC 關聯與未來的紅隊回放。             |  3  |  V  |

---

## C2.5 輸入速率限制與濫用防範

開發人員應透過限制輸入速率與偵測異常使用模式，防止對人工智慧系統的濫用、資源耗竭與自動化攻擊。

|   #   | 描述                                       | 等級  | 角色  |
| :---: | ---------------------------------------- | :-: | :-: |
| 2.5.1 | 請驗證對所有輸入端點是否實施按使用者、按 IP 以及按 API 金鑰的速率限制。 |  1  | D/V |
| 2.5.2 | 驗證突發與持續速率限制是否已微調，以防止 DoS 攻擊與暴力破解。        |  2  | D/V |
| 2.5.3 | 驗證異常使用模式 (例如連發請求、輸入大量資料) 是否會觸發自動封鎖或升級處理。 |  2  | D/V |
| 2.5.4 | 驗證濫用防護日誌已被保留並審查，以識別新出現的攻擊模式。             |  3  |  V  |

---

## C2.6 多模態輸入驗證

AI 系統應該對非文本輸入（影像、音訊、檔案）進行強健的驗證，以防止注入、繞過或資源濫用。

|   #   | 描述                                   | 等級  | 角色  |
| :---: | ------------------------------------ | :-: | :-: |
| 2.6.1 | 在處理之前，請驗證所有非文本輸入（影像、音訊、檔案）的類型、大小與格式。 |  1  |  D  |
| 2.6.2 | 在資料攝取前，請確保檔案已經被掃描以檢測惡意軟體與隱寫載荷。       |  2  | D/V |
| 2.6.3 | 驗證圖像/音訊輸入是否已檢測出對抗性擾動或已知的攻擊模式。        |  2  | D/V |
| 2.6.4 | 驗證多模態輸入驗證失敗是否被記錄，並觸發用於調查的警報。         |  3  |  V  |

---

## C2.7 輸入來源與歸屬

AI 系統應透過監控並標註所有使用者輸入的來源，來支援審計、濫用追蹤與合規性。

|   #   | 描述                                               | 等級  | 角色  |
| :---: | ------------------------------------------------ | :-: | :-: |
| 2.7.1 | 在導入時，驗證所有使用者輸入是否都附有元資料（使用者識別碼、會話、來源、時間戳記、IP 位址）。 |  1  | D/V |
| 2.7.2 | 確保所有已處理輸入的溯源元資料被保留並可審計。                          |  2  | D/V |
| 2.7.3 | 驗證異常或不受信任的輸入來源是否已被標示，並納入加強審查或阻擋。                 |  2  | D/V |

---

## C2.8 實時自適應威脅偵測

開發人員應該採用先進的人工智慧威脅檢測系統，這些系統能適應新攻擊模式，並以已編譯的模式匹配提供實時保護。

|   #   | 描述                                               | 等級  | 角色  |
| :---: | ------------------------------------------------ | :-: | :-: |
| 2.8.1 | 驗證威脅檢測模式是否已編譯成優化的正則表達式引擎，以實現高性能的實時過濾，並將延遲影響降至最低。 |  1  | D/V |
| 2.8.2 | 確認威脅偵測系統是否為不同的威脅類別維護獨立的模式庫（提示注入、有害內容、敏感資料、系統命令）。 |  1  | D/V |
| 2.8.3 | 驗證自適應威脅偵測是否包含根據攻擊頻率與成功率更新威脅敏感度的機器學習模型。           |  2  | D/V |
| 2.8.4 | 驗證實時威脅情報來源是否能自動更新簽名庫，以納入新的攻擊簽名與 IOCs（入侵指標）。      |  2  | D/V |
| 2.8.5 | 確保威脅偵測的假陽性率持續受到監控，並且模式特異性會自動調整，以降低對合法使用案例的干擾。    |  3  | D/V |
| 2.8.6 | 驗證情境威脅分析是否考慮輸入來源、使用者行為模式與會話歷史，以提高偵測準確性。          |  3  | D/V |
| 2.8.7 | 驗證威脅檢測性能指標（檢測率、處理延遲、資源利用率）是否在實時監控並進行優化。          |  3  | D/V |

---

## C2.9 多模態 安全 驗證 流程

開發人員應為文字、影像、音訊，以及其他 AI 輸入模態提供安全驗證，並具備特定類型的威脅偵測與資源隔離。

|   #   | 描述                                                                         | 等級  | 角色  |
| :---: | -------------------------------------------------------------------------- | :-: | :-: |
| 2.9.1 | 驗證每個輸入模態是否具備專用的安全驗證器，並具備文件化的威脅模式（文本：提示注入，圖像：隱寫術，音訊：頻譜圖攻擊）以及偵測閾值。           |  1  | D/V |
| 2.9.2 | 驗證多模態輸入在隔離沙盒中處理，並具備針對每種模態類型指定的資源限制（記憶體、CPU、處理時間），且這些限制在安全政策中有記錄。           |  2  | D/V |
| 2.9.3 | 驗證跨模態攻擊偵測是否能識別跨越多種輸入類型的協同攻擊（例如，在圖像中嵌入的隱寫有效載荷與文本中的提示注入），並使用相關規則與警報產生機制。     |  2  | D/V |
| 2.9.4 | 驗證多模態驗證失敗會觸發詳細日誌記錄，該日誌記錄包含所有輸入模態、驗證結果、威脅分數，以及以結構化日誌格式進行的相關性分析，便於與 SIEM 整合。 |  3  | D/V |
| 2.9.5 | 核實模態特定內容分類器是否依據有文件記錄的排程（至少每季一次）更新，加入新的威脅模式、對抗性樣本，並使性能基準維持高於基準閾值。           |  3  | D/V |

---

## 參考文獻

* [LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security](https://genai.owasp.org/llmrisk/llm01-prompt-injection/)
* [Generative AI's Biggest Security Flaw Is Not Easy to Fix](https://www.wired.com/story/generative-ai-prompt-injection-hacking)
* [Many-shot jailbreaking \ Anthropic](https://www.anthropic.com/research/many-shot-jailbreaking)
* [$PDF$ OpenAI GPT-4.5 System Card](https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf)
* [Notebook for the CheckThat Lab at CLEF 2024](https://ceur-ws.org/Vol-3740/paper-53.pdf)
* [Mitigate jailbreaks and prompt injections – Anthropic](https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks)
* [Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis](https://ama.drwhy.ai/mitre-attck.html)
* [OWASP Top 10 for LLM Applications 2025 – WorldTech IT](https://wtit.com/blog/2025/04/17/owasp-top-10-for-llm-applications-2025/)
* [OWASP Machine Learning Security Top Ten](https://owasp.org/www-project-machine-learning-security-top-10/)
* [Few words about AI Security – Jussi Metso](https://www.jussimetso.com/index.php/2024/09/28/few-words-about-ai-security/)
* [How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry](https://modelmetry.com/blog/how-to-ensure-llm-output-adheres-to-a-json-schema)
* [Easily enforcing valid JSON schema following – API](https://community.openai.com/t/feature-request-function-calling-easily-enforcing-valid-json-schema-following/263515?utm_source)
* [AI Safety + Cybersecurity R\&D Tracker – Fairly AI](https://www.fairly.ai/blog/ai-cybersecurity-tracker)
* [Anthropic makes 'jailbreak' advance to stop AI models producing harmful results](https://www.ft.com/content/cf11ebd8-aa0b-4ed4-945b-a5d4401d186e)
* [Pattern matching filter rules - IBM](https://www.ibm.com/docs/ssw_aix_71/security/intrusion_pattern_matching_filter_rules.html)
* [Real-time Threat Detection](https://www.darktrace.com/cyber-ai-glossary/real-time-threat-detection)

