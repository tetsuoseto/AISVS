# C2 使用者輸入驗證

## 控制目標

對使用者輸入的強健驗證是防禦對人工智慧系統最具破壞性的某些攻擊的第一道防線。提示注入攻擊可能會覆寫系統指令、洩漏敏感資料，或引導模型朝向不被允許的行為。除非設置專門的過濾器和指令層級，研究顯示利用非常長的上下文視窗進行的「多次嘗試」逃脫攻擊將會有效。此外，細微的對抗性擾動攻擊——如同形異字替換或豹語言——能夠悄無聲息地改變模型的決策。

---

## C2.1 提示注入防禦

提示注入是 AI 系統的主要風險之一。針對此策略的防禦措施結合了靜態模式過濾器、動態分類器以及指令層級管理。

|   #   | 描述                                                                     | 等級  | 角色  |
| :---: | ---------------------------------------------------------------------- | :-: | :-: |
| 2.1.1 | 驗證使用者輸入是否經過篩選，對照持續更新的已知提示注入模式庫（包括越獄關鍵字、「忽略先前指令」、角色扮演鏈、間接 HTML/URL 攻擊）。 |  1  | D/V |
| 2.1.2 | 驗證系統是否執行指令層級，其中系統或開發者訊息會覆蓋使用者指令，即使在上下文視窗擴展後亦然。                         |  1  | D/V |
| 2.1.3 | 驗證每次模型或提示範本發布前，都必須進行對抗性評估測試（例如，紅隊「多次嘗試」提示），並設定成功率門檻及自動阻擋回歸。            |  2  | D/V |
| 2.1.4 | 請確認來自第三方內容（網頁、PDF、電子郵件）的提示在被串接進主提示之前，已在隔離的解析環境中進行清理。                   |  2  |  D  |
| 2.1.5 | 確認所有提示過濾規則更新、分類器模型版本以及阻擋清單變更均受到版本控制並可進行稽核。                             |  3  | D/V |

---

## C2.2 對抗範例抗性

自然語言處理（NLP）模型仍然容易受到人類經常忽略但模型容易錯誤分類的細微字元或詞彙層級擾動的影響。

|   #   | 描述                                                 | 等級  | 角色  |
| :---: | -------------------------------------------------- | :-: | :-: |
| 2.2.1 | 確認基本的輸入正規化步驟（Unicode NFC、同形字元映射、空白修剪）在分詞之前執行。      |  1  |  D  |
| 2.2.2 | 驗證統計異常檢測是否能標記與語言規範有異常高編輯距離、過度重複的標記或異常嵌入距離的輸入。      |  2  | D/V |
| 2.2.3 | 驗證推理流程是否支援可選的對抗訓練強化模型變體或防禦層（例如，隨機化、防禦性蒸餾）以用於高風險端點。 |  2  |  D  |
| 2.2.4 | 確認可疑的對抗性輸入已被隔離，並在刪除個人識別資訊後完整記錄其有效載荷。               |  2  |  V  |
| 2.2.5 | 確認堅固性指標（已知攻擊套件的成功率）隨時間被追蹤，且回歸問題會觸發發行阻擋。            |  3  | D/V |

---

## C2.3 架構、類型及長度驗證

AI 攻擊中使用格式錯誤或過大輸入可能導致解析錯誤、提示跨欄位溢出以及資源耗盡。嚴格的結構驗證也是執行確定性工具調用的必要條件。

|   #   | 描述                                                                            | 等級  | 角色  |
| :---: | ----------------------------------------------------------------------------- | :-: | :-: |
| 2.3.1 | 確認每個 API 或函數呼叫端點都定義了明確的輸入結構（JSON Schema、Protobuf 或多模態等效結構），並且在組裝提示詞之前對輸入進行驗證。 |  1  |  D  |
| 2.3.2 | 驗證超過最大代幣或位元組限制的輸入會以安全錯誤被拒絕，且絕不會被無聲截斷。                                         |  1  | D/V |
| 2.3.3 | 請驗證類型檢查（例如，數值範圍、枚舉值、影像/音頻的 MIME 類型）是在伺服器端強制執行，而不僅僅是在客戶端代碼中。                   |  2  | D/V |
| 2.3.4 | 驗證語義驗證器（例如 JSON Schema）是否以恆定時間運行，以防止演算法式拒絕服務攻擊（DoS）。                          |  2  |  D  |
| 2.3.5 | 驗證失敗時，確認日誌中包含已摘除的有效負載片段及明確的錯誤代碼，以助於安全分流。                                      |  3  |  V  |

---

## C2.4 內容與政策篩選

開發人員應能識別語法上有效但請求禁止內容（如非法指令、仇恨言論及有版權保護的文本）的提示，並防止其擴散。

|   #   | 描述                                                     | 等級  | 角色  |
| :---: | ------------------------------------------------------ | :-: | :-: |
| 2.4.1 | 驗證內容分類器（零次學習或微調版）是否對每個輸入評分暴力、自殘、仇恨、性內容及非法請求，並支援可配置的閾值。 |  1  |  D  |
| 2.4.2 | 驗證違反政策的輸入將會收到標準化的拒絕或安全完成，確保不會傳遞到後續的大型語言模型調用中。          |  1  | D/V |
| 2.4.3 | 確認篩選模型或規則集至少每季重新訓練/更新一次，並納入新觀察到的逃脫限制或規則繞過模式。           |  2  |  D  |
| 2.4.4 | 透過在請求時解析的屬性規則，驗證篩選是否遵守用戶特定政策（年齡、區域法律限制）。               |  2  |  D  |
| 2.4.5 | 驗證篩選日誌是否包含用於SOC關聯和未來紅隊重播的分類器置信度分數和政策類別標籤。              |  3  |  V  |

---

## C2.5 輸入速率限制與濫用防止

開發人員應透過限制輸入速率及偵測異常使用模式，防止對人工智慧系統的濫用、資源耗盡及自動化攻擊。

|   #   | 描述                                       | 等級  | 角色  |
| :---: | ---------------------------------------- | :-: | :-: |
| 2.5.1 | 驗證所有輸入端點是否對每個使用者、每個 IP 及每個 API 金鑰執行速率限制。 |  1  | D/V |
| 2.5.2 | 驗證突發和持續速率限制是否已調整以防止DoS和暴力破解攻擊。           |  2  | D/V |
| 2.5.3 | 驗證異常使用模式（例如，快速連續請求、輸入淹沒）是否會觸發自動封鎖或升級處理。  |  2  | D/V |
| 2.5.4 | 確認濫用防止日誌是否被保留並審查以識別新興攻擊模式。               |  3  |  V  |

---

## C2.6 多模態輸入驗證

人工智慧系統應包含對非文字輸入（影像、音訊、檔案）的強健驗證，以防止注入、規避或資源濫用。

|   #   | 描述                                      | 等級  | 角色  |
| :---: | --------------------------------------- | :-: | :-: |
| 2.6.1 | 確認所有非文字輸入（圖像、音訊、檔案）在處理前均已進行類型、大小及格式的驗證。 |  1  |  D  |
| 2.6.2 | 確認在導入之前，檔案已被掃描以檢測惡意軟體和隱寫有效載荷。           |  2  | D/V |
| 2.6.3 | 確認圖像/音訊輸入是否經過檢查，以防止對抗性擾動或已知攻擊模式。        |  2  | D/V |
| 2.6.4 | 驗證多模態輸入驗證失敗是否被記錄並觸發調查警報。                |  3  |  V  |

---

## C2.7 輸入來源追蹤與歸因

人工智慧系統應透過監控並標記所有使用者輸入的來源，以支持審計、濫用追蹤和合規性。

|   #   | 描述                                        | 等級  | 角色  |
| :---: | ----------------------------------------- | :-: | :-: |
| 2.7.1 | 驗證所有用戶輸入在接收時均已標註元數據（用戶ID、會話、來源、時間戳、IP地址）。 |  1  | D/V |
| 2.7.2 | 驗證所有處理過的輸入皆保留並可審核其來源元資料。                  |  2  | D/V |
| 2.7.3 | 確認異常或不受信任的輸入來源被標記，並受到加強審查或封鎖。             |  2  | D/V |

---

## C2.8 即時自適應威脅檢測

開發人員應該採用先進的 AI 威脅檢測系統，該系統能夠適應新的攻擊模式，並通過編譯模式匹配提供即時保護。

|   #   | 描述                                               | 等級  | 角色  |
| :---: | ------------------------------------------------ | :-: | :-: |
| 2.8.1 | 驗證威脅偵測模式是否已編譯成優化的正則表達式引擎，以實現高效能的即時過濾，並將延遲影響降至最低。 |  1  | D/V |
| 2.8.2 | 請確認威脅檢測系統為不同的威脅類別（提示注入、有害內容、敏感資料、系統指令）維護獨立的模式庫。  |  1  | D/V |
| 2.8.3 | 確認自適應威脅檢測包含機器學習模型，該模型根據攻擊頻率和成功率更新威脅敏感度。          |  2  | D/V |
| 2.8.4 | 驗證即時威脅情報來源是否自動更新模式庫，包含新的攻擊簽名和妥協指標（IOC）。          |  2  | D/V |
| 2.8.5 | 確認持續監控威脅檢測誤報率，並自動調整模式特異性以最小化對合法使用案例的干擾。          |  3  | D/V |
| 2.8.6 | 確認上下文威脅分析考慮了輸入來源、使用者行為模式和會話歷史，以提升偵測準確度。          |  3  | D/V |
| 2.8.7 | 確認威脅檢測效能指標（檢測率、處理延遲、資源利用率）被即時監控並優化。              |  3  | D/V |

---

## C2.9 多模態安全驗證流程

開發人員應針對文字、影像、音訊及其他 AI 輸入模態，提供具體類型的威脅檢測與資源隔離的安全驗證。

|   #   | 描述                                                                 | 等級  | 角色  |
| :---: | ------------------------------------------------------------------ | :-: | :-: |
| 2.9.1 | 驗證每種輸入模態是否具有專用的安全驗證器，並具備有文件記錄的威脅模式（文本：提示注入，圖像：隱寫術，音頻：頻譜圖攻擊）及檢測閾值。  |  1  | D/V |
| 2.9.2 | 確認多模態輸入在隔離的沙箱中處理，並針對每種模態類型設定明確的資源限制（記憶體、CPU、處理時間），且這些限制已在安全政策中記錄。  |  2  | D/V |
| 2.9.3 | 驗證跨模態攻擊檢測能夠識別涵蓋多種輸入類型的協同攻擊（例如，結合影像中的隱寫有效載荷與文字中的提示注入）透過關聯規則和警報生成。   |  2  | D/V |
| 2.9.4 | 驗證多模態驗證失敗是否觸發詳細記錄，包括所有輸入模態、驗證結果、威脅分數以及使用結構化日誌格式的相關分析，以便SIEM整合。     |  3  | D/V |
| 2.9.5 | 確認特定模態內容分類器是否根據文件化的時間表（至少每季）更新，內容包括新的威脅模式、對抗性範例，並確保其效能基準維持在基線閾值以上。 |  3  | D/V |

---

## 參考文獻

* [LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security](https://genai.owasp.org/llmrisk/llm01-prompt-injection/)
* [Generative AI's Biggest Security Flaw Is Not Easy to Fix](https://www.wired.com/story/generative-ai-prompt-injection-hacking)
* [Many-shot jailbreaking \ Anthropic](https://www.anthropic.com/research/many-shot-jailbreaking)
* [$PDF$ OpenAI GPT-4.5 System Card](https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf)
* [Notebook for the CheckThat Lab at CLEF 2024](https://ceur-ws.org/Vol-3740/paper-53.pdf)
* [Mitigate jailbreaks and prompt injections – Anthropic](https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks)
* [Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis](https://ama.drwhy.ai/mitre-attck.html)
* [OWASP Top 10 for LLM Applications 2025 – WorldTech IT](https://wtit.com/blog/2025/04/17/owasp-top-10-for-llm-applications-2025/)
* [OWASP Machine Learning Security Top Ten](https://owasp.org/www-project-machine-learning-security-top-10/)
* [Few words about AI Security – Jussi Metso](https://www.jussimetso.com/index.php/2024/09/28/few-words-about-ai-security/)
* [How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry](https://modelmetry.com/blog/how-to-ensure-llm-output-adheres-to-a-json-schema)
* [Easily enforcing valid JSON schema following – API](https://community.openai.com/t/feature-request-function-calling-easily-enforcing-valid-json-schema-following/263515?utm_source)
* [AI Safety + Cybersecurity R\&D Tracker – Fairly AI](https://www.fairly.ai/blog/ai-cybersecurity-tracker)
* [Anthropic makes 'jailbreak' advance to stop AI models producing harmful results](https://www.ft.com/content/cf11ebd8-aa0b-4ed4-945b-a5d4401d186e)
* [Pattern matching filter rules - IBM](https://www.ibm.com/docs/ssw_aix_71/security/intrusion_pattern_matching_filter_rules.html)
* [Real-time Threat Detection](https://www.darktrace.com/cyber-ai-glossary/real-time-threat-detection)

