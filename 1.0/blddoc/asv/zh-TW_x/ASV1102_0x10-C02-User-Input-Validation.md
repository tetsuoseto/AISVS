# C2 使用者輸入驗證

## 控制目標

對使用者輸入的強健驗證是防範對人工智慧系統造成最嚴重損害的攻擊之第一道防線。提示注入攻擊可以覆蓋系統指令、洩露敏感資料，或引導模型行為偏離允許範圍。除非設有專門的過濾器和指令層級，研究顯示利用非常長的上下文窗口進行的「多重」越獄攻擊將會有效。此外，細微的對抗性擾動攻擊——例如同形異字替換或數字字母混用——能無聲地改變模型的決策。

---

## C2.1 提示注入防禦

提示注入是 AI 系統的主要風險之一。針對這種策略的防禦措施結合了靜態模式過濾器、動態分類器和指令層級強制執行。

|   #   | 描述                                                                       | 層級  | 角色  |
| :---: | ------------------------------------------------------------------------ | :-: | :-: |
| 2.1.1 | 驗證使用者輸入是否經過篩選，針對持續更新的已知提示注入模式庫（越獄關鍵字、「忽略先前內容」、角色扮演鏈、間接 HTML/URL 攻擊）進行檢查。 |  1  | D/V |
| 2.1.2 | 驗證系統是否強制執行指令層級結構，使系統或開發者訊息即使在擴展上下文視窗後，仍能覆蓋使用者指令。                         |  1  | D/V |
| 2.1.3 | 確認在每次模型或提示範本釋出之前，都會進行對抗性評估測試（例如，紅隊「多次執行」提示），並設有成功率門檻和自動阻斷回歸的機制。          |  2  | D/V |
| 2.1.4 | 驗證來自第三方內容（網頁、PDF、電子郵件）的提示是否在被串接到主提示之前，已在獨立解析環境中進行清理。                     |  2  |  D  |
| 2.1.5 | 驗證所有提示過濾規則更新、分類器模型版本和封鎖清單變更皆具版本控制且可審計。                                   |  3  | D/V |

---

## C2.2 對抗範例抵抗性

自然語言處理（NLP）模型仍然容易受到細微的字元或詞彙層級擾動影響，這些擾動通常人類不易察覺，但模型卻往往會誤分類。

|   #   | 描述                                                | 層級  | 角色  |
| :---: | ------------------------------------------------- | :-: | :-: |
| 2.2.1 | 確認基本輸入正規化步驟（Unicode NFC、同形字映射、空白字元修剪）在分詞之前執行。     |  1  |  D  |
| 2.2.2 | 驗證統計異常檢測是否能標記出編輯距離異常高於語言規範、過多重複詞元或嵌入距離異常的輸入。      |  2  | D/V |
| 2.2.3 | 驗證推理管線是否支援選擇性對抗訓練強化的模型變體或防禦層（如隨機化、防禦性蒸餾）以用於高風險端點。 |  2  |  D  |
| 2.2.4 | 確認可疑的對抗性輸入已被隔離，並在刪除個人識別資訊（PII）後，完整有效載荷均已記錄。       |  2  |  V  |
| 2.2.5 | 確認魯棒性指標（已知攻擊套件的成功率）會隨時間進行追蹤，且退化時會觸發發行阻擋。          |  3  | D/V |

---

## C2.3 架構、類型與長度驗證

包含格式錯誤或過大輸入的 AI 攻擊可能導致解析錯誤、提示跨欄位溢出以及資源耗盡。在執行確定性工具呼叫時，嚴格的結構定義強制也是前提條件。

|   #   | 描述                                                                           | 層級  | 角色  |
| :---: | ---------------------------------------------------------------------------- | :-: | :-: |
| 2.3.1 | 確認每個 API 或函數調用端點均定義了明確的輸入結構（JSON Schema、Protobuf 或多模態等效格式），並且在組裝提示之前對輸入進行驗證。 |  1  |  D  |
| 2.3.2 | 驗證超出最大標記或位元組限制的輸入是否會被拒絕，並顯示安全錯誤，且絕不會靜默地截斷。                                   |  1  | D/V |
| 2.3.3 | 確認型別檢查（例如數值範圍、列舉值、圖像/音頻的 MIME 類型）是在伺服器端強制執行，而不僅僅是在用戶端代碼中。                    |  2  | D/V |
| 2.3.4 | 驗證語義驗證器（例如，JSON Schema）是否以恆定時間運行，以防止演算法拒絕服務（DoS）攻擊。                          |  2  |  D  |
| 2.3.5 | 確認驗證失敗時，會以經過遮蔽的有效負載片段和明確無歧義的錯誤代碼記錄，以協助安全事件分類。                                |  3  |  V  |

---

## C2.4 內容與政策審查

開發者應能夠檢測語法上有效但要求不允許內容（例如非法指令、仇恨言論和受版權保護的文本）的提示，並阻止其擴散。

|   #   | 描述                                                      | 層級  | 角色  |
| :---: | ------------------------------------------------------- | :-: | :-: |
| 2.4.1 | 驗證內容分類器（零樣本或微調）是否對每個輸入進行暴力、自殘、仇恨、性內容及非法請求的評分，並具備可配置的閾值。 |  1  |  D  |
| 2.4.2 | 確認違反政策的輸入會收到標準化的拒絕或安全完成回應，以避免傳播至下游的大型語言模型調用。            |  1  | D/V |
| 2.4.3 | 確認篩選模型或規則集至少每季度重新訓練/更新一次，納入新觀察到的越獄或規則繞過模式。              |  2  |  D  |
| 2.4.4 | 透過在請求時解析的屬性基規則，驗證篩選是否符合使用者特定政策（年齡、區域法規限制）。              |  2  |  D  |
| 2.4.5 | 驗證篩選日誌是否包含用於SOC關聯和未來紅隊重放的分類器置信度分數及政策類別標籤。               |  3  |  V  |

---

## C2.5 輸入速率限制與濫用防範

開發人員應透過限制輸入速率和偵測異常使用模式來防止對 AI 系統的濫用、資源耗盡及自動化攻擊。

|   #   | 描述                                     | 層級  | 角色  |
| :---: | -------------------------------------- | :-: | :-: |
| 2.5.1 | 驗證所有輸入端點是否強制執行每用戶、每 IP 及每 API 金鑰的速率限制。 |  1  | D/V |
| 2.5.2 | 確認突發和持續速率限制已調整到防止服務阻斷（DoS）和暴力破解攻擊。     |  2  | D/V |
| 2.5.3 | 確認異常使用模式（例如，連續快速請求、輸入洪流）是否觸發自動封鎖或升級處理。 |  2  | D/V |
| 2.5.4 | 確認濫用防範日誌被保留並審查以識別新興攻擊模式。               |  3  |  V  |

---

## C2.6 多模態輸入驗證

人工智慧系統應包含對非文字輸入（影像、音訊、檔案）的強健驗證，以防止注入、規避或資源濫用。

|   #   | 描述                                    | 層級  | 角色  |
| :---: | ------------------------------------- | :-: | :-: |
| 2.6.1 | 驗證所有非文字輸入（圖像、音訊、檔案）在處理前皆已檢查其類型、大小及格式。 |  1  |  D  |
| 2.6.2 | 確認在資料輸入前，檔案已經過惡意軟體及隱寫載荷的掃描。           |  2  | D/V |
| 2.6.3 | 確認影像/音訊輸入是否經過對抗性擾動或已知攻擊模式的檢查。         |  2  | D/V |
| 2.6.4 | 驗證多模態輸入驗證失敗是否有記錄並觸發警報以進行調查。           |  3  |  V  |

---

## C2.7 輸入來源與歸屬

AI 系統應該通過監控和標記所有用戶輸入的來源來支持審計、濫用追蹤和合規。

|   #   | 描述                                         | 層級  | 角色  |
| :---: | ------------------------------------------ | :-: | :-: |
| 2.7.1 | 驗證所有用戶輸入在接收時均已標註元資料（用戶ID、會話、來源、時間戳記、IP地址）。 |  1  | D/V |
| 2.7.2 | 驗證所有處理過的輸入皆保留並可審核其來源元數據。                   |  2  | D/V |
| 2.7.3 | 確認異常或不受信任的輸入來源被標記並受到加強的審查或阻擋。              |  2  | D/V |

---

## C2.8 即時自適應威脅檢測

開發人員應該使用先進的 AI 威脅偵測系統，能夠適應新的攻擊模式並透過編譯模式匹配提供即時防護。

|   #   | 描述                                             | 層級  | 角色  |
| :---: | ---------------------------------------------- | :-: | :-: |
| 2.8.1 | 確認威脅檢測模式已編譯成優化的正則表達式引擎，以實現高效能的即時過濾，並將延遲影響降至最低。 |  1  | D/V |
| 2.8.2 | 確認威脅檢測系統為不同的威脅類別（提示注入、有害內容、敏感資料、系統指令）維護獨立的模式庫。 |  1  | D/V |
| 2.8.3 | 驗證自適應威脅檢測是否包含機器學習模型，該模型根據攻擊頻率和成功率更新威脅敏感度。      |  2  | D/V |
| 2.8.4 | 確認即時威脅情報源自動使用新的攻擊特徵與妥協指標（IOC）更新模式庫。            |  2  | D/V |
| 2.8.5 | 確認威脅檢測的誤報率持續受到監控，並且模式特異性自動調整以最小化對合法使用情境的干擾。    |  3  | D/V |
| 2.8.6 | 驗證情境威脅分析是否考慮輸入來源、使用者行為模式以及會話歷史，以提升偵測準確性。       |  3  | D/V |
| 2.8.7 | 確認威脅檢測效能指標（檢測率、處理延遲、資源利用率）是否被即時監控與優化。          |  3  | D/V |

---

## C2.9 多模態安全驗證流程

開發人員應針對文字、影像、音訊及其他 AI 輸入模態，提供具有特定威脅檢測與資源隔離的安全驗證。

|   #   | 描述                                                                     | 層級  | 角色  |
| :---: | ---------------------------------------------------------------------- | :-: | :-: |
| 2.9.1 | 驗證每種輸入模式是否具有專用的安全驗證器，並具備紀錄在案的威脅模式（文字：提示注入，影像：隱寫術，音訊：頻譜圖攻擊）及偵測閾值。       |  1  | D/V |
| 2.9.2 | 驗證多模態輸入是否在具備明確資源限制（記憶體、CPU、處理時間）且針對每種模態類型定義的獨立沙箱中處理，並且這些限制已記錄在安全政策中。   |  2  | D/V |
| 2.9.3 | 驗證跨模態攻擊檢測能夠透過相關規則和警報生成，識別跨多種輸入類型的協同攻擊（例如，圖像中的隱寫載荷與文本中的提示注入結合）。         |  2  | D/V |
| 2.9.4 | 驗證多模態驗證失敗是否會觸發詳細日誌記錄，包括所有輸入模態、驗證結果、威脅評分以及使用結構化日誌格式進行的相關性分析，以便整合至 SIEM。 |  3  | D/V |
| 2.9.5 | 驗證特定於模態的內容分類器是否根據文件記錄的時間表（至少每季度）進行更新，包含新的威脅模式、對抗範例，並且性能基準維持在基線閾值以上。    |  3  | D/V |

---

## 參考文獻

* [LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security](https://genai.owasp.org/llmrisk/llm01-prompt-injection/)
* [Generative AI's Biggest Security Flaw Is Not Easy to Fix](https://www.wired.com/story/generative-ai-prompt-injection-hacking)
* [Many-shot jailbreaking \ Anthropic](https://www.anthropic.com/research/many-shot-jailbreaking)
* [$PDF$ OpenAI GPT-4.5 System Card](https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf)
* [Notebook for the CheckThat Lab at CLEF 2024](https://ceur-ws.org/Vol-3740/paper-53.pdf)
* [Mitigate jailbreaks and prompt injections – Anthropic](https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks)
* [Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis](https://ama.drwhy.ai/mitre-attck.html)
* [OWASP Top 10 for LLM Applications 2025 – WorldTech IT](https://wtit.com/blog/2025/04/17/owasp-top-10-for-llm-applications-2025/)
* [OWASP Machine Learning Security Top Ten](https://owasp.org/www-project-machine-learning-security-top-10/)
* [Few words about AI Security – Jussi Metso](https://www.jussimetso.com/index.php/2024/09/28/few-words-about-ai-security/)
* [How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry](https://modelmetry.com/blog/how-to-ensure-llm-output-adheres-to-a-json-schema)
* [Easily enforcing valid JSON schema following – API](https://community.openai.com/t/feature-request-function-calling-easily-enforcing-valid-json-schema-following/263515?utm_source)
* [AI Safety + Cybersecurity R\&D Tracker – Fairly AI](https://www.fairly.ai/blog/ai-cybersecurity-tracker)
* [Anthropic makes 'jailbreak' advance to stop AI models producing harmful results](https://www.ft.com/content/cf11ebd8-aa0b-4ed4-945b-a5d4401d186e)
* [Pattern matching filter rules - IBM](https://www.ibm.com/docs/ssw_aix_71/security/intrusion_pattern_matching_filter_rules.html)
* [Real-time Threat Detection](https://www.darktrace.com/cyber-ai-glossary/real-time-threat-detection)

