# 10 對抗性魯棒性與隱私防禦

## 控制目標

確保 AI 模型在面對規避攻擊、推理攻擊、提取攻擊或中毒攻擊時，仍然保持可靠性、隱私保護能力與抗濫用性。

---

## 10.1 模型對齊與安全性

防範有害或違反政策的輸出。

|   #    | 描述                                             | 等級  | 角色  |
| :----: | ---------------------------------------------- | :-: | :-: |
| 10.1.1 | 請確認對齊測試套件（紅隊提示、越狱探測、禁止內容）已經經過版本控制，並在每次模型發布時執行。 |  1  | D/V |
| 10.1.2 | 驗證拒絕與安全完成護欄是否已被執行。                             |  1  |  D  |
| 10.1.3 | 驗證自動評估器是否能測量有害內容比例，並在超過設定閾值時標示性能退化。            |  2  | D/V |
| 10.1.4 | 驗證對抗越獄訓練是否已被記錄且可重現。                            |  2  |  D  |
| 10.1.5 | 驗證形式化的政策合規證明或經認證的監控是否覆蓋關鍵領域。                   |  3  |  V  |

---

## 10.2 對抗性樣本-加固

提高對被操控輸入的魯棒性。健壯的對抗訓練與基準測試成績是當前的最佳實踐。

|   #    | 描述                                          | 等級  | 角色  |
| :----: | ------------------------------------------- | :-: | :-: |
| 10.2.1 | 驗證專案倉庫是否包含具有可重現種子之對抗性訓練配置。                  |  1  |  D  |
| 10.2.2 | 驗證對抗性樣本偵測是否在生產管線中觸發阻塞警報。                    |  2  | D/V |
| 10.2.4 | 驗證經認證的魯棒性證明或區間界限證書至少涵蓋最關鍵的前幾個類別。            |  3  |  V  |
| 10.2.5 | 驗證 是否 回歸測試 使用 自適應 攻擊 以 確認 沒有 可 測量 的 魯棒性 損失。 |  3  |  V  |

---

## 10.3 成員身份推斷的緩解

限制判斷某條紀錄是否出現在訓練資料中的能力。差分隱私和置信分數遮罩仍然是目前已知最有效的防禦措施。

|   #    | 描述                                                      | 等級  | 角色  |
| :----: | ------------------------------------------------------- | :-: | :-: |
| 10.3.1 | 驗證每個查詢的熵正則化或溫度縮放是否能降低過度自信的預測。                           |  1  |  D  |
| 10.3.2 | 驗證訓練是否對敏感資料集使用 ε-有界的差分隱私優化。                             |  2  |  D  |
| 10.3.3 | 驗證攻擊模擬（shadow-model 或 black-box）在留出資料上的攻擊 AUC 值 ≤ 0.60。 |  2  |  V  |

---

## 10.4 模型反演抗性

防止私有屬性被重建。 最近的調查強調輸出截斷與差分隱私（DP）保證作為實用的防禦措施。

|   #    | 描述                             | 等級  | 角色  |
| :----: | ------------------------------ | :-: | :-: |
| 10.4.1 | 驗證敏感屬性不會被直接輸出；如有需要，請使用分桶或單向轉換。 |  1  |  D  |
| 10.4.2 | 驗證查詢速率限制是否會對同一主體的重複自適應查詢進行節流。  |  1  | D/V |
| 10.4.3 | 驗證該模型是否以隱私保護的噪音進行訓練。           |  2  |  D  |

---

## 10.5 模型-提取 防禦

偵測並遏止未經授權的複製。建議採用水印技術與查詢模式分析。

|   #    | 描述                                                         | 等級  | 角色  |
| :----: | ---------------------------------------------------------- | :-: | :-: |
| 10.5.1 | 驗證推理閘道是否能實施全域與逐個 API 金鑰的速率限制，且其設定是否經過調整以符合模型的記憶閾值。         |  1  |  D  |
| 10.5.2 | 驗證 查詢熵 與 輸入多樣性 統計 是否 能 為 自動化 提取 偵測器 提供 資料。                 |  2  | D/V |
| 10.5.3 | 驗證 脆弱型 或 機率性 水印 在 對 可疑 克隆體 的 ≤ 1 000 次 查詢 中 可 證明 p < 0.01。 |  2  |  V  |
| 10.5.4 | 驗證水印密鑰與觸發集合是否儲存在硬體安全模組中，並每年輪換。                             |  3  |  D  |
| 10.5.5 | 確認提取警報事件是否包含不當查詢，並與事件回應作業手冊整合。                             |  3  |  V  |

---

## 10.6 推理時的 污染-數據 檢測

識別並中和帶有後門或被污染的輸入。

|   #    | 描述                                                    | 等級  | 角色  |
| :----: | ----------------------------------------------------- | :-: | :-: |
| 10.6.1 | 在模型推論之前，請確保輸入會經過異常檢測器 (例如 STRIP、consistency-scoring)。 |  1  |  D  |
| 10.6.2 | 確保偵測器的閾值在乾淨的/被污染的驗證集上調整，以實現小於5%的假陽性率。                 |  1  |  V  |
| 10.6.3 | 驗證被標記為受污染的輸入是否會觸發軟封鎖和人工審核工作流程。                        |  2  |  D  |
| 10.6.4 | 驗證檢測器是否已經接受過以自適應、無觸發的後門攻擊進行的壓力測試。                     |  2  |  V  |
| 10.6.5 | 確保偵測效能指標已被記錄，並定期在新的威脅情報下重新評估。                         |  3  |  D  |

---

## 10.7 動態安全策略自適應

基於威脅情報與行為分析的實時安全策略更新。

|   #    | 描述                                      | 等級  | 角色  |
| :----: | --------------------------------------- | :-: | :-: |
| 10.7.1 | 驗證安全策略能在不重新啟動代理程式的情況下動態更新，同時維護策略版本的完整性。 |  1  | D/V |
| 10.7.2 | 驗證政策更新是否經由授權的資安人員以密碼學簽章簽署，並在套用前進行驗證。    |  2  | D/V |
| 10.7.3 | 驗證動態策略變更是否已完整記錄，包含審計追蹤、變更理由、批准鏈以及回滾程序。  |  2  | D/V |
| 10.7.4 | 驗證自適應安全機制是否根據風險情境與行為模式調整威脅偵測的敏感度。       |  3  | D/V |
| 10.7.5 | 驗證策略自適應的決策具備可解釋性，並為安全團隊審查提供證據軌跡。        |  3  | D/V |

---

## 10.8 基於反射的安全分析

通過 智能體的 自我反思 與 元-認知分析 進行 安全驗證。

|   #    | 描述                                                    | 等級  | 角色  |
| :----: | ----------------------------------------------------- | :-: | :-: |
| 10.8.1 | 驗證智能體的反思機制是否包含以安全為重點的對決策與行為的自我評估。                     |  1  | D/V |
| 10.8.2 | 確保反思輸出已被驗證，以防止對自我評估機制被對抗性輸入操縱。                        |  2  | D/V |
| 10.8.3 | 驗證元認知安全分析是否能識別代理推理過程中的潛在偏見、操縱或妥協。                     |  2  | D/V |
| 10.8.4 | 驗證基於反射的安全警告是否會觸發增強監控，以及潛在的人為干預工作流程。                   |  3  | D/V |
| 10.8.5 | 驗證 從 安全 反思 中 持續 學習 是否 能 在 不 降低 正當 功能 的 情況 下 提升 威脅 偵測。 |  3  | D/V |

---

## 10.9 演化與自我提升的安全性

針對具自我修改與演化能力的代理系統的安全控制。

|   #    | 描述                                 | 等級  | 角色  |
| :----: | ---------------------------------- | :-: | :-: |
| 10.9.1 | 驗證自我修改能力是否僅限於指定的安全區域，並以正式驗證邊界加以界定。 |  1  | D/V |
| 10.9.2 | 確保演化提案在實施前已經經過安全影響評估。              |  2  | D/V |
| 10.9.3 | 驗證自我改進機制是否具備回滾能力與完整性驗證。            |  2  | D/V |
| 10.9.4 | 驗證元學習的安全性是否能阻止對改進算法的對抗性操控。         |  3  | D/V |
| 10.9.5 | 驗證遞歸自我提升受到正式安全約束所限制，並提供收斂性的數學證明。   |  3  | D/V |

---

### 參考文獻

* [MITRE ATLAS adversary tactics for ML](https://atlas.mitre.org/)
* [NIST AI Risk Management Framework 1.0, 2023](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [OWASP Top 10 for LLM Applications, 2025](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Adversarial Training: A Survey — Zhao et al., 2024](https://arxiv.org/abs/2410.15042)
* [RobustBench adversarial-robustness benchmark](https://robustbench.github.io/)
* [Membership-Inference & Model-Inversion Risk Survey, 2025](https://www.sciencedirect.com/science/article/abs/pii/S0950705125003867)
* [PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023](https://ojs.aaai.org/index.php/AAAI/article/view/26289)
* [Model-Inversion Attacks & Defenses Survey — AI Review, 2025](https://link.springer.com/article/10.1007/s10462-025-11248-0)
* [Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024](https://doi.org/10.1109/TDSC.2023.3261327)
* [Fragile Model Watermarking Survey — 2025](https://www.sciencedirect.com/science/article/abs/pii/S0165168425002026)
* [Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025](https://arxiv.org/abs/2503.22759)
* [BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024](https://arxiv.org/abs/2405.15269)

