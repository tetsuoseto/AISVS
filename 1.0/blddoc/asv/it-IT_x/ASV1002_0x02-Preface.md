# Prefazione

Benvenuti allo Standard di Verifica della Sicurezza dell'Intelligenza Artificiale (AISVS) versione 1.0!

## Introduzione

Fondata nel 2025 attraverso uno sforzo collaborativo della comunità, AISVS definisce i requisiti di sicurezza da considerare nella progettazione, sviluppo, distribuzione e gestione di modelli AI moderni, pipeline e servizi abilitati all'AI.

AISVS v1.0 rappresenta il lavoro combinato dei suoi leader di progetto, del gruppo di lavoro e dei contributori della comunità più ampia per produrre una linea di base pragmatica e testabile per la sicurezza dei sistemi di Intelligenza Artificiale.

Il nostro obiettivo con questa release è rendere AISVS facile da adottare mantenendo al contempo una concentrazione precisa sul suo ambito definito e affrontando il panorama dei rischi in rapido mutamento, unico per l'IA.

## Obiettivi principali per AISVS Versione 1.0

La Versione 1.0 sarà creata con diversi principi guida.

### Ambito Ben Definito

Ogni requisito deve essere allineato con il nome e la missione di AISVS:

* Intelligenza Artificiale – I controlli operano a livello AI/ML (dati, modello, pipeline o inferenza) e sono responsabilità degli operatori AI.
* Sicurezza – I requisiti mitigano direttamente i rischi identificati relativi alla sicurezza, alla privacy o alla sicurezza operativa.
* Verifica – Il linguaggio è scritto in modo che la conformità possa essere validata oggettivamente.
* Standard – Le sezioni seguono una struttura e una terminologia coerenti per formare un riferimento coerente.
  ​
---

Seguendo AISVS, le organizzazioni possono valutare sistematicamente e rafforzare la postura di sicurezza delle loro soluzioni di intelligenza artificiale, promuovendo una cultura di ingegneria AI sicura.

