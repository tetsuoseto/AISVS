# Prefazione

Benvenuto nello Standard di Verifica della Sicurezza dell'Intelligenza Artificiale (AISVS) versione 1.0!

## Introduzione

Fondata nel 2025 attraverso uno sforzo collaborativo della comunità, AISVS definisce i requisiti di sicurezza da considerare durante la progettazione, lo sviluppo, l'implementazione e l'operatività di modelli di IA moderni, pipeline e servizi abilitati dall'IA.

AISVS v1.0 rappresenta il lavoro congiunto dei suoi responsabili di progetto, del gruppo di lavoro e dei contributori della comunità più ampia, al fine di produrre una base di riferimento pragmatica e testabile per mettere in sicurezza i sistemi di IA.

Il nostro obiettivo con questo rilascio è rendere AISVS facile da adottare, mantenendo al contempo una focalizzazione estremamente mirata sul suo ambito definito e affrontando il panorama dei rischi in rapida evoluzione tipico dell'IA.

## Obiettivi chiave per AISVS Versione 1.0

La versione 1.0 sarà creata con diversi principi guida.

### Ambito ben definito

Ogni requisito deve allinearsi al nome e alla missione di AISVS:

* Intelligenza Artificiale – i controlli operano a livello AI/ML (dati, modello, pipeline o inferenza) e sono responsabilità dei professionisti dell'IA.
* Sicurezza – I requisiti mitigano direttamente i rischi identificati relativi alla sicurezza, alla privacy o alla tutela della sicurezza.
* Verificazione – Il linguaggio è scritto in modo che la conformità possa essere oggettivamente validata.
* Standard – Le sezioni seguono una struttura e una terminologia coerenti per formare un riferimento coerente.
  ​
---

Seguendo AISVS, le organizzazioni possono valutare in modo sistematico e rafforzare il profilo di sicurezza delle loro soluzioni di IA, promuovendo una cultura dell'ingegneria dell'IA sicura.

