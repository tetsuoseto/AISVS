# Frontespizio

## Informazioni sullo standard

Lo Standard di Verifica della Sicurezza dell'Intelligenza Artificiale (AISVS) è un catalogo di requisiti di sicurezza guidato dalla comunità che scienziati dei dati, ingegneri MLOps, architetti software, sviluppatori, tester, professionisti della sicurezza, fornitori di strumenti, regolatori e consumatori possono utilizzare per progettare, costruire, testare e verificare sistemi e applicazioni AI affidabili. Fornisce un linguaggio comune per la specifica dei controlli di sicurezza lungo l'intero ciclo di vita dell'AI — dalla raccolta dei dati e sviluppo del modello alla distribuzione e monitoraggio continuo — in modo che le organizzazioni possano misurare e migliorare la resilienza, la privacy e la sicurezza delle loro soluzioni AI.

## Copyright e licenza

Versione 0.1 (Prima Bozza Pubblica - Lavori in Corso), 2025  

![license](../images/license.png)

Copyright © 2025 Il Progetto AISVS.  

Rilasciato sotto la[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
Per qualsiasi riutilizzo o distribuzione, devi comunicare chiaramente i termini di licenza di questo lavoro ad altri.

## Responsabili di progetto

|            |                         |
| ---------- | ----------------------- |
| Jim Manico | Aras “Russ” Memisyazici |

## Collaboratori e Revisori

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS è uno standard completamente nuovo creato appositamente per affrontare le sfide uniche di sicurezza dei sistemi di intelligenza artificiale. Sebbene si ispiri alle migliori pratiche di sicurezza più ampie, ogni requisito di AISVS è stato sviluppato da zero per riflettere il panorama delle minacce dell’AI e per aiutare le organizzazioni a costruire soluzioni AI più sicure e resilienti.

