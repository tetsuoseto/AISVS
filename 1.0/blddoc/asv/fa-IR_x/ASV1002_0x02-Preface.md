# مقدمه

به استاندارد تأیید امنیت هوش مصنوعی (AISVS) نسخه 1.0 خوش آمدید!

## مقدمه

AISVS که در سال 2025 از طریق یک تلاش مشترک جامعه‌ای تاسیس شد، الزامات امنیتی را که باید هنگام طراحی، توسعه، استقرار و بهره‌برداری از مدل‌های هوش مصنوعی مدرن، خطوط لوله و خدمات فعال‌شده توسط هوش مصنوعی در نظر گرفته شود، تعریف می‌کند.

AISVS v1.0 نمایانگر همکاری مشترک رهبران پروژه، گروه کاری و مشارکت‌کنندگان گسترده‌تر جامعه برای ایجاد یک مبنای عملی و قابل آزمایش در زمینه امنیت سیستم‌های هوش مصنوعی است.

هدف ما در این نسخه این است که AISVS را به‌گونه‌ای ساده برای پذیرش ارائه دهیم در حالی که تمرکز دقیقی بر دامنه تعریف‌شده آن داشته و به چشم‌انداز ریسک‌های به سرعت در حال تحول که منحصر به هوش مصنوعی است، پاسخ دهیم.

## اهداف کلیدی برای نسخه 1.0 AISVS

نسخه 1.0 با چندین اصل راهنما ایجاد خواهد شد.

### دامنه مشخص و واضح

هر الزامی باید با نام و ماموریت AISVS همسو باشد:

* هوش مصنوعی – کنترل‌ها در لایه AI/ML (داده، مدل، خط لوله، یا استنتاج) عمل می‌کنند و مسئولیت آن‌ها بر عهده متخصصان هوش مصنوعی است.
* امنیت – الزامات به‌طور مستقیم خطرات شناسایی‌شده در زمینه امنیت، حریم خصوصی یا ایمنی را کاهش می‌دهند.
* اعتبارسنجی – زبان به گونه‌ای نوشته شده است که انطباق آن بتواند به صورت عینی تأیید شود.
* استاندارد – بخش‌ها ساختار و اصطلاحات ثابتی را دنبال می‌کنند تا یک مرجع منسجم ایجاد کنند.
  ​
---

با پیروی از AISVS، سازمان‌ها می‌توانند به‌طور سیستماتیک وضعیت امنیتی راهکارهای هوش مصنوعی خود را ارزیابی و تقویت کنند و فرهنگ مهندسی هوش مصنوعی امن را ترویج دهند.

