# پیشگفتار

به استاندارد صحت‌سنجی امنیت هوش مصنوعی (AISVS) نسخه 1.0 خوش آمدید!

## مقدمه

AISVS که در سال 2025 از طریق تلاش‌های مشترک جامعه تأسیس شد، الزامات امنیتی را که باید هنگام طراحی، توسعه، استقرار و بهره‌برداری از مدل‌های مدرن هوش مصنوعی، خطوط لوله و خدمات مجهز به هوش مصنوعی در نظر گرفته شوند، تعریف می‌کند.

AISVS v1.0 نشان‌دهنده کار مشترک رهبران پروژه، گروه کاری و مشارکت‌کنندگان گسترده‌تر جامعه برای تولید یک خط‌مبنای عملی و قابل آزمون به منظور تأمین امنیت سیستم‌های هوش مصنوعی است.

هدف ما از این نسخه، ساده‌سازی پذیرش AISVS در حالی است که به طور دقیق روی دامنه تعریف‌شده آن متمرکز مانده و به چشم‌انداز ریسک‌های به‌سرعت در حال تحول و منحصربه‌فرد هوش مصنوعی پاسخ می‌دهد.

## اهداف کلیدی برای نسخه 1.0 AISVS

نسخه 1.0 با چندین اصول راهنما ساخته خواهد شد.

### دامنه به‌خوبی تعریف شده

هر الزامی باید با نام و ماموریت AISVS همسو باشد:

* هوش مصنوعی – کنترل‌ها در لایه AI/ML (داده، مدل، خط لوله، یا استنتاج) اجرا می‌شوند و مسئولیت آن‌ها بر عهده متخصصان هوش مصنوعی است.
* امنیت – الزامات به‌طور مستقیم ریسک‌های شناسایی شده امنیتی، حریم خصوصی یا ایمنی را کاهش می‌دهند.
* تأیید صحت – زبان به گونه‌ای نوشته شده است که انطباق می‌تواند به صورت عینی ارزیابی شود.
* استاندارد – بخش‌ها ساختار و اصطلاحات یکسانی را دنبال می‌کنند تا یک مرجع منسجم تشکیل دهند.
  ​
---

با دنبال کردن AISVS، سازمان‌ها می‌توانند به صورت نظام‌مند موضع امنیتی راه‌حل‌های هوش مصنوعی خود را ارزیابی و تقویت کنند و فرهنگ مهندسی هوش مصنوعی امن را پرورش دهند.

