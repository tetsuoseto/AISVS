# پیشگفتار

به استاندارد ارزیابی امنیت هوش مصنوعی (AISVS) نسخه 1.0 خوش آمدید!

## مقدمه

AISVS در سال 2025 و از طریق تلاشی جمعی از سوی جامعه تأسیس شد و الزامات امنیتی را تعریف می‌کند که هنگام طراحی، توسعه، استقرار و عملیات مدل‌های هوش مصنوعی مدرن، پیپلاین‌ها و خدمات مبتنی بر هوش مصنوعی باید در نظر گرفته شوند.

AISVS v1.0 نمایانگر کار مشترک رهبران پروژه، کارگروه و مشارکت‌کنندگان جامعه گسترده آن است تا یک خط پایه عملی و قابل آزمون برای ایمن‌سازی سامانه‌های هوش مصنوعی ایجاد کند.

هدف ما از این انتشار این است که AISVS را برای پذیرش آسان فراهم آورد، در عین حال با laser‑focused بودن بر دامنهٔ تعریف‌شدهٔ آن و رسیدگی به چشم‌انداز ریسکِ به‌سرعت در حال تحولِ منحصربه‌هوش مصنوعی.

## اهداف کلیدی برای AISVS نسخه 1.0

نسخه 1.0 با چندین اصل راهنما تدوین خواهد شد.

### دامنه به‌خوبی تعریف‌شده

هر الزام باید با نام و مأموریت AISVS همسو باشد:

* هوش مصنوعی – کنترل‌ها در لایه هوش مصنوعی/یادگیری ماشین (داده‌ها، مدل، خط لوله یا استنتاج) عمل می‌کنند و مسئولیت آن بر عهدهٔ متخصصان هوش مصنوعی است.
* امنیت – الزامات مستقیماً ریسک‌های امنیتی، حریم خصوصی یا ایمنی شناسایی‌شده را کاهش می‌دهد.
* تایید – زبان به‌گونه‌ای نوشته می‌شود تا انطباق به‌طور عینی اعتبارسنجی شود.
* استاندارد – بخش‌ها از ساختار و اصطلاحات یکسان پیروی می‌کنند تا مرجع همسو و منسجم ایجاد شود.
  ​
---

با پیروی از AISVS، سازمان‌ها می‌توانند به‌طور سیستماتیک امنیت راه‌حل‌های هوش مصنوعی خود را ارزیابی و تقویت کنند و فرهنگی از مهندسی امن هوش مصنوعی را ترویج نمایند.

