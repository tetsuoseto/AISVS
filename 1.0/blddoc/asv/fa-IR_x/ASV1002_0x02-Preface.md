# مقدمه

به استاندارد تایید امنیت هوش مصنوعی (AISVS) نسخه 1.0 خوش آمدید!

## مقدمه

AISVS که در سال 2025 از طریق همکاری جامعه شکل گرفت، الزامات امنیتی را که باید هنگام طراحی، توسعه، استقرار و بهره‌برداری از مدل‌های مدرن هوش مصنوعی، خطوط لوله و خدمات فعال‌شده با هوش مصنوعی در نظر گرفته شوند، تعریف می‌کند.

AISVS v1.0 نمایانگر همکاری مشترک رهبران پروژه، گروه کاری و مشارکت‌کنندگان گسترده‌تر جامعه است تا یک پایه عملی و قابل آزمایش برای ایمن‌سازی سیستم‌های هوش مصنوعی ارائه دهد.

هدف ما در این نسخه این است که AISVS را به گونه‌ای ارائه دهیم که استفاده از آن ساده باشد، در حالی که به طور دقیق بر دامنه تعریف شده آن متمرکز مانده و به چشم‌انداز ریسک به سرعت در حال تحول که منحصربه‌فرد هوش مصنوعی است، پرداخته شود.

## اهداف کلیدی برای نسخه 1.0 AISVS

نسخه 1.0 با چندین اصل راهنما ایجاد خواهد شد.

### حوزه مشخص و تعریف شده

هر الزام باید با نام و مأموریت AISVS هماهنگ باشد:

* هوش مصنوعی – کنترل‌ها در لایه AI/ML (داده، مدل، خط لوله، یا استنتاج) عمل می‌کنند و مسئولیت آن‌ها بر عهده متخصصان هوش مصنوعی است.
* امنیت – الزامات به‌طور مستقیم خطرات شناسایی‌شده امنیتی، حریم خصوصی یا ایمنی را کاهش می‌دهند.
* اعتبارسنجی – زبان به گونه‌ای نوشته شده است که انطباق آن بتواند به طور عینی تایید شود.
* استاندارد – بخش‌ها ساختار و اصطلاحات یکسانی را دنبال می‌کنند تا مرجع منسجمی ایجاد کنند.
  ​
---

با پیروی از AISVS، سازمان‌ها می‌توانند به‌طور سیستماتیک وضعیت امنیتی راه‌حل‌های هوش مصنوعی خود را ارزیابی و تقویت کنند و فرهنگ مهندسی امن هوش مصنوعی را ترویج دهند.

