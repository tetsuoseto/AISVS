# پیش‌گفتار

به استاندارد تأیید امنیت هوش مصنوعی (AISVS) نسخه 1.0 خوش آمدید!

## مقدمه

AISVS که در سال 2025 از طریق یک تلاش جمعی جامعه تأسیس شد، الزامات امنیتی را که باید هنگام طراحی، توسعه، استقرار و راه‌اندازی مدل‌های مدرن هوش مصنوعی، خطوط لوله و خدمات فعال‌شده با هوش مصنوعی در نظر گرفته شوند، تعریف می‌کند.

AISVS v1.0 نمایانگر تلاش مشترک سرپرستان پروژه، گروه کاری و مشارکت‌کنندگان گسترده‌تر جامعه است تا یک خط مبنای عملی و قابل آزمون برای امن‌سازی سیستم‌های هوش مصنوعی ارائه دهد.

هدف ما با این نسخه این است که AISVS را به طور ساده قابل پذیرش کنیم در حالی که به طور دقیق به دامنه تعریف‌شده آن متمرکز بمانیم و به چشم‌انداز ریسک به سرعت در حال تحول که منحصر به هوش مصنوعی است رسیدگی کنیم.

## اهداف کلیدی برای نسخه 1.0 AISVS

نسخه 1.0 با چندین اصول راهنمایی ایجاد خواهد شد.

### دامنه‌ مشخص و تعریف‌شده

هر الزام باید با نام و مأموریت AISVS همسو باشد:

* هوش مصنوعی – کنترل‌ها در لایه هوش مصنوعی/یادگیری ماشین (داده، مدل، خط لوله یا استنتاج) عمل می‌کنند و مسئولیت آن بر عهده متخصصان هوش مصنوعی است.
* امنیت – الزامات به طور مستقیم خطرات شناسایی شده امنیتی، حریم خصوصی یا ایمنی را کاهش می‌دهند.
* تأیید صحت – زبان به گونه‌ای نوشته شده است که انطباق آن بتواند به‌صورت عینی اعتبارسنجی شود.
* استاندارد – بخش‌ها از ساختار و اصطلاحات یکسانی پیروی می‌کنند تا مرجعی منسجم تشکیل دهند.
  ​
---

با پیروی از AISVS، سازمان‌ها می‌توانند به‌طور سیستماتیک وضعیت امنیتی راه‌حل‌های هوش مصنوعی خود را ارزیابی و تقویت کنند و فرهنگ مهندسی هوش مصنوعی ایمن را ترویج دهند.

