# پیشگفتار

به استاندارد تایید امنیت هوش مصنوعی (AISVS) نسخه 1.0 خوش آمدید!

## مقدمه

AISVS که در سال 2025 از طریق یک تلاش مشترک جامعه تأسیس شد، الزامات امنیتی را که باید هنگام طراحی، توسعه، استقرار و بهره‌برداری از مدل‌های مدرن هوش مصنوعی، خطوط لوله و خدمات فعال‌شده با هوش مصنوعی در نظر گرفته شوند، تعریف می‌کند.

AISVS نسخه 1.0 نمایانگر کار مشترک سرپرستان پروژه، گروه کاری و مشارکت‌کنندگان گسترده‌تر جامعه برای ایجاد یک معیار پایه عملی و قابل آزمایش برای امنیت سیستم‌های هوش مصنوعی است.

هدف ما در این نسخه این است که AISVS را به‌سادگی قابل استفاده کنیم و در عین حال با تمرکز دقیق روی حوزه تعریف‌شده آن و پرداختن به چشم‌انداز خطرات به‌سرعت در حال تحول که مختص هوش مصنوعی است، پیش رویم.

## اهداف کلیدی برای نسخه 1.0 AISVS

نسخه 1.0 با چندین اصل راهنما ایجاد خواهد شد.

### دامنه تعریف‌شده واضح

هر الزام باید با نام و مأموریت AISVS همسو باشد:

* هوش مصنوعی – کنترل‌ها در لایه‌ی AI/ML (داده، مدل، خط لوله، یا استنتاج) عمل می‌کنند و مسئولیت آن‌ها با متخصصان هوش مصنوعی است.
* امنیت – الزامات به طور مستقیم خطرات شناسایی شده امنیتی، حریم خصوصی یا ایمنی را کاهش می‌دهند.
* تأیید - زبان به گونه‌ای نوشته شده است که تطابق آن بتواند به طور عینی اعتبارسنجی شود.
* استاندارد – بخش‌ها ساختار و اصطلاحات ثابتی دارند تا یک مرجع منسجم را شکل دهند.
  ​
---

با پیروی از AISVS، سازمان‌ها می‌توانند به‌طور سیستماتیک وضعیت امنیتی راه‌حل‌های هوش مصنوعی خود را ارزیابی و تقویت کنند و فرهنگ مهندسی امن هوش مصنوعی را پرورش دهند.

