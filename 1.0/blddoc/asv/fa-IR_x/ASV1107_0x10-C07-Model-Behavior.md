# رفتار مدل C7، کنترل خروجی و تضمین ایمنی

## هدف کنترل

خروجی‌های مدل باید ساختارمند، قابل اعتماد، ایمن، قابل توضیح و به‌طور مداوم در محیط تولید نظارت شده باشند. انجام این کار موجب کاهش توهمات، نفوذهای حریم خصوصی، محتوای مضر و اقدامات کنترل‌نشده می‌شود و همزمان اعتماد کاربران و انطباق با مقررات را افزایش می‌دهد.

---

## C7.1 اجرای قالب خروجی

طرح‌های ساختاری سختگیرانه، رمزگشایی محدود شده و اعتبارسنجی پس‌زمینه باعث جلوگیری از انتشار محتوای نادرست یا مخرب می‌شوند.

|   #   | توضیحات                                                                                                                                                                             | سطح | نقش |
| :---: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 7.1.1 | اطمینان حاصل کنید که طرح‌های پاسخ (مثلاً JSON Schema) در فرمان سیستمی ارائه شده‌اند و هر خروجی به‌طور خودکار اعتبارسنجی می‌شود؛ خروجی‌های ناسازگار موجب تعمیر یا رد شدن می‌شوند.    |  1  | D/V |
| 7.1.2 | تأیید کنید که رمزگشایی محدود شده (توقف توکن‌ها، عبارات منظم، حداکثر توکن‌ها) فعال باشد تا از سرریز یا کانال‌های جانبی تزریق ورودی جلوگیری شود.                                      |  1  | D/V |
| 7.1.3 | تأیید کنید که مؤلفه‌های پایین‌دست خروجی‌ها را به‌عنوان داده‌های غیرقابل اعتماد در نظر می‌گیرند و آن‌ها را در برابر شِماها یا دِسریالایزرهای ایمن در برابر تزریق اعتبارسنجی می‌کنند. |  2  | D/V |
| 7.1.4 | اطمینان حاصل کنید که رویدادهای خروجی نادرست ثبت، محدودیت نرخ اعمال شده و به نظارت ارائه می‌شوند.                                                                                    |  3  |  V  |

---

## C7.2 تشخیص و کاهش هذیان

برآورد عدم قطعیت و استراتژی‌های جایگزین پاسخ‌های ساختگی را محدود می‌کنند.

|   #   | توضیحات                                                                                                                                                    | سطح | نقش |
| :---: | ---------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 7.2.1 | تأیید کنید که احتمال‌های لگاریتمی در سطح توکن، انسجام خود مجموعه‌ای، یا آشکارسازهای تجربه‌ی دقیق تنظیم‌شده، امتیاز اطمینان را به هر پاسخ اختصاص می‌دهند.   |  1  | D/V |
| 7.2.2 | تأیید کنید که پاسخ‌های زیر آستانه اطمینان قابل تنظیم، فرآیندهای جایگزین (مانند تولید تقویت‌شده با بازیابی، مدل ثانویه، یا بازبینی انسانی) را فعال می‌کنند. |  1  | D/V |
| 7.2.3 | اطمینان حاصل کنید که حوادث توهم با فراداده علت اصلی برچسب‌گذاری شده و به خطوط لوله پس از رخداد و تنظیم دقیق داده می‌شوند.                                  |  2  | D/V |
| 7.2.4 | تأیید کنید که آستانه‌ها و آشکارسازها پس از به‌روزرسانی‌های عمده مدل یا پایگاه دانش دوباره کالیبره شده باشند.                                               |  3  | D/V |
| 7.2.5 | تأیید کنید که تجسم‌های داشبورد نرخ‌های توهم زایی را رهگیری می‌کنند.                                                                                        |  3  |  V  |

---

## C7.3 فیلتر کردن ایمنی و حفظ حریم خصوصی خروجی

فیلترهای سیاستی و پوشش تیم قرمز از کاربران و داده‌های محرمانه محافظت می‌کنند.

|   #   | توضیحات                                                                                                                                                | سطح | نقش |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------ | :-: | :-: |
| 7.3.1 | تأیید کنید که دسته‌بندهای قبل و بعد از تولید، محتوای نفرت‌انگیز، آزاردهنده، خودآزار، افراطی و محتوای جنسی صریح را که با سیاست همسو است، مسدود می‌کنند. |  1  | D/V |
| 7.3.2 | اطمینان حاصل کنید که شناسایی PII/PCI و حذف خودکار در هر پاسخ اجرا می‌شود؛ تخلفات منجر به ایجاد حادثه حفظ حریم خصوصی می‌گردد.                           |  1  | D/V |
| 7.3.3 | اطمینان حاصل کنید که برچسب‌های محرمانگی (مانند اسرار تجاری) در تمامی حالت‌ها منتقل می‌شوند تا از نشت اطلاعات در متن، تصاویر یا کد جلوگیری شود.         |  2  |  D  |
| 7.3.4 | تأیید کنید که تلاش‌های عبور از فیلتر یا طبقه‌بندی‌های پرخطر نیاز به تأیید ثانویه یا احراز هویت مجدد کاربر دارند.                                       |  3  | D/V |
| 7.3.5 | تأیید کنید که آستانه‌های فیلتر کردن منعکس‌کننده حوزه‌های قضایی قانونی و زمینه سُنی/نقش کاربر باشند.                                                    |  3  | D/V |

---

## C7.4 محدودسازی خروجی و اقدام

محدودیت‌های نرخ و دروازه‌های تأیید از سوء استفاده و خودمختاری بیش از حد جلوگیری می‌کنند.

|   #   | توضیحات                                                                                                                                                                                                | سطح | نقش |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :-: | :-: |
| 7.4.1 | تأیید کنید که سهمیه‌های هر کاربر و هر کلید API درخواست‌ها، توکن‌ها و هزینه‌ها را با استفاده از روش عقب‌نشینی نمایی در مواجهه با خطاهای 429 محدود می‌کنند.                                              |  1  |  D  |
| 7.4.2 | تأیید کنید که اقدامات ویژه (نوشتن فایل، اجرای کد، تماس‌های شبکه) نیازمند تأیید مبتنی بر سیاست یا دخالت انسانی هستند.                                                                                   |  1  | D/V |
| 7.4.3 | تأیید کنید که بررسی‌های هم‌سویی بین حالت‌ها (cross-modal consistency checks) اطمینان حاصل می‌کنند که تصاویر، کد و متن تولید شده برای یک درخواست مشابه، نمی‌توانند برای قاچاق محتوای مخرب استفاده شوند. |  2  | D/V |
| 7.4.4 | اطمینان حاصل کنید که عمق واگذاری نماینده، محدودیت‌های بازگشتی، و فهرست ابزارهای مجاز به صورت صریح پیکربندی شده‌اند.                                                                                    |  2  |  D  |
| 7.4.5 | تأیید کنید که نقض محدودیت‌ها رویدادهای امنیتی ساخت‌یافته برای جذب در SIEM صادر می‌کند.                                                                                                                 |  3  |  V  |

---

## C7.5 قابلیت توضیح خروجی

سیگنال‌های شفاف به بهبود اعتماد کاربران و اشکال‌زدایی داخلی کمک می‌کنند.

|   #   | توضیحات                                                                                                                                                       | سطح | نقش |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 7.5.1 | اطمینان حاصل کنید که امتیازات اطمینان نمایش داده شده برای کاربر یا خلاصه‌های کوتاه استدلال زمانی که ارزیابی ریسک مناسب تشخیص داده می‌شود، نمایش داده می‌شوند. |  2  | D/V |
| 7.5.2 | اطمینان حاصل کنید که توضیحات تولید شده از افشای دستورات حساس سیستم یا داده‌های اختصاصی جلوگیری می‌کنند.                                                       |  2  | D/V |
| 7.5.3 | اطمینان حاصل کنید که سیستم احتمال‌های لگاریتمی در سطح توکن یا نقشه‌های توجه را ضبط کرده و آن‌ها را برای بازرسی مجاز ذخیره می‌کند.                             |  3  |  D  |
| 7.5.4 | اطمینان حاصل کنید که آثار توضیح‌پذیری به همراه نسخه‌های مدل برای قابلیت حسابرسی تحت کنترل نسخه قرار دارند.                                                    |  3  |  V  |

---

## C7.6 یکپارچه‌سازی نظارت

قابلیت مشاهده در زمان واقعی حلقه ارتباط بین توسعه و تولید را می‌بندد.

|   #   | توضیحات                                                                                                                                    | سطح | نقش |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------ | :-: | :-: |
| 7.6.1 | تأیید کنید که معیارها (نقض‌های طرح، نرخ هالوسینیشن، سمیت، نشت اطلاعات شناسایی شخصی، تأخیر، هزینه) به یک پلتفرم مرکزی نظارتی ارسال می‌شوند. |  1  |  D  |
| 7.6.2 | تأیید کنید که آستانه‌های هشدار برای هر معیار ایمنی تعریف شده‌اند و مسیرهای ارتقاء برای تماس در دسترس قرار گرفته‌اند.                       |  1  |  V  |
| 7.6.3 | اطمینان حاصل کنید که داشبوردها ناهنجاری‌های خروجی را با مدل/نسخه، پرچم ویژگی و تغییرات داده‌های بالادستی مرتبط می‌کنند.                    |  2  |  V  |
| 7.6.4 | تأیید کنید که داده‌های مانیتورینگ به بازآموزی، تنظیم دقیق یا به‌روزرسانی قوانین درون یک جریان کاری مستند MLOps بازمی‌گردند.                |  2  | D/V |
| 7.6.5 | اطمینان حاصل کنید که پایپلاین‌های نظارتی تحت آزمایش نفوذ قرار گرفته و کنترل دسترسی شده‌اند تا از نشت گزارش‌های حساس جلوگیری شود.           |  3  |  V  |

---

## 7.7 تدابیر حفاظتی رسانه‌های مولد

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی محتوای رسانه‌ای غیرقانونی، مضر یا غیرمجاز تولید نکنند، از طریق اعمال محدودیت‌های سیاستی، اعتبارسنجی خروجی و قابلیت ردیابی.

|   #   | توضیحات                                                                                                                                                                               | سطح | نقش |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 7.7.1 | اطمینان حاصل کنید که دستورات سیستم و راهنمایی‌های کاربر صراحتاً تولید رسانه‌های دیپ‌فیک غیرقانونی، مضر یا بدون رضایت (مانند تصویر، ویدیو، صدا) را ممنوع می‌دانند.                     |  1  | D/V |
| 7.7.2 | اطمینان حاصل کنید که درخواست‌ها برای تلاش در تولید جعل هویت، دیپ‌فیک‌های جنسی صریح، یا رسانه‌هایی که افراد واقعی را بدون رضایت نشان می‌دهند، فیلتر می‌شوند.                           |  2  | D/V |
| 7.7.3 | تأیید کنید که سیستم از هش درک‌شده، تشخیص علامت آبی، یا اثرانگشت دیجیتال برای جلوگیری از بازتولید غیرمجاز رسانه‌های دارای حق نشر استفاده می‌کند.                                       |  2  |  V  |
| 7.7.4 | اطمینان حاصل کنید که تمام رسانه‌های تولید شده رمزنگاری شده، دارای واترمارک یا شامل فراداده‌های منشأ مقاوم در برابر دستکاری برای قابلیت ردیابی در مراحل بعدی باشند.                    |  3  | D/V |
| 7.7.5 | تأیید کنید که تلاش‌های دورزدن (مثلاً مبهم‌سازی فرمان، زبان عامیانه، بیان معارض) شناسایی، ثبت لاگ، و محدودیت نرخ اعمال می‌شوند؛ سوءاستفاده مکرر به سیستم‌های نظارتی گزارش داده می‌شود. |  3  |  V  |

## مراجع

* [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)
* [ISO/IEC 42001:2023 – AI Management System](https://www.iso.org/obp/ui/en/)
* [OWASP Top-10 for Large Language Model Applications (2025)](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Improper Output Handling – OWASP LLM05:2025](https://genai.owasp.org/llmrisk/llm052025-improper-output-handling/)
* [Practical Techniques to Constrain LLM Output](https://mychen76.medium.com/practical-techniques-to-constraint-llm-output-in-json-format-e3e72396c670)
* [Dataiku – Structured Text Generation Guide](https://blog.dataiku.com/your-guide-to-structured-text-generation)
* [VL-Uncertainty: Detecting Hallucinations](https://arxiv.org/abs/2411.11919)
* [HaDeMiF: Hallucination Detection & Mitigation](https://openreview.net/forum?id=VwOYxPScxB)
* [Building Confidence in LLM Outputs](https://www.alkymi.io/data-science-room/building-confidence-in-llm-outputs)
* [Explainable AI & LLMs](https://duncsand.medium.com/explainable-ai-140912d31b3b)
* [LLM Red-Teaming Guide](https://www.confident-ai.com/blog/red-teaming-llms-a-step-by-step-guide)
* [Sensitive Information Disclosure in LLMs](https://virtualcyberlabs.com/llm-sensitive-information-disclosure/)
* [LangChain – Chat Model Rate Limiting](https://python.langchain.com/docs/how_to/chat_model_rate_limiting/)
* [OpenAI Rate-Limit & Exponential Back-off](https://hackernoon.com/openais-rate-limit-a-guide-to-exponential-backoff-for-llm-evaluation)
* [Arize AI – LLM Observability Platform](https://arize.com/)

