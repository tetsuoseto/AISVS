# 10 مقاومت خصمانه و دفاع از حریم خصوصی

## هدف کنترل

اطمینان حاصل کنید که مدل‌های هوش مصنوعی هنگام مواجهه با حملات گریز، استنباط، استخراج یا مسموم‌سازی، قابل اعتماد، حفظ‌کننده حریم خصوصی و مقاوم در برابر سوءاستفاده باقی بمانند.

---

## 10.1 هم‌راستایی مدل و ایمنی

جلوگیری از خروجی‌های مضر یا مغایر با سیاست‌ها.

|   #    | توضیحات                                                                                                                                                          | سطح | نقش |
| :----: | ---------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.1.1 | اطمینان حاصل کنید که یک مجموعه آزمایش هم‌راستایی (پرامپت‌های تیم قرمز، آزمایش‌های ورود به سیستم، محتوای مجاز نشده) نسخه‌بندی شده و در هر انتشار مدل اجرا می‌شود. |  1  | D/V |
| 10.1.2 | اطمینان حاصل کنید که موانع امتناع و تکمیل ایمن اعمال شده‌اند.                                                                                                    |  1  |  D  |
| 10.1.3 | تأیید کنید که یک ارزیاب خودکار نرخ محتوای مضر را اندازه‌گیری کرده و بازگشت‌ها (Regression) را که فراتر از یک آستانه مشخص هستند، علامت‌گذاری می‌کند.              |  2  | D/V |
| 10.1.4 | اطمینان حاصل کنید که آموزش مقابله با فرار از زندان مستند و قابل تکرار باشد.                                                                                      |  2  |  D  |
| 10.1.5 | تأیید کنید که اثبات‌های رسمی انطباق با سیاست یا نظارت دارای گواهی، حوزه‌های حیاتی را پوشش می‌دهند.                                                               |  3  |  V  |

---

## 10.2 سخت‌سازی نمونه‌های مخرب

افزایش مقاومت در برابر ورودی‌های دست‌کاری شده. آموزش مقابله‌ای مقاوم و امتیازدهی معیارهای ارزیابی، بهترین روش‌های فعلی هستند.

|   #    | توضیحات                                                                                                               | سطح | نقش |
| :----: | --------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.2.1 | بررسی کنید که مخازن پروژه شامل پیکربندی‌های آموزش خصمانه با دانه‌های قابل بازتولید باشند.                             |  1  |  D  |
| 10.2.2 | اطمینان حاصل کنید که تشخیص نمونه‌های مخرب هشدارهای مسدودکننده را در خطوط لوله تولید ایجاد می‌کند.                     |  2  | D/V |
| 10.2.4 | تأیید کنید که اثبات‌های استحکام دارای گواهی یا گواهینامه‌های بازه‌ای حداقل کلاس‌های بحرانی برتر را پوشش می‌دهند.      |  3  |  V  |
| 10.2.5 | تأیید کنید که آزمون‌های رگرسیون از حملات تطبیقی برای تأیید عدم وجود کاهش قابل اندازه‌گیری در استحکام استفاده می‌کنند. |  3  |  V  |

---

## 10.3 کاهش استنتاج عضویت

محدود کردن توانایی تشخیص اینکه آیا یک رکورد در داده‌های آموزش وجود داشته است. حفظ حریم خصوصی تفاضلی و ماسک‌گذاری امتیاز اطمینان همچنان موثرترین دفاع‌های شناخته شده باقی می‌مانند.

|   #    | توضیحات                                                                                                                                   | سطح | نقش |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.3.1 | تأیید کنید که تنظیم منظم انتروپی به ازای هر پرس‌وجو یا مقیاس‌بندی دما پیش‌بینی‌های بیش از حد اطمینان را کاهش می‌دهد.                      |  1  |  D  |
| 10.3.2 | اطمینان حاصل کنید که آموزش از بهینه‌سازی متفاوت-محافظت‌شده با حد ε برای داده‌های حساس استفاده می‌کند.                                     |  2  |  D  |
| 10.3.3 | اطمینان حاصل کنید که شبیه‌سازی‌های حمله (مدل سایه یا جعبه سیاه) شاخص AUC حمله را بر داده‌های نگهداری‌شده کمتر یا مساوی 0.60 نشان می‌دهند. |  2  |  V  |

---

## 10.4 مقاومت در برابر معکوس‌سازی مدل

جلوگیری از بازسازی ویژگی‌های خصوصی. بررسی‌های اخیر تأکید می‌کنند که قطع کردن خروجی و تضمین‌های حفظ حریم خصوصی تفاضلی (DP) به عنوان دفاع‌های عملی محسوب می‌شوند.

|   #    | توضیحات                                                                                                                             | سطح | نقش |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.4.1 | اطمینان حاصل کنید که ویژگی‌های حساس هرگز به طور مستقیم نمایش داده نمی‌شوند؛ در صورت نیاز از سطل‌ها یا تبدیلات یک‌طرفه استفاده کنید. |  1  |  D  |
| 10.4.2 | اطمینان حاصل کنید که نرخ محدودیت‌های پرس‌وجو، پرس‌وجوهای تطبیقی مکرر از همان شخص اصلی را محدود می‌کنند.                             |  1  | D/V |
| 10.4.3 | اطمینان حاصل کنید که مدل با نویز حفظ حریم خصوصی آموزش دیده است.                                                                     |  2  |  D  |

---

## 10.5 دفاع استخراج مدل

شناسایی و جلوگیری از کلون‌سازی غیرمجاز. استفاده از علامت‌گذاری آب و تحلیل الگوی پرس‌وجو توصیه می‌شود.

|   #    | توضیحات                                                                                                                                                     | سطح | نقش |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.5.1 | اطمینان حاصل کنید که دروازه‌های استنتاج محدودیت‌های نرخ کلی و محدودیت‌های نرخ هر کلید API را که متناسب با آستانه یادسپاری مدل تنظیم شده‌اند، اعمال می‌کنند. |  1  |  D  |
| 10.5.2 | اطمینان حاصل کنید که آمارهای انتروپی پرس‌وجو و کثرت ورودی، یک آشکارساز استخراج خودکار را تغذیه می‌کنند.                                                     |  2  | D/V |
| 10.5.3 | تأیید کنید که واترمارک‌های شکننده یا احتمالاتی را می‌توان با p < 0.01 در ≤ 1 000 پرس‌وجو علیه یک کپی مشکوک اثبات کرد.                                       |  2  |  V  |
| 10.5.4 | اطمینان حاصل کنید که کلیدهای واترمارک و مجموعه‌های محرک در ماژول امنیت سخت‌افزاری ذخیره شده و سالیانه چرخش می‌یابند.                                        |  3  |  D  |
| 10.5.5 | تأیید کنید که رویدادهای extraction-alert شامل کوئری‌های متخلف بوده و با کتاب‌های راهنمای پاسخ به حادثه ادغام شده‌اند.                                       |  3  |  V  |

---

## 10.6 تشخیص داده‌های آلوده در زمان استنتاج

شناسایی و خنثی‌سازی ورودی‌های دارای در پشتی یا آلوده.

|   #    | توضیحات                                                                                                                                        | سطح | نقش |
| :----: | ---------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.6.1 | اطمینان حاصل کنید که ورودی‌ها قبل از استنتاج مدل از طریق یک شناسگر ناهنجاری (مثلاً STRIP، امتیازدهی سازگاری) عبور کنند.                        |  1  |  D  |
| 10.6.2 | اطمینان حاصل کنید که آستانه‌های تشخیص‌دهنده بر روی مجموعه‌های اعتبارسنجی تمیز/آلوده تنظیم شده‌اند تا کمتر از ۵٪ مثبت کاذب به دست آید.          |  1  |  V  |
| 10.6.3 | اطمینان حاصل کنید که ورودی‌هایی که به عنوان مسموم‌شده علامت‌گذاری شده‌اند، باعث فعال شدن نرم‌مسدودسازی و گردش‌های کاری بازبینی انسانی می‌شوند. |  2  |  D  |
| 10.6.4 | اطمینان حاصل کنید که آشکارسازها با حملات بک‌دور تطبیقی و بدون نیاز به تریگر به طور کامل تحت فشار قرار گرفته‌اند.                               |  2  |  V  |
| 10.6.5 | اطمینان حاصل کنید که معیارهای اثربخشی تشخیص ثبت شده و به صورت دوره‌ای با اطلاعات جدید تهدید بازبینی می‌شوند.                                   |  3  |  D  |

---

## 10.7 تطبیق پویا سیاست‌های امنیتی

به‌روزرسانی‌های سیاست امنیتی در زمان واقعی بر اساس اطلاعات تهدید و تحلیل رفتاری.

|   #    | توضیحات                                                                                                                                             | سطح | نقش |
| :----: | --------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.7.1 | تأیید کنید که سیاست‌های امنیتی می‌توانند به صورت پویا بدون نیاز به راه‌اندازی مجدد عامل به‌روزرسانی شوند در حالی که یکپارچگی نسخه سیاست حفظ می‌شود. |  1  | D/V |
| 10.7.2 | اطمینان حاصل کنید که به‌روزرسانی‌های سیاست‌ها توسط پرسنل امنیتی مجاز به صورت رمزنگاری شده امضا شده و قبل از اعمال اعتبارسنجی می‌شوند.               |  2  | D/V |
| 10.7.3 | اطمینان حاصل کنید که تغییرات دینامیک سیاست با سوابق کامل حسابرسی شامل توجیه، زنجیره‌های تصویب، و روش‌های بازگردانی ثبت می‌شوند.                     |  2  | D/V |
| 10.7.4 | تأیید کنید که مکانیزم‌های امنیتی تطبیقی حساسیت شناسایی تهدید را بر اساس زمینه ریسک و الگوهای رفتاری تنظیم می‌کنند.                                  |  3  | D/V |
| 10.7.5 | تأیید کنید که تصمیمات تطبیق سیاست قابل توضیح باشند و شامل مسیرهای شواهد برای بازبینی تیم امنیتی باشند.                                              |  3  | D/V |

---

## 10.8 تحلیل امنیت مبتنی بر بازتاب

اعتبارسنجی امنیت از طریق خودبازتابی عامل و تحلیل فراشناختی.

|   #    | توضیحات                                                                                                                         | سطح | نقش |
| :----: | ------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.8.1 | اطمینان حاصل کنید که مکانیزم‌های بازتاب عامل شامل ارزیابی خودمتمرکز امنیتی از تصمیمات و اقدامات باشد.                           |  1  | D/V |
| 10.8.2 | اطمینان حاصل کنید که خروجی‌های بازتابی برای جلوگیری از دستکاری مکانیزم‌های خودارزیابی توسط ورودی‌های خصمانه اعتبارسنجی می‌شوند. |  2  | D/V |
| 10.8.3 | تأیید کنید که تحلیل امنیت متا-شناختی، سوگیری، دستکاری یا به خطر افتادن احتمالی در فرآیندهای استدلال عامل را شناسایی می‌کند.     |  2  | D/V |
| 10.8.4 | اطمینان حاصل کنید که هشدارهای امنیتی مبتنی بر بازتاب باعث فعال شدن نظارت پیشرفته و فرآیندهای احتمالی دخالت انسانی می‌شوند.      |  3  | D/V |
| 10.8.5 | تأیید کنید که یادگیری مداوم از بازتاب‌های امنیتی، تشخیص تهدید را بهبود می‌بخشد بدون اینکه عملکرد مشروع را کاهش دهد.             |  3  | D/V |

---

## ۱۰.۹ امنیت تکامل و خودبهبودی

کنترل‌های امنیتی برای سیستم‌های عامل که قادر به خودتغییری و تکامل هستند.

|   #    | توضیحات                                                                                               | سطح | نقش |
| :----: | ----------------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.9.1 | تأیید کنید که قابلیت‌های خودتعدیلی به مناطق ایمن تعیین شده با مرزهای رسمی تأیید محدود شده‌اند.        |  1  | D/V |
| 10.9.2 | اطمینان حاصل کنید که پیشنهادهای توسعه قبل از اجرا مورد ارزیابی تأثیر امنیتی قرار گیرند.               |  2  | D/V |
| 10.9.3 | تأیید کنید که مکانیسم‌های خودبهبودی شامل قابلیت‌های بازگشت به حالت قبلی با بررسی صحت داده‌ها هستند.   |  2  | D/V |
| 10.9.4 | تأیید کنید که امنیت متا-یادگیری از دستکاری خصمانه الگوریتم‌های بهبود جلوگیری می‌کند.                  |  3  | D/V |
| 10.9.5 | تأیید کنید که بهبود خود بازگشتی توسط محدودیت‌های رسمی ایمنی محدود شده است با اثبات‌های ریاضی همگرایی. |  3  | D/V |

---

### مراجع

* [MITRE ATLAS adversary tactics for ML](https://atlas.mitre.org/)
* [NIST AI Risk Management Framework 1.0, 2023](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [OWASP Top 10 for LLM Applications, 2025](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Adversarial Training: A Survey — Zhao et al., 2024](https://arxiv.org/abs/2410.15042)
* [RobustBench adversarial-robustness benchmark](https://robustbench.github.io/)
* [Membership-Inference & Model-Inversion Risk Survey, 2025](https://www.sciencedirect.com/science/article/abs/pii/S0950705125003867)
* [PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023](https://ojs.aaai.org/index.php/AAAI/article/view/26289)
* [Model-Inversion Attacks & Defenses Survey — AI Review, 2025](https://link.springer.com/article/10.1007/s10462-025-11248-0)
* [Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024](https://doi.org/10.1109/TDSC.2023.3261327)
* [Fragile Model Watermarking Survey — 2025](https://www.sciencedirect.com/science/article/abs/pii/S0165168425002026)
* [Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025](https://arxiv.org/abs/2503.22759)
* [BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024](https://arxiv.org/abs/2405.15269)

