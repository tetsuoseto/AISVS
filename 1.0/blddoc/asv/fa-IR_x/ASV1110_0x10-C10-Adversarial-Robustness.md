# ۱۰ مقاومت مقابله‌ای و دفاع از حریم خصوصی

## هدف کنترل

اطمینان حاصل کنید که مدل‌های هوش مصنوعی در مواجهه با حملات دورزدن، استنتاج، استخراج یا مسموم‌سازی، قابل اعتماد، محافظت‌کننده از حریم خصوصی و مقاوم در برابر سوءاستفاده باقی می‌مانند.

---

## 10.1 هم‌راستایی مدل و ایمنی

محافظت در برابر خروجی‌های مضر یا نقض‌کننده سیاست‌ها.

|   #    | توضیحات                                                                                                                                                              | سطح | نقش |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.1.1 | اطمینان حاصل کنید که یک مجموعه آزمایش هم‌ترازی (دستورات تیم قرمز، کاوش‌های فرار از محدودیت، محتویات ممنوعه) تحت کنترل نسخه قرار دارد و در هر انتشار مدل اجرا می‌شود. |  1  | D/V |
| 10.1.2 | اطمینان حاصل کنید که موانع جلوگیری از امتناع و تکمیل ایمن اجرا می‌شوند.                                                                                              |  1  |  D  |
| 10.1.3 | تأیید کنید که یک ارزیاب خودکار نرخ محتوای مضر را اندازه‌گیری کرده و پسرفت‌ها را فراتر از یک آستانه تعیین شده علامت‌گذاری می‌کند.                                     |  2  | D/V |
| 10.1.4 | اطمینان حاصل کنید که آموزش ضد فرار از زندان مستند و قابل بازتولید است.                                                                                               |  2  |  D  |
| 10.1.5 | تأیید کنید که اثبات‌های انطباق با سیاست رسمی یا نظارت معتبر حوزه‌های حیاتی را پوشش می‌دهند.                                                                          |  3  |  V  |

---

## 10.2 سخت‌سازی نمونه‌های خصمانه

افزایش مقاومت در برابر ورودی‌های دستکاری شده. آموزش مقاوم در برابر حملات و ارزیابی معیارها بهترین روش‌های فعلی هستند.

|   #    | توضیحات                                                                                                                  | سطح | نقش |
| :----: | ------------------------------------------------------------------------------------------------------------------------ | :-: | :-: |
| 10.2.1 | اطمینان حاصل کنید که مخازن پروژه شامل پیکربندی‌های آموزش مقابله‌ای با دانه‌های قابل بازتولید باشند.                      |  1  |  D  |
| 10.2.2 | اطمینان حاصل کنید که تشخیص نمونه‌های مخرب در خطوط تولید هشدارهای مسدودکننده ایجاد می‌کند.                                |  2  | D/V |
| 10.2.4 | اطمینان حاصل کنید که اثبات‌های صحت مقاومتی تایید شده یا گواهی‌های بازه‌محدود حداقل کلاس‌های بحرانی برتر را پوشش می‌دهند. |  3  |  V  |
| 10.2.5 | تأیید کنید که آزمون‌های رگرسیون از حملات تطبیقی برای اطمینان از عدم کاهش قابل اندازه‌گیری در مقاومت استفاده می‌کنند.     |  3  |  V  |

---

## 10.3 کاهش استنباط عضویت

محدود کردن توانایی تصمیم‌گیری درباره اینکه آیا یک رکورد در داده‌های آموزش بوده است یا خیر. محرمانگی تفاضلی و ماسک‌گذاری امتیاز اطمینان همچنان مؤثرترین دفاع‌های شناخته‌شده هستند.

|   #    | توضیحات                                                                                                                          | سطح | نقش |
| :----: | -------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.3.1 | تأیید کنید که منظم‌سازی آنتروپی به ازای هر پرس‌وجو یا مقیاس‌بندی دما پیش‌بینی‌های بیش‌اعتماد را کاهش می‌دهد.                     |  1  |  D  |
| 10.3.2 | تأیید کنید که آموزش از بهینه‌سازی متفاوت-خصوصی با کران ε برای مجموعه داده‌های حساس استفاده می‌کند.                               |  2  |  D  |
| 10.3.3 | اطمینان حاصل کنید که شبیه‌سازی‌های حمله (مدل سایه یا جعبه سیاه) مقدار AUC حمله ≤ 0.60 را روی داده‌های کنار گذاشته شده نشان دهند. |  2  |  V  |

---

## 10.4 مقاومت در برابر معکوس‌سازی مدل

جلوگیری از بازسازی ویژگی‌های خصوصی. نظرسنجی‌های اخیر بر برش خروجی و تضمین‌های DP به‌عنوان دفاع‌های عملی تأکید دارند.

|   #    | توضیحات                                                                                                                    | سطح | نقش |
| :----: | -------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.4.1 | تأیید کنید که ویژگی‌های حساس هرگز به طور مستقیم خروجی داده نشوند؛ در صورت نیاز، از بکت‌ها یا تبدیلات یک‌طرفه استفاده کنید. |  1  |  D  |
| 10.4.2 | تأیید کنید که محدودیت‌های نرخ پرس‌وجو، پرس‌وجوهای تطبیقی مکرر از همان مرجع را محدود می‌کنند.                               |  1  | D/V |
| 10.4.3 | تأیید کنید که مدل با نویز حفظ‌کننده حریم خصوصی آموزش داده شده باشد.                                                        |  2  |  D  |

---

## 10.5 دفاع در برابر استخراج مدل

شناسایی و جلوگیری از تکثیر غیرمجاز. علامت‌گذاری آبی (واترمارک) و تحلیل الگوی پرس‌وجو توصیه می‌شود.

|   #    | توضیحات                                                                                                                                             | سطح | نقش |
| :----: | --------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.5.1 | اطمینان حاصل کنید که دروازه‌های استنتاج محدودیت‌های نرخ کلی و محدودیت‌های نرخ خاص هر کلید API را که به آستانه حفظ مدل تنظیم شده‌اند، اعمال می‌کنند. |  1  |  D  |
| 10.5.2 | اطمینان حاصل کنید که آمارهای انتروپی پرس‌و‌جو و تعداد جمع ورودی در تغذیه یک آشکارساز استخراج خودکار نقش دارند.                                      |  2  | D/V |
| 10.5.3 | تأیید کنید که واترمارک‌های شکننده یا احتمالاتی می‌توانند با p < 0.01 در ≤ 1 000 پرس‌وجو علیه یک کلون مشکوک اثبات شوند.                              |  2  |  V  |
| 10.5.4 | اطمینان حاصل کنید که کلیدهای واترمارک و مجموعه‌های محرک در ماژول امنیت سخت‌افزاری ذخیره شده و سالانه تغییر می‌یابند.                                |  3  |  D  |
| 10.5.5 | تأیید کنید که رویدادهای استخراج-هشدار شامل پرس و جوهای تخلف‌کننده باشند و با کتاب‌های راهنمای پاسخ به حادثه یکپارچه شده باشند.                      |  3  |  V  |

---

## 10.6 تشخیص داده‌های آلوده در زمان استنتاج

ورودی‌های دارای بک‌دور یا آلوده شده را شناسایی و خنثی کنید.

|   #    | توضیحات                                                                                                                            | سطح | نقش |
| :----: | ---------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.6.1 | اطمینان حاصل کنید که ورودی‌ها قبل از استنتاج مدل از طریق یک آشکارساز ناهنجاری (مثلاً STRIP، امتیازدهی سازگاری) عبور کنند.          |  1  |  D  |
| 10.6.2 | بررسی کنید که آستانه‌های آشکارساز بر روی مجموعه‌های اعتبارسنجی تمیز/آلوده تنظیم شده باشند تا کمتر از ۵٪ مثبت کاذب حاصل شود.        |  1  |  V  |
| 10.6.3 | اطمینان حاصل کنید که ورودی‌هایی که به عنوان آلوده شده علامت‌گذاری شده‌اند، روندهای مسدودسازی نرم و بازبینی انسانی را فعال می‌کنند. |  2  |  D  |
| 10.6.4 | تأیید کنید که آشکارسازها با حملات پشتی مخفی بدون ماشه و تطبیقی به‌طور تحت فشار آزمون قرار می‌گیرند.                                |  2  |  V  |
| 10.6.5 | اطمینان حاصل کنید که معیارهای اثربخشی تشخیص ثبت شده و به طور دوره‌ای با اطلاعات تهدید تازه بازبینی می‌شوند.                        |  3  |  D  |

---

## 10.7 انطباق پویای سیاست امنیتی

به‌روزرسانی‌های سیاست امنیتی به‌صورت زنده بر اساس اطلاعات تهدید و تحلیل رفتاری.

|   #    | توضیحات                                                                                                                                        | سطح | نقش |
| :----: | ---------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.7.1 | اطمینان حاصل کنید که سیاست‌های امنیتی می‌توانند به‌صورت پویا بدون راه‌اندازی مجدد عاملی به‌روزرسانی شوند در حالی که صحت نسخه سیاست حفظ می‌شود. |  1  | D/V |
| 10.7.2 | اطمینان حاصل کنید که به‌روزرسانی‌های سیاست به‌صورت رمزنگاری‌شده توسط کارکنان امنیتی مجاز امضا شده و قبل از اعمال اعتبارسنجی شده‌اند.           |  2  | D/V |
| 10.7.3 | تأیید کنید که تغییرات سیاست پویا با سوابق کامل حسابرسی شامل توجیه، زنجیره‌های تأیید و روش‌های بازگشت ثبت می‌شوند.                              |  2  | D/V |
| 10.7.4 | اطمینان حاصل کنید که مکانیزم‌های امنیت تطبیقی حساسیت شناسایی تهدید را بر اساس زمینه ریسک و الگوهای رفتاری تنظیم می‌کنند.                       |  3  | D/V |
| 10.7.5 | تأیید کنید که تصمیمات سازگاری سیاست قابل توضیح باشند و شامل مسیرهای شواهد برای بازبینی تیم امنیتی باشند.                                       |  3  | D/V |

---

## 10.8 تحلیل امنیت مبتنی بر بازتاب

اعتبارسنجی امنیت از طریق خوداندیشی عامل و تحلیل متا-شناختی.

|   #    | توضیحات                                                                                                                           | سطح | نقش |
| :----: | --------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.8.1 | تأیید کنید که مکانیزم‌های بازتاب عامل شامل ارزیابی خودی با تمرکز بر امنیت در تصمیمات و اقدامات می‌باشد.                           |  1  | D/V |
| 10.8.2 | اطمینان حاصل کنید که خروجی‌های بازتابی اعتبارسنجی می‌شوند تا از دستکاری مکانیزم‌های خودارزیابی توسط ورودی‌های خصمانه جلوگیری شود. |  2  | D/V |
| 10.8.3 | اطمینان حاصل کنید که تحلیل امنیت متاکاگنیتیو، تعصبات احتمالی، دستکاری یا به خطر افتادن فرآیندهای استدلال عامل را شناسایی می‌کند.  |  2  | D/V |
| 10.8.4 | تأیید کنید که هشدارهای امنیتی مبتنی بر بازتاب باعث فعال شدن نظارت پیشرفته و جریان‌های کاری احتمالی مداخله انسانی می‌شوند.         |  3  | D/V |
| 10.8.5 | تأیید کنید که یادگیری مداوم از بازتاب‌های امنیتی، تشخیص تهدید را بهبود می‌بخشد بدون اینکه عملکرد قانونی را تخریب کند.             |  3  | D/V |

---

## ۱۰.۹ امنیت تکامل و خودبهبود

کنترل‌های امنیتی برای سیستم‌های عامل که قادر به خودتعدیلی و تکامل هستند.

|   #    | توضیحات                                                                                                     | سطح | نقش |
| :----: | ----------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 10.9.1 | تأیید کنید که قابلیت‌های خود-تغییردهی محدود به نواحی ایمن مشخص شده با مرزهای رسمی تأیید شده باشند.          |  1  | D/V |
| 10.9.2 | اطمینان حاصل کنید که پیشنهادهای تکامل قبل از اجرا تحت ارزیابی تاثیر امنیتی قرار می‌گیرند.                   |  2  | D/V |
| 10.9.3 | تأیید کنید که مکانیزم‌های خودبهبودی شامل قابلیت‌های بازگشت به عقب همراه با تأیید صحت باشند.                 |  2  | D/V |
| 10.9.4 | تأیید کنید که امنیت یادگیری فرادانشی از دستکاری مخرب الگوریتم‌های بهبود جلوگیری می‌کند.                     |  3  | D/V |
| 10.9.5 | اطمینان حاصل کنید که بهبود خودبازگشتی توسط محدودیت‌های رسمی ایمنی محدود شده است با اثبات‌های ریاضی همگرایی. |  3  | D/V |

---

### مراجع

* [MITRE ATLAS adversary tactics for ML](https://atlas.mitre.org/)
* [NIST AI Risk Management Framework 1.0, 2023](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [OWASP Top 10 for LLM Applications, 2025](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Adversarial Training: A Survey — Zhao et al., 2024](https://arxiv.org/abs/2410.15042)
* [RobustBench adversarial-robustness benchmark](https://robustbench.github.io/)
* [Membership-Inference & Model-Inversion Risk Survey, 2025](https://www.sciencedirect.com/science/article/abs/pii/S0950705125003867)
* [PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023](https://ojs.aaai.org/index.php/AAAI/article/view/26289)
* [Model-Inversion Attacks & Defenses Survey — AI Review, 2025](https://link.springer.com/article/10.1007/s10462-025-11248-0)
* [Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024](https://doi.org/10.1109/TDSC.2023.3261327)
* [Fragile Model Watermarking Survey — 2025](https://www.sciencedirect.com/science/article/abs/pii/S0165168425002026)
* [Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025](https://arxiv.org/abs/2503.22759)
* [BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024](https://arxiv.org/abs/2405.15269)

