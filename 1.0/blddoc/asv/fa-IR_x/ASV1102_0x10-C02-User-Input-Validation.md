# C2 اعتبارسنجی ورودی کاربر

## هدف کنترل

اعتبارسنجی قوی ورودی کاربر، دفاعی خط اول در برابر برخی از مخرب‌ترین حملات علیه سامانه‌های هوش مصنوعی است. حملات تزریق پرامپت می‌توانند دستورات سیستمی را کنار بزنند، داده‌های حساس را فاش کنند یا مدل را به رفتاری که مجاز نیست هدایت کنند. مگر اینکه فیلترهای اختصاصی و سلسله‌مراتب دستورالعمل در جای خود وجود داشته باشند، تحقیقات نشان می‌دهد که «multi-shot» جیلبریک‌هایی که از پنجره‌های زمینه‌ای بسیار طولانی بهره می‌برند، مؤثر خواهند بود. همچنین حملات اخلال‌آفرین مخالفانه—مانند تعویض‌های هم‌ریخت (هموگلیف) یا لیت‌اسپیک—می‌توانند به‌طور پنهان تصمیم‌های مدل را تغییر دهند.

---

## C2.1 دفاع در برابر تزریق پرومپت

تزریق پرامپت یکی از مهم‌ترین خطرات برای سیستم‌های هوش مصنوعی است. دفاع‌های در برابر این تاکتیک از ترکیبی از فیلترهای الگوهای ایستا، طبقه‌بندهای پویا و اجرای سلسله‌مراتب دستورات استفاده می‌کنند.

|   #   | شرح                                                                                                                                                                                                                                   | سطح | نقش |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.1.1 | اطمینان حاصل کنید که ورودی‌های کاربر در برابر کتابخانه‌ای به‌طور مداوم به‌روزرسانی‌شده از الگوهای شناخته‌شده تزریق پرامپت غربال می‌شوند (کلیدواژه‌های jailbreak، "ignore previous"، زنجیره‌های نقش‌آفرینی، حملات HTML/URL غیرمستقیم). |  1  | D/V |
| 2.1.2 | تأیید کنید که سیستم یک سلسله‌مراتب دستورالعمل اجرا می‌کند که در آن پیام‌های سیستم یا توسعه‌دهنده از دستورالعمل‌های کاربر پیشی می‌گیرند، حتی پس از گسترش پنجره زمینه.                                                                  |  1  | D/V |
| 2.1.3 | تأیید کنید که آزمایش‌های ارزیابی خصمانه (مثلاً پرومپت‌های Red Team "many-shot") قبل از هر انتشار مدل یا قالب پرومپت اجرا می‌شوند، با آستانه‌های نرخ موفقیت و موانع خودکار برای جلوگیری از ریگریسیون‌ها.                               |  2  | D/V |
| 2.1.4 | تأیید کنید که پرامپت‌هایی که از محتوای شخص ثالث منشأ می‌گیرند، در یک زمینهٔ تحلیل ایزوله‌شده پاک‌سازی می‌شوند، پیش از الحاق آن‌ها به پرامپت اصلی.                                                                                     |  2  |  D  |
| 2.1.5 | همه به‌روزرسانی‌های قوانین فیلتر پرامپت، نسخه‌های مدل طبقه‌بندی و تغییرات block-list دارای کنترل نسخه و قابل ممیزی هستند.                                                                                                             |  3  | D/V |

---

## C2.2 مقاومت در برابر نمونه‌های خصمانه

مدل‌های پردازش زبان طبیعی (NLP) هنوز در برابر تغییرات ظریف در سطح کاراکتر یا کلمه آسیب‌پذیرند که انسان‌ها اغلب از آن‌ها چشم‌پوشی می‌کنند، اما مدل‌ها تمایل دارند آن‌ها را به اشتباه طبقه‌بندی کنند.

|   #   | شرح                                                                                                                                                                                              | سطح | نقش |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :-: | :-: |
| 2.2.1 | اطمینان حاصل کنید که مراحل پایه نرمال‌سازی ورودی (Unicode NFC، نگاشت هموگلیف‌ها، برداشتن فاصله‌های سفید) قبل از توکن‌سازی اجرا می‌شوند.                                                          |  1  |  D  |
| 2.2.2 | تشخیص ناهنجاری آماری ورودی‌ها را با فاصلهٔ ویرایشی غیرعادی نسبت به هنجارهای زبان، توکن‌های تکراری بیش از حد یا فواصل امبدینگ غیرعادی علامت‌گذاری می‌کند.                                         |  2  | D/V |
| 2.2.3 | تأیید کنید که خط لوله استنتاج از انواع مدل‌های اختیاریِ adversarial-training–hardened یا لایه‌های دفاعی پشتیبانی می‌کند (به‌عنوان مثال، تصادفی‌سازی، تقطیر دفاعی) برای نقاط پایانی با ریسک بالا. |  2  |  D  |
| 2.2.4 | بررسی کنید که ورودی‌های مظنون به مخرب بودن در قرنطینه نگهداری شوند و با محموله‌های کامل لاگ شوند (پس از حذف اطلاعات شخصی قابل تشخیص).                                                            |  2  |  V  |
| 2.2.5 | بررسی کنید که معیارهای استحکام (نرخ موفقیت مجموعه‌های حمله شناخته‌شده) در طول زمان پیگیری می‌شوند و رگرسیون‌ها باعث فعال شدن موانع انتشار می‌شوند.                                               |  3  | D/V |

---

## C2.3 اسکیما، نوع و طول اعتبارسنجی

حملات هوش مصنوعی که ورودی‌های نامعتبر یا با اندازهٔ بیش از حد را در بر می‌گیرند، می‌توانند منجر به خطاهای تجزیه، ریزش پرومپت در فیلدها، و اتمام منابع شوند.  همچنین اجرای دقیق طرحواره یک پیش‌نیاز هنگام انجام فراخوانی‌های ابزار قطعی است.

|   #   | شرح                                                                                                                                                                                           | سطح | نقش |
| :---: | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.3.1 | اطمینان حاصل کنید که هر نقطه پایانی API یا فراخوانی تابع، یک طرح ورودی صریح تعریف می‌کند (JSON Schema، Protobuf یا معادل چندرسانه‌ای) و اینکه ورودی‌ها پیش از ساخت پرامپت اعتبارسنجی می‌شوند. |  1  |  D  |
| 2.3.2 | تأیید کنید که ورودی‌هایی که از حداکثر محدودیت‌های توکن یا بایت فراتر می‌روند با یک خطای ایمن رد می‌شوند و هرگز به صورت خاموش قطع نمی‌شوند.                                                    |  1  | D/V |
| 2.3.3 | اطمینان حاصل کنید که بررسی‌های نوع داده (مثلاً بازه‌های عددی، مقادیر enum، انواع MIME برای تصاویر و صداها) در سمت سرور اعمال می‌شوند، نه فقط در کد سمت کلاینت.                                |  2  | D/V |
| 2.3.4 | اطمینان حاصل کنید که اعتبارسنج‌های معنایی (مثلاً JSON Schema) در زمان ثابت اجرا شوند تا از حملات DoS الگوریتمی جلوگیری شود.                                                                   |  2  |  D  |
| 2.3.5 | اطمینان حاصل کنید که شکست‌های اعتبارسنجی با قطعات پیلود حذف‌شده و کدهای خطای صریح ثبت می‌شوند تا به تریاژ امنیتی کمک کنند.                                                                    |  3  |  V  |

---

## C2.4 غربالگری محتوا و سیاست‌ها

توسعه‌دهندگان باید بتوانند پرامپت‌های نحوی معتبر را تشخیص دهند که محتوای غیرمجاز را درخواست می‌کنند، و سپس از انتشار آنها جلوگیری نمایند.

|   #   | شرح                                                                                                                                                                                     | سطح | نقش |
| :---: | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.4.1 | تأیید کنید که یک طبقه‌بندی‌کننده محتوا (zero-shot یا fine-tuned) برای هر ورودی امتیاز بدهد از نظر خشونت، خودآزاری، نفرت، محتوای جنسی و درخواست‌های غیرقانونی، با آستانه‌های قابل تنظیم. |  1  |  D  |
| 2.4.2 | تأیید کنید که ورودی‌هایی که سیاست‌ها را نقض می‌کنند، از پاسخ‌های امتناع استاندارد یا تکمیل‌های ایمن برخوردار می‌شوند تا به فراخوانی‌های LLM در مراحل بعدی منتقل نشوند.                  |  1  | D/V |
| 2.4.3 | اطمینان حاصل کنید که مدل غربالگری یا مجموعه قوانین حداقل هر سه ماه یکبار بازآموزی/به‌روزرسانی می‌شود و الگوهای تازه مشاهده‌شده برای جیل‌بریک یا دور زدن سیاست‌ها را در بر می‌گیرد.      |  2  |  D  |
| 2.4.4 | بررسی کنید که غربالگری به سیاست‌های مربوط به کاربر (سن، محدودیت‌های قانونی منطقه‌ای) از طریق قواعد مبتنی بر ویژگی که در زمان درخواست حل می‌شوند، احترام می‌گذارد.                       |  2  |  D  |
| 2.4.5 | اطمینان حاصل کنید که لاگ‌های غربالگری شامل نمرات اعتماد طبقه‌بند و برچسب‌های دسته‌بندی سیاستی برای همبستگی با SOC و بازتکرار تیم قرمز در آینده باشند.                                   |  3  |  V  |

---

## C2.5 محدودیت نرخ ورودی و پیشگیری از سوءاستفاده

توسعه‌دهندگان باید از سوءاستفاده، استنفاد منابع و حملات خودکار علیه سیستم‌های هوش مصنوعی جلوگیری کنند، با محدود کردن نرخ ورودی و تشخیص الگوهای استفاده نامعمول.

|   #   | شرح                                                                                                                                                  | سطح | نقش |
| :---: | ---------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.5.1 | تأیید کنید که محدودیت‌های نرخ برای هر کاربر، هر IP، و هر کلید API برای تمام نقاط ورودی اعمال می‌شود.                                                 |  1  | D/V |
| 2.5.2 | تایید کنید که محدودیت‌های نرخ ناگهانی و پایدار برای جلوگیری از حملات DoS و brute-force تنظیم شده‌اند.                                                |  2  | D/V |
| 2.5.3 | بررسی کنید که آیا الگوهای استفاده غیرعادی (مثلاً درخواست‌های پی‌درپی با سرعت بالا و سیلاب ورودی) منجر به بلوک‌های خودکار یا تشدیدهای خودکار می‌شوند. |  2  | D/V |
| 2.5.4 | اطمینان حاصل کنید که لاگ‌های جلوگیری از سوءاستفاده نگهداری می‌شوند و برای الگوهای حمله در حال ظهور بررسی می‌شوند.                                    |  3  |  V  |

---

## C2.6 اعتبارسنجی ورودی چندرسانه‌ای

سامانه‌های هوش مصنوعی باید اعتبارسنجی قوی برای ورودی‌های غیرمتنی (تصاویر، صوت، فایل‌ها) داشته باشند تا از تزریق، فرار از کنترل یا سوءاستفاده از منابع جلوگیری شود.

|   #   | شرح                                                                                                                                | سطح | نقش |
| :---: | ---------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.6.1 | اطمینان حاصل کنید که تمامی ورودی‌های غیرمتنی (تصاویر، صداها و فایل‌ها) پیش از پردازش از نظر نوع، اندازه و فرمت اعتبارسنجی می‌شوند. |  1  |  D  |
| 2.6.2 | اطمینان حاصل کنید که فایل‌ها قبل از درون‌ریزی برای بدافزارها و بارهای استگانوگرافی اسکن می‌شوند.                                   |  2  | D/V |
| 2.6.3 | اطمینان حاصل کنید که ورودی‌های تصویری و صوتی برای وجود انحرافات خصمانه یا الگوهای حمله شناخته‌شده بررسی می‌شوند.                   |  2  | D/V |
| 2.6.4 | تأیید کنید که شکست‌های اعتبارسنجی ورودی‌های چندرسانه‌ای ثبت می‌شوند و برای بررسی، هشدارهایی فعال می‌شوند.                          |  3  |  V  |

---

## C2.7 منشأ ورودی و انتساب

سیستم‌های هوش مصنوعی باید با نظارت بر منشاء ورودی‌های کاربران و برچسب‌گذاری آن‌ها، از ممیزی، پیگیری سوءاستفاده و انطباق پشتیبانی کنند.

|   #   | شرح                                                                                                                                | سطح | نقش |
| :---: | ---------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.7.1 | تأیید کنید که تمامی ورودی‌های کاربر در هنگام واردسازی با فراداده برچسب‌گذاری می‌شوند (شناسه کاربر، نشست، منبع، زمان ثبت، آدرس IP). |  1  | D/V |
| 2.7.2 | اطمینان حاصل کنید که متاداده منبع برای تمامی ورودی‌های پردازش‌شده حفظ شده و قابل بازرسی است.                                       |  2  | D/V |
| 2.7.3 | اطمینان حاصل کنید که منابع ورودی نامعمول یا نامعتبر علامت‌گذاری شده و مشمول بررسی دقیق‌تر یا مسدودسازی می‌شوند.                    |  2  | D/V |

---

## C2.8 تشخیص تهدید پویا در زمان واقعی

توسعه‌دهندگان باید از سیستم‌های تشخیص تهدید پیشرفته برای هوش مصنوعی استفاده کنند که با الگوهای حمله جدید سازگار می‌شوند و حفاظت در زمان واقعی را با تطبیق الگوهای کامپایل‌شده ارائه می‌کنند.

|   #   | شرح                                                                                                                                                                        | سطح | نقش |
| :---: | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.8.1 | تأیید کنید که الگوهای تشخیص تهدید به موتورهای مبتنی بر regex بهینه‌شده کامپایل می‌شوند تا فیلترینگ با کارایی بالا در زمان واقعی با کمترین تأخیر ممکن انجام شود.            |  1  | D/V |
| 2.8.2 | بررسی کنید که سیستم‌های تشخیص تهدید کتابخانه‌های الگوهای جداگانه را برای دسته‌های تهدید مختلف نگهداری می‌کنند (تزریق پرامپت، محتوای مضر، داده‌های حساس، دستورات سیستم).    |  1  | D/V |
| 2.8.3 | بررسی کنید که تشخیص تهدید تطبیقی از مدل‌های یادگیری ماشین استفاده می‌کند که حساسیت تهدید را بر اساس فراوانی حملات و نرخ‌های موفقیت به‌روزرسانی می‌کنند.                    |  2  | D/V |
| 2.8.4 | اطمینان حاصل کنید که جریان‌های اطلاعات تهدید در زمان واقعی به‌طور خودکار کتابخانه‌های الگو را با امضاهای حمله جدید و IOCs (شاخص‌های نفوذ) به‌روزرسانی می‌کنند.             |  2  | D/V |
| 2.8.5 | تأیید کنید که نرخ‌های مثبت کاذب در تشخیص تهدید به‌طور مداوم پایش می‌شوند و اختصاصیتِ الگوها به‌طور خودکار تنظیم می‌شود تا تداخل با موارد استفاده مشروع را به حداقل برساند. |  3  | D/V |
| 2.8.6 | تایید کنید که تحلیل تهدید مبتنی بر زمینه منبع ورودی، الگوهای رفتار کاربر و تاریخچه نشست را در نظر می‌گیرد تا دقت تشخیص بهبود یابد.                                         |  3  | D/V |
| 2.8.7 | اطمینان حاصل کنید که معیارهای عملکرد تشخیص تهدید (نرخ تشخیص، تاخیر پردازش، مصرف منابع) در زمان واقعی پایش و بهینه می‌شوند.                                                 |  3  | D/V |

---

## C2.9 خط لوله اعتبارسنجی امنیتی چند-رسانه‌ای

توسعه‌دهندگان باید اعتبارسنجی امنیتی برای متن، تصویر، صدا و سایر حالت‌های ورودی هوش مصنوعی را با انواع مشخصی از تشخیص تهدید و ایزول‌سازی منابع ارائه دهند.

|   #   | شرح                                                                                                                                                                                                                                                | سطح | نقش |
| :---: | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.9.1 | تأیید کنید که هر قالب ورودی دارای اعتبارسنج‌های امنیتی اختصاصی با الگوهای تهدید مستندسازی‌شده (متن: تزریق پرامپت، تصاویر: استگانوگرافی، صوت: حملات اسپکتروگرام) و آستانه‌های تشخیص باشد.                                                           |  1  | D/V |
| 2.9.2 | تأیید کنید که ورودی‌های چندمودالی در ساندباکس‌های ایزوله با محدودیت‌های منبع مشخص (حافظه، CPU، زمان پردازش) که برای هر نوع مودالیتی تعیین شده‌اند، پردازش می‌شوند و در سیاست‌های امنیتی مستندسازی شده‌اند.                                         |  2  | D/V |
| 2.9.3 | تأیید کنید که تشخیص حملات میان‌رسانه‌ای، حملات هماهنگ‌شده‌ای که ورودی‌های چندگانه را در بر می‌گیرند (مثلاً بارهای مخفی استگانوگرافی در تصاویر که با تزریق پرامپت در متن ترکیب می‌شوند)، با استفاده از قوانین همبستگی و تولید هشدار شناسایی می‌کند. |  2  | D/V |
| 2.9.4 | اطمینان حاصل کنید که شکست‌های اعتبارسنجی چندمودالی منجر به لاگ‌گذاری دقیق می‌شوند، که این لاگ‌گذاری شامل تمام مودال‌های ورودی، نتایج اعتبارسنجی، امتیازهای تهدید و تحلیل همبستگی با قالب‌های لاگ ساختاریافته برای ادغام با SIEM است.               |  3  | D/V |
| 2.9.5 | تأیید کنید که طبقه‌بندهای محتوای مختص هر مودالیتی مطابق با برنامه‌های مستند به‌روزرسانی می‌شوند، همراه با الگوهای تهدید جدید، نمونه‌های حمله‌ای و بنچمارک‌های عملکردی که بالاتر از آستانه‌های پایه نگه داشته می‌شوند.                              |  3  | D/V |

---

## منابع

* [LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security](https://genai.owasp.org/llmrisk/llm01-prompt-injection/)
* [Generative AI's Biggest Security Flaw Is Not Easy to Fix](https://www.wired.com/story/generative-ai-prompt-injection-hacking)
* [Many-shot jailbreaking \ Anthropic](https://www.anthropic.com/research/many-shot-jailbreaking)
* [$PDF$ OpenAI GPT-4.5 System Card](https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf)
* [Notebook for the CheckThat Lab at CLEF 2024](https://ceur-ws.org/Vol-3740/paper-53.pdf)
* [Mitigate jailbreaks and prompt injections – Anthropic](https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks)
* [Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis](https://ama.drwhy.ai/mitre-attck.html)
* [OWASP Top 10 for LLM Applications 2025 – WorldTech IT](https://wtit.com/blog/2025/04/17/owasp-top-10-for-llm-applications-2025/)
* [OWASP Machine Learning Security Top Ten](https://owasp.org/www-project-machine-learning-security-top-10/)
* [Few words about AI Security – Jussi Metso](https://www.jussimetso.com/index.php/2024/09/28/few-words-about-ai-security/)
* [How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry](https://modelmetry.com/blog/how-to-ensure-llm-output-adheres-to-a-json-schema)
* [Easily enforcing valid JSON schema following – API](https://community.openai.com/t/feature-request-function-calling-easily-enforcing-valid-json-schema-following/263515?utm_source)
* [AI Safety + Cybersecurity R\&D Tracker – Fairly AI](https://www.fairly.ai/blog/ai-cybersecurity-tracker)
* [Anthropic makes 'jailbreak' advance to stop AI models producing harmful results](https://www.ft.com/content/cf11ebd8-aa0b-4ed4-945b-a5d4401d186e)
* [Pattern matching filter rules - IBM](https://www.ibm.com/docs/ssw_aix_71/security/intrusion_pattern_matching_filter_rules.html)
* [Real-time Threat Detection](https://www.darktrace.com/cyber-ai-glossary/real-time-threat-detection)

