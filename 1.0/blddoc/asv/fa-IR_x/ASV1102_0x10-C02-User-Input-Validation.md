# اعتبارسنجی ورودی کاربر در C2

## هدف کنترل

اعتبارسنجی محکم ورودی کاربر، اولین خط دفاع در برابر برخی از مخرب‌ترین حملات به سیستم‌های هوش مصنوعی است. حملات تزریق فرمان می‌توانند دستورالعمل‌های سیستم را لغو کنند، اطلاعات حساس را فاش سازند یا مدل را به سمت رفتاری سوق دهند که مجاز نیست. مگر اینکه فیلترهای اختصاصی و سلسله‌مراتب دستورالعمل‌ها وجود داشته باشد، تحقیقات نشان می‌دهد که هک‌های "چندضربه‌ای" که از پنجره‌های متن بسیار طولانی بهره می‌برند، مؤثر خواهند بود. همچنین، حملات perturbation مخفیانه و خصمانه مانند جابجایی‌های هم‌ریش (homoglyph) یا نوشتار leetspeak می‌توانند تصمیمات مدل را به‌طور خاموش تغییر دهند.

---

## دفاع در برابر تزریق فرمان C2.1

تزریق پرامپت یکی از بزرگ‌ترین ریسک‌ها برای سیستم‌های هوش مصنوعی است. دفاع در برابر این تاکتیک از ترکیبی از فیلترهای الگوهای ایستا، دسته‌بندهای پویا و اجرای سلسله‌مراتبی دستورات استفاده می‌کند.

|   #   | توضیحات                                                                                                                                                                                                             | سطح | نقش |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.1.1 | تائید کنید که ورودی‌های کاربر در برابر یک کتابخانه به‌روز شده مداوم از الگوهای شناخته شده تزریق پرامپت (کلیدواژه‌های جیل‌بریک، "ignore previous"، زنجیره‌های نقش‌آفرینی، حملات غیرمستقیم HTML/URL) بررسی می‌شوند.   |  1  | D/V |
| 2.1.2 | تأیید کنید که سیستم یک سلسله مراتب دستوری را اعمال می‌کند که در آن پیام‌های سیستم یا توسعه‌دهنده بر دستورالعمل‌های کاربر اولویت دارند، حتی پس از گسترش پنجره زمینه.                                                 |  1  | D/V |
| 2.1.3 | اطمینان حاصل کنید که آزمایش‌های ارزیابی مقابله‌ای (مانند درخواست‌های "چند نمونه‌ای" تیم قرمز) قبل از هر نسخه مدل یا قالب درخواست اجرا می‌شوند، با آستانه‌های نرخ موفقیت و مسدودکننده‌های خودکار برای بازگشت به عقب. |  2  | D/V |
| 2.1.4 | تأیید کنید که درخواست‌هایی که از محتوای شخص ثالث (صفحات وب، فایل‌های PDF، ایمیل‌ها) می‌آیند، در یک محیط تجزیه جدا شده پاک‌سازی شوند قبل از اینکه به درخواست اصلی اضافه شوند.                                        |  2  |  D  |
| 2.1.5 | اطمینان حاصل کنید که همه به‌روزرسانی‌های قوانین فیلتر پرامپت، نسخه‌های مدل طبقه‌بندی‌کننده و تغییرات فهرست مسدود شده به صورت کنترل نسخه شده و قابل حسابرسی هستند.                                                   |  3  | D/V |

---

## C2.2 مقاومت در برابر نمونه‌های خصمانه

مدل‌های پردازش زبان طبیعی (NLP) همچنان در برابر تغییرات ظریف در سطح کاراکتر یا کلمه آسیب‌پذیر هستند که انسان‌ها اغلب آن‌ها را متوجه نمی‌شوند اما مدل‌ها به طور معمول آن‌ها را به اشتباه طبقه‌بندی می‌کنند.

|   #   | توضیحات                                                                                                                                                                                | سطح | نقش |
| :---: | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.2.1 | اطمینان حاصل کنید که مراحل پایه نرمال‌سازی ورودی (NFC یونیکد، نگاشت هم‌ریشه‌ها، حذف فاصله‌های اضافی) قبل از توکنیزه کردن اجرا شوند.                                                    |  1  |  D  |
| 2.2.2 | تأیید کنید که تشخیص ناهنجاری آماری ورودی‌هایی را که فاصله ویرایشی به‌طور غیرمعمول بالا نسبت به هنجارهای زبانی دارند، توکن‌های بیش از حد تکراری یا فاصله‌های تعبیه غیرعادی نشان می‌دهد. |  2  | D/V |
| 2.2.3 | تأیید کنید که خط لوله استنتاج از نسخه‌های مدل مقاوم‌شده به آموزش خصمانه اختیاری یا لایه‌های دفاعی (مانند تصادفی‌سازی، تقطیر دفاعی) برای نقاط پایانی با ریسک بالا پشتیبانی می‌کند.      |  2  |  D  |
| 2.2.4 | اطمینان حاصل کنید که ورودی‌های مشکوک به مهاجمان در قرنطینه قرار می‌گیرند و با بار کامل داده‌ها (پس از حذف اطلاعات شناسایی شخصی) ثبت می‌شوند.                                           |  2  |  V  |
| 2.2.5 | اطمینان حاصل کنید که معیارهای استحکام (نرخ موفقیت مجموعه‌های حمله شناخته شده) در طول زمان ردیابی شوند و بازگشت‌ها باعث ایجاد مانع برای انتشار شوند.                                    |  3  | D/V |

---

## C2.3 اعتبارسنجی طرح‌واره، نوع و طول

حملات هوش مصنوعی با ورودی‌های نامنظم یا بزرگ می‌توانند باعث خطاهای تجزیه، نشت دستورالعمل در زمینه‌ها و خستگی منابع شوند. اعمال دقیق طرح‌واره همچنین پیش‌نیاز لازم هنگام انجام فراخوانی‌های ابزار قطعی است.

|   #   | توضیحات                                                                                                                                                                                | سطح | نقش |
| :---: | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.3.1 | اطمینان حاصل کنید که هر نقطه پایان فراخوانی API یا تابع، یک طرح ورودی صریح (JSON Schema، Protobuf یا معادل چندرسانه‌ای) تعریف می‌کند و ورودی‌ها قبل از ساخت پرامپت اعتبارسنجی می‌شوند. |  1  |  D  |
| 2.3.2 | اطمینان حاصل کنید که ورودی‌هایی که از حد مجاز توکن یا بایت عبور می‌کنند، با یک خطای ایمن رد می‌شوند و هرگز به‌طور بی‌صدا کوتاه نمی‌شوند.                                               |  1  | D/V |
| 2.3.3 | بررسی کنید که چک‌های نوع (مانند محدوده‌های عددی، مقادیر enum، نوع MIME برای تصاویر/صوت) در سمت سرور اعمال شوند و نه فقط در کد سمت کلاینت.                                              |  2  | D/V |
| 2.3.4 | اطمینان حاصل کنید که اعتبارسنج‌های معنایی (مانند JSON Schema) در زمان ثابت اجرا می‌شوند تا از حملات DoS الگوریتمی جلوگیری شود.                                                         |  2  |  D  |
| 2.3.5 | اطمینان حاصل کنید که شکست‌های اعتبارسنجی با قطعات پالود داده شده و کدهای خطای بدون ابهام ثبت می‌شوند تا در بررسی امنیتی کمک کنند.                                                      |  3  |  V  |

---

## C2.4 غربالگری محتوا و سیاست‌ها

توسعه‌دهندگان باید قادر باشند پرسش‌های نحوی صحیح که درخواست محتوای ممنوعه (مانند دستورالعمل‌های غیرقانونی، گفتار نفرت‌انگیز و متون دارای حق کپی‌رایت) را دارند، شناسایی کرده و سپس از گسترش آنها جلوگیری کنند.

|   #   | توضیحات                                                                                                                                                                       | سطح | نقش |
| :---: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.4.1 | تأیید کنید که یک طبقه‌بند محتوا (صفر شات یا آموزش دیده شده) هر ورودی را برای خشونت، خودآسیبی، نفرت، محتوای جنسی و درخواست‌های غیرقانونی با آستانه‌های قابل تنظیم ارزیابی کند. |  1  |  D  |
| 2.4.2 | تأیید کنید که ورودی‌هایی که قوانین را نقض می‌کنند، پاسخ‌های استاندارد شده یا تکمیل‌های ایمن دریافت خواهند کرد تا به فراخوانی‌های بعدی مدل زبان بزرگ منتقل نشوند.              |  1  | D/V |
| 2.4.3 | اطمینان حاصل کنید که مدل غربالگری یا مجموعه قوانین حداقل به صورت فصلی بازآموزی/به‌روزرسانی شود و الگوهای تازه مشاهده شده فرار از محدودیت یا دورزدن سیاست‌ها را در بر گیرد.    |  2  |  D  |
| 2.4.4 | اطمینان حاصل کنید که غربالگری، سیاست‌های خاص کاربر (سن، محدودیت‌های قانونی منطقه‌ای) را از طریق قوانین مبتنی بر ویژگی که در زمان درخواست حل می‌شوند، رعایت می‌کند.            |  2  |  D  |
| 2.4.5 | تأیید کنید که گزارش‌های غربالگری شامل نمرات اطمینان طبقه‌بندی‌کننده و برچسب‌های دسته‌بندی سیاست برای همبستگی SOC و پخش مجدد تیم قرمز در آینده باشد.                           |  3  |  V  |

---

## C2.5 محدود کردن نرخ ورودی و پیشگیری از سوء استفاده

توسعه‌دهندگان باید از سوءاستفاده، خستگی منابع و حملات خودکار علیه سیستم‌های هوش مصنوعی با محدود کردن نرخ ورودی‌ها و شناسایی الگوهای استفاده غیرعادی جلوگیری کنند.

|   #   | توضیحات                                                                                                                                                | سطح | نقش |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------ | :-: | :-: |
| 2.5.1 | تأیید کنید که محدودیت‌های نرخ برای هر کاربر، هر آدرس IP و هر کلید API برای تمامی نقاط ورود داده اعمال می‌شوند.                                         |  1  | D/V |
| 2.5.2 | تأیید کنید که محدودیت‌های نرخ انفجاری و مداوم به گونه‌ای تنظیم شده‌اند که از حملات انکار سرویس (DoS) و حملات brute force جلوگیری کنند.                 |  2  | D/V |
| 2.5.3 | تأیید کنید که الگوهای استفاده غیرمعمول (برای مثال، درخواست‌های سریع متوالی، اشباع ورودی) باعث فعال شدن مسدودسازی‌های خودکار یا افزایش سطح رسیدگی شوند. |  2  | D/V |
| 2.5.4 | اطمینان حاصل کنید که گزارش‌های پیشگیری از سوءاستفاده حفظ شده و برای الگوهای حمله در حال ظهور بررسی می‌شوند.                                            |  3  |  V  |

---

## C2.6 اعتبارسنجی ورودی چندوجهی

سیستم‌های هوش مصنوعی باید اعتبارسنجی قوی برای ورودی‌های غیرمتنی (تصاویر، صدا، فایل‌ها) شامل شوند تا از تزریق، فرار یا سوءاستفاده از منابع جلوگیری شود.

|   #   | توضیحات                                                                                                                                  | سطح | نقش |
| :---: | ---------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.6.1 | اطمینان حاصل کنید که تمامی ورودی‌های غیر متنی (تصاویر، صدا، فایل‌ها) از نظر نوع، اندازه و فرمت قبل از پردازش بررسی و اعتبارسنجی شده‌اند. |  1  |  D  |
| 2.6.2 | اطمینان حاصل کنید که فایل‌ها قبل از بارگذاری، جهت شناسایی بدافزارها و بارهای استگانولوژیک اسکن می‌شوند.                                  |  2  | D/V |
| 2.6.3 | تأیید کنید که ورودی‌های تصویر/صدا برای اختلالات مخرب یا الگوهای حمله شناخته شده بررسی شده باشند.                                         |  2  | D/V |
| 2.6.4 | اطمینان حاصل کنید که شکست‌های اعتبارسنجی ورودی چندمودالی ثبت شده و هشدارهایی را برای بررسی ایجاد می‌کنند.                                |  3  |  V  |

---

## C2.7 منشأ ورودی و انتساب

سیستم‌های هوش مصنوعی باید از طریق نظارت و برچسب‌گذاری منابع تمام ورودی‌های کاربران، از ممیزی، پیگیری سوء استفاده و تطابق پشتیبانی کنند.

|   #   | توضیحات                                                                                                                          | سطح | نقش |
| :---: | -------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.7.1 | تأیید کنید که تمام ورودی‌های کاربر هنگام دریافت با متادیتا (شناسه کاربر، نشست، منبع، زمان‌بندی، نشانی IP) برچسب‌گذاری شده باشند. |  1  | D/V |
| 2.7.2 | اطمینان حاصل کنید که فراداده منشا برای تمام ورودی‌های پردازش شده حفظ شده و قابل بررسی باشد.                                      |  2  | D/V |
| 2.7.3 | مطمئن شوید که منابع ورودی غیرعادی یا غیرقابل اعتماد علامت‌گذاری شده و تحت بررسی دقیق‌تر یا مسدودسازی قرار می‌گیرند.              |  2  | D/V |

---

## C2.8 تشخیص تهدید تطبیقی در زمان واقعی

توسعه‌دهندگان باید از سیستم‌های پیشرفته شناسایی تهدید برای هوش مصنوعی استفاده کنند که به الگوهای جدید حمله سازگار شده و حفاظت در زمان واقعی با تطبیق الگوی کامپایل شده ارائه دهند.

|   #   | توضیحات                                                                                                                                                                              | سطح | نقش |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :-: | :-: |
| 2.8.1 | اطمینان حاصل کنید که الگوهای تشخیص تهدید به موتورهای regex بهینه‌شده تبدیل شده‌اند تا فیلترینگ بلادرنگ با عملکرد بالا و تأثیر حداقلی بر تأخیر انجام شود.                             |  1  | D/V |
| 2.8.2 | اطمینان حاصل کنید که سیستم‌های تشخیص تهدید، کتابخانه‌های الگو جداگانه برای دسته‌های مختلف تهدید (تزریق فرمان، محتوای مضر، داده‌های حساس، دستورات سیستم) حفظ می‌کنند.                 |  1  | D/V |
| 2.8.3 | اطمینان حاصل کنید که تشخیص تهدید تطبیقی شامل مدل‌های یادگیری ماشین است که حساسیت تهدید را بر اساس فراوانی حمله و نرخ موفقیت به‌روزرسانی می‌کنند.                                     |  2  | D/V |
| 2.8.4 | تأیید کنید که خوراک‌های اطلاعات تهدید به‌صورت بلادرنگ به‌طور خودکار کتابخانه‌های الگو را با امضاهای حمله جدید و شاخص‌های نفوذ (IOC) به‌روزرسانی می‌کنند.                             |  2  | D/V |
| 2.8.5 | اطمینان حاصل کنید که نرخ‌های مثبت کاذب در تشخیص تهدید به طور مداوم نظارت می‌شوند و ویژگی‌های الگو به طور خودکار تنظیم می‌شوند تا حداقل تداخل با موارد استفاده قانونی را داشته باشند. |  3  | D/V |
| 2.8.6 | بررسی کنید که تحلیل تهدید متنی منبع ورودی، الگوهای رفتار کاربر و تاریخچه جلسه را برای بهبود دقت تشخیص در نظر می‌گیرد.                                                                |  3  | D/V |
| 2.8.7 | اطمینان حاصل کنید که معیارهای عملکرد شناسایی تهدید (نرخ شناسایی، تأخیر پردازش، استفاده از منابع) به صورت آنلاین مانیتور شده و بهینه‌سازی می‌شوند.                                    |  3  | D/V |

---

## C2.9 خط لوله اعتبارسنجی امنیت چند حالته

توسعه‌دهندگان باید اعتبارسنجی امنیتی برای ورودی‌های متنی، تصویری، صوتی و سایر حالت‌های ورودی هوش مصنوعی با استفاده از انواع مشخصی از تشخیص تهدید و جداسازی منابع ارائه دهند.

|   #   | توضیحات                                                                                                                                                                                                                                   | سطح | نقش |
| :---: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.9.1 | اطمینان حاصل کنید که هر روش ورودی دارای اعتبارسنج‌های امنیتی اختصاصی با الگوهای تهدید مستند شده (متن: تزریق پرامپت، تصاویر: پنهان‌نگاری، صوت: حملات طیف‌نگار) و آستانه‌های تشخیص می‌باشد.                                                 |  1  | D/V |
| 2.9.2 | اطمینان حاصل کنید که ورودی‌های چند حالته در محیط‌های ایزوله با محدودیت‌های منابع مشخص (حافظه، CPU، زمان پردازش) که به هر نوع حالت اختصاص داده شده‌اند، پردازش می‌شوند و این موارد در سیاست‌های امنیتی مستندسازی شده‌اند.                  |  2  | D/V |
| 2.9.3 | اطمینان حاصل کنید که تشخیص حمله چندوجهی، حملات هماهنگ شده که چندین نوع ورودی را شامل می‌شوند (به عنوان مثال، بارهای نهان‌نگاری شده در تصاویر همراه با تزریق درخواست در متن) را با استفاده از قوانین همبستگی و تولید هشدار شناسایی می‌کند. |  2  | D/V |
| 2.9.4 | تأیید کنید که شکست‌های اعتبارسنجی چندوجهی باعث ثبت دقیق گزارش‌ها می‌شوند، از جمله همه حالت‌های ورودی، نتایج اعتبارسنجی، نمرات تهدید و تحلیل همبستگی با فرمت‌های گزارش ساختاریافته برای یکپارچگی با SIEM.                                  |  3  | D/V |
| 2.9.5 | اطمینان حاصل کنید که دسته‌بندهای محتوای اختصاصی مدالیته مطابق با برنامه‌های مستند (حداقل فصلی) با الگوهای تهدید جدید، نمونه‌های متخاصم و معیارهای عملکرد که بالاتر از آستانه‌های پایه نگهداری می‌شوند، به‌روزرسانی می‌شوند.               |  3  | D/V |

---

## مراجع

* [LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security](https://genai.owasp.org/llmrisk/llm01-prompt-injection/)
* [Generative AI's Biggest Security Flaw Is Not Easy to Fix](https://www.wired.com/story/generative-ai-prompt-injection-hacking)
* [Many-shot jailbreaking \ Anthropic](https://www.anthropic.com/research/many-shot-jailbreaking)
* [$PDF$ OpenAI GPT-4.5 System Card](https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf)
* [Notebook for the CheckThat Lab at CLEF 2024](https://ceur-ws.org/Vol-3740/paper-53.pdf)
* [Mitigate jailbreaks and prompt injections – Anthropic](https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks)
* [Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis](https://ama.drwhy.ai/mitre-attck.html)
* [OWASP Top 10 for LLM Applications 2025 – WorldTech IT](https://wtit.com/blog/2025/04/17/owasp-top-10-for-llm-applications-2025/)
* [OWASP Machine Learning Security Top Ten](https://owasp.org/www-project-machine-learning-security-top-10/)
* [Few words about AI Security – Jussi Metso](https://www.jussimetso.com/index.php/2024/09/28/few-words-about-ai-security/)
* [How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry](https://modelmetry.com/blog/how-to-ensure-llm-output-adheres-to-a-json-schema)
* [Easily enforcing valid JSON schema following – API](https://community.openai.com/t/feature-request-function-calling-easily-enforcing-valid-json-schema-following/263515?utm_source)
* [AI Safety + Cybersecurity R\&D Tracker – Fairly AI](https://www.fairly.ai/blog/ai-cybersecurity-tracker)
* [Anthropic makes 'jailbreak' advance to stop AI models producing harmful results](https://www.ft.com/content/cf11ebd8-aa0b-4ed4-945b-a5d4401d186e)
* [Pattern matching filter rules - IBM](https://www.ibm.com/docs/ssw_aix_71/security/intrusion_pattern_matching_filter_rules.html)
* [Real-time Threat Detection](https://www.darktrace.com/cyber-ai-glossary/real-time-threat-detection)

