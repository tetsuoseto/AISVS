# اعتبارسنجی ورودی کاربر C2

## هدف کنترل

اعتبارسنجی محکم ورودی کاربر، نخستین خط دفاع در برابر برخی از مخرب‌ترین حملات به سیستم‌های هوش مصنوعی است. حملات تزریق پرامپت می‌توانند دستورالعمل‌های سیستم را نادیده بگیرند، داده‌های حساس را فاش کنند یا مدل را به سمت رفتاری هدایت کنند که مجاز نیست. مگر اینکه فیلترهای اختصاصی و سلسله‌مراتب دستوری برقرار باشد، تحقیقات نشان می‌دهد که «جلبریک‌های چندمرحله‌ای» که از پنجره‌های زمینه بسیار طولانی سوء استفاده می‌کنند، مؤثر خواهند بود. همچنین، حملات تغییرات ظریف خصمانه—مانند تعویض هوموگلیف یا زبان لِتس‌پیک—می‌توانند به‌صورت بی‌صدا تصمیمات مدل را تغییر دهند.

---

## C2.1 دفاع در برابر تزریق پرامپت

تزریق پرامپت یکی از بزرگترین ریسک‌ها برای سیستم‌های هوش مصنوعی است. دفاع در برابر این تاکتیک شامل ترکیبی از فیلترهای الگوی ایستا، طبقه‌بندی‌کننده‌های پویا و اجرای سلسله‌مراتب دستورات است.

|   #   | توضیحات                                                                                                                                                                                                                                     | سطح | نقش |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.1.1 | تأیید کنید که ورودی‌های کاربر در برابر کتابخانه‌ای که به طور مداوم به‌روزرسانی می‌شود از الگوهای شناخته‌شده تزریق پرامپت (کلمات کلیدی فرار از محدودیت، «نادیده گرفتن قبلی»، زنجیره‌های نقش‌آفرینی، حملات غیرمستقیم HTML/URL) بررسی می‌شوند. |  1  | D/V |
| 2.1.2 | اطمینان حاصل کنید که سیستم یک سلسله مراتب دستوری را اعمال می‌کند که در آن پیام‌های سیستم یا توسعه‌دهنده دستورالعمل‌های کاربر را لغو می‌کند، حتی پس از گسترش پنجره زمینه.                                                                    |  1  | D/V |
| 2.1.3 | اطمینان حاصل کنید که آزمون‌های ارزیابی مقابله‌ای (مثلاً درخواست‌های "چندشات" تیم قرمز) قبل از هر انتشار مدل یا قالب درخواست اجرا می‌شوند، با تعیین آستانه‌های نرخ موفقیت و مسدودکننده‌های خودکار برای پسرفت‌ها.                             |  2  | D/V |
| 2.1.4 | اطمینان حاصل کنید که پرامپت‌های منشأ گرفته از محتوای شخص ثالث (صفحات وب، فایل‌های PDF، ایمیل‌ها) در یک زمینه پارسینگ جداگانه پاک‌سازی شده‌اند قبل از اینکه به پرامپت اصلی الحاق شوند.                                                       |  2  |  D  |
| 2.1.5 | اطمینان حاصل کنید که تمامی به‌روزرسانی‌های قوانین فیلتر پرامپت، نسخه‌های مدل طبقه‌بندی‌کننده و تغییرات فهرست مسدودشده تحت کنترل نسخه و قابل حسابرسی باشند.                                                                                  |  3  | D/V |

---

## مقاومت در برابر نمونه‌های تهدیدآمیز (Adversarial-Example Resistance)

مدل‌های پردازش زبان طبیعی (NLP) همچنان در برابر تغییرات ظریف در سطح کاراکتر یا کلمه آسیب‌پذیر هستند که انسان‌ها اغلب آن‌ها را تشخیص نمی‌دهند اما مدل‌ها معمولاً در طبقه‌بندی اشتباه می‌کنند.

|   #   | توضیحات                                                                                                                                                                                 | سطح | نقش |
| :---: | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.2.1 | اطمینان حاصل کنید که مراحل پایه نرمال‌سازی ورودی (NFC یونی‌کد، نگاشت هم‌ریشگی، حذف فاصله‌های زائد) قبل از توکنیزاسیون اجرا شوند.                                                        |  1  |  D  |
| 2.2.2 | بررسی کنید که تشخیص ناهنجاری آماری ورودی‌هایی را که فاصله ویرایشی غیرمعمول بالا نسبت به معیارهای زبانی، تکرار بیش از حد توکن‌ها، یا فاصله تعبیه نامتعارف دارند علامت‌گذاری کند.         |  2  | D/V |
| 2.2.3 | اطمینان حاصل کنید که خط لوله استنتاج از نسخه‌های مدل سخت‌شده با آموزش مقابله‌ای اختیاری یا لایه‌های دفاعی (برای مثال، تصادفی‌سازی، تقطیر دفاعی) برای نقاط پایانی پرخطر پشتیبانی می‌کند. |  2  |  D  |
| 2.2.4 | اطمینان حاصل کنید که ورودی‌های مشکوک به عنوان حملات خصمانه قرنطینه شده، با بار کامل (پس از حذف اطلاعات شناسایی شخصی) ثبت می‌شوند.                                                       |  2  |  V  |
| 2.2.5 | اطمینان حاصل کنید که معیارهای استحکام (نرخ موفقیت مجموعه حملات شناخته شده) در طول زمان رصد می‌شوند و پسرفت‌ها باعث ایجاد مانع در انتشار می‌شوند.                                        |  3  | D/V |

---

## C2.3 اعتبارسنجی طرحواره، نوع و طول

حملات هوش مصنوعی که شامل ورودی‌های نادرست یا بزرگ‌نمایی شده هستند می‌توانند باعث خطاهای تجزیه، نفوذ فرمان‌ها به فیلدهای دیگر و خستگی منابع شوند. همچنین، اجرای دقیق قوانین طرح‌واره (schema) هنگام انجام فراخوانی‌های ابزار قطعی ضروری است.

|   #   | توضیحات                                                                                                                                                                           | سطح | نقش |
| :---: | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.3.1 | تأیید کنید که هر نقطه پایان API یا فراخوانی تابع یک طرح ورودی صریح (JSON Schema، Protobuf یا معادل چندوجهی) تعریف کرده است و ورودی‌ها قبل از جمع‌آوری درخواست اعتبارسنجی می‌شوند. |  1  |  D  |
| 2.3.2 | تأیید کنید که ورودی‌هایی که از حداکثر محدودیت توکن یا بایت فراتر می‌روند، با خطای ایمن رد شوند و هرگز به‌طور پنهانی کوتاه نشوند.                                                  |  1  | D/V |
| 2.3.3 | تأیید کنید که بررسی‌های نوع (مثلاً محدوده‌های عددی، مقادیر enum، نوع MIME برای تصاویر/صدا) در سمت سرور اعمال می‌شوند و نه فقط در کد کلاینت.                                       |  2  | D/V |
| 2.3.4 | تأیید کنید که اعتبارسنج‌های معنایی (مانند JSON Schema) در زمان ثابت اجرا می‌شوند تا از حملات DoS الگوریتمی جلوگیری شود.                                                           |  2  |  D  |
| 2.3.5 | اطمینان حاصل کنید که شکست‌های اعتبارسنجی با بخش‌های حذف‌شده از محتوا و کدهای خطای بدون ابهام ثبت می‌شوند تا به فرایند بررسی‌های امنیتی کمک کنند.                                  |  3  |  V  |

---

## C2.4 بررسی محتوا و سیاست‌ها

توسعه‌دهندگان باید بتوانند پرامپت‌های نحوی صحیح که درخواست محتوای غیرمجاز (مانند دستورالعمل‌های غیرقانونی، سخنان نفرت‌انگیز و متن‌های دارای حق کپی‌رایت) را دارند، شناسایی کرده و سپس از انتشار آن‌ها جلوگیری کنند.

|   #   | توضیحات                                                                                                                                                                               | سطح | نقش |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.4.1 | تأیید کنید که یک طبقه‌بند محتوا (صفر شات یا ریزتنظیم شده) هر ورودی را برای خشونت، خودآسیبی، نفرت، محتوای جنسی و درخواست‌های غیرقانونی امتیازدهی می‌کند، با آستانه‌های قابل تنظیم.     |  1  |  D  |
| 2.4.2 | تأیید کنید که ورودی‌هایی که سیاست‌ها را نقض می‌کنند، پاسخ‌های استاندارد شده امتناع یا تکمیل‌های ایمن دریافت خواهند کرد تا از انتشار آن‌ها به تماس‌های بعدی مدل زبان بزرگ جلوگیری شود. |  1  | D/V |
| 2.4.3 | تأیید کنید که مدل غربالگری یا مجموعه قوانین حداقل به‌صورت فصلی بازآموزی/به‌روزرسانی می‌شود و الگوهای جدید مشاهده شده از دورزدن امنیت یا دورزدن سیاست را در بر می‌گیرد.                |  2  |  D  |
| 2.4.4 | تأیید کنید که غربالگری قوانین خاص کاربران (سن، محدودیت‌های قانونی منطقه‌ای) را از طریق قوانین مبتنی بر ویژگی که در زمان درخواست حل می‌شوند، رعایت می‌کند.                             |  2  |  D  |
| 2.4.5 | اطمینان حاصل کنید که لاگ‌های غربالگری شامل امتیازهای اطمینان طبقه‌بندی‌کننده و برچسب‌های دسته‌بندی سیاست برای همبستگی SOC و بازپخش تیم قرمز آینده باشند.                              |  3  |  V  |

---

## C2.5 محدود کردن نرخ ورودی و جلوگیری از سوءاستفاده

توسعه‌دهندگان باید از سوءاستفاده، اتمام منابع و حملات خودکار علیه سیستم‌های هوش مصنوعی با محدود کردن نرخ ورودی‌ها و شناسایی الگوهای استفاده غیرعادی جلوگیری کنند.

|   #   | توضیحات                                                                                                                                              | سطح | نقش |
| :---: | ---------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.5.1 | اطمینان حاصل کنید که محدودیت‌های نرخ برای هر کاربر، هر IP و هر کلید API برای تمام نقاط ورودی اعمال شده‌اند.                                          |  1  | D/V |
| 2.5.2 | تأیید کنید که محدودیت‌های نرخ انفجاری و پایدار به گونه‌ای تنظیم شده‌اند که از حملات انکار سرویس (DoS) و حدس‌های اجباری جلوگیری کنند.                 |  2  | D/V |
| 2.5.3 | تأیید کنید که الگوهای استفاده غیرمعمول (مثلاً درخواست‌های سریع متوالی، پرکردن ورودی) موجب فعال شدن مسدودسازی‌های خودکار یا افزایش سطح واکنش می‌شوند. |  2  | D/V |
| 2.5.4 | تأیید کنید که لاگ‌های پیشگیری از سوءاستفاده نگهداری شده و برای الگوهای حمله جدید بازبینی می‌شوند.                                                    |  3  |  V  |

---

## C2.6 اعتبارسنجی ورودی چندرسانه‌ای

سیستم‌های هوش مصنوعی باید اعتبارسنجی قوی برای ورودی‌های غیرمتنی (تصاویر، صوت، فایل‌ها) داشته باشند تا از تزریق، فرار یا سوءاستفاده از منابع جلوگیری کنند.

|   #   | توضیحات                                                                                                                      | سطح | نقش |
| :---: | ---------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.6.1 | اطمینان حاصل کنید که تمام ورودی‌های غیر متنی (تصاویر، صدا، فایل‌ها) از نظر نوع، اندازه و فرمت قبل از پردازش اعتبارسنجی شوند. |  1  |  D  |
| 2.6.2 | اطمینان حاصل کنید که فایل‌ها قبل از ورود، برای بدافزار و بارهای پنهان‌شده استگانوگرافیک اسکن شده‌اند.                        |  2  | D/V |
| 2.6.3 | اطمینان حاصل کنید که ورودی‌های تصویر/صدا برای اختلالات دشمن‌گونه یا الگوهای حمله شناخته شده بررسی شوند.                      |  2  | D/V |
| 2.6.4 | تأیید کنید که شکست‌های اعتبارسنجی ورودی چندرسانه‌ای ثبت و هشدارهایی برای تحقیق ایجاد می‌شوند.                                |  3  |  V  |

---

## C2.7 منشاء و انتساب ورودی

سیستم‌های هوش مصنوعی باید از طریق نظارت و برچسب‌گذاری مبدا تمام ورودی‌های کاربران، از حسابرسی، پیگیری سوءاستفاده و انطباق پشتیبانی کنند.

|   #   | توضیحات                                                                                                                             | سطح | نقش |
| :---: | ----------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.7.1 | اطمینان حاصل کنید که همه ورودی‌های کاربران هنگام ورود با فراداده (شناسه کاربر، نشست، منبع، زمان‌سنجی، آدرس IP) برچسب‌گذاری شده‌اند. |  1  | D/V |
| 2.7.2 | اطمینان حاصل کنید که فراداده منشاء برای تمام ورودی‌های پردازش شده حفظ شده و قابل حسابرسی است.                                       |  2  | D/V |
| 2.7.3 | اطمینان حاصل کنید که منابع ورودی غیرعادی یا نامعتبر شناسایی شده و تحت بررسی دقیق‌تر یا مسدودسازی قرار گیرند.                        |  2  | D/V |

---

## C2.8 تشخیص تهدید تطبیقی در زمان واقعی

توسعه‌دهندگان باید از سیستم‌های پیشرفته تشخیص تهدید برای هوش مصنوعی استفاده کنند که به الگوهای جدید حمله سازگار شده و حفاظت بلادرنگ با تطبیق الگوهای کامپایل شده ارائه دهند.

|   #   | توضیحات                                                                                                                                                                             | سطح | نقش |
| :---: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.8.1 | اطمینان حاصل کنید که الگوهای تشخیص تهدید به موتورهای regex بهینه شده برای فیلتر کردن بلادرنگ با عملکرد بالا و کمترین تأثیر بر تأخیر کامپایل شده‌اند.                                |  1  | D/V |
| 2.8.2 | اطمینان حاصل کنید که سیستم‌های شناسایی تهدید، کتابخانه‌های الگو جداگانه‌ای برای دسته‌های مختلف تهدید (تزریق فرمان، محتوای مضر، داده‌های حساس، فرمان‌های سیستم) نگهداری می‌کنند.     |  1  | D/V |
| 2.8.3 | تأیید کنید که تشخیص تهدید تطبیقی شامل مدل‌های یادگیری ماشین است که حساسیت تهدید را بر اساس فراوانی و نرخ موفقیت حملات به‌روزرسانی می‌کنند.                                          |  2  | D/V |
| 2.8.4 | اطمینان حاصل کنید که فیدهای اطلاعات تهدیدات به‌صورت بلادرنگ به‌طور خودکار کتابخانه‌های الگو را با امضاهای جدید حمله و شاخص‌های نفوذ (IOCها) به‌روزرسانی می‌کنند.                    |  2  | D/V |
| 2.8.5 | اطمینان حاصل کنید که نرخ‌های مثبت کاذب شناسایی تهدید به طور مداوم نظارت می‌شوند و ویژگی‌های الگوی تهدید به صورت خودکار تنظیم می‌شوند تا تداخل با موارد استفاده مشروع به حداقل برسد. |  3  | D/V |
| 2.8.6 | اطمینان حاصل کنید که تحلیل تهدید متنی منابع ورودی، الگوهای رفتار کاربر و تاریخچه جلسه را برای بهبود دقت تشخیص مدنظر قرار می‌دهد.                                                    |  3  | D/V |
| 2.8.7 | تأیید کنید که معیارهای عملکرد شناسایی تهدید (نرخ شناسایی، تأخیر پردازش، استفاده از منابع) به‌صورت بلادرنگ نظارت و بهینه‌سازی می‌شوند.                                               |  3  | D/V |

---

## C2.9 خط لوله اعتبارسنجی امنیت چندوجهی

توسعه‌دهندگان باید اعتبارسنجی امنیتی برای ورودی‌های متنی، تصویری، صوتی و سایر مدالیت‌های ورودی هوش مصنوعی با انواع خاصی از شناسایی تهدید و جداسازی منابع ارائه دهند.

|   #   | توضیحات                                                                                                                                                                                                                                        | سطح | نقش |
| :---: | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.9.1 | تأیید کنید که هر حالت ورودی دارای اعتبارسنج‌های امنیتی اختصاصی با الگوهای تهدید مستند شده (متن: تزریق درخواست، تصاویر: نهان‌نگاری، صدا: حملات طیف‌نمایی) و آستانه‌های شناسایی باشد.                                                            |  1  | D/V |
| 2.9.2 | تأیید کنید که ورودی‌های چندرسانه‌ای در محیط‌های ایزوله شده با محدودیت‌های منابع تعریف‌شده (حافظه، پردازنده، زمان پردازش) که مخصوص هر نوع حالت هستند و در سیاست‌های امنیتی مستندسازی شده‌اند، پردازش می‌شوند.                                   |  2  | D/V |
| 2.9.3 | اطمینان حاصل کنید که شناسایی حملات چندرسانه‌ای، حملات هماهنگ شده‌ای که شامل چندین نوع ورودی هستند (به عنوان مثال، بارهای پنهان‌شده در تصاویر همراه با تزریق درخواست در متن) را با قوانین همبستگی و تولید هشدار شناسایی می‌کند.                 |  2  | D/V |
| 2.9.4 | تأیید کنید که خطاهای اعتبارسنجی چندرسانه‌ای باعث ثبت دقیق لاگ شوند که شامل تمام حالت‌های ورودی، نتایج اعتبارسنجی، امتیازهای تهدید و تحلیل همبستگی با فرمت‌های ساختاریافته لاگ برای ادغام با SIEM باشد.                                         |  3  | D/V |
| 2.9.5 | اطمینان حاصل کنید که طبقه‌بندی‌کننده‌های محتوا مخصوص مدالیتی طبق برنامه‌های مستند شده (حداقل به صورت سه‌ماهه) با الگوهای تهدید جدید، نمونه‌های مقابله‌ای و معیارهای عملکردی که بالاتر از آستانه‌های پایه نگهداری می‌شوند، به‌روزرسانی می‌شوند. |  3  | D/V |

---

## مراجع

* [LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security](https://genai.owasp.org/llmrisk/llm01-prompt-injection/)
* [Generative AI's Biggest Security Flaw Is Not Easy to Fix](https://www.wired.com/story/generative-ai-prompt-injection-hacking)
* [Many-shot jailbreaking \ Anthropic](https://www.anthropic.com/research/many-shot-jailbreaking)
* [$PDF$ OpenAI GPT-4.5 System Card](https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf)
* [Notebook for the CheckThat Lab at CLEF 2024](https://ceur-ws.org/Vol-3740/paper-53.pdf)
* [Mitigate jailbreaks and prompt injections – Anthropic](https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks)
* [Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis](https://ama.drwhy.ai/mitre-attck.html)
* [OWASP Top 10 for LLM Applications 2025 – WorldTech IT](https://wtit.com/blog/2025/04/17/owasp-top-10-for-llm-applications-2025/)
* [OWASP Machine Learning Security Top Ten](https://owasp.org/www-project-machine-learning-security-top-10/)
* [Few words about AI Security – Jussi Metso](https://www.jussimetso.com/index.php/2024/09/28/few-words-about-ai-security/)
* [How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry](https://modelmetry.com/blog/how-to-ensure-llm-output-adheres-to-a-json-schema)
* [Easily enforcing valid JSON schema following – API](https://community.openai.com/t/feature-request-function-calling-easily-enforcing-valid-json-schema-following/263515?utm_source)
* [AI Safety + Cybersecurity R\&D Tracker – Fairly AI](https://www.fairly.ai/blog/ai-cybersecurity-tracker)
* [Anthropic makes 'jailbreak' advance to stop AI models producing harmful results](https://www.ft.com/content/cf11ebd8-aa0b-4ed4-945b-a5d4401d186e)
* [Pattern matching filter rules - IBM](https://www.ibm.com/docs/ssw_aix_71/security/intrusion_pattern_matching_filter_rules.html)
* [Real-time Threat Detection](https://www.darktrace.com/cyber-ai-glossary/real-time-threat-detection)

