# اعتبارسنجی ورودی کاربر C2

## هدف کنترل

اعتبارسنجی قوی ورودی کاربر یک خط دفاع اولیه در برابر برخی از مخرب‌ترین حملات به سیستم‌های هوش مصنوعی است. حملات تزریق دستورالعمل می‌تواند دستورات سیستم را بازنویسی کند، داده‌های حساس را نشت دهد یا مدل را به سمتی هدایت کند که رفتار غیرمجاز داشته باشد. مگر اینکه فیلترهای اختصاصی و سلسله مراتب دستورالعمل‌ها به کار گرفته شده باشند، تحقیقات نشان می‌دهد که «جلبریک‌»های چندمرحله‌ای که از پنجره‌های زمینه‌ای بسیار طولانی بهره می‌برند، موثر خواهند بود. همچنین، حملات تغییرات ظریف و متخاصم—مانند جایگزینی‌های هم‌نُمایه یا زبان لیت—می‌توانند بدون صدا تصمیمات مدل را تغییر دهند.

---

## C2.1 دفاع در برابر تزریق پرامپت

تزریق پرامپت یکی از بزرگ‌ترین ریسک‌ها برای سیستم‌های هوش مصنوعی است. دفاع در برابر این تاکتیک از ترکیبی از فیلترهای الگوی ایستا، طبقه‌بندهای پویا و اجرای سلسله‌مراتب دستورالعمل‌ها استفاده می‌کند.

|   #   | توضیحات                                                                                                                                                                                                                          | سطح | نقش |
| :---: | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.1.1 | اطمینان حاصل کنید که ورودی‌های کاربر در برابر یک کتابخانه به‌روز شده مداوم از الگوهای شناخته شده تزریق پرامپت (کلمات کلیدی فرار از محدودیت، "نادیده گرفتن قبلی"، زنجیره‌های نقش‌آفرینی، حملات غیرمستقیم HTML/URL) بررسی می‌شوند. |  1  | D/V |
| 2.1.2 | اطمینان حاصل کنید که سیستم یک سلسله‌مراتب دستوری را اجرا می‌کند که در آن پیام‌های سیستم یا توسعه‌دهنده، دستورالعمل‌های کاربر را حتی پس از گسترش پنجره زمینه، لغو می‌کنند.                                                        |  1  | D/V |
| 2.1.3 | اطمینان حاصل کنید که تست‌های ارزیابی خصمانه (برای مثال، پرامپت‌های "چند-شات" تیم قرمز) پیش از هر انتشار مدل یا قالب پرامپت اجرا می‌شوند، با آستانه‌های نرخ موفقیت و مسدودکننده‌های خودکار برای پسرفت‌ها.                         |  2  | D/V |
| 2.1.4 | تأیید کنید که درخواست‌هایی که از محتوای شخص ثالث (صفحات وب، فایل‌های PDF، ایمیل‌ها) منشأ می‌گیرند، در یک زمینه پارسینگ ایزوله شده تصفیه شوند قبل از اینکه به درخواست اصلی الحاق شوند.                                            |  2  |  D  |
| 2.1.5 | اطمینان حاصل کنید که تمامی به‌روزرسانی‌های قوانین فیلتر پرامپت، نسخه‌های مدل طبقه‌بندی‌کننده و تغییرات فهرست مسدودسازی، دارای کنترل نسخه و قابل ممیزی هستند.                                                                     |  3  | D/V |

---

## C2.2 مقاومت در برابر مثال‌های خصمانه

مدل‌های پردازش زبان طبیعی (NLP) همچنان نسبت به تغییرات ظریف در سطح حروف یا کلمات آسیب‌پذیر هستند که انسان‌ها اغلب متوجه آنها نمی‌شوند اما مدل‌ها تمایل دارند آنها را به اشتباه طبقه‌بندی کنند.

|   #   | توضیحات                                                                                                                                                                                        | سطح | نقش |
| :---: | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.2.1 | تأیید کنید که مراحل پایه نرمال‌سازی ورودی (Unicode NFC، نگاشت هم‌ریخت‌ها، برداشت فضای خالی) قبل از توکنیزاسیون اجرا شوند.                                                                      |  1  |  D  |
| 2.2.2 | اطمینان حاصل کنید که تشخیص ناهنجاری آماری ورودی‌هایی را علامت‌گذاری می‌کند که فاصله ویرایشی غیرمعمول بالا نسبت به هنجارهای زبانی، توکن‌های تکراری بیش از حد یا فاصله‌های جاسازی غیرعادی دارند. |  2  | D/V |
| 2.2.3 | اطمینان حاصل کنید که خط لوله استنتاج از نسخه‌های مدل مقاوم‌شده با آموزش خصمانه اختیاری یا لایه‌های دفاعی (مثلاً تصادفی‌سازی، تقطیر دفاعی) برای نقاط پایانی با ریسک بالا پشتیبانی می‌کند.       |  2  |  D  |
| 2.2.4 | اطمینان حاصل کنید که ورودی‌های مشکوک به حملات خصمانه در قرنطینه قرار گرفته، همراه با کل داده‌های بار (پس از حذف اطلاعات شناسایی شخصی) ثبت شوند.                                                |  2  |  V  |
| 2.2.5 | اطمینان حاصل کنید که معیارهای استحکام (نرخ موفقیت مجموعه‌های حمله شناخته‌شده) در طول زمان پیگیری می‌شوند و هرگونه پسرفت منجر به مسدودکننده انتشار می‌شود.                                      |  3  | D/V |

---

## اعتبارسنجی طرح‌واره، نوع و طول C2.3

حملات هوش مصنوعی که شامل ورودی‌های نادرست یا خیلی بزرگ هستند می‌توانند باعث بروز خطاهای تجزیه، نشت درخواست در بین فیلدها و خستگی منابع شوند. اجرای سختگیرانه‌ی ساختار (اسکیما) نیز پیش‌نیاز انجام فراخوانی‌های ابزار قطعی است.

|   #   | توضیحات                                                                                                                                                                                    | سطح | نقش |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :-: | :-: |
| 2.3.1 | اطمینان حاصل کنید که هر نقطه پایانی فراخوانی API یا تابع، یک اسکیمای ورودی صریح (JSON Schema، Protobuf یا معادل چندمودالی آن) را تعریف کند و ورودی‌ها قبل از ترکیب پرامپت اعتبارسنجی شوند. |  1  |  D  |
| 2.3.2 | بررسی کنید که ورودی‌هایی که از حد مجاز توکن یا بایت فراتر می‌روند، با یک خطای ایمن رد شوند و هرگز به طور خاموش قطع نشوند.                                                                  |  1  | D/V |
| 2.3.3 | اطمینان حاصل کنید که بررسی‌های نوع (برای مثال، بازه‌های عددی، مقادیر enum، نوع‌های MIME برای تصاویر/صدا) در سمت سرور اعمال می‌شوند و نه تنها در کد کلاینت.                                 |  2  | D/V |
| 2.3.4 | اطمینان حاصل کنید که اعتبارسنج‌های معنایی (مانند JSON Schema) در زمان ثابت اجرا می‌شوند تا از حملات DoS الگوریتمی جلوگیری شود.                                                             |  2  |  D  |
| 2.3.5 | اطمینان حاصل کنید که خطاهای اعتبارسنجی با قطعات داده‌های بازنویسی‌شده و کدهای خطای بی‌ابهام ثبت می‌شوند تا به طبقه‌بندی امنیتی کمک کنند.                                                   |  3  |  V  |

---

## C2.4 غربالگری محتوا و سیاست

توسعه‌دهندگان باید قادر باشند درخواست‌های معتبر نحوی که محتوای ممنوعه (مانند دستورالعمل‌های غیرمجاز، گفتار نفرت‌انگیز، و متون دارای حق نشر) را درخواست می‌کنند، شناسایی کرده و از انتشار آن‌ها جلوگیری کنند.

|   #   | توضیحات                                                                                                                                                                                                  | سطح | نقش |
| :---: | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.4.1 | اطمینان حاصل کنید که یک طبقه‌بند محتوا (بدون آموزش قبلی یا آموزش دیده) هر ورودی را برای خشونت، خودآسیب‌رسانی، نفرت، محتوای جنسی و درخواست‌های غیرقانونی امتیازدهی می‌کند، با آستانه‌های قابل تنظیم.      |  1  |  D  |
| 2.4.2 | تأیید کنید که ورودی‌هایی که قوانین را نقض می‌کنند، پاسخ‌های استاندارد شده امتناع یا تکمیل‌های ایمن دریافت خواهند کرد تا به تماس‌های بعدی مدل‌های زبانی بزرگ منتقل نشوند.                                 |  1  | D/V |
| 2.4.3 | اطمینان حاصل کنید که مدل غربالگری یا مجموعه قوانین حداقل هر سه ماه یکبار دوباره آموزش داده شده یا به‌روزرسانی می‌شود، به‌طوری که الگوهای جدید مشاهده‌شده از دور زدن محدودیت یا نقض سیاست را در بر بگیرد. |  2  |  D  |
| 2.4.4 | تأیید کنید که غربالگری قوانین مخصوص به کاربر (سن، محدودیت‌های قانونی منطقه‌ای) را از طریق قوانین مبتنی بر ویژگی که در زمان درخواست حل می‌شوند، رعایت می‌کند.                                             |  2  |  D  |
| 2.4.5 | تأیید کنید که لاگ‌های اسکرینینگ شامل امتیازهای اطمینان طبقه‌بندی‌کننده و برچسب‌های دسته‌بندی سیاست برای همبستگی SOC و پخش مجدد تیم قرمز در آینده باشند.                                                  |  3  |  V  |

---

## محدودیت نرخ ورودی C2.5 و پیشگیری از سوء استفاده

توسعه‌دهندگان باید از سوءاستفاده، خستگی منابع و حملات خودکار علیه سیستم‌های هوش مصنوعی جلوگیری کنند، از طریق محدود کردن نرخ ورودی‌ها و شناسایی الگوهای استفاده غیرعادی.

|   #   | توضیحات                                                                                                                                           | سطح | نقش |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.5.1 | اطمینان حاصل کنید که محدودیت‌های نرخ برای هر کاربر، هر آی‌پی و هر کلید API برای تمام نقطه‌های ورودی اعمال می‌شوند.                                |  1  | D/V |
| 2.5.2 | تأیید کنید که محدودیت‌های نرخ انفجار و نرخ پایدار تنظیم شده‌اند تا از حملات انکار سرویس (DoS) و حملات نیروی بی‌رحمانه جلوگیری کنند.               |  2  | D/V |
| 2.5.3 | تأیید کنید که الگوهای استفاده غیرطبیعی (مانند درخواست‌های سریع متوالی، پرکردن ورودی) باعث فعال شدن مسدودسازی‌های خودکار یا افزایش سطح هشدار شوند. |  2  | D/V |
| 2.5.4 | تأیید کنید که لاگ‌های جلوگیری از سوءاستفاده نگهداری شده و برای الگوهای حمله نوظهور مرور می‌شوند.                                                  |  3  |  V  |

---

## C2.6 اعتبارسنجی ورودی چند حالته

سیستم‌های هوش مصنوعی باید اعتبارسنجی قوی برای ورودی‌های غیر متنی (تصاویر، صدا، فایل‌ها) داشته باشند تا از تزریق، گریز یا سوء استفاده از منابع جلوگیری شود.

|   #   | توضیحات                                                                                                                           | سطح | نقش |
| :---: | --------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.6.1 | اطمینان حاصل کنید که همه ورودی‌های غیر متنی (تصاویر، صوت، فایل‌ها) قبل از پردازش از نظر نوع، اندازه و فرمت بررسی و تایید می‌شوند. |  1  |  D  |
| 2.6.2 | اطمینان حاصل کنید که فایل‌ها قبل از ورود اسکن شده و از نظر بدافزارها و بارهای مخفی‌نگاری شده بررسی شده‌اند.                       |  2  | D/V |
| 2.6.3 | اطمینان حاصل کنید که ورودی‌های تصویر/صدا برای تغییرات مخرب یا الگوهای حمله شناخته شده بررسی می‌شوند.                              |  2  | D/V |
| 2.6.4 | تأیید کنید که خطاهای اعتبارسنجی ورودی چند‌حالتی ثبت شده و هشدارهایی برای بررسی ایجاد می‌کنند.                                     |  3  |  V  |

---

## C2.7 منشأ و نسبت‌دهی ورودی

سیستم‌های هوش مصنوعی باید از حسابرسی، ردیابی سوء‌استفاده و تطبیق با قوانین پشتیبانی کنند، از طریق نظارت و برچسب‌گذاری مبدا همه ورودی‌های کاربر.

|   #   | توضیحات                                                                                                                             | سطح | نقش |
| :---: | ----------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.7.1 | تأیید کنید که تمام ورودی‌های کاربر با فراداده (شناسه کاربر، جلسه، منبع، زمان‌سنجی، آدرس IP) هنگام ورود داده‌ها برچسب‌گذاری شده‌اند. |  1  | D/V |
| 2.7.2 | تأیید کنید که متاداده منبع برای همه ورودی‌های پردازش شده حفظ شده و قابل حسابرسی باشد.                                               |  2  | D/V |
| 2.7.3 | بررسی کنید که منابع ورودی غیرعادی یا غیرقابل اعتماد علامت‌گذاری شده و تحت بررسی دقیق‌تر یا مسدودسازی قرار گیرند.                    |  2  | D/V |

---

## C2.8 شناسایی تهدید تطبیقی در زمان واقعی

توسعه‌دهندگان باید از سیستم‌های پیشرفته شناسایی تهدید برای هوش مصنوعی استفاده کنند که به الگوهای حمله جدید سازگار شده و با تطبیق الگوهای کامپایل شده، حفاظت بلادرنگ ارائه دهند.

|   #   | توضیحات                                                                                                                                                                              | سطح | نقش |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :-: | :-: |
| 2.8.1 | اطمینان حاصل کنید که الگوهای شناسایی تهدید به موتورهای بهینه‌شده عبارات منظم (regex) تبدیل شده‌اند تا فیلترکردن بلادرنگ با عملکرد بالا و کمترین تأثیر تأخیر انجام شود.               |  1  | D/V |
| 2.8.2 | تأیید کنید که سیستم‌های تشخیص تهدید، کتابخانه‌های الگویی جداگانه برای دسته‌های مختلف تهدید (تزریق درخواست، محتوای مضر، داده‌های حساس، دستورات سیستم) حفظ می‌کنند.                    |  1  | D/V |
| 2.8.3 | تأیید کنید که تشخیص تهدید تطبیقی شامل مدل‌های یادگیری ماشین است که حساسیت تهدید را بر اساس فرکانس و نرخ موفقیت حملات به‌روزرسانی می‌کنند.                                            |  2  | D/V |
| 2.8.4 | اطمینان حاصل کنید که خوراک‌های اطلاعات تهدید بلادرنگ به‌طور خودکار کتابخانه‌های الگو را با امضای حملات جدید و شاخص‌های نفوذ (IOCs) به‌روزرسانی می‌کنند.                              |  2  | D/V |
| 2.8.5 | اطمینان حاصل کنید که نرخ‌های مثبت کاذب در تشخیص تهدید به‌طور مداوم نظارت می‌شوند و ویژگی‌های الگو به‌طور خودکار تنظیم می‌شوند تا حداقل تداخل را با موارد استفاده قانونی داشته باشند. |  3  | D/V |
| 2.8.6 | تأیید کنید که تحلیل تهدید زمینه‌ای منبع ورودی، الگوهای رفتار کاربر و تاریخچه جلسه را برای بهبود دقت تشخیص در نظر می‌گیرد.                                                            |  3  | D/V |
| 2.8.7 | اطمینان حاصل کنید که معیارهای عملکرد تشخیص تهدید (نرخ تشخیص، تأخیر پردازش، استفاده از منابع) به‌صورت بلادرنگ نظارت و بهینه‌سازی می‌شوند.                                             |  3  | D/V |

---

## C2.9 خط لوله اعتبارسنجی امنیت چند-رسانه‌ای

توسعه‌دهندگان باید اعتبارسنجی امنیتی برای ورودی‌های متنی، تصویری، صوتی و دیگر مدالیت‌های ورودی هوش مصنوعی را با استفاده از انواع خاصی از شناسایی تهدید و ایزوله‌سازی منابع ارائه دهند.

|   #   | توضیحات                                                                                                                                                                                                                | سطح | نقش |
| :---: | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.9.1 | تأیید کنید که هر مدالیته ورودی دارای اعتبارسنج‌های امنیتی اختصاصی با الگوهای تهدید مستند شده (متن: تزریق پرامپت، تصاویر: استگانوگرافی، صوت: حملات اسپکتروگرام) و آستانه‌های تشخیص باشد.                                |  1  | D/V |
| 2.9.2 | اطمینان حاصل کنید که ورودی‌های چندوجهی در محیط‌های ایزوله با محدودیت‌های منابع مشخص (حافظه، پردازنده، زمان پردازش) که مختص هر نوع وجه هستند، پردازش می‌شوند و این موارد در سیاست‌های امنیتی مستند شده‌اند.             |  2  | D/V |
| 2.9.3 | تأیید کنید که تشخیص حملات چندوجهی، حملات هماهنگ‌شده‌ای که شامل چندین نوع ورودی هستند (مثلاً بارهای پنهان‌سازی‌شده در تصاویر همراه با تزریق پرامپت در متن) را با استفاده از قواعد همبستگی و تولید هشدار شناسایی می‌کند. |  2  | D/V |
| 2.9.4 | بررسی کنید که خطاهای اعتبارسنجی چندحالته باعث ثبت دقیق و مفصل لوگ‌ها شوند، شامل تمام حالت‌های ورودی، نتایج اعتبارسنجی، امتیازهای تهدید، و تحلیل همبستگی با فرمت‌های ساختاریافتهٔ لوگ برای یکپارچه‌سازی با SIEM.        |  3  | D/V |
| 2.9.5 | تأیید کنید که دسته‌بندهای محتوای مربوط به هر حالت بر اساس برنامه‌های مستند شده (حداقل فصلی) با الگوهای جدید تهدید، نمونه‌های مخرب و معیارهای عملکرد که بالاتر از آستانه‌های پایه حفظ شده‌اند، به‌روزرسانی می‌شوند.     |  3  | D/V |

---

## مراجع

* [LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security](https://genai.owasp.org/llmrisk/llm01-prompt-injection/)
* [Generative AI's Biggest Security Flaw Is Not Easy to Fix](https://www.wired.com/story/generative-ai-prompt-injection-hacking)
* [Many-shot jailbreaking \ Anthropic](https://www.anthropic.com/research/many-shot-jailbreaking)
* [$PDF$ OpenAI GPT-4.5 System Card](https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf)
* [Notebook for the CheckThat Lab at CLEF 2024](https://ceur-ws.org/Vol-3740/paper-53.pdf)
* [Mitigate jailbreaks and prompt injections – Anthropic](https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks)
* [Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis](https://ama.drwhy.ai/mitre-attck.html)
* [OWASP Top 10 for LLM Applications 2025 – WorldTech IT](https://wtit.com/blog/2025/04/17/owasp-top-10-for-llm-applications-2025/)
* [OWASP Machine Learning Security Top Ten](https://owasp.org/www-project-machine-learning-security-top-10/)
* [Few words about AI Security – Jussi Metso](https://www.jussimetso.com/index.php/2024/09/28/few-words-about-ai-security/)
* [How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry](https://modelmetry.com/blog/how-to-ensure-llm-output-adheres-to-a-json-schema)
* [Easily enforcing valid JSON schema following – API](https://community.openai.com/t/feature-request-function-calling-easily-enforcing-valid-json-schema-following/263515?utm_source)
* [AI Safety + Cybersecurity R\&D Tracker – Fairly AI](https://www.fairly.ai/blog/ai-cybersecurity-tracker)
* [Anthropic makes 'jailbreak' advance to stop AI models producing harmful results](https://www.ft.com/content/cf11ebd8-aa0b-4ed4-945b-a5d4401d186e)
* [Pattern matching filter rules - IBM](https://www.ibm.com/docs/ssw_aix_71/security/intrusion_pattern_matching_filter_rules.html)
* [Real-time Threat Detection](https://www.darktrace.com/cyber-ai-glossary/real-time-threat-detection)

