# اعتبارسنجی ورود داده‌های کاربر C2

## هدف کنترل

اعتبارسنجی قوی ورودی کاربران نخستین خط دفاع در برابر برخی از مخرب‌ترین حملات به سیستم‌های هوش مصنوعی است. حملات تزریق فرمان می‌توانند دستورالعمل‌های سیستم را بازنویسی کنند، داده‌های حساس را افشا کنند، یا مدل را به سمت رفتاری هدایت کنند که مجاز نیست. مگر اینکه فیلترهای ویژه و سلسله‌مراتب دستورالعمل‌ها برقرار شده باشند، تحقیقات نشان می‌دهد که «دورهای چندگانه» فرار از محدودیت که از پنجره‌های متن بسیار طولانی بهره می‌برند مؤثر خواهند بود. همچنین، حملات تغییرات ظریف متخاصم—مانند جابجایی حروف مشابه (homoglyph) یا گفتار رمزآمیز (leetspeak)—می‌توانند به طور بی‌صدا تصمیمات مدل را تغییر دهند.

---

## C2.1 دفاع در برابر تزریق پرامپت

تزریق پرامپت یکی از بزرگ‌ترین ریسک‌ها برای سیستم‌های هوش مصنوعی است. دفاع در برابر این تاکتیک از ترکیبی از فیلترهای الگوهای ایستا، دسته‌بندهای پویا و اجرای سلسله‌مراتبی دستورات استفاده می‌کند.

|   #   | توضیحات                                                                                                                                                                                                                              | سطح | نقش |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :-: | :-: |
| 2.1.1 | بررسی کنید که ورودی‌های کاربر در برابر یک کتابخانه به‌روز شده مداوم از الگوهای شناخته شده تزریق پرامپت (کلیدواژه‌های فرار از محدودیت، "نادیده گرفتن قبل"، زنجیره‌های نقش‌آفرینی، حملات غیرمستقیم HTML/URL) مورد بررسی قرار می‌گیرند. |  1  | D/V |
| 2.1.2 | تأیید کنید که سیستم سلسله‌مراتب دستورات را به‌گونه‌ای اعمال می‌کند که پیام‌های سیستم یا توسعه‌دهنده، دستورات کاربر را تحت‌الشعاع قرار می‌دهند، حتی پس از گسترش پنجره‌ی زمینه.                                                        |  1  | D/V |
| 2.1.3 | اطمینان حاصل کنید که ارزیابی‌های خصمانه (مثلاً درخواست‌های "تعداد زیاد" تیم قرمز) قبل از هر انتشار مدل یا قالب درخواست اجرا می‌شوند، با حد آستانه نرخ موفقیت و موانع خودکار برای برگشت‌ها.                                           |  2  | D/V |
| 2.1.4 | اطمینان حاصل کنید که پرامپت‌هایی که از محتوای شخص ثالث (صفحات وب، فایل‌های PDF، ایمیل‌ها) منشأ می‌گیرند، در یک زمینه تحلیل جداگانه پاک‌سازی شده باشند قبل از اینکه به پرامپت اصلی افزوده شوند.                                       |  2  |  D  |
| 2.1.5 | اطمینان حاصل کنید که همه به‌روزرسانی‌های قوانین فیلتر پرامپت، نسخه‌های مدل طبقه‌بندی‌کننده و تغییرات فهرست مسدود شده تحت کنترل نسخه بوده و قابل حسابرسی باشند.                                                                       |  3  | D/V |

---

## C2.2 مقاومت در برابر نمونه‌های خصمانه

مدل‌های پردازش زبان طبیعی (NLP) همچنان در برابر اختلالات ظریف در سطح کاراکتر یا کلمه آسیب‌پذیر هستند که انسان‌ها اغلب آن‌ها را تشخیص نمی‌دهند اما مدل‌ها معمولاً اشتباه طبقه‌بندی می‌کنند.

|   #   | توضیحات                                                                                                                                                                                   | سطح | نقش |
| :---: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.2.1 | اطمینان حاصل کنید که مراحل پایه نرمال‌سازی ورودی (Unicode NFC، نقشه‌برداری هم‌ریخت‌ها، حذف فاصله‌های اضافی) قبل از بخش‌بندی به توکن اجرا شوند.                                            |  1  |  D  |
| 2.2.2 | تأیید کنید که تشخیص ناهنجاری‌های آماری ورودی‌هایی را که فاصله ویرایشی غیرمعمول بالا نسبت به قواعد زبان، تکرار بیش از حد توکن‌ها، یا فاصله‌های تعبیه‌ای غیرعادی دارند، علامت‌گذاری می‌کند. |  2  | D/V |
| 2.2.3 | بررسی کنید که خط لوله استنتاج از نسخه‌های مدل تقویت‌شده با آموزش مقابله‌ای اختیاری یا لایه‌های دفاعی (مانند تصادفی‌سازی، تقطیر دفاعی) برای نقاط انتهایی با ریسک بالا پشتیبانی می‌کند.     |  2  |  D  |
| 2.2.4 | اطمینان حاصل کنید که ورودی‌های مشکوک به حمله دشمنی قرنطینه شده و با کل بار اطلاعاتی (پس از حذف داده‌های شناسایی شخصی) ثبت می‌شوند.                                                        |  2  |  V  |
| 2.2.5 | اطمینان حاصل کنید که معیارهای مقاومت (نرخ موفقیت مجموعه‌های حمله شناخته‌شده) به مرور زمان رصد می‌شوند و کاهش عملکرد باعث ایجاد مانع در انتشار نسخه می‌شود.                                |  3  | D/V |

---

## اعتبارسنجی طرح‌واره، نوع و طول C2.3

حملات هوش مصنوعی با ورودی‌های نادرست یا بیش از حد بزرگ می‌توانند باعث خطاهای تجزیه، انتشار درخواست‌ها در بین فیلدها و خستگی منابع شوند. اجرای دقیق اسکیمای داده نیز پیش‌نیازی ضروری هنگام انجام فراخوانی‌های ابزار قطعی است.

|   #   | توضیحات                                                                                                                                                                            | سطح | نقش |
| :---: | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.3.1 | اطمینان حاصل کنید که هر نقطه پایانی تماس با API یا تابع، یک طرح ورودی صریح (JSON Schema، Protobuf یا معادل چند حالته) تعریف می‌کند و ورودی‌ها قبل از ساخت پرسش اعتبارسنجی می‌شوند. |  1  |  D  |
| 2.3.2 | اطمینان حاصل کنید که ورودی‌هایی که از حداکثر محدودیت‌های توکن یا بایت فراتر می‌روند، با یک خطای ایمن رد می‌شوند و هرگز به‌صورت ناگهانی کوتاه نمی‌شوند.                             |  1  | D/V |
| 2.3.3 | اطمینان حاصل کنید که بررسی‌های نوع (مانند دامنه‌های عددی، مقادیر enum، نوع MIME برای تصاویر/صوت) در سمت سرور اعمال می‌شوند و تنها در کد کلاینت نیستند.                             |  2  | D/V |
| 2.3.4 | تأیید کنید که اعتبارسنج‌های معنایی (مانند JSON Schema) در زمان ثابت اجرا می‌شوند تا از حملات DoS الگوریتمی جلوگیری شود.                                                            |  2  |  D  |
| 2.3.5 | اطمینان حاصل کنید که خطاهای اعتبارسنجی با بخش‌هایی از بار داده حذف‌شده و کدهای خطای بدون ابهام ثبت می‌شوند تا در بررسی امنیتی کمک کنند.                                            |  3  |  V  |

---

## C2.4 غربالگری محتوا و سیاست‌ها

توسعه‌دهندگان باید قادر باشند درخواست‌های دستوری معتبر که محتوای غیراز مجاز (مانند دستورالعمل‌های غیرقانونی، سخنان نفرت‌پراکنانه، و متن‌های دارای حق نشر) را می‌خواهند شناسایی کنند و سپس از انتشار آن‌ها جلوگیری نمایند.

|   #   | توضیحات                                                                                                                                                                                             | سطح | نقش |
| :---: | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.4.1 | تأیید کنید که یک طبقه‌بندی‌کننده محتوا (بدون آموزش قبلی یا با آموزش دقیق شده) هر ورودی را برای خشونت، خودآسیبی، نفرت، محتوای جنسی و درخواست‌های غیرقانونی ارزیابی می‌کند، با آستانه‌های قابل تنظیم. |  1  |  D  |
| 2.4.2 | تأیید کنید که ورودی‌هایی که قوانین را نقض می‌کنند، پاسخ‌های استاندارد شده یا تکمیل‌های ایمن دریافت کنند تا این ورودی‌ها به فراخوانی‌های بعدی مدل‌های زبان بزرگ منتقل نشوند.                         |  1  | D/V |
| 2.4.3 | تأیید کنید که مدل غربالگری یا مجموعه قوانین حداقل هر سه ماه یکبار بازآموزی/به‌روزرسانی می‌شود و الگوهای جدید مشاهده‌شده فرار از محدودیت یا دور زدن سیاست‌ها در آن گنجانده شده است.                  |  2  |  D  |
| 2.4.4 | اطمینان حاصل کنید که غربالگری قوانین مخصوص به کاربر (سن، محدودیت‌های قانونی منطقه‌ای) را از طریق قواعد مبتنی بر ویژگی که در زمان درخواست حل می‌شوند، رعایت می‌کند.                                  |  2  |  D  |
| 2.4.5 | اطمینان حاصل کنید که لاگ‌های غربالگری شامل نمرات اطمینان طبقه‌بندی‌کننده و برچسب‌های دسته‌بندی سیاست برای همبستگی SOC و بازپخش تیم قرمز آینده باشد.                                                 |  3  |  V  |

---

## محدود کردن نرخ ورودی C2.5 و جلوگیری از سوءاستفاده

توسعه‌دهندگان باید با محدود کردن نرخ ورودی‌ها و شناسایی الگوهای استفاده غیرطبیعی، از سوءاستفاده، خستگی منابع و حملات خودکار علیه سیستم‌های هوش مصنوعی جلوگیری کنند.

|   #   | توضیحات                                                                                                                                                    | سطح | نقش |
| :---: | ---------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.5.1 | اطمینان حاصل کنید که محدودیت‌های نرخ برای هر کاربر، هر آی‌پی و هر کلید API برای همه نقطه‌های ورودی اجرا می‌شوند.                                           |  1  | D/V |
| 2.5.2 | تأیید کنید که محدودیت‌های نرخ انفجاری و پایدار به گونه‌ای تنظیم شده‌اند که از حملات انکار سرویس (DoS) و حملات جستجوی بی‌رحمانه (brute force) جلوگیری کنند. |  2  | D/V |
| 2.5.3 | اطمینان حاصل کنید که الگوهای استفاده ناهنجار (مانند درخواست‌های سریع و پیاپی، سیل ورودی) منجر به مسدودسازی خودکار یا افزایش سطح اقدامات شود.               |  2  | D/V |
| 2.5.4 | تأیید کنید که لاگ‌های پیشگیری از سوءاستفاده نگهداری شده و برای الگوهای حمله نوظهور بررسی می‌شوند.                                                          |  3  |  V  |

---

## C2.6 اعتبارسنجی ورودی چندرسانه‌ای

سیستم‌های هوش مصنوعی باید شامل اعتبارسنجی قوی برای ورودی‌های غیر متنی (تصاویر، صدا، فایل‌ها) باشند تا از تزریق، دور زدن یا سوءاستفاده از منابع جلوگیری کنند.

|   #   | توضیحات                                                                                                                    | سطح | نقش |
| :---: | -------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.6.1 | تأیید کنید که تمام ورودی‌های غیر متنی (تصاویر، صوت، فایل‌ها) از نظر نوع، اندازه و فرمت قبل از پردازش اعتبارسنجی شده باشند. |  1  |  D  |
| 2.6.2 | تأیید کنید که فایل‌ها قبل از ورود برای بدافزار و بارهای نهان‌نگاری شده اسکن می‌شوند.                                       |  2  | D/V |
| 2.6.3 | اطمینان حاصل کنید که ورودی‌های تصویر/صدا برای اختلالات متخاصم یا الگوهای حمله شناخته شده بررسی شده‌اند.                    |  2  | D/V |
| 2.6.4 | اطمینان حاصل کنید که خطاهای اعتبارسنجی ورودی چند‌رسانه‌ای ثبت می‌شوند و هشدارهایی را برای بررسی ایجاد می‌کنند.             |  3  |  V  |

---

## C2.7 منشأ ورودی و انتساب

سیستم‌های هوش مصنوعی باید با پایش و برچسب‌گذاری مبدا تمام ورودی‌های کاربران، از حسابرسی، ردیابی سوءاستفاده و انطباق پشتیبانی کنند.

|   #   | توضیحات                                                                                                                                 | سطح | نقش |
| :---: | --------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.7.1 | اطمینان حاصل کنید که تمام ورودی‌های کاربر با فراداده (شناسه کاربر، جلسه، منبع، زمان‌بندی، آدرس IP) در هنگام دریافت برچسب‌گذاری شده‌اند. |  1  | D/V |
| 2.7.2 | تأیید کنید که فراداده‌های منشاء برای تمام ورودی‌های پردازش‌شده حفظ شده و قابل حسابرسی باشند.                                            |  2  | D/V |
| 2.7.3 | اطمینان حاصل کنید که منابع ورودی غیرعادی یا غیرقابل اعتماد شناسایی شده و تحت بررسی دقیق‌تر یا مسدودسازی قرار می‌گیرند.                  |  2  | D/V |

---

## C2.8 شناسایی تهدید تطبیقی بلادرنگ

توسعه‌دهندگان باید از سیستم‌های پیشرفته شناسایی تهدید برای هوش مصنوعی استفاده کنند که به الگوهای حمله جدید سازگار شده و حفاظت به‌موقع با تطبیق الگوهای کامپایل شده را فراهم کنند.

|   #   | توضیحات                                                                                                                                                                                  | سطح | نقش |
| :---: | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.8.1 | تأیید کنید که الگوهای شناسایی تهدید به موتورهای بهینه‌شده‌ی regex کامپایل شده‌اند تا فیلترینگ بلادرنگ با عملکرد بالا و کمترین تأخیر انجام شود.                                           |  1  | D/V |
| 2.8.2 | اطمینان حاصل کنید که سیستم‌های شناسایی تهدید، کتابخانه‌های الگو جداگانه‌ای برای دسته‌های مختلف تهدید (تزریق فرمان، محتوای مضر، داده‌های حساس، دستورات سیستمی) حفظ می‌کنند.               |  1  | D/V |
| 2.8.3 | تأیید کنید که شناسایی تهدید تطبیقی شامل مدل‌های یادگیری ماشین است که حساسیت به تهدید را بر اساس فراوانی حمله و نرخ‌های موفقیت به‌روز می‌کنند.                                            |  2  | D/V |
| 2.8.4 | تأیید کنید که خوراک‌های اطلاعات تهدیدات در زمان واقعی به‌طور خودکار کتابخانه‌های الگو را با امضاهای جدید حمله و شاخص‌های نفوذ (IOCs) به‌روزرسانی می‌کنند.                                |  2  | D/V |
| 2.8.5 | اطمینان حاصل کنید که نرخ خطاهای مثبت کاذب در تشخیص تهدیدها به طور مداوم پایش می‌شوند و ویژگی‌های الگو به صورت خودکار تنظیم می‌شوند تا حداقل تداخل با موارد استفاده مشروع را داشته باشند. |  3  | D/V |
| 2.8.6 | تأیید کنید که تحلیل تهدید متنی، منبع ورودی، الگوهای رفتار کاربر و سابقه جلسه را برای بهبود دقت شناسایی در نظر می‌گیرد.                                                                   |  3  | D/V |
| 2.8.7 | تأیید کنید که معیارهای عملکرد تشخیص تهدید (نرخ شناسایی، تأخیر پردازش، استفاده از منابع) به صورت بلادرنگ پایش و بهینه می‌شوند.                                                            |  3  | D/V |

---

## C2.9 خط لوله اعتبارسنجی امنیت چندوجهی

توسعه‌دهندگان باید اعتبارسنجی امنیتی برای متن، تصویر، صوت و سایر روش‌های ورودی هوش مصنوعی را با انواع خاصی از تشخیص تهدید و جداسازی منابع ارائه دهند.

|   #   | توضیحات                                                                                                                                                                                                                                                  | سطح | نقش |
| :---: | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.9.1 | اطمینان حاصل کنید که هر حالت ورودی دارای اعتبارسنج‌های امنیتی اختصاصی با الگوهای تهدید مستند شده (متن: تزریق پرامپت، تصاویر: استگانوگرافی، صوت: حملات اسپکتروگرام) و آستانه‌های تشخیص باشد.                                                              |  1  | D/V |
| 2.9.2 | تأیید کنید که ورودی‌های چندرسانه‌ای در محیط‌های جداگانه با محدودیت‌های منابع تعریف شده (حافظه، واحد پردازش مرکزی، زمان پردازش) که مختص هر نوع حالت چندرسانه‌ای هستند، پردازش می‌شوند و این موارد در سیاست‌های امنیتی مستند شده‌اند.                      |  2  | D/V |
| 2.9.3 | تأیید کنید که تشخیص حملات میان‌مدلی، حملات هماهنگ شده‌ای که چندین نوع ورودی را در بر می‌گیرند (مثلاً بارگذاری‌های استگانوگرافیک در تصاویر همراه با تزریق فرمان در متن) با استفاده از قوانین همبستگی و تولید هشدار شناسایی می‌کند.                        |  2  | D/V |
| 2.9.4 | تأیید کنید که خطاهای اعتبارسنجی چندمدلی باعث فعال شدن ثبت گزارش‌های دقیق شامل تمامی حالت‌های ورودی، نتایج اعتبارسنجی، امتیازهای تهدید، و تحلیل همبستگی با فرمت‌های ثبت ساختاریافته برای یکپارچه‌سازی با SIEM شوند.                                       |  3  | D/V |
| 2.9.5 | اطمینان حاصل کنید که طبقه‌بندهای محتوای مربوط به مدالیته خاص طبق برنامه‌های مستند شده (حداقل به صورت سه‌ماهه) با الگوهای جدید تهدید، نمونه‌های خصمانه و معیارهای عملکردی به‌روزرسانی شده‌اند و عملکرد آن‌ها بالاتر از آستانه‌های پایه نگه داشته شده است. |  3  | D/V |

---

## مراجع

* [LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security](https://genai.owasp.org/llmrisk/llm01-prompt-injection/)
* [Generative AI's Biggest Security Flaw Is Not Easy to Fix](https://www.wired.com/story/generative-ai-prompt-injection-hacking)
* [Many-shot jailbreaking \ Anthropic](https://www.anthropic.com/research/many-shot-jailbreaking)
* [$PDF$ OpenAI GPT-4.5 System Card](https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf)
* [Notebook for the CheckThat Lab at CLEF 2024](https://ceur-ws.org/Vol-3740/paper-53.pdf)
* [Mitigate jailbreaks and prompt injections – Anthropic](https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks)
* [Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis](https://ama.drwhy.ai/mitre-attck.html)
* [OWASP Top 10 for LLM Applications 2025 – WorldTech IT](https://wtit.com/blog/2025/04/17/owasp-top-10-for-llm-applications-2025/)
* [OWASP Machine Learning Security Top Ten](https://owasp.org/www-project-machine-learning-security-top-10/)
* [Few words about AI Security – Jussi Metso](https://www.jussimetso.com/index.php/2024/09/28/few-words-about-ai-security/)
* [How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry](https://modelmetry.com/blog/how-to-ensure-llm-output-adheres-to-a-json-schema)
* [Easily enforcing valid JSON schema following – API](https://community.openai.com/t/feature-request-function-calling-easily-enforcing-valid-json-schema-following/263515?utm_source)
* [AI Safety + Cybersecurity R\&D Tracker – Fairly AI](https://www.fairly.ai/blog/ai-cybersecurity-tracker)
* [Anthropic makes 'jailbreak' advance to stop AI models producing harmful results](https://www.ft.com/content/cf11ebd8-aa0b-4ed4-945b-a5d4401d186e)
* [Pattern matching filter rules - IBM](https://www.ibm.com/docs/ssw_aix_71/security/intrusion_pattern_matching_filter_rules.html)
* [Real-time Threat Detection](https://www.darktrace.com/cyber-ai-glossary/real-time-threat-detection)

