# اعتبارسنجی ورودی کاربر C2

## هدف کنترل

اعتبارسنجی قوی ورودی کاربر دفاع خط اول در برابر برخی از آسیب‌زننده‌ترین حملات به سیستم‌های هوش مصنوعی است. حملات تزریق پرامپت می‌توانند دستورالعمل‌های سیستم را لغو کنند، داده‌های حساس را لو دهند، یا مدل را به سمتی سوق دهند که رفتار غیرمجاز داشته باشد. مگر اینکه فیلترها و سلسله مراتب دستوری اختصاصی وجود داشته باشند، تحقیقات نشان می‌دهد که "جیل‌بریک‌های چند-شات" که از پنجره‌های متنی بسیار طولانی بهره می‌برند، موثر خواهند بود. همچنین، حملات تغییرات ظریف خصمانه—مانند جابه‌جایی همولوگلیف‌ها یا زبان لیت—می‌توانند به‌صورت پنهانی تصمیمات مدل را تغییر دهند.

---

## دفاع در برابر تزریق دستورات C2.1

تزریق پرامپت یکی از بزرگ‌ترین ریسک‌ها برای سیستم‌های هوش مصنوعی است. تدابیر دفاعی در برابر این تاکتیک از ترکیبی از فیلترهای الگوی ایستا، دسته‌بندی‌کننده‌های پویا و اعمال سلسله‌مراتب دستورات استفاده می‌کنند.

|   #   | توضیحات                                                                                                                                                                                                                               | سطح | نقش |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.1.1 | اطمینان حاصل کنید که ورودی‌های کاربر در برابر یک کتابخانه به‌روزرسانی‌شده و مداوم از الگوهای شناخته شده تزریق دستور (کلیدواژه‌های فرار از محدودیت، "نادیده گرفتن قبلی"، زنجیره‌های نقش‌بازی، حملات غیرمستقیم HTML/URL) بررسی می‌شوند. |  1  | D/V |
| 2.1.2 | اطمینان حاصل کنید که سیستم سلسله‌مراتب دستورات را اعمال می‌کند به گونه‌ای که پیام‌های سیستم یا توسعه‌دهنده، دستورات کاربر را نقض می‌کنند، حتی پس از افزایش پنجره زمینه.                                                               |  1  | D/V |
| 2.1.3 | تأیید کنید که آزمون‌های ارزیابی خصمانه (مانند پرسش‌های «چند-نمونه‌ای» تیم قرمز) قبل از هر انتشار مدل یا قالب پرسش اجرا می‌شوند، با تعیین حد آستانه نرخ موفقیت و موانع خودکار برای افت کیفیت.                                          |  2  | D/V |
| 2.1.4 | اطمینان حاصل کنید که پرامپت‌های منشأ گرفته از محتوای شخص ثالث (صفحات وب، فایل‌های PDF، ایمیل‌ها) در یک زمینه تجزیه جداگانه پاک‌سازی شده‌اند قبل از آن که به پرامپت اصلی الحاق شوند.                                                   |  2  |  D  |
| 2.1.5 | اطمینان حاصل کنید که تمام به‌روزرسانی‌های قوانین فیلتر پرامپت، نسخه‌های مدل دسته‌بندی‌کننده و تغییرات فهرست مسدودسازی کنترل نسخه شده و قابل حسابرسی باشند.                                                                            |  3  | D/V |

---

## C2.2 مقاومت در برابر نمونه‌های خصمانه

مدل‌های پردازش زبان طبیعی (NLP) همچنان در برابر تغییرات جزئی در سطح نویسه یا کلمه که معمولاً برای انسان‌ها قابل تشخیص نیست اما مدل‌ها اغلب این تغییرات را به اشتباه طبقه‌بندی می‌کنند، آسیب‌پذیر هستند.

|   #   | توضیحات                                                                                                                                                                                             | سطح | نقش |
| :---: | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.2.1 | اطمینان حاصل کنید که مراحل پایه نرمال‌سازی ورودی (Unicode NFC، نگاشت هوموگلیف، حذف فضای اضافی) قبل از توکنیزه‌سازی اجرا می‌شوند.                                                                    |  1  |  D  |
| 2.2.2 | اطمینان حاصل کنید که شناسایی ناهنجاری‌های آماری ورودی‌هایی را که فاصله ویرایشی غیرمعمول بالا نسبت به هنجارهای زبانی، تکرار بیش از حد توکن‌ها، یا فاصله‌های تعبیه غیرعادی دارند، علامت‌گذاری می‌کند. |  2  | D/V |
| 2.2.3 | تأیید کنید که خط لوله استنتاج از نمونه‌های مدل مقاوم‌شده با آموزش مقابله‌ای اختیاری یا لایه‌های دفاعی (مثلاً، رندوم‌سازی، تقطیر دفاعی) برای نقاط پایانی با ریسک بالا پشتیبانی می‌کند.               |  2  |  D  |
| 2.2.4 | تأیید کنید که ورودی‌های مشکوک به حملات مخرب قرنطینه شده و با کل بار داده (پس از حذف اطلاعات شناسایی شخصی) ثبت می‌شوند.                                                                              |  2  |  V  |
| 2.2.5 | اطمینان حاصل کنید که معیارهای استحکام (نرخ موفقیت مجموعه‌های حمله شناخته شده) به مرور زمان پیگیری می‌شوند و بازگشت‌ها باعث ایجاد مانع برای انتشار می‌شوند.                                          |  3  | D/V |

---

## C2.3 اعتبارسنجی طرح‌واره، نوع و طول

حملات هوش مصنوعی که شامل ورودی‌های ناقص یا بیش‌ازحد بزرگ هستند می‌توانند باعث خطاهای تجزیه، نشت داده در بین فیلدها و خستگی منابع شوند. همچنین، اعمال دقیق الزامات ساختار داده‌ها (schema) پیش‌نیاز انجام فراخوانی‌های قطعی ابزار است.

|   #   | توضیحات                                                                                                                                                                                     | سطح | نقش |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.3.1 | اطمینان حاصل کنید که هر نقطه پایانی فراخوانی API یا تابع، یک طرح ورودی صریح (JSON Schema، Protobuf یا معادل چندرسانه‌ای) را تعریف کرده و ورودی‌ها قبل از مونتاژ درخواست اعتبارسنجی شده‌اند. |  1  |  D  |
| 2.3.2 | تأیید کنید که ورودی‌هایی که از حد مجاز توکن یا بایت فراتر می‌روند، با یک خطای ایمن رد شده و هرگز به‌طور خاموش کوتاه نشده باشند.                                                             |  1  | D/V |
| 2.3.3 | اطمینان حاصل کنید که چک‌های نوع (مثلاً بازه‌های عددی، مقادیر enum، نوع MIME برای تصاویر/صوت) در سمت سرور اجرا می‌شوند و نه تنها در کد کلاینت.                                               |  2  | D/V |
| 2.3.4 | تأیید کنید که اعتبارسنج‌های معنایی (مثلاً JSON Schema) در زمان ثابت اجرا می‌شوند تا از حملات محروم‌سازی سرویس الگوریتمی جلوگیری شود.                                                        |  2  |  D  |
| 2.3.5 | اطمینان حاصل کنید که خطاهای اعتبارسنجی با قطعات بار مفید مخفی شده و کدهای خطای بدون ابهام ثبت می‌شوند تا به تشخیص امنیتی کمک کند.                                                           |  3  |  V  |

---

## C2.4 بررسی محتوا و سیاست‌ها

توسعه‌دهندگان باید قادر باشند تا درخواست‌های دارای ساختار نحوی صحیح که محتوای غیرمجاز (مانند دستورالعمل‌های غیرقانونی، سخنان نفرت‌پراکنی و متن‌های دارای حق کپی‌رایت) را درخواست می‌کنند، شناسایی کرده و سپس از انتشار آن‌ها جلوگیری کنند.

|   #   | توضیحات                                                                                                                                                                                                       | سطح | نقش |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.4.1 | اطمینان حاصل کنید که یک طبقه‌بندی‌کننده محتوا (بدون آموزش قبلی یا با آموزش دقیق) هر ورودی را برای خشونت، خودآسیبی، نفرت، محتوای جنسی و درخواست‌های غیرقانونی ارزیابی می‌کند، با آستانه‌های قابل تنظیم.        |  1  |  D  |
| 2.4.2 | اطمینان حاصل کنید که ورودی‌هایی که سیاست‌ها را نقض می‌کنند، پاسخ‌های استاندارد شده رد یا تکمیل ایمن دریافت می‌کنند تا به تماس‌های بعدی با مدل‌های زبان بزرگ منتقل نشوند.                                      |  1  | D/V |
| 2.4.3 | اطمینان حاصل کنید که مدل غربالگری یا مجموعه قواعد حداقل هر سه ماه یکبار مجدداً آموزش دیده یا به‌روزرسانی می‌شود، به‌طوری که الگوهای جدید مشاهده شده از دورزدن محدودیت‌ها یا نقض سیاست‌ها در آن لحاظ شده باشد. |  2  |  D  |
| 2.4.4 | اطمینان حاصل کنید که غربالگری قوانین خاص کاربر (سن، محدودیت‌های قانونی منطقه‌ای) را از طریق قوانین مبتنی بر ویژگی که در زمان درخواست حل می‌شوند، رعایت می‌کند.                                                |  2  |  D  |
| 2.4.5 | تأیید کنید که لاگ‌های غربالگری شامل امتیازهای اطمینان کلاس‌بندی و برچسب‌های دسته‌بندی سیاست برای همبستگی SOC و بازپخش تیم قرمز آینده باشد.                                                                    |  3  |  V  |

---

## محدودسازی نرخ ورودی C2.5 و پیشگیری از سوء استفاده

توسعه‌دهندگان باید با محدود کردن نرخ ورودی و شناسایی الگوهای استفاده غیرمعمول، از سوءاستفاده، خستگی منابع و حملات خودکار علیه سیستم‌های هوش مصنوعی جلوگیری کنند.

|   #   | توضیحات                                                                                                                                                            | سطح | نقش |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :-: | :-: |
| 2.5.1 | تأیید کنید که محدودیت‌های نرخ بر اساس هر کاربر، هر آی‌پی و هر کلید API برای همه نقاط پایانی ورودی اجرا شده‌اند.                                                    |  1  | D/V |
| 2.5.2 | تأیید کنید که محدودیت‌های نرخ انفجاری و پایدار به‌گونه‌ای تنظیم شده‌اند که از حملات عدم سرویس (DoS) و تلاش‌های رمزگشایی اجباری جلوگیری کنند.                       |  2  | D/V |
| 2.5.3 | اطمینان حاصل کنید که الگوهای استفاده غیرمعمول (مثلاً درخواست‌های سریع پشت سر هم، ارسال انبوه ورودی) باعث فعال شدن مسدودسازی‌های خودکار یا ارتقاهای امنیتی می‌شوند. |  2  | D/V |
| 2.5.4 | تأیید کنید که گزارش‌های پیشگیری از سوءاستفاده حفظ و برای شناسایی الگوهای حمله نوظهور بررسی می‌شوند.                                                                |  3  |  V  |

---

## C2.6 اعتبارسنجی ورودی چندحالته

سیستم‌های هوش مصنوعی باید اعتبارسنجی قوی برای ورودی‌های غیر متنی (تصاویر، صدا، فایل‌ها) شامل شوند تا از تزریق، دورزدن یا سوءاستفاده از منابع جلوگیری شود.

|   #   | توضیحات                                                                                                                   | سطح | نقش |
| :---: | ------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.6.1 | اطمینان حاصل کنید که تمام ورودی‌های غیر متنی (تصاویر، صداها، فایل‌ها) قبل از پردازش از نظر نوع، اندازه و فرمت تأیید شوند. |  1  |  D  |
| 2.6.2 | اطمینان حاصل کنید که فایل‌ها قبل از ورود، برای بدافزارها و بارهای پنهان استگانوگرافیک اسکن شده‌اند.                       |  2  | D/V |
| 2.6.3 | اطمینان حاصل کنید که ورودی‌های تصویر/صدا برای آشفتگی‌های مخرب یا الگوهای حمله شناخته شده بررسی می‌شوند.                   |  2  | D/V |
| 2.6.4 | تأیید کنید که خطاهای صحت‌سنجی ورودی چندوجهی ثبت شده و هشدارهایی برای بررسی ایجاد می‌کنند.                                 |  3  |  V  |

---

## C2.7 منبع ورودی و نسبت‌دهی

سیستم‌های هوش مصنوعی باید با نظارت و برچسب‌گذاری منابع تمامی ورودی‌های کاربران، از حسابرسی، ردیابی سوءاستفاده و انطباق پشتیبانی کنند.

|   #   | توضیحات                                                                                                                             | سطح | نقش |
| :---: | ----------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.7.1 | اطمینان حاصل کنید که تمام ورودی‌های کاربر هنگام دریافت با متادیتا (شناسه کاربر، جلسه، منبع، زمان ثبت، آدرس IP) برچسب‌گذاری شده‌اند. |  1  | D/V |
| 2.7.2 | تأیید کنید که داده‌های متادیتای منشأ برای همه ورودی‌های پردازش شده حفظ شده و قابل حسابرسی باشد.                                     |  2  | D/V |
| 2.7.3 | اطمینان حاصل کنید که منابع ورودی غیرعادی یا غیرقابل اعتماد علامت‌گذاری شده و تحت بررسی دقیق‌تر یا مسدودسازی قرار گیرند.             |  2  | D/V |

---

## C2.8 تشخیص تهدید تطبیقی در زمان واقعی

توسعه‌دهندگان باید از سیستم‌های پیشرفته شناسایی تهدید برای هوش مصنوعی استفاده کنند که به الگوهای جدید حمله سازگار شده و حفاظت بلادرنگ با تطبیق الگوهای کامپایل شده را فراهم کنند.

|   #   | توضیحات                                                                                                                                                                       | سطح | نقش |
| :---: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| 2.8.1 | تأیید کنید که الگوهای شناسایی تهدید به موتورهای منظم بهینه شده تبدیل شده‌اند تا برای فیلتر کردن در زمان واقعی با عملکرد بالا و حداقل تأثیر بر تأخیر استفاده شوند.             |  1  | D/V |
| 2.8.2 | اطمینان حاصل کنید که سیستم‌های شناسایی تهدید کتابخانه‌های الگو جداگانه‌ای برای دسته‌های مختلف تهدید (تزریق دستور، محتوای مضر، داده‌های حساس، دستورهای سیستم) نگهداری می‌کنند. |  1  | D/V |
| 2.8.3 | تأیید کنید که تشخیص تهدید تطبیقی شامل مدل‌های یادگیری ماشین است که حساسیت تهدید را بر اساس فراوانی حمله و نرخ موفقیت به‌روزرسانی می‌کنند.                                     |  2  | D/V |
| 2.8.4 | تأیید کنید که منابع اطلاعات تهدید زمان واقعی به‌طور خودکار کتابخانه‌های الگو را با امضاهای جدید حمله و شاخص‌های نفوذ (IOCs) به‌روزرسانی می‌کنند.                              |  2  | D/V |
| 2.8.5 | اطمینان حاصل کنید که نرخ‌های مثبت کاذب در تشخیص تهدید به طور مداوم نظارت می‌شوند و ویژگی‌های الگو به‌صورت خودکار تنظیم می‌شوند تا تداخل با موارد استفاده مشروع حداقل شود.     |  3  | D/V |
| 2.8.6 | تأیید کنید که تحلیل تهدید متنی منبع ورودی، الگوهای رفتار کاربر و سابقه جلسه را برای بهبود دقت تشخیص در نظر می‌گیرد.                                                           |  3  | D/V |
| 2.8.7 | تأیید کنید که معیارهای عملکرد تشخیص تهدید (نرخ تشخیص، تأخیر پردازش، بهره‌وری منابع) به‌صورت بلادرنگ پایش و بهینه‌سازی می‌شوند.                                                |  3  | D/V |

---

## C2.9 خط لوله اعتبارسنجی امنیت چندرسانه‌ای

توسعه‌دهندگان باید اعتبارسنجی امنیتی را برای ورودی‌های متنی، تصویری، صوتی و سایر حالت‌های ورودی هوش مصنوعی با استفاده از نوع‌های خاصی از شناسایی تهدید و جداسازی منابع ارائه دهند.

|   #   | توضیحات                                                                                                                                                                                                                              | سطح | نقش |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :-: | :-: |
| 2.9.1 | اطمینان حاصل کنید که هر حالت ورودی دارای اعتبارسنج‌های امنیتی اختصاصی با الگوهای تهدید مستندسازی شده (متن: تزریق پرامپت، تصاویر: استگانوگرافی، صوت: حملات اسپکتروگرام) و آستانه‌های شناسایی است.                                     |  1  | D/V |
| 2.9.2 | بررسی کنید که ورودی‌های چندوجهی در محیط‌های ایزوله شده با محدودیت‌های منابع مشخص (حافظه، CPU، زمان پردازش) که به هر نوع حالت چندوجهی اختصاص داده شده‌اند، پردازش می‌شوند و این موارد در سیاست‌های امنیتی مستند شده‌اند.              |  2  | D/V |
| 2.9.3 | تأیید کنید که شناسایی حملات چندرسانه‌ای، حملات هماهنگ‌شده‌ای که چندین نوع ورودی را شامل می‌شوند (مانند بارهای مخفی استگانوگرافیک در تصاویر همراه با تزریق فرمان در متن) را با استفاده از قواعد همبستگی و تولید هشدار شناسایی می‌کند. |  2  | D/V |
| 2.9.4 | تأیید کنید که خطاهای اعتبارسنجی چند modality باعث ثبت گزارش‌های دقیق می‌شوند که شامل تمام حالت‌های ورودی، نتایج اعتبارسنجی، امتیازهای تهدید و تحلیل همبستگی با فرمت‌های گزارش ساخت‌یافته برای یکپارچه‌سازی با SIEM باشد.             |  3  | D/V |
| 2.9.5 | تأیید کنید که دسته‌بندی‌کننده‌های محتوای خاص هر مدالیت طبق برنامه‌های مستند به‌روزرسانی شده‌اند (حداقل فصلی) با الگوهای تهدید جدید، نمونه‌های خصمانه و معیارهای عملکردی که بالاتر از آستانه‌های پایه نگهداری می‌شوند.                |  3  | D/V |

---

## مراجع

* [LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security](https://genai.owasp.org/llmrisk/llm01-prompt-injection/)
* [Generative AI's Biggest Security Flaw Is Not Easy to Fix](https://www.wired.com/story/generative-ai-prompt-injection-hacking)
* [Many-shot jailbreaking \ Anthropic](https://www.anthropic.com/research/many-shot-jailbreaking)
* [$PDF$ OpenAI GPT-4.5 System Card](https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf)
* [Notebook for the CheckThat Lab at CLEF 2024](https://ceur-ws.org/Vol-3740/paper-53.pdf)
* [Mitigate jailbreaks and prompt injections – Anthropic](https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks)
* [Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis](https://ama.drwhy.ai/mitre-attck.html)
* [OWASP Top 10 for LLM Applications 2025 – WorldTech IT](https://wtit.com/blog/2025/04/17/owasp-top-10-for-llm-applications-2025/)
* [OWASP Machine Learning Security Top Ten](https://owasp.org/www-project-machine-learning-security-top-10/)
* [Few words about AI Security – Jussi Metso](https://www.jussimetso.com/index.php/2024/09/28/few-words-about-ai-security/)
* [How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry](https://modelmetry.com/blog/how-to-ensure-llm-output-adheres-to-a-json-schema)
* [Easily enforcing valid JSON schema following – API](https://community.openai.com/t/feature-request-function-calling-easily-enforcing-valid-json-schema-following/263515?utm_source)
* [AI Safety + Cybersecurity R\&D Tracker – Fairly AI](https://www.fairly.ai/blog/ai-cybersecurity-tracker)
* [Anthropic makes 'jailbreak' advance to stop AI models producing harmful results](https://www.ft.com/content/cf11ebd8-aa0b-4ed4-945b-a5d4401d186e)
* [Pattern matching filter rules - IBM](https://www.ibm.com/docs/ssw_aix_71/security/intrusion_pattern_matching_filter_rules.html)
* [Real-time Threat Detection](https://www.darktrace.com/cyber-ai-glossary/real-time-threat-detection)

