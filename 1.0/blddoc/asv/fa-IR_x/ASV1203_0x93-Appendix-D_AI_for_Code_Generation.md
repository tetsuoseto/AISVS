# پیوست D: حاکمیت و تأیید کدگذاری ایمن با کمک هوش مصنوعی

## هدف

این فصل کنترل‌های سازمانی پایه را برای استفاده ایمن و مؤثر از ابزارهای کدنویسی کمکی هوش مصنوعی در طول توسعه نرم‌افزار تعریف می‌کند، به‌گونه‌ای که امنیت و قابلیت ردیابی در سراسر چرخه عمر توسعه نرم‌افزار (SDLC) تضمین شود.

---

## AD.1 جریان کاری کدنویسی امن با کمک هوش مصنوعی

ابزارهای هوش مصنوعی را در چرخه عمر توسعه نرم‌افزار امن سازمان (SSDLC) ادغام کنید بدون اینکه دفاع‌های امنیتی موجود تضعیف شوند.

|   #    | توضیحات                                                                                                                                                                            | سطح | نقش |
| :----: | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| AD.1.1 | تأیید کنید که یک گردش کار مستند شده زمانی و نحوه استفاده از ابزارهای هوش مصنوعی برای تولید، بازسازی یا مرور کد را شرح می‌دهد.                                                      |  1  | D/V |
| AD.1.2 | تأیید کنید که جریان کاری به هر مرحله از SSDLC (طراحی، پیاده‌سازی، بازبینی کد، آزمون، استقرار) نگاشت شود.                                                                           |  2  |  D  |
| AD.1.3 | اطمینان حاصل کنید که معیارها (برای مثال، چگالی آسیب‌پذیری، میانگین زمان شناسایی) بر روی کد تولید شده توسط هوش مصنوعی جمع‌آوری شده و با معیارهای پایه‌ای فقط انسانی مقایسه می‌شوند. |  3  | D/V |

---

## AD.2 صلاحیت ابزار هوش مصنوعی و مدل‌سازی تهدید

اطمینان حاصل شود که ابزارهای کدنویسی هوش مصنوعی قبل از پذیرش، از نظر قابلیت‌های امنیتی، ریسک و تاثیر زنجیره تامین ارزیابی شوند.

|   #    | توضیحات                                                                                                                                          | سطح | نقش |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------ | :-: | :-: |
| AD.2.1 | اطمینان حاصل کنید که مدل تهدید برای هر ابزار هوش مصنوعی، سوءاستفاده، وارونگی مدل، نشت داده و خطرات زنجیره وابستگی را شناسایی می‌کند.             |  1  | D/V |
| AD.2.2 | اطمینان حاصل کنید که ارزیابی‌های ابزار شامل تحلیل ایستا/پویا از هر جزء محلی و ارزیابی نقاط انتهایی SaaS (TLS، تأیید هویت/مجوزدهی، ثبت لاگ) باشد. |  2  |  D  |
| AD.2.3 | اطمینان حاصل کنید که ارزیابی‌ها بر اساس یک چارچوب شناخته شده انجام شده‌اند و پس از تغییرات عمده نسخه مجدداً انجام می‌شوند.                       |  3  | D/V |

---

## AD.3 مدیریت امن درخواست و زمینه

جلوگیری از نشت اسرار، کد اختصاصی و داده‌های شخصی هنگام ساختن پرامپت‌ها یا زمینه‌ها برای مدل‌های هوش مصنوعی.

|   #    | توضیحات                                                                                                                                                             | سطح | نقش |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| AD.3.1 | بررسی کنید که راهنمایی‌های مکتوب ارسال اسرار، مدارک احراز هویت یا داده‌های طبقه‌بندی شده در دستورات را ممنوع کرده باشد.                                             |  1  | D/V |
| AD.3.2 | تأیید کنید که کنترل‌های فنی (حذف اطلاعات حساس در سمت کلاینت، فیلترهای متن تایید شده) به‌صورت خودکار اشیاء حساس را حذف می‌کنند.                                      |  2  |  D  |
| AD.3.3 | اطمینان حاصل کنید که درخواست‌ها و پاسخ‌ها توکنیزه شده، در حین انتقال و در حالت استراحت رمزگذاری شده‌اند و دوره‌های نگهداری با سیاست طبقه‌بندی داده‌ها مطابقت دارند. |  3  | D/V |

---

## AD.4 اعتبارسنجی کد تولید شده توسط هوش مصنوعی

شناسایی و رفع آسیب‌پذیری‌های ایجاد شده توسط خروجی هوش مصنوعی قبل از ادغام یا استقرار کد.

|   #    | توضیحات                                                                                                                                                                                   | سطح | نقش |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| AD.4.1 | تأیید کنید که کد تولید شده توسط هوش مصنوعی همیشه تحت بازبینی کد انسانی قرار می‌گیرد.                                                                                                      |  1  | D/V |
| AD.4.2 | اطمینان حاصل کنید که اسکنرهای خودکار (SAST/IAST/DAST) روی هر درخواست Pull که شامل کد تولید شده توسط هوش مصنوعی است اجرا می‌شوند و ادغام‌ها را در صورت وجود یافته‌های حیاتی مسدود می‌کنند. |  2  |  D  |
| AD.4.3 | اطمینان حاصل کنید که تست‌های فراگیر تفاضلی یا تست‌های مبتنی بر ویژگی، رفتارهای حیاتی امنیتی (مانند اعتبارسنجی ورودی، منطق مجوزدهی) را اثبات می‌کنند.                                      |  3  | D/V |

---

## AD.5 قابلیت توضیح‌پذیری و ردیابی پیشنهادات کد

برای حسابرسان و توسعه‌دهندگان بینش ارائه دهید که چرا یک پیشنهاد ارائه شده است و چگونه تکامل یافته است.

|   #    | توضیحات                                                                                                                                                                           | سطح | نقش |
| :----: | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| AD.5.1 | اطمینان حاصل کنید که جفت‌های پرسش/پاسخ با شناسه‌های تعهد (commit IDs) ثبت می‌شوند.                                                                                                |  1  | D/V |
| AD.5.2 | تأیید کنید که توسعه‌دهندگان قادر به ارائه استنادهای مدل (قطعات آموزشی، مستندات) که پیشنهاد را پشتیبانی می‌کند، باشند.                                                             |  2  |  D  |
| AD.5.3 | اطمینان حاصل کنید که گزارش‌های قابلیت توضیح با مصنوعات طراحی ذخیره شده و در بازبینی‌های امنیتی به آن‌ها ارجاع داده شده‌اند، به‌طوری که اصول ردیابی ISO/IEC 42001 را برآورده کنند. |  3  | D/V |

---

## AD.6 بازخورد مداوم و تنظیم دقیق مدل

عملکرد امنیت مدل را در طول زمان بهبود بخشید و در عین حال از بروز روند منفی جلوگیری کنید.

|   #    | توضیحات                                                                                                                                                                                     | سطح | نقش |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| AD.6.1 | اطمینان حاصل کنید که توسعه‌دهندگان می‌توانند پیشنهادات ناامن یا غیرمطابق را علامت‌گذاری کنند و اینکه این علامت‌ها پیگیری می‌شوند.                                                           |  1  | D/V |
| AD.6.2 | تأیید کنید که بازخورد تجمیع‌شده برای تنظیم دقیق دوره‌ای یا تولید تقویت‌شده با بازیابی با مجموعه‌های کدگذاری امن تأیید شده (به عنوان مثال، دفترچه‌های تقلب OWASP) مورد استفاده قرار می‌گیرد. |  2  |  D  |
| AD.6.3 | اطمینان حاصل کنید که یک هارنس ارزیابی حلقه بسته پس از هر تنظیم دقیق، آزمایش‌های رگرسیون را اجرا می‌کند؛ معیارهای امنیتی باید قبل از استقرار برابر یا بهتر از خطوط پایه قبلی باشند.          |  3  | D/V |

---

### مراجع

* [NIST AI Risk Management Framework 1.0](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [ISO/IEC 42001:2023 — AI Management Systems Requirements](https://www.iso.org/standard/81230.html)
* [OWASP Secure Coding Practices — Quick Reference Guide](https://owasp.org/www-project-secure-coding-practices-quick-reference-guide/)

