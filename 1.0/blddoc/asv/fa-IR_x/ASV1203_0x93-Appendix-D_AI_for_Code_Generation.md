# ضمیمه D: حاکمیت کدنویسی امن با کمک هوش مصنوعی و صحت‌سنجی

## هدف

این فصل کنترل‌های سازمانی پایه را برای استفاده ایمن و مؤثر از ابزارهای کدنویسی AI-assisted در طول توسعه نرم‌افزار تعریف می‌کند و امنیت و قابلیت ردیابی را در سراسر SDLC تضمین می‌کند.

---

## AD.1 جریان کار کدنویسی امن با کمک هوش مصنوعی

ابزارهای هوش مصنوعی را در چرخه توسعه امن نرم‌افزار سازمان (SSDLC) بدون تضعیف دروازه‌های امنیتی موجود یکپارچه کنید.

|   #    | شرح                                                                                                                                                                 | سطح | نقش |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| AD.1.1 | تأیید کنید که یک گردش کار مستند توضیح می‌دهد که ابزارهای هوش مصنوعی چه زمانی و چگونه می‌توانند کد تولید کنند، کد را بازنگری کنند یا کد را بازبینی کنند.             |  1  | D/V |
| AD.1.2 | اطمینان حاصل کنید که جریان کار با هر فاز SSDLC مطابقت دارد (طراحی، پیاده‌سازی، بازبینی کد، تست، استقرار).                                                           |  2  |  D  |
| AD.1.3 | تأیید کنید که معیارها (برای مثال، چگالی آسیب‌پذیری، میانگین زمان تا کشف) برای کد تولیدشده توسط هوش مصنوعی جمع‌آوری می‌شوند و با پایه‌های فقط انسانی مقایسه می‌شوند. |  3  | D/V |

---

## AD.2 صلاحیت ابزار هوش مصنوعی و مدل‌سازی تهدید

اطمینان حاصل کنید که ابزارهای کدنویسی هوش مصنوعی قبل از پذیرش از نظر قابلیت‌های امنیتی، ریسک و تأثیر زنجیره-تامین ارزیابی شوند.

|   #    | شرح                                                                                                                                                | سطح | نقش |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| AD.2.1 | اطمینان حاصل کنید که برای هر ابزار هوش مصنوعی، مدل تهدید، سوء استفاده، معکوس‌سازی مدل، نشت داده‌ها و خطرات زنجیره‑وابستگی را شناسایی می‌کند.       |  1  | D/V |
| AD.2.2 | اطمینان حاصل کنید که ارزیابی‌های ابزار شامل تحلیل ایستا/پویا از هر جزء محلی و ارزیابی نقاط پایانی SaaS (TLS، احراز هویت/مجوزدهی، ثبت لاگ) می‌شوند. |  2  |  D  |
| AD.2.3 | تأیید کنید که ارزیابی‌ها از یک چارچوب شناخته‌شده پیروی می‌کنند و پس از تغییرات نسخهٔ عمده دوباره انجام می‌شوند.                                    |  3  | D/V |

---

## AD.3 مدیریت امن پرامپت و زمینه

جلوگیری از افشای اسرار، کدهای مالکیتی و داده‌های شخصی هنگام ساخت پرامپت‌ها یا زمینه‌های مدل‌های هوش مصنوعی.

|   #    | شرح                                                                                                                                                               | سطح | نقش |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| AD.3.1 | تأیید کنید که راهنمایی‌های مکتوب ارسال اسرار، اعتبارنامه‌ها یا داده‌های طبقه‌بندی‌شده در پرامپت‌ها را منع می‌کند.                                                 |  1  | D/V |
| AD.3.2 | بررسی کن که کنترل‌های فنی (حذف محرمانه در سمت کاربر، فیلترهای زمینه تأییدشده) به‌طور خودکار آثاری حساس را حذف می‌کنند.                                            |  2  |  D  |
| AD.3.3 | اطمینان حاصل کنید که پرومپت‌ها و پاسخ‌ها توکن‌شده‌اند، در حال انتقال و در حالت سکون رمزگذاری می‌شوند، و دوره‌های نگهداری با سیاست-طبقه‌بندی داده‌ها مطابقت دارند. |  3  | D/V |

---

## AD.4 اعتبارسنجی کد تولیدشده توسط هوش مصنوعی

آسیب‌پذیری‌های ناشی از خروجی هوش مصنوعی را قبل از ادغام یا استقرار کد شناسایی و رفع کنید.

|   #    | شرح                                                                                                                                                                                  | سطح | نقش |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :-: | :-: |
| AD.4.1 | تأیید کنید که کد تولیدشده توسط هوش مصنوعی همواره تحت بازبینی کد توسط انسان قرار می‌گیرد.                                                                                             |  1  | D/V |
| AD.4.2 | اطمینان حاصل کنید که اسکنرهای خودکار (SAST/IAST/DAST) در هر درخواست کشش که حاوی کد تولیدشده توسط هوش مصنوعی است، اجرا شوند و در صورت یافتن یافته‌های بحرانی، ادغام‌ها را مسدود کنند. |  2  |  D  |
| AD.4.3 | بررسی کنید که آیا آزمایش فازی تفاضلی یا آزمایش‌های مبتنی بر ویژگی، رفتارهای بحرانی امنیتی را اثبات می‌کنند (مثلاً اعتبارسنجی ورودی، منطق مجوزدهی).                                   |  3  | D/V |

---

## AD.5 توضیح‌پذیری و پیگیری پیشنهادهای کد

برای حسابرسان و توسعه‌دهندگان، بینشی در مورد چرایی ارائه یک پیشنهاد و چگونگی تکامل آن ارائه کنید.

|   #    | شرح                                                                                                                                                                  | سطح | نقش |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| AD.5.1 | اطمینان حاصل کنید که زوج‌های پرومپت/پاسخ با شناسه‌های کامیت ثبت می‌شوند.                                                                                             |  1  | D/V |
| AD.5.2 | اطمینان حاصل کنید که توسعه‌دهندگان می‌توانند استنادهای مدل (نمونه‌های آموزشی، مستندات) که از یک پیشنهاد پشتیبانی می‌کنند، به نمایش بگذارند.                          |  2  |  D  |
| AD.5.3 | بررسی کنید که گزارش‌های توضیح‌پذیری با مستندات طراحی ذخیره شوند و در بازبینی‌های امنیتی به آنها ارجاع داده شوند، تا با اصول ردیابی ISO/IEC 42001 مطابقت داشته باشند. |  3  | D/V |

---

## AD.6 بازخورد مداوم و تنظیم دقیق مدل

بهبود مداوم عملکرد امنیتی مدل در طول زمان در عین جلوگیری از انحراف منفی.

|   #    | شرح                                                                                                                                                                                                   | سطح | نقش |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-: | :-: |
| AD.6.1 | بررسی کنید که توسعه‌دهندگان بتوانند پیشنهادهای ناامن یا غیر منطبق با استانداردها را پرچم‌گذاری کنند و اینکه پرچم‌ها ردیابی می‌شوند۔                                                                   |  1  | D/V |
| AD.6.2 | تأیید کنید که بازخوردهای تجمیعی، به‌روزرسانی‌های دوره‌ای یا تولید با استفاده از بازیابی تقویت‌شده را با مجموعه‌های داده امن‑کدنویسیِ تأییدشده هدایت می‌کند (برای مثال OWASP Cheat Sheets).            |  2  |  D  |
| AD.6.3 | اطمینان حاصل کنید که یک چارچوب ارزیابی حلقه‌ بسته پس از هر ریزتنظیم، تست‌های رگرسیون را اجرا می‌کند؛ معیارهای امنیتی باید قبل از استقرار با پایه‌های قبلی هم‌خوانی داشته باشند یا از آنها فراتر روند. |  3  | D/V |

---

### منابع

* [NIST AI Risk Management Framework 1.0](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [ISO/IEC 42001:2023 — AI Management Systems Requirements](https://www.iso.org/standard/81230.html)
* [OWASP Secure Coding Practices — Quick Reference Guide](https://owasp.org/www-project-secure-coding-practices-quick-reference-guide/)

