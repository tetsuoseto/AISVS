# صفحه‌ی روبرو

## درباره استاندارد

استاندارد اعتبارسنجی امنیت هوش مصنوعی (AISVS) یک فهرست نیازمندی‌های امنیتی است که توسط جامعه ‌ای از دانشمندان داده، مهندسان MLOps، معماران نرم‌افزار، توسعه‌دهندگان، آزمون‌کنندگان، متخصصان امنیت، فروشندگان ابزار، ناظران و مصرف‌کنندگان ایجاد شده است و می‌تواند برای طراحی، ساخت، آزمون و اعتبارسنجی سیستم‌ها و برنامه‌های مبتنی بر هوش مصنوعی قابل اعتماد استفاده شود. این استاندارد زبان مشترکی برای مشخص کردن کنترل‌های امنیتی در سراسر چرخه عمر هوش مصنوعی فراهم می‌کند—از جمع‌آوری داده‌ها و توسعه مدل تا استقرار و پایش مستمر—تا سازمان‌ها بتوانند تاب‌آوری، حفظ حریم خصوصی و ایمنی راه‌حل‌های هوش مصنوعی خود را اندازه‌گیری و بهبود دهند.

## حق چاپ و مجوز

نسخه 0.1 (اولین پیش‌نویس عمومی - در حال انجام کار)، 2025  

![license](../images/license.png)

کپی‌رایت © 2025 پروژه AISVS.  

منتشر شده تحت[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
برای هر گونه استفاده مجدد یا توزیع، باید شرایط مجوز این اثر را به طور واضح به دیگران اطلاع دهید.

## رهبران پروژه

|             |                       |
| ----------- | --------------------- |
| جیم مَنی‌کو | آراس "راس" ممیزیازیچی |

## مشارکت‌کنندگان و بازبین‌ها

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS یک استاندارد کاملاً جدید است که به طور خاص برای پرداختن به چالش‌های امنیتی منحصر به فرد سیستم‌های هوش مصنوعی ایجاد شده است. در حالی که از بهترین شیوه‌های امنیتی گسترده‌تر الهام گرفته است، هر الزام در AISVS از پایه توسعه یافته است تا نمایانگر چشم‌انداز تهدیدات هوش مصنوعی باشد و به سازمان‌ها در ساخت راه‌حل‌های هوش مصنوعی ایمن‌تر و مقاوم‌تر کمک کند.

