# صفحه عنوان

## درباره استاندارد

استاندارد تایید امنیت هوش مصنوعی (AISVS) یک فهرست مبتنی بر مشارکت جامعه از الزامات امنیتی است که دانشمندان داده، مهندسان MLOps، معماران نرم‌افزار، توسعه‌دهندگان، آزمون‌گران، متخصصان امنیتی، فروشندگان ابزار، نهادهای نظارتی و مصرف‌کنندگان می‌توانند از آن برای طراحی، ساخت، آزمون و تایید سیستم‌ها و برنامه‌های مبتنی بر هوش مصنوعی قابل اعتماد استفاده کنند. این استاندارد زبان مشترکی برای مشخص کردن کنترل‌های امنیتی در سرتاسر چرخه عمر هوش مصنوعی ارائه می‌دهد—از جمع‌آوری داده و توسعه مدل تا استقرار و پایش مداوم—تا سازمان‌ها بتوانند مقاومت، حریم خصوصی و ایمنی راهکارهای هوش مصنوعی خود را اندازه‌گیری و بهبود بخشند.

## کپی‌رایت و مجوز

نسخه 0.1 (اولین پیش‌نویس عمومی - در حال کار)، 2025  

![license](../images/license.png)

حقوق نشر © 2025 پروژه AISVS.  

منتشر شده تحت [Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
برای هر گونه استفاده مجدد یا توزیع، باید شرایط مجوز این اثر را به‌طور واضح به دیگران اطلاع دهید.

## رهبران پروژه

|             |                        |
| ----------- | ---------------------- |
| جیم مانویکو | آراس "راس" میمیسیازیچی |

## مشارکت‌کنندگان و بررسی‌کنندگان

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS یک استاندارد کاملاً جدید است که به طور خاص برای مقابله با چالش‌های امنیتی منحصر به فرد سیستم‌های هوش مصنوعی ایجاد شده است. در حالی که از بهترین شیوه‌های امنیتی گسترده‌تر الهام می‌گیرد، هر الزامی در AISVS از پایه توسعه یافته است تا چشم‌انداز تهدیدات هوش مصنوعی را منعکس کند و به سازمان‌ها کمک کند تا راه‌حل‌های هوش مصنوعی ایمن‌تر و مقاوم‌تری بسازند.

