# صفحه عنوان

## درباره استاندارد

استاندارد بررسی امنیت هوش مصنوعی (AISVS) یک فهرست مبتنی بر جامعه از الزامات امنیتی است که دانشمندان داده، مهندسان MLOps، معماران نرم‌افزار، توسعه‌دهندگان، آزمون‌گران، متخصصان امنیت، فروشندگان ابزار، تنظیم‌کنندگان و کاربران می‌توانند از آن برای طراحی، ساخت، آزمایش و تأیید سیستم‌ها و برنامه‌های قابل اعتماد مجهز به هوش مصنوعی استفاده کنند. این استاندارد زبان مشترکی برای تعیین کنترل‌های امنیتی در سراسر چرخه عمر هوش مصنوعی ارائه می‌دهد — از جمع‌آوری داده‌ها و توسعه مدل تا استقرار و نظارت مداوم — تا سازمان‌ها بتوانند مقاومت، حریم خصوصی و ایمنی راه‌حل‌های هوش مصنوعی خود را اندازه‌گیری و بهبود بخشند.

## حق نشر و مجوز

نسخه 0.1 (اولین پیش‌نویس عمومی - در حال کار)، 2025  

![license](../images/license.png)

کپی‌رایت © 2025 پروژه AISVS.  

منتشر شده تحت[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
برای هرگونه استفاده مجدد یا توزیع، شما باید شرایط مجوز این اثر را به‌طور واضح به دیگران اعلام کنید.

## رهبران پروژه

|            |                     |
| ---------- | ------------------- |
| جیم مانیكو | آراس "راس" ممیزیاقی |

## مشارکت‌کنندگان و بازبین‌ها

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS یک استاندارد کاملاً جدید است که به‌طور خاص برای پاسخ به چالش‌های امنیتی منحصربه‌فرد سیستم‌های هوش مصنوعی ایجاد شده است. در حالی که از بهترین شیوه‌های امنیتی گسترده‌تر الهام می‌گیرد، هر الزامی در AISVS از ابتدا به گونه‌ای توسعه یافته است که چشم‌انداز تهدیدات هوش مصنوعی را منعکس کند و به سازمان‌ها کمک کند تا راه‌حل‌های هوش مصنوعی ایمن‌تر و مقاوم‌تری بسازند.

