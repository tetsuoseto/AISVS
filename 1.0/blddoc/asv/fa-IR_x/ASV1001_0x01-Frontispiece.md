# تصویر روی صفحهٔ عنوان

## درباره استاندارد

استاندارد ارزیابی امنیت هوش مصنوعی (AISVS) یک فهرست هدایت‌شده توسط جامعه از الزامات امنیتی است که دانش‌مندان داده، مهندسان MLOps، معماران نرم‌افزار، توسعه‌دهندگان، آزمایشگران، متخصصان امنیت، فروشندگان ابزار، تنظیم‌کنندگان و مصرف‌کنندگان می‌توانند از آن برای طراحی، ساخت، آزمایش و تأیید سیستم‌ها و برنامه‌های مبتنی بر هوش مصنوعی قابل اعتماد استفاده کنند. این استاندارد یک زبان مشترک برای مشخص‌کردن کنترل‌های امنیتی در طول چرخه حیات هوش مصنوعی فراهم می‌کند — از جمع‌آوری داده‌ها و توسعه مدل تا استقرار و پایش مستمر — تا سازمان‌ها بتوانند تاب‌آوری، حریم خصوصی و ایمنی راه‌حل‌های هوش مصنوعی خود را اندازه‌گیری و بهبود ببخشند.

## کپی‌رایت و مجوز

نسخه 0.1 (اولین پیش‌نویس عمومی - در حال کار), 2025  

![license](../images/license.png)

کپی‌رایت © 2025 پروژه AISVS.  

منتشر شده تحت  [Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
برای هرگونه استفاده مجدد یا توزیع، باید به وضوح شرایط مجوز این اثر را به دیگران اطلاع دهید.

## رهبران پروژه

|           |                          |
| --------- | ------------------------ |
| جیم منیکو | آراس «Russ» میمیس یازیجی |

## سازندگان و بازبین‌کنندگان

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS یک استاندارد کاملاً جدید است که به طور خاص برای پرداختن به چالش‌های امنیتی منحصر به فرد سامانه‌های هوش مصنوعی ایجاد شده است. در حالی که از بهترین شیوه‌های امنیتی گسترده‌تر الهام می‌گیرد، هر الزام در AISVS از پایه و اساس توسعه یافته است تا بازتاب‌دهنده چشم‌انداز تهدیدهای هوش مصنوعی باشد و به سازمان‌ها کمک کند تا راه‌حل‌های هوش مصنوعی ایمن‌تر و مقاوم‌تری بسازند.

