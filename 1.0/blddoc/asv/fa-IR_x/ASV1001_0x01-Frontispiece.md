# صفحه‌ی عنوان

## درباره استاندارد

استاندارد تأیید امنیت هوش مصنوعی (AISVS) یک فهرست جامعه‌محور از الزامات امنیتی است که دانشمندان داده، مهندسان MLOps، معماران نرم‌افزار، توسعه‌دهندگان، تست‌کنندگان، متخصصان امنیت، فروشندگان ابزار، تنظیم‌کنندگان مقررات و مصرف‌کنندگان می‌توانند برای طراحی، ساخت، آزمون و تأیید سیستم‌ها و برنامه‌های کاربردی قابل اعتماد مبتنی بر هوش مصنوعی از آن استفاده کنند. این استاندارد زبان مشترکی برای مشخص کردن کنترل‌های امنیتی در سراسر چرخه عمر هوش مصنوعی ارائه می‌دهد—از جمع‌آوری داده‌ها و توسعه مدل تا استقرار و نظارت مستمر—تا سازمان‌ها بتوانند مقاومت، حریم خصوصی و ایمنی راه‌حل‌های هوش مصنوعی خود را اندازه‌گیری و بهبود بخشند.

## حق نشر و مجوز

نسخه 0.1 (اولین پیش‌نویس عمومی - در دست انجام)، 2025  

![license](../images/license.png)

حق نشر © 2025 پروژه AISVS.  

منتشر شده تحت [Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
برای هرگونه استفاده مجدد یا توزیع، باید شرایط مجوز این اثر را به طور واضح به دیگران اطلاع دهید.

## رهبران پروژه

|            |                         |
| ---------- | ----------------------- |
| جیم مانیكو | آراس "راس" ممیسی‌یازیچی |

## مشارکت‌کنندگان و بازبین‌ها

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS یک استاندارد کاملاً جدید است که به طور خاص برای پرداختن به چالش‌های امنیتی منحصر به فرد سیستم‌های هوش مصنوعی ایجاد شده است. در حالی که از بهترین شیوه‌های کلی امنیت الهام گرفته شده است، هر نیاز در AISVS از پایه توسعه یافته تا نمایانگر چشم‌انداز تهدیدات هوش مصنوعی باشد و به سازمان‌ها کمک کند تا راه‌حل‌های هوش مصنوعی ایمن‌تر و مقاوم‌تری بسازند.

