# صفحه عنوان

## درباره استاندارد

استاندارد ارزیابی امنیت هوش مصنوعی (AISVS) یک فهرست مبتنی بر جامعه از الزامات امنیتی است که دانشمندان داده، مهندسان MLOps، معماران نرم‌افزار، توسعه‌دهندگان، آزمایش‌کنندگان، متخصصان امنیت، فروشندگان ابزار، تنظیم‌کنندگان مقررات و مصرف‌کنندگان می‌توانند از آن برای طراحی، ساخت، آزمایش و تأیید سیستم‌ها و برنامه‌های کاربردی قابل اعتماد مبتنی بر هوش مصنوعی استفاده کنند. این استاندارد زبان مشترکی برای مشخص کردن کنترل‌های امنیتی در سراسر چرخه عمر هوش مصنوعی فراهم می‌کند—از جمع‌آوری داده‌ها و توسعه مدل تا استقرار و نظارت مداوم—تا سازمان‌ها بتوانند تاب‌آوری، حریم خصوصی و ایمنی راه‌حل‌های هوش مصنوعی خود را اندازه‌گیری و بهبود بخشند.

## حق نشر و مجوز

نسخه 0.1 (اولین پیش‌نویس عمومی - در حال کار)، 2025  

![license](../images/license.png)

کپی‌رایت © 2025 پروژه AISVS.  

منتشر شده تحت[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
برای هر گونه استفاده مجدد یا توزیع، باید شرایط مجوز این اثر را به‌طور واضح به دیگران اطلاع دهید.

## رهبران پروژه

|            |                       |
| ---------- | --------------------- |
| جیم مانیكو | آراس «راس» ممیزیازیکی |

## مشارکت‌کنندگان و بازبینی‌کنندگان

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS یک استاندارد کاملاً جدید است که به طور خاص برای رسیدگی به چالش‌های منحصر به فرد امنیتی سیستم‌های هوش مصنوعی ایجاد شده است. در حالی که از بهترین شیوه‌های امنیتی گسترده‌تر الهام گرفته است، هر نیازمندی در AISVS از پایه توسعه یافته است تا بازتاب دهنده چشم‌انداز تهدیدهای هوش مصنوعی باشد و به سازمان‌ها کمک کند راه‌حل‌های هوش مصنوعی امن‌تر و مقاوم‌تری بسازند.

