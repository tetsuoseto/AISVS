# Vorderseite

## Über den Standard

Der Artificial Intelligence Security Verification Standard (AISVS) ist ein gemeinschaftlich erstellter Katalog von Sicherheitsanforderungen, den Data Scientists, MLOps-Ingenieure, Softwarearchitekten, Entwickler, Tester, Sicherheitsexperten, Tool-Anbieter, Regulierungsbehörden und Anwender nutzen können, um vertrauenswürdige KI-gestützte Systeme und Anwendungen zu entwerfen, zu entwickeln, zu testen und zu verifizieren. Er bietet eine gemeinsame Sprache zur Spezifikation von Sicherheitskontrollen im gesamten KI-Lebenszyklus – von der Datenerfassung und Modellentwicklung bis hin zur Bereitstellung und laufenden Überwachung – sodass Organisationen die Widerstandsfähigkeit, den Datenschutz und die Sicherheit ihrer KI-Lösungen messen und verbessern können.

## Urheberrecht und Lizenz

Version 0.1 (Erster öffentlicher Entwurf – Arbeit im Gange), 2025  

![license](../images/license.png)

Copyright © 2025 Das AISVS-Projekt.  

Veröffentlicht unter der[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
Für jegliche Wiederverwendung oder Verbreitung müssen Sie die Lizenzbedingungen dieses Werks deutlich an andere kommunizieren.

## Projektleiter

|            |                         |
| ---------- | ----------------------- |
| Jim Manico | Aras „Russ“ Memisyazici |

## Mitwirkende und Prüfer

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS ist ein brandneuer Standard, der speziell entwickelt wurde, um die einzigartigen Sicherheitsherausforderungen von künstlichen Intelligenzsystemen zu adressieren. Während er sich von allgemeinen Sicherheits-Best-Practices inspirieren lässt, wurde jede Anforderung in AISVS von Grund auf entwickelt, um die Bedrohungslandschaft im Bereich KI abzubilden und Organisationen dabei zu unterstützen, sicherere und widerstandsfähigere KI-Lösungen zu entwickeln.

