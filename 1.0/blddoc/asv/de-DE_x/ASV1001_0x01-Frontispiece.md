# Frontispiz

## Über den Standard

Der Artificial Intelligence Security Verification Standard (AISVS) ist ein gemeinschaftlich erstellter Katalog von Sicherheitsanforderungen, den Data Scientists, MLOps-Ingenieure, Softwarearchitekten, Entwickler, Tester, Sicherheitsexperten, Tool-Anbieter, Regulierungsbehörden und Anwender nutzen können, um vertrauenswürdige KI-basierte Systeme und Anwendungen zu entwerfen, zu entwickeln, zu testen und zu verifizieren. Er bietet eine gemeinsame Sprache zur Spezifizierung von Sicherheitskontrollen über den gesamten KI-Lebenszyklus hinweg – von der Datenerfassung und Modellentwicklung bis hin zu Einsatz und fortlaufender Überwachung – damit Organisationen die Belastbarkeit, den Datenschutz und die Sicherheit ihrer KI-Lösungen messen und verbessern können.

## Urheberrecht und Lizenz

Version 0.1 (Erster öffentlicher Entwurf - Arbeit im Gange), 2025  

![license](../images/license.png)

Copyright © 2025 Das AISVS-Projekt.  

Veröffentlicht unter der[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
Für jede Wiederverwendung oder Verbreitung müssen Sie die Lizenzbedingungen dieses Werks anderen klar kommunizieren.

## Projektleiter

|            |                         |
| ---------- | ----------------------- |
| Jim Manico | Aras „Russ“ Memisyazici |

## Mitwirkende und Gutachter

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS ist ein brandneuer Standard, der speziell entwickelt wurde, um die einzigartigen Sicherheitsherausforderungen von Systemen der künstlichen Intelligenz zu adressieren. Obwohl er sich an allgemeineren Sicherheits-Best Practices orientiert, wurde jeder einzelne Anforderungspunkt in AISVS von Grund auf neu entwickelt, um die Bedrohungslandschaft im Bereich der KI widerzuspiegeln und Organisationen dabei zu helfen, sicherere und widerstandsfähigere KI-Lösungen zu entwickeln.

