# Frontispiz

## Über den Standard

Der Artificial Intelligence Security Verification Standard (AISVS) ist ein gemeinschaftlich entwickelter Katalog von Sicherheitsanforderungen, den Data Scientists, MLOps-Ingenieure, Softwarearchitekten, Entwickler, Tester, Sicherheitsexperten, Tool-Anbieter, Regulierungsbehörden und Anwender nutzen können, um vertrauenswürdige KI-gestützte Systeme und Anwendungen zu entwerfen, zu entwickeln, zu testen und zu verifizieren. Er bietet eine gemeinsame Sprache zur Spezifikation von Sicherheitskontrollen über den gesamten KI-Lebenszyklus hinweg – von der Datenerfassung und Modellentwicklung bis hin zur Bereitstellung und laufenden Überwachung – sodass Organisationen die Widerstandsfähigkeit, Privatsphäre und Sicherheit ihrer KI-Lösungen messen und verbessern können.

## Urheberrecht und Lizenz

Version 0.1 (Erster öffentlicher Entwurf - In Bearbeitung), 2025  

![license](../images/license.png)

Copyright © 2025 Das AISVS-Projekt.  

Veröffentlicht unter der[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
Für jegliche Wiederverwendung oder Verbreitung müssen Sie die Lizenzbedingungen dieses Werkes klar an andere kommunizieren.

## Projektleiter

|            |                         |
| ---------- | ----------------------- |
| Jim Manico | Aras „Russ“ Memisyazici |

## Mitwirkende und Gutachter

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS ist ein brandneuer Standard, der speziell entwickelt wurde, um die einzigartigen Sicherheitsherausforderungen von künstlichen Intelligenzsystemen zu adressieren. Während er sich von allgemeinen bewährten Sicherheitspraktiken inspirieren lässt, wurde jede Anforderung in AISVS von Grund auf entwickelt, um die Bedrohungslandschaft im Bereich der KI widerzuspiegeln und Organisationen dabei zu unterstützen, sicherere und widerstandsfähigere KI-Lösungen zu entwickeln.

