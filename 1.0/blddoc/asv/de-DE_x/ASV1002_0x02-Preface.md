# Vorwort

Willkommen zum Artificial Intelligence Security Verification Standard (AISVS) Version 1.0!

## Einführung

Gegründet im Jahr 2025 durch eine gemeinschaftliche Kooperation definiert AISVS die Sicherheitsanforderungen, die bei der Gestaltung, Entwicklung, Bereitstellung und dem Betrieb moderner KI-Modelle, Pipelines und KI-basierter Dienste zu berücksichtigen sind.

AISVS v1.0 stellt die gemeinsame Arbeit seiner Projektleiter, Arbeitsgruppe und breiteren Community-Beitragenden dar, um eine pragmatische, überprüfbare Basis für die Sicherung von KI-Systemen zu schaffen.

Unser Ziel mit dieser Veröffentlichung ist es, AISVS einfach anwendbar zu machen, dabei jedoch den klar definierten Aufgabenbereich strikt einzuhalten und die sich schnell ändernde Risikolandschaft, die für KI einzigartig ist, gezielt anzugehen.

## Hauptziele für AISVS Version 1.0

Version 1.0 wird mit mehreren Leitprinzipien erstellt.

### Gut definierter Umfang

Jede Anforderung muss mit dem Namen und der Mission von AISVS übereinstimmen:

* Künstliche Intelligenz – Kontrollen werden auf der AI/ML-Ebene (Daten, Modell, Pipeline oder Inferenz) durchgeführt und liegen in der Verantwortung der AI-Fachleute.
* Sicherheit – Anforderungen mindern direkt identifizierte Sicherheits-, Datenschutz- oder Sicherheitsrisiken.
* Verifikation – Die Sprache ist so verfasst, dass die Konformität objektiv validiert werden kann.
* Standard – Abschnitte folgen einer konsistenten Struktur und Terminologie, um eine kohärente Referenz zu bilden.
  ​
---

Durch die Einhaltung von AISVS können Organisationen die Sicherheitslage ihrer KI-Lösungen systematisch bewerten und stärken, wodurch eine Kultur der sicheren KI-Entwicklung gefördert wird.

