# Vorwort

Willkommen beim Artificial Intelligence Security Verification Standard (AISVS) Version 1.0!

## Einführung

AISVS wurde im Jahr 2025 durch eine gemeinsame Gemeinschaftsinitiative gegründet und definiert die Sicherheitsanforderungen, die bei der Gestaltung, Entwicklung, Bereitstellung und dem Betrieb moderner KI-Modelle, Pipelines und KI-gestützter Dienste zu berücksichtigen sind.

AISVS v1.0 stellt die gemeinsame Arbeit seiner Projektleiter, der Arbeitsgruppe und der breiteren Gemeinschaft von Beitragenden dar, um eine pragmatische, überprüfbare Grundlage für die Sicherung von KI-Systemen zu schaffen.

Unser Ziel mit dieser Veröffentlichung ist es, AISVS einfach anwendbar zu machen, dabei aber den definierten Umfang strikt einzuhalten und die sich schnell entwickelnde, einzigartige Risikolandschaft im Bereich der KI zu adressieren.

## Schlüsselziele für AISVS Version 1.0

Version 1.0 wird mit mehreren Leitprinzipien erstellt.

### Gut definierter Umfang

Jede Anforderung muss mit dem Namen und der Mission von AISVS übereinstimmen:

* Künstliche Intelligenz – Kontrollen erfolgen auf der AI/ML-Ebene (Daten, Modell, Pipeline oder Inferenz) und liegen in der Verantwortung der AI-Fachleute.
* Sicherheit – Anforderungen mindern direkt identifizierte Sicherheits-, Datenschutz- oder Sicherheitsrisiken.
* Verifizierung – Die Sprache ist so verfasst, dass die Übereinstimmung objektiv validiert werden kann.
* Standard – Abschnitte folgen einer einheitlichen Struktur und Terminologie, um eine kohärente Referenz zu bilden.
  ​
---

Indem sie AISVS befolgen, können Organisationen systematisch die Sicherheitslage ihrer KI-Lösungen bewerten und stärken, wodurch eine Kultur der sicheren KI-Entwicklung gefördert wird.

