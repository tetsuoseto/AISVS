# Vorwort

Willkommen beim Sicherheitsverifizierungsstandard für Künstliche Intelligenz (AISVS) Version 1.0!

## Einführung

Im Jahr 2025 durch eine gemeinschaftliche Anstrengung der Community gegründet, definiert AISVS die Sicherheitsanforderungen, die bei der Gestaltung, Entwicklung, Bereitstellung und dem Betrieb moderner KI‑Modelle, Pipelines und KI‑gestützter Dienste zu beachten sind.

AISVS v1.0 repräsentiert die gemeinsame Arbeit seiner Projektleitungen, der Arbeitsgruppe und der breiten Community-Beiträge, um eine pragmatische, testbare Basis zur Absicherung von KI-Systemen zu schaffen.

Unser Ziel mit dieser Veröffentlichung ist es, AISVS einfach einführbar zu machen, während wir uns gleichzeitig eng auf den definierten Umfang konzentrieren und die sich rasch entwickelnde Risikolandschaft, die für KI einzigartig ist, adressieren.

## Kernziele für AISVS Version 1.0

Version 1.0 wird mit mehreren Leitprinzipien erstellt.

### Gut definierter Umfang

Jede Anforderung muss mit dem Namen und der Mission von AISVS übereinstimmen:

* Künstliche Intelligenz – Kontrollen arbeiten auf der KI/ML-Ebene (Daten, Modell, Pipeline oder Inferenz) und liegen in der Verantwortung der KI-Praktiker.
* Sicherheit – Anforderungen mindern direkt identifizierte Sicherheits-, Datenschutz- oder Sicherheitsrisiken.
* Verifikation – Die Sprache ist so verfasst, dass die Konformität objektiv verifiziert werden kann.
* Standard – Abschnitte folgen einer konsistenten Struktur und Terminologie, um eine kohärente Referenz zu bilden.
  ​
---

Durch die Befolgung von AISVS können Organisationen systematisch die Sicherheitslage ihrer KI-Lösungen bewerten und stärken und so eine Kultur der sicheren KI-Entwicklung fördern.

