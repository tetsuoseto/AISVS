# Vorwort

Willkommen zum Artificial Intelligence Security Verification Standard (AISVS) Version 1.0!

## Einführung

AISVS wurde 2025 durch eine gemeinschaftliche Zusammenarbeit gegründet und definiert die Sicherheitsanforderungen, die bei der Gestaltung, Entwicklung, Bereitstellung und dem Betrieb moderner KI-Modelle, Pipelines und KI-gestützter Dienste berücksichtigt werden müssen.

AISVS v1.0 stellt die gemeinsame Arbeit seiner Projektleiter, der Arbeitsgruppe und der weiteren Community-Beiträge dar, um eine pragmatische, testbare Basis für die Absicherung von KI-Systemen zu schaffen.

Unser Ziel mit dieser Veröffentlichung ist es, AISVS leicht verständlich und anwendbar zu machen, dabei jedoch strikt auf den definierten Umfang fokussiert zu bleiben und die sich schnell entwickelnde, einzigartige Risikolandschaft im Bereich der KI zu adressieren.

## Hauptziele für AISVS Version 1.0

Version 1.0 wird nach mehreren Leitprinzipien erstellt.

### Gut definierter Umfang

Jede Anforderung muss mit dem Namen und der Mission von AISVS übereinstimmen:

* Künstliche Intelligenz – Die Kontrollen arbeiten auf der AI/ML-Ebene (Daten, Modell, Pipeline oder Inferenz) und liegen in der Verantwortung der KI-Fachleute.
* Sicherheit – Anforderungen mindern direkt identifizierte Sicherheits-, Datenschutz- oder Sicherheitsrisiken.
* Verifikation – Die Sprache ist so geschrieben, dass die Konformität objektiv überprüfbar ist.
* Standard – Abschnitte folgen einer konsistenten Struktur und Terminologie, um eine kohärente Referenz zu bilden.
  ​
---

Durch die Befolgung von AISVS können Organisationen systematisch die Sicherheitslage ihrer KI-Lösungen bewerten und stärken und so eine Kultur der sicheren KI-Entwicklung fördern.

