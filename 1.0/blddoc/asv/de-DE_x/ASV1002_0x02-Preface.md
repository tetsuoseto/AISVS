# Vorwort

Willkommen zum Artificial Intelligence Security Verification Standard (AISVS) Version 1.0!

## Einleitung

Die im Jahr 2025 durch eine gemeinschaftliche Zusammenarbeit gegründete AISVS definiert die Sicherheitsanforderungen, die bei der Konzeption, Entwicklung, Implementierung und dem Betrieb moderner KI-Modelle, Pipelines und KI-gestützter Dienste zu berücksichtigen sind.

AISVS v1.0 stellt die gemeinsame Arbeit seiner Projektleiter, Arbeitsgruppe und der breiteren Gemeinschaft von Mitwirkenden dar, um eine pragmatische, testbare Grundlage für die Sicherung von KI-Systemen zu schaffen.

Unser Ziel mit dieser Veröffentlichung ist es, AISVS einfach zu übernehmen, während wir gleichzeitig strikt auf dessen definierten Umfang fokussiert bleiben und die sich schnell entwickelnde Risikolandschaft, die für KI einzigartig ist, adressieren.

## Hauptziele für AISVS Version 1.0

Version 1.0 wird mit mehreren Leitprinzipien erstellt.

### Gut definierter Umfang

Jede Anforderung muss mit dem Namen und der Mission von AISVS übereinstimmen:

* Künstliche Intelligenz – Kontrollen werden auf der AI/ML-Ebene (Daten, Modell, Pipeline oder Inferenz) durchgeführt und liegen in der Verantwortung der AI-Praktiker.
* Sicherheit – Anforderungen mildern direkt identifizierte Sicherheits-, Datenschutz- oder Sicherheitsrisiken.
* Verifikation – Die Sprache ist so verfasst, dass die Konformität objektiv überprüft werden kann.
* Standard – Abschnitte folgen einer konsistenten Struktur und Terminologie, um eine kohärente Referenz zu bilden.
  ​
---

Durch die Befolgung von AISVS können Organisationen die Sicherheitslage ihrer KI-Lösungen systematisch bewerten und stärken und damit eine Kultur der sicheren KI-Entwicklung fördern.

