# পরিশিষ্ট এ: শব্দকোষ

এই বিস্তৃত শব্দভন্ডারটি AISVS জুড়ে ব্যবহৃত মূল AI, ML, এবং নিরাপত্তা শব্দগুলির সংজ্ঞা প্রদান করে স্পষ্টতা এবং সাধারণ বোঝাপড়া নিশ্চিত করতে।

* বিরোধী উদাহরণ: একটি ইনপুট যা ইচ্ছাকৃতভাবে তৈরি করা হয় যাতে একটি AI মডেল ভুল করে, সাধারণত মানুষের পক্ষে অদৃশ্য সূক্ষ্ম বিঘ্ন যোগ করার মাধ্যমে।
  ​
* প্রতিদ্বন্দ্বিতামূলক দৃঢ়তা – এআই-তে প্রতিদ্বন্দ্বিতামূলক দৃঢ়তা বলতে একটি মডেলের ক্ষমতাকে বুঝায় যা তার কর্মক্ষমতা বজায় রাখতে এবং ইচ্ছাকৃতভাবে তৈরি করা ক্ষতিকর ইনপুটের মাধ্যমে বিভ্রান্ত বা প্রতারিত হওয়া থেকে বিরত থাকতে পারে, যা ত্রুটি সৃষ্টির জন্য ডিজাইন করা হয়েছে।
  ​
* এজেন্ট – AI এজেন্ট হল সফটওয়্যার সিস্টেম যা ব্যবহারকারীর পক্ষ থেকে লক্ষ্য পূরণ এবং কাজ সম্পন্ন করার জন্য কৃত্রিম বুদ্ধিমত্তা ব্যবহার করে। তারা যুক্তি, পরিকল্পনা, এবং স্মৃতি প্রদর্শন করে এবং সিদ্ধান্ত গ্রহণ, শেখার এবং অভিযোজন করার একটি স্তরের স্বায়ত্তশাসন রয়েছে।
  ​
* এজেন্সিক AI: AI সিস্টেমগুলি যা কিছু ডিগ্রি স্বাধীনতা নিয়ে কাজ করতে পারে লক্ষ্য অর্জনের জন্য, প্রায়ই সরাসরি মানব হস্তক্ষেপ ছাড়াই সিদ্ধান্ত নেয় এবং পদক্ষেপ গ্রহণ করে।
  ​
* অ্যাট্রিবিউট-ভিত্তিক অ্যাক্সেস কন্ট্রোল (ABAC): একটি অ্যাক্সেস কন্ট্রোল প্যারাডাইম যেখানে অনুমোদন সিদ্ধান্তগুলো ব্যবহারকারী, সম্পদ, ক্রিয়া, এবং পরিবেশের অ্যাট্রিবিউটের উপর ভিত্তি করে নেওয়া হয়, যা কোয়েরি সময়ে মূল্যায়ন করা হয়।
  ​
* ব্যাকডোর আক্রমণ: ডেটা পয়জনিং আক্রমণের একটি ধরন যেখানে মডেলকে নির্দিষ্ট ট্রিগারের প্রতি নির্দিষ্টভাবে সাড়া দিতে প্রশিক্ষণ দেওয়া হয়, যদিও অন্যথায় এটি স্বাভাবিকভাবে কাজ করে।
  ​
* পক্ষপাত: AI মডেলের আউটপুটে সিস্টেম্যাটিক ত্রুটি যা নির্দিষ্ট গোষ্ঠী বা নির্দিষ্ট প্রেক্ষাপটে অন্যায় বা বৈষম্যমূলক ফলাফলের দিকে নিয়ে যেতে পারে।
  ​
* পক্ষপাত শোষণ: একটি আক্রমণ কৌশল যা কৃত্রিম বুদ্ধিমত্তা মডেলগুলির পরিচিত পক্ষপাতকে কাজে লাগিয়ে আউটপুট বা ফলাফল নিয়ন্ত্রণ করে।
  ​
* Cedar: অ্যামাজনের পলিসি ভাষা এবং ইঞ্জিন যা AI সিস্টেমের জন্য ABAC বাস্তবায়নে সূক্ষ্ম-সন্নিবেশ অনুমতির জন্য ব্যবহৃত হয়।
  ​
* চেইন অফ থট: একটি প্রযুক্তি যা ভাষার মডেলগুলিতে সিদ্ধান্ত গ্রহণ উন্নত করার জন্য মধ্যবর্তী যুক্তির ধাপগুলি তৈরি করে চূড়ান্ত উত্তর প্রদানের আগে।
  ​
* সার্কিট ব্রেকারস: এমন মেকানিজম যা নির্দিষ্ট ঝুঁকির সীমা অতিক্রম করলে স্বয়ংক্রিয়ভাবে AI সিস্টেমের কার্যক্রম বন্ধ করে দেয়।
  ​
* ডেটা লিকেজ: AI মডেলের আউটপুট বা আচরণের মাধ্যমে সংবেদনশীল তথ্যের অবাঞ্ছিত প্রকাশ।
  ​
* ডেটা পয়জনিং: মডেলের অখণ্ডতা ক্ষতির জন্য প্রশিক্ষণ ডেটা চিকিত্‍সিতভাবে ক্ষতিগ্রস্ত করা, যা প্রায়ই ব্যাকডোর ইনস্টল করা বা কার্যক্ষমতা নষ্ট করার উদ্দেশ্যে করা হয়।
  ​
* ডিফারেনশিয়াল প্রাইভেসি – ডিফারেনশিয়াল প্রাইভেসি হল একটি গাণিতিকভাবে কঠোর কাঠামো যা ডেটাসেট সম্পর্কিত পরিসংখ্যানগত তথ্য প্রকাশের জন্য ব্যবহৃত হয়, পাশাপাশি ব্যক্তিগত ডেটা বিষয়ের গোপনীয়তা রক্ষা করে। এটি একটি ডেটা হোল্ডারকে গোষ্ঠীর সার্বিক প্যাটার্ন শেয়ার করার অনুমতি দেয়, যদিও নির্দিষ্ট ব্যক্তিদের সম্পর্কে তথ্য ফাঁস হওয়া সীমাবদ্ধ করে।
  ​
* এম্বেডিংস: ঘন ভেক্টর উপস্থাপনা যা ডেটার (পাঠ্য, ছবি ইত্যাদি) সেম্যান্টিক অর্থকে একটি উচ্চ-ডাইমেনশনাল স্পেসে ধারণ করে।
  ​
* ব্যাখ্যাত্মকতা – AI-তে ব্যাখ্যাত্মকতা হলো একটি AI সিস্টেমের এমন একটি ক্ষমতা যা তার সিদ্ধান্ত ও পূর্বাভাষের জন্য মানব-বোধ্য কারণ প্রদান করতে পারে, যা তার অভ্যন্তরীণ কার্যপ্রণালীর অন্তর্দৃষ্টি প্রদান করে।
  ​
* বর্ণনাযোগ্য এআই (XAI): এমন এআই সিস্টেম যা তাদের সিদ্ধান্ত এবং আচরণের জন্য মানুষের বোঝার উপযোগী ব্যাখ্যা প্রদান করার জন্য বিভিন্ন প্রযুক্তি এবং কাঠামোর মাধ্যমে ডিজাইন করা হয়েছে।
  ​
* ফেডারেটেড লার্নিং: একটি মেশিন লার্নিং পদ্ধতি যেখানে মডেলগুলি বিভিন্ন বিকেন্দ্রীভূত ডিভাইসে, যা স্থানীয় ডেটা নমুনা ধারণ করে, ডেটা বিনিময় না করে প্রশিক্ষিত হয়।
  ​
* গার্ডরেইলস: সীমাবদ্ধতা যা AI সিস্টেমগুলোকে ক্ষতিকর, পূর্বাগ্রাহী বা অন্যথায় অনাকাঙ্ক্ষিত আউটপুট তৈরি থেকে রোধ করতে প্রয়োগ করা হয়।
  ​
* হ্যালুসিনেশন – একটি AI হ্যালুসিনেশন এমন একটি ঘটনা বোঝায় যেখানে একটি AI মডেল অকুর্ত বা বিভ্রান্তিকর তথ্য তৈরি করে যা তার প্রশিক্ষণ ডেটা বা বাস্তব সত্যের উপর ভিত্তি করে নয়।
  ​
* হিউম্যান-ইন-দ্য-লুপ (HITL): সিস্টেমগুলি ডিজাইন করা হয়েছে যা গুরুত্বপূর্ণ সিদ্ধান্ত নেওয়ার পয়েন্টগুলিতে মানব তত্ত্ববধান, যাচাইকরণ, বা হস্তক্ষেপের প্রয়োজন।
  ​
* ইনফ্রাস্ট্রাকচার অ্যাজ কোড (IaC): ম্যানুয়াল প্রক্রিয়ার পরিবর্তে কোডের মাধ্যমে ইনফ্রাস্ট্রাকচার পরিচালনা এবং প্রভিশন করা, যা সিকিউরিটি স্ক্যানিং এবং ধারাবাহিক ডিপ্লয়মেন্ট সক্ষম করে।
  ​
* জেলব্রেক: কৌশল যা AI সিস্টেমে, বিশেষ করে বৃহৎ ভাষা মডেলগুলিতে নিরাপত্তা সুরক্ষা বেষ্টনীগুলো অতিক্রম করতে ব্যবহৃত হয়, নিষিদ্ধ সামগ্রী তৈরি করতে।
  ​
* সর্বনিম্ন অনুমতি: ইউজার এবং প্রক্রিয়াগুলির জন্য শুধুমাত্র সর্বনিম্ন প্রয়োজনীয় প্রবেশাধিকার দেওয়ার সুরক্ষা নীতি।
  ​
* LIME (লোকাল ইন্টারপ্রেটেবল মডেল-এজেনস্টিক এক্সপ্লানেশনস): যেকোনো মেশিন লার্নিং ক্লাসিফায়ারের ভবিষ্যদ্বাণীগুলো ব্যাখ্যা করার একটি কৌশল যা স্থানীয়ভাবে একটি ইন্টারপ্রেটেবল মডেল দিয়ে তা আনুমানিক করে।
  ​
* মেম্বারশিপ ইনফারেন্স আক্রমণ: একটি আক্রমণ যা লক্ষ্য করে নির্ধারণ করা যে নির্দিষ্ট একটি ডেটা পয়েন্ট একটি মেশিন লার্নিং মডেল প্রশিক্ষণের জন্য ব্যবহৃত হয়েছে কিনা।
  ​
* MITRE ATLAS: কৃত্রিম-বুদ্ধিমত্তা সিস্টেমের বিরুদ্ধে প্রতিদ্বন্দ্বী বিপদ পরিমণ্ডল; AI সিস্টেমের বিরুদ্ধে প্রতিদ্বন্দ্বী কৌশল এবং প্রযুক্তির একটি জ্ঞানভিত্তিক ভাণ্ডার।
  ​
* মডেল কার্ড – একটি মডেল কার্ড হলো একটি দলিল যা একটি AI মডেলের কার্যক্ষমতা, সীমাবদ্ধতা, উদ্দেশ্যপ্রণোদিত ব্যবহার এবং নৈতিক বিবেচনাসমূহ সম্পর্কে মানকীকৃত তথ্য প্রদান করে, যা স্বচ্ছতা এবং দায়িত্বশীল AI উন্নয়ন প্রচারের জন্য ব্যবহৃত হয়।
  ​
* মডেল এক্সট্রাকশন: একটি আক্রমণ যেখানে একজন প্রতিপক্ষ বারবার একটি টার্গেট মডেলকে প্রশ্ন করে অনুমতি ছাড়াই কার্যকরীভাবে অনুরূপ একটি কপি তৈরি করে।
  ​
* মডেল ইনভার্শন: একটি আক্রমণ যা মডেল আউটপুট বিশ্লেষণ করে প্রশিক্ষণ ডেটা পুনর্নির্মাণের চেষ্টা করে।
  ​
* মডেল লাইফসাইকেল ম্যানেজমেন্ট – AI মডেল লাইফসাইকেল ম্যানেজমেন্ট হল একটি AI মডেলের অস্তিত্বের সমস্ত ধাপ পর্যবেক্ষণ করার প্রক্রিয়া, যার মধ্যে রয়েছে এর ডিজাইন, উন্নয়ন, স্থাপন, পর্যবেক্ষণ, রক্ষণাবেক্ষণ এবং শেষ পর্যন্ত অবসর নেওয়া, যাতে এটি কার্যকর থাকে এবং উদ্দেশ্যগুলোর সাথে সামঞ্জস্যপূর্ণ থাকে।
  ​
* মডেল পয়জনিং: প্রশিক্ষণ প্রক্রিয়ার সময় সরাসরি একটি মডেলের মধ্যে দুর্বলতা বা ব্যাকডোর সংযোজন।
  ​
* মডেল চুরি/চুরি: বারবার প্রশ্নের মাধ্যমে একটি মালিকানাধীন মডেলের একটি অনুলিপি বা আনুমানিক কপি বের করা।
  ​
* মাল্টি-এজেন্ট সিস্টেম: একাধিক পরস্পরের সাথে ক্রিয়াশীল AI এজেন্ট নিয়ে গঠিত একটি সিস্টেম, যার প্রত্যেকটির সম্ভাব্য ভিন্ন ক্ষমতা এবং লক্ষ্য থাকতে পারে।
  ​
* OPA (ওপেন পলিসি এজেন্ট): একটি ওপেন-সোর্স পলিসি ইঞ্জিন যা স্ট্যাক জুড়ে একক Pপলিসি প্রয়োগ সক্ষম করে।
  ​
* গোপনীয়তা রক্ষাকারী মেশিন লার্নিং (PPML): প্রশিক্ষণ ডেটার গোপনীয়তা সুরক্ষিত রেখে এমএল মডেলগুলি প্রশিক্ষণ এবং মোতায়েন করার কৌশল এবং পদ্ধতি।
  ​
* প্ৰম্পট ইঞ্জেকশন: একধৰণৰ আক্ৰমণ য'ত দূষিত নিৰ্দেশাবলী ইনপুটসমূহত সন্নিৱিষ্ট কৰা হয় মডেলৰ উদ্দেশ্যমূলক আচৰণক অধিকাৰ কৰি থবলৈ।
  ​
* RAG (রিট্রিভাল-অগমেন্টেড জনারেশন): একটি প্রযুক্তি যা বড় ভাষা মডেলকে উন্নত করে বাহ্যিক জ্ঞান উৎস থেকে প্রাসঙ্গিক তথ্য উদ্ধার করে প্রতিক্রিয়া তৈরি করার আগে।
  ​
* রেড-টিমিং: প্রতিস্ঠানীয় আক্রমণের মাধ্যমে কৃত্রিম বুদ্ধিমত্তা সিস্টেমগুলিকে সক্রিয়ভাবে পরীক্ষা করার প্রক্রিয়া, যা দুর্বলতা চিহ্নিত করে।
  ​
* SBOM (সফটওয়্যার বিল অফ ম্যাটেরিয়ালস): সফটওয়্যার বা AI মডেল তৈরিতে ব্যবহৃত বিভিন্ন উপাদানের বিবরণ এবং সরবরাহ চেইন সম্পর্কগুলির একটি আনুষ্ঠানিক রেকর্ড।
  ​
* SHAP (শ্যাপলেয় এডিটিভ এক্সপ্লেনেশনস): যেকোনো মেশিন লার্নিং মডেলের আউটপুট ব্যাখ্যা করার জন্য একটি গেম থিওরেটিক পদ্ধতি, যা প্রতিটি ফিচারের ভবিষ্যদ্বাণীতে অবদানের পরিমাণ গণনা করে।
  ​
* সরবরাহ শৃঙ্খল আক্রমণ: তৃতীয় পক্ষের লাইব্রেরি, ডেটাসেট বা প্রি-ট্রেইনড মডেলগুলির মতো তার সরবরাহ শৃঙ্খলের কম সুরক্ষিত উপাদানগুলোকে লক্ষ্য করে একটি সিস্টেমের নিরাপত্তা ভঙ্গ করা।
  ​
* ট্রান্সফার লার্নিং: একটি কৌশল যেখানে একটি নির্দিষ্ট কাজের জন্য তৈরি মডেলটি দ্বিতীয় কাজের জন্য মডেলের শুরু বিন্দু হিসেবে পুনঃব্যবহার করা হয়।
  ​
* ভেক্টর ডাটাবেস: একটি বিশেষায়িত ডাটাবেস যা উচ্চ-মাপের ভেক্টর (এম্বেডিংস) সংরক্ষণ করার জন্য এবং কার্যকর সাদৃশ্য অনুসন্ধান সম্পাদনের জন্য ডিজাইন করা হয়েছে।
  ​
* ভালনারেবিলিটি স্ক্যানিং: স্বয়ংক্রিয় সরঞ্জাম যা সফটওয়্যার উপাদানগুলিতে পরিচিত সুরক্ষা দুর্বলতাগুলি যেমন AI ফ্রেমওয়ার্ক এবং নির্ভরশীলতাগুলি চিহ্নিত করে।
  ​
* ওয়াটারমার্কিং: AI-উৎপাদিত সামগ্রীতে অদৃশ্য চিহ্ন স্থাপন করার কৌশল যা এর উত্স অনুসরণ বা AI উৎপত্তি সনাক্ত করতে ব্যবহৃত হয়।
  ​
* জিরো-ডে দুর্বলতা: একটি পূর্বে অজানা দুর্বলতা যা আক্রমণকারীরা ডেভেলপাররা একটি প্যাচ তৈরি এবং স্থাপন করার আগে শোষণ করতে পারে।

